{"kind": "Listing", "data": {"after": "t3_149k0bx", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "That is all", "author_fullname": "t2_vm5kbtxr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I missed you guys", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1497ngt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 122, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 122, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686748613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;That is all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1497ngt", "is_robot_indexable": true, "report_reasons": null, "author": "srevolve", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1497ngt/i_missed_you_guys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1497ngt/i_missed_you_guys/", "subreddit_subscribers": 110479, "created_utc": 1686748613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Started a year ago with microsoft exams, started a minimum wage job doing DE and have been for 10 months and I've been offered an amazing job actually helping people and also exploring analytics/datascience and other stuff too. \n\nComplete DE freedom to engineer and explore and find ways to help people, bonus is its 1.5x my salary and offers senior level relatively quickly. \n\nI've always struggled and felt like an imposter but in such a short time I've come far and I can't wait to learn more. \n\nI suck at doing off job projects, I prefer having  data shoved in my face and told to fix or do something with it!\n\nHad a rough year but this has worked out amazingly and I'm thankful for everyone's support!\n\n(Sorry if it's slight brag)", "author_fullname": "t2_6o5h731v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 year since I started data engineer and I found the job of my dreams while you guys were gone \ud83d\ude2d", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149fhb7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 77, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 77, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686767941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Started a year ago with microsoft exams, started a minimum wage job doing DE and have been for 10 months and I&amp;#39;ve been offered an amazing job actually helping people and also exploring analytics/datascience and other stuff too. &lt;/p&gt;\n\n&lt;p&gt;Complete DE freedom to engineer and explore and find ways to help people, bonus is its 1.5x my salary and offers senior level relatively quickly. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve always struggled and felt like an imposter but in such a short time I&amp;#39;ve come far and I can&amp;#39;t wait to learn more. &lt;/p&gt;\n\n&lt;p&gt;I suck at doing off job projects, I prefer having  data shoved in my face and told to fix or do something with it!&lt;/p&gt;\n\n&lt;p&gt;Had a rough year but this has worked out amazingly and I&amp;#39;m thankful for everyone&amp;#39;s support!&lt;/p&gt;\n\n&lt;p&gt;(Sorry if it&amp;#39;s slight brag)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "149fhb7", "is_robot_indexable": true, "report_reasons": null, "author": "anonymous6156", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149fhb7/1_year_since_i_started_data_engineer_and_i_found/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149fhb7/1_year_since_i_started_data_engineer_and_i_found/", "subreddit_subscribers": 110479, "created_utc": 1686767941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just curious, whenever I look for examples and syntax, Apache has these one-liners like \"this is what it is and don't ask anymore questions\" lol.\n\n[https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.row\\_number.html?highlight=row\\_number#pyspark.sql.functions.row\\_number](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.row_number.html?highlight=row_number#pyspark.sql.functions.row_number)\n\nCompared to Pandas docs, for example, which are more descriptive and useful. Thoughts?", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 1, "clicked": false, "title": "why is Apache Pyspark documentation so...sparse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149g5zk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 74, "total_awards_received": 1, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 74, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_2": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686769576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious, whenever I look for examples and syntax, Apache has these one-liners like &amp;quot;this is what it is and don&amp;#39;t ask anymore questions&amp;quot; lol.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.row_number.html?highlight=row_number#pyspark.sql.functions.row_number\"&gt;https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.sql.functions.row_number.html?highlight=row_number#pyspark.sql.functions.row_number&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Compared to Pandas docs, for example, which are more descriptive and useful. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 500, "id": "gid_2", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 100, "icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png", "days_of_premium": 7, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Gives 100 Reddit Coins and a week of r/lounge access and ad-free browsing.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Gold", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/gold_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/gold_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/gold_512.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149g5zk", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149g5zk/why_is_apache_pyspark_documentation_sosparse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149g5zk/why_is_apache_pyspark_documentation_sosparse/", "subreddit_subscribers": 110479, "created_utc": 1686769576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a3kj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The \"Big Three's\" Data Storage Offerings", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_149urpv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 69, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 69, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kTLt1vS-piYXFh1mKJXM_Op8tJCHs5sT7_hCkPofglI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686810263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ao5lvu6rk46b1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ao5lvu6rk46b1.png?auto=webp&amp;v=enabled&amp;s=27c4f5642ec71a6917eb144a3b186bdb72f620e6", "width": 3000, "height": 4396}, "resolutions": [{"url": "https://preview.redd.it/ao5lvu6rk46b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=267d77192297b3165b5bccfb8e4b9e3c1abeb6a2", "width": 108, "height": 158}, {"url": "https://preview.redd.it/ao5lvu6rk46b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e5178e30536621b9a6fe9b56b116d220e115d4f8", "width": 216, "height": 316}, {"url": "https://preview.redd.it/ao5lvu6rk46b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=402d13fab01a7840e1298aaacfcf5ff1b1f954a6", "width": 320, "height": 468}, {"url": "https://preview.redd.it/ao5lvu6rk46b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d34030a3563af43f0422d1a2b95220bd365a1b57", "width": 640, "height": 937}, {"url": "https://preview.redd.it/ao5lvu6rk46b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b1eaa1596ba60797c50b966062f88b6681fa1e3c", "width": 960, "height": 1406}, {"url": "https://preview.redd.it/ao5lvu6rk46b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=606373e96a0a8eb4d4f075533460ddf1a84d797f", "width": 1080, "height": 1582}], "variants": {}, "id": "JVIhxd8crozI4pTCAovrd8ipptSOJkbKIIS5_iTA3H8"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149urpv", "is_robot_indexable": true, "report_reasons": null, "author": "Kickass_Wizard", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149urpv/the_big_threes_data_storage_offerings/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ao5lvu6rk46b1.png", "subreddit_subscribers": 110479, "created_utc": 1686810263.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\n\n\n\n\nBefore, I saw several people who said that it was right to study while working, but I always thought that these people took the time to do some new mooc not very work-related. What I understood is that actually the best way to learn is to work on real work projects that use new knowledge, research and whatever else I need to develop myself, before I only studied tools and programming languages that I wouldn't even use in the work. I can even use moocs, but for projects that make sense and that I'm working on. Before, I was very tired of studying outside of work, sometimes even on the weekend and I didn't have the expected results, I believe that this way I can reach seniority at work. Do you also do something similar to this? I believe that dedicating work hours to the connection between work and study is much more valuable than simply taking an online course and not having daily practice with what you learned. I will no longer study after work hours, even to have a healthy balance in life.", "author_fullname": "t2_cne2tl51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I think I finally understand the relationship between learning and work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1496ukf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686746400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Before, I saw several people who said that it was right to study while working, but I always thought that these people took the time to do some new mooc not very work-related. What I understood is that actually the best way to learn is to work on real work projects that use new knowledge, research and whatever else I need to develop myself, before I only studied tools and programming languages that I wouldn&amp;#39;t even use in the work. I can even use moocs, but for projects that make sense and that I&amp;#39;m working on. Before, I was very tired of studying outside of work, sometimes even on the weekend and I didn&amp;#39;t have the expected results, I believe that this way I can reach seniority at work. Do you also do something similar to this? I believe that dedicating work hours to the connection between work and study is much more valuable than simply taking an online course and not having daily practice with what you learned. I will no longer study after work hours, even to have a healthy balance in life.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1496ukf", "is_robot_indexable": true, "report_reasons": null, "author": "gintokiredditbr", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1496ukf/i_think_i_finally_understand_the_relationship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1496ukf/i_think_i_finally_understand_the_relationship/", "subreddit_subscribers": 110479, "created_utc": 1686746400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone. Just wanted to let you know that there\u2019s a 5 book bundle @ [Humble Bundle](https://www.humblebundle.com/books/popular-programming-languages-2023-oreilly-books?hmb_source=&amp;hmb_medium=product_tile&amp;hmb_campaign=mosaic_section_1_layout_index_1_layout_type_threes_tile_index_2_c_popularprogramminglanguages2023oreilly_bookbundle) going for 1\u20ac (or more if you want to donate to Code for America) that includes Scala Cookbook, Robust Python and more. There\u2019s also a 10 and 15 book bundle if you\u2019re interested in those books!\n\nOffer ends in 12 days, hope this helped you!", "author_fullname": "t2_9d8b8hr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PSA: Scala Cookbook (+ Robust Python &amp; more books) for 1\u20ac at Humble Bundle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149gppg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686770873.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone. Just wanted to let you know that there\u2019s a 5 book bundle @ &lt;a href=\"https://www.humblebundle.com/books/popular-programming-languages-2023-oreilly-books?hmb_source=&amp;amp;hmb_medium=product_tile&amp;amp;hmb_campaign=mosaic_section_1_layout_index_1_layout_type_threes_tile_index_2_c_popularprogramminglanguages2023oreilly_bookbundle\"&gt;Humble Bundle&lt;/a&gt; going for 1\u20ac (or more if you want to donate to Code for America) that includes Scala Cookbook, Robust Python and more. There\u2019s also a 10 and 15 book bundle if you\u2019re interested in those books!&lt;/p&gt;\n\n&lt;p&gt;Offer ends in 12 days, hope this helped you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?auto=webp&amp;v=enabled&amp;s=145c5031dd9a76b3a193c59bb037b7f969636343", "width": 1120, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff318a3e2d3d005fb2b97fba6815f8e46f0df195", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e533d028be1491f12d960c5d200ac7ab94084045", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdeb2123bb81cdeb7d8445bab1776ec7145007df", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0e1fa92d72d541f6ea0ef6099d91cfc9c6cb4509", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=42abec49d1559a82ba3501a0721124d8bac2044c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/1_PX3qdTAodSNVui3XcRTHc4dIHtwUTeCGa5IKhL0lM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6b179f527a048da516c574ee3436a15d9754f85b", "width": 1080, "height": 607}], "variants": {}, "id": "RyTlK6qn5A-hML7nwk6v7Ctu-pDz9VPLPbeDYzhPn4I"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149gppg", "is_robot_indexable": true, "report_reasons": null, "author": "TauIsRC", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149gppg/psa_scala_cookbook_robust_python_more_books_for_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149gppg/psa_scala_cookbook_robust_python_more_books_for_1/", "subreddit_subscribers": 110479, "created_utc": 1686770873.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm doing work with a client who sends daily reports of order data to an email data connector on Fivetran. The order records are only 1,000 - 2,000 rows daily, but the issue is that the file also contains \\~100,000 empty rows. I was doing some MAR usage tracking this week and realized that **Fivetran is charging us for ingesting the empty rows**.\n\nDoes anyone know a way around this - to avoid FT from charging for the empty rows / considering those valid records?  I'm trying to solve this on the FT side, and not having to goto the client and ask them to alter the way they're currently sending their files.\n\nThanks in advance!", "author_fullname": "t2_6fg82tze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran Charging for Empty Rows in CSV's", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149raph", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686799060.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m doing work with a client who sends daily reports of order data to an email data connector on Fivetran. The order records are only 1,000 - 2,000 rows daily, but the issue is that the file also contains ~100,000 empty rows. I was doing some MAR usage tracking this week and realized that &lt;strong&gt;Fivetran is charging us for ingesting the empty rows&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know a way around this - to avoid FT from charging for the empty rows / considering those valid records?  I&amp;#39;m trying to solve this on the FT side, and not having to goto the client and ask them to alter the way they&amp;#39;re currently sending their files.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "149raph", "is_robot_indexable": true, "report_reasons": null, "author": "plutodoesnotexist", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149raph/fivetran_charging_for_empty_rows_in_csvs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149raph/fivetran_charging_for_empty_rows_in_csvs/", "subreddit_subscribers": 110479, "created_utc": 1686799060.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently reading about the Kimball method in The Data Warehousing Toolkit, 3rd edition. I\u2019m familiar with dimensional modeling in data warehouses, but I\u2019m struggling to understand the difference between 3NF and Dimensional models. It says the key is the degree of normalization\u2026 does this mean still PKs and FKs function the same way as they do in star schemas? is the difference essentially context (dimensional models being source system agnostic)? I wanna make sure I understand this before I move further in the book.", "author_fullname": "t2_tm7d06j2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Difference between 3NF and Dimensional models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_149nipn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cB2pCD0m80y1sH-QBsW1iLtQgYZw8h5cf4A8QxfXtug.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686787957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently reading about the Kimball method in The Data Warehousing Toolkit, 3rd edition. I\u2019m familiar with dimensional modeling in data warehouses, but I\u2019m struggling to understand the difference between 3NF and Dimensional models. It says the key is the degree of normalization\u2026 does this mean still PKs and FKs function the same way as they do in star schemas? is the difference essentially context (dimensional models being source system agnostic)? I wanna make sure I understand this before I move further in the book.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/pjz6do1mq26b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/pjz6do1mq26b1.jpg?auto=webp&amp;v=enabled&amp;s=49e372bda4891f9c71bb69d86c5a2562862a0e37", "width": 1125, "height": 2436}, "resolutions": [{"url": "https://preview.redd.it/pjz6do1mq26b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=039f931dd2c2ecc420bd43b489ff9683610f1da6", "width": 108, "height": 216}, {"url": "https://preview.redd.it/pjz6do1mq26b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=71d1ea217534f39184ba9088c91353c0f1aac0d8", "width": 216, "height": 432}, {"url": "https://preview.redd.it/pjz6do1mq26b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8e2fd6ddc22ef7a71b52c72c679303a399788fe6", "width": 320, "height": 640}, {"url": "https://preview.redd.it/pjz6do1mq26b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5866e50e3086d9f9bae458221136d695756d6e0b", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/pjz6do1mq26b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d8f9a3e1cb986d24d83406d72204f3b94179d78", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/pjz6do1mq26b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a157058202ed7f928d7fca9d080b2cbc02b941b6", "width": 1080, "height": 2160}], "variants": {}, "id": "X0Tc-1PlRGcGa4v3Bb4WfjL0W7n4j9rbvnB82ZGwNNc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "149nipn", "is_robot_indexable": true, "report_reasons": null, "author": "oscarwranglin", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149nipn/difference_between_3nf_and_dimensional_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/pjz6do1mq26b1.jpg", "subreddit_subscribers": 110479, "created_utc": 1686787957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_d8afn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A Continuous Slack=&gt;ChatGPT=&gt;Google Sheets Pipeline using Estuary Flow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149h80m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1686772120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "estuary.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://estuary.dev/gpt-real-time-pipeline/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "149h80m", "is_robot_indexable": true, "report_reasons": null, "author": "johnnygraettinger", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149h80m/a_continuous_slackchatgptgoogle_sheets_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://estuary.dev/gpt-real-time-pipeline/", "subreddit_subscribers": 110479, "created_utc": 1686772120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Help. I'm on the BI team at a large fortune 500 company with immature data pipelines for our analytics reporting and I am struggling. I have more of a tech background than data. Before I joined, reporting for my business domain has been outsourced to an offshore company that has produced unmaintainable/undocumented massive SQL queries with hardcoded conditions scattered/duplicated throughout subqueries and a mess of v1,v2,copy,test tables in production. Understanding the data flow takes hours of data archeology and I'm worried that others will think this a reflection of me rather than the messy structure.\n\nBusiness logic is littered throughout the entire reporting ecosystem (alteryx, stored procs, BI tool cubes, etc) and data ownership and knowledge is split across teams and team members (enterprise data architecture/offshore teams/business owners writing their own sql, etc). Domain reporting is siloed and we are all responsible for building our own data pipelines to our BI reporting tool for our specific domain stakeholders. My domain has the most stakeholders. Our team is not really supposed to be business owner facing but our intermediaries (the analysts) are doing their own thing running queries and building scrappy dashboards for their stakeholders with conversations between our teams mainly being \"how do I do x\" vs true collaboration. I'm consistently bogged down by incidents of things breaking and don't have time to focus on learning what I believe could be the solution to a lot of our problems (spoiler: dbt). The issues are glaringly obvious to me but I'm not always able to articulate my thoughts live (probably because idk what will sink in or make me sound stupid).\n\nThe offshore team that built everything is gone and it's now up to me to become the SME of this domain's data and reporting. I feel like I walked into a trap that will end with me being the face of failure and me pointing out these problems to my leadership comes off as excuses or complaining as this has been seemingly working up until now. (My anxiety about this is through the roof at this point and I've contemplated leaving before this happens).\n\nThe solution to me sounds like we need to scrap everything and model our pipelines correctly in a maintainable way with good documentation right in the code.\n\nHow do I convince my team/department that have been in this space much longer than I have that we need real change to something like dbt to help organize the mess and move forward? I feel like my inexperience and recent output struggles hurts my ability to impact positive change, especially when I basically have to tell the story of why the way the BI team/Analytics dept decided to operate led us to this. Do I continue to struggle and risk being fired or abandon ship for a more data-mature company? I now know want to become a data engineer or analytics engineer and rebuild everything but I can't get out from under the current situation and the stress is eating me alive. Nor do I have the DE hard skills/experience to get where I want to be yet if I were to leave for a similar role.\n\nAny advice at all is very appreciated. Thanks", "author_fullname": "t2_h4xz1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help - how do I promote a better data culture when so new to the space", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1499n97", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686763445.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686753697.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Help. I&amp;#39;m on the BI team at a large fortune 500 company with immature data pipelines for our analytics reporting and I am struggling. I have more of a tech background than data. Before I joined, reporting for my business domain has been outsourced to an offshore company that has produced unmaintainable/undocumented massive SQL queries with hardcoded conditions scattered/duplicated throughout subqueries and a mess of v1,v2,copy,test tables in production. Understanding the data flow takes hours of data archeology and I&amp;#39;m worried that others will think this a reflection of me rather than the messy structure.&lt;/p&gt;\n\n&lt;p&gt;Business logic is littered throughout the entire reporting ecosystem (alteryx, stored procs, BI tool cubes, etc) and data ownership and knowledge is split across teams and team members (enterprise data architecture/offshore teams/business owners writing their own sql, etc). Domain reporting is siloed and we are all responsible for building our own data pipelines to our BI reporting tool for our specific domain stakeholders. My domain has the most stakeholders. Our team is not really supposed to be business owner facing but our intermediaries (the analysts) are doing their own thing running queries and building scrappy dashboards for their stakeholders with conversations between our teams mainly being &amp;quot;how do I do x&amp;quot; vs true collaboration. I&amp;#39;m consistently bogged down by incidents of things breaking and don&amp;#39;t have time to focus on learning what I believe could be the solution to a lot of our problems (spoiler: dbt). The issues are glaringly obvious to me but I&amp;#39;m not always able to articulate my thoughts live (probably because idk what will sink in or make me sound stupid).&lt;/p&gt;\n\n&lt;p&gt;The offshore team that built everything is gone and it&amp;#39;s now up to me to become the SME of this domain&amp;#39;s data and reporting. I feel like I walked into a trap that will end with me being the face of failure and me pointing out these problems to my leadership comes off as excuses or complaining as this has been seemingly working up until now. (My anxiety about this is through the roof at this point and I&amp;#39;ve contemplated leaving before this happens).&lt;/p&gt;\n\n&lt;p&gt;The solution to me sounds like we need to scrap everything and model our pipelines correctly in a maintainable way with good documentation right in the code.&lt;/p&gt;\n\n&lt;p&gt;How do I convince my team/department that have been in this space much longer than I have that we need real change to something like dbt to help organize the mess and move forward? I feel like my inexperience and recent output struggles hurts my ability to impact positive change, especially when I basically have to tell the story of why the way the BI team/Analytics dept decided to operate led us to this. Do I continue to struggle and risk being fired or abandon ship for a more data-mature company? I now know want to become a data engineer or analytics engineer and rebuild everything but I can&amp;#39;t get out from under the current situation and the stress is eating me alive. Nor do I have the DE hard skills/experience to get where I want to be yet if I were to leave for a similar role.&lt;/p&gt;\n\n&lt;p&gt;Any advice at all is very appreciated. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1499n97", "is_robot_indexable": true, "report_reasons": null, "author": "soorr", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1499n97/help_how_do_i_promote_a_better_data_culture_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1499n97/help_how_do_i_promote_a_better_data_culture_when/", "subreddit_subscribers": 110479, "created_utc": 1686753697.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Check out an E2E example of the beneof the new dagster DBT Integration in my blog post https://georgheiler.com/2023/06/13/unlocking-advanced-metadata-extraction-with-the-new-dbt-api-in-dagster/", "author_fullname": "t2_8dvvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster DBT and OpenMetadata", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1499w55", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686754275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Check out an E2E example of the beneof the new dagster DBT Integration in my blog post &lt;a href=\"https://georgheiler.com/2023/06/13/unlocking-advanced-metadata-extraction-with-the-new-dbt-api-in-dagster/\"&gt;https://georgheiler.com/2023/06/13/unlocking-advanced-metadata-extraction-with-the-new-dbt-api-in-dagster/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4P3UUg0HhqroVHjWhbbBN5b0dW1Rmw9ECmuTHFILN7s.jpg?auto=webp&amp;v=enabled&amp;s=aa32a37254e14adf3e475b1006064c87146e67e5", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/4P3UUg0HhqroVHjWhbbBN5b0dW1Rmw9ECmuTHFILN7s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9d49440a898cd6eb78c5939cfe2480f33ac70d48", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/4P3UUg0HhqroVHjWhbbBN5b0dW1Rmw9ECmuTHFILN7s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=524221a933940f49dcb7659be8ffb496cb1bc1de", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/4P3UUg0HhqroVHjWhbbBN5b0dW1Rmw9ECmuTHFILN7s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29354e993b55adf8026761862b447fbf5c028285", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/4P3UUg0HhqroVHjWhbbBN5b0dW1Rmw9ECmuTHFILN7s.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=655bf1b2c7e35f378533d0b18ea04bad6a18830f", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/4P3UUg0HhqroVHjWhbbBN5b0dW1Rmw9ECmuTHFILN7s.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ea6342f16cde2177b5af1ed2ea83a69a739056ac", "width": 960, "height": 960}], "variants": {}, "id": "9XePCxBEEF3qzr3JG-bBuvoOQn1z5ZLCXspSZIlahwc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1499w55", "is_robot_indexable": true, "report_reasons": null, "author": "geoheil", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1499w55/dagster_dbt_and_openmetadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1499w55/dagster_dbt_and_openmetadata/", "subreddit_subscribers": 110479, "created_utc": 1686754275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are some issues that data teams face in comparison to SWE (typical web/mobile) teams?\n\nOne thing I\u2019ve noticed is that my peers on the SWE side have more dedicated and specialized roles:  project/product managers, architect, principal or staff positions, UI/UX, note-takers, among others.\n\nWhereas every company I\u2019ve worked for has expected data team members to wear all of the hats (design, architecture, implementation, communication, and delivery/analysis).\n\nLike I\u2019m put in situations where I\u2019m given a short timeline, and I\u2019m expected to flesh out all of the Jira tickets, communicate it out to stakeholders, gather all the requirements, think up the design for this new problem, sell the architecture to stakeholders, implement it (including creating tests and deployment infrastructure), configure monitoring, and then follow-up with thorough communications and updates throughout this whole process.\n\nWhereas my SWE counterparts have their tickets handed to them, implement the feature, and merge that jawn to main when it\u2019s ready while providing intermittent updates to the PM.\n\nMy experience seems pretty normal for DE, but is my understanding of SWE correct (at a well-run shop), and should this experience be normal for DE?", "author_fullname": "t2_f16v22yv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Problems more unique to DE than SWE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149l0up", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686781350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some issues that data teams face in comparison to SWE (typical web/mobile) teams?&lt;/p&gt;\n\n&lt;p&gt;One thing I\u2019ve noticed is that my peers on the SWE side have more dedicated and specialized roles:  project/product managers, architect, principal or staff positions, UI/UX, note-takers, among others.&lt;/p&gt;\n\n&lt;p&gt;Whereas every company I\u2019ve worked for has expected data team members to wear all of the hats (design, architecture, implementation, communication, and delivery/analysis).&lt;/p&gt;\n\n&lt;p&gt;Like I\u2019m put in situations where I\u2019m given a short timeline, and I\u2019m expected to flesh out all of the Jira tickets, communicate it out to stakeholders, gather all the requirements, think up the design for this new problem, sell the architecture to stakeholders, implement it (including creating tests and deployment infrastructure), configure monitoring, and then follow-up with thorough communications and updates throughout this whole process.&lt;/p&gt;\n\n&lt;p&gt;Whereas my SWE counterparts have their tickets handed to them, implement the feature, and merge that jawn to main when it\u2019s ready while providing intermittent updates to the PM.&lt;/p&gt;\n\n&lt;p&gt;My experience seems pretty normal for DE, but is my understanding of SWE correct (at a well-run shop), and should this experience be normal for DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149l0up", "is_robot_indexable": true, "report_reasons": null, "author": "etl_boi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149l0up/problems_more_unique_to_de_than_swe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149l0up/problems_more_unique_to_de_than_swe/", "subreddit_subscribers": 110479, "created_utc": 1686781350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As of now our team is pretty old-school and everyone creates their own local dev environment using a `requirements.txt` file and a bootstrapping doc that outlines any other steps necessary to recreate prod.  We have images for our Airflow servers for easy redeployment, and we're considering containerizing these to use for local dev work.  This seems like a natural progression, and will reduce any room for issues or inconsistencies in setting up a dev environment.  For anyone who's done or considered this, what are your thoughts? And what best practices should we be following?", "author_fullname": "t2_22ksp1z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone here use a container (Docker or otherwise) as their development environment? What are the best practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149igv5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686775839.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686775092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As of now our team is pretty old-school and everyone creates their own local dev environment using a &lt;code&gt;requirements.txt&lt;/code&gt; file and a bootstrapping doc that outlines any other steps necessary to recreate prod.  We have images for our Airflow servers for easy redeployment, and we&amp;#39;re considering containerizing these to use for local dev work.  This seems like a natural progression, and will reduce any room for issues or inconsistencies in setting up a dev environment.  For anyone who&amp;#39;s done or considered this, what are your thoughts? And what best practices should we be following?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149igv5", "is_robot_indexable": true, "report_reasons": null, "author": "x1084", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149igv5/does_anyone_here_use_a_container_docker_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149igv5/does_anyone_here_use_a_container_docker_or/", "subreddit_subscribers": 110479, "created_utc": 1686775092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, maybe a bit of a naive question. Our company traditionally uses Informatica as our ETL for a long time. \n\nOur team is looking for something a bit more UI friendly to do ETL or ELT. My question is can we use Fivetran to ingest from various sources (I know fivetran offers over 200+). Then use Fivetran to parse xml, json, etc into .csv for analytics ready? Or do we need a different tool? \n\nHow much volume fivetran can handle? What are the pros and cons?", "author_fullname": "t2_vlbvypwa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Fivetran for ingestion and transforming", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ibrz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686774743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, maybe a bit of a naive question. Our company traditionally uses Informatica as our ETL for a long time. &lt;/p&gt;\n\n&lt;p&gt;Our team is looking for something a bit more UI friendly to do ETL or ELT. My question is can we use Fivetran to ingest from various sources (I know fivetran offers over 200+). Then use Fivetran to parse xml, json, etc into .csv for analytics ready? Or do we need a different tool? &lt;/p&gt;\n\n&lt;p&gt;How much volume fivetran can handle? What are the pros and cons?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "149ibrz", "is_robot_indexable": true, "report_reasons": null, "author": "dataeng_328", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149ibrz/using_fivetran_for_ingestion_and_transforming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149ibrz/using_fivetran_for_ingestion_and_transforming/", "subreddit_subscribers": 110479, "created_utc": 1686774743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been brought in at this company to help them with their reporting. In 1.5 years we are on the 4th iteration due to lack of data engineering capacity and now the holy grail that is ringing around the water cooler is a new data model, based on untrustworthy sources will solve all reporting issues.\n\nI am pretty fed up but do not have enough DE expertise to convince the manager that we are taking a wrong turn here and that moving to a new data model will actually make the reporting quality worse. Any suggestions what to do?\n\n1st iteration: moved transformations from visualization tool (Power BI) to reporting schema in views in Serverless SQL - quick win\n\n2nd iteration: rewrote SQL to be more optimized due to data volume being too large (which sounds weird since we are talking about 5/6 sources with # rows varying between 500k - 9m)\n\n3rd iteration (current): had a freelancer create a pipeline to write SQL views to external tables using parquet\n\n4th iteration (to be): new Serverless SQL environment where I am tasked with creating a new data model in views that will be written to external tables overnight\n\nThe base of these are csv files that are processed overnight using ADF and these sources are all historized in parquet files using an SCD2 type mechanism: they are given a startdate, but enddate is solved in a view.\n\nAll columns are processed as maxed varchars, there are no data quality checks, source\\_a that is fed into the production environment of source\\_b does not include the unique id from source\\_a so matching these things is arbitrary on similar characteristics. The DE consultants are pushing different environments for development, testing and production while our analysts are drowning in reporting work and are not allowed to create their own tables and/or files.", "author_fullname": "t2_2sss2inq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I wrong here? Tasked with data modeling using only views, 4th iteration in 1.5 years", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149xd8e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686819604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been brought in at this company to help them with their reporting. In 1.5 years we are on the 4th iteration due to lack of data engineering capacity and now the holy grail that is ringing around the water cooler is a new data model, based on untrustworthy sources will solve all reporting issues.&lt;/p&gt;\n\n&lt;p&gt;I am pretty fed up but do not have enough DE expertise to convince the manager that we are taking a wrong turn here and that moving to a new data model will actually make the reporting quality worse. Any suggestions what to do?&lt;/p&gt;\n\n&lt;p&gt;1st iteration: moved transformations from visualization tool (Power BI) to reporting schema in views in Serverless SQL - quick win&lt;/p&gt;\n\n&lt;p&gt;2nd iteration: rewrote SQL to be more optimized due to data volume being too large (which sounds weird since we are talking about 5/6 sources with # rows varying between 500k - 9m)&lt;/p&gt;\n\n&lt;p&gt;3rd iteration (current): had a freelancer create a pipeline to write SQL views to external tables using parquet&lt;/p&gt;\n\n&lt;p&gt;4th iteration (to be): new Serverless SQL environment where I am tasked with creating a new data model in views that will be written to external tables overnight&lt;/p&gt;\n\n&lt;p&gt;The base of these are csv files that are processed overnight using ADF and these sources are all historized in parquet files using an SCD2 type mechanism: they are given a startdate, but enddate is solved in a view.&lt;/p&gt;\n\n&lt;p&gt;All columns are processed as maxed varchars, there are no data quality checks, source_a that is fed into the production environment of source_b does not include the unique id from source_a so matching these things is arbitrary on similar characteristics. The DE consultants are pushing different environments for development, testing and production while our analysts are drowning in reporting work and are not allowed to create their own tables and/or files.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "149xd8e", "is_robot_indexable": true, "report_reasons": null, "author": "foldingtoiletpaper", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149xd8e/am_i_wrong_here_tasked_with_data_modeling_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149xd8e/am_i_wrong_here_tasked_with_data_modeling_using/", "subreddit_subscribers": 110479, "created_utc": 1686819604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello beautiful people,\n\nMy organization is considering to migrate from dbt to dataform. We are using GBQ as the data warehouse. Is it a good idea to move from dbt to dataform? What are the pros and cons? \n\nI searched this forum for the same questions. The answers were pretty old. I was thinking if the attitude towards dataform could have changed in the couple of months. Maybe.\n\nCan you give you ideas, please?\n\nThanks", "author_fullname": "t2_auriunhuo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt vs Dataform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149rv4a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "a96f3daa-e787-11ed-bb3c-927138abd1d2", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686800826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello beautiful people,&lt;/p&gt;\n\n&lt;p&gt;My organization is considering to migrate from dbt to dataform. We are using GBQ as the data warehouse. Is it a good idea to move from dbt to dataform? What are the pros and cons? &lt;/p&gt;\n\n&lt;p&gt;I searched this forum for the same questions. The answers were pretty old. I was thinking if the attitude towards dataform could have changed in the couple of months. Maybe.&lt;/p&gt;\n\n&lt;p&gt;Can you give you ideas, please?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Junior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149rv4a", "is_robot_indexable": true, "report_reasons": null, "author": "Interesting-Rub-3984", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/149rv4a/dbt_vs_dataform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149rv4a/dbt_vs_dataform/", "subreddit_subscribers": 110479, "created_utc": 1686800826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am interested in learning KDB+ because getting into fund trading industry is always what I desire.\n\nI just realise so many investment bank trading teams and hedge funds are still using KDB+.\n\nIs there any learning material or beginner project for me to learn KDB+?\n\nThank you!", "author_fullname": "t2_txqvauef", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is anyone now learning KDB+?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149djon", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686763242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am interested in learning KDB+ because getting into fund trading industry is always what I desire.&lt;/p&gt;\n\n&lt;p&gt;I just realise so many investment bank trading teams and hedge funds are still using KDB+.&lt;/p&gt;\n\n&lt;p&gt;Is there any learning material or beginner project for me to learn KDB+?&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149djon", "is_robot_indexable": true, "report_reasons": null, "author": "Dice__R", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149djon/is_anyone_now_learning_kdb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149djon/is_anyone_now_learning_kdb/", "subreddit_subscribers": 110479, "created_utc": 1686763242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A tech lead asked me to look into managing permissions and users on redshift for a ~100TB DB that around a dozen colleagues (data engineers, software engineers, data scientists, analysts) will be pulling pulling data from, creating new tables, running analysis, etc.  \n\nI am wondering what the general convention is here. Are you guys all just sharing admin credentials around the team (current practice in my team)? Do you have someone fulfill a DBA role that creates users inside of redshift, grants permissions, and sends them around to team members? Do you use [IAM roles to authenticate](https://docs.aws.amazon.com/redshift/latest/mgmt/generating-user-credentials.html)? \n\nElse, any good resources for role/user/permission management?", "author_fullname": "t2_kdj5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing Redshift Users", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149c85c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686759999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A tech lead asked me to look into managing permissions and users on redshift for a ~100TB DB that around a dozen colleagues (data engineers, software engineers, data scientists, analysts) will be pulling pulling data from, creating new tables, running analysis, etc.  &lt;/p&gt;\n\n&lt;p&gt;I am wondering what the general convention is here. Are you guys all just sharing admin credentials around the team (current practice in my team)? Do you have someone fulfill a DBA role that creates users inside of redshift, grants permissions, and sends them around to team members? Do you use &lt;a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/generating-user-credentials.html\"&gt;IAM roles to authenticate&lt;/a&gt;? &lt;/p&gt;\n\n&lt;p&gt;Else, any good resources for role/user/permission management?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149c85c", "is_robot_indexable": true, "report_reasons": null, "author": "Touvejs", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149c85c/managing_redshift_users/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149c85c/managing_redshift_users/", "subreddit_subscribers": 110479, "created_utc": 1686759999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a scraper application that I want to run sporadically. The goal is to have a database for this but since it's really just a minor pet project/POC, I am totally not willing to use any managed SQL service because they are super expensive. But I do want a relational database. I was thinking I could just make use of SQLite? Has anyone done this before, can I just save the .db in cloud storage and use a connector?\n\nEdit: how about if I just use BigQuery. This data I have is not even 1GB, so it should be basically free, right?", "author_fullname": "t2_genrcwic", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cheap SQL in GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149bpxt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686760151.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686758755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a scraper application that I want to run sporadically. The goal is to have a database for this but since it&amp;#39;s really just a minor pet project/POC, I am totally not willing to use any managed SQL service because they are super expensive. But I do want a relational database. I was thinking I could just make use of SQLite? Has anyone done this before, can I just save the .db in cloud storage and use a connector?&lt;/p&gt;\n\n&lt;p&gt;Edit: how about if I just use BigQuery. This data I have is not even 1GB, so it should be basically free, right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "149bpxt", "is_robot_indexable": true, "report_reasons": null, "author": "nacho_biznis", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149bpxt/cheap_sql_in_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149bpxt/cheap_sql_in_gcp/", "subreddit_subscribers": 110479, "created_utc": 1686758755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Everyone! I am looking for an in-depth explanations with examples of the different ETL (mostly T) services that GCP offers and when to use what, if anyone has a good resources (or don\u2019t mind writing it here) please share.\nLooking for when to use DataProc (lift and shift of Hadoop) VS Dataflow (for streaming) VS DataFusion (kind of basic version of Informatica/SSIS) VS SP in BigQuery (for ELT), I even worked in company where they are doing the T in Composer itself which is causing a hell of troubles and Composer Cluster is downtown more then up most of the times. Feel free to share the current architecture in your current company, real GCP projects are very limited on the internet. Appreciate everyone\u2019s help and time!", "author_fullname": "t2_6ot8pfmy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL - GCP Services !!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ar42", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686756393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone! I am looking for an in-depth explanations with examples of the different ETL (mostly T) services that GCP offers and when to use what, if anyone has a good resources (or don\u2019t mind writing it here) please share.\nLooking for when to use DataProc (lift and shift of Hadoop) VS Dataflow (for streaming) VS DataFusion (kind of basic version of Informatica/SSIS) VS SP in BigQuery (for ELT), I even worked in company where they are doing the T in Composer itself which is causing a hell of troubles and Composer Cluster is downtown more then up most of the times. Feel free to share the current architecture in your current company, real GCP projects are very limited on the internet. Appreciate everyone\u2019s help and time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "149ar42", "is_robot_indexable": true, "report_reasons": null, "author": "WeirdWorldDz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149ar42/etl_gcp_services/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149ar42/etl_gcp_services/", "subreddit_subscribers": 110479, "created_utc": 1686756393.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company has recently gone through a merger. My team and I, an executive of the company, faced many issues that took too much time to solve. That got me thinking: how many other executives and team leads out there will have to struggle through the same issues, and how can I help them prepare? This is why I gathered some useful information that I believe could be useful for many people.\n\n  \nMergers and acquisitions (M&amp;A) bring about significant shifts in operations and culture for employees and the impact of data-related challenges on these aspects is frequently overlooked. Ensure you or your company are not making the same mistake.\n\n  \nMergers and acquisitions often trigger substantial organizational uncertainty about what lies ahead: typically, the operational model and culture undergo significant transformations for one or both of the merging entities. These alterations extend beyond just a new name and executive leadership; first and foremost, M&amp;A change the way IT teams work. Anticipating and addressing these IT challenges can pave the way for smooth and efficient integration. Conversely, failure to foresee and manage these issues can result in poor business performance, attrition of key talent, and potential data breaches. In this article, experts from AINSYS delve into the IT complications that can emerge during and post M&amp;A, and provide tools for addressing them effectively.\n\n  \nDuring and after M&amp;A, two companies\u2019 tech stacks essentially collide, and IT management has to deal with a number of challenges:\n\n# 1. Integrating disparate systems and platforms\n\nIntegrating disparate systems and platforms is one of the most significant challenges during mergers and acquisitions. When two companies come together, they often bring with them different IT systems and platforms that have been tailored to their specific business processes and needs. These systems can range from customer relationship management (CRM) and enterprise resource planning (ERP) systems, to data management platforms, financial systems, and more.  \nHere are some of the key issues that arise during this integration process:\n\n* Compatibility: the systems used by the merging companies may not be compatible. They may be built on different architectures, use different data formats, or be based on different technologies. This can make integration a complex and time-consuming process;\n* Data Consistency: each system may have its own way of storing and structuring data. Ensuring consistency in data definitions, formats, and structures across all systems is crucial to avoid confusion and errors in data analysis and decision-making;\n* Redundancy: there may be significant overlap in the functionality of the systems used by the two companies, leading to redundancy. Identifying and eliminating these redundancies is important to avoid unnecessary costs and complexity;\n* Security and Compliance: each system will have its own security measures and compliance requirements. Ensuring that the integrated system meets all necessary security standards and regulatory requirements is crucial;\n* User Training: Employees from each company will be familiar with their own systems, but may need training to use the new integrated system effectively;\n* System Performance: Integrating two systems can put a strain on the performance of the IT infrastructure. Ensuring the integrated system performs effectively without causing downtime or delays is important.\n\n2. Reconciling different data formats and standards\n\nWhen two companies merge, they bring with them different data systems that have been tailored to their specific needs and processes. These systems may use different data formats and adhere to different data standards, which can create several issues during integration, including data inconsistency, data loss (if one system uses a data format that the other system does not support, some data may be lost during the conversion process, leading to incomplete or inaccurate data in the integrated system), data quality (one system might allow for missing values in certain fields, while the other does not), and compliance issues.\n\n3. Significant differences in the technological maturity between the two companies\n\nIf one of the companies has a significant technological advantage over the other, several issues may arise:\n\n* Integration Complexity: if one company uses modern, cloud-based systems while the other still relies on legacy systems, integrating the two can be complex and time-consuming. It may require significant resources to upgrade or replace outdated systems;\n* Operational Disruptions: if one company\u2019s systems are automated and the other\u2019s are manual, it could disrupt business processes and workflows until the less advanced systems are upgraded;\n* Security Risks: Older, less advanced systems may have more vulnerabilities, increasing the risk of data breaches or cyberattacks. It\u2019s crucial to assess and address these risks as part of the integration process.\n\n4. Considering the human element\n\nThis is perhaps the most complex and difficult issue to solve, seeing as no specialist is alike and supporting employees through change in M&amp;A is the most important matter you will need to solve. Why is that? Well, the reason is that the success of any merger or acquisition is not just about integrating systems and processes, but also about bringing together people from different organizational cultures. Employees are the backbone of any organization, and their acceptance and adaptation to change can significantly impact the outcome of the M&amp;A.\n\n  \nThe problem is, employees are conservative and don\u2019t want to switch from systems they have been using for years, having to learn new skills to actually use them. Additionally, companies often have to hire additional employees or IT consultants in order to support them through the process.  \nAnd it is not like executives can allow their employees to take their sweet time to figure out a whole new way of doing things \u2013 they need to start profiting from the merger or acquisition as soon as possible.\n\n  \nMerging or acquiring companies must shift the day-to-day behavior and mind-sets of their employees to protect a deal\u2019s sources of value, both financial and organizational, and to make changes sustainable. Yet when McKinsey asked 3,199 leaders if they regarded the change programs at their own companies as successful, only one-third did.\n\n  \nIn fact, comprehensive change management strategies are vital in easing transitions during mergers and acquisitions (M&amp;As), as they help increase acceptance among employees and minimize potential disruption. Here\u2019s how these strategies can be applied:  \n\n\n* Implement Surveys for In-depth Understanding: confidential surveys can encourage employees to express concerns they might not voice in person. These surveys should be designed to address specific issues identified during the interviews, such as opportunities for promotion. The responses can provide a more detailed understanding of the company\u2019s situation;\n* Compile and Present a Detailed Report to Stakeholders: the findings from the interviews and surveys should be compiled into a comprehensive report. This report should highlight both the positive aspects and potential issues within the company, such as knowledge gaps or cultural problems. The report should be presented to stakeholders in a clear and concise manner;\n* Include Personalized Action Plans in the Report: the report should also contain personalized action plans for key tasks. This assigns responsibility and accountability, ensuring that important tasks are not overlooked. A well-implemented action plan can drive value-generating changes in the company;\n* Perform a Potential Resistance Analysis: a potential resistance analysis can identify potential obstacles within both organizations involved in the acquisition. This step should avoid creating a divisive \u2018us versus them\u2019 mentality. Instead, it should focus on understanding employee concerns, perceived negatives of the deal, and their vision of their future roles in the company. This analysis can help drive the acquisition forward in a positive and inclusive manner.  \nOther issues can be solved via the right tool that addresses every issue mentioned.\n\n# How to effectively address data-related M&amp;A challenges?\n\nTo effectively address the challenges posed by M&amp;A, a comprehensive approach is required that addresses not only the technical aspects but also the human element. A no-code data sync and integration solution that serves as a central source of truth can be the key to this approach. This solution would transform data into a uniform format and securely store it in a single data warehouse, simplifying the integration process and ensuring data consistency and security.\n\n  \nA central source of truth (CSOT) is a concept in data management that refers to a single, authoritative source of data that everyone in the organization agrees is the real, trusted number. In the context of M&amp;A, a CSOT can help eliminate data inconsistencies and redundancies, streamline data management, and ensure all employees have access to the same, accurate data.\n\n  \nBy transforming all data into the same format, a CSOT can help to overcome the challenges of integrating disparate systems and reconciling different data formats and standards. No code aspect of the tool can significantly reduce the complexity and time required for data integration by involving business in the process. This ensures that all data is consistent and reliable.\n\n  \nMoreover, by storing all data securely in one data warehouse, a CSOT can help to maintain data privacy and security during and after the M&amp;A process. This can help to prevent data breaches and ensure compliance with all relevant regulations.\n\n# No-Code Data Solutions\n\nNo-code data solutions can play a crucial role in integrating two systems. These solutions allow users to manage and manipulate data without needing to write any code, making them accessible to both IT specialists and employees with no coding experience. This can help to speed up the integration process and enable companies to start profiting from M&amp;A right away.  \nFurthermore, by enabling non-technical employees to work with data, no-code solutions can help to address the human element of M&amp;A. They can get more employees on board with adopting new systems and for them to adapt to new workflows. This can help to reduce resistance to change and increase employee engagement and productivity.\n\nIn addition, no-code solutions can reduce the need to hire IT consultants or spend time figuring out the best IT architecture option. This can result in significant cost savings and allow companies to focus their resources on other aspects of the M&amp;A process.  \nThe rest of research can be found here:  https://ainsys.com/blog/2023/06/12/data-management-challenges-in-ma/?utm\\_source=linkedin&amp;utm\\_medium=social&amp;utm\\_campaign=data\\_engineering&amp;utm\\_content=migrations\\_acquistions&amp;utm\\_term=ITarchitecture", "author_fullname": "t2_ct09rz3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data management challenges in M&amp;A", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_149yxju", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686825092.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company has recently gone through a merger. My team and I, an executive of the company, faced many issues that took too much time to solve. That got me thinking: how many other executives and team leads out there will have to struggle through the same issues, and how can I help them prepare? This is why I gathered some useful information that I believe could be useful for many people.&lt;/p&gt;\n\n&lt;p&gt;Mergers and acquisitions (M&amp;amp;A) bring about significant shifts in operations and culture for employees and the impact of data-related challenges on these aspects is frequently overlooked. Ensure you or your company are not making the same mistake.&lt;/p&gt;\n\n&lt;p&gt;Mergers and acquisitions often trigger substantial organizational uncertainty about what lies ahead: typically, the operational model and culture undergo significant transformations for one or both of the merging entities. These alterations extend beyond just a new name and executive leadership; first and foremost, M&amp;amp;A change the way IT teams work. Anticipating and addressing these IT challenges can pave the way for smooth and efficient integration. Conversely, failure to foresee and manage these issues can result in poor business performance, attrition of key talent, and potential data breaches. In this article, experts from AINSYS delve into the IT complications that can emerge during and post M&amp;amp;A, and provide tools for addressing them effectively.&lt;/p&gt;\n\n&lt;p&gt;During and after M&amp;amp;A, two companies\u2019 tech stacks essentially collide, and IT management has to deal with a number of challenges:&lt;/p&gt;\n\n&lt;h1&gt;1. Integrating disparate systems and platforms&lt;/h1&gt;\n\n&lt;p&gt;Integrating disparate systems and platforms is one of the most significant challenges during mergers and acquisitions. When two companies come together, they often bring with them different IT systems and platforms that have been tailored to their specific business processes and needs. These systems can range from customer relationship management (CRM) and enterprise resource planning (ERP) systems, to data management platforms, financial systems, and more.&lt;br/&gt;\nHere are some of the key issues that arise during this integration process:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Compatibility: the systems used by the merging companies may not be compatible. They may be built on different architectures, use different data formats, or be based on different technologies. This can make integration a complex and time-consuming process;&lt;/li&gt;\n&lt;li&gt;Data Consistency: each system may have its own way of storing and structuring data. Ensuring consistency in data definitions, formats, and structures across all systems is crucial to avoid confusion and errors in data analysis and decision-making;&lt;/li&gt;\n&lt;li&gt;Redundancy: there may be significant overlap in the functionality of the systems used by the two companies, leading to redundancy. Identifying and eliminating these redundancies is important to avoid unnecessary costs and complexity;&lt;/li&gt;\n&lt;li&gt;Security and Compliance: each system will have its own security measures and compliance requirements. Ensuring that the integrated system meets all necessary security standards and regulatory requirements is crucial;&lt;/li&gt;\n&lt;li&gt;User Training: Employees from each company will be familiar with their own systems, but may need training to use the new integrated system effectively;&lt;/li&gt;\n&lt;li&gt;System Performance: Integrating two systems can put a strain on the performance of the IT infrastructure. Ensuring the integrated system performs effectively without causing downtime or delays is important.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Reconciling different data formats and standards&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;When two companies merge, they bring with them different data systems that have been tailored to their specific needs and processes. These systems may use different data formats and adhere to different data standards, which can create several issues during integration, including data inconsistency, data loss (if one system uses a data format that the other system does not support, some data may be lost during the conversion process, leading to incomplete or inaccurate data in the integrated system), data quality (one system might allow for missing values in certain fields, while the other does not), and compliance issues.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Significant differences in the technological maturity between the two companies&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If one of the companies has a significant technological advantage over the other, several issues may arise:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Integration Complexity: if one company uses modern, cloud-based systems while the other still relies on legacy systems, integrating the two can be complex and time-consuming. It may require significant resources to upgrade or replace outdated systems;&lt;/li&gt;\n&lt;li&gt;Operational Disruptions: if one company\u2019s systems are automated and the other\u2019s are manual, it could disrupt business processes and workflows until the less advanced systems are upgraded;&lt;/li&gt;\n&lt;li&gt;Security Risks: Older, less advanced systems may have more vulnerabilities, increasing the risk of data breaches or cyberattacks. It\u2019s crucial to assess and address these risks as part of the integration process.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Considering the human element&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This is perhaps the most complex and difficult issue to solve, seeing as no specialist is alike and supporting employees through change in M&amp;amp;A is the most important matter you will need to solve. Why is that? Well, the reason is that the success of any merger or acquisition is not just about integrating systems and processes, but also about bringing together people from different organizational cultures. Employees are the backbone of any organization, and their acceptance and adaptation to change can significantly impact the outcome of the M&amp;amp;A.&lt;/p&gt;\n\n&lt;p&gt;The problem is, employees are conservative and don\u2019t want to switch from systems they have been using for years, having to learn new skills to actually use them. Additionally, companies often have to hire additional employees or IT consultants in order to support them through the process.&lt;br/&gt;\nAnd it is not like executives can allow their employees to take their sweet time to figure out a whole new way of doing things \u2013 they need to start profiting from the merger or acquisition as soon as possible.&lt;/p&gt;\n\n&lt;p&gt;Merging or acquiring companies must shift the day-to-day behavior and mind-sets of their employees to protect a deal\u2019s sources of value, both financial and organizational, and to make changes sustainable. Yet when McKinsey asked 3,199 leaders if they regarded the change programs at their own companies as successful, only one-third did.&lt;/p&gt;\n\n&lt;p&gt;In fact, comprehensive change management strategies are vital in easing transitions during mergers and acquisitions (M&amp;amp;As), as they help increase acceptance among employees and minimize potential disruption. Here\u2019s how these strategies can be applied:  &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Implement Surveys for In-depth Understanding: confidential surveys can encourage employees to express concerns they might not voice in person. These surveys should be designed to address specific issues identified during the interviews, such as opportunities for promotion. The responses can provide a more detailed understanding of the company\u2019s situation;&lt;/li&gt;\n&lt;li&gt;Compile and Present a Detailed Report to Stakeholders: the findings from the interviews and surveys should be compiled into a comprehensive report. This report should highlight both the positive aspects and potential issues within the company, such as knowledge gaps or cultural problems. The report should be presented to stakeholders in a clear and concise manner;&lt;/li&gt;\n&lt;li&gt;Include Personalized Action Plans in the Report: the report should also contain personalized action plans for key tasks. This assigns responsibility and accountability, ensuring that important tasks are not overlooked. A well-implemented action plan can drive value-generating changes in the company;&lt;/li&gt;\n&lt;li&gt;Perform a Potential Resistance Analysis: a potential resistance analysis can identify potential obstacles within both organizations involved in the acquisition. This step should avoid creating a divisive \u2018us versus them\u2019 mentality. Instead, it should focus on understanding employee concerns, perceived negatives of the deal, and their vision of their future roles in the company. This analysis can help drive the acquisition forward in a positive and inclusive manner.&lt;br/&gt;\nOther issues can be solved via the right tool that addresses every issue mentioned.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;How to effectively address data-related M&amp;amp;A challenges?&lt;/h1&gt;\n\n&lt;p&gt;To effectively address the challenges posed by M&amp;amp;A, a comprehensive approach is required that addresses not only the technical aspects but also the human element. A no-code data sync and integration solution that serves as a central source of truth can be the key to this approach. This solution would transform data into a uniform format and securely store it in a single data warehouse, simplifying the integration process and ensuring data consistency and security.&lt;/p&gt;\n\n&lt;p&gt;A central source of truth (CSOT) is a concept in data management that refers to a single, authoritative source of data that everyone in the organization agrees is the real, trusted number. In the context of M&amp;amp;A, a CSOT can help eliminate data inconsistencies and redundancies, streamline data management, and ensure all employees have access to the same, accurate data.&lt;/p&gt;\n\n&lt;p&gt;By transforming all data into the same format, a CSOT can help to overcome the challenges of integrating disparate systems and reconciling different data formats and standards. No code aspect of the tool can significantly reduce the complexity and time required for data integration by involving business in the process. This ensures that all data is consistent and reliable.&lt;/p&gt;\n\n&lt;p&gt;Moreover, by storing all data securely in one data warehouse, a CSOT can help to maintain data privacy and security during and after the M&amp;amp;A process. This can help to prevent data breaches and ensure compliance with all relevant regulations.&lt;/p&gt;\n\n&lt;h1&gt;No-Code Data Solutions&lt;/h1&gt;\n\n&lt;p&gt;No-code data solutions can play a crucial role in integrating two systems. These solutions allow users to manage and manipulate data without needing to write any code, making them accessible to both IT specialists and employees with no coding experience. This can help to speed up the integration process and enable companies to start profiting from M&amp;amp;A right away.&lt;br/&gt;\nFurthermore, by enabling non-technical employees to work with data, no-code solutions can help to address the human element of M&amp;amp;A. They can get more employees on board with adopting new systems and for them to adapt to new workflows. This can help to reduce resistance to change and increase employee engagement and productivity.&lt;/p&gt;\n\n&lt;p&gt;In addition, no-code solutions can reduce the need to hire IT consultants or spend time figuring out the best IT architecture option. This can result in significant cost savings and allow companies to focus their resources on other aspects of the M&amp;amp;A process.&lt;br/&gt;\nThe rest of research can be found here:  &lt;a href=\"https://ainsys.com/blog/2023/06/12/data-management-challenges-in-ma/?utm%5C_source=linkedin&amp;amp;utm%5C_medium=social&amp;amp;utm%5C_campaign=data%5C_engineering&amp;amp;utm%5C_content=migrations%5C_acquistions&amp;amp;utm%5C_term=ITarchitecture\"&gt;https://ainsys.com/blog/2023/06/12/data-management-challenges-in-ma/?utm\\_source=linkedin&amp;amp;utm\\_medium=social&amp;amp;utm\\_campaign=data\\_engineering&amp;amp;utm\\_content=migrations\\_acquistions&amp;amp;utm\\_term=ITarchitecture&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I3xJj8ELsQOmy2H-NeHKFmGnh2tKVfHX1i7SJ1O1qwE.jpg?auto=webp&amp;v=enabled&amp;s=a857d06fc3f1362c48ce1ce4e18be17b3a3dc051", "width": 79, "height": 86}, "resolutions": [], "variants": {}, "id": "fKkAw45B6Aa1K9gfC0CvmXNzCjb0F-J2wvKUvaKf1Vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "149yxju", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Speech36", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149yxju/data_management_challenges_in_ma/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149yxju/data_management_challenges_in_ma/", "subreddit_subscribers": 110479, "created_utc": 1686825092.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello \ud83d\udc4b \n\nI'm here to seek your input on whether now is the right time to make a job switch. Currently, I'm employed in Europe, primarily working on MLOPS, which is not fulfilling for me. I aspire to work in Data Engineering specially on spark or flink, involving tasks like building pipelines, coding from scratch, and gaining a deeper understanding of data.\n\nConsidering this, I have contemplated exploring new job opportunities. However, I'm also mindful of the current state of the job market. I would appreciate hearing your thoughts on whether it is advisable to switch jobs in the field of Data Engineering at this time.\n\nThanks in advance :)", "author_fullname": "t2_ci308gob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this the right to switch DE jobs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149u2mc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686807934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello \ud83d\udc4b &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m here to seek your input on whether now is the right time to make a job switch. Currently, I&amp;#39;m employed in Europe, primarily working on MLOPS, which is not fulfilling for me. I aspire to work in Data Engineering specially on spark or flink, involving tasks like building pipelines, coding from scratch, and gaining a deeper understanding of data.&lt;/p&gt;\n\n&lt;p&gt;Considering this, I have contemplated exploring new job opportunities. However, I&amp;#39;m also mindful of the current state of the job market. I would appreciate hearing your thoughts on whether it is advisable to switch jobs in the field of Data Engineering at this time.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "149u2mc", "is_robot_indexable": true, "report_reasons": null, "author": "Delicious_Attempt_99", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149u2mc/is_this_the_right_to_switch_de_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149u2mc/is_this_the_right_to_switch_de_jobs/", "subreddit_subscribers": 110479, "created_utc": 1686807934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone worked here with ETL tool called Ab Initio? What are your impressions and any company you would recommend. Thank you", "author_fullname": "t2_9navdxud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ab Initio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149sd0m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686802386.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone worked here with ETL tool called Ab Initio? What are your impressions and any company you would recommend. Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149sd0m", "is_robot_indexable": true, "report_reasons": null, "author": "Electrical-Grade2960", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149sd0m/ab_initio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149sd0m/ab_initio/", "subreddit_subscribers": 110479, "created_utc": 1686802386.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My company is struggling in picking whether to stick with the DataVault 2.0 methodology vs starting to leverage delta tables that are available to us within our apps. I was wondering if anyone has pros and cons vs the other?", "author_fullname": "t2_3h5wixaf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DataVault vs Delta Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149my8r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686786387.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is struggling in picking whether to stick with the DataVault 2.0 methodology vs starting to leverage delta tables that are available to us within our apps. I was wondering if anyone has pros and cons vs the other?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "149my8r", "is_robot_indexable": true, "report_reasons": null, "author": "J0hnDutt00n", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149my8r/datavault_vs_delta_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149my8r/datavault_vs_delta_tables/", "subreddit_subscribers": 110479, "created_utc": 1686786387.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Setting up dbt I have noticed strange behavior when paired with Snowflake MFA.  I seem to have to authenticate 4x + another time for every model I build.  \n\nIs this expected behavior?  There appears some fixes with dbt core but I am on dbt cloud.\n\nThe MFA token isn\u2019t getting cached in dbt cloud even though I have it enabled in snowflake.  I believe with core I have to set up the profile.yml to use the mfa cache.", "author_fullname": "t2_rzj76ely", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake dbt MFA issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149k0bx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686778835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Setting up dbt I have noticed strange behavior when paired with Snowflake MFA.  I seem to have to authenticate 4x + another time for every model I build.  &lt;/p&gt;\n\n&lt;p&gt;Is this expected behavior?  There appears some fixes with dbt core but I am on dbt cloud.&lt;/p&gt;\n\n&lt;p&gt;The MFA token isn\u2019t getting cached in dbt cloud even though I have it enabled in snowflake.  I believe with core I have to set up the profile.yml to use the mfa cache.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "149k0bx", "is_robot_indexable": true, "report_reasons": null, "author": "Parking-Ad-6808", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/149k0bx/snowflake_dbt_mfa_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/149k0bx/snowflake_dbt_mfa_issue/", "subreddit_subscribers": 110479, "created_utc": 1686778835.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}