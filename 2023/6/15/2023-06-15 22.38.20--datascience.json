{"kind": "Listing", "data": {"after": "t3_14acv5x", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I graduated University last month, and have had 3 different data scientist internships, and have just started a full time Data Scientist position at a scale-up company, where I am the second data scientist (the other data scientist is my manager) - and am 3 days into my job. \n\nI got hired with the company knowing I have zero experience with AWS, and I have no experience or domain knowledge industry of this industry (telecom industry). \n\nI\u2019ve been tasked for my first project by the founder and the CTO of the company which is to understand how a \u2018big and important\u2019 client is losing so much money in Asia. And have been told numerous times how important the success of this project is for my company\u2019s financial future and if the project isn\u2019t successful we would lose this major client - and there is a strict deadline for 1 months time to complete this major project, which includes answering over 20 giant questions about the data, with many deliverables (it doesn\u2019t help the quality of data is absolutely garbage). \n\nIt\u2019s only been 3 days and I feel so out of my depth. The founders and CTO are referring to this project as a \u2018trial by fire\u2019 and I am terrified. \n\nSure the project is do-able, but I\u2019m a fresh grad, junior data scientist and don\u2019t feel like a project of this scale and importance should be given to a junior. Or maybe it should and I\u2019m going crazy. \n\nMy manager is great but has little time to support me. \n\nNot sure what to do or feel, but terrified and burnt out already by the thought of failing this project, losing the company tons of money and maybe getting fired as I\u2019m on probation for the first 6 months of my job. \n\nOr am I a pussy and this is just normal for a junior?", "author_fullname": "t2_md7hc6om", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Burned out after 3 days", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14a2u7h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 175, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 175, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686836698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I graduated University last month, and have had 3 different data scientist internships, and have just started a full time Data Scientist position at a scale-up company, where I am the second data scientist (the other data scientist is my manager) - and am 3 days into my job. &lt;/p&gt;\n\n&lt;p&gt;I got hired with the company knowing I have zero experience with AWS, and I have no experience or domain knowledge industry of this industry (telecom industry). &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been tasked for my first project by the founder and the CTO of the company which is to understand how a \u2018big and important\u2019 client is losing so much money in Asia. And have been told numerous times how important the success of this project is for my company\u2019s financial future and if the project isn\u2019t successful we would lose this major client - and there is a strict deadline for 1 months time to complete this major project, which includes answering over 20 giant questions about the data, with many deliverables (it doesn\u2019t help the quality of data is absolutely garbage). &lt;/p&gt;\n\n&lt;p&gt;It\u2019s only been 3 days and I feel so out of my depth. The founders and CTO are referring to this project as a \u2018trial by fire\u2019 and I am terrified. &lt;/p&gt;\n\n&lt;p&gt;Sure the project is do-able, but I\u2019m a fresh grad, junior data scientist and don\u2019t feel like a project of this scale and importance should be given to a junior. Or maybe it should and I\u2019m going crazy. &lt;/p&gt;\n\n&lt;p&gt;My manager is great but has little time to support me. &lt;/p&gt;\n\n&lt;p&gt;Not sure what to do or feel, but terrified and burnt out already by the thought of failing this project, losing the company tons of money and maybe getting fired as I\u2019m on probation for the first 6 months of my job. &lt;/p&gt;\n\n&lt;p&gt;Or am I a pussy and this is just normal for a junior?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a2u7h", "is_robot_indexable": true, "report_reasons": null, "author": "Classic_Training_740", "discussion_type": null, "num_comments": 98, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a2u7h/burned_out_after_3_days/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a2u7h/burned_out_after_3_days/", "subreddit_subscribers": 925404, "created_utc": 1686836698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For everyone working in a large and/or consulting org, how has your executive team adapted to this new AI wave since chatgpt hit the media?  It\u2019s complete chaos at my org.  SVPs with zero data skills trying to spin up \u201cAI strategies\u201d galore and they\u2019re basically ignoring every technical AIML expert at the org.  Are y\u2019all seeing this too?  Any ideas on how to manage in this environment other than just waiting it out?\n\nIt\u2019s only a matter of time before we see \u201cAgile AI,\u201d sigh..", "author_fullname": "t2_a6aqo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are your executive team members armchair \u201cAI strategists\u201d now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149nszy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 112, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 112, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1686845915.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686788760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For everyone working in a large and/or consulting org, how has your executive team adapted to this new AI wave since chatgpt hit the media?  It\u2019s complete chaos at my org.  SVPs with zero data skills trying to spin up \u201cAI strategies\u201d galore and they\u2019re basically ignoring every technical AIML expert at the org.  Are y\u2019all seeing this too?  Any ideas on how to manage in this environment other than just waiting it out?&lt;/p&gt;\n\n&lt;p&gt;It\u2019s only a matter of time before we see \u201cAgile AI,\u201d sigh..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149nszy", "is_robot_indexable": true, "report_reasons": null, "author": "JasonSuave", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149nszy/are_your_executive_team_members_armchair_ai/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149nszy/are_your_executive_team_members_armchair_ai/", "subreddit_subscribers": 925404, "created_utc": 1686788760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry in advance if this post becomes a rant or is overly negative. I don't mean it to be. \n\nSo on one hand ChatGPT and LLMs are really impressive. It's really cool you can give a prompt and get a response that is almost or exactly what you asked for. But I'm already tried of hearing everyone talk about it constantly. \n\nThe fact it can create code is amazing, however it can \"hallucinate\" and create package and functions that don't exist... I mean, this is impressive, but is this useful? To create boilerplate code that you have to review before using? Why not write it from scratch? Even if the LLM gives you code that is syntactically correct, is it even quality code?\n\nAgain I know I probably sound like an old man or something, but it's annoying hearing about it constantly (I guess I'm not helping by posting about it :)).", "author_fullname": "t2_10yrzc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone not really care about ChatGPT and LLMs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14a8cx4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686850294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry in advance if this post becomes a rant or is overly negative. I don&amp;#39;t mean it to be. &lt;/p&gt;\n\n&lt;p&gt;So on one hand ChatGPT and LLMs are really impressive. It&amp;#39;s really cool you can give a prompt and get a response that is almost or exactly what you asked for. But I&amp;#39;m already tried of hearing everyone talk about it constantly. &lt;/p&gt;\n\n&lt;p&gt;The fact it can create code is amazing, however it can &amp;quot;hallucinate&amp;quot; and create package and functions that don&amp;#39;t exist... I mean, this is impressive, but is this useful? To create boilerplate code that you have to review before using? Why not write it from scratch? Even if the LLM gives you code that is syntactically correct, is it even quality code?&lt;/p&gt;\n\n&lt;p&gt;Again I know I probably sound like an old man or something, but it&amp;#39;s annoying hearing about it constantly (I guess I&amp;#39;m not helping by posting about it :)).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a8cx4", "is_robot_indexable": true, "report_reasons": null, "author": "Run_nerd", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a8cx4/does_anyone_not_really_care_about_chatgpt_and_llms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a8cx4/does_anyone_not_really_care_about_chatgpt_and_llms/", "subreddit_subscribers": 925404, "created_utc": 1686850294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_agau7cbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "There\u2019s a lot of data science books out there, any recommendations for must-reads?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14a388u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686837713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a388u", "is_robot_indexable": true, "report_reasons": null, "author": "Koalashart1", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a388u/theres_a_lot_of_data_science_books_out_there_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a388u/theres_a_lot_of_data_science_books_out_there_any/", "subreddit_subscribers": 925404, "created_utc": 1686837713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_7vejmk2w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "After AlphaFold cracked a 50-year-old problem of structural bioinformatics by learning to predict protein structures, it couldn't solve the mutant protein stability problem. And the AI has not really \u201clearned\u201d the physics of proteins either, a new study concludes.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "name": "t3_14a4lf8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bdWClXgR12bbItPRBIjyaS1I66MYv0hwGNpZGs4zfDY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686841137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "journals.plos.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0282689", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/G43Fni1YSx9-v88aLeOoQ8gokECNAtkvuG7pCtlmkt0.jpg?auto=webp&amp;v=enabled&amp;s=f1c236b3b35836eea305dba3d8b788e760f0c405", "width": 320, "height": 153}, "resolutions": [{"url": "https://external-preview.redd.it/G43Fni1YSx9-v88aLeOoQ8gokECNAtkvuG7pCtlmkt0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=828dc5d4653f7dc49467d626f38bd50de946ad08", "width": 108, "height": 51}, {"url": "https://external-preview.redd.it/G43Fni1YSx9-v88aLeOoQ8gokECNAtkvuG7pCtlmkt0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ddcfb39dd46d7249ddbf46a0681393e9a9cd2f13", "width": 216, "height": 103}, {"url": "https://external-preview.redd.it/G43Fni1YSx9-v88aLeOoQ8gokECNAtkvuG7pCtlmkt0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ad84c8eb3f71bafc1ab8a233cbb9894f245e8269", "width": 320, "height": 153}], "variants": {}, "id": "tCI2YexzCzklyEUTZdAHNm-PIthtHNuqzO2CYkMFsW8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a4lf8", "is_robot_indexable": true, "report_reasons": null, "author": "Skoltech_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a4lf8/after_alphafold_cracked_a_50yearold_problem_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0282689", "subreddit_subscribers": 925404, "created_utc": 1686841137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've used Mac for years. I need to get a new laptop, though, and I'm *so* tempted to switch to PC (mostly I just like the UI better). But I know a lot of people say that Mac is faster/more worthwhile for data science. Any strong opinions? And/or recs for a good laptop that you use for work?\n\ncontext: I work from home on my own laptop", "author_fullname": "t2_41zaxyo9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mac vs PC?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14a4mh0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686841206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve used Mac for years. I need to get a new laptop, though, and I&amp;#39;m &lt;em&gt;so&lt;/em&gt; tempted to switch to PC (mostly I just like the UI better). But I know a lot of people say that Mac is faster/more worthwhile for data science. Any strong opinions? And/or recs for a good laptop that you use for work?&lt;/p&gt;\n\n&lt;p&gt;context: I work from home on my own laptop&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a4mh0", "is_robot_indexable": true, "report_reasons": null, "author": "oneohsevenam", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a4mh0/mac_vs_pc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a4mh0/mac_vs_pc/", "subreddit_subscribers": 925404, "created_utc": 1686841206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For people who've worked in industry for more than 2 years, how do you quickly find out what the latest changes are in the field. Like 4-5 years ago I was right out of college and then catboost came out, transfer learning became viable with resnet and hugging face (which was massive since it allows deeplearning for small datasets), but I feel like since then I've basically just sharped up on engineering practices and GPT-3 is a better language model. \n\nAre there just less new things coming out or how do you see the top 5 highlights each year that you should play around with", "author_fullname": "t2_23bi1gsr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you keep up to date with the latest changes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ve08", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686812437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For people who&amp;#39;ve worked in industry for more than 2 years, how do you quickly find out what the latest changes are in the field. Like 4-5 years ago I was right out of college and then catboost came out, transfer learning became viable with resnet and hugging face (which was massive since it allows deeplearning for small datasets), but I feel like since then I&amp;#39;ve basically just sharped up on engineering practices and GPT-3 is a better language model. &lt;/p&gt;\n\n&lt;p&gt;Are there just less new things coming out or how do you see the top 5 highlights each year that you should play around with&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149ve08", "is_robot_indexable": true, "report_reasons": null, "author": "Alienbushman", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149ve08/how_do_you_keep_up_to_date_with_the_latest_changes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149ve08/how_do_you_keep_up_to_date_with_the_latest_changes/", "subreddit_subscribers": 925404, "created_utc": 1686812437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How does one un-learn how to micro-manage, especially in data science where it can be tempting to drift on your own path into an EDA rabbit-hole, and accidentally hoard all the work? Or rather get into a rabbit-hole and produce a disproportionately higher volume of (perhaps even unneeded) work compared to your teammates, making it *seem* like you shouldered most of the effort?\n\nI've come from a high school experience where I've been surrounded by slackers. But now that I'm in a good college, I should know that I am surrounded by diligent, educated peers. And yet in a lot of the coding projects that I can recall, I've always hoarded most of the work or fell back into my old high school habits of micro-managing. What do I do?", "author_fullname": "t2_w594l9jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlearning how to micro-manage in DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149rbom", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686799550.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686799149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How does one un-learn how to micro-manage, especially in data science where it can be tempting to drift on your own path into an EDA rabbit-hole, and accidentally hoard all the work? Or rather get into a rabbit-hole and produce a disproportionately higher volume of (perhaps even unneeded) work compared to your teammates, making it &lt;em&gt;seem&lt;/em&gt; like you shouldered most of the effort?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve come from a high school experience where I&amp;#39;ve been surrounded by slackers. But now that I&amp;#39;m in a good college, I should know that I am surrounded by diligent, educated peers. And yet in a lot of the coding projects that I can recall, I&amp;#39;ve always hoarded most of the work or fell back into my old high school habits of micro-managing. What do I do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149rbom", "is_robot_indexable": true, "report_reasons": null, "author": "Lockonon3", "discussion_type": null, "num_comments": 6, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149rbom/unlearning_how_to_micromanage_in_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149rbom/unlearning_how_to_micromanage_in_ds/", "subreddit_subscribers": 925404, "created_utc": 1686799149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi folks , I am actually a data science intern and I am stuck at a task. There is an unstructured invoice which is having data like transaction number , weight , pincodes etc. I want to extract this and export it to excel. I have reached the level where in I am using pymupdf and pdfquerry libraries. I extracted the data in form of xml but I am unable to find the way to clean/filter it and extract the data I want. Can anyone guide me for this?    \n\n\nIf anybody can please ping me we can discuss it in more detail.  \n\n\nThanks!", "author_fullname": "t2_t423y52t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Want to scrape unstructured and repetitive data from a pdf", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ky0f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686781156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks , I am actually a data science intern and I am stuck at a task. There is an unstructured invoice which is having data like transaction number , weight , pincodes etc. I want to extract this and export it to excel. I have reached the level where in I am using pymupdf and pdfquerry libraries. I extracted the data in form of xml but I am unable to find the way to clean/filter it and extract the data I want. Can anyone guide me for this?    &lt;/p&gt;\n\n&lt;p&gt;If anybody can please ping me we can discuss it in more detail.  &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149ky0f", "is_robot_indexable": true, "report_reasons": null, "author": "YoloPoloGolo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149ky0f/want_to_scrape_unstructured_and_repetitive_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149ky0f/want_to_scrape_unstructured_and_repetitive_data/", "subreddit_subscribers": 925404, "created_utc": 1686781156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "First some background: I\u2019m currently attending an Ivy League for a PhD in neuroscience and am pursuing a joint field in data science. I\u2019ve been trying to transition away from academia and after many applications I was I was hired as a data science intern for the summer at a local startup. \n\nHowever, now that I\u2019ve started the position I\u2019m learning that my job isn\u2019t really data science AT ALL. My whole job for the summer is to create a proposal for what data the company should collect to assess how users interact with their product \u2014 ie. UX research. It\u2019s been one week, but I really hate this internship. There\u2019s no data whatsoever, and after asking if I could join another team that does work on data science-esque things I was told to focus on this project. What do I do? \n\nI\u2019m being paid, but I took the job for data science experience. My main issue is that I feel like this will leave me even farther from my career goals \u2014 but also, this job encompasses all the things that drove me to want to leave academia.", "author_fullname": "t2_4zlosufn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Internship Woes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14aeq81", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686866239.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First some background: I\u2019m currently attending an Ivy League for a PhD in neuroscience and am pursuing a joint field in data science. I\u2019ve been trying to transition away from academia and after many applications I was I was hired as a data science intern for the summer at a local startup. &lt;/p&gt;\n\n&lt;p&gt;However, now that I\u2019ve started the position I\u2019m learning that my job isn\u2019t really data science AT ALL. My whole job for the summer is to create a proposal for what data the company should collect to assess how users interact with their product \u2014 ie. UX research. It\u2019s been one week, but I really hate this internship. There\u2019s no data whatsoever, and after asking if I could join another team that does work on data science-esque things I was told to focus on this project. What do I do? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m being paid, but I took the job for data science experience. My main issue is that I feel like this will leave me even farther from my career goals \u2014 but also, this job encompasses all the things that drove me to want to leave academia.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14aeq81", "is_robot_indexable": true, "report_reasons": null, "author": "anonymousporcup1ne", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14aeq81/internship_woes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14aeq81/internship_woes/", "subreddit_subscribers": 925404, "created_utc": 1686866239.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A lot of people are telling me about tools like AirByte and Y42. I\u2019ve never got to work with them. Are they any good? What do they do best and worst?", "author_fullname": "t2_a2ps3jf8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opinion Tools Like AirByte?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14aedkc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686865404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A lot of people are telling me about tools like AirByte and Y42. I\u2019ve never got to work with them. Are they any good? What do they do best and worst?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14aedkc", "is_robot_indexable": true, "report_reasons": null, "author": "Dependent-Bunch7505", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14aedkc/opinion_tools_like_airbyte/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14aedkc/opinion_tools_like_airbyte/", "subreddit_subscribers": 925404, "created_utc": 1686865404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The parallelization of transformers and RNNs (Recurrent Neural Networks) is often discussed. It's commonly said that transformers are more parallelizable than RNNs. However, this is a rather vague statement that merits further discussion.\n\nOne could argue that an RNN can be made as parallelizable as desired by simply adding more instances to each batch.\n\nWhat is generally meant by saying transformers are more parallelizable is that transformers lack time-dependent operations. In other words, given an input, all operations can be done at once (although not all, since one layer needs to be computed before the next).\n\nContrast this with an RNN, where computations from one time step are carried forward and used in the next. Some people argue that this time-dependence makes RNNs less parallelizable.\n\nHowever, one could also argue that to achieve a level of parallelization in an RNN similar to that in a transformer, one could simply increase the batch size by a factor equal to the number of time steps in the sequence. This way, both the transformer and the RNN would perform the same training in the same time frame.\n\nA potential counterpoint to this argument might be that this would increase the memory requirements for the RNN, as the entire unfolding of the network needs to be stored. However, the memory requirement for an RNN grows linearly with the size of the input, whereas for a transformer, it grows quadratically.\n\nTherefore, one could argue that, given their linear memory growth, RNNs should actually require less memory than transformers, making them just as parallelizable.\n\nI look forward to getting some clarity on this issue. Does the parallelization advantage of transformers over RNNs lie in something more than just memory and time-step computations?\n\nI understand there might be other reasons why to choose a transformer over a RNN, for instance the vanishing gradient problem, but I'm particularly interested in the statement \"Transformers are more parallelizable than RNN's\" because it doesn't seem obvious to me why this would be true.\n\nThere might also be good reasons for not wanting to increase the batch size, I'm interested on that too.", "author_fullname": "t2_v01xiyj8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is it said transformers are more parallelizable than RNN's?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14ae7qy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686865022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The parallelization of transformers and RNNs (Recurrent Neural Networks) is often discussed. It&amp;#39;s commonly said that transformers are more parallelizable than RNNs. However, this is a rather vague statement that merits further discussion.&lt;/p&gt;\n\n&lt;p&gt;One could argue that an RNN can be made as parallelizable as desired by simply adding more instances to each batch.&lt;/p&gt;\n\n&lt;p&gt;What is generally meant by saying transformers are more parallelizable is that transformers lack time-dependent operations. In other words, given an input, all operations can be done at once (although not all, since one layer needs to be computed before the next).&lt;/p&gt;\n\n&lt;p&gt;Contrast this with an RNN, where computations from one time step are carried forward and used in the next. Some people argue that this time-dependence makes RNNs less parallelizable.&lt;/p&gt;\n\n&lt;p&gt;However, one could also argue that to achieve a level of parallelization in an RNN similar to that in a transformer, one could simply increase the batch size by a factor equal to the number of time steps in the sequence. This way, both the transformer and the RNN would perform the same training in the same time frame.&lt;/p&gt;\n\n&lt;p&gt;A potential counterpoint to this argument might be that this would increase the memory requirements for the RNN, as the entire unfolding of the network needs to be stored. However, the memory requirement for an RNN grows linearly with the size of the input, whereas for a transformer, it grows quadratically.&lt;/p&gt;\n\n&lt;p&gt;Therefore, one could argue that, given their linear memory growth, RNNs should actually require less memory than transformers, making them just as parallelizable.&lt;/p&gt;\n\n&lt;p&gt;I look forward to getting some clarity on this issue. Does the parallelization advantage of transformers over RNNs lie in something more than just memory and time-step computations?&lt;/p&gt;\n\n&lt;p&gt;I understand there might be other reasons why to choose a transformer over a RNN, for instance the vanishing gradient problem, but I&amp;#39;m particularly interested in the statement &amp;quot;Transformers are more parallelizable than RNN&amp;#39;s&amp;quot; because it doesn&amp;#39;t seem obvious to me why this would be true.&lt;/p&gt;\n\n&lt;p&gt;There might also be good reasons for not wanting to increase the batch size, I&amp;#39;m interested on that too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ae7qy", "is_robot_indexable": true, "report_reasons": null, "author": "Substantial_Shirt234", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ae7qy/why_is_it_said_transformers_are_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ae7qy/why_is_it_said_transformers_are_more/", "subreddit_subscribers": 925404, "created_utc": 1686865022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working with a team of individuals in the social sciences and we came across this paper from the ISD: [https://www.isdglobal.org/digital\\_dispatches/a-false-picture-for-many-audiences-how-russian-language-pro-kremlin-telegram-channels-spread-propaganda-and-disinformation-about-refugees-from-ukraine/](https://www.isdglobal.org/digital_dispatches/a-false-picture-for-many-audiences-how-russian-language-pro-kremlin-telegram-channels-spread-propaganda-and-disinformation-about-refugees-from-ukraine/)  \n\n\nAs disclosed in their methodologies they utilized a software suite from CASM Technology: [https://www.casmtechnology.com/](https://www.casmtechnology.com/) but I can not find any further information regarding how to test the validity of their data and how their data is acquired.  \n\n\nHas anyone used this software before? Are they reliable?", "author_fullname": "t2_hbdu8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is CASM Technology a reliable software solution?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14a54xw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686842406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working with a team of individuals in the social sciences and we came across this paper from the ISD: &lt;a href=\"https://www.isdglobal.org/digital_dispatches/a-false-picture-for-many-audiences-how-russian-language-pro-kremlin-telegram-channels-spread-propaganda-and-disinformation-about-refugees-from-ukraine/\"&gt;https://www.isdglobal.org/digital_dispatches/a-false-picture-for-many-audiences-how-russian-language-pro-kremlin-telegram-channels-spread-propaganda-and-disinformation-about-refugees-from-ukraine/&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;As disclosed in their methodologies they utilized a software suite from CASM Technology: &lt;a href=\"https://www.casmtechnology.com/\"&gt;https://www.casmtechnology.com/&lt;/a&gt; but I can not find any further information regarding how to test the validity of their data and how their data is acquired.  &lt;/p&gt;\n\n&lt;p&gt;Has anyone used this software before? Are they reliable?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vz3da6DLXx6YY7D9KJN3uKJ1GufQtPwl8lTLjhGTbdM.jpg?auto=webp&amp;v=enabled&amp;s=130f6894a7e308e7d11661d41246a305f87190f1", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/vz3da6DLXx6YY7D9KJN3uKJ1GufQtPwl8lTLjhGTbdM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b3c71096c6df77e25a2925f4f58b97bc1b9d2e5", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/vz3da6DLXx6YY7D9KJN3uKJ1GufQtPwl8lTLjhGTbdM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=297dc9b7341ffa5335ad18aced96e6f567508747", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/vz3da6DLXx6YY7D9KJN3uKJ1GufQtPwl8lTLjhGTbdM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f18dbb853dcfaff40c8ffaaad802a0f24c6aa3f", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/vz3da6DLXx6YY7D9KJN3uKJ1GufQtPwl8lTLjhGTbdM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6bc206c3756571f2492832b40bd610de7619cea2", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/vz3da6DLXx6YY7D9KJN3uKJ1GufQtPwl8lTLjhGTbdM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=20b4a229d1ab1100ff854daa8f2e79daa8151ae8", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/vz3da6DLXx6YY7D9KJN3uKJ1GufQtPwl8lTLjhGTbdM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cdc9210534ce93b0bd6fcb479324eabc4ff608d4", "width": 1080, "height": 567}], "variants": {}, "id": "JgmazrX9aTx1pMsjrSU7THmxBuF8pqL_mmtbz-44ddE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a54xw", "is_robot_indexable": true, "report_reasons": null, "author": "adammartin13", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a54xw/is_casm_technology_a_reliable_software_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a54xw/is_casm_technology_a_reliable_software_solution/", "subreddit_subscribers": 925404, "created_utc": 1686842406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We built PyPOTS: an open-source Python toolbox for data mining on Partially-Observed Time Series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14a54jm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_4iz6qtg8", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MRm-lbG38dN9Tjec8ipemtTqAK5NKzQwHlKPOsLZqws.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "github", "selftext": "Due to all kinds of reasons like failure of collection sensors, communication error, and unexpected malfunction, missing values are common to see in time series from the real-world environment. This makes partially-observed time series (POTS) a pervasive problem in open-world modeling and prevents advanced data analysis. Although this problem is important, the area of data mining on POTS still lacks a dedicated toolkit. PyPOTS is created to fill in this gap.\n\nPyPOTS (pronounced \"Pie Pots\") is the first (and so far the only) Python toolbox/library specifically designed for data mining and machine learning on partially-observed time series (POTS), namely, incomplete time series with missing values, A.K.A. irregularly-sampled time series, supporting tasks of imputation, classification, clustering, and forecasting on POTS datasets. It is born to become a handy toolbox that is going to make data mining on POTS easy rather than tedious, to help engineers and researchers focus more on the core problems in their hands rather than on how to deal with the missing parts in their data. PyPOTS will keep integrating classical and the latest state-of-the-art data mining algorithms for partially-observed multivariate time series. For sure, besides various algorithms, PyPOTS has unified APIs together with detailed documentation and interactive examples across algorithms as tutorials.\n\nFeedback and contributions are very welcome!\n\n&amp;#x200B;\n\nWebsite: [https://pypots.com](https://pypots.com)\n\nPaper link: [https://arxiv.org/abs/2305.18811](https://arxiv.org/abs/2305.18811)\n\nGitHub repo: [https://github.com/WenjieDu/PyPOTS](https://github.com/WenjieDu/PyPOTS)\n\nhttps://preview.redd.it/bly5p3edx56b1.jpg?width=1801&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=9fb5084d03ec048b4cf13f04b29b91cba65c6a49", "author_fullname": "t2_4iz6qtg8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We built PyPOTS: an open-source Python toolbox for data mining on Partially-Observed Time Series", "link_flair_richtext": [], "subreddit_name_prefixed": "r/github", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"bly5p3edx56b1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 29, "x": 108, "u": "https://preview.redd.it/bly5p3edx56b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=74f07fec47b7a1d4c77123334d7969f3126fe1e4"}, {"y": 59, "x": 216, "u": "https://preview.redd.it/bly5p3edx56b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6e83b87bee93a6a6cb68450faabb543dc224423f"}, {"y": 88, "x": 320, "u": "https://preview.redd.it/bly5p3edx56b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=80d4c7ee28f0fcbd8d59c1040289236209d67f29"}, {"y": 177, "x": 640, "u": "https://preview.redd.it/bly5p3edx56b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3576a1ee6850f0c43e8b82f904947d9687000b58"}, {"y": 265, "x": 960, "u": "https://preview.redd.it/bly5p3edx56b1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=59663dedd31657df1ff5e57b715577c46da6e6c6"}, {"y": 299, "x": 1080, "u": "https://preview.redd.it/bly5p3edx56b1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0b165e49a805e7ae7550f85649c53dcf5940db4c"}], "s": {"y": 499, "x": 1801, "u": "https://preview.redd.it/bly5p3edx56b1.jpg?width=1801&amp;format=pjpg&amp;auto=webp&amp;v=enabled&amp;s=9fb5084d03ec048b4cf13f04b29b91cba65c6a49"}, "id": "bly5p3edx56b1"}}, "name": "t3_149zdd9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/MRm-lbG38dN9Tjec8ipemtTqAK5NKzQwHlKPOsLZqws.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686826585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.github", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Due to all kinds of reasons like failure of collection sensors, communication error, and unexpected malfunction, missing values are common to see in time series from the real-world environment. This makes partially-observed time series (POTS) a pervasive problem in open-world modeling and prevents advanced data analysis. Although this problem is important, the area of data mining on POTS still lacks a dedicated toolkit. PyPOTS is created to fill in this gap.&lt;/p&gt;\n\n&lt;p&gt;PyPOTS (pronounced &amp;quot;Pie Pots&amp;quot;) is the first (and so far the only) Python toolbox/library specifically designed for data mining and machine learning on partially-observed time series (POTS), namely, incomplete time series with missing values, A.K.A. irregularly-sampled time series, supporting tasks of imputation, classification, clustering, and forecasting on POTS datasets. It is born to become a handy toolbox that is going to make data mining on POTS easy rather than tedious, to help engineers and researchers focus more on the core problems in their hands rather than on how to deal with the missing parts in their data. PyPOTS will keep integrating classical and the latest state-of-the-art data mining algorithms for partially-observed multivariate time series. For sure, besides various algorithms, PyPOTS has unified APIs together with detailed documentation and interactive examples across algorithms as tutorials.&lt;/p&gt;\n\n&lt;p&gt;Feedback and contributions are very welcome!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Website: &lt;a href=\"https://pypots.com\"&gt;https://pypots.com&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Paper link: &lt;a href=\"https://arxiv.org/abs/2305.18811\"&gt;https://arxiv.org/abs/2305.18811&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;GitHub repo: &lt;a href=\"https://github.com/WenjieDu/PyPOTS\"&gt;https://github.com/WenjieDu/PyPOTS&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/bly5p3edx56b1.jpg?width=1801&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9fb5084d03ec048b4cf13f04b29b91cba65c6a49\"&gt;https://preview.redd.it/bly5p3edx56b1.jpg?width=1801&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9fb5084d03ec048b4cf13f04b29b91cba65c6a49&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?auto=webp&amp;v=enabled&amp;s=ae18da170d54a52f1073bf11f7d048c5a12962d0", "width": 1201, "height": 629}, "resolutions": [{"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a2a77f45b53751b494327fedd714b523034241a", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d9f30536681c6d1fddf2c5126b80f631e11bce1", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=567ae17fb9d2d4e40e09c033653354c1309eb75f", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9aa92dc7e349ba3089543da32836081b782de01a", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0725f3f4df1d6fcaea98ad8b82f200707595c63d", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da6916df36b5d3142764d9a689159a70d4eec0eb", "width": 1080, "height": 565}], "variants": {}, "id": "Fpe5wYBZaVfZMk60KGAqRJN_j6Ixp5cTN5LGAeoHZGo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2s5m1", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149zdd9", "is_robot_indexable": true, "report_reasons": null, "author": "WenjayDu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/github/comments/149zdd9/we_built_pypots_an_opensource_python_toolbox_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/github/comments/149zdd9/we_built_pypots_an_opensource_python_toolbox_for/", "subreddit_subscribers": 79917, "created_utc": 1686826585.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1686842378.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.github", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/github/comments/149zdd9/we_built_pypots_an_opensource_python_toolbox_for/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?auto=webp&amp;v=enabled&amp;s=ae18da170d54a52f1073bf11f7d048c5a12962d0", "width": 1201, "height": 629}, "resolutions": [{"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a2a77f45b53751b494327fedd714b523034241a", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5d9f30536681c6d1fddf2c5126b80f631e11bce1", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=567ae17fb9d2d4e40e09c033653354c1309eb75f", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9aa92dc7e349ba3089543da32836081b782de01a", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0725f3f4df1d6fcaea98ad8b82f200707595c63d", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/e8HHf-THPrCMQa7lxpMVr87t6jcp01GF2xxFA4GVXwc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=da6916df36b5d3142764d9a689159a70d4eec0eb", "width": 1080, "height": 565}], "variants": {}, "id": "Fpe5wYBZaVfZMk60KGAqRJN_j6Ixp5cTN5LGAeoHZGo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a54jm", "is_robot_indexable": true, "report_reasons": null, "author": "WenjayDu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_149zdd9", "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a54jm/we_built_pypots_an_opensource_python_toolbox_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/github/comments/149zdd9/we_built_pypots_an_opensource_python_toolbox_for/", "subreddit_subscribers": 925404, "created_utc": 1686842378.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi guys, I am full-stack web developer. I am going to build a web app which will make data predictions. For example, I sell three different chocolate brands at my shop which I order from a wholesaler. I want my app to make predictions for my next order according to the sales. But I don't have any knowledge of predictive analysis or data science. Though I know Python. I want to start learning Data science and I want it learn in way so that I can create this app. Can someone tell me how should I start and what should I learn?", "author_fullname": "t2_v9vzrxv4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predictive analysis as a web developer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14a44ca", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686839959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I am full-stack web developer. I am going to build a web app which will make data predictions. For example, I sell three different chocolate brands at my shop which I order from a wholesaler. I want my app to make predictions for my next order according to the sales. But I don&amp;#39;t have any knowledge of predictive analysis or data science. Though I know Python. I want to start learning Data science and I want it learn in way so that I can create this app. Can someone tell me how should I start and what should I learn?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a44ca", "is_robot_indexable": true, "report_reasons": null, "author": "eaazzy-eeee", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a44ca/predictive_analysis_as_a_web_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a44ca/predictive_analysis_as_a_web_developer/", "subreddit_subscribers": 925404, "created_utc": 1686839959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Another post of mine (non data scientist). This is rather a statistics problem.     \n\nI have about 120 samples with about 6 factors/features.  I really just want to examine the effect of 1 of those 6 factors. However, when I split my data according to the two factor levels that I'm trying to compute the effect of my two samples to compare are not normally distributed so that I cannot perform a t-test. If I rescale/normalize those factors by just computing a mean I essentially reduce my sample size but I get normally distributed samples.    \n\nNow, I have a very stupid comprehension problem.      \n1. Should I average out my data to make it normally distributed? (imagine it like having a bimodal distribution that arises from two distributions. But if I pool these distributions into one by averaging and essentially reducing the sample size by a factor of 2 I get a normal distribution. I assume that both distributions just differ by an offset since one sample was taken on day 1 and the other on day 7).         \n2. Should I not average out and instead use another test other than a t-test that doesn't require a normal distribution?        \n\nThanks!", "author_fullname": "t2_2fohpkzi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Normalization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14a3x3f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686839795.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686839451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Another post of mine (non data scientist). This is rather a statistics problem.     &lt;/p&gt;\n\n&lt;p&gt;I have about 120 samples with about 6 factors/features.  I really just want to examine the effect of 1 of those 6 factors. However, when I split my data according to the two factor levels that I&amp;#39;m trying to compute the effect of my two samples to compare are not normally distributed so that I cannot perform a t-test. If I rescale/normalize those factors by just computing a mean I essentially reduce my sample size but I get normally distributed samples.    &lt;/p&gt;\n\n&lt;p&gt;Now, I have a very stupid comprehension problem.&lt;br/&gt;\n1. Should I average out my data to make it normally distributed? (imagine it like having a bimodal distribution that arises from two distributions. But if I pool these distributions into one by averaging and essentially reducing the sample size by a factor of 2 I get a normal distribution. I assume that both distributions just differ by an offset since one sample was taken on day 1 and the other on day 7).&lt;br/&gt;\n2. Should I not average out and instead use another test other than a t-test that doesn&amp;#39;t require a normal distribution?        &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a3x3f", "is_robot_indexable": true, "report_reasons": null, "author": "mikehawk1988", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a3x3f/normalization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a3x3f/normalization/", "subreddit_subscribers": 925404, "created_utc": 1686839451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am an analyst and one of the things I work on is understanding the statistical significance of our A/B tests. The way some of our A/B tests work is that users are split into the control or test group as they log on to the website. When the test has finished running (14 days), we open the results and see that the two populations are not similar enough on the pre-treatment metrics that we are measuring - so the test is garbage. (It's not possible to allocate users to test or control as the test is running to make sure the pre-treatment metrics are similar.)\nIs there any way to throw out users who skew the pre -treatment measurements without destroying the statistical accuracy?", "author_fullname": "t2_13b1f3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pre-test biases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14a2sd5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686836555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am an analyst and one of the things I work on is understanding the statistical significance of our A/B tests. The way some of our A/B tests work is that users are split into the control or test group as they log on to the website. When the test has finished running (14 days), we open the results and see that the two populations are not similar enough on the pre-treatment metrics that we are measuring - so the test is garbage. (It&amp;#39;s not possible to allocate users to test or control as the test is running to make sure the pre-treatment metrics are similar.)\nIs there any way to throw out users who skew the pre -treatment measurements without destroying the statistical accuracy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a2sd5", "is_robot_indexable": true, "report_reasons": null, "author": "aaquad", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a2sd5/pretest_biases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a2sd5/pretest_biases/", "subreddit_subscribers": 925404, "created_utc": 1686836555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi MLearners, i would like to know if some of you has imagined the features and weights that can be included in the famous \"algorithm\" for positioning a video on YouTube, like views, upvote, down vote, semantic analysis of comments, video length, seo title...what's next?", "author_fullname": "t2_16ei22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google algorithm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14a0ctj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686829736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi MLearners, i would like to know if some of you has imagined the features and weights that can be included in the famous &amp;quot;algorithm&amp;quot; for positioning a video on YouTube, like views, upvote, down vote, semantic analysis of comments, video length, seo title...what&amp;#39;s next?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a0ctj", "is_robot_indexable": true, "report_reasons": null, "author": "satchurated", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a0ctj/google_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a0ctj/google_algorithm/", "subreddit_subscribers": 925404, "created_utc": 1686829736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,  \n\n\nI have received an interview invitation from a small company (&lt;100 employees) regarding the position of ML / AI student assistant. I already have a job in an even smaller company as a BI developer, but I have been considering the switch for some time already.   \n\n\nThat hiring company has started the digitization process last year and is now looking to hire a team of 3 students - 2 AI/ML students and 1 BI student - to work with CDO/CIO to research, test, build and implement new technologies. It is also mentioned that I would both be closely cooperating with that team as well as have some individual projects to work on.   \n\n\nAs for the responsibilities,  the job would be to \"research existing AI and ML tools, test them,  present the possible use-cases and either implement and integrate the existing tools that are already on the market or build your own. You will focus on how AI and ML can be utilized in both e-commerce and  digital marketing to create results and how it can be used in the entire clothing design process to assist our designers\".   \n\n\nI am happy to receive the interview invitation, but I would like to know what red flags should I spot and be wary of. I have a weird feeling that something is odd about it, even though I know close-to-nothing about the industry.", "author_fullname": "t2_5d0gohyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job opportunity potential red flags", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14a082z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686829317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,  &lt;/p&gt;\n\n&lt;p&gt;I have received an interview invitation from a small company (&amp;lt;100 employees) regarding the position of ML / AI student assistant. I already have a job in an even smaller company as a BI developer, but I have been considering the switch for some time already.   &lt;/p&gt;\n\n&lt;p&gt;That hiring company has started the digitization process last year and is now looking to hire a team of 3 students - 2 AI/ML students and 1 BI student - to work with CDO/CIO to research, test, build and implement new technologies. It is also mentioned that I would both be closely cooperating with that team as well as have some individual projects to work on.   &lt;/p&gt;\n\n&lt;p&gt;As for the responsibilities,  the job would be to &amp;quot;research existing AI and ML tools, test them,  present the possible use-cases and either implement and integrate the existing tools that are already on the market or build your own. You will focus on how AI and ML can be utilized in both e-commerce and  digital marketing to create results and how it can be used in the entire clothing design process to assist our designers&amp;quot;.   &lt;/p&gt;\n\n&lt;p&gt;I am happy to receive the interview invitation, but I would like to know what red flags should I spot and be wary of. I have a weird feeling that something is odd about it, even though I know close-to-nothing about the industry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14a082z", "is_robot_indexable": true, "report_reasons": null, "author": "Mewashek", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14a082z/job_opportunity_potential_red_flags/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14a082z/job_opportunity_potential_red_flags/", "subreddit_subscribers": 925404, "created_utc": 1686829317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been a data scientist in industry for a couple years now. It has been a great experience but I feel like I am stagnating in building new skills since my role is somewhat repetitive. I was recently approached for a position as a sales engineer at a data cloud / AI company. I feel like it is a good opportunity to further my career and broaden my skill set. I am mainly worried that this will shut the door for me to return to data science and machine learning if I decide to move back to more technical roles. Does this sales engineering role sound like it would limit my career path in that way?", "author_fullname": "t2_2413z598", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science to Sales Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149t0kp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686804460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been a data scientist in industry for a couple years now. It has been a great experience but I feel like I am stagnating in building new skills since my role is somewhat repetitive. I was recently approached for a position as a sales engineer at a data cloud / AI company. I feel like it is a good opportunity to further my career and broaden my skill set. I am mainly worried that this will shut the door for me to return to data science and machine learning if I decide to move back to more technical roles. Does this sales engineering role sound like it would limit my career path in that way?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149t0kp", "is_robot_indexable": true, "report_reasons": null, "author": "cbarraugh", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149t0kp/data_science_to_sales_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149t0kp/data_science_to_sales_engineering/", "subreddit_subscribers": 925404, "created_utc": 1686804460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Canada\u2019s population to hit 40M. Watch a live counter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149rbwn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_r1sc3tvt", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "ontario", "selftext": "Do we have room for them ?", "author_fullname": "t2_r1sc3tvt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Canada\u2019s population to hit 40M. Watch a live counter", "link_flair_richtext": [], "subreddit_name_prefixed": "r/ontario", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ra88", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Article", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1686799019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "statcan.gc.ca", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do we have room for them ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www150.statcan.gc.ca/n1/pub/71-607-x/71-607-x2018005-eng.htm", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1213e742-a307-11eb-a14c-0e1bcc14e645", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2qsf3", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "149ra88", "is_robot_indexable": true, "report_reasons": null, "author": "Correct_Signal_", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/ontario/comments/149ra88/canadas_population_to_hit_40m_watch_a_live_counter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www150.statcan.gc.ca/n1/pub/71-607-x/71-607-x2018005-eng.htm", "subreddit_subscribers": 672211, "created_utc": 1686799019.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1686799169.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "statcan.gc.ca", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www150.statcan.gc.ca/n1/pub/71-607-x/71-607-x2018005-eng.htm", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149rbwn", "is_robot_indexable": true, "report_reasons": null, "author": "Correct_Signal_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_149ra88", "author_flair_text_color": null, "permalink": "/r/datascience/comments/149rbwn/canadas_population_to_hit_40m_watch_a_live_counter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www150.statcan.gc.ca/n1/pub/71-607-x/71-607-x2018005-eng.htm", "subreddit_subscribers": 925404, "created_utc": 1686799169.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In the context of a bank's internal audit function, I understand that it is about risk management by evaluating the controls and processes.\n\nHow do we apply machine learning in the internal audit function?", "author_fullname": "t2_pnx7y1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Machine Learning in Internal Audit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149ptdq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686794593.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the context of a bank&amp;#39;s internal audit function, I understand that it is about risk management by evaluating the controls and processes.&lt;/p&gt;\n\n&lt;p&gt;How do we apply machine learning in the internal audit function?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149ptdq", "is_robot_indexable": true, "report_reasons": null, "author": "appleciderv", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149ptdq/machine_learning_in_internal_audit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149ptdq/machine_learning_in_internal_audit/", "subreddit_subscribers": 925404, "created_utc": 1686794593.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "cross posting from analytics to here in hopes to get some thoughts on this:\n\n&amp;#x200B;\n\nHow should your approach change in analyzing results if you have 3 groups?\n\nWe have an A/B test measuring clicks per user, and we have a control group and 2 treatment groups so 3 groups total.\n\ndo we typically try to measure performance of 1 group against both groups, or do we typically measure performance of 1 group vs 1 of the other 2, if that makes sense. for example group A vs group B, and then group A vs group C, or do we try to say \"group A showed an statistically sig lift vs groups B and C\"", "author_fullname": "t2_133emd5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A/B. test with 2 groups vs 3 groups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149m9s7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686784559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;cross posting from analytics to here in hopes to get some thoughts on this:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How should your approach change in analyzing results if you have 3 groups?&lt;/p&gt;\n\n&lt;p&gt;We have an A/B test measuring clicks per user, and we have a control group and 2 treatment groups so 3 groups total.&lt;/p&gt;\n\n&lt;p&gt;do we typically try to measure performance of 1 group against both groups, or do we typically measure performance of 1 group vs 1 of the other 2, if that makes sense. for example group A vs group B, and then group A vs group C, or do we try to say &amp;quot;group A showed an statistically sig lift vs groups B and C&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149m9s7", "is_robot_indexable": true, "report_reasons": null, "author": "vatom14", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149m9s7/ab_test_with_2_groups_vs_3_groups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149m9s7/ab_test_with_2_groups_vs_3_groups/", "subreddit_subscribers": 925404, "created_utc": 1686784559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "First of all: not a data scientist.\n\nI have a time series and I would like to detect steps. I've found a few algorithms on the internet but they are too parametric and need a lot of optimization that is hard to apply to versatile time series. \n\nMy data is not very noisy and there are very strong steps just like from a stair. One data set has about 40 steps. One drawback is that sometimes the steps start with a strong peak that very quickly fades again. Essentially a needle placed vertically at the beginning of a step, whereas a step should be defined at the beginning of these needles.\n\nWhat so far worked best was just to compute a moving min-max with window size of e.g. 5. If the min max surpasses a certain threshold I interpret it as a step. This leads to about 4 consecutive values surpassing that value such that I get rid of the first 3 and classify the 4th as a \"step\".    \n\nHowever, one problem arises when the step is very small and falls below the noise of my data, but the step is still very apparent. In that case I should be doing a t-test to compare the means of previous to subsequent steps with also e.g. window size 5, but I don't know how to implement it such that it only applies to these affected regions. It would be amazing to perform a \"moving t-test with window size 5 and 5, both windows representing one sample and being located next to each other\" instead of \"min max\".\n\nDo you think this is a good approach and if so, could you add something to that? Alternative approaches are also appreciated.\n\nI was also thinking about using a convolutional neural network with a 1D kernel and training data, but I think that ML algorithms will not do the job especially since labeling my graphs would take an eternity and hyperparameter tuning too.\n\nThanks!", "author_fullname": "t2_2fohpkzi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Step detector algorithm", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_149l3rz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686782267.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686781556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First of all: not a data scientist.&lt;/p&gt;\n\n&lt;p&gt;I have a time series and I would like to detect steps. I&amp;#39;ve found a few algorithms on the internet but they are too parametric and need a lot of optimization that is hard to apply to versatile time series. &lt;/p&gt;\n\n&lt;p&gt;My data is not very noisy and there are very strong steps just like from a stair. One data set has about 40 steps. One drawback is that sometimes the steps start with a strong peak that very quickly fades again. Essentially a needle placed vertically at the beginning of a step, whereas a step should be defined at the beginning of these needles.&lt;/p&gt;\n\n&lt;p&gt;What so far worked best was just to compute a moving min-max with window size of e.g. 5. If the min max surpasses a certain threshold I interpret it as a step. This leads to about 4 consecutive values surpassing that value such that I get rid of the first 3 and classify the 4th as a &amp;quot;step&amp;quot;.    &lt;/p&gt;\n\n&lt;p&gt;However, one problem arises when the step is very small and falls below the noise of my data, but the step is still very apparent. In that case I should be doing a t-test to compare the means of previous to subsequent steps with also e.g. window size 5, but I don&amp;#39;t know how to implement it such that it only applies to these affected regions. It would be amazing to perform a &amp;quot;moving t-test with window size 5 and 5, both windows representing one sample and being located next to each other&amp;quot; instead of &amp;quot;min max&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Do you think this is a good approach and if so, could you add something to that? Alternative approaches are also appreciated.&lt;/p&gt;\n\n&lt;p&gt;I was also thinking about using a convolutional neural network with a 1D kernel and training data, but I think that ML algorithms will not do the job especially since labeling my graphs would take an eternity and hyperparameter tuning too.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "149l3rz", "is_robot_indexable": true, "report_reasons": null, "author": "mikehawk1988", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/149l3rz/step_detector_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/149l3rz/step_detector_algorithm/", "subreddit_subscribers": 925404, "created_utc": 1686781556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Little late to the bandwagon but finally managed some time to play with LangChain. It honestly felt unethical being able to do such powerful tasks with such an ease \ud83d\ude2f For anyone out there still wondering about it, just give it a shot. LangChain definitely is one of the best packages with amazing documentation out there. \n\nAnyone have any tips on any newsletter/blog that would give a nice summary of all the products coming out built on top of LNgChain+LLMs?", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Blown away by the Langchain + OpenAi API combo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14acv5x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686861868.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Little late to the bandwagon but finally managed some time to play with LangChain. It honestly felt unethical being able to do such powerful tasks with such an ease \ud83d\ude2f For anyone out there still wondering about it, just give it a shot. LangChain definitely is one of the best packages with amazing documentation out there. &lt;/p&gt;\n\n&lt;p&gt;Anyone have any tips on any newsletter/blog that would give a nice summary of all the products coming out built on top of LNgChain+LLMs?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14acv5x", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14acv5x/blown_away_by_the_langchain_openai_api_combo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14acv5x/blown_away_by_the_langchain_openai_api_combo/", "subreddit_subscribers": 925404, "created_utc": 1686861868.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}