{"kind": "Listing", "data": {"after": "t3_14lo4ku", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just announced, Delta Lake 3.0 now compatible with Hudi and Iceberg.\n\nMy life just got more interesting.", "author_fullname": "t2_713dpi97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake 3.0", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lfqfu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 94, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 94, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687973614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just announced, Delta Lake 3.0 now compatible with Hudi and Iceberg.&lt;/p&gt;\n\n&lt;p&gt;My life just got more interesting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Manager", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lfqfu", "is_robot_indexable": true, "report_reasons": null, "author": "rexicusmaximus", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14lfqfu/delta_lake_30/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lfqfu/delta_lake_30/", "subreddit_subscribers": 113006, "created_utc": 1687973614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With all of the buzz around the high costs of various platforms and tools used for building data pipelines, including data collection, data warehousing, data processing and transformation, extracting insights out of the data - \n\nWhich are the most inefficient, ineffective, expensive products that you have experienced?\n\nTop 5 or 10 products listicles in various categories are just paid marketing campaigns and provide biased information.\n\nWhat is the tribal wisdom about the worst offenders in data tools and platforms that you would recommend staying away from and why?\n\nShare away and help the budding data engineers out.", "author_fullname": "t2_6pheknqy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which are the most inefficient, ineffective, expensive tools in your data stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ltv6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 58, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 58, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688009399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With all of the buzz around the high costs of various platforms and tools used for building data pipelines, including data collection, data warehousing, data processing and transformation, extracting insights out of the data - &lt;/p&gt;\n\n&lt;p&gt;Which are the most inefficient, ineffective, expensive products that you have experienced?&lt;/p&gt;\n\n&lt;p&gt;Top 5 or 10 products listicles in various categories are just paid marketing campaigns and provide biased information.&lt;/p&gt;\n\n&lt;p&gt;What is the tribal wisdom about the worst offenders in data tools and platforms that you would recommend staying away from and why?&lt;/p&gt;\n\n&lt;p&gt;Share away and help the budding data engineers out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ltv6p", "is_robot_indexable": true, "report_reasons": null, "author": "drc1728", "discussion_type": null, "num_comments": 131, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ltv6p/which_are_the_most_inefficient_ineffective/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ltv6p/which_are_the_most_inefficient_ineffective/", "subreddit_subscribers": 113006, "created_utc": 1688009399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to switch jobs and trying to determine what skills I would need to learn to try and get some interviews. My current job skills are heavy database, and coding in c#.  Therefore I think one of the skills I apparently need is Python, but I am not sure in want context I would need to learn/use it.\n\nSo my question is how are you using it? Is it simply to import files, run transform calc and export file? Are you exporting results to Databases/ pulling from databases? What editor do you use for your programs/scripts? I just feel lost at the idea of the generic \"learn python\", like I do with most other skills I am going to have to learn.", "author_fullname": "t2_11j6lc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is it you do with Python in your Job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lhzv9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687978940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to switch jobs and trying to determine what skills I would need to learn to try and get some interviews. My current job skills are heavy database, and coding in c#.  Therefore I think one of the skills I apparently need is Python, but I am not sure in want context I would need to learn/use it.&lt;/p&gt;\n\n&lt;p&gt;So my question is how are you using it? Is it simply to import files, run transform calc and export file? Are you exporting results to Databases/ pulling from databases? What editor do you use for your programs/scripts? I just feel lost at the idea of the generic &amp;quot;learn python&amp;quot;, like I do with most other skills I am going to have to learn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lhzv9", "is_robot_indexable": true, "report_reasons": null, "author": "Cstadler25", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lhzv9/what_is_it_you_do_with_python_in_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lhzv9/what_is_it_you_do_with_python_in_your_job/", "subreddit_subscribers": 113006, "created_utc": 1687978940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most people in their resume mention, they improved processing speeds by 20%, 30% etc, reduced costs. by x, y etc, . Do most developers know these kind of impacts in general? as an interviewer, do you care to ask them to elaborate? and people who mentioned stats like this, do you see improved calls for interviews? Also, at what years of experience people will care about this? ", "author_fullname": "t2_8fqzfba1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you as an engineer care how much efficiency/cost reductions you're bringing in?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lhlo6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687978013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most people in their resume mention, they improved processing speeds by 20%, 30% etc, reduced costs. by x, y etc, . Do most developers know these kind of impacts in general? as an interviewer, do you care to ask them to elaborate? and people who mentioned stats like this, do you see improved calls for interviews? Also, at what years of experience people will care about this? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lhlo6", "is_robot_indexable": true, "report_reasons": null, "author": "OptimistCherry", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lhlo6/do_you_as_an_engineer_care_how_much/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lhlo6/do_you_as_an_engineer_care_how_much/", "subreddit_subscribers": 113006, "created_utc": 1687978013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u8kebhp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks releases official SDK for Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14leo16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/T4Cm8TpuEbsjx0eN9z_Sxuq9ad6WD_ct5CZcJr74BF4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687971083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/databricks/databricks-sdk-py", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?auto=webp&amp;v=enabled&amp;s=acc4f5041fcaf40d949a2e4cd847bc08fcb005a4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adf867fe2bcae051621aeba4736112dbc20c72f0", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57141edffce8ca6d2acbb15a7b65388ad21e2056", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cfef8eca6f82325f924314d9d07cdf8e6cd3b9ff", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=feeb38a5a98bbef277fc0c31b6606bc79483fd91", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fb4920be5ece8ef16eaf4b82c39c87fa81b0fb5", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb059ae1542e2484e120ecd8e83f3351fc15ec07", "width": 1080, "height": 540}], "variants": {}, "id": "6IBNQF9cmQiIH3ZxOSSypIOoNLMuRKd750KVDHEoZxE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14leo16", "is_robot_indexable": true, "report_reasons": null, "author": "serge_databricks", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14leo16/databricks_releases_official_sdk_for_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/databricks/databricks-sdk-py", "subreddit_subscribers": 113006, "created_utc": 1687971083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I am still a newbie. I have a python project where I am scraping data from some log files on a daily basis and cleaning it then pushing it to db. I have scheduled this project to run daily on windows task scheduler. Is there any other(better) way it can be scheduled on a windows system?", "author_fullname": "t2_1js9ugwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I schedule python ETL code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lu0dk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688009808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am still a newbie. I have a python project where I am scraping data from some log files on a daily basis and cleaning it then pushing it to db. I have scheduled this project to run daily on windows task scheduler. Is there any other(better) way it can be scheduled on a windows system?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lu0dk", "is_robot_indexable": true, "report_reasons": null, "author": "Rawvik", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lu0dk/how_can_i_schedule_python_etl_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lu0dk/how_can_i_schedule_python_etl_code/", "subreddit_subscribers": 113006, "created_utc": 1688009808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "These are all boiler plate concerns and just seeking an open dialogue on advice. \n\nI have worked at multiple startups as a data engineer and run successful data warehouses. I write and follow standards, procedures, and best practices. Typically ive worked solo or with one other person. I am proud of the data platforms I have created. \n\nI am starting a new project as a consultant next week with a well known billion dollar company that I cant disclose. Im a little nervous because my past projects have been significantly less data than in the past. I work with snowflake. What do I need to be prepared for when working at scale. I.e I previously have worked with fact tables 500k-1M rows, now will be working with MM and billion row tables. \n\nI consider myself good at optimizing queries and I hope the power of larger snowflake warehouses will be of assistance. I am the lead engineer on the project so want to be as ready as possible for the transition from a small warehouse to a large warehouse. \n\nAnything helps! Thanks!", "author_fullname": "t2_6iq3gwld9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First DE gig at large scale", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lwjf0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688017626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;These are all boiler plate concerns and just seeking an open dialogue on advice. &lt;/p&gt;\n\n&lt;p&gt;I have worked at multiple startups as a data engineer and run successful data warehouses. I write and follow standards, procedures, and best practices. Typically ive worked solo or with one other person. I am proud of the data platforms I have created. &lt;/p&gt;\n\n&lt;p&gt;I am starting a new project as a consultant next week with a well known billion dollar company that I cant disclose. Im a little nervous because my past projects have been significantly less data than in the past. I work with snowflake. What do I need to be prepared for when working at scale. I.e I previously have worked with fact tables 500k-1M rows, now will be working with MM and billion row tables. &lt;/p&gt;\n\n&lt;p&gt;I consider myself good at optimizing queries and I hope the power of larger snowflake warehouses will be of assistance. I am the lead engineer on the project so want to be as ready as possible for the transition from a small warehouse to a large warehouse. &lt;/p&gt;\n\n&lt;p&gt;Anything helps! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14lwjf0", "is_robot_indexable": true, "report_reasons": null, "author": "ElephantCorrect2132", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lwjf0/first_de_gig_at_large_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lwjf0/first_de_gig_at_large_scale/", "subreddit_subscribers": 113006, "created_utc": 1688017626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I have recently started using Delta tables with Pyspark and AWS S3 storage.\n\nI am doing a merge into my Delta table, with conditions for update and insert.\n\nI have some test data that does not change between runs, so I was expecting the merge to be idempotent, meaning: two subsequent merges should not write any data to S3.\n\n&amp;#x200B;\n\nHowever, when I run the merge statement, most of the delta table is re-written.\n\nEven stranger,  when I check the Delta table's history, I verify that 0 rows were inserted, 0 rows were updated, and 0 rows were deleted - but also that 70 files were removed and 70 fliles were added (corresponding to most of my dataset).\n\nAny ideas why this might be the case? Thank you!", "author_fullname": "t2_8xg3h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta merge is writing data, even though there are no inserts or updates?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lnprw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687992523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have recently started using Delta tables with Pyspark and AWS S3 storage.&lt;/p&gt;\n\n&lt;p&gt;I am doing a merge into my Delta table, with conditions for update and insert.&lt;/p&gt;\n\n&lt;p&gt;I have some test data that does not change between runs, so I was expecting the merge to be idempotent, meaning: two subsequent merges should not write any data to S3.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, when I run the merge statement, most of the delta table is re-written.&lt;/p&gt;\n\n&lt;p&gt;Even stranger,  when I check the Delta table&amp;#39;s history, I verify that 0 rows were inserted, 0 rows were updated, and 0 rows were deleted - but also that 70 files were removed and 70 fliles were added (corresponding to most of my dataset).&lt;/p&gt;\n\n&lt;p&gt;Any ideas why this might be the case? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lnprw", "is_robot_indexable": true, "report_reasons": null, "author": "Fredbull", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lnprw/delta_merge_is_writing_data_even_though_there_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lnprw/delta_merge_is_writing_data_even_though_there_are/", "subreddit_subscribers": 113006, "created_utc": 1687992523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What do you guys think of dagsters new pricing model? I am pretty new to dagster and the pricing model just changed during trial.\nWith the Team Subscription, you have 10000 Credits available, which means 330 asset matrializations a day, which seems pretty low when you have a lot of small assets you are materializing daily. Materializing one asset every 10min gets you 150 already. Do I have a  wrong understanding of this?", "author_fullname": "t2_1jlb0188", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster Cloud Pricing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lk206", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687983809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you guys think of dagsters new pricing model? I am pretty new to dagster and the pricing model just changed during trial.\nWith the Team Subscription, you have 10000 Credits available, which means 330 asset matrializations a day, which seems pretty low when you have a lot of small assets you are materializing daily. Materializing one asset every 10min gets you 150 already. Do I have a  wrong understanding of this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lk206", "is_robot_indexable": true, "report_reasons": null, "author": "KindaRoot", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lk206/dagster_cloud_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lk206/dagster_cloud_pricing/", "subreddit_subscribers": 113006, "created_utc": 1687983809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would very much appreciate some advice.\n\nWe have a ton of historic semi-structured data which is stored in JSON. I say semi-structured because the structure has been expanded over the years, so the schema is not fixed over time, even if the major dimensions have not changed, the key figures have expanded.\n\nWe have probably records rows a day of JSON for the last 5 years, so 2m records. Each JSON record could be as much as a few kb. Maybe a few GB total, at the very most.\n\nIs there a product (ideally cloud) which is well suited to really easily importing this data and enabling us to do some basic time series analysis? I need some quick and dirty analysis and want to avoid a big data warehouse project. Doesn't matter if it's a commercial or open source product.\n\nBack in the day I used MongoDB to do things like this, but maybe there are better options now?", "author_fullname": "t2_pfwmnuy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data mart for semi-structured JSON data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m4bmf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688043350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would very much appreciate some advice.&lt;/p&gt;\n\n&lt;p&gt;We have a ton of historic semi-structured data which is stored in JSON. I say semi-structured because the structure has been expanded over the years, so the schema is not fixed over time, even if the major dimensions have not changed, the key figures have expanded.&lt;/p&gt;\n\n&lt;p&gt;We have probably records rows a day of JSON for the last 5 years, so 2m records. Each JSON record could be as much as a few kb. Maybe a few GB total, at the very most.&lt;/p&gt;\n\n&lt;p&gt;Is there a product (ideally cloud) which is well suited to really easily importing this data and enabling us to do some basic time series analysis? I need some quick and dirty analysis and want to avoid a big data warehouse project. Doesn&amp;#39;t matter if it&amp;#39;s a commercial or open source product.&lt;/p&gt;\n\n&lt;p&gt;Back in the day I used MongoDB to do things like this, but maybe there are better options now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14m4bmf", "is_robot_indexable": true, "report_reasons": null, "author": "thebemusedmuse", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m4bmf/data_mart_for_semistructured_json_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m4bmf/data_mart_for_semistructured_json_data/", "subreddit_subscribers": 113006, "created_utc": 1688043350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone else here? What are your thoughts so far?", "author_fullname": "t2_8y2a4hfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Data + AI Summit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lw0op", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688015974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone else here? What are your thoughts so far?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lw0op", "is_robot_indexable": true, "report_reasons": null, "author": "Known-Delay7227", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lw0op/databricks_data_ai_summit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lw0op/databricks_data_ai_summit/", "subreddit_subscribers": 113006, "created_utc": 1688015974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are working on setting up our databricks environment (I\u2019m sure you\u2019ve seen my other posts) I am wondering how you guys use these \n\n- do you have one to many storage credentials to external locations or one to one? \n- do you specify external locations at the top most level of a bucket or to a folder hierarchy in the bucket? \n- how do external tables work with unity catalog? If I make a catalog/ schema with an external location, where is that catalog and schema?", "author_fullname": "t2_18qay50v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External tables, storage credentials, and Unity Catalog.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lqcqk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687999390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are working on setting up our databricks environment (I\u2019m sure you\u2019ve seen my other posts) I am wondering how you guys use these &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;do you have one to many storage credentials to external locations or one to one? &lt;/li&gt;\n&lt;li&gt;do you specify external locations at the top most level of a bucket or to a folder hierarchy in the bucket? &lt;/li&gt;\n&lt;li&gt;how do external tables work with unity catalog? If I make a catalog/ schema with an external location, where is that catalog and schema?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lqcqk", "is_robot_indexable": true, "report_reasons": null, "author": "Doyale_royale", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lqcqk/external_tables_storage_credentials_and_unity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lqcqk/external_tables_storage_credentials_and_unity/", "subreddit_subscribers": 113006, "created_utc": 1687999390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event-driven architecture best practices for databases and files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14m7hqv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/WTOJsEP0Rq5B1qL_kKqfQ1YGjuTP2-adTlM2QKTxF08.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688051403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tbrd.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://tbrd.co/event-driven-rd", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?auto=webp&amp;v=enabled&amp;s=f07418903d601b5c94f23174f94ef0a2a98ea701", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34571a0268eff0b3a64ecf4b9c470bb7e6b06118", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c786a9e2dbbc1d0e2d5badf6476728fc35be3495", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a811005ee7b75d95e4e6beb57341ee7564b95d8f", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be5288509bf3e53a34b6a50b3d296b9c0787795b", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d6ca159b059f846d0efa50825649bfb601b8457", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95f59b0ec379c3314e9fe1e2d8fb71350ee965f0", "width": 1080, "height": 567}], "variants": {}, "id": "RwmfZSh5NCQ_MukD79s6jkdRZRfQvX6cHfjXu1xJKFI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14m7hqv", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m7hqv/eventdriven_architecture_best_practices_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tbrd.co/event-driven-rd", "subreddit_subscribers": 113006, "created_utc": 1688051403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been at my current job for 7 years. It\u2019s a small team (3 devs) maintaining. SaaS CRM for 1000 users at a $7billion company.\n\nMy development work consists of creating new screens in the web app with handlebars / JQuery / JavaScript, writing Rest API calls for other teams and passing them the postman file or working on Azure Synapse (spark) pipelines, the Azure SQL DB (stored procedures, views, etc)\n\nI pretty much feel like it\u2019s a Jack of all\nTrades situation.  Anything that comes up no matter l, what gets thrown at us devs.  If I update my Linked In to say Data Engineer it goes dark as I suspect not many companies use Azure SQL and Synapse and when I update it to Full Stack Developer or similar I get a lot of hits from people wanting me to work in the same CRM(D365) for them.  \n\nIf I\u2019m trying to target a new DE role somewhere should I drop all the front end Dev work stuff off my linked in and just write about the data work?  Any advice on how to parlay my Synapse / Azure SQL experience into something else? My goal for a next position would just be pure DE so I\u2019m not also tweaking CSS and writing handlebar templates half the time.  \nThanks", "author_fullname": "t2_5yj82gi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you call yourself if you do both front end Dev and DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m6t8f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688049782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been at my current job for 7 years. It\u2019s a small team (3 devs) maintaining. SaaS CRM for 1000 users at a $7billion company.&lt;/p&gt;\n\n&lt;p&gt;My development work consists of creating new screens in the web app with handlebars / JQuery / JavaScript, writing Rest API calls for other teams and passing them the postman file or working on Azure Synapse (spark) pipelines, the Azure SQL DB (stored procedures, views, etc)&lt;/p&gt;\n\n&lt;p&gt;I pretty much feel like it\u2019s a Jack of all\nTrades situation.  Anything that comes up no matter l, what gets thrown at us devs.  If I update my Linked In to say Data Engineer it goes dark as I suspect not many companies use Azure SQL and Synapse and when I update it to Full Stack Developer or similar I get a lot of hits from people wanting me to work in the same CRM(D365) for them.  &lt;/p&gt;\n\n&lt;p&gt;If I\u2019m trying to target a new DE role somewhere should I drop all the front end Dev work stuff off my linked in and just write about the data work?  Any advice on how to parlay my Synapse / Azure SQL experience into something else? My goal for a next position would just be pure DE so I\u2019m not also tweaking CSS and writing handlebar templates half the time.&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14m6t8f", "is_robot_indexable": true, "report_reasons": null, "author": "Swimming_Cry_6841", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m6t8f/what_do_you_call_yourself_if_you_do_both_front/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m6t8f/what_do_you_call_yourself_if_you_do_both_front/", "subreddit_subscribers": 113006, "created_utc": 1688049782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you design to handle EndEffectiveDate in DV Sat tables or SCD type2?\n\nDo you run updates with incremental loads or calculate on the fly with LAG(), or other ways?\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you design to handle EndEffectiveDate in DV Sat tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lkktf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687985256.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687985043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you design to handle EndEffectiveDate in DV Sat tables or SCD type2?&lt;/p&gt;\n\n&lt;p&gt;Do you run updates with incremental loads or calculate on the fly with LAG(), or other ways?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lkktf", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lkktf/how_do_you_design_to_handle_endeffectivedate_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lkktf/how_do_you_design_to_handle_endeffectivedate_in/", "subreddit_subscribers": 113006, "created_utc": 1687985043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\n\nI am writing a query in dataflow lookup with schema name as a parameter.\nI have already created a schema_name parameter with $parameter_name with string default value.\nSo how should i write a below query in lookup.\nSelect * from $parameter_name.tablename\n\nI have tried-\nConcat(\u2018Select * from \u2019, $parameter_name,\n\u2018.tablename\u2019)\n\nThis is working, it is not able read the value of parameter.\n\nCan anyone help me with the solution.", "author_fullname": "t2_jrlp2tiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF parameters in SQL query -Urgent", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14letcn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687971436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;I am writing a query in dataflow lookup with schema name as a parameter.\nI have already created a schema_name parameter with $parameter_name with string default value.\nSo how should i write a below query in lookup.\nSelect * from $parameter_name.tablename&lt;/p&gt;\n\n&lt;p&gt;I have tried-\nConcat(\u2018Select * from \u2019, $parameter_name,\n\u2018.tablename\u2019)&lt;/p&gt;\n\n&lt;p&gt;This is working, it is not able read the value of parameter.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help me with the solution.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14letcn", "is_robot_indexable": true, "report_reasons": null, "author": "ProcedureScared2970", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14letcn/adf_parameters_in_sql_query_urgent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14letcn/adf_parameters_in_sql_query_urgent/", "subreddit_subscribers": 113006, "created_utc": 1687971436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been struggling to get some decent client facing analytic tools up and running because our legacy on premise setup is basically two extremes of \"a couple poorly deployed COTS front end COTS apps only connected to 20% of our data\" or \"spark clusters and jupyter notebook data science\". The latter works for myself and other tech literate analysts or users.\n\nBeen reading more about OpenSearch since the current open-source ELK stack is super restricted to basically useless (you can't even print a dashboard or viz to PDF) and it's starting to look very appealing to get some datamarts hooked up to dashboards and viz, but I don't really come across discussion around OpenSearch and ELK stacks beyond search engines or as part of another app. No one at my workplace seems to have experience because everything for search engines deployed are all Solr setups.\n\nHow difficult are some of the AD integration for authn and authz to setup or the ABAC permission configs that the docs explain? Or setting up logstash / beats data connectors that listen in on an API?\n\nIt's all very outside my mostly SQL world wheelhouse but I experimented with it and kibana on a small ad hoc dataset and I really liked it as a kind of data exploration, EDA and search tool.\n\nBut is it something you would look to create indexes on a couple datamarts with some dashboards as a general purpose analytics tool or is the effort and esoteric configs just not worth it?", "author_fullname": "t2_51nsnxi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OpenSearch ELK stack for analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m44y9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688042829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been struggling to get some decent client facing analytic tools up and running because our legacy on premise setup is basically two extremes of &amp;quot;a couple poorly deployed COTS front end COTS apps only connected to 20% of our data&amp;quot; or &amp;quot;spark clusters and jupyter notebook data science&amp;quot;. The latter works for myself and other tech literate analysts or users.&lt;/p&gt;\n\n&lt;p&gt;Been reading more about OpenSearch since the current open-source ELK stack is super restricted to basically useless (you can&amp;#39;t even print a dashboard or viz to PDF) and it&amp;#39;s starting to look very appealing to get some datamarts hooked up to dashboards and viz, but I don&amp;#39;t really come across discussion around OpenSearch and ELK stacks beyond search engines or as part of another app. No one at my workplace seems to have experience because everything for search engines deployed are all Solr setups.&lt;/p&gt;\n\n&lt;p&gt;How difficult are some of the AD integration for authn and authz to setup or the ABAC permission configs that the docs explain? Or setting up logstash / beats data connectors that listen in on an API?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s all very outside my mostly SQL world wheelhouse but I experimented with it and kibana on a small ad hoc dataset and I really liked it as a kind of data exploration, EDA and search tool.&lt;/p&gt;\n\n&lt;p&gt;But is it something you would look to create indexes on a couple datamarts with some dashboards as a general purpose analytics tool or is the effort and esoteric configs just not worth it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14m44y9", "is_robot_indexable": true, "report_reasons": null, "author": "VersatileGuru", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m44y9/opensearch_elk_stack_for_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m44y9/opensearch_elk_stack_for_analytics/", "subreddit_subscribers": 113006, "created_utc": 1688042829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data analyst, and I'm not on the development side really I mainly run BI style analysis on our spark clusters with notebooks.\n\nI've done lots of reading and tutorials and the like on different ML applications in python, but all of them seem like they are quite 'heavy' in terms of investment, and really are best done as part of a concerted effort to actually build in a model onto some sort of product (i.e. recommendation engine on your app).\n\nBut, aside from that, are there any applications of ML or NLP that are more for making some of the more mundane tasks easier when it comes to analysis or ELT that is *actually* less work than writing out specific functions for transformation or dedupe or data enrichment?\n\nFor example, are there any interesting techniques people have somehow applied to help automate metadata tagging or data normalization?\n\n I don't mean like some magical one button non existent AI bullshit. I just mean practical day to day techniques that are repeatable and actually worth the time spent doing (as opposed to just tackling it manually) like when looking at a new data source for ETL \"you could use NLP to flag columns that likely match your existing schema\".\n\nClosest example I'm currently looking to play with is a few NLP based libraries for identifying and flagging PII or GDPR data that needs to be masked / purged.", "author_fullname": "t2_51nsnxi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Practical Applications of ML for analysis or ETL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m3oxa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688041586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data analyst, and I&amp;#39;m not on the development side really I mainly run BI style analysis on our spark clusters with notebooks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done lots of reading and tutorials and the like on different ML applications in python, but all of them seem like they are quite &amp;#39;heavy&amp;#39; in terms of investment, and really are best done as part of a concerted effort to actually build in a model onto some sort of product (i.e. recommendation engine on your app).&lt;/p&gt;\n\n&lt;p&gt;But, aside from that, are there any applications of ML or NLP that are more for making some of the more mundane tasks easier when it comes to analysis or ELT that is &lt;em&gt;actually&lt;/em&gt; less work than writing out specific functions for transformation or dedupe or data enrichment?&lt;/p&gt;\n\n&lt;p&gt;For example, are there any interesting techniques people have somehow applied to help automate metadata tagging or data normalization?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t mean like some magical one button non existent AI bullshit. I just mean practical day to day techniques that are repeatable and actually worth the time spent doing (as opposed to just tackling it manually) like when looking at a new data source for ETL &amp;quot;you could use NLP to flag columns that likely match your existing schema&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Closest example I&amp;#39;m currently looking to play with is a few NLP based libraries for identifying and flagging PII or GDPR data that needs to be masked / purged.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14m3oxa", "is_robot_indexable": true, "report_reasons": null, "author": "VersatileGuru", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m3oxa/practical_applications_of_ml_for_analysis_or_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m3oxa/practical_applications_of_ml_for_analysis_or_etl/", "subreddit_subscribers": 113006, "created_utc": 1688041586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m an embedded engineer intern working part time at a small startup with novel sensors and we\u2019re looking to start logging and storing important information from the devices. \n\nI want to go through the whole process of creating the database on new hardware, sending data from IOT devices, accessing data via an API, and having the database automatically manage the data via scripts (such as filtering). However, this is all extremely new to me, as I\u2019m only extremely familiar with low-level programming and hardware design so I want to choose the simplest and barebones tools as possible for this job.\n\nSo far everything we\u2019ve done is with basic files in a shared drive + emails lmao. I\u2019m wondering what machine should I get (what OS) if I\u2019m to use it for the sole purpose of database. What management system should I use? How do I create the API? How do I log data from embedded devices? I want to learn all this stuff, even though it\u2019s just for some current small-scale system as I aim to enter the IOT space.", "author_fullname": "t2_rkkbr1x8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating and utilizing a database in the simplest way possible", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lxz7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688022483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m an embedded engineer intern working part time at a small startup with novel sensors and we\u2019re looking to start logging and storing important information from the devices. &lt;/p&gt;\n\n&lt;p&gt;I want to go through the whole process of creating the database on new hardware, sending data from IOT devices, accessing data via an API, and having the database automatically manage the data via scripts (such as filtering). However, this is all extremely new to me, as I\u2019m only extremely familiar with low-level programming and hardware design so I want to choose the simplest and barebones tools as possible for this job.&lt;/p&gt;\n\n&lt;p&gt;So far everything we\u2019ve done is with basic files in a shared drive + emails lmao. I\u2019m wondering what machine should I get (what OS) if I\u2019m to use it for the sole purpose of database. What management system should I use? How do I create the API? How do I log data from embedded devices? I want to learn all this stuff, even though it\u2019s just for some current small-scale system as I aim to enter the IOT space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lxz7v", "is_robot_indexable": true, "report_reasons": null, "author": "aufry", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lxz7v/creating_and_utilizing_a_database_in_the_simplest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lxz7v/creating_and_utilizing_a_database_in_the_simplest/", "subreddit_subscribers": 113006, "created_utc": 1688022483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are my choices for working with data i.e. Data Engineering and ML/AI task on JAVA? \n\n&amp;#x200B;\n\nI know in Python there are many libraries/Frameworks choices Pandas(/numpy)/Polars/Dask/PySpark/Databricks depending on the size of data, type of system, on prem/cloud, project (webapp/edge device app) ect. For ML AI task again there are many options Scikit Learn, SparkML, Keras, ect. \n\n&amp;#x200B;\n\nAfter some googling and chatGPT prompts I didn't exactly find great results. I saw that many JAVA Frameworks that are used for ML task accept Tablesaw (Dataframes) i.e.DJL (Deep Java Library)\\\\DeepLearning4j\\\\Flink . However Tablesaw hasn't been updated since April 2022. I started looking at Spark on Java but had some trouble finding resources in Java. The resources I kept finding for spark ended up being for either Scala or Python. \n\n&amp;#x200B;\n\nAre there any good resources for data engineering and data science using JAVA. ", "author_fullname": "t2_h0k60d4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Java Data Engineering and Data Science Libraries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14licjh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687979786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are my choices for working with data i.e. Data Engineering and ML/AI task on JAVA? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know in Python there are many libraries/Frameworks choices Pandas(/numpy)/Polars/Dask/PySpark/Databricks depending on the size of data, type of system, on prem/cloud, project (webapp/edge device app) ect. For ML AI task again there are many options Scikit Learn, SparkML, Keras, ect. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;After some googling and chatGPT prompts I didn&amp;#39;t exactly find great results. I saw that many JAVA Frameworks that are used for ML task accept Tablesaw (Dataframes) i.e.DJL (Deep Java Library)\\DeepLearning4j\\Flink . However Tablesaw hasn&amp;#39;t been updated since April 2022. I started looking at Spark on Java but had some trouble finding resources in Java. The resources I kept finding for spark ended up being for either Scala or Python. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Are there any good resources for data engineering and data science using JAVA. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14licjh", "is_robot_indexable": true, "report_reasons": null, "author": "magu01", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14licjh/java_data_engineering_and_data_science_libraries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14licjh/java_data_engineering_and_data_science_libraries/", "subreddit_subscribers": 113006, "created_utc": 1687979786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hope I'm not breaking any rules of this sub. \n\nI'm looking for some book (or any other resource tbh) recommendations to learn more about data virtualization. My company is now moving towards using Denodo and I'd like read up on this over the weekend. I probably don't want something that goes into the very minute detail - something that scratches the surface should suffice for the first pass.", "author_fullname": "t2_sucuw1gz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book recommendation for Data virtualization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m7djl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688051115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hope I&amp;#39;m not breaking any rules of this sub. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for some book (or any other resource tbh) recommendations to learn more about data virtualization. My company is now moving towards using Denodo and I&amp;#39;d like read up on this over the weekend. I probably don&amp;#39;t want something that goes into the very minute detail - something that scratches the surface should suffice for the first pass.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14m7djl", "is_robot_indexable": true, "report_reasons": null, "author": "x_butnocigar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m7djl/book_recommendation_for_data_virtualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m7djl/book_recommendation_for_data_virtualization/", "subreddit_subscribers": 113006, "created_utc": 1688051115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# Background\n\n* I\u2019ve been playing around with `explain` out of curiosity\n* I\u2019m trying to understand how column-level lineages can be built from `explain(\"formatted\")` (although this isn\u2019t that relevant to my question)\n* This question\u2019s scope is limited to query plans for queries of the form `spark.table(\"schema.table\").explain(\"formatted\")`\n\n# Question\n\n* When running the above query on separate tables, why is it that the column identifiers start at different values for different tables (see example below)?\n\n# Examples\n\n* Disclaimers:\n   * The columns and identifiers are separated from each other and stored in a dictionary as a result of a function I wrote to process the `explain(\"formatted\")` output\n   * I\u2019ve renamed the columns since they\u2019re from actual tables used in my company\n\n**Table A**\n\n    {'a_1': '0L',\n     'a_2': '1L',\n     'a_3': '2',\n     'a_4': '3',\n     'a_5': '4',\n     'a_6': '5',\n     'a_7': '6',\n     'a_8': '7',\n     'a_9': '8L',\n     'a_10': '9',\n     'a_11': '10',\n     'a_12': '11',\n     'a_13': '12',\n     'a_14': '13',\n     'a_15': '14',\n     'a_16': '15',\n     'a_17': '16'}\n\n**Table B**\n\n    {'b_1': '1844L',\n     'b_2': '1845',\n     'b_3': '1846',\n     'b_4': '1847L',\n     'b_5': '1848',\n     'b_6': '1849',\n     'b_7': '1850',\n     'b_8': '1851',\n     'b_9': '1852',\n     'b_10': '1853'}", "author_fullname": "t2_a8joqf7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark explain(): how does Spark decide on the value of column identifiers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m6etv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688048787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Background&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I\u2019ve been playing around with &lt;code&gt;explain&lt;/code&gt; out of curiosity&lt;/li&gt;\n&lt;li&gt;I\u2019m trying to understand how column-level lineages can be built from &lt;code&gt;explain(&amp;quot;formatted&amp;quot;)&lt;/code&gt; (although this isn\u2019t that relevant to my question)&lt;/li&gt;\n&lt;li&gt;This question\u2019s scope is limited to query plans for queries of the form &lt;code&gt;spark.table(&amp;quot;schema.table&amp;quot;).explain(&amp;quot;formatted&amp;quot;)&lt;/code&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Question&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;When running the above query on separate tables, why is it that the column identifiers start at different values for different tables (see example below)?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Examples&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Disclaimers:\n\n&lt;ul&gt;\n&lt;li&gt;The columns and identifiers are separated from each other and stored in a dictionary as a result of a function I wrote to process the &lt;code&gt;explain(&amp;quot;formatted&amp;quot;)&lt;/code&gt; output&lt;/li&gt;\n&lt;li&gt;I\u2019ve renamed the columns since they\u2019re from actual tables used in my company&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Table A&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{&amp;#39;a_1&amp;#39;: &amp;#39;0L&amp;#39;,\n &amp;#39;a_2&amp;#39;: &amp;#39;1L&amp;#39;,\n &amp;#39;a_3&amp;#39;: &amp;#39;2&amp;#39;,\n &amp;#39;a_4&amp;#39;: &amp;#39;3&amp;#39;,\n &amp;#39;a_5&amp;#39;: &amp;#39;4&amp;#39;,\n &amp;#39;a_6&amp;#39;: &amp;#39;5&amp;#39;,\n &amp;#39;a_7&amp;#39;: &amp;#39;6&amp;#39;,\n &amp;#39;a_8&amp;#39;: &amp;#39;7&amp;#39;,\n &amp;#39;a_9&amp;#39;: &amp;#39;8L&amp;#39;,\n &amp;#39;a_10&amp;#39;: &amp;#39;9&amp;#39;,\n &amp;#39;a_11&amp;#39;: &amp;#39;10&amp;#39;,\n &amp;#39;a_12&amp;#39;: &amp;#39;11&amp;#39;,\n &amp;#39;a_13&amp;#39;: &amp;#39;12&amp;#39;,\n &amp;#39;a_14&amp;#39;: &amp;#39;13&amp;#39;,\n &amp;#39;a_15&amp;#39;: &amp;#39;14&amp;#39;,\n &amp;#39;a_16&amp;#39;: &amp;#39;15&amp;#39;,\n &amp;#39;a_17&amp;#39;: &amp;#39;16&amp;#39;}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;Table B&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{&amp;#39;b_1&amp;#39;: &amp;#39;1844L&amp;#39;,\n &amp;#39;b_2&amp;#39;: &amp;#39;1845&amp;#39;,\n &amp;#39;b_3&amp;#39;: &amp;#39;1846&amp;#39;,\n &amp;#39;b_4&amp;#39;: &amp;#39;1847L&amp;#39;,\n &amp;#39;b_5&amp;#39;: &amp;#39;1848&amp;#39;,\n &amp;#39;b_6&amp;#39;: &amp;#39;1849&amp;#39;,\n &amp;#39;b_7&amp;#39;: &amp;#39;1850&amp;#39;,\n &amp;#39;b_8&amp;#39;: &amp;#39;1851&amp;#39;,\n &amp;#39;b_9&amp;#39;: &amp;#39;1852&amp;#39;,\n &amp;#39;b_10&amp;#39;: &amp;#39;1853&amp;#39;}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14m6etv", "is_robot_indexable": true, "report_reasons": null, "author": "haskathon", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m6etv/spark_explain_how_does_spark_decide_on_the_value/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m6etv/spark_explain_how_does_spark_decide_on_the_value/", "subreddit_subscribers": 113006, "created_utc": 1688048787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am currently on the verge of completing my Ph.D. in Bioinformatics and I am exploring potential career opportunities outside of academia. I have been considering a transition to the field of Data Engineering and I'm curious to know if anyone here has made a similar leap or has insights to share.\n\nTo provide some background, I thoroughly enjoy working with data, especially when it comes to organizing, curating, and cleaning it. While I also find joy in analyzing data and making predictions, I feel a stronger affinity towards the data management aspects of the process. With proficiency in Python, SQL, and R, I have a solid foundation in data-related programming languages.\n\nDuring my research journey, I extensively employed ML algorithms, particularly focusing on clustering, within the domain of Genomic Data Science. This experience allowed me to gain valuable skills in data manipulation, preprocessing, and extracting meaningful insights from complex biological datasets.\n\nMoreover, to further enhance my skills in data management and engineering, I completed the Data Engineering career path on DataCamp. This course deepened my understanding of various data storage and processing technologies, such as Apache Spark, Hadoop, and ETL pipelines.\n\nGiven this background, I am curious to know if it is possible to transition from Bioinformatics to Data Engineering. I understand that there might be differences in the domains, but I believe that the skills I have acquired can be transferrable.\n\nI would greatly appreciate any insights, experiences, or advice from those who have successfully transitioned from Bioinformatics or a related field to Data Engineering. Are there any specific skills or knowledge areas that I should focus on to increase my chances of making a smooth transition? Are there any potential hurdles or challenges that I should be aware of?\n\nThank you in advance for your time and valuable input. I am eager to hear your thoughts and experiences on this matter.", "author_fullname": "t2_3x005wsk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from Bioinformatics to Data Engineering: Feasibility and Career Opportunities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m4j6x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688043907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am currently on the verge of completing my Ph.D. in Bioinformatics and I am exploring potential career opportunities outside of academia. I have been considering a transition to the field of Data Engineering and I&amp;#39;m curious to know if anyone here has made a similar leap or has insights to share.&lt;/p&gt;\n\n&lt;p&gt;To provide some background, I thoroughly enjoy working with data, especially when it comes to organizing, curating, and cleaning it. While I also find joy in analyzing data and making predictions, I feel a stronger affinity towards the data management aspects of the process. With proficiency in Python, SQL, and R, I have a solid foundation in data-related programming languages.&lt;/p&gt;\n\n&lt;p&gt;During my research journey, I extensively employed ML algorithms, particularly focusing on clustering, within the domain of Genomic Data Science. This experience allowed me to gain valuable skills in data manipulation, preprocessing, and extracting meaningful insights from complex biological datasets.&lt;/p&gt;\n\n&lt;p&gt;Moreover, to further enhance my skills in data management and engineering, I completed the Data Engineering career path on DataCamp. This course deepened my understanding of various data storage and processing technologies, such as Apache Spark, Hadoop, and ETL pipelines.&lt;/p&gt;\n\n&lt;p&gt;Given this background, I am curious to know if it is possible to transition from Bioinformatics to Data Engineering. I understand that there might be differences in the domains, but I believe that the skills I have acquired can be transferrable.&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate any insights, experiences, or advice from those who have successfully transitioned from Bioinformatics or a related field to Data Engineering. Are there any specific skills or knowledge areas that I should focus on to increase my chances of making a smooth transition? Are there any potential hurdles or challenges that I should be aware of?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your time and valuable input. I am eager to hear your thoughts and experiences on this matter.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14m4j6x", "is_robot_indexable": true, "report_reasons": null, "author": "greengecko7", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m4j6x/transitioning_from_bioinformatics_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m4j6x/transitioning_from_bioinformatics_to_data/", "subreddit_subscribers": 113006, "created_utc": 1688043907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "A nice article shows how to utilize ipinfo database to create location-based access control in a full-stack app. Good to see how those new data cloud products can use to create much better security for every app in no time.\n\n[https://io.permit.io/location-based-access](https://io.permit.io/location-based-access) ", "author_fullname": "t2_ij9mevpn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Meet Security for Location-based Access Control", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m2ch5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688037537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A nice article shows how to utilize ipinfo database to create location-based access control in a full-stack app. Good to see how those new data cloud products can use to create much better security for every app in no time.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://io.permit.io/location-based-access\"&gt;https://io.permit.io/location-based-access&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14m2ch5", "is_robot_indexable": true, "report_reasons": null, "author": "Permit_io", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m2ch5/data_meet_security_for_locationbased_access/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m2ch5/data_meet_security_for_locationbased_access/", "subreddit_subscribers": 113006, "created_utc": 1688037537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering how do we decide on how often we schedule ETL job for delta extraction? What factors are to be considered?\n\nSay a workorder table record may have multiple changes happening within a day, scheduling ELT job hourly may bring in multiple records for same work order in DW vs nightly once run. So what are the guiding principles or business cases for a decision\n\nHow often your extraction jobs are run/scheduled at your company and how were they decided?\n\nAlso besides the business needs are there any technical reasons that influence scheduling?", "author_fullname": "t2_4ck30tok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you decide when to extract delta?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lo4ku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688010232.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687993523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering how do we decide on how often we schedule ETL job for delta extraction? What factors are to be considered?&lt;/p&gt;\n\n&lt;p&gt;Say a workorder table record may have multiple changes happening within a day, scheduling ELT job hourly may bring in multiple records for same work order in DW vs nightly once run. So what are the guiding principles or business cases for a decision&lt;/p&gt;\n\n&lt;p&gt;How often your extraction jobs are run/scheduled at your company and how were they decided?&lt;/p&gt;\n\n&lt;p&gt;Also besides the business needs are there any technical reasons that influence scheduling?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lo4ku", "is_robot_indexable": true, "report_reasons": null, "author": "Nomad4455", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lo4ku/how_do_you_decide_when_to_extract_delta/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lo4ku/how_do_you_decide_when_to_extract_delta/", "subreddit_subscribers": 113006, "created_utc": 1687993523.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}