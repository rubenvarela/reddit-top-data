{"kind": "Listing", "data": {"after": "t3_14lms2a", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just announced, Delta Lake 3.0 now compatible with Hudi and Iceberg.\n\nMy life just got more interesting.", "author_fullname": "t2_713dpi97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake 3.0", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lfqfu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 81, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 81, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687973614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just announced, Delta Lake 3.0 now compatible with Hudi and Iceberg.&lt;/p&gt;\n\n&lt;p&gt;My life just got more interesting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Manager", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lfqfu", "is_robot_indexable": true, "report_reasons": null, "author": "rexicusmaximus", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14lfqfu/delta_lake_30/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lfqfu/delta_lake_30/", "subreddit_subscribers": 112926, "created_utc": 1687973614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to switch jobs and trying to determine what skills I would need to learn to try and get some interviews. My current job skills are heavy database, and coding in c#.  Therefore I think one of the skills I apparently need is Python, but I am not sure in want context I would need to learn/use it.\n\nSo my question is how are you using it? Is it simply to import files, run transform calc and export file? Are you exporting results to Databases/ pulling from databases? What editor do you use for your programs/scripts? I just feel lost at the idea of the generic \"learn python\", like I do with most other skills I am going to have to learn.", "author_fullname": "t2_11j6lc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is it you do with Python in your Job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lhzv9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687978940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to switch jobs and trying to determine what skills I would need to learn to try and get some interviews. My current job skills are heavy database, and coding in c#.  Therefore I think one of the skills I apparently need is Python, but I am not sure in want context I would need to learn/use it.&lt;/p&gt;\n\n&lt;p&gt;So my question is how are you using it? Is it simply to import files, run transform calc and export file? Are you exporting results to Databases/ pulling from databases? What editor do you use for your programs/scripts? I just feel lost at the idea of the generic &amp;quot;learn python&amp;quot;, like I do with most other skills I am going to have to learn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lhzv9", "is_robot_indexable": true, "report_reasons": null, "author": "Cstadler25", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lhzv9/what_is_it_you_do_with_python_in_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lhzv9/what_is_it_you_do_with_python_in_your_job/", "subreddit_subscribers": 112926, "created_utc": 1687978940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u8kebhp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks releases official SDK for Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14leo16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/T4Cm8TpuEbsjx0eN9z_Sxuq9ad6WD_ct5CZcJr74BF4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687971083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/databricks/databricks-sdk-py", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?auto=webp&amp;v=enabled&amp;s=acc4f5041fcaf40d949a2e4cd847bc08fcb005a4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adf867fe2bcae051621aeba4736112dbc20c72f0", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57141edffce8ca6d2acbb15a7b65388ad21e2056", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cfef8eca6f82325f924314d9d07cdf8e6cd3b9ff", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=feeb38a5a98bbef277fc0c31b6606bc79483fd91", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fb4920be5ece8ef16eaf4b82c39c87fa81b0fb5", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb059ae1542e2484e120ecd8e83f3351fc15ec07", "width": 1080, "height": 540}], "variants": {}, "id": "6IBNQF9cmQiIH3ZxOSSypIOoNLMuRKd750KVDHEoZxE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14leo16", "is_robot_indexable": true, "report_reasons": null, "author": "serge_databricks", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14leo16/databricks_releases_official_sdk_for_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/databricks/databricks-sdk-py", "subreddit_subscribers": 112926, "created_utc": 1687971083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most people in their resume mention, they improved processing speeds by 20%, 30% etc, reduced costs. by x, y etc, . Do most developers know these kind of impacts in general? as an interviewer, do you care to ask them to elaborate? and people who mentioned stats like this, do you see improved calls for interviews? Also, at what years of experience people will care about this? ", "author_fullname": "t2_8fqzfba1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you as an engineer care how much efficiency/cost reductions you're bringing in?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lhlo6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687978013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most people in their resume mention, they improved processing speeds by 20%, 30% etc, reduced costs. by x, y etc, . Do most developers know these kind of impacts in general? as an interviewer, do you care to ask them to elaborate? and people who mentioned stats like this, do you see improved calls for interviews? Also, at what years of experience people will care about this? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lhlo6", "is_robot_indexable": true, "report_reasons": null, "author": "OptimistCherry", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lhlo6/do_you_as_an_engineer_care_how_much/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lhlo6/do_you_as_an_engineer_care_how_much/", "subreddit_subscribers": 112926, "created_utc": 1687978013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I ask as someone who is completely unfamiliar with the field and only knows it as a subset of software engineering \u2014 my title is software engineer and I\u2019m part of a new grad rotational program and the rotation that I was just assigned to is basically a data engineering role. \n\nI\u2019ve been told I\u2019ll be using Python, GCP, and some APIs/ETL tools but I have really no concept of what that looks like in terms of how they interact with each other or how technical it will be. I\u2019ve read on this sub that it can vary from solutions where you don\u2019t write a ton of code and that most of the heavy lifting is done by some tool or low-code platform, to just being Python scripts gathering things from different sources, to really complex brain surgery code. I know that every case is different, but what is the most common scenario (especially given the technologies I mentioned)?", "author_fullname": "t2_5ah07udc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How complex is the coding in data engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l2se5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687937371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ask as someone who is completely unfamiliar with the field and only knows it as a subset of software engineering \u2014 my title is software engineer and I\u2019m part of a new grad rotational program and the rotation that I was just assigned to is basically a data engineering role. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been told I\u2019ll be using Python, GCP, and some APIs/ETL tools but I have really no concept of what that looks like in terms of how they interact with each other or how technical it will be. I\u2019ve read on this sub that it can vary from solutions where you don\u2019t write a ton of code and that most of the heavy lifting is done by some tool or low-code platform, to just being Python scripts gathering things from different sources, to really complex brain surgery code. I know that every case is different, but what is the most common scenario (especially given the technologies I mentioned)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14l2se5", "is_robot_indexable": true, "report_reasons": null, "author": "jimharbaughthrowaway", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l2se5/how_complex_is_the_coding_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l2se5/how_complex_is_the_coding_in_data_engineering/", "subreddit_subscribers": 112926, "created_utc": 1687937371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_cp1afbpy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Facebook data transfers declared illegal", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14l4vx6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/W8uGyrlvQygFg_rRgAMqXpeLJ3YONTEx29NRiIgY6kE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687944975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "simpleanalytics.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.simpleanalytics.com/blog/meta-hit-with-record-breaking-1-3-billion-fine-over-facebook-data-transfers-to-the-us", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?auto=webp&amp;v=enabled&amp;s=4656d7a82bd341b62c92ae3ea737313ccf033fa4", "width": 1000, "height": 523}, "resolutions": [{"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a3c3430786c5f80cb771c67a3759036191424d61", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ef490707114127b18201183b737925a2d1aef3b6", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0ebeae41cc50014b4dbda964f13017329b909e27", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e206fdb52dc4d73d477ec0cd93963175a4eac4d7", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/z2jkFROUO_WHtf0InrWOR2SFPF6fWztXK6ZBOxCzcAQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5bd40816e9cd524436e774f464dfcd8ac7d71c26", "width": 960, "height": 502}], "variants": {}, "id": "p4LUfDlJMgUcV_dAFYAKR_AN31ciT_2jgZfllIkmSX4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14l4vx6", "is_robot_indexable": true, "report_reasons": null, "author": "nulovyk", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l4vx6/facebook_data_transfers_declared_illegal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.simpleanalytics.com/blog/meta-hit-with-record-breaking-1-3-billion-fine-over-facebook-data-transfers-to-the-us", "subreddit_subscribers": 112926, "created_utc": 1687944975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LakehouseIQ: Your new AI overlord", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14lcl25", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5Cj0uZCvWJ3ImvXy1b7VYd5DorYe54LBpuERUqXRoGs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687966222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "databricks.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.databricks.com/blog/introducing-lakehouseiq-ai-powered-engine-uniquely-understands-your-business", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?auto=webp&amp;v=enabled&amp;s=54c85608339efd7fc98d82c6e5b6c9037d5411f2", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49591bac210c847aac0bde7034427b597fa95e23", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2abb0c0cf8bf149f255a6877f21eeedfcf1d7fba", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5964f5ea655f0c082865c46c6b9b9bcdb6bf5d10", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08d9fdd05bddec589e96728cffd91c20aa02822a", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cff40cf2a10d7a4505e1a08f0230f717c73a797e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2da1bbe17bc855612237efc1fa8f4b062fea442d", "width": 1080, "height": 565}], "variants": {}, "id": "1WPTbdrGWkjPjVPTtLKBuew_V3jfMV5ZAV1IKBysEkc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14lcl25", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lcl25/lakehouseiq_your_new_ai_overlord/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.databricks.com/blog/introducing-lakehouseiq-ai-powered-engine-uniquely-understands-your-business", "subreddit_subscribers": 112926, "created_utc": 1687966222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently a postdoc at a university, but I would like to move into a private industry career that acquires and analyzes weather/climate/geospatial data. For example, there are a ton of mapping apps (OnX, Gaia, etc) that I think would benefit from including more weather data and derived products. \n\n&amp;nbsp;\n\n**Are there any resources (websites, books) that deal explicitly with the DE challenges unique to these data?** For example, I have almost never had to use SQL in my work and most things I work with are gridded (i.e. raster). I know there will be overlap with things like AWS, Spark, etc, so I am focusing on those right now. \n\n&amp;nbsp;\n\nThanks!", "author_fullname": "t2_bf1rl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for Weather/Geospatial data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lcyxr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687967137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a postdoc at a university, but I would like to move into a private industry career that acquires and analyzes weather/climate/geospatial data. For example, there are a ton of mapping apps (OnX, Gaia, etc) that I think would benefit from including more weather data and derived products. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Are there any resources (websites, books) that deal explicitly with the DE challenges unique to these data?&lt;/strong&gt; For example, I have almost never had to use SQL in my work and most things I work with are gridded (i.e. raster). I know there will be overlap with things like AWS, Spark, etc, so I am focusing on those right now. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lcyxr", "is_robot_indexable": true, "report_reasons": null, "author": "gbromley", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lcyxr/resources_for_weathergeospatial_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lcyxr/resources_for_weathergeospatial_data/", "subreddit_subscribers": 112926, "created_utc": 1687967137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With all of the buzz around the high costs of various platforms and tools used for building data pipelines, including data collection, data warehousing, data processing and transformation, extracting insights out of the data - \n\nWhich are the most inefficient, ineffective, expensive products that you have experienced?\n\nTop 5 or 10 products listicles in various categories are just paid marketing campaigns and provide biased information.\n\nWhat is the tribal wisdom about the worst offenders in data tools and platforms that you would recommend staying away from and why?\n\nShare away and help the budding data engineers out.", "author_fullname": "t2_6pheknqy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which are the most inefficient, ineffective, expensive tools in your data stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ltv6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688009399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With all of the buzz around the high costs of various platforms and tools used for building data pipelines, including data collection, data warehousing, data processing and transformation, extracting insights out of the data - &lt;/p&gt;\n\n&lt;p&gt;Which are the most inefficient, ineffective, expensive products that you have experienced?&lt;/p&gt;\n\n&lt;p&gt;Top 5 or 10 products listicles in various categories are just paid marketing campaigns and provide biased information.&lt;/p&gt;\n\n&lt;p&gt;What is the tribal wisdom about the worst offenders in data tools and platforms that you would recommend staying away from and why?&lt;/p&gt;\n\n&lt;p&gt;Share away and help the budding data engineers out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ltv6p", "is_robot_indexable": true, "report_reasons": null, "author": "drc1728", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ltv6p/which_are_the_most_inefficient_ineffective/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ltv6p/which_are_the_most_inefficient_ineffective/", "subreddit_subscribers": 112926, "created_utc": 1688009399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I have recently started using Delta tables with Pyspark and AWS S3 storage.\n\nI am doing a merge into my Delta table, with conditions for update and insert.\n\nI have some test data that does not change between runs, so I was expecting the merge to be idempotent, meaning: two subsequent merges should not write any data to S3.\n\n&amp;#x200B;\n\nHowever, when I run the merge statement, most of the delta table is re-written.\n\nEven stranger,  when I check the Delta table's history, I verify that 0 rows were inserted, 0 rows were updated, and 0 rows were deleted - but also that 70 files were removed and 70 fliles were added (corresponding to most of my dataset).\n\nAny ideas why this might be the case? Thank you!", "author_fullname": "t2_8xg3h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta merge is writing data, even though there are no inserts or updates?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lnprw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687992523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have recently started using Delta tables with Pyspark and AWS S3 storage.&lt;/p&gt;\n\n&lt;p&gt;I am doing a merge into my Delta table, with conditions for update and insert.&lt;/p&gt;\n\n&lt;p&gt;I have some test data that does not change between runs, so I was expecting the merge to be idempotent, meaning: two subsequent merges should not write any data to S3.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, when I run the merge statement, most of the delta table is re-written.&lt;/p&gt;\n\n&lt;p&gt;Even stranger,  when I check the Delta table&amp;#39;s history, I verify that 0 rows were inserted, 0 rows were updated, and 0 rows were deleted - but also that 70 files were removed and 70 fliles were added (corresponding to most of my dataset).&lt;/p&gt;\n\n&lt;p&gt;Any ideas why this might be the case? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lnprw", "is_robot_indexable": true, "report_reasons": null, "author": "Fredbull", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lnprw/delta_merge_is_writing_data_even_though_there_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lnprw/delta_merge_is_writing_data_even_though_there_are/", "subreddit_subscribers": 112926, "created_utc": 1687992523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What do you guys think of dagsters new pricing model? I am pretty new to dagster and the pricing model just changed during trial.\nWith the Team Subscription, you have 10000 Credits available, which means 330 asset matrializations a day, which seems pretty low when you have a lot of small assets you are materializing daily. Materializing one asset every 10min gets you 150 already. Do I have a  wrong understanding of this?", "author_fullname": "t2_1jlb0188", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster Cloud Pricing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lk206", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687983809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you guys think of dagsters new pricing model? I am pretty new to dagster and the pricing model just changed during trial.\nWith the Team Subscription, you have 10000 Credits available, which means 330 asset matrializations a day, which seems pretty low when you have a lot of small assets you are materializing daily. Materializing one asset every 10min gets you 150 already. Do I have a  wrong understanding of this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lk206", "is_robot_indexable": true, "report_reasons": null, "author": "KindaRoot", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lk206/dagster_cloud_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lk206/dagster_cloud_pricing/", "subreddit_subscribers": 112926, "created_utc": 1687983809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I am still a newbie. I have a python project where I am scraping data from some log files on a daily basis and cleaning it then pushing it to db. I have scheduled this project to run daily on windows task scheduler. Is there any other(better) way it can be scheduled on a windows system?", "author_fullname": "t2_1js9ugwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I schedule python ETL code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lu0dk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688009808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am still a newbie. I have a python project where I am scraping data from some log files on a daily basis and cleaning it then pushing it to db. I have scheduled this project to run daily on windows task scheduler. Is there any other(better) way it can be scheduled on a windows system?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lu0dk", "is_robot_indexable": true, "report_reasons": null, "author": "Rawvik", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lu0dk/how_can_i_schedule_python_etl_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lu0dk/how_can_i_schedule_python_etl_code/", "subreddit_subscribers": 112926, "created_utc": 1688009808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uypc8pwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring Graphs in Rust. Yikes.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_14lcciw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w7A3n7NOh83dDxukY5zsnG72JmKkQ6tJdlFr7s_UiSA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687965666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "confessionsofadataguy.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.confessionsofadataguy.com/exploring-graphs-in-rust-yikes/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?auto=webp&amp;v=enabled&amp;s=fda8c60d7a50945b57821af3599a39dd7a2311ce", "width": 1030, "height": 511}, "resolutions": [{"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e978f0e26b5253388ce5d2e091ddf9f8c72248a", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34a8c0dea0a4814284917b3628a2034aa3f221bd", "width": 216, "height": 107}, {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9e3586c3d359d92ef4ad3fdc9dc31e8a122f49a", "width": 320, "height": 158}, {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1fbdee8fa2883d6a099972a972e6c3fb586299f", "width": 640, "height": 317}, {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4546983493885ca9ff0ddea1e30868c4ca32b779", "width": 960, "height": 476}], "variants": {}, "id": "sB9wqRwDtNXITSnlZBdxKU18Nhco9x0ZHuKL_Jn4Y_s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14lcciw", "is_robot_indexable": true, "report_reasons": null, "author": "DarkClear3881", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lcciw/exploring_graphs_in_rust_yikes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.confessionsofadataguy.com/exploring-graphs-in-rust-yikes/", "subreddit_subscribers": 112926, "created_utc": 1687965666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vd2d51zd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udc49 New Awesome Polars release! What's new in the world of Polars in June 2023 ? Let's find out! \ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14la4y2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/gqtPViRGBsKIrIJLyK_hSIjXArCufvNmUE135m4TIC8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687960389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/ddotta/awesome-polars/releases/tag/2023-06-28", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?auto=webp&amp;v=enabled&amp;s=112b9d316153e774ab88765bc9f581c2b6a33feb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bae859fbf853259a52562afce9f36c9c5ea37068", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44f2d000933928749cf1e76e290388c1a64f2b88", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2c578d631f51a640c097e9893cee238f3a997c41", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1e8119a50a2d6aae203727ecbf3e07a742106bc", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28f9c60e425f5a482c13ef5ccf8c62c99277514f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c612bd2f8f22ab035d6fe28c1f79ae276f57be6a", "width": 1080, "height": 540}], "variants": {}, "id": "JLi9UEo1JLI2HplShAk-3FlVXxlreLI_Mw3YPTU9RTY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14la4y2", "is_robot_indexable": true, "report_reasons": null, "author": "damiendotta", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14la4y2/new_awesome_polars_release_whats_new_in_the_world/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/ddotta/awesome-polars/releases/tag/2023-06-28", "subreddit_subscribers": 112926, "created_utc": 1687960389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently a senior analyst/junior engineer.\n\nI\u2019ve built one pipeline using snowflake as a storage solution.\n\nShould I continue learning snowflake? Or should I learn databricks. (I\u2019m also looking to get certified in one or the other).", "author_fullname": "t2_602r7p43", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake or Databicks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l5wfj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687948330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a senior analyst/junior engineer.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve built one pipeline using snowflake as a storage solution.&lt;/p&gt;\n\n&lt;p&gt;Should I continue learning snowflake? Or should I learn databricks. (I\u2019m also looking to get certified in one or the other).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14l5wfj", "is_robot_indexable": true, "report_reasons": null, "author": "rolledthrough7578", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l5wfj/snowflake_or_databicks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l5wfj/snowflake_or_databicks/", "subreddit_subscribers": 112926, "created_utc": 1687948330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "These are all boiler plate concerns and just seeking an open dialogue on advice. \n\nI have worked at multiple startups as a data engineer and run successful data warehouses. I write and follow standards, procedures, and best practices. Typically ive worked solo or with one other person. I am proud of the data platforms I have created. \n\nI am starting a new project as a consultant next week with a well known billion dollar company that I cant disclose. Im a little nervous because my past projects have been significantly less data than in the past. I work with snowflake. What do I need to be prepared for when working at scale. I.e I previously have worked with fact tables 500k-1M rows, now will be working with MM and billion row tables. \n\nI consider myself good at optimizing queries and I hope the power of larger snowflake warehouses will be of assistance. I am the lead engineer on the project so want to be as ready as possible for the transition from a small warehouse to a large warehouse. \n\nAnything helps! Thanks!", "author_fullname": "t2_6iq3gwld9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First DE gig at large scale", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14lwjf0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688017626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;These are all boiler plate concerns and just seeking an open dialogue on advice. &lt;/p&gt;\n\n&lt;p&gt;I have worked at multiple startups as a data engineer and run successful data warehouses. I write and follow standards, procedures, and best practices. Typically ive worked solo or with one other person. I am proud of the data platforms I have created. &lt;/p&gt;\n\n&lt;p&gt;I am starting a new project as a consultant next week with a well known billion dollar company that I cant disclose. Im a little nervous because my past projects have been significantly less data than in the past. I work with snowflake. What do I need to be prepared for when working at scale. I.e I previously have worked with fact tables 500k-1M rows, now will be working with MM and billion row tables. &lt;/p&gt;\n\n&lt;p&gt;I consider myself good at optimizing queries and I hope the power of larger snowflake warehouses will be of assistance. I am the lead engineer on the project so want to be as ready as possible for the transition from a small warehouse to a large warehouse. &lt;/p&gt;\n\n&lt;p&gt;Anything helps! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14lwjf0", "is_robot_indexable": true, "report_reasons": null, "author": "ElephantCorrect2132", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lwjf0/first_de_gig_at_large_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lwjf0/first_de_gig_at_large_scale/", "subreddit_subscribers": 112926, "created_utc": 1688017626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you design to handle EndEffectiveDate in DV Sat tables or SCD type2?\n\nDo you run updates with incremental loads or calculate on the fly with LAG(), or other ways?\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you design to handle EndEffectiveDate in DV Sat tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lkktf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687985256.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687985043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you design to handle EndEffectiveDate in DV Sat tables or SCD type2?&lt;/p&gt;\n\n&lt;p&gt;Do you run updates with incremental loads or calculate on the fly with LAG(), or other ways?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lkktf", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lkktf/how_do_you_design_to_handle_endeffectivedate_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lkktf/how_do_you_design_to_handle_endeffectivedate_in/", "subreddit_subscribers": 112926, "created_utc": 1687985043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\n\nI am writing a query in dataflow lookup with schema name as a parameter.\nI have already created a schema_name parameter with $parameter_name with string default value.\nSo how should i write a below query in lookup.\nSelect * from $parameter_name.tablename\n\nI have tried-\nConcat(\u2018Select * from \u2019, $parameter_name,\n\u2018.tablename\u2019)\n\nThis is working, it is not able read the value of parameter.\n\nCan anyone help me with the solution.", "author_fullname": "t2_jrlp2tiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF parameters in SQL query -Urgent", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14letcn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687971436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;I am writing a query in dataflow lookup with schema name as a parameter.\nI have already created a schema_name parameter with $parameter_name with string default value.\nSo how should i write a below query in lookup.\nSelect * from $parameter_name.tablename&lt;/p&gt;\n\n&lt;p&gt;I have tried-\nConcat(\u2018Select * from \u2019, $parameter_name,\n\u2018.tablename\u2019)&lt;/p&gt;\n\n&lt;p&gt;This is working, it is not able read the value of parameter.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help me with the solution.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14letcn", "is_robot_indexable": true, "report_reasons": null, "author": "ProcedureScared2970", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14letcn/adf_parameters_in_sql_query_urgent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14letcn/adf_parameters_in_sql_query_urgent/", "subreddit_subscribers": 112926, "created_utc": 1687971436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When getting my career started (information technology BS degree with an emphasis on data/data systems). I got in with a smaller, somewhat new startup and had the opportunity of my life. I got to design a data warehouse from the ground up based on the source data, nothing more and no opinions,  using a very solid ERP system as my source. \n\nI created a very nice kimball model that fit the specs to a T (I still get reminded how good it is whenever I have to let my old boss know he's being used as a reference). \n\nAfter that I knew what my skill was and I moved on to keep building instead of creating reports/dashboards from my own design. The probablem is no one gives a F about scalability anyone. Sure it's always something talked about but as soon as you try to say something such as \"We are talking a lot about dataset C that is generated from dataset A and dataset B but as the engineer can someone start by defining dataset A Or B?\n\n...crickets. And then I ask, as someone new I have to ask, do you know what the error tolerance of our reports are?", "author_fullname": "t2_nw770", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone else really frustrated with the additional responsibilities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l93wo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1687958109.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687957762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When getting my career started (information technology BS degree with an emphasis on data/data systems). I got in with a smaller, somewhat new startup and had the opportunity of my life. I got to design a data warehouse from the ground up based on the source data, nothing more and no opinions,  using a very solid ERP system as my source. &lt;/p&gt;\n\n&lt;p&gt;I created a very nice kimball model that fit the specs to a T (I still get reminded how good it is whenever I have to let my old boss know he&amp;#39;s being used as a reference). &lt;/p&gt;\n\n&lt;p&gt;After that I knew what my skill was and I moved on to keep building instead of creating reports/dashboards from my own design. The probablem is no one gives a F about scalability anyone. Sure it&amp;#39;s always something talked about but as soon as you try to say something such as &amp;quot;We are talking a lot about dataset C that is generated from dataset A and dataset B but as the engineer can someone start by defining dataset A Or B?&lt;/p&gt;\n\n&lt;p&gt;...crickets. And then I ask, as someone new I have to ask, do you know what the error tolerance of our reports are?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14l93wo", "is_robot_indexable": true, "report_reasons": null, "author": "PeacefullyFighting", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l93wo/anyone_else_really_frustrated_with_the_additional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l93wo/anyone_else_really_frustrated_with_the_additional/", "subreddit_subscribers": 112926, "created_utc": 1687957762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are working on setting up our databricks environment (I\u2019m sure you\u2019ve seen my other posts) I am wondering how you guys use these \n\n- do you have one to many storage credentials to external locations or one to one? \n- do you specify external locations at the top most level of a bucket or to a folder hierarchy in the bucket? \n- how do external tables work with unity catalog? If I make a catalog/ schema with an external location, where is that catalog and schema?", "author_fullname": "t2_18qay50v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External tables, storage credentials, and Unity Catalog.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lqcqk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687999390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are working on setting up our databricks environment (I\u2019m sure you\u2019ve seen my other posts) I am wondering how you guys use these &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;do you have one to many storage credentials to external locations or one to one? &lt;/li&gt;\n&lt;li&gt;do you specify external locations at the top most level of a bucket or to a folder hierarchy in the bucket? &lt;/li&gt;\n&lt;li&gt;how do external tables work with unity catalog? If I make a catalog/ schema with an external location, where is that catalog and schema?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lqcqk", "is_robot_indexable": true, "report_reasons": null, "author": "Doyale_royale", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lqcqk/external_tables_storage_credentials_and_unity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lqcqk/external_tables_storage_credentials_and_unity/", "subreddit_subscribers": 112926, "created_utc": 1687999390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are my choices for working with data i.e. Data Engineering and ML/AI task on JAVA? \n\n&amp;#x200B;\n\nI know in Python there are many libraries/Frameworks choices Pandas(/numpy)/Polars/Dask/PySpark/Databricks depending on the size of data, type of system, on prem/cloud, project (webapp/edge device app) ect. For ML AI task again there are many options Scikit Learn, SparkML, Keras, ect. \n\n&amp;#x200B;\n\nAfter some googling and chatGPT prompts I didn't exactly find great results. I saw that many JAVA Frameworks that are used for ML task accept Tablesaw (Dataframes) i.e.DJL (Deep Java Library)\\\\DeepLearning4j\\\\Flink . However Tablesaw hasn't been updated since April 2022. I started looking at Spark on Java but had some trouble finding resources in Java. The resources I kept finding for spark ended up being for either Scala or Python. \n\n&amp;#x200B;\n\nAre there any good resources for data engineering and data science using JAVA. ", "author_fullname": "t2_h0k60d4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Java Data Engineering and Data Science Libraries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14licjh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687979786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are my choices for working with data i.e. Data Engineering and ML/AI task on JAVA? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know in Python there are many libraries/Frameworks choices Pandas(/numpy)/Polars/Dask/PySpark/Databricks depending on the size of data, type of system, on prem/cloud, project (webapp/edge device app) ect. For ML AI task again there are many options Scikit Learn, SparkML, Keras, ect. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;After some googling and chatGPT prompts I didn&amp;#39;t exactly find great results. I saw that many JAVA Frameworks that are used for ML task accept Tablesaw (Dataframes) i.e.DJL (Deep Java Library)\\DeepLearning4j\\Flink . However Tablesaw hasn&amp;#39;t been updated since April 2022. I started looking at Spark on Java but had some trouble finding resources in Java. The resources I kept finding for spark ended up being for either Scala or Python. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Are there any good resources for data engineering and data science using JAVA. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14licjh", "is_robot_indexable": true, "report_reasons": null, "author": "magu01", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14licjh/java_data_engineering_and_data_science_libraries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14licjh/java_data_engineering_and_data_science_libraries/", "subreddit_subscribers": 112926, "created_utc": 1687979786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good evening Gentleman and Ladies.\n\nI have an Internship that starts July 10th, this will be my first job ever.\n\nI want to get a head start.\n\n* Internship will involve **Reltio a master data maangement platform.**\n* I will be **learning to manage records**\n* With s**ql I will be managing/creating burn down list**\n* **Writing querys to target certain records.**\n\nMy questions are:\n\n1. What SQL Commands/Functions should I be really trying to Master to do this task?\n2. I don't know much about IT too be honest, what are some basic things I should know about to not look clueless.\n3. How can I get good at using Reltio?\n\nTo those who took the time to answer, thank you.", "author_fullname": "t2_htrki4x9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reltio and SQL for my first job ever.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lb7i0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687962987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good evening Gentleman and Ladies.&lt;/p&gt;\n\n&lt;p&gt;I have an Internship that starts July 10th, this will be my first job ever.&lt;/p&gt;\n\n&lt;p&gt;I want to get a head start.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Internship will involve &lt;strong&gt;Reltio a master data maangement platform.&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;I will be &lt;strong&gt;learning to manage records&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;With s&lt;strong&gt;ql I will be managing/creating burn down list&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Writing querys to target certain records.&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What SQL Commands/Functions should I be really trying to Master to do this task?&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t know much about IT too be honest, what are some basic things I should know about to not look clueless.&lt;/li&gt;\n&lt;li&gt;How can I get good at using Reltio?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;To those who took the time to answer, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lb7i0", "is_robot_indexable": true, "report_reasons": null, "author": "TophKatara", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lb7i0/reltio_and_sql_for_my_first_job_ever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lb7i0/reltio_and_sql_for_my_first_job_ever/", "subreddit_subscribers": 112926, "created_utc": 1687962987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello All,\nCan anyone help me in understanding whether migrating the delta lake tables as well as the storage account mounted to it will migrate all the data from the databricks or we need to also migrate the object storage which it creates for itself needs to be migrated as well ?\nAny help is highly appreciated.", "author_fullname": "t2_6dhjrj7u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrate Databricks Data across Tenant", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l2esp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687935987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,\nCan anyone help me in understanding whether migrating the delta lake tables as well as the storage account mounted to it will migrate all the data from the databricks or we need to also migrate the object storage which it creates for itself needs to be migrated as well ?\nAny help is highly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14l2esp", "is_robot_indexable": true, "report_reasons": null, "author": "Extra_Blacksmith_567", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l2esp/migrate_databricks_data_across_tenant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l2esp/migrate_databricks_data_across_tenant/", "subreddit_subscribers": 112926, "created_utc": 1687935987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering how do we decide on how often we schedule ETL job for delta extraction? What factors are to be considered?\n\nSay a workorder table record may have multiple changes happening within a day, scheduling ELT job hourly may bring in multiple records for same work order in DW vs nightly once run. So what are the guiding principles or business cases for a decision\n\nHow often your extraction jobs are run/scheduled at your company and how were they decided?\n\nAlso besides the business needs are there any technical reasons that influence scheduling?", "author_fullname": "t2_4ck30tok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you decide when to extract delta?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lo4ku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688010232.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687993523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering how do we decide on how often we schedule ETL job for delta extraction? What factors are to be considered?&lt;/p&gt;\n\n&lt;p&gt;Say a workorder table record may have multiple changes happening within a day, scheduling ELT job hourly may bring in multiple records for same work order in DW vs nightly once run. So what are the guiding principles or business cases for a decision&lt;/p&gt;\n\n&lt;p&gt;How often your extraction jobs are run/scheduled at your company and how were they decided?&lt;/p&gt;\n\n&lt;p&gt;Also besides the business needs are there any technical reasons that influence scheduling?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lo4ku", "is_robot_indexable": true, "report_reasons": null, "author": "Nomad4455", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lo4ku/how_do_you_decide_when_to_extract_delta/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lo4ku/how_do_you_decide_when_to_extract_delta/", "subreddit_subscribers": 112926, "created_utc": 1687993523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So my background is in MS SQL Server and SSIS mainly and I've never used Matillion before (not even seen it).  But I need to help someone else figure out what I think is an elementary problem.  Since they're not familiar with ETL at *all*, I've been promoted to the rank of Local Expert (*in the land of the blind*... and all that).\n\nHe* literally needs to do 2 things:\n\n* Append some new hardcoded and derived columns to the dataflow\n* Flatten some json (to map keys to destination table columns)\n\nBasic stuff, i feel, but could someone point my nose in the right direction?  Bonus points if you can translate it into SQL Server terms.\n\nIn SSIS land I'd chuck a derived column and a 3rd-party tool/c# script at the problem and get on with my life, but with Matillion I'm not sure what the equivalent is.  I've also heard a nasty rumour that Matillion ETL is conceptually more like ELT anyway so I realise there may not be direct equivalents of SSIS patterns.\n\nI'm sure I could find out the answer with enough googling but it would save us a bit of project time if we could crack this when he takes me through what he's trying to do tomorrow.\n\n*very aware this sounds like I'm \"asking for a friend\" but I really am... *as well as* asking for myself...", "author_fullname": "t2_w83n6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Basic Matillion question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lms2a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687990197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So my background is in MS SQL Server and SSIS mainly and I&amp;#39;ve never used Matillion before (not even seen it).  But I need to help someone else figure out what I think is an elementary problem.  Since they&amp;#39;re not familiar with ETL at &lt;em&gt;all&lt;/em&gt;, I&amp;#39;ve been promoted to the rank of Local Expert (&lt;em&gt;in the land of the blind&lt;/em&gt;... and all that).&lt;/p&gt;\n\n&lt;p&gt;He* literally needs to do 2 things:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Append some new hardcoded and derived columns to the dataflow&lt;/li&gt;\n&lt;li&gt;Flatten some json (to map keys to destination table columns)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Basic stuff, i feel, but could someone point my nose in the right direction?  Bonus points if you can translate it into SQL Server terms.&lt;/p&gt;\n\n&lt;p&gt;In SSIS land I&amp;#39;d chuck a derived column and a 3rd-party tool/c# script at the problem and get on with my life, but with Matillion I&amp;#39;m not sure what the equivalent is.  I&amp;#39;ve also heard a nasty rumour that Matillion ETL is conceptually more like ELT anyway so I realise there may not be direct equivalents of SSIS patterns.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure I could find out the answer with enough googling but it would save us a bit of project time if we could crack this when he takes me through what he&amp;#39;s trying to do tomorrow.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;very aware this sounds like I&amp;#39;m &amp;quot;asking for a friend&amp;quot; but I really am... *as well as&lt;/em&gt; asking for myself...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lms2a", "is_robot_indexable": true, "report_reasons": null, "author": "el_pedrodude", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lms2a/basic_matillion_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lms2a/basic_matillion_question/", "subreddit_subscribers": 112926, "created_utc": 1687990197.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}