{"kind": "Listing", "data": {"after": "t3_14ltc7b", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My 2-bay Synology NAS is almost full (2x4 TB - nothing compared to many here!).   Is there a 'sweet spot' for price vs capacity these days?  Current drives are WD Reds, still a good choice?  Or should I be looking at Seagate, others?\n\nThanks!", "author_fullname": "t2_fjjko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where's the current NAS HDD sweet spot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lhhdr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 164, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 164, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687977726.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My 2-bay Synology NAS is almost full (2x4 TB - nothing compared to many here!).   Is there a &amp;#39;sweet spot&amp;#39; for price vs capacity these days?  Current drives are WD Reds, still a good choice?  Or should I be looking at Seagate, others?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lhhdr", "is_robot_indexable": true, "report_reasons": null, "author": "YankeeATZ", "discussion_type": null, "num_comments": 92, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lhhdr/wheres_the_current_nas_hdd_sweet_spot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lhhdr/wheres_the_current_nas_hdd_sweet_spot/", "subreddit_subscribers": 690070, "created_utc": 1687977726.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm backing up a NAS with about 120 TB on Synology SMB shares over 10GbE to a SAS LTO8 drive (not an autoloader) which is on a Windows workstation.\n\nTL;DR is there a solution with a clearly organized UI that inspires confidence, and tape management with local file inventory?\n\nI did research here and elsewhere and here's the software I've tried so far:\n\n\\- **VEEAM**: Widely recommended but it turns out that it only supports a measly **500 GB** of data under the Community Edition and to do 120 TB it's several thousand dollars a year. It didn't disclose this until I had set everything up, catalogued my tapes and tried to run a backup at which point it failed with insufficient licenses. Their web site doesn't include this limitation in the comparison tables. The install is huge and the UI is terrible. It gave progress indication by file and by speed but in weird little sub panes that couldn't be properly resized. I gather the 500 GB thing is new, so people should stop recommending this.\n\n\\- **Acronis Cyber Protect Backup Advanced**: A test backup worked, but it's a wonky web UI and it doesn't give any information on the backup progress except percentage complete (no current file being backed up, no MBps average, etc.) There is no guidance in the app or their web site on how to organize tapes, merely to dump them into a pool. There are two **deal-breakers**: 1) When adding SMB shares to a backup it expands every directory and doesn't let you collapse the view, so once you add 8-10 shares the list is enormous and cannot be navigated. 2) If I try to backup a subdirectory off an SMB share there is a bug where the credentials fail, e.g. \"\\\\\\\\server\\\\share\" works but \"\\\\\\\\server\\\\share\\\\folder\" fails using the same credentials.\n\n\\- **EaseUS Todo Backup**: Says it supports tape but that feature appears to be missing, their support was clueless and they're a China based company.\n\nI looked at the **Bacula** site but their UI was incomprehensible and it seems designed for Linux with some CLI scripting either good to have or required. Not my cup of tea.\n\nI also checked out **Uranium Backup** and **Iperius Backup** but looking through their tutorials and documentation it doesn't appear that either app has any tape management/local file inventory whatsoever, they just use tape as a dumb backup destination only.\n\n&amp;#x200B;", "author_fullname": "t2_slqb6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Revisiting LTO tape backup software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lqufr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688000733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m backing up a NAS with about 120 TB on Synology SMB shares over 10GbE to a SAS LTO8 drive (not an autoloader) which is on a Windows workstation.&lt;/p&gt;\n\n&lt;p&gt;TL;DR is there a solution with a clearly organized UI that inspires confidence, and tape management with local file inventory?&lt;/p&gt;\n\n&lt;p&gt;I did research here and elsewhere and here&amp;#39;s the software I&amp;#39;ve tried so far:&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;VEEAM&lt;/strong&gt;: Widely recommended but it turns out that it only supports a measly &lt;strong&gt;500 GB&lt;/strong&gt; of data under the Community Edition and to do 120 TB it&amp;#39;s several thousand dollars a year. It didn&amp;#39;t disclose this until I had set everything up, catalogued my tapes and tried to run a backup at which point it failed with insufficient licenses. Their web site doesn&amp;#39;t include this limitation in the comparison tables. The install is huge and the UI is terrible. It gave progress indication by file and by speed but in weird little sub panes that couldn&amp;#39;t be properly resized. I gather the 500 GB thing is new, so people should stop recommending this.&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Acronis Cyber Protect Backup Advanced&lt;/strong&gt;: A test backup worked, but it&amp;#39;s a wonky web UI and it doesn&amp;#39;t give any information on the backup progress except percentage complete (no current file being backed up, no MBps average, etc.) There is no guidance in the app or their web site on how to organize tapes, merely to dump them into a pool. There are two &lt;strong&gt;deal-breakers&lt;/strong&gt;: 1) When adding SMB shares to a backup it expands every directory and doesn&amp;#39;t let you collapse the view, so once you add 8-10 shares the list is enormous and cannot be navigated. 2) If I try to backup a subdirectory off an SMB share there is a bug where the credentials fail, e.g. &amp;quot;\\\\server\\share&amp;quot; works but &amp;quot;\\\\server\\share\\folder&amp;quot; fails using the same credentials.&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;EaseUS Todo Backup&lt;/strong&gt;: Says it supports tape but that feature appears to be missing, their support was clueless and they&amp;#39;re a China based company.&lt;/p&gt;\n\n&lt;p&gt;I looked at the &lt;strong&gt;Bacula&lt;/strong&gt; site but their UI was incomprehensible and it seems designed for Linux with some CLI scripting either good to have or required. Not my cup of tea.&lt;/p&gt;\n\n&lt;p&gt;I also checked out &lt;strong&gt;Uranium Backup&lt;/strong&gt; and &lt;strong&gt;Iperius Backup&lt;/strong&gt; but looking through their tutorials and documentation it doesn&amp;#39;t appear that either app has any tape management/local file inventory whatsoever, they just use tape as a dumb backup destination only.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lqufr", "is_robot_indexable": true, "report_reasons": null, "author": "WonderSausage", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lqufr/revisiting_lto_tape_backup_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lqufr/revisiting_lto_tape_backup_software/", "subreddit_subscribers": 690070, "created_utc": 1688000733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A few months old 256 GB flash stick, with its USB3(connected 2 a desktop PC) &amp; USB-C ends, was burning hot (even had that odor/smell) from idling overnight!  Same for an older 512 GB USB2. I noticed both use aluminum/metal case type.\n\nDoes anyone else have this problem too? Thank you for reading and hopefully answering soon.", "author_fullname": "t2_4a27h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it me or do Sandisk USB flash sticks get too hot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lqr56", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688000502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few months old 256 GB flash stick, with its USB3(connected 2 a desktop PC) &amp;amp; USB-C ends, was burning hot (even had that odor/smell) from idling overnight!  Same for an older 512 GB USB2. I noticed both use aluminum/metal case type.&lt;/p&gt;\n\n&lt;p&gt;Does anyone else have this problem too? Thank you for reading and hopefully answering soon.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Where's the big floppy disk(ette) flair? :P", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lqr56", "is_robot_indexable": true, "report_reasons": null, "author": "antdude", "discussion_type": null, "num_comments": 12, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14lqr56/is_it_me_or_do_sandisk_usb_flash_sticks_get_too/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lqr56/is_it_me_or_do_sandisk_usb_flash_sticks_get_too/", "subreddit_subscribers": 690070, "created_utc": 1688000502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_5xe5d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stitcher (podcasting app/site) is being killed off by parent company Sirius XM, effective August 29th. Export your podcasts &amp; metadata while you can!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14m4smh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1688044621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "stitcher.helpshift.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://stitcher.helpshift.com/hc/en/1-stitcher/section/151-stitcher-farewell-1687885657/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "72TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m4smh", "is_robot_indexable": true, "report_reasons": null, "author": "AtmaJnana", "discussion_type": null, "num_comments": 7, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14m4smh/stitcher_podcasting_appsite_is_being_killed_off/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://stitcher.helpshift.com/hc/en/1-stitcher/section/151-stitcher-farewell-1687885657/", "subreddit_subscribers": 690070, "created_utc": 1688044621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, \nat work we use an older external website as a kind of wiki, a page that requires a login with we have. Now our IT department decided to modernize everything and at the end of the year the old page will be offline. The replacement really sucks so we decided to try to make some kind of backup of the page and its really helpful articles there.\n\nThe page itself looks like an older Wikipedia, along with links to older articles. Since it is an older page I tried to save the page via Browser and got a html file along with a folder, that contains a lot of .js files. I've opened the html and I could access the articles along with the links. But the problem now: the login itself - on my PC there should be a temporary session (probably cookie based?) active since my colleagues were asked for the password.\n\nAre there any tools around that can save a complete local copy and remove the login requirement afterwards (since after they put it offline out login would not work anymore)? Thank you for any ideas.", "author_fullname": "t2_1ei11v97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local offline backup of a Wiki-like homepage with login possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lugfs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688011156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, \nat work we use an older external website as a kind of wiki, a page that requires a login with we have. Now our IT department decided to modernize everything and at the end of the year the old page will be offline. The replacement really sucks so we decided to try to make some kind of backup of the page and its really helpful articles there.&lt;/p&gt;\n\n&lt;p&gt;The page itself looks like an older Wikipedia, along with links to older articles. Since it is an older page I tried to save the page via Browser and got a html file along with a folder, that contains a lot of .js files. I&amp;#39;ve opened the html and I could access the articles along with the links. But the problem now: the login itself - on my PC there should be a temporary session (probably cookie based?) active since my colleagues were asked for the password.&lt;/p&gt;\n\n&lt;p&gt;Are there any tools around that can save a complete local copy and remove the login requirement afterwards (since after they put it offline out login would not work anymore)? Thank you for any ideas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lugfs", "is_robot_indexable": true, "report_reasons": null, "author": "ChrisM243", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lugfs/local_offline_backup_of_a_wikilike_homepage_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lugfs/local_offline_backup_of_a_wikilike_homepage_with/", "subreddit_subscribers": 690070, "created_utc": 1688011156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Media files + ZFS/XFS + Samba + Windows Explorer + The magic setting that speeds things up!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lhn3o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "author_fullname": "t2_9ymyrd1f", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "PleX", "selftext": "So something that has been plaguing me has finally been resolved. Hopefully, this helps someone else in the future in Google search.\n\nIf you have a Linux machine (ZFS + Samba server) and you browse your media files on Windows (Samba client), you probably noticed how incredibly slow browsing folders with a large number of files is. I've been looking for a solution for months. \n\n(Edit: Apparently, this affects XFS filesystems also)\n\n# PROBLEMS:\n\n* Just opening the directory in Windows Explorer:\n   * 1,000 files/folders = around 10 seconds to load\n   * 10,000 files/folder = around 30+ seconds to load\n   * 50,000 files/folder = an eternity...\n* Intermittent slowing and pausing of network activity.\n   * You'll notice that when you're loading a directory, everything else stops because Samba is taking all the instruction bandwidth. For example, when you're encoding (Tdarr, Handbrake, etc.), the encoding will slow down or pause while you're trying to load a directory.\n* Fluctuating transfer speeds while an app is scanning a ZFS samba directory.\n* Very slow search of ZFS directories via Samba using Windows Search or UltraSearch Pro.\n* Applications like r/TinyMediaManager take forever to go through and scan your library. I created a separate NFS share for this reason, and it's 10x faster.\n\n&amp;#x200B;\n\n**After this fix, 10,000 files/folder loads instantly. And no more hogging the network bandwidth. The searching/loading speed is close to NFS.**\n\nI had no idea this was related to ZFS. I've only been looking for answers to Samba in relation to Linux and Windows. It finally clicked for me that it had to do with ZFS when I shared a folder that wasn't a ZFS drive with 10,000+ folders.\n\n&amp;#x200B;\n\n# SOLUTION: Add this to your /etc/samba/smb.conf\n\n    store dos attributes = no \n    ea support = no \n    map archive = no \n    map hidden = no \n    map system = no \n    map readonly = no\n\nIf you want to read more about why this solution works, just google \"disabling dos attributes on samba,\" or you can [go here,](https://www.truenas.com/community/threads/cifs-directory-browsing-slow-try-this.27751/) where I found the solution (and that post is several years old!!!). Other solutions I've seen is to use NFS, but that has its own set of problems. Or to subdivide directories by the first letter like /B/Braveheart/Braveheart.mkv \u2014 which is not very good for Plex at all. And it only makes it \"easier\" to browse files. It doesn't fix the other problems. Also don't think that installing a 10gbe network will solve this as I did... it doesn't lol", "author_fullname": "t2_9ymyrd1f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Media files + ZFS + Samba + Windows Explorer + The magic setting that speeds things up!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/PleX", "hidden": false, "pwls": 6, "link_flair_css_class": "tips", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14kqixq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": "#d3d6da", "subreddit_type": "public", "ups": 52, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "5e1da282-e6a3-11e7-ae90-0e38a789ce1c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tips", "can_mod_post": false, "score": 52, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687977574.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687902228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.PleX", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So something that has been plaguing me has finally been resolved. Hopefully, this helps someone else in the future in Google search.&lt;/p&gt;\n\n&lt;p&gt;If you have a Linux machine (ZFS + Samba server) and you browse your media files on Windows (Samba client), you probably noticed how incredibly slow browsing folders with a large number of files is. I&amp;#39;ve been looking for a solution for months. &lt;/p&gt;\n\n&lt;p&gt;(Edit: Apparently, this affects XFS filesystems also)&lt;/p&gt;\n\n&lt;h1&gt;PROBLEMS:&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Just opening the directory in Windows Explorer:\n\n&lt;ul&gt;\n&lt;li&gt;1,000 files/folders = around 10 seconds to load&lt;/li&gt;\n&lt;li&gt;10,000 files/folder = around 30+ seconds to load&lt;/li&gt;\n&lt;li&gt;50,000 files/folder = an eternity...&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Intermittent slowing and pausing of network activity.\n\n&lt;ul&gt;\n&lt;li&gt;You&amp;#39;ll notice that when you&amp;#39;re loading a directory, everything else stops because Samba is taking all the instruction bandwidth. For example, when you&amp;#39;re encoding (Tdarr, Handbrake, etc.), the encoding will slow down or pause while you&amp;#39;re trying to load a directory.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Fluctuating transfer speeds while an app is scanning a ZFS samba directory.&lt;/li&gt;\n&lt;li&gt;Very slow search of ZFS directories via Samba using Windows Search or UltraSearch Pro.&lt;/li&gt;\n&lt;li&gt;Applications like &lt;a href=\"/r/TinyMediaManager\"&gt;r/TinyMediaManager&lt;/a&gt; take forever to go through and scan your library. I created a separate NFS share for this reason, and it&amp;#39;s 10x faster.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;After this fix, 10,000 files/folder loads instantly. And no more hogging the network bandwidth. The searching/loading speed is close to NFS.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I had no idea this was related to ZFS. I&amp;#39;ve only been looking for answers to Samba in relation to Linux and Windows. It finally clicked for me that it had to do with ZFS when I shared a folder that wasn&amp;#39;t a ZFS drive with 10,000+ folders.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h1&gt;SOLUTION: Add this to your /etc/samba/smb.conf&lt;/h1&gt;\n\n&lt;pre&gt;&lt;code&gt;store dos attributes = no \nea support = no \nmap archive = no \nmap hidden = no \nmap system = no \nmap readonly = no\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;If you want to read more about why this solution works, just google &amp;quot;disabling dos attributes on samba,&amp;quot; or you can &lt;a href=\"https://www.truenas.com/community/threads/cifs-directory-browsing-slow-try-this.27751/\"&gt;go here,&lt;/a&gt; where I found the solution (and that post is several years old!!!). Other solutions I&amp;#39;ve seen is to use NFS, but that has its own set of problems. Or to subdivide directories by the first letter like /B/Braveheart/Braveheart.mkv \u2014 which is not very good for Plex at all. And it only makes it &amp;quot;easier&amp;quot; to browse files. It doesn&amp;#39;t fix the other problems. Also don&amp;#39;t think that installing a 10gbe network will solve this as I did... it doesn&amp;#39;t lol&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ac1f62e2-409a-11e5-a180-0ec131dbf691", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "400TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2ql7e", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0a7bff", "id": "14kqixq", "is_robot_indexable": true, "report_reasons": null, "author": "Fit-Arugula-1592", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/PleX/comments/14kqixq/media_files_zfs_samba_windows_explorer_the_magic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/PleX/comments/14kqixq/media_files_zfs_samba_windows_explorer_the_magic/", "subreddit_subscribers": 261320, "created_utc": 1687902228.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1687978113.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.PleX", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/PleX/comments/14kqixq/media_files_zfs_samba_windows_explorer_the_magic/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "400TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14lhn3o", "is_robot_indexable": true, "report_reasons": null, "author": "Fit-Arugula-1592", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_14kqixq", "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14lhn3o/media_files_zfsxfs_samba_windows_explorer_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/PleX/comments/14kqixq/media_files_zfs_samba_windows_explorer_the_magic/", "subreddit_subscribers": 690070, "created_utc": 1687978113.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If I don\u2019t know the actual link to something, is it possible to search for something in the way back machine? Like if I was trying to search a certain strategy for Factorio, for example.", "author_fullname": "t2_7h9f6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can we search through the new Reddit archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lceap", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687965779.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I don\u2019t know the actual link to something, is it possible to search for something in the way back machine? Like if I was trying to search a certain strategy for Factorio, for example.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lceap", "is_robot_indexable": true, "report_reasons": null, "author": "Hockeygoalie35", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lceap/how_can_we_search_through_the_new_reddit_archive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lceap/how_can_we_search_through_the_new_reddit_archive/", "subreddit_subscribers": 690070, "created_utc": 1687965779.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI'm trying to save files from a telegram Channel that has download/transfer disabled.\nI tried it on android, and found those files. I also know that there's an extension that brings back the save button on a web browser.\nBut it's just too many files for me to have on my phone then transfer to pc. And going one by one on browser is not viable either.\nI tried to look for it in the desktop versions files, but I only find what a bunch is a bunch of folders named in 2 random characters (letters or numbers) containing a few extensionless files named with random characters. (Found in tdata\\user_data\\media_cache). \nI'm guessing it's some kind of hash file system used by telegram.", "author_fullname": "t2_r3ui1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to save telegram protected files on desktop'", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lld29", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687986866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to save files from a telegram Channel that has download/transfer disabled.\nI tried it on android, and found those files. I also know that there&amp;#39;s an extension that brings back the save button on a web browser.\nBut it&amp;#39;s just too many files for me to have on my phone then transfer to pc. And going one by one on browser is not viable either.\nI tried to look for it in the desktop versions files, but I only find what a bunch is a bunch of folders named in 2 random characters (letters or numbers) containing a few extensionless files named with random characters. (Found in tdata\\user_data\\media_cache). \nI&amp;#39;m guessing it&amp;#39;s some kind of hash file system used by telegram.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lld29", "is_robot_indexable": true, "report_reasons": null, "author": "TheArtofWarPIGEON", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lld29/how_to_save_telegram_protected_files_on_desktop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lld29/how_to_save_telegram_protected_files_on_desktop/", "subreddit_subscribers": 690070, "created_utc": 1687986866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Was looking at NAS boxes, 6 bay and the Asustor AS6706T caught my eye as it is available directly and seems pretty decent. The Synology ones are on back order. But has anyone here used this? I see usually people recommend Synology.\n\nWas gonna go with 6x16TB disks.", "author_fullname": "t2_10fiz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody used the Asustor AS6706T? maybe looking at getting one", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lfkmx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687973230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was looking at NAS boxes, 6 bay and the Asustor AS6706T caught my eye as it is available directly and seems pretty decent. The Synology ones are on back order. But has anyone here used this? I see usually people recommend Synology.&lt;/p&gt;\n\n&lt;p&gt;Was gonna go with 6x16TB disks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lfkmx", "is_robot_indexable": true, "report_reasons": null, "author": "Boogertwilliams", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lfkmx/anybody_used_the_asustor_as6706t_maybe_looking_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lfkmx/anybody_used_the_asustor_as6706t_maybe_looking_at/", "subreddit_subscribers": 690070, "created_utc": 1687973230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Since tape/lto is slow but huge capacity, and flash/ssd is fast but have smaller capacity (at least more expensive), is there SSD+Tape hybrid drive? so the filesystem (which file on which position on the tape) stored on SSD for fast listing, but the data itself stored on tape?", "author_fullname": "t2_7bbojdkz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there ssd+tape hybrid drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m21td", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688036585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since tape/lto is slow but huge capacity, and flash/ssd is fast but have smaller capacity (at least more expensive), is there SSD+Tape hybrid drive? so the filesystem (which file on which position on the tape) stored on SSD for fast listing, but the data itself stored on tape?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m21td", "is_robot_indexable": true, "report_reasons": null, "author": "kokizzu2", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m21td/is_there_ssdtape_hybrid_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m21td/is_there_ssdtape_hybrid_drive/", "subreddit_subscribers": 690070, "created_utc": 1688036585.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So there's this game, called Block World. I found this address that may be the place where it originated: [https://html5.gamemonetize.co/ztj2w5e5pdnhdomxkoufe27b35sk1ng1/](https://html5.gamemonetize.co/ztj2w5e5pdnhdomxkoufe27b35sk1ng1/). I have downloaded all of that website's files, but there were none that are the game's actual code and it's assets. Does anyone know how can i download its files so i can run it locally on my pc?\n\n[\\(if this is the wrong subreddit please redirect me. Thanks\\)](https://preview.redd.it/zga6v41f5t8b1.png?width=799&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ab170a5f5f84c1b56e0eb0dc97fbf0470db09eae)", "author_fullname": "t2_75arolm6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unity WebGL game download help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 104, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zga6v41f5t8b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 80, "x": 108, "u": "https://preview.redd.it/zga6v41f5t8b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c8c49b20a1fec0b626b99778915a99a23ec321e"}, {"y": 161, "x": 216, "u": "https://preview.redd.it/zga6v41f5t8b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=883c8d0842d83c839766b548079451f8d9793002"}, {"y": 238, "x": 320, "u": "https://preview.redd.it/zga6v41f5t8b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=98c58ff5833c4a901cd9a8b6bcc82f0515546847"}, {"y": 477, "x": 640, "u": "https://preview.redd.it/zga6v41f5t8b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e49bd8e70db3324f147c9299d727c45200f62d1b"}], "s": {"y": 596, "x": 799, "u": "https://preview.redd.it/zga6v41f5t8b1.png?width=799&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=ab170a5f5f84c1b56e0eb0dc97fbf0470db09eae"}, "id": "zga6v41f5t8b1"}}, "name": "t3_14li9jy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/mn3c98K9x_tPz2bZFeoertA7mRS66HAUzWtY-c8z9qc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687979578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So there&amp;#39;s this game, called Block World. I found this address that may be the place where it originated: &lt;a href=\"https://html5.gamemonetize.co/ztj2w5e5pdnhdomxkoufe27b35sk1ng1/\"&gt;https://html5.gamemonetize.co/ztj2w5e5pdnhdomxkoufe27b35sk1ng1/&lt;/a&gt;. I have downloaded all of that website&amp;#39;s files, but there were none that are the game&amp;#39;s actual code and it&amp;#39;s assets. Does anyone know how can i download its files so i can run it locally on my pc?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zga6v41f5t8b1.png?width=799&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=ab170a5f5f84c1b56e0eb0dc97fbf0470db09eae\"&gt;(if this is the wrong subreddit please redirect me. Thanks)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14li9jy", "is_robot_indexable": true, "report_reasons": null, "author": "BlockScientist7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14li9jy/unity_webgl_game_download_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14li9jy/unity_webgl_game_download_help/", "subreddit_subscribers": 690070, "created_utc": 1687979578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Has anyone switched to ShareFile since Google Workspace cutoff their unlimited storage? I am using rclone to mount a google drive for storage but its over its limit and I need another option. It looks like ShareFile is supported by rclone and offers a $50 monthly plan the is unlimited. Thoughts? \n\nPS: I know about Dropbox Advanced as well", "author_fullname": "t2_2ogh45xc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ShareFile to replace Google Workspace?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lg75h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687974728.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone switched to ShareFile since Google Workspace cutoff their unlimited storage? I am using rclone to mount a google drive for storage but its over its limit and I need another option. It looks like ShareFile is supported by rclone and offers a $50 monthly plan the is unlimited. Thoughts? &lt;/p&gt;\n\n&lt;p&gt;PS: I know about Dropbox Advanced as well&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lg75h", "is_robot_indexable": true, "report_reasons": null, "author": "IkeTaylor11", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lg75h/sharefile_to_replace_google_workspace/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lg75h/sharefile_to_replace_google_workspace/", "subreddit_subscribers": 690070, "created_utc": 1687974728.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone know if the IoSafe Duo fire proof DAS units support reading SMART data (when using JBOD)?  Also do they support the UASP protocol?  Haven't been able to find this info anywhere yet.", "author_fullname": "t2_mgmtm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does IoSafe Duo Support SMART and UASP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lfrfk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687973685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone know if the IoSafe Duo fire proof DAS units support reading SMART data (when using JBOD)?  Also do they support the UASP protocol?  Haven&amp;#39;t been able to find this info anywhere yet.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lfrfk", "is_robot_indexable": true, "report_reasons": null, "author": "HarryMuscle", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lfrfk/does_iosafe_duo_support_smart_and_uasp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lfrfk/does_iosafe_duo_support_smart_and_uasp/", "subreddit_subscribers": 690070, "created_utc": 1687973685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I am looking for some recommendations on an external drive bay enclosure. I currently have 9 Best Buy easy store drives connected to my Mac mini via usbc hubs renting from 8tb to 18tbs. I would like to shuck them and combine them into one enclosure so that can be read as one drive instead of 9.  Current use is for plex media management. The Mac mini acts as the plex server with hardware transcoding so I don\u2019t think I need a nas. I am not worried about data recovery so I think I would use a raid 0 type set-up. Happy to answer any questions!", "author_fullname": "t2_y1dt8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for recommendation for external drive bay", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14m5bpl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688046011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am looking for some recommendations on an external drive bay enclosure. I currently have 9 Best Buy easy store drives connected to my Mac mini via usbc hubs renting from 8tb to 18tbs. I would like to shuck them and combine them into one enclosure so that can be read as one drive instead of 9.  Current use is for plex media management. The Mac mini acts as the plex server with hardware transcoding so I don\u2019t think I need a nas. I am not worried about data recovery so I think I would use a raid 0 type set-up. Happy to answer any questions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m5bpl", "is_robot_indexable": true, "report_reasons": null, "author": "mprice06", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m5bpl/looking_for_recommendation_for_external_drive_bay/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m5bpl/looking_for_recommendation_for_external_drive_bay/", "subreddit_subscribers": 690070, "created_utc": 1688046011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_16oo8k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lewtwo has just archived the whole Pok\u00e9mon Shirts company's work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": true, "name": "t3_14m4s0h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;In June 2023, the Pok\u00e9mon Shirts company announced their complete shutdown.&lt;br&gt;&lt;br&gt;here&amp;#39;s how we archived the entire company&amp;#39;s work in just six hours. \ud83e\uddf5 &lt;a href=\"https://t.co/TMI03xXm7j\"&gt;pic.twitter.com/TMI03xXm7j&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lewtwo (@Lewchube) &lt;a href=\"https://twitter.com/Lewchube/status/1674402577939677185?ref_src=twsrc%5Etfw\"&gt;June 29, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/Lewchube/status/1674402577939677185", "author_name": "Lewtwo", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;In June 2023, the Pok\u00e9mon Shirts company announced their complete shutdown.&lt;br&gt;&lt;br&gt;here&amp;#39;s how we archived the entire company&amp;#39;s work in just six hours. \ud83e\uddf5 &lt;a href=\"https://t.co/TMI03xXm7j\"&gt;pic.twitter.com/TMI03xXm7j&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lewtwo (@Lewchube) &lt;a href=\"https://twitter.com/Lewchube/status/1674402577939677185?ref_src=twsrc%5Etfw\"&gt;June 29, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/Lewchube", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;In June 2023, the Pok\u00e9mon Shirts company announced their complete shutdown.&lt;br&gt;&lt;br&gt;here&amp;#39;s how we archived the entire company&amp;#39;s work in just six hours. \ud83e\uddf5 &lt;a href=\"https://t.co/TMI03xXm7j\"&gt;pic.twitter.com/TMI03xXm7j&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lewtwo (@Lewchube) &lt;a href=\"https://twitter.com/Lewchube/status/1674402577939677185?ref_src=twsrc%5Etfw\"&gt;June 29, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/14m4s0h", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/n6EIIVzMke_b9eQpPlCC17G8xLKqGMAXmD75tX2DYcU.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688044573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/Lewchube/status/1674402577939677185", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/m1O7vvsd8OoiAahWfVzVQ-yTDAtjmeiGUttqHVJ1kdI.jpg?auto=webp&amp;v=enabled&amp;s=ac87403ae71983e94b8a2bb2a0218a1168d1c672", "width": 140, "height": 97}, "resolutions": [{"url": "https://external-preview.redd.it/m1O7vvsd8OoiAahWfVzVQ-yTDAtjmeiGUttqHVJ1kdI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=991797453b50a8378ef02f707ff6ac4ca2e63225", "width": 108, "height": 74}], "variants": {}, "id": "tQIa1crPnmfmzCXF4JFHargl7PN717JzBb7IfKFUAAw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "42 TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14m4s0h", "is_robot_indexable": true, "report_reasons": null, "author": "DarthJahus", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14m4s0h/lewtwo_has_just_archived_the_whole_pok\u00e9mon_shirts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/Lewchube/status/1674402577939677185", "subreddit_subscribers": 690070, "created_utc": 1688044573.0, "num_crossposts": 0, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/Lewchube/status/1674402577939677185", "author_name": "Lewtwo", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;In June 2023, the Pok\u00e9mon Shirts company announced their complete shutdown.&lt;br&gt;&lt;br&gt;here&amp;#39;s how we archived the entire company&amp;#39;s work in just six hours. \ud83e\uddf5 &lt;a href=\"https://t.co/TMI03xXm7j\"&gt;pic.twitter.com/TMI03xXm7j&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lewtwo (@Lewchube) &lt;a href=\"https://twitter.com/Lewchube/status/1674402577939677185?ref_src=twsrc%5Etfw\"&gt;June 29, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/Lewchube", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "On my windowa laptop i use Wincatalog for cataloguing external hard disks. But on my mac book I have not found any good software so far for this. Please suggest. If it is cheap or free it would be bonus. But dont have a problem paying for a really good software.", "author_fullname": "t2_8x9iq4z6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mac Software for Cataloguing External Hard Disks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14m3zge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688042405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On my windowa laptop i use Wincatalog for cataloguing external hard disks. But on my mac book I have not found any good software so far for this. Please suggest. If it is cheap or free it would be bonus. But dont have a problem paying for a really good software.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m3zge", "is_robot_indexable": true, "report_reasons": null, "author": "general_smooth", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m3zge/mac_software_for_cataloguing_external_hard_disks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m3zge/mac_software_for_cataloguing_external_hard_disks/", "subreddit_subscribers": 690070, "created_utc": 1688042405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I came down with some kind of disease (it's still ongoing) where I scrubbed the marketplace on low hours, low on/off count 4TB HDDs. I currently have 5, with no signs of slowing down. They were mostly WD Purples and nighthawks (I know... but they were 36 bucks)\n\nI'm planning on deploying them on a trunas scale machine, just for general NAS usage and media center (with some HDD being offline backups of important files). Nothing high-performance (I only have gigabit ethernet, old dualcore machine) But I can't seem to find any guide on the pre-deployment process. Like what kind of diagnostics to do, what programs to use, best practices, what to look for, is it even worth it spending days diagnosing, etc. Right now I'm only relying on crystaldiskinfo which is really not in-depth.\n\nAny inputs would help tremendously. Hoping it can prevent some headaches I might encounter in the future had I not done them today. Thanks a lot! Happy hunting!", "author_fullname": "t2_1jo7anhj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a general guide/steps before deploying (used) HDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m1yz0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688036368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came down with some kind of disease (it&amp;#39;s still ongoing) where I scrubbed the marketplace on low hours, low on/off count 4TB HDDs. I currently have 5, with no signs of slowing down. They were mostly WD Purples and nighthawks (I know... but they were 36 bucks)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on deploying them on a trunas scale machine, just for general NAS usage and media center (with some HDD being offline backups of important files). Nothing high-performance (I only have gigabit ethernet, old dualcore machine) But I can&amp;#39;t seem to find any guide on the pre-deployment process. Like what kind of diagnostics to do, what programs to use, best practices, what to look for, is it even worth it spending days diagnosing, etc. Right now I&amp;#39;m only relying on crystaldiskinfo which is really not in-depth.&lt;/p&gt;\n\n&lt;p&gt;Any inputs would help tremendously. Hoping it can prevent some headaches I might encounter in the future had I not done them today. Thanks a lot! Happy hunting!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m1yz0", "is_robot_indexable": true, "report_reasons": null, "author": "rsnst", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m1yz0/looking_for_a_general_guidesteps_before_deploying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m1yz0/looking_for_a_general_guidesteps_before_deploying/", "subreddit_subscribers": 690070, "created_utc": 1688036368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am planning to build a NAS using a Pi4 running Rasbian light.\n\nI know I have different options, open media vault, FileCloud and NextCloud.\n\nMy main purpose is to back up photos automatically from the camera roll on iPhones, similar to Google photos.\n\nDo all three solutions support this? Which one has the better iOS app?\nThe setup will be super basic, I will just be mounting a 4tb hard drive to my Pi. \n \nThank you :-)", "author_fullname": "t2_ld9gl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best iOS photo backup on a Raspberry pi?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m1y0v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688036277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning to build a NAS using a Pi4 running Rasbian light.&lt;/p&gt;\n\n&lt;p&gt;I know I have different options, open media vault, FileCloud and NextCloud.&lt;/p&gt;\n\n&lt;p&gt;My main purpose is to back up photos automatically from the camera roll on iPhones, similar to Google photos.&lt;/p&gt;\n\n&lt;p&gt;Do all three solutions support this? Which one has the better iOS app?\nThe setup will be super basic, I will just be mounting a 4tb hard drive to my Pi. &lt;/p&gt;\n\n&lt;p&gt;Thank you :-)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m1y0v", "is_robot_indexable": true, "report_reasons": null, "author": "AlexKLMan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m1y0v/best_ios_photo_backup_on_a_raspberry_pi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m1y0v/best_ios_photo_backup_on_a_raspberry_pi/", "subreddit_subscribers": 690070, "created_utc": 1688036277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am in the process of ripping my dads CD collection wit EAC as mentioned in another post on this sub.   \n\n\nI would like to take the root folder and run it through a tool to fill in the metadata as well as embed the cover artwork, so when I play it via VLC on my chromecast, it displays both the artwork and the proper title and author.  \n\n\nIf it is any help I have the following folder structure:\n\n    CDs\n    \u251c\u2500\u2500 Album 1\n    \u2502   \u251c\u2500\u2500 Song 1.wav\n    \u2502   \u251c\u2500\u2500 Song 2.wav\n    \u2502   \u2514\u2500\u2500 Song 3.wav\n    \u251c\u2500\u2500 Album 2\n    \u2502   \u251c\u2500\u2500 Song 1.wav\n    \u2502   \u251c\u2500\u2500 Song 2.wav\n    \u2502   \u2514\u2500\u2500 Song 3.wav\n    \u2514\u2500\u2500 Album 3\n        \u251c\u2500\u2500 Song 1.wav\n        \u251c\u2500\u2500 Song 2.wav\n        \u2514\u2500\u2500 Song 3.wav\n\n&amp;#x200B;", "author_fullname": "t2_3umnofow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A way to get CD metadata and artwork", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m10d1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688033110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am in the process of ripping my dads CD collection wit EAC as mentioned in another post on this sub.   &lt;/p&gt;\n\n&lt;p&gt;I would like to take the root folder and run it through a tool to fill in the metadata as well as embed the cover artwork, so when I play it via VLC on my chromecast, it displays both the artwork and the proper title and author.  &lt;/p&gt;\n\n&lt;p&gt;If it is any help I have the following folder structure:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CDs\n\u251c\u2500\u2500 Album 1\n\u2502   \u251c\u2500\u2500 Song 1.wav\n\u2502   \u251c\u2500\u2500 Song 2.wav\n\u2502   \u2514\u2500\u2500 Song 3.wav\n\u251c\u2500\u2500 Album 2\n\u2502   \u251c\u2500\u2500 Song 1.wav\n\u2502   \u251c\u2500\u2500 Song 2.wav\n\u2502   \u2514\u2500\u2500 Song 3.wav\n\u2514\u2500\u2500 Album 3\n    \u251c\u2500\u2500 Song 1.wav\n    \u251c\u2500\u2500 Song 2.wav\n    \u2514\u2500\u2500 Song 3.wav\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m10d1", "is_robot_indexable": true, "report_reasons": null, "author": "Arimodu", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m10d1/a_way_to_get_cd_metadata_and_artwork/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m10d1/a_way_to_get_cd_metadata_and_artwork/", "subreddit_subscribers": 690070, "created_utc": 1688033110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All,\n\nSo I have a Samsung 970Evo Plus less than a year old that started to fail.  I have a stable workstation since more than year and I recently added a rtx3090 for ML/Cuda work. Then by chance I noticed some failures on a btrfs partition that was not recognized anymore.\n\nI rebooted to a rescue session and I could confirm btrfs filesystem check errors. On this disk I have 3 btrfs partitions. One does not mount anymore and the two others have errors but still mounting. On the kernel messages I can clearly see the I/O errors during fs check. \n\nI turned off the system  until receiving a replacement disk. However I want to know what was the most likely reason for this ? \n\n1. I struggled a bit when I mounted the graphic card and probably physically touched this nvme disk but nothing extreme. Could it be due to shock ?\n\n2. The GPU was mounted on a PCIe slot right over this nvme slot which basically fully covered it. Could it be due to the heat ? \n\nIn any case I will probably change the GPU location far from the nvme slots but am curious what is the most probable reason ?\n\nEDIT:\n\nsince I was using this disk for the linux system using a btrfs partition + separate boot UEFI partition, my plan for replacing the new one was the following:\n\n- Clone the whole disk using Clonezilla \n- Then do an other `btrfs replace` on the btrfs partitions than can be mounted from old to new.\n- than try a btrfs recovery on the cloned but non mountable broken btrfs partition\n\n\nIs this a good strategy ?", "author_fullname": "t2_dm4m2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "nvme hw failures after installing GPU right over it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lz83z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688046132.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688026945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;So I have a Samsung 970Evo Plus less than a year old that started to fail.  I have a stable workstation since more than year and I recently added a rtx3090 for ML/Cuda work. Then by chance I noticed some failures on a btrfs partition that was not recognized anymore.&lt;/p&gt;\n\n&lt;p&gt;I rebooted to a rescue session and I could confirm btrfs filesystem check errors. On this disk I have 3 btrfs partitions. One does not mount anymore and the two others have errors but still mounting. On the kernel messages I can clearly see the I/O errors during fs check. &lt;/p&gt;\n\n&lt;p&gt;I turned off the system  until receiving a replacement disk. However I want to know what was the most likely reason for this ? &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I struggled a bit when I mounted the graphic card and probably physically touched this nvme disk but nothing extreme. Could it be due to shock ?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The GPU was mounted on a PCIe slot right over this nvme slot which basically fully covered it. Could it be due to the heat ? &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;In any case I will probably change the GPU location far from the nvme slots but am curious what is the most probable reason ?&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;since I was using this disk for the linux system using a btrfs partition + separate boot UEFI partition, my plan for replacing the new one was the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Clone the whole disk using Clonezilla &lt;/li&gt;\n&lt;li&gt;Then do an other &lt;code&gt;btrfs replace&lt;/code&gt; on the btrfs partitions than can be mounted from old to new.&lt;/li&gt;\n&lt;li&gt;than try a btrfs recovery on the cloned but non mountable broken btrfs partition&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is this a good strategy ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lz83z", "is_robot_indexable": true, "report_reasons": null, "author": "use_your_imagination", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lz83z/nvme_hw_failures_after_installing_gpu_right_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lz83z/nvme_hw_failures_after_installing_gpu_right_over/", "subreddit_subscribers": 690070, "created_utc": 1688026945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey, so, I'm trying to compile a database of different types of repair shops for my state from a google maps search. I tried octoparse and scrapstorm but both required a membership to export. Looking for options that don't. ", "author_fullname": "t2_bzpr9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good free scraper?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lvyz2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688015815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, so, I&amp;#39;m trying to compile a database of different types of repair shops for my state from a google maps search. I tried octoparse and scrapstorm but both required a membership to export. Looking for options that don&amp;#39;t. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lvyz2", "is_robot_indexable": true, "report_reasons": null, "author": "heather-gray", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lvyz2/good_free_scraper/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lvyz2/good_free_scraper/", "subreddit_subscribers": 690070, "created_utc": 1688015815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_hbwoyw04", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I hate so much the fact that it's so complicated to know if it's an SMR or CMR drive, can you help me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14lkxqh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wn8k0DT06YS1KSXZ48t8QRY7U-mqp4vjXqQmol91hEU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687985892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "serverpartdeals.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://serverpartdeals.com/collections/hard-drives/products/seagate-exos-x22-st22000nm001e-3hm103-001-22tb-7-2k-rpm-sata-6gb-s-512e-3-5-recertified-hard-drive", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?auto=webp&amp;v=enabled&amp;s=1bec9f5e789e131b4d3063b2708b4de7c92ef0f4", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd945ca82a48b834144e1604904e1dbb54e660aa", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72f934f9a2ff494d22e5ea3dfc3b95401de4eaf5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=defe19f6d9e7fccb6270b79abdedd031f0b52588", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a99f342ffc6db007cecf8edba49702207c42dcce", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f0c071e64fd0f6f03e1b333789cb856be245b10", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88d63dece55ac3ec31e972fa2ed63c4a5f27671c", "width": 1080, "height": 1080}], "variants": {}, "id": "3ccPDPuPGsR3ww0JLnwJyAFLMYAJgaaJqsmBa3t1Dj8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lkxqh", "is_robot_indexable": true, "report_reasons": null, "author": "igmyeongui", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lkxqh/i_hate_so_much_the_fact_that_its_so_complicated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://serverpartdeals.com/collections/hard-drives/products/seagate-exos-x22-st22000nm001e-3hm103-001-22tb-7-2k-rpm-sata-6gb-s-512e-3-5-recertified-hard-drive", "subreddit_subscribers": 690070, "created_utc": 1687985892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm confused.\n\nHow is this so cheap? Less than 0.25 cents per gb / month? Is this forever?", "author_fullname": "t2_42ctn8f3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is IDrive 100gb, $2.95/year , every year? Or only the 1st one.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ldad6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687967913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m confused.&lt;/p&gt;\n\n&lt;p&gt;How is this so cheap? Less than 0.25 cents per gb / month? Is this forever?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14ldad6", "is_robot_indexable": true, "report_reasons": null, "author": "Trainer_Red99", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14ldad6/is_idrive_100gb_295year_every_year_or_only_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14ldad6/is_idrive_100gb_295year_every_year_or_only_the/", "subreddit_subscribers": 690070, "created_utc": 1687967913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone,\n\nI would like make my homelab small and easy to manage. Currently I have a Fractal 804, but I was thinking about moving to a NUC+DAS (1 to begin with, then 1 for main disks and 1 for backup disks).\n\nI use the home server mostly for backup and media storage/plex.\n\nThe PRO:\n\n* Smaller and quieter\n* easy access to all disks\n* \"up to\" 8/10 disks\n\nthe CONS\n\n* is USB reliable? Do i have to fear for more errors compared to sata?\n* Will linux recognize them as 4 HDDs if I put 4 disks into one DAS?\n\nAm I missing any other cons? I know that the speed may be slower compared to a normal NAS, but since I have a 1gbit ethernet on my PC I don't see it as an issue  \n\n\nEDIT: I'm also fine with a case with at least 4 hot swap disks where I can put a mATX motherboard", "author_fullname": "t2_24u5cpux", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "NUC+ double DAS for backup and media storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lasdm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687965076.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687961973.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I would like make my homelab small and easy to manage. Currently I have a Fractal 804, but I was thinking about moving to a NUC+DAS (1 to begin with, then 1 for main disks and 1 for backup disks).&lt;/p&gt;\n\n&lt;p&gt;I use the home server mostly for backup and media storage/plex.&lt;/p&gt;\n\n&lt;p&gt;The PRO:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Smaller and quieter&lt;/li&gt;\n&lt;li&gt;easy access to all disks&lt;/li&gt;\n&lt;li&gt;&amp;quot;up to&amp;quot; 8/10 disks&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;the CONS&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;is USB reliable? Do i have to fear for more errors compared to sata?&lt;/li&gt;\n&lt;li&gt;Will linux recognize them as 4 HDDs if I put 4 disks into one DAS?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Am I missing any other cons? I know that the speed may be slower compared to a normal NAS, but since I have a 1gbit ethernet on my PC I don&amp;#39;t see it as an issue  &lt;/p&gt;\n\n&lt;p&gt;EDIT: I&amp;#39;m also fine with a case with at least 4 hot swap disks where I can put a mATX motherboard&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lasdm", "is_robot_indexable": true, "report_reasons": null, "author": "TopdeckIsSkill", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lasdm/nuc_double_das_for_backup_and_media_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lasdm/nuc_double_das_for_backup_and_media_storage/", "subreddit_subscribers": 690070, "created_utc": 1687961973.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If you check out WD's product page: https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-blue-hdd/product-brief-western-digital-wd-blue-pc-hdd.pdf\n\nand Amazon product page: https://www.amazon.com/dp/B0BNGL4BND?th=1\n\nthe newest models of all WD Blue desktop drives are all CMR:\n\n* 2TB: WD20EARZ\n* 3TB: WD20EZAX\n* 4TB: WD40EZAX\n* 6TB: WD60EZAX\n* 8TB: WD80EAZZ (always has been CMR tho)", "author_fullname": "t2_fzwj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looks like WD Blue drives are changing back to CMR", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ltc7b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688007836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you check out WD&amp;#39;s product page: &lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-blue-hdd/product-brief-western-digital-wd-blue-pc-hdd.pdf\"&gt;https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-blue-hdd/product-brief-western-digital-wd-blue-pc-hdd.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;and Amazon product page: &lt;a href=\"https://www.amazon.com/dp/B0BNGL4BND?th=1\"&gt;https://www.amazon.com/dp/B0BNGL4BND?th=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;the newest models of all WD Blue desktop drives are all CMR:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;2TB: WD20EARZ&lt;/li&gt;\n&lt;li&gt;3TB: WD20EZAX&lt;/li&gt;\n&lt;li&gt;4TB: WD40EZAX&lt;/li&gt;\n&lt;li&gt;6TB: WD60EZAX&lt;/li&gt;\n&lt;li&gt;8TB: WD80EAZZ (always has been CMR tho)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1TB = 0.909495TiB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14ltc7b", "is_robot_indexable": true, "report_reasons": null, "author": "HTWingNut", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14ltc7b/looks_like_wd_blue_drives_are_changing_back_to_cmr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14ltc7b/looks_like_wd_blue_drives_are_changing_back_to_cmr/", "subreddit_subscribers": 690070, "created_utc": 1688007836.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}