{"kind": "Listing", "data": {"after": "t3_14lo4ku", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just announced, Delta Lake 3.0 now compatible with Hudi and Iceberg.\n\nMy life just got more interesting.", "author_fullname": "t2_713dpi97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta Lake 3.0", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lfqfu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 87, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "9ecf3c88-e787-11ed-957e-de1616aeae13", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 87, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687973614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just announced, Delta Lake 3.0 now compatible with Hudi and Iceberg.&lt;/p&gt;\n\n&lt;p&gt;My life just got more interesting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineering Manager", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lfqfu", "is_robot_indexable": true, "report_reasons": null, "author": "rexicusmaximus", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/14lfqfu/delta_lake_30/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lfqfu/delta_lake_30/", "subreddit_subscribers": 112961, "created_utc": 1687973614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to switch jobs and trying to determine what skills I would need to learn to try and get some interviews. My current job skills are heavy database, and coding in c#.  Therefore I think one of the skills I apparently need is Python, but I am not sure in want context I would need to learn/use it.\n\nSo my question is how are you using it? Is it simply to import files, run transform calc and export file? Are you exporting results to Databases/ pulling from databases? What editor do you use for your programs/scripts? I just feel lost at the idea of the generic \"learn python\", like I do with most other skills I am going to have to learn.", "author_fullname": "t2_11j6lc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is it you do with Python in your Job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lhzv9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687978940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to switch jobs and trying to determine what skills I would need to learn to try and get some interviews. My current job skills are heavy database, and coding in c#.  Therefore I think one of the skills I apparently need is Python, but I am not sure in want context I would need to learn/use it.&lt;/p&gt;\n\n&lt;p&gt;So my question is how are you using it? Is it simply to import files, run transform calc and export file? Are you exporting results to Databases/ pulling from databases? What editor do you use for your programs/scripts? I just feel lost at the idea of the generic &amp;quot;learn python&amp;quot;, like I do with most other skills I am going to have to learn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lhzv9", "is_robot_indexable": true, "report_reasons": null, "author": "Cstadler25", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lhzv9/what_is_it_you_do_with_python_in_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lhzv9/what_is_it_you_do_with_python_in_your_job/", "subreddit_subscribers": 112961, "created_utc": 1687978940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_u8kebhp6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks releases official SDK for Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14leo16", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/T4Cm8TpuEbsjx0eN9z_Sxuq9ad6WD_ct5CZcJr74BF4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687971083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/databricks/databricks-sdk-py", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?auto=webp&amp;v=enabled&amp;s=acc4f5041fcaf40d949a2e4cd847bc08fcb005a4", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=adf867fe2bcae051621aeba4736112dbc20c72f0", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=57141edffce8ca6d2acbb15a7b65388ad21e2056", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cfef8eca6f82325f924314d9d07cdf8e6cd3b9ff", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=feeb38a5a98bbef277fc0c31b6606bc79483fd91", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9fb4920be5ece8ef16eaf4b82c39c87fa81b0fb5", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/jQprwFtUGDsJwNm7_3sWzWH-ICNK8d91NaSzhkWiAd0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb059ae1542e2484e120ecd8e83f3351fc15ec07", "width": 1080, "height": 540}], "variants": {}, "id": "6IBNQF9cmQiIH3ZxOSSypIOoNLMuRKd750KVDHEoZxE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14leo16", "is_robot_indexable": true, "report_reasons": null, "author": "serge_databricks", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14leo16/databricks_releases_official_sdk_for_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/databricks/databricks-sdk-py", "subreddit_subscribers": 112961, "created_utc": 1687971083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With all of the buzz around the high costs of various platforms and tools used for building data pipelines, including data collection, data warehousing, data processing and transformation, extracting insights out of the data - \n\nWhich are the most inefficient, ineffective, expensive products that you have experienced?\n\nTop 5 or 10 products listicles in various categories are just paid marketing campaigns and provide biased information.\n\nWhat is the tribal wisdom about the worst offenders in data tools and platforms that you would recommend staying away from and why?\n\nShare away and help the budding data engineers out.", "author_fullname": "t2_6pheknqy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which are the most inefficient, ineffective, expensive tools in your data stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ltv6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688009399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With all of the buzz around the high costs of various platforms and tools used for building data pipelines, including data collection, data warehousing, data processing and transformation, extracting insights out of the data - &lt;/p&gt;\n\n&lt;p&gt;Which are the most inefficient, ineffective, expensive products that you have experienced?&lt;/p&gt;\n\n&lt;p&gt;Top 5 or 10 products listicles in various categories are just paid marketing campaigns and provide biased information.&lt;/p&gt;\n\n&lt;p&gt;What is the tribal wisdom about the worst offenders in data tools and platforms that you would recommend staying away from and why?&lt;/p&gt;\n\n&lt;p&gt;Share away and help the budding data engineers out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ltv6p", "is_robot_indexable": true, "report_reasons": null, "author": "drc1728", "discussion_type": null, "num_comments": 84, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ltv6p/which_are_the_most_inefficient_ineffective/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ltv6p/which_are_the_most_inefficient_ineffective/", "subreddit_subscribers": 112961, "created_utc": 1688009399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most people in their resume mention, they improved processing speeds by 20%, 30% etc, reduced costs. by x, y etc, . Do most developers know these kind of impacts in general? as an interviewer, do you care to ask them to elaborate? and people who mentioned stats like this, do you see improved calls for interviews? Also, at what years of experience people will care about this? ", "author_fullname": "t2_8fqzfba1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you as an engineer care how much efficiency/cost reductions you're bringing in?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lhlo6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687978013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most people in their resume mention, they improved processing speeds by 20%, 30% etc, reduced costs. by x, y etc, . Do most developers know these kind of impacts in general? as an interviewer, do you care to ask them to elaborate? and people who mentioned stats like this, do you see improved calls for interviews? Also, at what years of experience people will care about this? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lhlo6", "is_robot_indexable": true, "report_reasons": null, "author": "OptimistCherry", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lhlo6/do_you_as_an_engineer_care_how_much/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lhlo6/do_you_as_an_engineer_care_how_much/", "subreddit_subscribers": 112961, "created_utc": 1687978013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I am still a newbie. I have a python project where I am scraping data from some log files on a daily basis and cleaning it then pushing it to db. I have scheduled this project to run daily on windows task scheduler. Is there any other(better) way it can be scheduled on a windows system?", "author_fullname": "t2_1js9ugwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I schedule python ETL code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lu0dk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688009808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am still a newbie. I have a python project where I am scraping data from some log files on a daily basis and cleaning it then pushing it to db. I have scheduled this project to run daily on windows task scheduler. Is there any other(better) way it can be scheduled on a windows system?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lu0dk", "is_robot_indexable": true, "report_reasons": null, "author": "Rawvik", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lu0dk/how_can_i_schedule_python_etl_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lu0dk/how_can_i_schedule_python_etl_code/", "subreddit_subscribers": 112961, "created_utc": 1688009808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LakehouseIQ: Your new AI overlord", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14lcl25", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5Cj0uZCvWJ3ImvXy1b7VYd5DorYe54LBpuERUqXRoGs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687966222.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "databricks.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.databricks.com/blog/introducing-lakehouseiq-ai-powered-engine-uniquely-understands-your-business", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?auto=webp&amp;v=enabled&amp;s=54c85608339efd7fc98d82c6e5b6c9037d5411f2", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=49591bac210c847aac0bde7034427b597fa95e23", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2abb0c0cf8bf149f255a6877f21eeedfcf1d7fba", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5964f5ea655f0c082865c46c6b9b9bcdb6bf5d10", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=08d9fdd05bddec589e96728cffd91c20aa02822a", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cff40cf2a10d7a4505e1a08f0230f717c73a797e", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/cZSUEWVbt0YijLEByMUzOZlFq8dYPE78pE0g5-PCsDQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2da1bbe17bc855612237efc1fa8f4b062fea442d", "width": 1080, "height": 565}], "variants": {}, "id": "1WPTbdrGWkjPjVPTtLKBuew_V3jfMV5ZAV1IKBysEkc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14lcl25", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lcl25/lakehouseiq_your_new_ai_overlord/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.databricks.com/blog/introducing-lakehouseiq-ai-powered-engine-uniquely-understands-your-business", "subreddit_subscribers": 112961, "created_utc": 1687966222.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently a postdoc at a university, but I would like to move into a private industry career that acquires and analyzes weather/climate/geospatial data. For example, there are a ton of mapping apps (OnX, Gaia, etc) that I think would benefit from including more weather data and derived products. \n\n&amp;nbsp;\n\n**Are there any resources (websites, books) that deal explicitly with the DE challenges unique to these data?** For example, I have almost never had to use SQL in my work and most things I work with are gridded (i.e. raster). I know there will be overlap with things like AWS, Spark, etc, so I am focusing on those right now. \n\n&amp;nbsp;\n\nThanks!", "author_fullname": "t2_bf1rl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for Weather/Geospatial data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lcyxr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687967137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a postdoc at a university, but I would like to move into a private industry career that acquires and analyzes weather/climate/geospatial data. For example, there are a ton of mapping apps (OnX, Gaia, etc) that I think would benefit from including more weather data and derived products. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Are there any resources (websites, books) that deal explicitly with the DE challenges unique to these data?&lt;/strong&gt; For example, I have almost never had to use SQL in my work and most things I work with are gridded (i.e. raster). I know there will be overlap with things like AWS, Spark, etc, so I am focusing on those right now. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lcyxr", "is_robot_indexable": true, "report_reasons": null, "author": "gbromley", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lcyxr/resources_for_weathergeospatial_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lcyxr/resources_for_weathergeospatial_data/", "subreddit_subscribers": 112961, "created_utc": 1687967137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "These are all boiler plate concerns and just seeking an open dialogue on advice. \n\nI have worked at multiple startups as a data engineer and run successful data warehouses. I write and follow standards, procedures, and best practices. Typically ive worked solo or with one other person. I am proud of the data platforms I have created. \n\nI am starting a new project as a consultant next week with a well known billion dollar company that I cant disclose. Im a little nervous because my past projects have been significantly less data than in the past. I work with snowflake. What do I need to be prepared for when working at scale. I.e I previously have worked with fact tables 500k-1M rows, now will be working with MM and billion row tables. \n\nI consider myself good at optimizing queries and I hope the power of larger snowflake warehouses will be of assistance. I am the lead engineer on the project so want to be as ready as possible for the transition from a small warehouse to a large warehouse. \n\nAnything helps! Thanks!", "author_fullname": "t2_6iq3gwld9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First DE gig at large scale", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lwjf0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688017626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;These are all boiler plate concerns and just seeking an open dialogue on advice. &lt;/p&gt;\n\n&lt;p&gt;I have worked at multiple startups as a data engineer and run successful data warehouses. I write and follow standards, procedures, and best practices. Typically ive worked solo or with one other person. I am proud of the data platforms I have created. &lt;/p&gt;\n\n&lt;p&gt;I am starting a new project as a consultant next week with a well known billion dollar company that I cant disclose. Im a little nervous because my past projects have been significantly less data than in the past. I work with snowflake. What do I need to be prepared for when working at scale. I.e I previously have worked with fact tables 500k-1M rows, now will be working with MM and billion row tables. &lt;/p&gt;\n\n&lt;p&gt;I consider myself good at optimizing queries and I hope the power of larger snowflake warehouses will be of assistance. I am the lead engineer on the project so want to be as ready as possible for the transition from a small warehouse to a large warehouse. &lt;/p&gt;\n\n&lt;p&gt;Anything helps! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14lwjf0", "is_robot_indexable": true, "report_reasons": null, "author": "ElephantCorrect2132", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lwjf0/first_de_gig_at_large_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lwjf0/first_de_gig_at_large_scale/", "subreddit_subscribers": 112961, "created_utc": 1688017626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I have recently started using Delta tables with Pyspark and AWS S3 storage.\n\nI am doing a merge into my Delta table, with conditions for update and insert.\n\nI have some test data that does not change between runs, so I was expecting the merge to be idempotent, meaning: two subsequent merges should not write any data to S3.\n\n&amp;#x200B;\n\nHowever, when I run the merge statement, most of the delta table is re-written.\n\nEven stranger,  when I check the Delta table's history, I verify that 0 rows were inserted, 0 rows were updated, and 0 rows were deleted - but also that 70 files were removed and 70 fliles were added (corresponding to most of my dataset).\n\nAny ideas why this might be the case? Thank you!", "author_fullname": "t2_8xg3h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta merge is writing data, even though there are no inserts or updates?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lnprw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687992523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have recently started using Delta tables with Pyspark and AWS S3 storage.&lt;/p&gt;\n\n&lt;p&gt;I am doing a merge into my Delta table, with conditions for update and insert.&lt;/p&gt;\n\n&lt;p&gt;I have some test data that does not change between runs, so I was expecting the merge to be idempotent, meaning: two subsequent merges should not write any data to S3.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, when I run the merge statement, most of the delta table is re-written.&lt;/p&gt;\n\n&lt;p&gt;Even stranger,  when I check the Delta table&amp;#39;s history, I verify that 0 rows were inserted, 0 rows were updated, and 0 rows were deleted - but also that 70 files were removed and 70 fliles were added (corresponding to most of my dataset).&lt;/p&gt;\n\n&lt;p&gt;Any ideas why this might be the case? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lnprw", "is_robot_indexable": true, "report_reasons": null, "author": "Fredbull", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lnprw/delta_merge_is_writing_data_even_though_there_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lnprw/delta_merge_is_writing_data_even_though_there_are/", "subreddit_subscribers": 112961, "created_utc": 1687992523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone else here? What are your thoughts so far?", "author_fullname": "t2_8y2a4hfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Data + AI Summit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lw0op", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688015974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone else here? What are your thoughts so far?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lw0op", "is_robot_indexable": true, "report_reasons": null, "author": "Known-Delay7227", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lw0op/databricks_data_ai_summit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lw0op/databricks_data_ai_summit/", "subreddit_subscribers": 112961, "created_utc": 1688015974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What do you guys think of dagsters new pricing model? I am pretty new to dagster and the pricing model just changed during trial.\nWith the Team Subscription, you have 10000 Credits available, which means 330 asset matrializations a day, which seems pretty low when you have a lot of small assets you are materializing daily. Materializing one asset every 10min gets you 150 already. Do I have a  wrong understanding of this?", "author_fullname": "t2_1jlb0188", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster Cloud Pricing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lk206", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687983809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you guys think of dagsters new pricing model? I am pretty new to dagster and the pricing model just changed during trial.\nWith the Team Subscription, you have 10000 Credits available, which means 330 asset matrializations a day, which seems pretty low when you have a lot of small assets you are materializing daily. Materializing one asset every 10min gets you 150 already. Do I have a  wrong understanding of this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lk206", "is_robot_indexable": true, "report_reasons": null, "author": "KindaRoot", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lk206/dagster_cloud_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lk206/dagster_cloud_pricing/", "subreddit_subscribers": 112961, "created_utc": 1687983809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uypc8pwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Exploring Graphs in Rust. Yikes.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 69, "top_awarded_type": null, "hide_score": false, "name": "t3_14lcciw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/w7A3n7NOh83dDxukY5zsnG72JmKkQ6tJdlFr7s_UiSA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687965666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "confessionsofadataguy.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.confessionsofadataguy.com/exploring-graphs-in-rust-yikes/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?auto=webp&amp;v=enabled&amp;s=fda8c60d7a50945b57821af3599a39dd7a2311ce", "width": 1030, "height": 511}, "resolutions": [{"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3e978f0e26b5253388ce5d2e091ddf9f8c72248a", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34a8c0dea0a4814284917b3628a2034aa3f221bd", "width": 216, "height": 107}, {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b9e3586c3d359d92ef4ad3fdc9dc31e8a122f49a", "width": 320, "height": 158}, {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c1fbdee8fa2883d6a099972a972e6c3fb586299f", "width": 640, "height": 317}, {"url": "https://external-preview.redd.it/leaDZrZsRwQH7vX4fLfmGRzwrr0gpvpRX-ysnpBhCyU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4546983493885ca9ff0ddea1e30868c4ca32b779", "width": 960, "height": 476}], "variants": {}, "id": "sB9wqRwDtNXITSnlZBdxKU18Nhco9x0ZHuKL_Jn4Y_s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14lcciw", "is_robot_indexable": true, "report_reasons": null, "author": "DarkClear3881", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lcciw/exploring_graphs_in_rust_yikes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.confessionsofadataguy.com/exploring-graphs-in-rust-yikes/", "subreddit_subscribers": 112961, "created_utc": 1687965666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vd2d51zd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udc49 New Awesome Polars release! What's new in the world of Polars in June 2023 ? Let's find out! \ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14la4y2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/gqtPViRGBsKIrIJLyK_hSIjXArCufvNmUE135m4TIC8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687960389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/ddotta/awesome-polars/releases/tag/2023-06-28", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?auto=webp&amp;v=enabled&amp;s=112b9d316153e774ab88765bc9f581c2b6a33feb", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bae859fbf853259a52562afce9f36c9c5ea37068", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=44f2d000933928749cf1e76e290388c1a64f2b88", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2c578d631f51a640c097e9893cee238f3a997c41", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f1e8119a50a2d6aae203727ecbf3e07a742106bc", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28f9c60e425f5a482c13ef5ccf8c62c99277514f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/NJSjt1kVwCPKuf7YWCXhbkJ1IC-bKf2bPA2bzxPNrnU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c612bd2f8f22ab035d6fe28c1f79ae276f57be6a", "width": 1080, "height": 540}], "variants": {}, "id": "JLi9UEo1JLI2HplShAk-3FlVXxlreLI_Mw3YPTU9RTY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14la4y2", "is_robot_indexable": true, "report_reasons": null, "author": "damiendotta", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14la4y2/new_awesome_polars_release_whats_new_in_the_world/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/ddotta/awesome-polars/releases/tag/2023-06-28", "subreddit_subscribers": 112961, "created_utc": 1687960389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are working on setting up our databricks environment (I\u2019m sure you\u2019ve seen my other posts) I am wondering how you guys use these \n\n- do you have one to many storage credentials to external locations or one to one? \n- do you specify external locations at the top most level of a bucket or to a folder hierarchy in the bucket? \n- how do external tables work with unity catalog? If I make a catalog/ schema with an external location, where is that catalog and schema?", "author_fullname": "t2_18qay50v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External tables, storage credentials, and Unity Catalog.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lqcqk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687999390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are working on setting up our databricks environment (I\u2019m sure you\u2019ve seen my other posts) I am wondering how you guys use these &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;do you have one to many storage credentials to external locations or one to one? &lt;/li&gt;\n&lt;li&gt;do you specify external locations at the top most level of a bucket or to a folder hierarchy in the bucket? &lt;/li&gt;\n&lt;li&gt;how do external tables work with unity catalog? If I make a catalog/ schema with an external location, where is that catalog and schema?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lqcqk", "is_robot_indexable": true, "report_reasons": null, "author": "Doyale_royale", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lqcqk/external_tables_storage_credentials_and_unity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lqcqk/external_tables_storage_credentials_and_unity/", "subreddit_subscribers": 112961, "created_utc": 1687999390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you design to handle EndEffectiveDate in DV Sat tables or SCD type2?\n\nDo you run updates with incremental loads or calculate on the fly with LAG(), or other ways?\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you design to handle EndEffectiveDate in DV Sat tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lkktf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687985256.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687985043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you design to handle EndEffectiveDate in DV Sat tables or SCD type2?&lt;/p&gt;\n\n&lt;p&gt;Do you run updates with incremental loads or calculate on the fly with LAG(), or other ways?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lkktf", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lkktf/how_do_you_design_to_handle_endeffectivedate_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lkktf/how_do_you_design_to_handle_endeffectivedate_in/", "subreddit_subscribers": 112961, "created_utc": 1687985043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\n\nI am writing a query in dataflow lookup with schema name as a parameter.\nI have already created a schema_name parameter with $parameter_name with string default value.\nSo how should i write a below query in lookup.\nSelect * from $parameter_name.tablename\n\nI have tried-\nConcat(\u2018Select * from \u2019, $parameter_name,\n\u2018.tablename\u2019)\n\nThis is working, it is not able read the value of parameter.\n\nCan anyone help me with the solution.", "author_fullname": "t2_jrlp2tiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ADF parameters in SQL query -Urgent", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14letcn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687971436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;I am writing a query in dataflow lookup with schema name as a parameter.\nI have already created a schema_name parameter with $parameter_name with string default value.\nSo how should i write a below query in lookup.\nSelect * from $parameter_name.tablename&lt;/p&gt;\n\n&lt;p&gt;I have tried-\nConcat(\u2018Select * from \u2019, $parameter_name,\n\u2018.tablename\u2019)&lt;/p&gt;\n\n&lt;p&gt;This is working, it is not able read the value of parameter.&lt;/p&gt;\n\n&lt;p&gt;Can anyone help me with the solution.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14letcn", "is_robot_indexable": true, "report_reasons": null, "author": "ProcedureScared2970", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14letcn/adf_parameters_in_sql_query_urgent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14letcn/adf_parameters_in_sql_query_urgent/", "subreddit_subscribers": 112961, "created_utc": 1687971436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When getting my career started (information technology BS degree with an emphasis on data/data systems). I got in with a smaller, somewhat new startup and had the opportunity of my life. I got to design a data warehouse from the ground up based on the source data, nothing more and no opinions,  using a very solid ERP system as my source. \n\nI created a very nice kimball model that fit the specs to a T (I still get reminded how good it is whenever I have to let my old boss know he's being used as a reference). \n\nAfter that I knew what my skill was and I moved on to keep building instead of creating reports/dashboards from my own design. The probablem is no one gives a F about scalability anyone. Sure it's always something talked about but as soon as you try to say something such as \"We are talking a lot about dataset C that is generated from dataset A and dataset B but as the engineer can someone start by defining dataset A Or B?\n\n...crickets. And then I ask, as someone new I have to ask, do you know what the error tolerance of our reports are?", "author_fullname": "t2_nw770", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone else really frustrated with the additional responsibilities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14l93wo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1687958109.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687957762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When getting my career started (information technology BS degree with an emphasis on data/data systems). I got in with a smaller, somewhat new startup and had the opportunity of my life. I got to design a data warehouse from the ground up based on the source data, nothing more and no opinions,  using a very solid ERP system as my source. &lt;/p&gt;\n\n&lt;p&gt;I created a very nice kimball model that fit the specs to a T (I still get reminded how good it is whenever I have to let my old boss know he&amp;#39;s being used as a reference). &lt;/p&gt;\n\n&lt;p&gt;After that I knew what my skill was and I moved on to keep building instead of creating reports/dashboards from my own design. The probablem is no one gives a F about scalability anyone. Sure it&amp;#39;s always something talked about but as soon as you try to say something such as &amp;quot;We are talking a lot about dataset C that is generated from dataset A and dataset B but as the engineer can someone start by defining dataset A Or B?&lt;/p&gt;\n\n&lt;p&gt;...crickets. And then I ask, as someone new I have to ask, do you know what the error tolerance of our reports are?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14l93wo", "is_robot_indexable": true, "report_reasons": null, "author": "PeacefullyFighting", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14l93wo/anyone_else_really_frustrated_with_the_additional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14l93wo/anyone_else_really_frustrated_with_the_additional/", "subreddit_subscribers": 112961, "created_utc": 1687957762.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data analyst, and I'm not on the development side really I mainly run BI style analysis on our spark clusters with notebooks.\n\nI've done lots of reading and tutorials and the like on different ML applications in python, but all of them seem like they are quite 'heavy' in terms of investment, and really are best done as part of a concerted effort to actually build in a model onto some sort of product (i.e. recommendation engine on your app).\n\nBut, aside from that, are there any applications of ML or NLP that are more for making some of the more mundane tasks easier when it comes to analysis or ELT that is *actually* less work than writing out specific functions for transformation or dedupe or data enrichment?\n\nFor example, are there any interesting techniques people have somehow applied to help automate metadata tagging or data normalization?\n\n I don't mean like some magical one button non existent AI bullshit. I just mean practical day to day techniques that are repeatable and actually worth the time spent doing (as opposed to just tackling it manually) like when looking at a new data source for ETL \"you could use NLP to flag columns that likely match your existing schema\".\n\nClosest example I'm currently looking to play with is a few NLP based libraries for identifying and flagging PII or GDPR data that needs to be masked / purged.", "author_fullname": "t2_51nsnxi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Practical Applications of ML for analysis or ETL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14m3oxa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688041586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data analyst, and I&amp;#39;m not on the development side really I mainly run BI style analysis on our spark clusters with notebooks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done lots of reading and tutorials and the like on different ML applications in python, but all of them seem like they are quite &amp;#39;heavy&amp;#39; in terms of investment, and really are best done as part of a concerted effort to actually build in a model onto some sort of product (i.e. recommendation engine on your app).&lt;/p&gt;\n\n&lt;p&gt;But, aside from that, are there any applications of ML or NLP that are more for making some of the more mundane tasks easier when it comes to analysis or ELT that is &lt;em&gt;actually&lt;/em&gt; less work than writing out specific functions for transformation or dedupe or data enrichment?&lt;/p&gt;\n\n&lt;p&gt;For example, are there any interesting techniques people have somehow applied to help automate metadata tagging or data normalization?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t mean like some magical one button non existent AI bullshit. I just mean practical day to day techniques that are repeatable and actually worth the time spent doing (as opposed to just tackling it manually) like when looking at a new data source for ETL &amp;quot;you could use NLP to flag columns that likely match your existing schema&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Closest example I&amp;#39;m currently looking to play with is a few NLP based libraries for identifying and flagging PII or GDPR data that needs to be masked / purged.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14m3oxa", "is_robot_indexable": true, "report_reasons": null, "author": "VersatileGuru", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m3oxa/practical_applications_of_ml_for_analysis_or_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m3oxa/practical_applications_of_ml_for_analysis_or_etl/", "subreddit_subscribers": 112961, "created_utc": 1688041586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m an embedded engineer intern working part time at a small startup with novel sensors and we\u2019re looking to start logging and storing important information from the devices. \n\nI want to go through the whole process of creating the database on new hardware, sending data from IOT devices, accessing data via an API, and having the database automatically manage the data via scripts (such as filtering). However, this is all extremely new to me, as I\u2019m only extremely familiar with low-level programming and hardware design so I want to choose the simplest and barebones tools as possible for this job.\n\nSo far everything we\u2019ve done is with basic files in a shared drive + emails lmao. I\u2019m wondering what machine should I get (what OS) if I\u2019m to use it for the sole purpose of database. What management system should I use? How do I create the API? How do I log data from embedded devices? I want to learn all this stuff, even though it\u2019s just for some current small-scale system as I aim to enter the IOT space.", "author_fullname": "t2_rkkbr1x8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating and utilizing a database in the simplest way possible", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lxz7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688022483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m an embedded engineer intern working part time at a small startup with novel sensors and we\u2019re looking to start logging and storing important information from the devices. &lt;/p&gt;\n\n&lt;p&gt;I want to go through the whole process of creating the database on new hardware, sending data from IOT devices, accessing data via an API, and having the database automatically manage the data via scripts (such as filtering). However, this is all extremely new to me, as I\u2019m only extremely familiar with low-level programming and hardware design so I want to choose the simplest and barebones tools as possible for this job.&lt;/p&gt;\n\n&lt;p&gt;So far everything we\u2019ve done is with basic files in a shared drive + emails lmao. I\u2019m wondering what machine should I get (what OS) if I\u2019m to use it for the sole purpose of database. What management system should I use? How do I create the API? How do I log data from embedded devices? I want to learn all this stuff, even though it\u2019s just for some current small-scale system as I aim to enter the IOT space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lxz7v", "is_robot_indexable": true, "report_reasons": null, "author": "aufry", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lxz7v/creating_and_utilizing_a_database_in_the_simplest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lxz7v/creating_and_utilizing_a_database_in_the_simplest/", "subreddit_subscribers": 112961, "created_utc": 1688022483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are my choices for working with data i.e. Data Engineering and ML/AI task on JAVA? \n\n&amp;#x200B;\n\nI know in Python there are many libraries/Frameworks choices Pandas(/numpy)/Polars/Dask/PySpark/Databricks depending on the size of data, type of system, on prem/cloud, project (webapp/edge device app) ect. For ML AI task again there are many options Scikit Learn, SparkML, Keras, ect. \n\n&amp;#x200B;\n\nAfter some googling and chatGPT prompts I didn't exactly find great results. I saw that many JAVA Frameworks that are used for ML task accept Tablesaw (Dataframes) i.e.DJL (Deep Java Library)\\\\DeepLearning4j\\\\Flink . However Tablesaw hasn't been updated since April 2022. I started looking at Spark on Java but had some trouble finding resources in Java. The resources I kept finding for spark ended up being for either Scala or Python. \n\n&amp;#x200B;\n\nAre there any good resources for data engineering and data science using JAVA. ", "author_fullname": "t2_h0k60d4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Java Data Engineering and Data Science Libraries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14licjh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687979786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are my choices for working with data i.e. Data Engineering and ML/AI task on JAVA? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know in Python there are many libraries/Frameworks choices Pandas(/numpy)/Polars/Dask/PySpark/Databricks depending on the size of data, type of system, on prem/cloud, project (webapp/edge device app) ect. For ML AI task again there are many options Scikit Learn, SparkML, Keras, ect. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;After some googling and chatGPT prompts I didn&amp;#39;t exactly find great results. I saw that many JAVA Frameworks that are used for ML task accept Tablesaw (Dataframes) i.e.DJL (Deep Java Library)\\DeepLearning4j\\Flink . However Tablesaw hasn&amp;#39;t been updated since April 2022. I started looking at Spark on Java but had some trouble finding resources in Java. The resources I kept finding for spark ended up being for either Scala or Python. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Are there any good resources for data engineering and data science using JAVA. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14licjh", "is_robot_indexable": true, "report_reasons": null, "author": "magu01", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14licjh/java_data_engineering_and_data_science_libraries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14licjh/java_data_engineering_and_data_science_libraries/", "subreddit_subscribers": 112961, "created_utc": 1687979786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good evening Gentleman and Ladies.\n\nI have an Internship that starts July 10th, this will be my first job ever.\n\nI want to get a head start.\n\n* Internship will involve **Reltio a master data maangement platform.**\n* I will be **learning to manage records**\n* With s**ql I will be managing/creating burn down list**\n* **Writing querys to target certain records.**\n\nMy questions are:\n\n1. What SQL Commands/Functions should I be really trying to Master to do this task?\n2. I don't know much about IT too be honest, what are some basic things I should know about to not look clueless.\n3. How can I get good at using Reltio?\n\nTo those who took the time to answer, thank you.", "author_fullname": "t2_htrki4x9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reltio and SQL for my first job ever.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lb7i0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687962987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good evening Gentleman and Ladies.&lt;/p&gt;\n\n&lt;p&gt;I have an Internship that starts July 10th, this will be my first job ever.&lt;/p&gt;\n\n&lt;p&gt;I want to get a head start.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Internship will involve &lt;strong&gt;Reltio a master data maangement platform.&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;I will be &lt;strong&gt;learning to manage records&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;With s&lt;strong&gt;ql I will be managing/creating burn down list&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Writing querys to target certain records.&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My questions are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What SQL Commands/Functions should I be really trying to Master to do this task?&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t know much about IT too be honest, what are some basic things I should know about to not look clueless.&lt;/li&gt;\n&lt;li&gt;How can I get good at using Reltio?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;To those who took the time to answer, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lb7i0", "is_robot_indexable": true, "report_reasons": null, "author": "TophKatara", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lb7i0/reltio_and_sql_for_my_first_job_ever/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lb7i0/reltio_and_sql_for_my_first_job_ever/", "subreddit_subscribers": 112961, "created_utc": 1687962987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would very much appreciate some advice.\n\nWe have a ton of historic semi-structured data which is stored in JSON. I say semi-structured because the structure has been expanded over the years, so the schema is not fixed over time, even if the major dimensions have not changed, the key figures have expanded.\n\nWe have probably records rows a day of JSON for the last 5 years, so 2m records. Each JSON record could be as much as a few kb. Maybe a few GB total, at the very most.\n\nIs there a product (ideally cloud) which is well suited to really easily importing this data and enabling us to do some basic time series analysis? I need some quick and dirty analysis and want to avoid a big data warehouse project. Doesn't matter if it's a commercial or open source product.\n\nBack in the day I used MongoDB to do things like this, but maybe there are better options now?", "author_fullname": "t2_pfwmnuy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data mart for semi-structured JSON data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14m4bmf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688043350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would very much appreciate some advice.&lt;/p&gt;\n\n&lt;p&gt;We have a ton of historic semi-structured data which is stored in JSON. I say semi-structured because the structure has been expanded over the years, so the schema is not fixed over time, even if the major dimensions have not changed, the key figures have expanded.&lt;/p&gt;\n\n&lt;p&gt;We have probably records rows a day of JSON for the last 5 years, so 2m records. Each JSON record could be as much as a few kb. Maybe a few GB total, at the very most.&lt;/p&gt;\n\n&lt;p&gt;Is there a product (ideally cloud) which is well suited to really easily importing this data and enabling us to do some basic time series analysis? I need some quick and dirty analysis and want to avoid a big data warehouse project. Doesn&amp;#39;t matter if it&amp;#39;s a commercial or open source product.&lt;/p&gt;\n\n&lt;p&gt;Back in the day I used MongoDB to do things like this, but maybe there are better options now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14m4bmf", "is_robot_indexable": true, "report_reasons": null, "author": "thebemusedmuse", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m4bmf/data_mart_for_semistructured_json_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m4bmf/data_mart_for_semistructured_json_data/", "subreddit_subscribers": 112961, "created_utc": 1688043350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been struggling to get some decent client facing analytic tools up and running because our legacy on premise setup is basically two extremes of \"a couple poorly deployed COTS front end COTS apps only connected to 20% of our data\" or \"spark clusters and jupyter notebook data science\". The latter works for myself and other tech literate analysts or users.\n\nBeen reading more about OpenSearch since the current open-source ELK stack is super restricted to basically useless (you can't even print a dashboard or viz to PDF) and it's starting to look very appealing to get some datamarts hooked up to dashboards and viz, but I don't really come across discussion around OpenSearch and ELK stacks beyond search engines or as part of another app. No one at my workplace seems to have experience because everything for search engines deployed are all Solr setups.\n\nHow difficult are some of the AD integration for authn and authz to setup or the ABAC permission configs that the docs explain? Or setting up logstash / beats data connectors that listen in on an API?\n\nIt's all very outside my mostly SQL world wheelhouse but I experimented with it and kibana on a small ad hoc dataset and I really liked it as a kind of data exploration, EDA and search tool.\n\nBut is it something you would look to create indexes on a couple datamarts with some dashboards as a general purpose analytics tool or is the effort and esoteric configs just not worth it?", "author_fullname": "t2_51nsnxi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OpenSearch ELK stack for analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14m44y9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688042829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been struggling to get some decent client facing analytic tools up and running because our legacy on premise setup is basically two extremes of &amp;quot;a couple poorly deployed COTS front end COTS apps only connected to 20% of our data&amp;quot; or &amp;quot;spark clusters and jupyter notebook data science&amp;quot;. The latter works for myself and other tech literate analysts or users.&lt;/p&gt;\n\n&lt;p&gt;Been reading more about OpenSearch since the current open-source ELK stack is super restricted to basically useless (you can&amp;#39;t even print a dashboard or viz to PDF) and it&amp;#39;s starting to look very appealing to get some datamarts hooked up to dashboards and viz, but I don&amp;#39;t really come across discussion around OpenSearch and ELK stacks beyond search engines or as part of another app. No one at my workplace seems to have experience because everything for search engines deployed are all Solr setups.&lt;/p&gt;\n\n&lt;p&gt;How difficult are some of the AD integration for authn and authz to setup or the ABAC permission configs that the docs explain? Or setting up logstash / beats data connectors that listen in on an API?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s all very outside my mostly SQL world wheelhouse but I experimented with it and kibana on a small ad hoc dataset and I really liked it as a kind of data exploration, EDA and search tool.&lt;/p&gt;\n\n&lt;p&gt;But is it something you would look to create indexes on a couple datamarts with some dashboards as a general purpose analytics tool or is the effort and esoteric configs just not worth it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14m44y9", "is_robot_indexable": true, "report_reasons": null, "author": "VersatileGuru", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m44y9/opensearch_elk_stack_for_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m44y9/opensearch_elk_stack_for_analytics/", "subreddit_subscribers": 112961, "created_utc": 1688042829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering how do we decide on how often we schedule ETL job for delta extraction? What factors are to be considered?\n\nSay a workorder table record may have multiple changes happening within a day, scheduling ELT job hourly may bring in multiple records for same work order in DW vs nightly once run. So what are the guiding principles or business cases for a decision\n\nHow often your extraction jobs are run/scheduled at your company and how were they decided?\n\nAlso besides the business needs are there any technical reasons that influence scheduling?", "author_fullname": "t2_4ck30tok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you decide when to extract delta?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lo4ku", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688010232.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687993523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering how do we decide on how often we schedule ETL job for delta extraction? What factors are to be considered?&lt;/p&gt;\n\n&lt;p&gt;Say a workorder table record may have multiple changes happening within a day, scheduling ELT job hourly may bring in multiple records for same work order in DW vs nightly once run. So what are the guiding principles or business cases for a decision&lt;/p&gt;\n\n&lt;p&gt;How often your extraction jobs are run/scheduled at your company and how were they decided?&lt;/p&gt;\n\n&lt;p&gt;Also besides the business needs are there any technical reasons that influence scheduling?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lo4ku", "is_robot_indexable": true, "report_reasons": null, "author": "Nomad4455", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lo4ku/how_do_you_decide_when_to_extract_delta/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lo4ku/how_do_you_decide_when_to_extract_delta/", "subreddit_subscribers": 112961, "created_utc": 1687993523.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}