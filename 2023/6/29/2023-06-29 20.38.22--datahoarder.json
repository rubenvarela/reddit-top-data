{"kind": "Listing", "data": {"after": "t3_14lovdw", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_5xe5d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stitcher (podcasting app/site) is being killed off by parent company Sirius XM, effective August 29th. Export your podcasts &amp; metadata while you can!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m4smh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 159, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 159, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1688044621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "stitcher.helpshift.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://stitcher.helpshift.com/hc/en/1-stitcher/section/151-stitcher-farewell-1687885657/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "72TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m4smh", "is_robot_indexable": true, "report_reasons": null, "author": "AtmaJnana", "discussion_type": null, "num_comments": 19, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14m4smh/stitcher_podcasting_appsite_is_being_killed_off/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://stitcher.helpshift.com/hc/en/1-stitcher/section/151-stitcher-farewell-1687885657/", "subreddit_subscribers": 690223, "created_utc": 1688044621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm backing up a NAS with about 120 TB on Synology SMB shares over 10GbE to a SAS LTO8 drive (not an autoloader) which is on a Windows workstation.\n\nTL;DR is there a solution with a clearly organized UI that inspires confidence, and tape management with local file inventory?\n\nI did research here and elsewhere and here's the software I've tried so far:\n\n\\- **VEEAM**: Widely recommended but it turns out that it only supports a measly **500 GB** of data under the Community Edition and to do 120 TB it's several thousand dollars a year. It didn't disclose this until I had set everything up, catalogued my tapes and tried to run a backup at which point it failed with insufficient licenses. Their web site doesn't include this limitation in the comparison tables. The install is huge and the UI is terrible. It gave progress indication by file and by speed but in weird little sub panes that couldn't be properly resized. I gather the 500 GB thing is new, so people should stop recommending this. **UPDATE**: I got a Veeam NFR license and that only increased the limit from 500 GB to **5 TB** which is still super low given there are 22 TB single HDDs.\n\n\\- **Acronis Cyber Protect Backup Advanced**: A test backup worked, but it's a wonky web UI and it doesn't give any information on the backup progress except percentage complete (no current file being backed up, no MBps average, etc.) There is no guidance in the app or their web site on how to organize tapes, merely to dump them into a pool. There are two **deal-breakers**: 1) When adding SMB shares to a backup it expands every directory and doesn't let you collapse the view, so once you add 8-10 shares the list is enormous and cannot be navigated. 2) If I try to backup a subdirectory off an SMB share there is a bug where the credentials fail, e.g. \"\\\\\\\\server\\\\share\" works but \"\\\\\\\\server\\\\share\\\\folder\" fails using the same credentials. **UPDATE**: I also realized there is **no way to select files by date**, so it's impossible to do a file-based incremental/new/changed backup, you have to redo the entire backup every time.\n\n\\- **EaseUS Todo Backup**: Says it supports tape but that feature appears to be missing, their support was clueless and they're a China based company.\n\nI looked at the **Bacula** site but their UI was incomprehensible and it seems designed for Linux with some CLI scripting either good to have or required. Not my cup of tea.\n\nI also checked out **Uranium Backup** and **Iperius Backup** but looking through their tutorials and documentation it doesn't appear that either app has any tape management/local file inventory whatsoever, they just use tape as a dumb backup destination only.\n\n&amp;#x200B;", "author_fullname": "t2_slqb6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Revisiting LTO tape backup software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lqufr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1688070214.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688000733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m backing up a NAS with about 120 TB on Synology SMB shares over 10GbE to a SAS LTO8 drive (not an autoloader) which is on a Windows workstation.&lt;/p&gt;\n\n&lt;p&gt;TL;DR is there a solution with a clearly organized UI that inspires confidence, and tape management with local file inventory?&lt;/p&gt;\n\n&lt;p&gt;I did research here and elsewhere and here&amp;#39;s the software I&amp;#39;ve tried so far:&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;VEEAM&lt;/strong&gt;: Widely recommended but it turns out that it only supports a measly &lt;strong&gt;500 GB&lt;/strong&gt; of data under the Community Edition and to do 120 TB it&amp;#39;s several thousand dollars a year. It didn&amp;#39;t disclose this until I had set everything up, catalogued my tapes and tried to run a backup at which point it failed with insufficient licenses. Their web site doesn&amp;#39;t include this limitation in the comparison tables. The install is huge and the UI is terrible. It gave progress indication by file and by speed but in weird little sub panes that couldn&amp;#39;t be properly resized. I gather the 500 GB thing is new, so people should stop recommending this. &lt;strong&gt;UPDATE&lt;/strong&gt;: I got a Veeam NFR license and that only increased the limit from 500 GB to &lt;strong&gt;5 TB&lt;/strong&gt; which is still super low given there are 22 TB single HDDs.&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Acronis Cyber Protect Backup Advanced&lt;/strong&gt;: A test backup worked, but it&amp;#39;s a wonky web UI and it doesn&amp;#39;t give any information on the backup progress except percentage complete (no current file being backed up, no MBps average, etc.) There is no guidance in the app or their web site on how to organize tapes, merely to dump them into a pool. There are two &lt;strong&gt;deal-breakers&lt;/strong&gt;: 1) When adding SMB shares to a backup it expands every directory and doesn&amp;#39;t let you collapse the view, so once you add 8-10 shares the list is enormous and cannot be navigated. 2) If I try to backup a subdirectory off an SMB share there is a bug where the credentials fail, e.g. &amp;quot;\\\\server\\share&amp;quot; works but &amp;quot;\\\\server\\share\\folder&amp;quot; fails using the same credentials. &lt;strong&gt;UPDATE&lt;/strong&gt;: I also realized there is &lt;strong&gt;no way to select files by date&lt;/strong&gt;, so it&amp;#39;s impossible to do a file-based incremental/new/changed backup, you have to redo the entire backup every time.&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;EaseUS Todo Backup&lt;/strong&gt;: Says it supports tape but that feature appears to be missing, their support was clueless and they&amp;#39;re a China based company.&lt;/p&gt;\n\n&lt;p&gt;I looked at the &lt;strong&gt;Bacula&lt;/strong&gt; site but their UI was incomprehensible and it seems designed for Linux with some CLI scripting either good to have or required. Not my cup of tea.&lt;/p&gt;\n\n&lt;p&gt;I also checked out &lt;strong&gt;Uranium Backup&lt;/strong&gt; and &lt;strong&gt;Iperius Backup&lt;/strong&gt; but looking through their tutorials and documentation it doesn&amp;#39;t appear that either app has any tape management/local file inventory whatsoever, they just use tape as a dumb backup destination only.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lqufr", "is_robot_indexable": true, "report_reasons": null, "author": "WonderSausage", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lqufr/revisiting_lto_tape_backup_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lqufr/revisiting_lto_tape_backup_software/", "subreddit_subscribers": 690223, "created_utc": 1688000733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A few months old 256 GB flash stick, with its USB3(connected 2 a desktop PC) &amp; USB-C ends, was burning hot (even had that odor/smell) from idling overnight!  Same for an older 512 GB USB2. I noticed both use aluminum/metal case type.\n\nDoes anyone else have this problem too? Thank you for reading and hopefully answering soon.", "author_fullname": "t2_4a27h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it me or do Sandisk USB flash sticks get too hot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lqr56", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688000502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few months old 256 GB flash stick, with its USB3(connected 2 a desktop PC) &amp;amp; USB-C ends, was burning hot (even had that odor/smell) from idling overnight!  Same for an older 512 GB USB2. I noticed both use aluminum/metal case type.&lt;/p&gt;\n\n&lt;p&gt;Does anyone else have this problem too? Thank you for reading and hopefully answering soon.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Where's the big floppy disk(ette) flair? :P", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lqr56", "is_robot_indexable": true, "report_reasons": null, "author": "antdude", "discussion_type": null, "num_comments": 14, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14lqr56/is_it_me_or_do_sandisk_usb_flash_sticks_get_too/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lqr56/is_it_me_or_do_sandisk_usb_flash_sticks_get_too/", "subreddit_subscribers": 690223, "created_utc": 1688000502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, \nat work we use an older external website as a kind of wiki, a page that requires a login with we have. Now our IT department decided to modernize everything and at the end of the year the old page will be offline. The replacement really sucks so we decided to try to make some kind of backup of the page and its really helpful articles there.\n\nThe page itself looks like an older Wikipedia, along with links to older articles. Since it is an older page I tried to save the page via Browser and got a html file along with a folder, that contains a lot of .js files. I've opened the html and I could access the articles along with the links. But the problem now: the login itself - on my PC there should be a temporary session (probably cookie based?) active since my colleagues were asked for the password.\n\nAre there any tools around that can save a complete local copy and remove the login requirement afterwards (since after they put it offline out login would not work anymore)? Thank you for any ideas.", "author_fullname": "t2_1ei11v97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local offline backup of a Wiki-like homepage with login possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lugfs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688011156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, \nat work we use an older external website as a kind of wiki, a page that requires a login with we have. Now our IT department decided to modernize everything and at the end of the year the old page will be offline. The replacement really sucks so we decided to try to make some kind of backup of the page and its really helpful articles there.&lt;/p&gt;\n\n&lt;p&gt;The page itself looks like an older Wikipedia, along with links to older articles. Since it is an older page I tried to save the page via Browser and got a html file along with a folder, that contains a lot of .js files. I&amp;#39;ve opened the html and I could access the articles along with the links. But the problem now: the login itself - on my PC there should be a temporary session (probably cookie based?) active since my colleagues were asked for the password.&lt;/p&gt;\n\n&lt;p&gt;Are there any tools around that can save a complete local copy and remove the login requirement afterwards (since after they put it offline out login would not work anymore)? Thank you for any ideas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lugfs", "is_robot_indexable": true, "report_reasons": null, "author": "ChrisM243", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lugfs/local_offline_backup_of_a_wikilike_homepage_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lugfs/local_offline_backup_of_a_wikilike_homepage_with/", "subreddit_subscribers": 690223, "created_utc": 1688011156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_16oo8k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lewtwo has just archived the whole Pok\u00e9mon Shirts company's work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "name": "t3_14m4s0h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;In June 2023, the Pok\u00e9mon Shirts company announced their complete shutdown.&lt;br&gt;&lt;br&gt;here&amp;#39;s how we archived the entire company&amp;#39;s work in just six hours. \ud83e\uddf5 &lt;a href=\"https://t.co/TMI03xXm7j\"&gt;pic.twitter.com/TMI03xXm7j&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lewtwo (@Lewchube) &lt;a href=\"https://twitter.com/Lewchube/status/1674402577939677185?ref_src=twsrc%5Etfw\"&gt;June 29, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/Lewchube/status/1674402577939677185", "author_name": "Lewtwo", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;In June 2023, the Pok\u00e9mon Shirts company announced their complete shutdown.&lt;br&gt;&lt;br&gt;here&amp;#39;s how we archived the entire company&amp;#39;s work in just six hours. \ud83e\uddf5 &lt;a href=\"https://t.co/TMI03xXm7j\"&gt;pic.twitter.com/TMI03xXm7j&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lewtwo (@Lewchube) &lt;a href=\"https://twitter.com/Lewchube/status/1674402577939677185?ref_src=twsrc%5Etfw\"&gt;June 29, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/Lewchube", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;In June 2023, the Pok\u00e9mon Shirts company announced their complete shutdown.&lt;br&gt;&lt;br&gt;here&amp;#39;s how we archived the entire company&amp;#39;s work in just six hours. \ud83e\uddf5 &lt;a href=\"https://t.co/TMI03xXm7j\"&gt;pic.twitter.com/TMI03xXm7j&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lewtwo (@Lewchube) &lt;a href=\"https://twitter.com/Lewchube/status/1674402577939677185?ref_src=twsrc%5Etfw\"&gt;June 29, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/14m4s0h", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/n6EIIVzMke_b9eQpPlCC17G8xLKqGMAXmD75tX2DYcU.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688044573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/Lewchube/status/1674402577939677185", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/m1O7vvsd8OoiAahWfVzVQ-yTDAtjmeiGUttqHVJ1kdI.jpg?auto=webp&amp;v=enabled&amp;s=ac87403ae71983e94b8a2bb2a0218a1168d1c672", "width": 140, "height": 97}, "resolutions": [{"url": "https://external-preview.redd.it/m1O7vvsd8OoiAahWfVzVQ-yTDAtjmeiGUttqHVJ1kdI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=991797453b50a8378ef02f707ff6ac4ca2e63225", "width": 108, "height": 74}], "variants": {}, "id": "tQIa1crPnmfmzCXF4JFHargl7PN717JzBb7IfKFUAAw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "42 TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14m4s0h", "is_robot_indexable": true, "report_reasons": null, "author": "DarthJahus", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14m4s0h/lewtwo_has_just_archived_the_whole_pok\u00e9mon_shirts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/Lewchube/status/1674402577939677185", "subreddit_subscribers": 690223, "created_utc": 1688044573.0, "num_crossposts": 0, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/Lewchube/status/1674402577939677185", "author_name": "Lewtwo", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;In June 2023, the Pok\u00e9mon Shirts company announced their complete shutdown.&lt;br&gt;&lt;br&gt;here&amp;#39;s how we archived the entire company&amp;#39;s work in just six hours. \ud83e\uddf5 &lt;a href=\"https://t.co/TMI03xXm7j\"&gt;pic.twitter.com/TMI03xXm7j&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lewtwo (@Lewchube) &lt;a href=\"https://twitter.com/Lewchube/status/1674402577939677185?ref_src=twsrc%5Etfw\"&gt;June 29, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/Lewchube", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I am looking for some recommendations on an external drive bay enclosure. I currently have 9 Best Buy easy store drives connected to my Mac mini via usbc hubs renting from 8tb to 18tbs. I would like to shuck them and combine them into one enclosure so that can be read as one drive instead of 9.  Current use is for plex media management. The Mac mini acts as the plex server with hardware transcoding so I don\u2019t think I need a nas. I am not worried about data recovery so I think I would use a raid 0 type set-up. Happy to answer any questions!", "author_fullname": "t2_y1dt8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for recommendation for external drive bay", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m5bpl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688046011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am looking for some recommendations on an external drive bay enclosure. I currently have 9 Best Buy easy store drives connected to my Mac mini via usbc hubs renting from 8tb to 18tbs. I would like to shuck them and combine them into one enclosure so that can be read as one drive instead of 9.  Current use is for plex media management. The Mac mini acts as the plex server with hardware transcoding so I don\u2019t think I need a nas. I am not worried about data recovery so I think I would use a raid 0 type set-up. Happy to answer any questions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m5bpl", "is_robot_indexable": true, "report_reasons": null, "author": "mprice06", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m5bpl/looking_for_recommendation_for_external_drive_bay/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m5bpl/looking_for_recommendation_for_external_drive_bay/", "subreddit_subscribers": 690223, "created_utc": 1688046011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Since tape/lto is slow but huge capacity, and flash/ssd is fast but have smaller capacity (at least more expensive), is there SSD+Tape hybrid drive? so the filesystem (which file on which position on the tape) stored on SSD for fast listing, but the data itself stored on tape?", "author_fullname": "t2_7bbojdkz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there ssd+tape hybrid drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m21td", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688036585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since tape/lto is slow but huge capacity, and flash/ssd is fast but have smaller capacity (at least more expensive), is there SSD+Tape hybrid drive? so the filesystem (which file on which position on the tape) stored on SSD for fast listing, but the data itself stored on tape?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m21td", "is_robot_indexable": true, "report_reasons": null, "author": "kokizzu2", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m21td/is_there_ssdtape_hybrid_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m21td/is_there_ssdtape_hybrid_drive/", "subreddit_subscribers": 690223, "created_utc": 1688036585.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI'm trying to save files from a telegram Channel that has download/transfer disabled.\nI tried it on android, and found those files. I also know that there's an extension that brings back the save button on a web browser.\nBut it's just too many files for me to have on my phone then transfer to pc. And going one by one on browser is not viable either.\nI tried to look for it in the desktop versions files, but I only find what a bunch is a bunch of folders named in 2 random characters (letters or numbers) containing a few extensionless files named with random characters. (Found in tdata\\user_data\\media_cache). \nI'm guessing it's some kind of hash file system used by telegram.", "author_fullname": "t2_r3ui1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to save telegram protected files on desktop'", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lld29", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687986866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to save files from a telegram Channel that has download/transfer disabled.\nI tried it on android, and found those files. I also know that there&amp;#39;s an extension that brings back the save button on a web browser.\nBut it&amp;#39;s just too many files for me to have on my phone then transfer to pc. And going one by one on browser is not viable either.\nI tried to look for it in the desktop versions files, but I only find what a bunch is a bunch of folders named in 2 random characters (letters or numbers) containing a few extensionless files named with random characters. (Found in tdata\\user_data\\media_cache). \nI&amp;#39;m guessing it&amp;#39;s some kind of hash file system used by telegram.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lld29", "is_robot_indexable": true, "report_reasons": null, "author": "TheArtofWarPIGEON", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lld29/how_to_save_telegram_protected_files_on_desktop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lld29/how_to_save_telegram_protected_files_on_desktop/", "subreddit_subscribers": 690223, "created_utc": 1687986866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, \n\nI am looking for a FREE cloud storage provider who allows to mount the storage directly to a linux server to use as a backup for sql dumps. \n\nDatabase files are rather small and I certainly dont mind paying, its just I can fit within free tier of most providers easily. Looking for one with the mount support like I described.\n\n&amp;#x200B;\n\nDont want:   \nMega (dont allow for mount. require using their cmd tool which sucks big time)  \ngdrive (not really a server friendly solution)  \nMicrosoft (I hate Microsoft)  \npCloud (nice but their tool cannot be compiled successfully for some reason.. wish it would but hoping to find alternative here)  \n[Sync.com](https://Sync.com) (very bad reputation.. feel free to change my mind, I have no personal experience with this service. I just read some stuff on reddit about it and it gave me a bad vibes)  \n\n\nthanks!", "author_fullname": "t2_elz9khng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a free and safe place to keep database backups (small files)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m9nuw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688056555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I am looking for a FREE cloud storage provider who allows to mount the storage directly to a linux server to use as a backup for sql dumps. &lt;/p&gt;\n\n&lt;p&gt;Database files are rather small and I certainly dont mind paying, its just I can fit within free tier of most providers easily. Looking for one with the mount support like I described.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Dont want:&lt;br/&gt;\nMega (dont allow for mount. require using their cmd tool which sucks big time)&lt;br/&gt;\ngdrive (not really a server friendly solution)&lt;br/&gt;\nMicrosoft (I hate Microsoft)&lt;br/&gt;\npCloud (nice but their tool cannot be compiled successfully for some reason.. wish it would but hoping to find alternative here)&lt;br/&gt;\n&lt;a href=\"https://Sync.com\"&gt;Sync.com&lt;/a&gt; (very bad reputation.. feel free to change my mind, I have no personal experience with this service. I just read some stuff on reddit about it and it gave me a bad vibes)  &lt;/p&gt;\n\n&lt;p&gt;thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m9nuw", "is_robot_indexable": true, "report_reasons": null, "author": "madroots2", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m9nuw/looking_for_a_free_and_safe_place_to_keep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m9nuw/looking_for_a_free_and_safe_place_to_keep/", "subreddit_subscribers": 690223, "created_utc": 1688056555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm not sure what to use to preserve about 500gb-1tb of videos and maybe a bit of music:\n\nI was considering SSDs but they're known to fail, despite there being the chance that they could last over ten years. That's the sort of timeframe I would like - decades. At least one decade. Specifically I was considering the Sandisk Extreme and Samsung T7 which seem a popular choice for casual use but they may last three to five years. If that's the case, then I'd like to reconsider. I just don't want to risk losing it all, or paying for both the initial storage and a backup. Would cloud storage be reasonable? I mean, paid cloud storage so that there's a bit of security for something so non-physical. I don't know if cloud storage would have longevity either but I feel like it would - Google Drive has been pretty consistent.\n\nI don't have too much money I would like to spend but I can always spend more if there's a high chance of longevity. I've also heard of m-discs but I don't have a disk player on my computer.\n\nCurrently my files are spread across numerous USBs and I know that they are quite short-term, hence their incredibly low price.", "author_fullname": "t2_c39ycuca", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Long-term Archiving", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m8ild", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688053831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not sure what to use to preserve about 500gb-1tb of videos and maybe a bit of music:&lt;/p&gt;\n\n&lt;p&gt;I was considering SSDs but they&amp;#39;re known to fail, despite there being the chance that they could last over ten years. That&amp;#39;s the sort of timeframe I would like - decades. At least one decade. Specifically I was considering the Sandisk Extreme and Samsung T7 which seem a popular choice for casual use but they may last three to five years. If that&amp;#39;s the case, then I&amp;#39;d like to reconsider. I just don&amp;#39;t want to risk losing it all, or paying for both the initial storage and a backup. Would cloud storage be reasonable? I mean, paid cloud storage so that there&amp;#39;s a bit of security for something so non-physical. I don&amp;#39;t know if cloud storage would have longevity either but I feel like it would - Google Drive has been pretty consistent.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have too much money I would like to spend but I can always spend more if there&amp;#39;s a high chance of longevity. I&amp;#39;ve also heard of m-discs but I don&amp;#39;t have a disk player on my computer.&lt;/p&gt;\n\n&lt;p&gt;Currently my files are spread across numerous USBs and I know that they are quite short-term, hence their incredibly low price.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m8ild", "is_robot_indexable": true, "report_reasons": null, "author": "queenofthehours1971", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m8ild/longterm_archiving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m8ild/longterm_archiving/", "subreddit_subscribers": 690223, "created_utc": 1688053831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "On my windowa laptop i use Wincatalog for cataloguing external hard disks. But on my mac book I have not found any good software so far for this. Please suggest. If it is cheap or free it would be bonus. But dont have a problem paying for a really good software.", "author_fullname": "t2_8x9iq4z6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mac Software for Cataloguing External Hard Disks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m3zge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688042405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On my windowa laptop i use Wincatalog for cataloguing external hard disks. But on my mac book I have not found any good software so far for this. Please suggest. If it is cheap or free it would be bonus. But dont have a problem paying for a really good software.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m3zge", "is_robot_indexable": true, "report_reasons": null, "author": "general_smooth", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m3zge/mac_software_for_cataloguing_external_hard_disks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m3zge/mac_software_for_cataloguing_external_hard_disks/", "subreddit_subscribers": 690223, "created_utc": 1688042405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If you check out WD's product page: https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-blue-hdd/product-brief-western-digital-wd-blue-pc-hdd.pdf\n\nand Amazon product page: https://www.amazon.com/dp/B0BNGL4BND?th=1\n\nthe newest models of all WD Blue desktop drives are all CMR:\n\n* 2TB: WD20EARZ\n* 3TB: WD20EZAX\n* 4TB: WD40EZAX\n* 6TB: WD60EZAX\n* 8TB: WD80EAZZ (always has been CMR tho)", "author_fullname": "t2_fzwj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looks like WD Blue drives are changing back to CMR", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ltc7b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688007836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you check out WD&amp;#39;s product page: &lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-blue-hdd/product-brief-western-digital-wd-blue-pc-hdd.pdf\"&gt;https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-blue-hdd/product-brief-western-digital-wd-blue-pc-hdd.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;and Amazon product page: &lt;a href=\"https://www.amazon.com/dp/B0BNGL4BND?th=1\"&gt;https://www.amazon.com/dp/B0BNGL4BND?th=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;the newest models of all WD Blue desktop drives are all CMR:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;2TB: WD20EARZ&lt;/li&gt;\n&lt;li&gt;3TB: WD20EZAX&lt;/li&gt;\n&lt;li&gt;4TB: WD40EZAX&lt;/li&gt;\n&lt;li&gt;6TB: WD60EZAX&lt;/li&gt;\n&lt;li&gt;8TB: WD80EAZZ (always has been CMR tho)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1TB = 0.909495TiB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14ltc7b", "is_robot_indexable": true, "report_reasons": null, "author": "HTWingNut", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14ltc7b/looks_like_wd_blue_drives_are_changing_back_to_cmr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14ltc7b/looks_like_wd_blue_drives_are_changing_back_to_cmr/", "subreddit_subscribers": 690223, "created_utc": 1688007836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I am uploading 4TB worth of files from my WD My Passport External HDD. Im uploading it to Backblaze.\n\nDuring the upload process, will my external HDD continue spinning? I understand that it will take some time to finish, is it okay to leave my hdd on for a day or two?", "author_fullname": "t2_5t4wm6o5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uploading from portable external hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14me2i6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688067050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am uploading 4TB worth of files from my WD My Passport External HDD. Im uploading it to Backblaze.&lt;/p&gt;\n\n&lt;p&gt;During the upload process, will my external HDD continue spinning? I understand that it will take some time to finish, is it okay to leave my hdd on for a day or two?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14me2i6", "is_robot_indexable": true, "report_reasons": null, "author": "linothefourth", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14me2i6/uploading_from_portable_external_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14me2i6/uploading_from_portable_external_hard_drive/", "subreddit_subscribers": 690223, "created_utc": 1688067050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a few really large movie files that don't play in my crappy  laptop. On my tv though they play without any problems. I just want a way to play them in my laptop so I can verify if the subtitles are in sync. So basically it has to be the fastest way possible to create another file much smaller just so I can do this, and then I would delete the small files and play the big ones on tv with the subtitle already synchronized.", "author_fullname": "t2_1kncv7m0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fastest way to reduce file size? No problem in reducing video quality at all", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14mdtvv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688066477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few really large movie files that don&amp;#39;t play in my crappy  laptop. On my tv though they play without any problems. I just want a way to play them in my laptop so I can verify if the subtitles are in sync. So basically it has to be the fastest way possible to create another file much smaller just so I can do this, and then I would delete the small files and play the big ones on tv with the subtitle already synchronized.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14mdtvv", "is_robot_indexable": true, "report_reasons": null, "author": "rollingcircus123", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14mdtvv/fastest_way_to_reduce_file_size_no_problem_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14mdtvv/fastest_way_to_reduce_file_size_no_problem_in/", "subreddit_subscribers": 690223, "created_utc": 1688066477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently got an external HDD (WD elements 16TB), and I'm mainly using it for my plex server. I upgraded from an external seagate 5TB, which was a 2.5 inches. When I used my old 5TB drive, it didn't have any boot time (or none that I could notice), but my 16TB takes about 10 seconds to boot up. It starts making this noise, which I know is normal by reading other posts on this sub.\n\nNow my problem is that the drive seems to \"sleep\" every 20 min or so (or maybe less). I'm noticing this because whenever I'm using plex and pick an episode to watch, the drive boot up sounds start, and I'm waiting around 10 sec for the episode to start. And then when I want to go for the next episode, it does the same thing. My episodes are around 20 min long, so after the drive reads the whole episode, and it's all cached on my plex media player (the client), the drive goes to sleep, and only turns back on when I'm going for the next episode.\n\nSo is there a way to increase the drive's sleep time? If I make it to be around 30 min, I should be fine, and it should never sleep when I'm using plex because the episode are only 20 min long. But I think that the manufacturer put this feature for a reason, and maybe it's for the longevity of the drive? I never had this issue on my 2.5 external seagate, so I don't know if the 2.5inch take less time to boot, or it's the 5TB vs 16TB size difference that causes this. So what do you suggest I do? I'd prefer making the sleep time longer, but if it would be bad for the drive's health, I can live with waiting 10 second before an episode starts.", "author_fullname": "t2_4bxhznee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD elements 16TB sleeps every 20min", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14mbh08", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688060881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently got an external HDD (WD elements 16TB), and I&amp;#39;m mainly using it for my plex server. I upgraded from an external seagate 5TB, which was a 2.5 inches. When I used my old 5TB drive, it didn&amp;#39;t have any boot time (or none that I could notice), but my 16TB takes about 10 seconds to boot up. It starts making this noise, which I know is normal by reading other posts on this sub.&lt;/p&gt;\n\n&lt;p&gt;Now my problem is that the drive seems to &amp;quot;sleep&amp;quot; every 20 min or so (or maybe less). I&amp;#39;m noticing this because whenever I&amp;#39;m using plex and pick an episode to watch, the drive boot up sounds start, and I&amp;#39;m waiting around 10 sec for the episode to start. And then when I want to go for the next episode, it does the same thing. My episodes are around 20 min long, so after the drive reads the whole episode, and it&amp;#39;s all cached on my plex media player (the client), the drive goes to sleep, and only turns back on when I&amp;#39;m going for the next episode.&lt;/p&gt;\n\n&lt;p&gt;So is there a way to increase the drive&amp;#39;s sleep time? If I make it to be around 30 min, I should be fine, and it should never sleep when I&amp;#39;m using plex because the episode are only 20 min long. But I think that the manufacturer put this feature for a reason, and maybe it&amp;#39;s for the longevity of the drive? I never had this issue on my 2.5 external seagate, so I don&amp;#39;t know if the 2.5inch take less time to boot, or it&amp;#39;s the 5TB vs 16TB size difference that causes this. So what do you suggest I do? I&amp;#39;d prefer making the sleep time longer, but if it would be bad for the drive&amp;#39;s health, I can live with waiting 10 second before an episode starts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14mbh08", "is_robot_indexable": true, "report_reasons": null, "author": "MoonlessNightss", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14mbh08/wd_elements_16tb_sleeps_every_20min/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14mbh08/wd_elements_16tb_sleeps_every_20min/", "subreddit_subscribers": 690223, "created_utc": 1688060881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it possible that I only select the two HDDs in my system for RAID 1 to store and backup my data while keeping my SSD only for programs and OS?\n\nAlso can I add new drives without adding them to the RAID setup?  \nI'm new to RAID...\n\nThe two HDDs are 2TB 7200rpm drives if that matters while my SSD is an m.2 1TB.  \n", "author_fullname": "t2_21n9ijwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSI B450 Tomahawk Max Raid Setup (1 SSD without raid and 2 HDDs in RAID 1) possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ma9x1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688058046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible that I only select the two HDDs in my system for RAID 1 to store and backup my data while keeping my SSD only for programs and OS?&lt;/p&gt;\n\n&lt;p&gt;Also can I add new drives without adding them to the RAID setup?&lt;br/&gt;\nI&amp;#39;m new to RAID...&lt;/p&gt;\n\n&lt;p&gt;The two HDDs are 2TB 7200rpm drives if that matters while my SSD is an m.2 1TB.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14ma9x1", "is_robot_indexable": true, "report_reasons": null, "author": "NKkrisz", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14ma9x1/msi_b450_tomahawk_max_raid_setup_1_ssd_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14ma9x1/msi_b450_tomahawk_max_raid_setup_1_ssd_without/", "subreddit_subscribers": 690223, "created_utc": 1688058046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I came down with some kind of disease (it's still ongoing) where I scrubbed the marketplace on low hours, low on/off count 4TB HDDs. I currently have 5, with no signs of slowing down. They were mostly WD Purples and nighthawks (I know... but they were 36 bucks)\n\nI'm planning on deploying them on a trunas scale machine, just for general NAS usage and media center (with some HDD being offline backups of important files). Nothing high-performance (I only have gigabit ethernet, old dualcore machine) But I can't seem to find any guide on the pre-deployment process. Like what kind of diagnostics to do, what programs to use, best practices, what to look for, is it even worth it spending days diagnosing, etc. Right now I'm only relying on crystaldiskinfo which is really not in-depth.\n\nAny inputs would help tremendously. Hoping it can prevent some headaches I might encounter in the future had I not done them today. Thanks a lot! Happy hunting!", "author_fullname": "t2_1jo7anhj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a general guide/steps before deploying (used) HDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m1yz0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688036368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came down with some kind of disease (it&amp;#39;s still ongoing) where I scrubbed the marketplace on low hours, low on/off count 4TB HDDs. I currently have 5, with no signs of slowing down. They were mostly WD Purples and nighthawks (I know... but they were 36 bucks)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on deploying them on a trunas scale machine, just for general NAS usage and media center (with some HDD being offline backups of important files). Nothing high-performance (I only have gigabit ethernet, old dualcore machine) But I can&amp;#39;t seem to find any guide on the pre-deployment process. Like what kind of diagnostics to do, what programs to use, best practices, what to look for, is it even worth it spending days diagnosing, etc. Right now I&amp;#39;m only relying on crystaldiskinfo which is really not in-depth.&lt;/p&gt;\n\n&lt;p&gt;Any inputs would help tremendously. Hoping it can prevent some headaches I might encounter in the future had I not done them today. Thanks a lot! Happy hunting!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m1yz0", "is_robot_indexable": true, "report_reasons": null, "author": "rsnst", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m1yz0/looking_for_a_general_guidesteps_before_deploying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m1yz0/looking_for_a_general_guidesteps_before_deploying/", "subreddit_subscribers": 690223, "created_utc": 1688036368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am planning to build a NAS using a Pi4 running Rasbian light.\n\nI know I have different options, open media vault, FileCloud and NextCloud.\n\nMy main purpose is to back up photos automatically from the camera roll on iPhones, similar to Google photos.\n\nDo all three solutions support this? Which one has the better iOS app?\nThe setup will be super basic, I will just be mounting a 4tb hard drive to my Pi. \n \nThank you :-)", "author_fullname": "t2_ld9gl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best iOS photo backup on a Raspberry pi?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m1y0v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688036277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning to build a NAS using a Pi4 running Rasbian light.&lt;/p&gt;\n\n&lt;p&gt;I know I have different options, open media vault, FileCloud and NextCloud.&lt;/p&gt;\n\n&lt;p&gt;My main purpose is to back up photos automatically from the camera roll on iPhones, similar to Google photos.&lt;/p&gt;\n\n&lt;p&gt;Do all three solutions support this? Which one has the better iOS app?\nThe setup will be super basic, I will just be mounting a 4tb hard drive to my Pi. &lt;/p&gt;\n\n&lt;p&gt;Thank you :-)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m1y0v", "is_robot_indexable": true, "report_reasons": null, "author": "AlexKLMan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m1y0v/best_ios_photo_backup_on_a_raspberry_pi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m1y0v/best_ios_photo_backup_on_a_raspberry_pi/", "subreddit_subscribers": 690223, "created_utc": 1688036277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am in the process of ripping my dads CD collection wit EAC as mentioned in another post on this sub.   \n\n\nI would like to take the root folder and run it through a tool to fill in the metadata as well as embed the cover artwork, so when I play it via VLC on my chromecast, it displays both the artwork and the proper title and author.  \n\n\nIf it is any help I have the following folder structure:\n\n    CDs\n    \u251c\u2500\u2500 Album 1\n    \u2502   \u251c\u2500\u2500 Song 1.wav\n    \u2502   \u251c\u2500\u2500 Song 2.wav\n    \u2502   \u2514\u2500\u2500 Song 3.wav\n    \u251c\u2500\u2500 Album 2\n    \u2502   \u251c\u2500\u2500 Song 1.wav\n    \u2502   \u251c\u2500\u2500 Song 2.wav\n    \u2502   \u2514\u2500\u2500 Song 3.wav\n    \u2514\u2500\u2500 Album 3\n        \u251c\u2500\u2500 Song 1.wav\n        \u251c\u2500\u2500 Song 2.wav\n        \u2514\u2500\u2500 Song 3.wav\n\n&amp;#x200B;", "author_fullname": "t2_3umnofow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A way to get CD metadata and artwork", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m10d1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688033110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am in the process of ripping my dads CD collection wit EAC as mentioned in another post on this sub.   &lt;/p&gt;\n\n&lt;p&gt;I would like to take the root folder and run it through a tool to fill in the metadata as well as embed the cover artwork, so when I play it via VLC on my chromecast, it displays both the artwork and the proper title and author.  &lt;/p&gt;\n\n&lt;p&gt;If it is any help I have the following folder structure:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CDs\n\u251c\u2500\u2500 Album 1\n\u2502   \u251c\u2500\u2500 Song 1.wav\n\u2502   \u251c\u2500\u2500 Song 2.wav\n\u2502   \u2514\u2500\u2500 Song 3.wav\n\u251c\u2500\u2500 Album 2\n\u2502   \u251c\u2500\u2500 Song 1.wav\n\u2502   \u251c\u2500\u2500 Song 2.wav\n\u2502   \u2514\u2500\u2500 Song 3.wav\n\u2514\u2500\u2500 Album 3\n    \u251c\u2500\u2500 Song 1.wav\n    \u251c\u2500\u2500 Song 2.wav\n    \u2514\u2500\u2500 Song 3.wav\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m10d1", "is_robot_indexable": true, "report_reasons": null, "author": "Arimodu", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m10d1/a_way_to_get_cd_metadata_and_artwork/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m10d1/a_way_to_get_cd_metadata_and_artwork/", "subreddit_subscribers": 690223, "created_utc": 1688033110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All,\n\nSo I have a Samsung 970Evo Plus less than a year old that started to fail.  I have a stable workstation since more than year and I recently added a rtx3090 for ML/Cuda work. Then by chance I noticed some failures on a btrfs partition that was not recognized anymore.\n\nI rebooted to a rescue session and I could confirm btrfs filesystem check errors. On this disk I have 3 btrfs partitions. One does not mount anymore and the two others have errors but still mounting. On the kernel messages I can clearly see the I/O errors during fs check. \n\nI turned off the system  until receiving a replacement disk. However I want to know what was the most likely reason for this ? \n\n1. I struggled a bit when I mounted the graphic card and probably physically touched this nvme disk but nothing extreme. Could it be due to shock ?\n\n2. The GPU was mounted on a PCIe slot right over this nvme slot which basically fully covered it. Could it be due to the heat ? \n\nIn any case I will probably change the GPU location far from the nvme slots but am curious what is the most probable reason ?\n\nEDIT:\n\nsince I was using this disk for the linux system using a btrfs partition + separate boot UEFI partition, my plan for replacing the new one was the following:\n\n- Clone the whole disk using Clonezilla \n- Then do an other `btrfs replace` on the btrfs partitions than can be mounted from old to new.\n- than try a btrfs recovery on the cloned but non mountable broken btrfs partition\n\n\nIs this a good strategy ?", "author_fullname": "t2_dm4m2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "nvme hw failures after installing GPU right over it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lz83z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688046132.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688026945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;So I have a Samsung 970Evo Plus less than a year old that started to fail.  I have a stable workstation since more than year and I recently added a rtx3090 for ML/Cuda work. Then by chance I noticed some failures on a btrfs partition that was not recognized anymore.&lt;/p&gt;\n\n&lt;p&gt;I rebooted to a rescue session and I could confirm btrfs filesystem check errors. On this disk I have 3 btrfs partitions. One does not mount anymore and the two others have errors but still mounting. On the kernel messages I can clearly see the I/O errors during fs check. &lt;/p&gt;\n\n&lt;p&gt;I turned off the system  until receiving a replacement disk. However I want to know what was the most likely reason for this ? &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I struggled a bit when I mounted the graphic card and probably physically touched this nvme disk but nothing extreme. Could it be due to shock ?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The GPU was mounted on a PCIe slot right over this nvme slot which basically fully covered it. Could it be due to the heat ? &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;In any case I will probably change the GPU location far from the nvme slots but am curious what is the most probable reason ?&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;since I was using this disk for the linux system using a btrfs partition + separate boot UEFI partition, my plan for replacing the new one was the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Clone the whole disk using Clonezilla &lt;/li&gt;\n&lt;li&gt;Then do an other &lt;code&gt;btrfs replace&lt;/code&gt; on the btrfs partitions than can be mounted from old to new.&lt;/li&gt;\n&lt;li&gt;than try a btrfs recovery on the cloned but non mountable broken btrfs partition&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is this a good strategy ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lz83z", "is_robot_indexable": true, "report_reasons": null, "author": "use_your_imagination", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lz83z/nvme_hw_failures_after_installing_gpu_right_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lz83z/nvme_hw_failures_after_installing_gpu_right_over/", "subreddit_subscribers": 690223, "created_utc": 1688026945.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_hbwoyw04", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I hate so much the fact that it's so complicated to know if it's an SMR or CMR drive, can you help me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14lkxqh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/wn8k0DT06YS1KSXZ48t8QRY7U-mqp4vjXqQmol91hEU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687985892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "serverpartdeals.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://serverpartdeals.com/collections/hard-drives/products/seagate-exos-x22-st22000nm001e-3hm103-001-22tb-7-2k-rpm-sata-6gb-s-512e-3-5-recertified-hard-drive", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?auto=webp&amp;v=enabled&amp;s=1bec9f5e789e131b4d3063b2708b4de7c92ef0f4", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd945ca82a48b834144e1604904e1dbb54e660aa", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=72f934f9a2ff494d22e5ea3dfc3b95401de4eaf5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=defe19f6d9e7fccb6270b79abdedd031f0b52588", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a99f342ffc6db007cecf8edba49702207c42dcce", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3f0c071e64fd0f6f03e1b333789cb856be245b10", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/MxFyTF2tLYDAtAyjo-NYGxUFQneekTTezMK0LGT0o3M.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88d63dece55ac3ec31e972fa2ed63c4a5f27671c", "width": 1080, "height": 1080}], "variants": {}, "id": "3ccPDPuPGsR3ww0JLnwJyAFLMYAJgaaJqsmBa3t1Dj8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lkxqh", "is_robot_indexable": true, "report_reasons": null, "author": "igmyeongui", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lkxqh/i_hate_so_much_the_fact_that_its_so_complicated/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://serverpartdeals.com/collections/hard-drives/products/seagate-exos-x22-st22000nm001e-3hm103-001-22tb-7-2k-rpm-sata-6gb-s-512e-3-5-recertified-hard-drive", "subreddit_subscribers": 690223, "created_utc": 1687985892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey, so, I'm trying to compile a database of different types of repair shops for my state from a google maps search. I tried octoparse and scrapstorm but both required a membership to export. Looking for options that don't. ", "author_fullname": "t2_bzpr9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good free scraper?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lvyz2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688015815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, so, I&amp;#39;m trying to compile a database of different types of repair shops for my state from a google maps search. I tried octoparse and scrapstorm but both required a membership to export. Looking for options that don&amp;#39;t. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lvyz2", "is_robot_indexable": true, "report_reasons": null, "author": "heather-gray", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lvyz2/good_free_scraper/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lvyz2/good_free_scraper/", "subreddit_subscribers": 690223, "created_utc": 1688015815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a Netapp DS426 connected to my HP DL360 G9. The Netapp has 2x IOM6's and 2 PSU's\n\nI would like to lower the power consumption, even by a few watts since it does run 24/7. I'm only using SATA drives and my OS is Unraid.\n\nI have noticed if I unplug one of the IOM's the fans ramp up to ridiculously noisy levels. is there a way I can make it not do that? I hear you can buy blanks to stop that from happening but I don't see how that works as simply pulling the level to remove the IOM, but not actually taking it out, jacks the fan speeds up. Also I quick look up on ebay, they are super expensive, due to shipping to Australia\n\nI have also read that swapping the power supplies for some Dell 80+ units can lower power consumption. I couldn't find a model number I could google. Also I'm not opposed to opening some power supplies (I know this can be dangerous) and dropping some quieter fans in.  \n\n\nAny links/info would greatly be appreciated.", "author_fullname": "t2_d2w78", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Netapp DS4246 reduce power consumption/noise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lrxtu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688003835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Netapp DS426 connected to my HP DL360 G9. The Netapp has 2x IOM6&amp;#39;s and 2 PSU&amp;#39;s&lt;/p&gt;\n\n&lt;p&gt;I would like to lower the power consumption, even by a few watts since it does run 24/7. I&amp;#39;m only using SATA drives and my OS is Unraid.&lt;/p&gt;\n\n&lt;p&gt;I have noticed if I unplug one of the IOM&amp;#39;s the fans ramp up to ridiculously noisy levels. is there a way I can make it not do that? I hear you can buy blanks to stop that from happening but I don&amp;#39;t see how that works as simply pulling the level to remove the IOM, but not actually taking it out, jacks the fan speeds up. Also I quick look up on ebay, they are super expensive, due to shipping to Australia&lt;/p&gt;\n\n&lt;p&gt;I have also read that swapping the power supplies for some Dell 80+ units can lower power consumption. I couldn&amp;#39;t find a model number I could google. Also I&amp;#39;m not opposed to opening some power supplies (I know this can be dangerous) and dropping some quieter fans in.  &lt;/p&gt;\n\n&lt;p&gt;Any links/info would greatly be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lrxtu", "is_robot_indexable": true, "report_reasons": null, "author": "Ziogref", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lrxtu/netapp_ds4246_reduce_power_consumptionnoise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lrxtu/netapp_ds4246_reduce_power_consumptionnoise/", "subreddit_subscribers": 690223, "created_utc": 1688003835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://www.amazon.ca/Sabrent-External-Lay-Flat-Docking-EC-DFLT/dp/B00LS5NFQ2/ref=asc_df_B00LS5NFQ2/?tag=googlemobshop-20&amp;linkCode=df0&amp;hvadid=326972463096&amp;hvpos=&amp;hvnetw=g&amp;hvrand=11174736066399861552&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=m&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9000762&amp;hvtargid=pla-365069372813&amp;psc=1\n\nI just bought a new HDD because I need more space on my PC only to find out that I can\u2019t install it inside so I was looking at getting this. Is it any good? And also, is it worth spending the extra little bit to get the fan version?", "author_fullname": "t2_4zfembme", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone have any experience with this docking station?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lpl3q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687997328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.amazon.ca/Sabrent-External-Lay-Flat-Docking-EC-DFLT/dp/B00LS5NFQ2/ref=asc_df_B00LS5NFQ2/?tag=googlemobshop-20&amp;amp;linkCode=df0&amp;amp;hvadid=326972463096&amp;amp;hvpos=&amp;amp;hvnetw=g&amp;amp;hvrand=11174736066399861552&amp;amp;hvpone=&amp;amp;hvptwo=&amp;amp;hvqmt=&amp;amp;hvdev=m&amp;amp;hvdvcmdl=&amp;amp;hvlocint=&amp;amp;hvlocphy=9000762&amp;amp;hvtargid=pla-365069372813&amp;amp;psc=1\"&gt;https://www.amazon.ca/Sabrent-External-Lay-Flat-Docking-EC-DFLT/dp/B00LS5NFQ2/ref=asc_df_B00LS5NFQ2/?tag=googlemobshop-20&amp;amp;linkCode=df0&amp;amp;hvadid=326972463096&amp;amp;hvpos=&amp;amp;hvnetw=g&amp;amp;hvrand=11174736066399861552&amp;amp;hvpone=&amp;amp;hvptwo=&amp;amp;hvqmt=&amp;amp;hvdev=m&amp;amp;hvdvcmdl=&amp;amp;hvlocint=&amp;amp;hvlocphy=9000762&amp;amp;hvtargid=pla-365069372813&amp;amp;psc=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I just bought a new HDD because I need more space on my PC only to find out that I can\u2019t install it inside so I was looking at getting this. Is it any good? And also, is it worth spending the extra little bit to get the fan version?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lpl3q", "is_robot_indexable": true, "report_reasons": null, "author": "Zoo_town", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lpl3q/anyone_have_any_experience_with_this_docking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lpl3q/anyone_have_any_experience_with_this_docking/", "subreddit_subscribers": 690223, "created_utc": 1687997328.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have (4) 2.5\" external drives but they are 15mm and I cannot find a bay\n\nI found this https://www.amazon.com/dp/B07VMK6ND7/\n\nI would like it for 2.5\" only but I have yet to find one", "author_fullname": "t2_lzwh7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help looking for a hard drive bay for 2.5", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lovdw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687995490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have (4) 2.5&amp;quot; external drives but they are 15mm and I cannot find a bay&lt;/p&gt;\n\n&lt;p&gt;I found this &lt;a href=\"https://www.amazon.com/dp/B07VMK6ND7/\"&gt;https://www.amazon.com/dp/B07VMK6ND7/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I would like it for 2.5&amp;quot; only but I have yet to find one&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lovdw", "is_robot_indexable": true, "report_reasons": null, "author": "cmdrmcgarrett", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lovdw/need_help_looking_for_a_hard_drive_bay_for_25/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lovdw/need_help_looking_for_a_hard_drive_bay_for_25/", "subreddit_subscribers": 690223, "created_utc": 1687995490.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}