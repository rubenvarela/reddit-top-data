{"kind": "Listing", "data": {"after": "t3_14m6etv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With all of the buzz around the high costs of various platforms and tools used for building data pipelines, including data collection, data warehousing, data processing and transformation, extracting insights out of the data - \n\nWhich are the most inefficient, ineffective, expensive products that you have experienced?\n\nTop 5 or 10 products listicles in various categories are just paid marketing campaigns and provide biased information.\n\nWhat is the tribal wisdom about the worst offenders in data tools and platforms that you would recommend staying away from and why?\n\nShare away and help the budding data engineers out.", "author_fullname": "t2_6pheknqy6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which are the most inefficient, ineffective, expensive tools in your data stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ltv6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 65, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 65, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688009399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With all of the buzz around the high costs of various platforms and tools used for building data pipelines, including data collection, data warehousing, data processing and transformation, extracting insights out of the data - &lt;/p&gt;\n\n&lt;p&gt;Which are the most inefficient, ineffective, expensive products that you have experienced?&lt;/p&gt;\n\n&lt;p&gt;Top 5 or 10 products listicles in various categories are just paid marketing campaigns and provide biased information.&lt;/p&gt;\n\n&lt;p&gt;What is the tribal wisdom about the worst offenders in data tools and platforms that you would recommend staying away from and why?&lt;/p&gt;\n\n&lt;p&gt;Share away and help the budding data engineers out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14ltv6p", "is_robot_indexable": true, "report_reasons": null, "author": "drc1728", "discussion_type": null, "num_comments": 145, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14ltv6p/which_are_the_most_inefficient_ineffective/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14ltv6p/which_are_the_most_inefficient_ineffective/", "subreddit_subscribers": 113032, "created_utc": 1688009399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I am still a newbie. I have a python project where I am scraping data from some log files on a daily basis and cleaning it then pushing it to db. I have scheduled this project to run daily on windows task scheduler. Is there any other(better) way it can be scheduled on a windows system?", "author_fullname": "t2_1js9ugwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I schedule python ETL code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lu0dk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688009808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am still a newbie. I have a python project where I am scraping data from some log files on a daily basis and cleaning it then pushing it to db. I have scheduled this project to run daily on windows task scheduler. Is there any other(better) way it can be scheduled on a windows system?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lu0dk", "is_robot_indexable": true, "report_reasons": null, "author": "Rawvik", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lu0dk/how_can_i_schedule_python_etl_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lu0dk/how_can_i_schedule_python_etl_code/", "subreddit_subscribers": 113032, "created_utc": 1688009808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Event-driven architecture best practices for databases and files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14m7hqv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/WTOJsEP0Rq5B1qL_kKqfQ1YGjuTP2-adTlM2QKTxF08.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688051403.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tbrd.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://tbrd.co/event-driven-rd", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?auto=webp&amp;v=enabled&amp;s=f07418903d601b5c94f23174f94ef0a2a98ea701", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=34571a0268eff0b3a64ecf4b9c470bb7e6b06118", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c786a9e2dbbc1d0e2d5badf6476728fc35be3495", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a811005ee7b75d95e4e6beb57341ee7564b95d8f", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be5288509bf3e53a34b6a50b3d296b9c0787795b", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8d6ca159b059f846d0efa50825649bfb601b8457", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/hrofVjV5_13ajYPVmStPDsOdGAyKSduQhkQ_EmqdUGQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=95f59b0ec379c3314e9fe1e2d8fb71350ee965f0", "width": 1080, "height": 567}], "variants": {}, "id": "RwmfZSh5NCQ_MukD79s6jkdRZRfQvX6cHfjXu1xJKFI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14m7hqv", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m7hqv/eventdriven_architecture_best_practices_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tbrd.co/event-driven-rd", "subreddit_subscribers": 113032, "created_utc": 1688051403.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "These are all boiler plate concerns and just seeking an open dialogue on advice. \n\nI have worked at multiple startups as a data engineer and run successful data warehouses. I write and follow standards, procedures, and best practices. Typically ive worked solo or with one other person. I am proud of the data platforms I have created. \n\nI am starting a new project as a consultant next week with a well known billion dollar company that I cant disclose. Im a little nervous because my past projects have been significantly less data than in the past. I work with snowflake. What do I need to be prepared for when working at scale. I.e I previously have worked with fact tables 500k-1M rows, now will be working with MM and billion row tables. \n\nI consider myself good at optimizing queries and I hope the power of larger snowflake warehouses will be of assistance. I am the lead engineer on the project so want to be as ready as possible for the transition from a small warehouse to a large warehouse. \n\nAnything helps! Thanks!", "author_fullname": "t2_6iq3gwld9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First DE gig at large scale", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lwjf0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688017626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;These are all boiler plate concerns and just seeking an open dialogue on advice. &lt;/p&gt;\n\n&lt;p&gt;I have worked at multiple startups as a data engineer and run successful data warehouses. I write and follow standards, procedures, and best practices. Typically ive worked solo or with one other person. I am proud of the data platforms I have created. &lt;/p&gt;\n\n&lt;p&gt;I am starting a new project as a consultant next week with a well known billion dollar company that I cant disclose. Im a little nervous because my past projects have been significantly less data than in the past. I work with snowflake. What do I need to be prepared for when working at scale. I.e I previously have worked with fact tables 500k-1M rows, now will be working with MM and billion row tables. &lt;/p&gt;\n\n&lt;p&gt;I consider myself good at optimizing queries and I hope the power of larger snowflake warehouses will be of assistance. I am the lead engineer on the project so want to be as ready as possible for the transition from a small warehouse to a large warehouse. &lt;/p&gt;\n\n&lt;p&gt;Anything helps! Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14lwjf0", "is_robot_indexable": true, "report_reasons": null, "author": "ElephantCorrect2132", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lwjf0/first_de_gig_at_large_scale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lwjf0/first_de_gig_at_large_scale/", "subreddit_subscribers": 113032, "created_utc": 1688017626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "pyspark-ai: English SDK for Apache Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_14m8ze6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tmDbKdWKv3ioGmEGtEHXWw0CENZ2A6XE_xYTo8pJ0xw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688054926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/databrickslabs/pyspark-ai/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/czJMbwxp2uqnLLJ4ISBRaCju2qyLxBrd-4XbC3Coviw.jpg?auto=webp&amp;v=enabled&amp;s=43812a8b27435746383a11413d2b660a0488de00", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/czJMbwxp2uqnLLJ4ISBRaCju2qyLxBrd-4XbC3Coviw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c07cbad04c935a7fab2e782b4073fabd64d02284", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/czJMbwxp2uqnLLJ4ISBRaCju2qyLxBrd-4XbC3Coviw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a618ad65cb7824d926bfb6e75ec5a04db8f855eb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/czJMbwxp2uqnLLJ4ISBRaCju2qyLxBrd-4XbC3Coviw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d95abe4b1180c1800ab8b1b8bd26b001237c6814", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/czJMbwxp2uqnLLJ4ISBRaCju2qyLxBrd-4XbC3Coviw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8a6a69f33eea9d4f5dd379507c7b061ad2f3755", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/czJMbwxp2uqnLLJ4ISBRaCju2qyLxBrd-4XbC3Coviw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2035ee410ff696fbb8c5bcb32607a15ec2301bcc", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/czJMbwxp2uqnLLJ4ISBRaCju2qyLxBrd-4XbC3Coviw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7fbc7ca990b809187ffd77d82cf366cab41b2026", "width": 1080, "height": 540}], "variants": {}, "id": "5UKpPdDxQshhEjaRqo1XR7SAnbFVrVSY7ZiUJ_doCWA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "14m8ze6", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m8ze6/pysparkai_english_sdk_for_apache_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/databrickslabs/pyspark-ai/", "subreddit_subscribers": 113032, "created_utc": 1688054926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I have recently started using Delta tables with Pyspark and AWS S3 storage.\n\nI am doing a merge into my Delta table, with conditions for update and insert.\n\nI have some test data that does not change between runs, so I was expecting the merge to be idempotent, meaning: two subsequent merges should not write any data to S3.\n\n&amp;#x200B;\n\nHowever, when I run the merge statement, most of the delta table is re-written.\n\nEven stranger,  when I check the Delta table's history, I verify that 0 rows were inserted, 0 rows were updated, and 0 rows were deleted - but also that 70 files were removed and 70 fliles were added (corresponding to most of my dataset).\n\nAny ideas why this might be the case? Thank you!", "author_fullname": "t2_8xg3h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Delta merge is writing data, even though there are no inserts or updates?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lnprw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687992523.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have recently started using Delta tables with Pyspark and AWS S3 storage.&lt;/p&gt;\n\n&lt;p&gt;I am doing a merge into my Delta table, with conditions for update and insert.&lt;/p&gt;\n\n&lt;p&gt;I have some test data that does not change between runs, so I was expecting the merge to be idempotent, meaning: two subsequent merges should not write any data to S3.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;However, when I run the merge statement, most of the delta table is re-written.&lt;/p&gt;\n\n&lt;p&gt;Even stranger,  when I check the Delta table&amp;#39;s history, I verify that 0 rows were inserted, 0 rows were updated, and 0 rows were deleted - but also that 70 files were removed and 70 fliles were added (corresponding to most of my dataset).&lt;/p&gt;\n\n&lt;p&gt;Any ideas why this might be the case? Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lnprw", "is_robot_indexable": true, "report_reasons": null, "author": "Fredbull", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lnprw/delta_merge_is_writing_data_even_though_there_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lnprw/delta_merge_is_writing_data_even_though_there_are/", "subreddit_subscribers": 113032, "created_utc": 1687992523.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would very much appreciate some advice.\n\nWe have a ton of historic semi-structured data which is stored in JSON. I say semi-structured because the structure has been expanded over the years, so the schema is not fixed over time, even if the major dimensions have not changed, the key figures have expanded.\n\nWe have probably records rows a day of JSON for the last 5 years, so 2m records. Each JSON record could be as much as a few kb. Maybe a few GB total, at the very most.\n\nIs there a product (ideally cloud) which is well suited to really easily importing this data and enabling us to do some basic time series analysis? I need some quick and dirty analysis and want to avoid a big data warehouse project. Doesn't matter if it's a commercial or open source product.\n\nBack in the day I used MongoDB to do things like this, but maybe there are better options now?", "author_fullname": "t2_pfwmnuy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data mart for semi-structured JSON data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m4bmf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688043350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would very much appreciate some advice.&lt;/p&gt;\n\n&lt;p&gt;We have a ton of historic semi-structured data which is stored in JSON. I say semi-structured because the structure has been expanded over the years, so the schema is not fixed over time, even if the major dimensions have not changed, the key figures have expanded.&lt;/p&gt;\n\n&lt;p&gt;We have probably records rows a day of JSON for the last 5 years, so 2m records. Each JSON record could be as much as a few kb. Maybe a few GB total, at the very most.&lt;/p&gt;\n\n&lt;p&gt;Is there a product (ideally cloud) which is well suited to really easily importing this data and enabling us to do some basic time series analysis? I need some quick and dirty analysis and want to avoid a big data warehouse project. Doesn&amp;#39;t matter if it&amp;#39;s a commercial or open source product.&lt;/p&gt;\n\n&lt;p&gt;Back in the day I used MongoDB to do things like this, but maybe there are better options now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14m4bmf", "is_robot_indexable": true, "report_reasons": null, "author": "thebemusedmuse", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m4bmf/data_mart_for_semistructured_json_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m4bmf/data_mart_for_semistructured_json_data/", "subreddit_subscribers": 113032, "created_utc": 1688043350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What do you guys think of dagsters new pricing model? I am pretty new to dagster and the pricing model just changed during trial.\nWith the Team Subscription, you have 10000 Credits available, which means 330 asset matrializations a day, which seems pretty low when you have a lot of small assets you are materializing daily. Materializing one asset every 10min gets you 150 already. Do I have a  wrong understanding of this?", "author_fullname": "t2_1jlb0188", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dagster Cloud Pricing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lk206", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687983809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you guys think of dagsters new pricing model? I am pretty new to dagster and the pricing model just changed during trial.\nWith the Team Subscription, you have 10000 Credits available, which means 330 asset matrializations a day, which seems pretty low when you have a lot of small assets you are materializing daily. Materializing one asset every 10min gets you 150 already. Do I have a  wrong understanding of this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lk206", "is_robot_indexable": true, "report_reasons": null, "author": "KindaRoot", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lk206/dagster_cloud_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lk206/dagster_cloud_pricing/", "subreddit_subscribers": 113032, "created_utc": 1687983809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been at my current job for 7 years. It\u2019s a small team (3 devs) maintaining. SaaS CRM for 1000 users at a $7billion company.\n\nMy development work consists of creating new screens in the web app with handlebars / JQuery / JavaScript, writing Rest API calls for other teams and passing them the postman file or working on Azure Synapse (spark) pipelines, the Azure SQL DB (stored procedures, views, etc)\n\nI pretty much feel like it\u2019s a Jack of all\nTrades situation.  Anything that comes up no matter l, what gets thrown at us devs.  If I update my Linked In to say Data Engineer it goes dark as I suspect not many companies use Azure SQL and Synapse and when I update it to Full Stack Developer or similar I get a lot of hits from people wanting me to work in the same CRM(D365) for them.  \n\nIf I\u2019m trying to target a new DE role somewhere should I drop all the front end Dev work stuff off my linked in and just write about the data work?  Any advice on how to parlay my Synapse / Azure SQL experience into something else? My goal for a next position would just be pure DE so I\u2019m not also tweaking CSS and writing handlebar templates half the time.  \nThanks", "author_fullname": "t2_5yj82gi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you call yourself if you do both front end Dev and DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m6t8f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688049782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been at my current job for 7 years. It\u2019s a small team (3 devs) maintaining. SaaS CRM for 1000 users at a $7billion company.&lt;/p&gt;\n\n&lt;p&gt;My development work consists of creating new screens in the web app with handlebars / JQuery / JavaScript, writing Rest API calls for other teams and passing them the postman file or working on Azure Synapse (spark) pipelines, the Azure SQL DB (stored procedures, views, etc)&lt;/p&gt;\n\n&lt;p&gt;I pretty much feel like it\u2019s a Jack of all\nTrades situation.  Anything that comes up no matter l, what gets thrown at us devs.  If I update my Linked In to say Data Engineer it goes dark as I suspect not many companies use Azure SQL and Synapse and when I update it to Full Stack Developer or similar I get a lot of hits from people wanting me to work in the same CRM(D365) for them.  &lt;/p&gt;\n\n&lt;p&gt;If I\u2019m trying to target a new DE role somewhere should I drop all the front end Dev work stuff off my linked in and just write about the data work?  Any advice on how to parlay my Synapse / Azure SQL experience into something else? My goal for a next position would just be pure DE so I\u2019m not also tweaking CSS and writing handlebar templates half the time.&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14m6t8f", "is_robot_indexable": true, "report_reasons": null, "author": "Swimming_Cry_6841", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m6t8f/what_do_you_call_yourself_if_you_do_both_front/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m6t8f/what_do_you_call_yourself_if_you_do_both_front/", "subreddit_subscribers": 113032, "created_utc": 1688049782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2d54n17m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering and Analytics Day", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 100, "top_awarded_type": null, "hide_score": false, "name": "t3_14m951l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_zozgUg7wO9AOGRwGzLySODIRw1xYV8tOmYX2X3N8zE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688055311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cloudonair.withgoogle.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cloudonair.withgoogle.com/events/data-engineering-and-analytics-day", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hQ-MEFIdhnhPpFrSgNDadIulPVHYbQYpY0yAxuESqhk.jpg?auto=webp&amp;v=enabled&amp;s=488f9afa013c261087fc69470d9af45c4574fc5c", "width": 1120, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/hQ-MEFIdhnhPpFrSgNDadIulPVHYbQYpY0yAxuESqhk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=75595505fba1d2fcda864f238c87826e353f8c3e", "width": 108, "height": 77}, {"url": "https://external-preview.redd.it/hQ-MEFIdhnhPpFrSgNDadIulPVHYbQYpY0yAxuESqhk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c0313fd54e3df7b8638016b274d8b899f6cf984b", "width": 216, "height": 154}, {"url": "https://external-preview.redd.it/hQ-MEFIdhnhPpFrSgNDadIulPVHYbQYpY0yAxuESqhk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=28487f01d54bf757b83b0ac472a63d36bbbf73cb", "width": 320, "height": 228}, {"url": "https://external-preview.redd.it/hQ-MEFIdhnhPpFrSgNDadIulPVHYbQYpY0yAxuESqhk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=39c27819c34d0b9e6632f3e33716b19eef6d9774", "width": 640, "height": 457}, {"url": "https://external-preview.redd.it/hQ-MEFIdhnhPpFrSgNDadIulPVHYbQYpY0yAxuESqhk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5f5cf93d3481e565d401d30c2bd5d2752a21f4e0", "width": 960, "height": 685}, {"url": "https://external-preview.redd.it/hQ-MEFIdhnhPpFrSgNDadIulPVHYbQYpY0yAxuESqhk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=48932e092d52a15f033afe050631f0c1e95f4612", "width": 1080, "height": 771}], "variants": {}, "id": "CR2JxvH0T4D7Eseodx7vN_B3ov2g5QBOFdJintHYbIo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14m951l", "is_robot_indexable": true, "report_reasons": null, "author": "fmaina1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m951l/data_engineering_and_analytics_day/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cloudonair.withgoogle.com/events/data-engineering-and-analytics-day", "subreddit_subscribers": 113032, "created_utc": 1688055311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone else here? What are your thoughts so far?", "author_fullname": "t2_8y2a4hfy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Data + AI Summit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lw0op", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688015974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone else here? What are your thoughts so far?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lw0op", "is_robot_indexable": true, "report_reasons": null, "author": "Known-Delay7227", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lw0op/databricks_data_ai_summit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lw0op/databricks_data_ai_summit/", "subreddit_subscribers": 113032, "created_utc": 1688015974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are working on setting up our databricks environment (I\u2019m sure you\u2019ve seen my other posts) I am wondering how you guys use these \n\n- do you have one to many storage credentials to external locations or one to one? \n- do you specify external locations at the top most level of a bucket or to a folder hierarchy in the bucket? \n- how do external tables work with unity catalog? If I make a catalog/ schema with an external location, where is that catalog and schema?", "author_fullname": "t2_18qay50v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External tables, storage credentials, and Unity Catalog.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lqcqk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687999390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are working on setting up our databricks environment (I\u2019m sure you\u2019ve seen my other posts) I am wondering how you guys use these &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;do you have one to many storage credentials to external locations or one to one? &lt;/li&gt;\n&lt;li&gt;do you specify external locations at the top most level of a bucket or to a folder hierarchy in the bucket? &lt;/li&gt;\n&lt;li&gt;how do external tables work with unity catalog? If I make a catalog/ schema with an external location, where is that catalog and schema?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lqcqk", "is_robot_indexable": true, "report_reasons": null, "author": "Doyale_royale", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lqcqk/external_tables_storage_credentials_and_unity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lqcqk/external_tables_storage_credentials_and_unity/", "subreddit_subscribers": 113032, "created_utc": 1687999390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys,  \nAs i didn't find any resources describing the whole chain allowing to test deploying Airflow and Spark within a Kubernetes cluster.  \nI have wrote a description of the whole process to get it work in local.  \n[https://medium.com/p/869c6b48a026](https://medium.com/p/869c6b48a026)\n\nI hope this could help any begginer stucking on running Airflow and Apache Spark in a local machine.", "author_fullname": "t2_ae4tw1pnk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Airflow, Spark, and Kubernetes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14mc2m9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1688062286.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys,&lt;br/&gt;\nAs i didn&amp;#39;t find any resources describing the whole chain allowing to test deploying Airflow and Spark within a Kubernetes cluster.&lt;br/&gt;\nI have wrote a description of the whole process to get it work in local.&lt;br/&gt;\n&lt;a href=\"https://medium.com/p/869c6b48a026\"&gt;https://medium.com/p/869c6b48a026&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I hope this could help any begginer stucking on running Airflow and Apache Spark in a local machine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QYi-iUbo0f9piut-pcH5kjBpqw6QMfeuLZ6kf61bJ7U.jpg?auto=webp&amp;v=enabled&amp;s=d2f8396770daa068b1b5e9330e7001f5c1af2bb6", "width": 574, "height": 312}, "resolutions": [{"url": "https://external-preview.redd.it/QYi-iUbo0f9piut-pcH5kjBpqw6QMfeuLZ6kf61bJ7U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=06655eb8c95104e0e0453fb7670a60a63f0dd2ee", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/QYi-iUbo0f9piut-pcH5kjBpqw6QMfeuLZ6kf61bJ7U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=63c69afe02189654b1523c7d194fa29ea686771d", "width": 216, "height": 117}, {"url": "https://external-preview.redd.it/QYi-iUbo0f9piut-pcH5kjBpqw6QMfeuLZ6kf61bJ7U.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=190aee51e5a8747ac2b7cc50859079731f4aa660", "width": 320, "height": 173}], "variants": {}, "id": "lPMLX4UOLiG31L-cTEzW4wWugTTDUOqJo0ISp0dvBM8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14mc2m9", "is_robot_indexable": true, "report_reasons": null, "author": "PhysicalTomorrow2098", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14mc2m9/apache_airflow_spark_and_kubernetes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14mc2m9/apache_airflow_spark_and_kubernetes/", "subreddit_subscribers": 113032, "created_utc": 1688062286.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am currently on the verge of completing my Ph.D. in Bioinformatics and I am exploring potential career opportunities outside of academia. I have been considering a transition to the field of Data Engineering and I'm curious to know if anyone here has made a similar leap or has insights to share.\n\nTo provide some background, I thoroughly enjoy working with data, especially when it comes to organizing, curating, and cleaning it. While I also find joy in analyzing data and making predictions, I feel a stronger affinity towards the data management aspects of the process. With proficiency in Python, SQL, and R, I have a solid foundation in data-related programming languages.\n\nDuring my research journey, I extensively employed ML algorithms, particularly focusing on clustering, within the domain of Genomic Data Science. This experience allowed me to gain valuable skills in data manipulation, preprocessing, and extracting meaningful insights from complex biological datasets.\n\nMoreover, to further enhance my skills in data management and engineering, I completed the Data Engineering career path on DataCamp. This course deepened my understanding of various data storage and processing technologies, such as Apache Spark, Hadoop, and ETL pipelines.\n\nGiven this background, I am curious to know if it is possible to transition from Bioinformatics to Data Engineering. I understand that there might be differences in the domains, but I believe that the skills I have acquired can be transferrable.\n\nI would greatly appreciate any insights, experiences, or advice from those who have successfully transitioned from Bioinformatics or a related field to Data Engineering. Are there any specific skills or knowledge areas that I should focus on to increase my chances of making a smooth transition? Are there any potential hurdles or challenges that I should be aware of?\n\nThank you in advance for your time and valuable input. I am eager to hear your thoughts and experiences on this matter.", "author_fullname": "t2_3x005wsk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from Bioinformatics to Data Engineering: Feasibility and Career Opportunities?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m4j6x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688043907.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am currently on the verge of completing my Ph.D. in Bioinformatics and I am exploring potential career opportunities outside of academia. I have been considering a transition to the field of Data Engineering and I&amp;#39;m curious to know if anyone here has made a similar leap or has insights to share.&lt;/p&gt;\n\n&lt;p&gt;To provide some background, I thoroughly enjoy working with data, especially when it comes to organizing, curating, and cleaning it. While I also find joy in analyzing data and making predictions, I feel a stronger affinity towards the data management aspects of the process. With proficiency in Python, SQL, and R, I have a solid foundation in data-related programming languages.&lt;/p&gt;\n\n&lt;p&gt;During my research journey, I extensively employed ML algorithms, particularly focusing on clustering, within the domain of Genomic Data Science. This experience allowed me to gain valuable skills in data manipulation, preprocessing, and extracting meaningful insights from complex biological datasets.&lt;/p&gt;\n\n&lt;p&gt;Moreover, to further enhance my skills in data management and engineering, I completed the Data Engineering career path on DataCamp. This course deepened my understanding of various data storage and processing technologies, such as Apache Spark, Hadoop, and ETL pipelines.&lt;/p&gt;\n\n&lt;p&gt;Given this background, I am curious to know if it is possible to transition from Bioinformatics to Data Engineering. I understand that there might be differences in the domains, but I believe that the skills I have acquired can be transferrable.&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate any insights, experiences, or advice from those who have successfully transitioned from Bioinformatics or a related field to Data Engineering. Are there any specific skills or knowledge areas that I should focus on to increase my chances of making a smooth transition? Are there any potential hurdles or challenges that I should be aware of?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your time and valuable input. I am eager to hear your thoughts and experiences on this matter.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14m4j6x", "is_robot_indexable": true, "report_reasons": null, "author": "greengecko7", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m4j6x/transitioning_from_bioinformatics_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m4j6x/transitioning_from_bioinformatics_to_data/", "subreddit_subscribers": 113032, "created_utc": 1688043907.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you design to handle EndEffectiveDate in DV Sat tables or SCD type2?\n\nDo you run updates with incremental loads or calculate on the fly with LAG(), or other ways?\n\n&amp;#x200B;", "author_fullname": "t2_9iyum30h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you design to handle EndEffectiveDate in DV Sat tables?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lkktf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687985256.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687985043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you design to handle EndEffectiveDate in DV Sat tables or SCD type2?&lt;/p&gt;\n\n&lt;p&gt;Do you run updates with incremental loads or calculate on the fly with LAG(), or other ways?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14lkktf", "is_robot_indexable": true, "report_reasons": null, "author": "PrtScr1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lkktf/how_do_you_design_to_handle_endeffectivedate_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lkktf/how_do_you_design_to_handle_endeffectivedate_in/", "subreddit_subscribers": 113032, "created_utc": 1687985043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a requirement to share data securely that lies on ADLS with a team outside of our organization. What are the options we have to get this done?", "author_fullname": "t2_6kmo2ecy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure data lake - Data Share", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14mbj7d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688061021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a requirement to share data securely that lies on ADLS with a team outside of our organization. What are the options we have to get this done?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14mbj7d", "is_robot_indexable": true, "report_reasons": null, "author": "soujoshi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14mbj7d/azure_data_lake_data_share/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14mbj7d/azure_data_lake_data_share/", "subreddit_subscribers": 113032, "created_utc": 1688061021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How did I do with this in-depth intro? [https://www.dataops.live/what-are-data-products](https://www.dataops.live/what-are-data-products)", "author_fullname": "t2_12li6zgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a Data Product? An In-depth Introduction", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m8os9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688054242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How did I do with this in-depth intro? &lt;a href=\"https://www.dataops.live/what-are-data-products\"&gt;https://www.dataops.live/what-are-data-products&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14m8os9", "is_robot_indexable": true, "report_reasons": null, "author": "Dkreig", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m8os9/what_is_a_data_product_an_indepth_introduction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m8os9/what_is_a_data_product_an_indepth_introduction/", "subreddit_subscribers": 113032, "created_utc": 1688054242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been struggling to get some decent client facing analytic tools up and running because our legacy on premise setup is basically two extremes of \"a couple poorly deployed COTS front end COTS apps only connected to 20% of our data\" or \"spark clusters and jupyter notebook data science\". The latter works for myself and other tech literate analysts or users.\n\nBeen reading more about OpenSearch since the current open-source ELK stack is super restricted to basically useless (you can't even print a dashboard or viz to PDF) and it's starting to look very appealing to get some datamarts hooked up to dashboards and viz, but I don't really come across discussion around OpenSearch and ELK stacks beyond search engines or as part of another app. No one at my workplace seems to have experience because everything for search engines deployed are all Solr setups.\n\nHow difficult are some of the AD integration for authn and authz to setup or the ABAC permission configs that the docs explain? Or setting up logstash / beats data connectors that listen in on an API?\n\nIt's all very outside my mostly SQL world wheelhouse but I experimented with it and kibana on a small ad hoc dataset and I really liked it as a kind of data exploration, EDA and search tool.\n\nBut is it something you would look to create indexes on a couple datamarts with some dashboards as a general purpose analytics tool or is the effort and esoteric configs just not worth it?", "author_fullname": "t2_51nsnxi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OpenSearch ELK stack for analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m44y9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688042829.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been struggling to get some decent client facing analytic tools up and running because our legacy on premise setup is basically two extremes of &amp;quot;a couple poorly deployed COTS front end COTS apps only connected to 20% of our data&amp;quot; or &amp;quot;spark clusters and jupyter notebook data science&amp;quot;. The latter works for myself and other tech literate analysts or users.&lt;/p&gt;\n\n&lt;p&gt;Been reading more about OpenSearch since the current open-source ELK stack is super restricted to basically useless (you can&amp;#39;t even print a dashboard or viz to PDF) and it&amp;#39;s starting to look very appealing to get some datamarts hooked up to dashboards and viz, but I don&amp;#39;t really come across discussion around OpenSearch and ELK stacks beyond search engines or as part of another app. No one at my workplace seems to have experience because everything for search engines deployed are all Solr setups.&lt;/p&gt;\n\n&lt;p&gt;How difficult are some of the AD integration for authn and authz to setup or the ABAC permission configs that the docs explain? Or setting up logstash / beats data connectors that listen in on an API?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s all very outside my mostly SQL world wheelhouse but I experimented with it and kibana on a small ad hoc dataset and I really liked it as a kind of data exploration, EDA and search tool.&lt;/p&gt;\n\n&lt;p&gt;But is it something you would look to create indexes on a couple datamarts with some dashboards as a general purpose analytics tool or is the effort and esoteric configs just not worth it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14m44y9", "is_robot_indexable": true, "report_reasons": null, "author": "VersatileGuru", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m44y9/opensearch_elk_stack_for_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m44y9/opensearch_elk_stack_for_analytics/", "subreddit_subscribers": 113032, "created_utc": 1688042829.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data analyst, and I'm not on the development side really I mainly run BI style analysis on our spark clusters with notebooks.\n\nI've done lots of reading and tutorials and the like on different ML applications in python, but all of them seem like they are quite 'heavy' in terms of investment, and really are best done as part of a concerted effort to actually build in a model onto some sort of product (i.e. recommendation engine on your app).\n\nBut, aside from that, are there any applications of ML or NLP that are more for making some of the more mundane tasks easier when it comes to analysis or ELT that is *actually* less work than writing out specific functions for transformation or dedupe or data enrichment?\n\nFor example, are there any interesting techniques people have somehow applied to help automate metadata tagging or data normalization?\n\n I don't mean like some magical one button non existent AI bullshit. I just mean practical day to day techniques that are repeatable and actually worth the time spent doing (as opposed to just tackling it manually) like when looking at a new data source for ETL \"you could use NLP to flag columns that likely match your existing schema\".\n\nClosest example I'm currently looking to play with is a few NLP based libraries for identifying and flagging PII or GDPR data that needs to be masked / purged.", "author_fullname": "t2_51nsnxi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Practical Applications of ML for analysis or ETL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m3oxa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688041586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data analyst, and I&amp;#39;m not on the development side really I mainly run BI style analysis on our spark clusters with notebooks.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done lots of reading and tutorials and the like on different ML applications in python, but all of them seem like they are quite &amp;#39;heavy&amp;#39; in terms of investment, and really are best done as part of a concerted effort to actually build in a model onto some sort of product (i.e. recommendation engine on your app).&lt;/p&gt;\n\n&lt;p&gt;But, aside from that, are there any applications of ML or NLP that are more for making some of the more mundane tasks easier when it comes to analysis or ELT that is &lt;em&gt;actually&lt;/em&gt; less work than writing out specific functions for transformation or dedupe or data enrichment?&lt;/p&gt;\n\n&lt;p&gt;For example, are there any interesting techniques people have somehow applied to help automate metadata tagging or data normalization?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t mean like some magical one button non existent AI bullshit. I just mean practical day to day techniques that are repeatable and actually worth the time spent doing (as opposed to just tackling it manually) like when looking at a new data source for ETL &amp;quot;you could use NLP to flag columns that likely match your existing schema&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Closest example I&amp;#39;m currently looking to play with is a few NLP based libraries for identifying and flagging PII or GDPR data that needs to be masked / purged.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14m3oxa", "is_robot_indexable": true, "report_reasons": null, "author": "VersatileGuru", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m3oxa/practical_applications_of_ml_for_analysis_or_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m3oxa/practical_applications_of_ml_for_analysis_or_etl/", "subreddit_subscribers": 113032, "created_utc": 1688041586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m an embedded engineer intern working part time at a small startup with novel sensors and we\u2019re looking to start logging and storing important information from the devices. \n\nI want to go through the whole process of creating the database on new hardware, sending data from IOT devices, accessing data via an API, and having the database automatically manage the data via scripts (such as filtering). However, this is all extremely new to me, as I\u2019m only extremely familiar with low-level programming and hardware design so I want to choose the simplest and barebones tools as possible for this job.\n\nSo far everything we\u2019ve done is with basic files in a shared drive + emails lmao. I\u2019m wondering what machine should I get (what OS) if I\u2019m to use it for the sole purpose of database. What management system should I use? How do I create the API? How do I log data from embedded devices? I want to learn all this stuff, even though it\u2019s just for some current small-scale system as I aim to enter the IOT space.", "author_fullname": "t2_rkkbr1x8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating and utilizing a database in the simplest way possible", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lxz7v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688022483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m an embedded engineer intern working part time at a small startup with novel sensors and we\u2019re looking to start logging and storing important information from the devices. &lt;/p&gt;\n\n&lt;p&gt;I want to go through the whole process of creating the database on new hardware, sending data from IOT devices, accessing data via an API, and having the database automatically manage the data via scripts (such as filtering). However, this is all extremely new to me, as I\u2019m only extremely familiar with low-level programming and hardware design so I want to choose the simplest and barebones tools as possible for this job.&lt;/p&gt;\n\n&lt;p&gt;So far everything we\u2019ve done is with basic files in a shared drive + emails lmao. I\u2019m wondering what machine should I get (what OS) if I\u2019m to use it for the sole purpose of database. What management system should I use? How do I create the API? How do I log data from embedded devices? I want to learn all this stuff, even though it\u2019s just for some current small-scale system as I aim to enter the IOT space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14lxz7v", "is_robot_indexable": true, "report_reasons": null, "author": "aufry", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14lxz7v/creating_and_utilizing_a_database_in_the_simplest/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14lxz7v/creating_and_utilizing_a_database_in_the_simplest/", "subreddit_subscribers": 113032, "created_utc": 1688022483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are my choices for working with data i.e. Data Engineering and ML/AI task on JAVA? \n\n&amp;#x200B;\n\nI know in Python there are many libraries/Frameworks choices Pandas(/numpy)/Polars/Dask/PySpark/Databricks depending on the size of data, type of system, on prem/cloud, project (webapp/edge device app) ect. For ML AI task again there are many options Scikit Learn, SparkML, Keras, ect. \n\n&amp;#x200B;\n\nAfter some googling and chatGPT prompts I didn't exactly find great results. I saw that many JAVA Frameworks that are used for ML task accept Tablesaw (Dataframes) i.e.DJL (Deep Java Library)\\\\DeepLearning4j\\\\Flink . However Tablesaw hasn't been updated since April 2022. I started looking at Spark on Java but had some trouble finding resources in Java. The resources I kept finding for spark ended up being for either Scala or Python. \n\n&amp;#x200B;\n\nAre there any good resources for data engineering and data science using JAVA. ", "author_fullname": "t2_h0k60d4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Java Data Engineering and Data Science Libraries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14licjh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687979786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are my choices for working with data i.e. Data Engineering and ML/AI task on JAVA? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I know in Python there are many libraries/Frameworks choices Pandas(/numpy)/Polars/Dask/PySpark/Databricks depending on the size of data, type of system, on prem/cloud, project (webapp/edge device app) ect. For ML AI task again there are many options Scikit Learn, SparkML, Keras, ect. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;After some googling and chatGPT prompts I didn&amp;#39;t exactly find great results. I saw that many JAVA Frameworks that are used for ML task accept Tablesaw (Dataframes) i.e.DJL (Deep Java Library)\\DeepLearning4j\\Flink . However Tablesaw hasn&amp;#39;t been updated since April 2022. I started looking at Spark on Java but had some trouble finding resources in Java. The resources I kept finding for spark ended up being for either Scala or Python. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Are there any good resources for data engineering and data science using JAVA. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14licjh", "is_robot_indexable": true, "report_reasons": null, "author": "magu01", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14licjh/java_data_engineering_and_data_science_libraries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14licjh/java_data_engineering_and_data_science_libraries/", "subreddit_subscribers": 113032, "created_utc": 1687979786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'd like to make a business case to my bosses that we can save a ton of money on human labor by beefing up some of our cloud spending. Anything from something as trivial as giving each engineer on my team a dedicated VM (as opposed to sharing them and running out of RAM), to spending more on our cloud compute for auto scaling so we don't need to worry about spending months designing our systems to be more fault tolerant of the days when users decide once per month to hit our system all at once.\n\nMy issue is other than my boss the CTO, who also favors automation, none of the rest of the C-Suite understands what a typical cloud bill in our industry is and may look at my ask and say \"we could hire 3 FTEs to do xyz in other departments with the money your asking for\", which I can counter with the hypothetical that hiring 2 software engineers to do this stuff is more costly. \n\n Compared to past companies I've worked for which support a similar number of customers, our current cloud bill is fractions of what we spent in the past for similar problems. Obviously I can't go sharing that out loud with specific numbers since it's non public information, but I'm curious if there are publicly available well respected benchmarks I can reference?", "author_fullname": "t2_decct72a5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good resources for average cloud bill benchmarking for different company sizes/ industries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14mc7wg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688062634.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to make a business case to my bosses that we can save a ton of money on human labor by beefing up some of our cloud spending. Anything from something as trivial as giving each engineer on my team a dedicated VM (as opposed to sharing them and running out of RAM), to spending more on our cloud compute for auto scaling so we don&amp;#39;t need to worry about spending months designing our systems to be more fault tolerant of the days when users decide once per month to hit our system all at once.&lt;/p&gt;\n\n&lt;p&gt;My issue is other than my boss the CTO, who also favors automation, none of the rest of the C-Suite understands what a typical cloud bill in our industry is and may look at my ask and say &amp;quot;we could hire 3 FTEs to do xyz in other departments with the money your asking for&amp;quot;, which I can counter with the hypothetical that hiring 2 software engineers to do this stuff is more costly. &lt;/p&gt;\n\n&lt;p&gt;Compared to past companies I&amp;#39;ve worked for which support a similar number of customers, our current cloud bill is fractions of what we spent in the past for similar problems. Obviously I can&amp;#39;t go sharing that out loud with specific numbers since it&amp;#39;s non public information, but I&amp;#39;m curious if there are publicly available well respected benchmarks I can reference?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14mc7wg", "is_robot_indexable": true, "report_reasons": null, "author": "Dull_Lettuce_4622", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14mc7wg/any_good_resources_for_average_cloud_bill/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14mc7wg/any_good_resources_for_average_cloud_bill/", "subreddit_subscribers": 113032, "created_utc": 1688062634.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Putting a Filesystem on Top of an Object Store is a Bad Idea. Here is why.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 41, "top_awarded_type": null, "hide_score": false, "name": "t3_14mav25", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/edBU9aFpD8SqegGzd0OpQ9OMsJcfdkYIb0NFtcyy0lY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688059430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.min.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.min.io/filesystem-on-object-store-is-a-bad-idea/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/U_Uvx_DucKrwlcOZbx_1ICXO4MAIbztF3iWjCKq-6o4.jpg?auto=webp&amp;v=enabled&amp;s=d44cb43aa632774bc19c70bbd913616103031873", "width": 2000, "height": 598}, "resolutions": [{"url": "https://external-preview.redd.it/U_Uvx_DucKrwlcOZbx_1ICXO4MAIbztF3iWjCKq-6o4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e66278d5b7370b36dfd2ad4a7f97105a78036113", "width": 108, "height": 32}, {"url": "https://external-preview.redd.it/U_Uvx_DucKrwlcOZbx_1ICXO4MAIbztF3iWjCKq-6o4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1ab708b140b74aad2807de609ea0d13a198b220a", "width": 216, "height": 64}, {"url": "https://external-preview.redd.it/U_Uvx_DucKrwlcOZbx_1ICXO4MAIbztF3iWjCKq-6o4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7bfd685d21bffc0f7c978edce1908bb3b2e64079", "width": 320, "height": 95}, {"url": "https://external-preview.redd.it/U_Uvx_DucKrwlcOZbx_1ICXO4MAIbztF3iWjCKq-6o4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a24ee538719c862b30ce2155f74d126b9dd2e6b", "width": 640, "height": 191}, {"url": "https://external-preview.redd.it/U_Uvx_DucKrwlcOZbx_1ICXO4MAIbztF3iWjCKq-6o4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b7be1ab056879967e163deec8b32ee821c748909", "width": 960, "height": 287}, {"url": "https://external-preview.redd.it/U_Uvx_DucKrwlcOZbx_1ICXO4MAIbztF3iWjCKq-6o4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a9667b3e838a7b768356b0c80d2da9c9b2a7b70d", "width": 1080, "height": 322}], "variants": {}, "id": "FFdJ3mgdskD8LJFBgknmxQAw9iYuzJQk6Qwg-ev1vJw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14mav25", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14mav25/putting_a_filesystem_on_top_of_an_object_store_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.min.io/filesystem-on-object-store-is-a-bad-idea/", "subreddit_subscribers": 113032, "created_utc": 1688059430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hope I'm not breaking any rules of this sub. \n\nI'm looking for some book (or any other resource tbh) recommendations to learn more about data virtualization. My company is now moving towards using Denodo and I'd like read up on this over the weekend. I probably don't want something that goes into the very minute detail - something that scratches the surface should suffice for the first pass.", "author_fullname": "t2_sucuw1gz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book recommendation for Data virtualization", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m7djl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688051115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hope I&amp;#39;m not breaking any rules of this sub. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for some book (or any other resource tbh) recommendations to learn more about data virtualization. My company is now moving towards using Denodo and I&amp;#39;d like read up on this over the weekend. I probably don&amp;#39;t want something that goes into the very minute detail - something that scratches the surface should suffice for the first pass.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14m7djl", "is_robot_indexable": true, "report_reasons": null, "author": "x_butnocigar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m7djl/book_recommendation_for_data_virtualization/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m7djl/book_recommendation_for_data_virtualization/", "subreddit_subscribers": 113032, "created_utc": 1688051115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "# Background\n\n* I\u2019ve been playing around with `explain` out of curiosity\n* I\u2019m trying to understand how column-level lineages can be built from `explain(\"formatted\")` (although this isn\u2019t that relevant to my question)\n* This question\u2019s scope is limited to query plans for queries of the form `spark.table(\"schema.table\").explain(\"formatted\")`\n\n# Question\n\n* When running the above query on separate tables, why is it that the column identifiers start at different values for different tables (see example below)?\n\n# Examples\n\n* Disclaimers:\n   * The columns and identifiers are separated from each other and stored in a dictionary as a result of a function I wrote to process the `explain(\"formatted\")` output\n   * I\u2019ve renamed the columns since they\u2019re from actual tables used in my company\n\n**Table A**\n\n    {'a_1': '0L',\n     'a_2': '1L',\n     'a_3': '2',\n     'a_4': '3',\n     'a_5': '4',\n     'a_6': '5',\n     'a_7': '6',\n     'a_8': '7',\n     'a_9': '8L',\n     'a_10': '9',\n     'a_11': '10',\n     'a_12': '11',\n     'a_13': '12',\n     'a_14': '13',\n     'a_15': '14',\n     'a_16': '15',\n     'a_17': '16'}\n\n**Table B**\n\n    {'b_1': '1844L',\n     'b_2': '1845',\n     'b_3': '1846',\n     'b_4': '1847L',\n     'b_5': '1848',\n     'b_6': '1849',\n     'b_7': '1850',\n     'b_8': '1851',\n     'b_9': '1852',\n     'b_10': '1853'}", "author_fullname": "t2_a8joqf7z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark explain(): how does Spark decide on the value of column identifiers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m6etv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688048787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;Background&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I\u2019ve been playing around with &lt;code&gt;explain&lt;/code&gt; out of curiosity&lt;/li&gt;\n&lt;li&gt;I\u2019m trying to understand how column-level lineages can be built from &lt;code&gt;explain(&amp;quot;formatted&amp;quot;)&lt;/code&gt; (although this isn\u2019t that relevant to my question)&lt;/li&gt;\n&lt;li&gt;This question\u2019s scope is limited to query plans for queries of the form &lt;code&gt;spark.table(&amp;quot;schema.table&amp;quot;).explain(&amp;quot;formatted&amp;quot;)&lt;/code&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Question&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;When running the above query on separate tables, why is it that the column identifiers start at different values for different tables (see example below)?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Examples&lt;/h1&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Disclaimers:\n\n&lt;ul&gt;\n&lt;li&gt;The columns and identifiers are separated from each other and stored in a dictionary as a result of a function I wrote to process the &lt;code&gt;explain(&amp;quot;formatted&amp;quot;)&lt;/code&gt; output&lt;/li&gt;\n&lt;li&gt;I\u2019ve renamed the columns since they\u2019re from actual tables used in my company&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Table A&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{&amp;#39;a_1&amp;#39;: &amp;#39;0L&amp;#39;,\n &amp;#39;a_2&amp;#39;: &amp;#39;1L&amp;#39;,\n &amp;#39;a_3&amp;#39;: &amp;#39;2&amp;#39;,\n &amp;#39;a_4&amp;#39;: &amp;#39;3&amp;#39;,\n &amp;#39;a_5&amp;#39;: &amp;#39;4&amp;#39;,\n &amp;#39;a_6&amp;#39;: &amp;#39;5&amp;#39;,\n &amp;#39;a_7&amp;#39;: &amp;#39;6&amp;#39;,\n &amp;#39;a_8&amp;#39;: &amp;#39;7&amp;#39;,\n &amp;#39;a_9&amp;#39;: &amp;#39;8L&amp;#39;,\n &amp;#39;a_10&amp;#39;: &amp;#39;9&amp;#39;,\n &amp;#39;a_11&amp;#39;: &amp;#39;10&amp;#39;,\n &amp;#39;a_12&amp;#39;: &amp;#39;11&amp;#39;,\n &amp;#39;a_13&amp;#39;: &amp;#39;12&amp;#39;,\n &amp;#39;a_14&amp;#39;: &amp;#39;13&amp;#39;,\n &amp;#39;a_15&amp;#39;: &amp;#39;14&amp;#39;,\n &amp;#39;a_16&amp;#39;: &amp;#39;15&amp;#39;,\n &amp;#39;a_17&amp;#39;: &amp;#39;16&amp;#39;}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;Table B&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{&amp;#39;b_1&amp;#39;: &amp;#39;1844L&amp;#39;,\n &amp;#39;b_2&amp;#39;: &amp;#39;1845&amp;#39;,\n &amp;#39;b_3&amp;#39;: &amp;#39;1846&amp;#39;,\n &amp;#39;b_4&amp;#39;: &amp;#39;1847L&amp;#39;,\n &amp;#39;b_5&amp;#39;: &amp;#39;1848&amp;#39;,\n &amp;#39;b_6&amp;#39;: &amp;#39;1849&amp;#39;,\n &amp;#39;b_7&amp;#39;: &amp;#39;1850&amp;#39;,\n &amp;#39;b_8&amp;#39;: &amp;#39;1851&amp;#39;,\n &amp;#39;b_9&amp;#39;: &amp;#39;1852&amp;#39;,\n &amp;#39;b_10&amp;#39;: &amp;#39;1853&amp;#39;}\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14m6etv", "is_robot_indexable": true, "report_reasons": null, "author": "haskathon", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14m6etv/spark_explain_how_does_spark_decide_on_the_value/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14m6etv/spark_explain_how_does_spark_decide_on_the_value/", "subreddit_subscribers": 113032, "created_utc": 1688048787.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}