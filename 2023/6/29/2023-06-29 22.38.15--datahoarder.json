{"kind": "Listing", "data": {"after": "t3_14lz83z", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_5xe5d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stitcher (podcasting app/site) is being killed off by parent company Sirius XM, effective August 29th. Export your podcasts &amp; metadata while you can!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m4smh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 190, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 190, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1688044621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "stitcher.helpshift.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://stitcher.helpshift.com/hc/en/1-stitcher/section/151-stitcher-farewell-1687885657/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "72TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m4smh", "is_robot_indexable": true, "report_reasons": null, "author": "AtmaJnana", "discussion_type": null, "num_comments": 27, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14m4smh/stitcher_podcasting_appsite_is_being_killed_off/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://stitcher.helpshift.com/hc/en/1-stitcher/section/151-stitcher-farewell-1687885657/", "subreddit_subscribers": 690237, "created_utc": 1688044621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm backing up a NAS with about 120 TB on Synology SMB shares over 10GbE to a SAS LTO8 drive (not an autoloader) which is on a Windows workstation.\n\nTL;DR is there a solution with a clearly organized UI that inspires confidence, and tape management with local file inventory?\n\nI did research here and elsewhere and here's the software I've tried so far:\n\n\\- **VEEAM**: Widely recommended but it turns out that it only supports a measly **500 GB** of data under the Community Edition and to do 120 TB it's several thousand dollars a year. It didn't disclose this until I had set everything up, catalogued my tapes and tried to run a backup at which point it failed with insufficient licenses. Their web site doesn't include this limitation in the comparison tables. The install is huge and the UI is terrible. It gave progress indication by file and by speed but in weird little sub panes that couldn't be properly resized. I gather the 500 GB thing is new, so people should stop recommending this. **UPDATE**: I got a Veeam NFR license and that only increased the limit from 500 GB to **5 TB** which is still super low given there are 22 TB single HDDs.\n\n\\- **Acronis Cyber Protect Backup Advanced**: A test backup worked, but it's a wonky web UI and it doesn't give any information on the backup progress except percentage complete (no current file being backed up, no MBps average, etc.) There is no guidance in the app or their web site on how to organize tapes, merely to dump them into a pool. There are two **deal-breakers**: 1) When adding SMB shares to a backup it expands every directory and doesn't let you collapse the view, so once you add 8-10 shares the list is enormous and cannot be navigated. 2) If I try to backup a subdirectory off an SMB share there is a bug where the credentials fail, e.g. \"\\\\\\\\server\\\\share\" works but \"\\\\\\\\server\\\\share\\\\folder\" fails using the same credentials. **UPDATE**: I also realized there is **no way to select files by date**, so it's impossible to do a file-based incremental/new/changed backup, you have to redo the entire backup every time.\n\n\\- **EaseUS Todo Backup**: Says it supports tape but that feature appears to be missing, their support was clueless and they're a China based company.\n\nI looked at the **Bacula** site but their UI was incomprehensible and it seems designed for Linux with some CLI scripting either good to have or required. Not my cup of tea.\n\nI also checked out **Uranium Backup** and **Iperius Backup** but looking through their tutorials and documentation it doesn't appear that either app has any tape management/local file inventory whatsoever, they just use tape as a dumb backup destination only.\n\n&amp;#x200B;", "author_fullname": "t2_slqb6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Revisiting LTO tape backup software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lqufr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1688070214.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688000733.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m backing up a NAS with about 120 TB on Synology SMB shares over 10GbE to a SAS LTO8 drive (not an autoloader) which is on a Windows workstation.&lt;/p&gt;\n\n&lt;p&gt;TL;DR is there a solution with a clearly organized UI that inspires confidence, and tape management with local file inventory?&lt;/p&gt;\n\n&lt;p&gt;I did research here and elsewhere and here&amp;#39;s the software I&amp;#39;ve tried so far:&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;VEEAM&lt;/strong&gt;: Widely recommended but it turns out that it only supports a measly &lt;strong&gt;500 GB&lt;/strong&gt; of data under the Community Edition and to do 120 TB it&amp;#39;s several thousand dollars a year. It didn&amp;#39;t disclose this until I had set everything up, catalogued my tapes and tried to run a backup at which point it failed with insufficient licenses. Their web site doesn&amp;#39;t include this limitation in the comparison tables. The install is huge and the UI is terrible. It gave progress indication by file and by speed but in weird little sub panes that couldn&amp;#39;t be properly resized. I gather the 500 GB thing is new, so people should stop recommending this. &lt;strong&gt;UPDATE&lt;/strong&gt;: I got a Veeam NFR license and that only increased the limit from 500 GB to &lt;strong&gt;5 TB&lt;/strong&gt; which is still super low given there are 22 TB single HDDs.&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;Acronis Cyber Protect Backup Advanced&lt;/strong&gt;: A test backup worked, but it&amp;#39;s a wonky web UI and it doesn&amp;#39;t give any information on the backup progress except percentage complete (no current file being backed up, no MBps average, etc.) There is no guidance in the app or their web site on how to organize tapes, merely to dump them into a pool. There are two &lt;strong&gt;deal-breakers&lt;/strong&gt;: 1) When adding SMB shares to a backup it expands every directory and doesn&amp;#39;t let you collapse the view, so once you add 8-10 shares the list is enormous and cannot be navigated. 2) If I try to backup a subdirectory off an SMB share there is a bug where the credentials fail, e.g. &amp;quot;\\\\server\\share&amp;quot; works but &amp;quot;\\\\server\\share\\folder&amp;quot; fails using the same credentials. &lt;strong&gt;UPDATE&lt;/strong&gt;: I also realized there is &lt;strong&gt;no way to select files by date&lt;/strong&gt;, so it&amp;#39;s impossible to do a file-based incremental/new/changed backup, you have to redo the entire backup every time.&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;EaseUS Todo Backup&lt;/strong&gt;: Says it supports tape but that feature appears to be missing, their support was clueless and they&amp;#39;re a China based company.&lt;/p&gt;\n\n&lt;p&gt;I looked at the &lt;strong&gt;Bacula&lt;/strong&gt; site but their UI was incomprehensible and it seems designed for Linux with some CLI scripting either good to have or required. Not my cup of tea.&lt;/p&gt;\n\n&lt;p&gt;I also checked out &lt;strong&gt;Uranium Backup&lt;/strong&gt; and &lt;strong&gt;Iperius Backup&lt;/strong&gt; but looking through their tutorials and documentation it doesn&amp;#39;t appear that either app has any tape management/local file inventory whatsoever, they just use tape as a dumb backup destination only.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lqufr", "is_robot_indexable": true, "report_reasons": null, "author": "WonderSausage", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lqufr/revisiting_lto_tape_backup_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lqufr/revisiting_lto_tape_backup_software/", "subreddit_subscribers": 690237, "created_utc": 1688000733.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A few months old 256 GB flash stick, with its USB3(connected 2 a desktop PC) &amp; USB-C ends, was burning hot (even had that odor/smell) from idling overnight!  Same for an older 512 GB USB2. I noticed both use aluminum/metal case type.\n\nDoes anyone else have this problem too? Thank you for reading and hopefully answering soon.", "author_fullname": "t2_4a27h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it me or do Sandisk USB flash sticks get too hot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lqr56", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e4444668-b98a-11e2-b419-12313d169640", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "threefive", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688000502.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few months old 256 GB flash stick, with its USB3(connected 2 a desktop PC) &amp;amp; USB-C ends, was burning hot (even had that odor/smell) from idling overnight!  Same for an older 512 GB USB2. I noticed both use aluminum/metal case type.&lt;/p&gt;\n\n&lt;p&gt;Does anyone else have this problem too? Thank you for reading and hopefully answering soon.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Where's the big floppy disk(ette) flair? :P", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lqr56", "is_robot_indexable": true, "report_reasons": null, "author": "antdude", "discussion_type": null, "num_comments": 15, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14lqr56/is_it_me_or_do_sandisk_usb_flash_sticks_get_too/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lqr56/is_it_me_or_do_sandisk_usb_flash_sticks_get_too/", "subreddit_subscribers": 690237, "created_utc": 1688000502.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, \nat work we use an older external website as a kind of wiki, a page that requires a login with we have. Now our IT department decided to modernize everything and at the end of the year the old page will be offline. The replacement really sucks so we decided to try to make some kind of backup of the page and its really helpful articles there.\n\nThe page itself looks like an older Wikipedia, along with links to older articles. Since it is an older page I tried to save the page via Browser and got a html file along with a folder, that contains a lot of .js files. I've opened the html and I could access the articles along with the links. But the problem now: the login itself - on my PC there should be a temporary session (probably cookie based?) active since my colleagues were asked for the password.\n\nAre there any tools around that can save a complete local copy and remove the login requirement afterwards (since after they put it offline out login would not work anymore)? Thank you for any ideas.", "author_fullname": "t2_1ei11v97", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local offline backup of a Wiki-like homepage with login possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lugfs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688011156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, \nat work we use an older external website as a kind of wiki, a page that requires a login with we have. Now our IT department decided to modernize everything and at the end of the year the old page will be offline. The replacement really sucks so we decided to try to make some kind of backup of the page and its really helpful articles there.&lt;/p&gt;\n\n&lt;p&gt;The page itself looks like an older Wikipedia, along with links to older articles. Since it is an older page I tried to save the page via Browser and got a html file along with a folder, that contains a lot of .js files. I&amp;#39;ve opened the html and I could access the articles along with the links. But the problem now: the login itself - on my PC there should be a temporary session (probably cookie based?) active since my colleagues were asked for the password.&lt;/p&gt;\n\n&lt;p&gt;Are there any tools around that can save a complete local copy and remove the login requirement afterwards (since after they put it offline out login would not work anymore)? Thank you for any ideas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lugfs", "is_robot_indexable": true, "report_reasons": null, "author": "ChrisM243", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lugfs/local_offline_backup_of_a_wikilike_homepage_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lugfs/local_offline_backup_of_a_wikilike_homepage_with/", "subreddit_subscribers": 690237, "created_utc": 1688011156.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_16oo8k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lewtwo has just archived the whole Pok\u00e9mon Shirts company's work", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "name": "t3_14m4s0h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;In June 2023, the Pok\u00e9mon Shirts company announced their complete shutdown.&lt;br&gt;&lt;br&gt;here&amp;#39;s how we archived the entire company&amp;#39;s work in just six hours. \ud83e\uddf5 &lt;a href=\"https://t.co/TMI03xXm7j\"&gt;pic.twitter.com/TMI03xXm7j&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lewtwo (@Lewchube) &lt;a href=\"https://twitter.com/Lewchube/status/1674402577939677185?ref_src=twsrc%5Etfw\"&gt;June 29, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/Lewchube/status/1674402577939677185", "author_name": "Lewtwo", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;In June 2023, the Pok\u00e9mon Shirts company announced their complete shutdown.&lt;br&gt;&lt;br&gt;here&amp;#39;s how we archived the entire company&amp;#39;s work in just six hours. \ud83e\uddf5 &lt;a href=\"https://t.co/TMI03xXm7j\"&gt;pic.twitter.com/TMI03xXm7j&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lewtwo (@Lewchube) &lt;a href=\"https://twitter.com/Lewchube/status/1674402577939677185?ref_src=twsrc%5Etfw\"&gt;June 29, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/Lewchube", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;In June 2023, the Pok\u00e9mon Shirts company announced their complete shutdown.&lt;br&gt;&lt;br&gt;here&amp;#39;s how we archived the entire company&amp;#39;s work in just six hours. \ud83e\uddf5 &lt;a href=\"https://t.co/TMI03xXm7j\"&gt;pic.twitter.com/TMI03xXm7j&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lewtwo (@Lewchube) &lt;a href=\"https://twitter.com/Lewchube/status/1674402577939677185?ref_src=twsrc%5Etfw\"&gt;June 29, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/14m4s0h", "height": 200}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/n6EIIVzMke_b9eQpPlCC17G8xLKqGMAXmD75tX2DYcU.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1688044573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/Lewchube/status/1674402577939677185", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/m1O7vvsd8OoiAahWfVzVQ-yTDAtjmeiGUttqHVJ1kdI.jpg?auto=webp&amp;v=enabled&amp;s=ac87403ae71983e94b8a2bb2a0218a1168d1c672", "width": 140, "height": 97}, "resolutions": [{"url": "https://external-preview.redd.it/m1O7vvsd8OoiAahWfVzVQ-yTDAtjmeiGUttqHVJ1kdI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=991797453b50a8378ef02f707ff6ac4ca2e63225", "width": 108, "height": 74}], "variants": {}, "id": "tQIa1crPnmfmzCXF4JFHargl7PN717JzBb7IfKFUAAw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "42 TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14m4s0h", "is_robot_indexable": true, "report_reasons": null, "author": "DarthJahus", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14m4s0h/lewtwo_has_just_archived_the_whole_pok\u00e9mon_shirts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/Lewchube/status/1674402577939677185", "subreddit_subscribers": 690237, "created_utc": 1688044573.0, "num_crossposts": 0, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/Lewchube/status/1674402577939677185", "author_name": "Lewtwo", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;In June 2023, the Pok\u00e9mon Shirts company announced their complete shutdown.&lt;br&gt;&lt;br&gt;here&amp;#39;s how we archived the entire company&amp;#39;s work in just six hours. \ud83e\uddf5 &lt;a href=\"https://t.co/TMI03xXm7j\"&gt;pic.twitter.com/TMI03xXm7j&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lewtwo (@Lewchube) &lt;a href=\"https://twitter.com/Lewchube/status/1674402577939677185?ref_src=twsrc%5Etfw\"&gt;June 29, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/Lewchube", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Haven't used anything Apple in years, but I've been walking down memory lane recently and remembered back when I got the 2nd or 3rd gen iPod touch back around 2009 and I'm really missing those old apps. I can remember playing Jelly Car and some other puzzle/physics games that I can't remember. So I'm really hoping it's possible to search through the app store as it was back in the day. Maybe there's some offline data source somewhere?", "author_fullname": "t2_wb6mq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone know if there's a \"Wayback Machine\" for the iOS app store?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14mgoz4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688073155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Haven&amp;#39;t used anything Apple in years, but I&amp;#39;ve been walking down memory lane recently and remembered back when I got the 2nd or 3rd gen iPod touch back around 2009 and I&amp;#39;m really missing those old apps. I can remember playing Jelly Car and some other puzzle/physics games that I can&amp;#39;t remember. So I&amp;#39;m really hoping it&amp;#39;s possible to search through the app store as it was back in the day. Maybe there&amp;#39;s some offline data source somewhere?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14mgoz4", "is_robot_indexable": true, "report_reasons": null, "author": "TinyStego", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14mgoz4/anyone_know_if_theres_a_wayback_machine_for_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14mgoz4/anyone_know_if_theres_a_wayback_machine_for_the/", "subreddit_subscribers": 690237, "created_utc": 1688073155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I am looking for some recommendations on an external drive bay enclosure. I currently have 9 Best Buy easy store drives connected to my Mac mini via usbc hubs renting from 8tb to 18tbs. I would like to shuck them and combine them into one enclosure so that can be read as one drive instead of 9.  Current use is for plex media management. The Mac mini acts as the plex server with hardware transcoding so I don\u2019t think I need a nas. I am not worried about data recovery so I think I would use a raid 0 type set-up. Happy to answer any questions!", "author_fullname": "t2_y1dt8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for recommendation for external drive bay", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m5bpl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688046011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am looking for some recommendations on an external drive bay enclosure. I currently have 9 Best Buy easy store drives connected to my Mac mini via usbc hubs renting from 8tb to 18tbs. I would like to shuck them and combine them into one enclosure so that can be read as one drive instead of 9.  Current use is for plex media management. The Mac mini acts as the plex server with hardware transcoding so I don\u2019t think I need a nas. I am not worried about data recovery so I think I would use a raid 0 type set-up. Happy to answer any questions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m5bpl", "is_robot_indexable": true, "report_reasons": null, "author": "mprice06", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m5bpl/looking_for_recommendation_for_external_drive_bay/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m5bpl/looking_for_recommendation_for_external_drive_bay/", "subreddit_subscribers": 690237, "created_utc": 1688046011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Since tape/lto is slow but huge capacity, and flash/ssd is fast but have smaller capacity (at least more expensive), is there SSD+Tape hybrid drive? so the filesystem (which file on which position on the tape) stored on SSD for fast listing, but the data itself stored on tape?", "author_fullname": "t2_7bbojdkz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there ssd+tape hybrid drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m21td", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688036585.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since tape/lto is slow but huge capacity, and flash/ssd is fast but have smaller capacity (at least more expensive), is there SSD+Tape hybrid drive? so the filesystem (which file on which position on the tape) stored on SSD for fast listing, but the data itself stored on tape?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m21td", "is_robot_indexable": true, "report_reasons": null, "author": "kokizzu2", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m21td/is_there_ssdtape_hybrid_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m21td/is_there_ssdtape_hybrid_drive/", "subreddit_subscribers": 690237, "created_utc": 1688036585.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If you check out WD's product page: https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-blue-hdd/product-brief-western-digital-wd-blue-pc-hdd.pdf\n\nand Amazon product page: https://www.amazon.com/dp/B0BNGL4BND?th=1\n\nthe newest models of all WD Blue desktop drives are all CMR:\n\n* 2TB: WD20EARZ\n* 3TB: WD20EZAX\n* 4TB: WD40EZAX\n* 6TB: WD60EZAX\n* 8TB: WD80EAZZ (always has been CMR tho)", "author_fullname": "t2_fzwj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looks like WD Blue drives are changing back to CMR", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ltc7b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688007836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you check out WD&amp;#39;s product page: &lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-blue-hdd/product-brief-western-digital-wd-blue-pc-hdd.pdf\"&gt;https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/internal-drives/wd-blue-hdd/product-brief-western-digital-wd-blue-pc-hdd.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;and Amazon product page: &lt;a href=\"https://www.amazon.com/dp/B0BNGL4BND?th=1\"&gt;https://www.amazon.com/dp/B0BNGL4BND?th=1&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;the newest models of all WD Blue desktop drives are all CMR:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;2TB: WD20EARZ&lt;/li&gt;\n&lt;li&gt;3TB: WD20EZAX&lt;/li&gt;\n&lt;li&gt;4TB: WD40EZAX&lt;/li&gt;\n&lt;li&gt;6TB: WD60EZAX&lt;/li&gt;\n&lt;li&gt;8TB: WD80EAZZ (always has been CMR tho)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1TB = 0.909495TiB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "14ltc7b", "is_robot_indexable": true, "report_reasons": null, "author": "HTWingNut", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14ltc7b/looks_like_wd_blue_drives_are_changing_back_to_cmr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14ltc7b/looks_like_wd_blue_drives_are_changing_back_to_cmr/", "subreddit_subscribers": 690237, "created_utc": 1688007836.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, \n\nI am looking for a FREE cloud storage provider who allows to mount the storage directly to a linux server to use as a backup for sql dumps. \n\nDatabase files are rather small and I certainly dont mind paying, its just I can fit within free tier of most providers easily. Looking for one with the mount support like I described.\n\n&amp;#x200B;\n\nDont want:   \nMega (dont allow for mount. require using their cmd tool which sucks big time)  \ngdrive (not really a server friendly solution)  \nMicrosoft (I hate Microsoft)  \npCloud (nice but their tool cannot be compiled successfully for some reason.. wish it would but hoping to find alternative here)  \n[Sync.com](https://Sync.com) (very bad reputation.. feel free to change my mind, I have no personal experience with this service. I just read some stuff on reddit about it and it gave me a bad vibes)  \n\n\nthanks!", "author_fullname": "t2_elz9khng", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a free and safe place to keep database backups (small files)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m9nuw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688056555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I am looking for a FREE cloud storage provider who allows to mount the storage directly to a linux server to use as a backup for sql dumps. &lt;/p&gt;\n\n&lt;p&gt;Database files are rather small and I certainly dont mind paying, its just I can fit within free tier of most providers easily. Looking for one with the mount support like I described.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Dont want:&lt;br/&gt;\nMega (dont allow for mount. require using their cmd tool which sucks big time)&lt;br/&gt;\ngdrive (not really a server friendly solution)&lt;br/&gt;\nMicrosoft (I hate Microsoft)&lt;br/&gt;\npCloud (nice but their tool cannot be compiled successfully for some reason.. wish it would but hoping to find alternative here)&lt;br/&gt;\n&lt;a href=\"https://Sync.com\"&gt;Sync.com&lt;/a&gt; (very bad reputation.. feel free to change my mind, I have no personal experience with this service. I just read some stuff on reddit about it and it gave me a bad vibes)  &lt;/p&gt;\n\n&lt;p&gt;thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m9nuw", "is_robot_indexable": true, "report_reasons": null, "author": "madroots2", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m9nuw/looking_for_a_free_and_safe_place_to_keep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m9nuw/looking_for_a_free_and_safe_place_to_keep/", "subreddit_subscribers": 690237, "created_utc": 1688056555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "On my windowa laptop i use Wincatalog for cataloguing external hard disks. But on my mac book I have not found any good software so far for this. Please suggest. If it is cheap or free it would be bonus. But dont have a problem paying for a really good software.", "author_fullname": "t2_8x9iq4z6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mac Software for Cataloguing External Hard Disks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m3zge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688042405.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;On my windowa laptop i use Wincatalog for cataloguing external hard disks. But on my mac book I have not found any good software so far for this. Please suggest. If it is cheap or free it would be bonus. But dont have a problem paying for a really good software.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m3zge", "is_robot_indexable": true, "report_reasons": null, "author": "general_smooth", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m3zge/mac_software_for_cataloguing_external_hard_disks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m3zge/mac_software_for_cataloguing_external_hard_disks/", "subreddit_subscribers": 690237, "created_utc": 1688042405.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What are some of the methods of encrypting my data for syncing to the cloud services like Drop Box, Crash Plan and the likes?\n\nI have been packing my data into password-protected RAR format, as a storage medium, without compression and sync by the folders/directories to the cloud. This also has created twice the amount of space at the local level: keeping the original files and the synced RARs. I have been doing this for the last couple years and it getting out of hand. I have about 2TB of data synced up, so 4TB at the local storage. Is there a way to encrypt the original directory and sync it to the cloud? If there's any changes to it (adding or deleting files), that shouldn't affect the overall structure of the folder and just sync the files. Thanks!", "author_fullname": "t2_a0k2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local Encryption for Cloud Backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14mfrhx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688070990.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are some of the methods of encrypting my data for syncing to the cloud services like Drop Box, Crash Plan and the likes?&lt;/p&gt;\n\n&lt;p&gt;I have been packing my data into password-protected RAR format, as a storage medium, without compression and sync by the folders/directories to the cloud. This also has created twice the amount of space at the local level: keeping the original files and the synced RARs. I have been doing this for the last couple years and it getting out of hand. I have about 2TB of data synced up, so 4TB at the local storage. Is there a way to encrypt the original directory and sync it to the cloud? If there&amp;#39;s any changes to it (adding or deleting files), that shouldn&amp;#39;t affect the overall structure of the folder and just sync the files. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14mfrhx", "is_robot_indexable": true, "report_reasons": null, "author": "nizzz", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14mfrhx/local_encryption_for_cloud_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14mfrhx/local_encryption_for_cloud_backup/", "subreddit_subscribers": 690237, "created_utc": 1688070990.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Google workspace has finally started to stomp out affordable cloud for backup via shared drives, so i'm looking to replace it for cold storage with LTO5 (Unless someone has a spare LTO6~9 reader handy?)\n\nI have got a 60 day now 56 day notice of the end times for my Workspace account.\n\nSo down to reality I'm down to 28.2TB but 9.1TB of this data is for the r/vhsdecode community If people want to [archive this public data](https://drive.google.com/drive/u/1/folders/1lzQWdFFfVclEQUDbuwngro0MCusOgPM6?usp=sharing) which is used for testing/demo and the long term development to multible places, I would appreciate it! first to go will be [5.7TB of teletext/tv data](https://drive.google.com/open?id=1NvVDPjMbZ06CemD_a4kiXhGDnm5OnSpA&amp;usp=drive_fs) which still exists on 2 physical offline copys so non-critical.\n\nSo i'm currently looking for recommendations for software to use LTO5 SAS readers on Linux Mint/Windows 10, I have a MBP 2017 so could go TB3--&gt;PCIe--&gt;SAS but would like to stick to Linux/Windows on a dedicated station ideally.\n\nI know there is plenty of \"commercial\" solutions but, I'm just looking for a GUI or CLI software like I have with K3B for doing archival to M-Disc Blu-Rays, my requiremet is to take compressed folders and or files and save them to tape, I dont need anything fancy just a simple burn and somthing to make universally compatible indexes with checksums/filesize/name/date infomation fields so I know what tape to pull out of storage later.\n\nIn taking on this jorney I would like to collect enough infomation to make a comprehensive guide for outhers in the process as its a bit grey for new commers.", "author_fullname": "t2_413nr2z7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Due to Google Workspace... Need LTO Tape Library Software &amp; Workflow Recomendations 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14mfjoh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688073283.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688070485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Google workspace has finally started to stomp out affordable cloud for backup via shared drives, so i&amp;#39;m looking to replace it for cold storage with LTO5 (Unless someone has a spare LTO6~9 reader handy?)&lt;/p&gt;\n\n&lt;p&gt;I have got a 60 day now 56 day notice of the end times for my Workspace account.&lt;/p&gt;\n\n&lt;p&gt;So down to reality I&amp;#39;m down to 28.2TB but 9.1TB of this data is for the &lt;a href=\"/r/vhsdecode\"&gt;r/vhsdecode&lt;/a&gt; community If people want to &lt;a href=\"https://drive.google.com/drive/u/1/folders/1lzQWdFFfVclEQUDbuwngro0MCusOgPM6?usp=sharing\"&gt;archive this public data&lt;/a&gt; which is used for testing/demo and the long term development to multible places, I would appreciate it! first to go will be &lt;a href=\"https://drive.google.com/open?id=1NvVDPjMbZ06CemD_a4kiXhGDnm5OnSpA&amp;amp;usp=drive_fs\"&gt;5.7TB of teletext/tv data&lt;/a&gt; which still exists on 2 physical offline copys so non-critical.&lt;/p&gt;\n\n&lt;p&gt;So i&amp;#39;m currently looking for recommendations for software to use LTO5 SAS readers on Linux Mint/Windows 10, I have a MBP 2017 so could go TB3--&amp;gt;PCIe--&amp;gt;SAS but would like to stick to Linux/Windows on a dedicated station ideally.&lt;/p&gt;\n\n&lt;p&gt;I know there is plenty of &amp;quot;commercial&amp;quot; solutions but, I&amp;#39;m just looking for a GUI or CLI software like I have with K3B for doing archival to M-Disc Blu-Rays, my requiremet is to take compressed folders and or files and save them to tape, I dont need anything fancy just a simple burn and somthing to make universally compatible indexes with checksums/filesize/name/date infomation fields so I know what tape to pull out of storage later.&lt;/p&gt;\n\n&lt;p&gt;In taking on this jorney I would like to collect enough infomation to make a comprehensive guide for outhers in the process as its a bit grey for new commers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "80TB \ud83c\udfe0 30TB \u2601\ufe0f", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14mfjoh", "is_robot_indexable": true, "report_reasons": null, "author": "TheRealHarrypm", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/14mfjoh/due_to_google_workspace_need_lto_tape_library/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14mfjoh/due_to_google_workspace_need_lto_tape_library/", "subreddit_subscribers": 690237, "created_utc": 1688070485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey fellow Redditors,\n\nI've recently been doing some research on getting myself a NAS setup and came across Terramaster and Synology as two potential choices. Synology is recommended by many and Terramaster is quite cheaper compared to Synology.\n\nI'm particularly interested in learning more about the software side of both brands because this is being so rarely mentioned. People usually say \"Synology is much better in terms of software...\" but never go into details of how exactly so ?\n\nIf you have any experience or knowledge regarding this topic, I'd greatly appreciate your insights especially if you own both of them it would be great to have your comments.\n\nAny advice or recommendations would also be highly appreciated.\n\n---\n\nJust for reference the two models I'm in between are:\n\n1. Terramaster F5-422 - 5-Bay -&gt; 480$ (There is a discount)\n2. Synology DS920+ - 4-Bay -&gt; 700$\n\nHowever I'm more keen on the software differences between the two", "author_fullname": "t2_2pehmw0n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Terramaster Vs Synology from Software side", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14mfa2x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688069854.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve recently been doing some research on getting myself a NAS setup and came across Terramaster and Synology as two potential choices. Synology is recommended by many and Terramaster is quite cheaper compared to Synology.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m particularly interested in learning more about the software side of both brands because this is being so rarely mentioned. People usually say &amp;quot;Synology is much better in terms of software...&amp;quot; but never go into details of how exactly so ?&lt;/p&gt;\n\n&lt;p&gt;If you have any experience or knowledge regarding this topic, I&amp;#39;d greatly appreciate your insights especially if you own both of them it would be great to have your comments.&lt;/p&gt;\n\n&lt;p&gt;Any advice or recommendations would also be highly appreciated.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Just for reference the two models I&amp;#39;m in between are:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Terramaster F5-422 - 5-Bay -&amp;gt; 480$ (There is a discount)&lt;/li&gt;\n&lt;li&gt;Synology DS920+ - 4-Bay -&amp;gt; 700$&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;However I&amp;#39;m more keen on the software differences between the two&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14mfa2x", "is_robot_indexable": true, "report_reasons": null, "author": "DuplexEspresso", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14mfa2x/terramaster_vs_synology_from_software_side/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14mfa2x/terramaster_vs_synology_from_software_side/", "subreddit_subscribers": 690237, "created_utc": 1688069854.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "WARNING: I don't want to use ZFS so if you're going to suggest that, just keep on walking please. :)\n\nMy current setup is a main server with an MDADM RAID 6 array (XFS fs, 72TB total, 20 4TB drives) and the backup server is an MDADM RAID 5 array (XFS fs, 72TB total, 10 8TB drives). Every day, the main server backs does an rsync to the backup server.\n\nOver the years, I've added drives to both arrays and after a day or so of non-stop re-silvering, everything just keeps humming along.\n\nMy next upgrade will be replacing all the 4TB drives on the main server with 8TB drives and just adding more 8TB drives to the backup server so I'll end up with 144TB in each chassis. I'm in no hurry as I have about 16+ TB of free space on my existing setup and based on my current storage trajectory, I'll have another year or so before I need to do any of this.\n\nWanting to cut down on re-silver time (due to unfounded?, scary stories about POSSIBLE read errors popping up during non-stop disk I/O of 8TB (and bigger drives), I was thinking about doing away with MDADM altogether and using LVM on both servers. If a drive fails, and brings the entire LVM down, I'll just replace the drive and copy data over and get back up and running.\n\nBUT, if I have everything in a single LVM, will life suck trying to figure out which files are missing? Will having an LVM with parity help that?\n\nNext question.... I wonder which is safer..... keep my existing setup (MDADM arrays on both servers) or LVM (with or without parity drive(s) on each: if a drive fails in MDADM, the hot spares will jump into rotation, re-silver kicks off and a day or 2 later, done vs...... LVMs on both and spend an hour or 2 copying data back to a failed 8TB drive and done.\n\nLike..... in a worst case scenario..... would one solution be any safer over the other? Sure, with MDADM, I have guaranteed uptime vs LVM on both which would mean the main server would be offline for a couple of hours during the copy process if IT had a drive failure and I need to restore from the backup one.\n\nJust looking for opinions. Something I agree with others on, increasing drive capacity makes re-silvering more and more worrying to me. The thoughts of re-silvering 2, 16TB drives sends chills down my spine so I can see why folks lean towards some other solution......... but what? :)", "author_fullname": "t2_amep8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions about LVM parity and MDADM vs. LVM as backup on another system", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14mf2ik", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688069381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;WARNING: I don&amp;#39;t want to use ZFS so if you&amp;#39;re going to suggest that, just keep on walking please. :)&lt;/p&gt;\n\n&lt;p&gt;My current setup is a main server with an MDADM RAID 6 array (XFS fs, 72TB total, 20 4TB drives) and the backup server is an MDADM RAID 5 array (XFS fs, 72TB total, 10 8TB drives). Every day, the main server backs does an rsync to the backup server.&lt;/p&gt;\n\n&lt;p&gt;Over the years, I&amp;#39;ve added drives to both arrays and after a day or so of non-stop re-silvering, everything just keeps humming along.&lt;/p&gt;\n\n&lt;p&gt;My next upgrade will be replacing all the 4TB drives on the main server with 8TB drives and just adding more 8TB drives to the backup server so I&amp;#39;ll end up with 144TB in each chassis. I&amp;#39;m in no hurry as I have about 16+ TB of free space on my existing setup and based on my current storage trajectory, I&amp;#39;ll have another year or so before I need to do any of this.&lt;/p&gt;\n\n&lt;p&gt;Wanting to cut down on re-silver time (due to unfounded?, scary stories about POSSIBLE read errors popping up during non-stop disk I/O of 8TB (and bigger drives), I was thinking about doing away with MDADM altogether and using LVM on both servers. If a drive fails, and brings the entire LVM down, I&amp;#39;ll just replace the drive and copy data over and get back up and running.&lt;/p&gt;\n\n&lt;p&gt;BUT, if I have everything in a single LVM, will life suck trying to figure out which files are missing? Will having an LVM with parity help that?&lt;/p&gt;\n\n&lt;p&gt;Next question.... I wonder which is safer..... keep my existing setup (MDADM arrays on both servers) or LVM (with or without parity drive(s) on each: if a drive fails in MDADM, the hot spares will jump into rotation, re-silver kicks off and a day or 2 later, done vs...... LVMs on both and spend an hour or 2 copying data back to a failed 8TB drive and done.&lt;/p&gt;\n\n&lt;p&gt;Like..... in a worst case scenario..... would one solution be any safer over the other? Sure, with MDADM, I have guaranteed uptime vs LVM on both which would mean the main server would be offline for a couple of hours during the copy process if IT had a drive failure and I need to restore from the backup one.&lt;/p&gt;\n\n&lt;p&gt;Just looking for opinions. Something I agree with others on, increasing drive capacity makes re-silvering more and more worrying to me. The thoughts of re-silvering 2, 16TB drives sends chills down my spine so I can see why folks lean towards some other solution......... but what? :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14mf2ik", "is_robot_indexable": true, "report_reasons": null, "author": "road_hazard", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14mf2ik/questions_about_lvm_parity_and_mdadm_vs_lvm_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14mf2ik/questions_about_lvm_parity_and_mdadm_vs_lvm_as/", "subreddit_subscribers": 690237, "created_utc": 1688069381.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "wheni open up my mac from sleep ill see the external drive is connected and it shows its there but ill se the message about it improperly ejected. ive seen this notification a few times in the last week. is this a sign of drive failure? its a samsung t5 ssd and about 5 years old. little concerned but my data is backed up ", "author_fullname": "t2_2o8t3n2r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "getting a Improperly ejected external hard drive notification often", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14mf0zl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688069279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;wheni open up my mac from sleep ill see the external drive is connected and it shows its there but ill se the message about it improperly ejected. ive seen this notification a few times in the last week. is this a sign of drive failure? its a samsung t5 ssd and about 5 years old. little concerned but my data is backed up &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14mf0zl", "is_robot_indexable": true, "report_reasons": null, "author": "QualitySound96", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14mf0zl/getting_a_improperly_ejected_external_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14mf0zl/getting_a_improperly_ejected_external_hard_drive/", "subreddit_subscribers": 690237, "created_utc": 1688069279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, I am uploading 4TB worth of files from my WD My Passport External HDD. Im uploading it to Backblaze.\n\nDuring the upload process, will my external HDD continue spinning? I understand that it will take some time to finish, is it okay to leave my hdd on for a day or two?", "author_fullname": "t2_5t4wm6o5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uploading from portable external hard drive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14me2i6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688067050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am uploading 4TB worth of files from my WD My Passport External HDD. Im uploading it to Backblaze.&lt;/p&gt;\n\n&lt;p&gt;During the upload process, will my external HDD continue spinning? I understand that it will take some time to finish, is it okay to leave my hdd on for a day or two?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14me2i6", "is_robot_indexable": true, "report_reasons": null, "author": "linothefourth", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14me2i6/uploading_from_portable_external_hard_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14me2i6/uploading_from_portable_external_hard_drive/", "subreddit_subscribers": 690237, "created_utc": 1688067050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a few really large movie files that don't play in my crappy  laptop. On my tv though they play without any problems. I just want a way to play them in my laptop so I can verify if the subtitles are in sync. So basically it has to be the fastest way possible to create another file much smaller just so I can do this, and then I would delete the small files and play the big ones on tv with the subtitle already synchronized.", "author_fullname": "t2_1kncv7m0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fastest way to reduce file size? No problem in reducing video quality at all", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14mdtvv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688066477.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few really large movie files that don&amp;#39;t play in my crappy  laptop. On my tv though they play without any problems. I just want a way to play them in my laptop so I can verify if the subtitles are in sync. So basically it has to be the fastest way possible to create another file much smaller just so I can do this, and then I would delete the small files and play the big ones on tv with the subtitle already synchronized.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14mdtvv", "is_robot_indexable": true, "report_reasons": null, "author": "rollingcircus123", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14mdtvv/fastest_way_to_reduce_file_size_no_problem_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14mdtvv/fastest_way_to_reduce_file_size_no_problem_in/", "subreddit_subscribers": 690237, "created_utc": 1688066477.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently got an external HDD (WD elements 16TB), and I'm mainly using it for my plex server. I upgraded from an external seagate 5TB, which was a 2.5 inches. When I used my old 5TB drive, it didn't have any boot time (or none that I could notice), but my 16TB takes about 10 seconds to boot up. It starts making this noise, which I know is normal by reading other posts on this sub.\n\nNow my problem is that the drive seems to \"sleep\" every 20 min or so (or maybe less). I'm noticing this because whenever I'm using plex and pick an episode to watch, the drive boot up sounds start, and I'm waiting around 10 sec for the episode to start. And then when I want to go for the next episode, it does the same thing. My episodes are around 20 min long, so after the drive reads the whole episode, and it's all cached on my plex media player (the client), the drive goes to sleep, and only turns back on when I'm going for the next episode.\n\nSo is there a way to increase the drive's sleep time? If I make it to be around 30 min, I should be fine, and it should never sleep when I'm using plex because the episode are only 20 min long. But I think that the manufacturer put this feature for a reason, and maybe it's for the longevity of the drive? I never had this issue on my 2.5 external seagate, so I don't know if the 2.5inch take less time to boot, or it's the 5TB vs 16TB size difference that causes this. So what do you suggest I do? I'd prefer making the sleep time longer, but if it would be bad for the drive's health, I can live with waiting 10 second before an episode starts.", "author_fullname": "t2_4bxhznee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD elements 16TB sleeps every 20min", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14mbh08", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688060881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently got an external HDD (WD elements 16TB), and I&amp;#39;m mainly using it for my plex server. I upgraded from an external seagate 5TB, which was a 2.5 inches. When I used my old 5TB drive, it didn&amp;#39;t have any boot time (or none that I could notice), but my 16TB takes about 10 seconds to boot up. It starts making this noise, which I know is normal by reading other posts on this sub.&lt;/p&gt;\n\n&lt;p&gt;Now my problem is that the drive seems to &amp;quot;sleep&amp;quot; every 20 min or so (or maybe less). I&amp;#39;m noticing this because whenever I&amp;#39;m using plex and pick an episode to watch, the drive boot up sounds start, and I&amp;#39;m waiting around 10 sec for the episode to start. And then when I want to go for the next episode, it does the same thing. My episodes are around 20 min long, so after the drive reads the whole episode, and it&amp;#39;s all cached on my plex media player (the client), the drive goes to sleep, and only turns back on when I&amp;#39;m going for the next episode.&lt;/p&gt;\n\n&lt;p&gt;So is there a way to increase the drive&amp;#39;s sleep time? If I make it to be around 30 min, I should be fine, and it should never sleep when I&amp;#39;m using plex because the episode are only 20 min long. But I think that the manufacturer put this feature for a reason, and maybe it&amp;#39;s for the longevity of the drive? I never had this issue on my 2.5 external seagate, so I don&amp;#39;t know if the 2.5inch take less time to boot, or it&amp;#39;s the 5TB vs 16TB size difference that causes this. So what do you suggest I do? I&amp;#39;d prefer making the sleep time longer, but if it would be bad for the drive&amp;#39;s health, I can live with waiting 10 second before an episode starts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14mbh08", "is_robot_indexable": true, "report_reasons": null, "author": "MoonlessNightss", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14mbh08/wd_elements_16tb_sleeps_every_20min/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14mbh08/wd_elements_16tb_sleeps_every_20min/", "subreddit_subscribers": 690237, "created_utc": 1688060881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is it possible that I only select the two HDDs in my system for RAID 1 to store and backup my data while keeping my SSD only for programs and OS?\n\nAlso can I add new drives without adding them to the RAID setup?  \nI'm new to RAID...\n\nThe two HDDs are 2TB 7200rpm drives if that matters while my SSD is an m.2 1TB.  \n", "author_fullname": "t2_21n9ijwe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MSI B450 Tomahawk Max Raid Setup (1 SSD without raid and 2 HDDs in RAID 1) possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ma9x1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688058046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible that I only select the two HDDs in my system for RAID 1 to store and backup my data while keeping my SSD only for programs and OS?&lt;/p&gt;\n\n&lt;p&gt;Also can I add new drives without adding them to the RAID setup?&lt;br/&gt;\nI&amp;#39;m new to RAID...&lt;/p&gt;\n\n&lt;p&gt;The two HDDs are 2TB 7200rpm drives if that matters while my SSD is an m.2 1TB.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14ma9x1", "is_robot_indexable": true, "report_reasons": null, "author": "NKkrisz", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14ma9x1/msi_b450_tomahawk_max_raid_setup_1_ssd_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14ma9x1/msi_b450_tomahawk_max_raid_setup_1_ssd_without/", "subreddit_subscribers": 690237, "created_utc": 1688058046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm not sure what to use to preserve about 500gb-1tb of videos and maybe a bit of music:\n\nI was considering SSDs but they're known to fail, despite there being the chance that they could last over ten years. That's the sort of timeframe I would like - decades. At least one decade. Specifically I was considering the Sandisk Extreme and Samsung T7 which seem a popular choice for casual use but they may last three to five years. If that's the case, then I'd like to reconsider. I just don't want to risk losing it all, or paying for both the initial storage and a backup. Would cloud storage be reasonable? I mean, paid cloud storage so that there's a bit of security for something so non-physical. I don't know if cloud storage would have longevity either but I feel like it would - Google Drive has been pretty consistent.\n\nI don't have too much money I would like to spend but I can always spend more if there's a high chance of longevity. I've also heard of m-discs but I don't have a disk player on my computer.\n\nCurrently my files are spread across numerous USBs and I know that they are quite short-term, hence their incredibly low price.", "author_fullname": "t2_c39ycuca", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Long-term Archiving", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m8ild", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688053831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not sure what to use to preserve about 500gb-1tb of videos and maybe a bit of music:&lt;/p&gt;\n\n&lt;p&gt;I was considering SSDs but they&amp;#39;re known to fail, despite there being the chance that they could last over ten years. That&amp;#39;s the sort of timeframe I would like - decades. At least one decade. Specifically I was considering the Sandisk Extreme and Samsung T7 which seem a popular choice for casual use but they may last three to five years. If that&amp;#39;s the case, then I&amp;#39;d like to reconsider. I just don&amp;#39;t want to risk losing it all, or paying for both the initial storage and a backup. Would cloud storage be reasonable? I mean, paid cloud storage so that there&amp;#39;s a bit of security for something so non-physical. I don&amp;#39;t know if cloud storage would have longevity either but I feel like it would - Google Drive has been pretty consistent.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t have too much money I would like to spend but I can always spend more if there&amp;#39;s a high chance of longevity. I&amp;#39;ve also heard of m-discs but I don&amp;#39;t have a disk player on my computer.&lt;/p&gt;\n\n&lt;p&gt;Currently my files are spread across numerous USBs and I know that they are quite short-term, hence their incredibly low price.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m8ild", "is_robot_indexable": true, "report_reasons": null, "author": "queenofthehours1971", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m8ild/longterm_archiving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m8ild/longterm_archiving/", "subreddit_subscribers": 690237, "created_utc": 1688053831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I came down with some kind of disease (it's still ongoing) where I scrubbed the marketplace on low hours, low on/off count 4TB HDDs. I currently have 5, with no signs of slowing down. They were mostly WD Purples and nighthawks (I know... but they were 36 bucks)\n\nI'm planning on deploying them on a trunas scale machine, just for general NAS usage and media center (with some HDD being offline backups of important files). Nothing high-performance (I only have gigabit ethernet, old dualcore machine) But I can't seem to find any guide on the pre-deployment process. Like what kind of diagnostics to do, what programs to use, best practices, what to look for, is it even worth it spending days diagnosing, etc. Right now I'm only relying on crystaldiskinfo which is really not in-depth.\n\nAny inputs would help tremendously. Hoping it can prevent some headaches I might encounter in the future had I not done them today. Thanks a lot! Happy hunting!", "author_fullname": "t2_1jo7anhj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a general guide/steps before deploying (used) HDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m1yz0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688036368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came down with some kind of disease (it&amp;#39;s still ongoing) where I scrubbed the marketplace on low hours, low on/off count 4TB HDDs. I currently have 5, with no signs of slowing down. They were mostly WD Purples and nighthawks (I know... but they were 36 bucks)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning on deploying them on a trunas scale machine, just for general NAS usage and media center (with some HDD being offline backups of important files). Nothing high-performance (I only have gigabit ethernet, old dualcore machine) But I can&amp;#39;t seem to find any guide on the pre-deployment process. Like what kind of diagnostics to do, what programs to use, best practices, what to look for, is it even worth it spending days diagnosing, etc. Right now I&amp;#39;m only relying on crystaldiskinfo which is really not in-depth.&lt;/p&gt;\n\n&lt;p&gt;Any inputs would help tremendously. Hoping it can prevent some headaches I might encounter in the future had I not done them today. Thanks a lot! Happy hunting!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m1yz0", "is_robot_indexable": true, "report_reasons": null, "author": "rsnst", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m1yz0/looking_for_a_general_guidesteps_before_deploying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m1yz0/looking_for_a_general_guidesteps_before_deploying/", "subreddit_subscribers": 690237, "created_utc": 1688036368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am planning to build a NAS using a Pi4 running Rasbian light.\n\nI know I have different options, open media vault, FileCloud and NextCloud.\n\nMy main purpose is to back up photos automatically from the camera roll on iPhones, similar to Google photos.\n\nDo all three solutions support this? Which one has the better iOS app?\nThe setup will be super basic, I will just be mounting a 4tb hard drive to my Pi. \n \nThank you :-)", "author_fullname": "t2_ld9gl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best iOS photo backup on a Raspberry pi?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m1y0v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688036277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning to build a NAS using a Pi4 running Rasbian light.&lt;/p&gt;\n\n&lt;p&gt;I know I have different options, open media vault, FileCloud and NextCloud.&lt;/p&gt;\n\n&lt;p&gt;My main purpose is to back up photos automatically from the camera roll on iPhones, similar to Google photos.&lt;/p&gt;\n\n&lt;p&gt;Do all three solutions support this? Which one has the better iOS app?\nThe setup will be super basic, I will just be mounting a 4tb hard drive to my Pi. &lt;/p&gt;\n\n&lt;p&gt;Thank you :-)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m1y0v", "is_robot_indexable": true, "report_reasons": null, "author": "AlexKLMan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m1y0v/best_ios_photo_backup_on_a_raspberry_pi/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m1y0v/best_ios_photo_backup_on_a_raspberry_pi/", "subreddit_subscribers": 690237, "created_utc": 1688036277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I am in the process of ripping my dads CD collection wit EAC as mentioned in another post on this sub.   \n\n\nI would like to take the root folder and run it through a tool to fill in the metadata as well as embed the cover artwork, so when I play it via VLC on my chromecast, it displays both the artwork and the proper title and author.  \n\n\nIf it is any help I have the following folder structure:\n\n    CDs\n    \u251c\u2500\u2500 Album 1\n    \u2502   \u251c\u2500\u2500 Song 1.wav\n    \u2502   \u251c\u2500\u2500 Song 2.wav\n    \u2502   \u2514\u2500\u2500 Song 3.wav\n    \u251c\u2500\u2500 Album 2\n    \u2502   \u251c\u2500\u2500 Song 1.wav\n    \u2502   \u251c\u2500\u2500 Song 2.wav\n    \u2502   \u2514\u2500\u2500 Song 3.wav\n    \u2514\u2500\u2500 Album 3\n        \u251c\u2500\u2500 Song 1.wav\n        \u251c\u2500\u2500 Song 2.wav\n        \u2514\u2500\u2500 Song 3.wav\n\n&amp;#x200B;", "author_fullname": "t2_3umnofow", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A way to get CD metadata and artwork", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14m10d1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688033110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am in the process of ripping my dads CD collection wit EAC as mentioned in another post on this sub.   &lt;/p&gt;\n\n&lt;p&gt;I would like to take the root folder and run it through a tool to fill in the metadata as well as embed the cover artwork, so when I play it via VLC on my chromecast, it displays both the artwork and the proper title and author.  &lt;/p&gt;\n\n&lt;p&gt;If it is any help I have the following folder structure:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;CDs\n\u251c\u2500\u2500 Album 1\n\u2502   \u251c\u2500\u2500 Song 1.wav\n\u2502   \u251c\u2500\u2500 Song 2.wav\n\u2502   \u2514\u2500\u2500 Song 3.wav\n\u251c\u2500\u2500 Album 2\n\u2502   \u251c\u2500\u2500 Song 1.wav\n\u2502   \u251c\u2500\u2500 Song 2.wav\n\u2502   \u2514\u2500\u2500 Song 3.wav\n\u2514\u2500\u2500 Album 3\n    \u251c\u2500\u2500 Song 1.wav\n    \u251c\u2500\u2500 Song 2.wav\n    \u2514\u2500\u2500 Song 3.wav\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14m10d1", "is_robot_indexable": true, "report_reasons": null, "author": "Arimodu", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14m10d1/a_way_to_get_cd_metadata_and_artwork/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14m10d1/a_way_to_get_cd_metadata_and_artwork/", "subreddit_subscribers": 690237, "created_utc": 1688033110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi All,\n\nSo I have a Samsung 970Evo Plus less than a year old that started to fail.  I have a stable workstation since more than year and I recently added a rtx3090 for ML/Cuda work. Then by chance I noticed some failures on a btrfs partition that was not recognized anymore.\n\nI rebooted to a rescue session and I could confirm btrfs filesystem check errors. On this disk I have 3 btrfs partitions. One does not mount anymore and the two others have errors but still mounting. On the kernel messages I can clearly see the I/O errors during fs check. \n\nI turned off the system  until receiving a replacement disk. However I want to know what was the most likely reason for this ? \n\n1. I struggled a bit when I mounted the graphic card and probably physically touched this nvme disk but nothing extreme. Could it be due to shock ?\n\n2. The GPU was mounted on a PCIe slot right over this nvme slot which basically fully covered it. Could it be due to the heat ? \n\nIn any case I will probably change the GPU location far from the nvme slots but am curious what is the most probable reason ?\n\nEDIT:\n\nsince I was using this disk for the linux system using a btrfs partition + separate boot UEFI partition, my plan for replacing the new one was the following:\n\n- Clone the whole disk using Clonezilla \n- Then do an other `btrfs replace` on the btrfs partitions than can be mounted from old to new.\n- than try a btrfs recovery on the cloned but non mountable broken btrfs partition\n\n\nIs this a good strategy ?", "author_fullname": "t2_dm4m2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "nvme hw failures after installing GPU right over it", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14lz83z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1688046132.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1688026945.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;So I have a Samsung 970Evo Plus less than a year old that started to fail.  I have a stable workstation since more than year and I recently added a rtx3090 for ML/Cuda work. Then by chance I noticed some failures on a btrfs partition that was not recognized anymore.&lt;/p&gt;\n\n&lt;p&gt;I rebooted to a rescue session and I could confirm btrfs filesystem check errors. On this disk I have 3 btrfs partitions. One does not mount anymore and the two others have errors but still mounting. On the kernel messages I can clearly see the I/O errors during fs check. &lt;/p&gt;\n\n&lt;p&gt;I turned off the system  until receiving a replacement disk. However I want to know what was the most likely reason for this ? &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;I struggled a bit when I mounted the graphic card and probably physically touched this nvme disk but nothing extreme. Could it be due to shock ?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The GPU was mounted on a PCIe slot right over this nvme slot which basically fully covered it. Could it be due to the heat ? &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;In any case I will probably change the GPU location far from the nvme slots but am curious what is the most probable reason ?&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;p&gt;since I was using this disk for the linux system using a btrfs partition + separate boot UEFI partition, my plan for replacing the new one was the following:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Clone the whole disk using Clonezilla &lt;/li&gt;\n&lt;li&gt;Then do an other &lt;code&gt;btrfs replace&lt;/code&gt; on the btrfs partitions than can be mounted from old to new.&lt;/li&gt;\n&lt;li&gt;than try a btrfs recovery on the cloned but non mountable broken btrfs partition&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is this a good strategy ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "14lz83z", "is_robot_indexable": true, "report_reasons": null, "author": "use_your_imagination", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/14lz83z/nvme_hw_failures_after_installing_gpu_right_over/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/14lz83z/nvme_hw_failures_after_installing_gpu_right_over/", "subreddit_subscribers": 690237, "created_utc": 1688026945.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}