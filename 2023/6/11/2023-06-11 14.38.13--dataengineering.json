{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[See here for the original r/dataengineering thread on this issue.](https://www.reddit.com/r/dataengineering/comments/140xtxu/does_the_de_community_want_to_join_the_reddit/)\n\n# What's going on?\n\nA recent Reddit policy change threatens to kill many beloved third-party mobile apps, making a great many quality-of-life features not seen in the official mobile app **permanently inaccessible** to users.\n\nOn May 31, 2023, Reddit announced they were raising the price to make calls to their API from being free to a level that will kill every third party app on Reddit, from [Apollo](https://www.reddit.com/r/apolloapp/comments/13ws4w3/had_a_call_with_reddit_to_discuss_pricing_bad/) to [Reddit is Fun](https://www.reddit.com/r/redditisfun/comments/13wxepd/rif_dev_here_reddits_api_changes_will_likely_kill/) to [Narwhal](https://www.reddit.com/r/getnarwhal/comments/13wv038/reddit_have_quoted_the_apollo_devs_a_ridiculous/jmdqtyt/) to [BaconReader](https://www.reddit.com/r/baconreader/comments/13wveb2/reddit_api_changes_and_baconreader/).\n\nEven if you're not a mobile user and don't use any of those apps, this is a step toward killing other ways of customizing Reddit, such as Reddit Enhancement Suite or the use of the old.reddit.com desktop interface.\n\nThis isn't only a problem on the user level: many subreddit moderators depend on tools only available outside the official app to keep their communities on-topic and spam-free.\n\n# What's the plan?\n\nOn June 12th, [many subreddits](https://old.reddit.com/r/ModCoord/comments/1401qw5/incomplete_and_growing_list_of_participating/) will be going dark to protest this policy. Some will return after 48 hours: others will go away *permanently* unless the issue is adequately addressed, since many moderators aren't able to put in the work they do with the poor tools available through the official app. This isn't something any of us do lightly: we do what we do because *we love Reddit*, and we truly believe this change will make it impossible to keep doing what we love.\n\nThe two-day blackout isn't the *goal*, and it isn't the end. Should things reach the 14th with no sign of Reddit choosing to fix what they've broken, we'll use the community and buzz we've built between then and now as a tool for further action.\n\nWhat can *you* do?\n\n1. **Complain.** Message the mods of [r/reddit](https://www.reddit.com/r/reddit/).com, who are the admins of the site: message [/u/reddit](https://www.reddit.com/u/reddit/): submit a [support request](https://support.reddithelp.com/hc/en-us/requests/new): comment in relevant threads on [r/reddit](https://www.reddit.com/r/reddit/), such as [this one](https://www.reddit.com/r/reddit/comments/12qwagm/an_update_regarding_reddits_api/), leave a negative review on their official iOS or Android app- and sign your username in support to this post.\n2. **Spread the word.** Rabble-rouse on related subreddits. Meme it up, make it spicy. Bitch about it to your cat. Suggest anyone you know who moderates a subreddit join us at our sister sub at [r/ModCoord](https://www.reddit.com/r/ModCoord/) \\- but please don't pester mods you *don't* know by simply spamming their modmail.\n3. **Boycott** ***and*** **spread the word...to Reddit's competition!** Stay off Reddit entirely on June 12th through the 13th- instead, take to your favorite *non*\\-Reddit platform of choice and make some noise in support!\n4. **Don't be a jerk.** As upsetting this may be, threats, profanity and vandalism will be worse than useless in getting people on our side. Please make every effort to be as restrained, polite, reasonable and law-abiding as possible.\n\n&amp;#x200B;\n\n*Any communication during the blackout will be made via* [*our official mailing list*](https://dataengineeringcommunity.substack.com/)*. Please sign up if you wish to receive updates.*", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "r/dataengineering will be joining the blackout from June 12-14 to protest the proposed API changes which will end 3rd party apps.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14663ur", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 266, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 266, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686418444.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/140xtxu/does_the_de_community_want_to_join_the_reddit/\"&gt;See here for the original r/dataengineering thread on this issue.&lt;/a&gt;&lt;/p&gt;\n\n&lt;h1&gt;What&amp;#39;s going on?&lt;/h1&gt;\n\n&lt;p&gt;A recent Reddit policy change threatens to kill many beloved third-party mobile apps, making a great many quality-of-life features not seen in the official mobile app &lt;strong&gt;permanently inaccessible&lt;/strong&gt; to users.&lt;/p&gt;\n\n&lt;p&gt;On May 31, 2023, Reddit announced they were raising the price to make calls to their API from being free to a level that will kill every third party app on Reddit, from &lt;a href=\"https://www.reddit.com/r/apolloapp/comments/13ws4w3/had_a_call_with_reddit_to_discuss_pricing_bad/\"&gt;Apollo&lt;/a&gt; to &lt;a href=\"https://www.reddit.com/r/redditisfun/comments/13wxepd/rif_dev_here_reddits_api_changes_will_likely_kill/\"&gt;Reddit is Fun&lt;/a&gt; to &lt;a href=\"https://www.reddit.com/r/getnarwhal/comments/13wv038/reddit_have_quoted_the_apollo_devs_a_ridiculous/jmdqtyt/\"&gt;Narwhal&lt;/a&gt; to &lt;a href=\"https://www.reddit.com/r/baconreader/comments/13wveb2/reddit_api_changes_and_baconreader/\"&gt;BaconReader&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Even if you&amp;#39;re not a mobile user and don&amp;#39;t use any of those apps, this is a step toward killing other ways of customizing Reddit, such as Reddit Enhancement Suite or the use of the old.reddit.com desktop interface.&lt;/p&gt;\n\n&lt;p&gt;This isn&amp;#39;t only a problem on the user level: many subreddit moderators depend on tools only available outside the official app to keep their communities on-topic and spam-free.&lt;/p&gt;\n\n&lt;h1&gt;What&amp;#39;s the plan?&lt;/h1&gt;\n\n&lt;p&gt;On June 12th, &lt;a href=\"https://old.reddit.com/r/ModCoord/comments/1401qw5/incomplete_and_growing_list_of_participating/\"&gt;many subreddits&lt;/a&gt; will be going dark to protest this policy. Some will return after 48 hours: others will go away &lt;em&gt;permanently&lt;/em&gt; unless the issue is adequately addressed, since many moderators aren&amp;#39;t able to put in the work they do with the poor tools available through the official app. This isn&amp;#39;t something any of us do lightly: we do what we do because &lt;em&gt;we love Reddit&lt;/em&gt;, and we truly believe this change will make it impossible to keep doing what we love.&lt;/p&gt;\n\n&lt;p&gt;The two-day blackout isn&amp;#39;t the &lt;em&gt;goal&lt;/em&gt;, and it isn&amp;#39;t the end. Should things reach the 14th with no sign of Reddit choosing to fix what they&amp;#39;ve broken, we&amp;#39;ll use the community and buzz we&amp;#39;ve built between then and now as a tool for further action.&lt;/p&gt;\n\n&lt;p&gt;What can &lt;em&gt;you&lt;/em&gt; do?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Complain.&lt;/strong&gt; Message the mods of &lt;a href=\"https://www.reddit.com/r/reddit/\"&gt;r/reddit&lt;/a&gt;.com, who are the admins of the site: message &lt;a href=\"https://www.reddit.com/u/reddit/\"&gt;/u/reddit&lt;/a&gt;: submit a &lt;a href=\"https://support.reddithelp.com/hc/en-us/requests/new\"&gt;support request&lt;/a&gt;: comment in relevant threads on &lt;a href=\"https://www.reddit.com/r/reddit/\"&gt;r/reddit&lt;/a&gt;, such as &lt;a href=\"https://www.reddit.com/r/reddit/comments/12qwagm/an_update_regarding_reddits_api/\"&gt;this one&lt;/a&gt;, leave a negative review on their official iOS or Android app- and sign your username in support to this post.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Spread the word.&lt;/strong&gt; Rabble-rouse on related subreddits. Meme it up, make it spicy. Bitch about it to your cat. Suggest anyone you know who moderates a subreddit join us at our sister sub at &lt;a href=\"https://www.reddit.com/r/ModCoord/\"&gt;r/ModCoord&lt;/a&gt; - but please don&amp;#39;t pester mods you &lt;em&gt;don&amp;#39;t&lt;/em&gt; know by simply spamming their modmail.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Boycott&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;and&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;spread the word...to Reddit&amp;#39;s competition!&lt;/strong&gt; Stay off Reddit entirely on June 12th through the 13th- instead, take to your favorite &lt;em&gt;non&lt;/em&gt;-Reddit platform of choice and make some noise in support!&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Don&amp;#39;t be a jerk.&lt;/strong&gt; As upsetting this may be, threats, profanity and vandalism will be worse than useless in getting people on our side. Please make every effort to be as restrained, polite, reasonable and law-abiding as possible.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Any communication during the blackout will be made via&lt;/em&gt; &lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;&lt;em&gt;our official mailing list&lt;/em&gt;&lt;/a&gt;&lt;em&gt;. Please sign up if you wish to receive updates.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5d8a87e8-a952-11eb-9a8a-0e3979f03641", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "14663ur", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 18, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14663ur/rdataengineering_will_be_joining_the_blackout/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/14663ur/rdataengineering_will_be_joining_the_blackout/", "subreddit_subscribers": 110100, "created_utc": 1686418444.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After reading some recommendations on [How do you guys ace your SQL skills? : dataengineering (reddit.com)](https://www.reddit.com/r/dataengineering/comments/vj10xz/how_do_you_guys_ace_your_sql_skills/) .\n\nI started reading the book T-SQL: Fundamentals. It\u2019s organized and packed it with lots of topics, such as joins, table expressions, window functions and so on.\n\nBut I haven\u2019t known exactly how will I apply those things in my upcoming Data Engineer position.\n\nI often ask myself:\n\n* What the point of learning CTEs?\n* Do I even need to master all kinds of joins as a Data Engineer?\n* How will I use window functions or stored procedures in my job?\n* \u2026\n\nI had minimal working experience, so here are my guesses:\n\n* Converting business rules, e.g. use mostly SELECT queries to calculate the total expense for each customer?\n* Building ETL pipeline, e.g.\n   * Extract: use SELECT to move data from Source tables to Staging Tables to store the query result temporarily.\n   * Transfrom + Load: use SELECT combined with aggregate/windows functions to transform and load (using MERGE? I guess) to the destination tables.\n* Probably implementing SCD type 1, 2\n\nAnd you see, my guesses are mostly related to merely using SELECT queries and not advanced SQL concepts.\n\n&gt;So my question is: ***How do you use SQL in daily tasks as a Data Engineer?***\n\nI did paste the entire question to chatGPT but I really want to know the actual use of SQL in real life and that's something only experienced Data Engineers out there can answer.\n\nThank you for reading. I hope you guys have a good day!", "author_fullname": "t2_l76nam8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83e\udd14\u2753How do you use SQL in daily tasks as a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146ifov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686456495.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686451422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After reading some recommendations on &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/vj10xz/how_do_you_guys_ace_your_sql_skills/\"&gt;How do you guys ace your SQL skills? : dataengineering (reddit.com)&lt;/a&gt; .&lt;/p&gt;\n\n&lt;p&gt;I started reading the book T-SQL: Fundamentals. It\u2019s organized and packed it with lots of topics, such as joins, table expressions, window functions and so on.&lt;/p&gt;\n\n&lt;p&gt;But I haven\u2019t known exactly how will I apply those things in my upcoming Data Engineer position.&lt;/p&gt;\n\n&lt;p&gt;I often ask myself:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What the point of learning CTEs?&lt;/li&gt;\n&lt;li&gt;Do I even need to master all kinds of joins as a Data Engineer?&lt;/li&gt;\n&lt;li&gt;How will I use window functions or stored procedures in my job?&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I had minimal working experience, so here are my guesses:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Converting business rules, e.g. use mostly SELECT queries to calculate the total expense for each customer?&lt;/li&gt;\n&lt;li&gt;Building ETL pipeline, e.g.\n\n&lt;ul&gt;\n&lt;li&gt;Extract: use SELECT to move data from Source tables to Staging Tables to store the query result temporarily.&lt;/li&gt;\n&lt;li&gt;Transfrom + Load: use SELECT combined with aggregate/windows functions to transform and load (using MERGE? I guess) to the destination tables.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Probably implementing SCD type 1, 2&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And you see, my guesses are mostly related to merely using SELECT queries and not advanced SQL concepts.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;So my question is: &lt;strong&gt;&lt;em&gt;How do you use SQL in daily tasks as a Data Engineer?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I did paste the entire question to chatGPT but I really want to know the actual use of SQL in real life and that&amp;#39;s something only experienced Data Engineers out there can answer.&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading. I hope you guys have a good day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146ifov", "is_robot_indexable": true, "report_reasons": null, "author": "lLovl", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146ifov/how_do_you_use_sql_in_daily_tasks_as_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146ifov/how_do_you_use_sql_in_daily_tasks_as_a_data/", "subreddit_subscribers": 110100, "created_utc": 1686451422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_k6yhi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IceDB v2 \ud83e\uddca - A dirt-cheap OLAP/data lake hybrid (PoC)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1463rqq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/pxreED4Ow1kAMCKv98b9bDgtrJKv6g9jlgCrm1wspdU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686412624.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.danthegoodman.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.danthegoodman.com/icedb-v2", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LZ3yDj2-ccvGMMzdEoYRlZooMAro9wyUDpgKtUNMI6w.jpg?auto=webp&amp;v=enabled&amp;s=bc135890a4b3e86dfae20d6e035e91dc2300c5c1", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/LZ3yDj2-ccvGMMzdEoYRlZooMAro9wyUDpgKtUNMI6w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=09910e0b0a55a1f16d1ae5e4aef040d0fefe5cce", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/LZ3yDj2-ccvGMMzdEoYRlZooMAro9wyUDpgKtUNMI6w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c00478eb2122acbd86ee37f81e3ef1854ed597d9", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/LZ3yDj2-ccvGMMzdEoYRlZooMAro9wyUDpgKtUNMI6w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=47b8995ee7f917c0cd039fc41b166abfb3866f71", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/LZ3yDj2-ccvGMMzdEoYRlZooMAro9wyUDpgKtUNMI6w.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=99458dd5fa715d9724fda556f8f1e7d6ea6bd090", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/LZ3yDj2-ccvGMMzdEoYRlZooMAro9wyUDpgKtUNMI6w.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=113465c40018ef500188c16e577bcc3deea9e830", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/LZ3yDj2-ccvGMMzdEoYRlZooMAro9wyUDpgKtUNMI6w.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9b693b48ab5dd4cd479e6b9046d26f917dcfb7f3", "width": 1080, "height": 567}], "variants": {}, "id": "DpoauKT_mTprty_xkNxG_mHBJK9kf8MCPhOQRMH44uU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1463rqq", "is_robot_indexable": true, "report_reasons": null, "author": "DanTheGoodman_", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1463rqq/icedb_v2_a_dirtcheap_olapdata_lake_hybrid_poc/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.danthegoodman.com/icedb-v2", "subreddit_subscribers": 110100, "created_utc": 1686412624.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seems to be a mishmash of stuff on YouTube, with dubious signal to noise.\n\nHoping someone could gently point me in the right direction.\n\nPS. I want to learn both approaches to pipelines: **low-code** (ADF/Data Flows GUI) and **pro-code** (SQL development).", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best bet for learning Azure Data Factory/Synapse Pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1467rq8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686422645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seems to be a mishmash of stuff on YouTube, with dubious signal to noise.&lt;/p&gt;\n\n&lt;p&gt;Hoping someone could gently point me in the right direction.&lt;/p&gt;\n\n&lt;p&gt;PS. I want to learn both approaches to pipelines: &lt;strong&gt;low-code&lt;/strong&gt; (ADF/Data Flows GUI) and &lt;strong&gt;pro-code&lt;/strong&gt; (SQL development).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1467rq8", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1467rq8/best_bet_for_learning_azure_data_factorysynapse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1467rq8/best_bet_for_learning_azure_data_factorysynapse/", "subreddit_subscribers": 110100, "created_utc": 1686422645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am a DE with 5 yrs experience now, I have majorly worked on building datapipelines and architectures using Aws services, Databricks and some apache airflow. I am a good python programmer and knows sql to moderate extent. \nAlso, I am Aws certified Solution Architect Associate. \n\nI am planning for a change of organization. \nHow should I prepare for the Interview. \nWhat are the areas I should concentrate. \nInterview resources I should refer. \nAny mock interview or screener portal I should try? \n\nI have 60 days for planning and preparation.", "author_fullname": "t2_nie4cn9s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE interview preparation guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146qptn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686480094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am a DE with 5 yrs experience now, I have majorly worked on building datapipelines and architectures using Aws services, Databricks and some apache airflow. I am a good python programmer and knows sql to moderate extent. \nAlso, I am Aws certified Solution Architect Associate. &lt;/p&gt;\n\n&lt;p&gt;I am planning for a change of organization. \nHow should I prepare for the Interview. \nWhat are the areas I should concentrate. \nInterview resources I should refer. \nAny mock interview or screener portal I should try? &lt;/p&gt;\n\n&lt;p&gt;I have 60 days for planning and preparation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146qptn", "is_robot_indexable": true, "report_reasons": null, "author": "sds66", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146qptn/de_interview_preparation_guide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146qptn/de_interview_preparation_guide/", "subreddit_subscribers": 110100, "created_utc": 1686480094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n&amp;#x200B;\n\nHello everyone,\n\n&amp;#x200B;\n\nI recently joined a new data engineering team, and I've noticed a few areas where we seem to be lacking a solid framework or best practices. I would greatly appreciate your suggestions and advice on how to address these challenges. Here are my observations:\n\n&amp;#x200B;\n\n1. Lack of Development Architecture: Our current approach to building pipelines involves using Python scripts as standalone jobs in Jenkins. However, we lack an orchestrator or a clear framework to separate the ETL process. As a result, our pipelines are not well-structured or easily manageable.\n\n&amp;#x200B;\n\n2. Internal API Dependency: We heavily rely on internal APIs as data sources, and more recently, we've started integrating streaming event data from Kafka topics. While the current approach provides us with data, it also means that we have a complex dependency on these APIs, which can introduce potential bottlenecks and fragility.\n\n&amp;#x200B;\n\n3. Repetition and Lack of Abstractions: I've noticed a significant amount of repetitive logic across our pipelines, including common modules. Additionally, the absence of wrappers or abstractions for consistently pulling data from our APIs leads to redundant code and increased maintenance overhead. Except for SQL Alchemy related functions, the logic in each pipeline is bespoke, making it challenging to maintain consistency.\n\n&amp;#x200B;\n\n4. Overreliance on Pandas: The data transformations performed by the Data Engineers heavily rely on pandas, resulting in complex and unorganized code. It becomes difficult to trace back where the output tables are generated from, as the logic spans hundreds of lines and often outputs multiple tables. This lack of modularity and structure makes it harder for others to understand and maintain the code.\n\n&amp;#x200B;\n\n5. Inconsistent SQL Integration: The SQL code is fragmented within the Python scripts, with SQL queries embedded by calling other Python scripts. This approach makes it harder to manage and understand the SQL codebase, leading to potential issues in data consistency and maintainability.\n\n&amp;#x200B;\n\nTo address these challenges, I have started by refactoring the common modules and introducing dbt. I believe it is crucial to abstract the Python code by introducing a layer or two, ensuring that all our ingestion processes follow a consistent pattern and output structure. Dbt has started providing better visibility and control over data transformations, replacing some of the complex pandas logic. However, I'm facing pushback from an experienced team member who prefers a more simplistic approach with a single table output per ingestion process. I find this approach to be an antipattern, but I'm struggling to clearly articulate the problems it can introduce.\n\n&amp;#x200B;\n\nMy background lies in working with dagster, dbt, and Snowflake, and I believe we have the resources to adopt a more scalable solution like Airflow, considering we are currently using PostgreSQL.\n\n&amp;#x200B;\n\nI would greatly appreciate your guidance on how to explain the flaws in our current approach to my team members. Any advice or suggestions on best practices, frameworks, or approaches would be highly valuable.\n\n&amp;#x200B;\n\nThank you in advance for your help and insights!", "author_fullname": "t2_10wjqv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice: Identifying and Addressing Data Engineering Challenges in My New Team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146mdqk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686464513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I recently joined a new data engineering team, and I&amp;#39;ve noticed a few areas where we seem to be lacking a solid framework or best practices. I would greatly appreciate your suggestions and advice on how to address these challenges. Here are my observations:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Lack of Development Architecture: Our current approach to building pipelines involves using Python scripts as standalone jobs in Jenkins. However, we lack an orchestrator or a clear framework to separate the ETL process. As a result, our pipelines are not well-structured or easily manageable.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Internal API Dependency: We heavily rely on internal APIs as data sources, and more recently, we&amp;#39;ve started integrating streaming event data from Kafka topics. While the current approach provides us with data, it also means that we have a complex dependency on these APIs, which can introduce potential bottlenecks and fragility.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Repetition and Lack of Abstractions: I&amp;#39;ve noticed a significant amount of repetitive logic across our pipelines, including common modules. Additionally, the absence of wrappers or abstractions for consistently pulling data from our APIs leads to redundant code and increased maintenance overhead. Except for SQL Alchemy related functions, the logic in each pipeline is bespoke, making it challenging to maintain consistency.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Overreliance on Pandas: The data transformations performed by the Data Engineers heavily rely on pandas, resulting in complex and unorganized code. It becomes difficult to trace back where the output tables are generated from, as the logic spans hundreds of lines and often outputs multiple tables. This lack of modularity and structure makes it harder for others to understand and maintain the code.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Inconsistent SQL Integration: The SQL code is fragmented within the Python scripts, with SQL queries embedded by calling other Python scripts. This approach makes it harder to manage and understand the SQL codebase, leading to potential issues in data consistency and maintainability.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To address these challenges, I have started by refactoring the common modules and introducing dbt. I believe it is crucial to abstract the Python code by introducing a layer or two, ensuring that all our ingestion processes follow a consistent pattern and output structure. Dbt has started providing better visibility and control over data transformations, replacing some of the complex pandas logic. However, I&amp;#39;m facing pushback from an experienced team member who prefers a more simplistic approach with a single table output per ingestion process. I find this approach to be an antipattern, but I&amp;#39;m struggling to clearly articulate the problems it can introduce.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My background lies in working with dagster, dbt, and Snowflake, and I believe we have the resources to adopt a more scalable solution like Airflow, considering we are currently using PostgreSQL.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate your guidance on how to explain the flaws in our current approach to my team members. Any advice or suggestions on best practices, frameworks, or approaches would be highly valuable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help and insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "146mdqk", "is_robot_indexable": true, "report_reasons": null, "author": "branllywd", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146mdqk/seeking_advice_identifying_and_addressing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146mdqk/seeking_advice_identifying_and_addressing_data/", "subreddit_subscribers": 110100, "created_utc": 1686464513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, all! I would appreciate your insights and advice on designing a data warehouse architecture for my project. Currently, we are bringing data from three different sources and dumping it as-is into an Azure SQL database. We then connect Power BI to this database to build reports. However, we now plan to implement a well-designed data warehouse with proper dimensional modeling.\n\nMy current idea is to create an Azure SQL database with two databases: one serving as a staging area and the other containing dimensionally modeled data. I believe this approach is suitable since our data size is under 1 TB, and using Synapse might not be necessary. However, I have a couple of concerns\n\n1. Can I use Azure Data Lake Storage (ADLS) as a staging area instead of Azure SQL database? My rationale behind this is that I can leverage CSV or Parquet files, but I am unsure if ADLS is an appropriate choice as a staging area without external tables to query the files.\n2. if i want to use adls i think iIshould go with synapse, so what is the cost difference going to be between azure sql db and serverless/dedicated sql pool in synapse. I understand it depends on many factors but please let me know if it is even worth considering synapse for my case\n\n&amp;#x200B;\n\nAre there any alternative architecture suggestions that you would recommend for my scenario?", "author_fullname": "t2_v1vre9oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Designing a Data Warehouse Architecture for Azure: Need Advice on Approach and Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146j6yq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686453797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, all! I would appreciate your insights and advice on designing a data warehouse architecture for my project. Currently, we are bringing data from three different sources and dumping it as-is into an Azure SQL database. We then connect Power BI to this database to build reports. However, we now plan to implement a well-designed data warehouse with proper dimensional modeling.&lt;/p&gt;\n\n&lt;p&gt;My current idea is to create an Azure SQL database with two databases: one serving as a staging area and the other containing dimensionally modeled data. I believe this approach is suitable since our data size is under 1 TB, and using Synapse might not be necessary. However, I have a couple of concerns&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can I use Azure Data Lake Storage (ADLS) as a staging area instead of Azure SQL database? My rationale behind this is that I can leverage CSV or Parquet files, but I am unsure if ADLS is an appropriate choice as a staging area without external tables to query the files.&lt;/li&gt;\n&lt;li&gt;if i want to use adls i think iIshould go with synapse, so what is the cost difference going to be between azure sql db and serverless/dedicated sql pool in synapse. I understand it depends on many factors but please let me know if it is even worth considering synapse for my case&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Are there any alternative architecture suggestions that you would recommend for my scenario?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "146j6yq", "is_robot_indexable": true, "report_reasons": null, "author": "sach_mess10", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146j6yq/designing_a_data_warehouse_architecture_for_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146j6yq/designing_a_data_warehouse_architecture_for_azure/", "subreddit_subscribers": 110100, "created_utc": 1686453797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been in data for ~8 years - from DBA, Analyst, Business Intelligence, to Consultant. Through all this I finally found what I *actually* enjoy doing and it\u2019s DE work.\n\nWith that said - I absolutely hate Pandas. It\u2019s almost like the developers of Pandas said \u201cHey. You know how everyone knows SQL? Let\u2019s make a program that uses completely different syntax. I\u2019m sure users will love it\u201d\n\nSpark on the other hand did it right.\n\nCurious for opinions from other experienced DEs - what do you think about Pandas?", "author_fullname": "t2_54i19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone else hate Pandas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146rj9m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686482813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been in data for ~8 years - from DBA, Analyst, Business Intelligence, to Consultant. Through all this I finally found what I &lt;em&gt;actually&lt;/em&gt; enjoy doing and it\u2019s DE work.&lt;/p&gt;\n\n&lt;p&gt;With that said - I absolutely hate Pandas. It\u2019s almost like the developers of Pandas said \u201cHey. You know how everyone knows SQL? Let\u2019s make a program that uses completely different syntax. I\u2019m sure users will love it\u201d&lt;/p&gt;\n\n&lt;p&gt;Spark on the other hand did it right.&lt;/p&gt;\n\n&lt;p&gt;Curious for opinions from other experienced DEs - what do you think about Pandas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146rj9m", "is_robot_indexable": true, "report_reasons": null, "author": "datingyourmom", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146rj9m/does_anyone_else_hate_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146rj9m/does_anyone_else_hate_pandas/", "subreddit_subscribers": 110100, "created_utc": 1686482813.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I'm posting here asking for guides developing a feature that combining decision tree &amp; data workflow. In brief, I want to build a feature that:\n\n1. Allow user to drag-and-drop to make a decision tree that split their data based on conditions: I think that I should use some 3rd plugins that help in drawing this tree, but couldn't found any. Currently I'm making a simple form instead\n2. After having that decision tree, the application should build an according workflow that runs SQL statements to produce desired output:\n\n\\+ At first, I supposed that if I was given a tree, I could myself make a single SQL statement for each branch of the tree to fetch data. However I realized that it is more difficult than I thought; it is not the normal SQL parse tree that I used to worked with.\n\n\\+ Their condition set includes OR condition, which makes me confuse to represent it on the decision tree. E.g: IF a.A=x OR a.B=y THEN a is categorized as M\n\n\\+ It the boss desire to make each condition evaluated on one step, and the output is then pipelined to the next select statement. I don't know if it is more efficient than the straightforward way of combining all features into one command only, but he rejected this idea and required us to do the workflow\n\n3. After having the output, transfer it to the target database, or emailing the result (in form of .csv/.xlsx file) to target user: I've done this task.\n\nHow should I do this? Apache Airflow and Apache Dolphin are suitable for building workflow by drag-and-drop, but not for making a decision tree. My users are not familiar with programming and writing SQL so it is impossible to tell them to write statements and put them in Airflow/Dolphin.\n\nThe source database lies on ClickHouse, and the target database is MariaDB.\n\nAny suggestion is appreciated.", "author_fullname": "t2_1qn84k08", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Asking for advice on a feature combining decision tree &amp; data workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1461v68", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686408536.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686407710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I&amp;#39;m posting here asking for guides developing a feature that combining decision tree &amp;amp; data workflow. In brief, I want to build a feature that:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Allow user to drag-and-drop to make a decision tree that split their data based on conditions: I think that I should use some 3rd plugins that help in drawing this tree, but couldn&amp;#39;t found any. Currently I&amp;#39;m making a simple form instead&lt;/li&gt;\n&lt;li&gt;After having that decision tree, the application should build an according workflow that runs SQL statements to produce desired output:&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;+ At first, I supposed that if I was given a tree, I could myself make a single SQL statement for each branch of the tree to fetch data. However I realized that it is more difficult than I thought; it is not the normal SQL parse tree that I used to worked with.&lt;/p&gt;\n\n&lt;p&gt;+ Their condition set includes OR condition, which makes me confuse to represent it on the decision tree. E.g: IF a.A=x OR a.B=y THEN a is categorized as M&lt;/p&gt;\n\n&lt;p&gt;+ It the boss desire to make each condition evaluated on one step, and the output is then pipelined to the next select statement. I don&amp;#39;t know if it is more efficient than the straightforward way of combining all features into one command only, but he rejected this idea and required us to do the workflow&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;After having the output, transfer it to the target database, or emailing the result (in form of .csv/.xlsx file) to target user: I&amp;#39;ve done this task.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;How should I do this? Apache Airflow and Apache Dolphin are suitable for building workflow by drag-and-drop, but not for making a decision tree. My users are not familiar with programming and writing SQL so it is impossible to tell them to write statements and put them in Airflow/Dolphin.&lt;/p&gt;\n\n&lt;p&gt;The source database lies on ClickHouse, and the target database is MariaDB.&lt;/p&gt;\n\n&lt;p&gt;Any suggestion is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1461v68", "is_robot_indexable": true, "report_reasons": null, "author": "saklovesyao", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1461v68/asking_for_advice_on_a_feature_combining_decision/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1461v68/asking_for_advice_on_a_feature_combining_decision/", "subreddit_subscribers": 110100, "created_utc": 1686407710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The manager of the data team where I work recently decided to switch to a different department so that he could be more hands on, they wanted him to be more managerial and it was too much for him. To replace him they found someone who has a history of managing teams in the tech space but has no technical experience herself and wouldn\u2019t be able to do things like code reviews before deployment. \nOn one hand, we loved him because he had the same background and he knew our capabilities so he took a hard line with the business if something was unreasonable. On the other hand, now we have someone purely dedicated to management who I feel will represent us well to the business even without the technical knowledge but won\u2019t be able to answer the technical questions or take care of certain tasks. \nWhat\u2019s everyone\u2019s preferences with these types of scenarios? Is one inherently better than the other?", "author_fullname": "t2_bfa6tlx6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manager with or without technical skills? What\u2019s your preference?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_146uka5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686491744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The manager of the data team where I work recently decided to switch to a different department so that he could be more hands on, they wanted him to be more managerial and it was too much for him. To replace him they found someone who has a history of managing teams in the tech space but has no technical experience herself and wouldn\u2019t be able to do things like code reviews before deployment. \nOn one hand, we loved him because he had the same background and he knew our capabilities so he took a hard line with the business if something was unreasonable. On the other hand, now we have someone purely dedicated to management who I feel will represent us well to the business even without the technical knowledge but won\u2019t be able to answer the technical questions or take care of certain tasks. \nWhat\u2019s everyone\u2019s preferences with these types of scenarios? Is one inherently better than the other?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146uka5", "is_robot_indexable": true, "report_reasons": null, "author": "Lost_Source824", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146uka5/manager_with_or_without_technical_skills_whats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146uka5/manager_with_or_without_technical_skills_whats/", "subreddit_subscribers": 110100, "created_utc": 1686491744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently working on my beginner DE side project and have come to a fork in the road for my solution architecture. Currently my python script scrapes a web site, generates a lot of small json records and now I would like to store the records for analytics. I would be generating about 25,000 unique records (in chunks) on a weekly basis. Schemas are the same or nearly the same between all the records.  \n\n&amp;nbsp;\n\n I\u2019m familiar with NoSQL but have never used it for a project and could see this as a good opportunity to learn it in a form such as MongoDB especially as the data is already in JSON.  \n\n&amp;nbsp;\n\nOn the other hand, with a little extra regular expression work I could transform the data into something more suitable for a relational database. I\u2019m already familiar with PostgreSQL. This could be a good option as I could then learn dbt. Or I could try to use both in my data pipeline? \n\n&amp;nbsp;\n\nThoughts?", "author_fullname": "t2_5bha3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solution architecture - MongoDB or PostgreSQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_146trgq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686490391.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686489532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently working on my beginner DE side project and have come to a fork in the road for my solution architecture. Currently my python script scrapes a web site, generates a lot of small json records and now I would like to store the records for analytics. I would be generating about 25,000 unique records (in chunks) on a weekly basis. Schemas are the same or nearly the same between all the records.  &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;I\u2019m familiar with NoSQL but have never used it for a project and could see this as a good opportunity to learn it in a form such as MongoDB especially as the data is already in JSON.  &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;On the other hand, with a little extra regular expression work I could transform the data into something more suitable for a relational database. I\u2019m already familiar with PostgreSQL. This could be a good option as I could then learn dbt. Or I could try to use both in my data pipeline? &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146trgq", "is_robot_indexable": true, "report_reasons": null, "author": "GreenSquid", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146trgq/solution_architecture_mongodb_or_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146trgq/solution_architecture_mongodb_or_postgresql/", "subreddit_subscribers": 110100, "created_utc": 1686489532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "i have passed a coding challenge for a summer internship the coding challenge include questions in sql,python,spark and elastic search what do you think i need to prepare for the interview. if you any ressource that can help please share it with me.", "author_fullname": "t2_feara4tb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "interview help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146bou7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686432600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have passed a coding challenge for a summer internship the coding challenge include questions in sql,python,spark and elastic search what do you think i need to prepare for the interview. if you any ressource that can help please share it with me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "146bou7", "is_robot_indexable": true, "report_reasons": null, "author": "Kratos_1412", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146bou7/interview_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146bou7/interview_help/", "subreddit_subscribers": 110100, "created_utc": 1686432600.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}