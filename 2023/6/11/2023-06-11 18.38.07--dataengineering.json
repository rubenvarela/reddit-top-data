{"kind": "Listing", "data": {"after": null, "dist": 14, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been in data for ~8 years - from DBA, Analyst, Business Intelligence, to Consultant. Through all this I finally found what I *actually* enjoy doing and it\u2019s DE work.\n\nWith that said - I absolutely hate Pandas. It\u2019s almost like the developers of Pandas said \u201cHey. You know how everyone knows SQL? Let\u2019s make a program that uses completely different syntax. I\u2019m sure users will love it\u201d\n\nSpark on the other hand did it right.\n\nCurious for opinions from other experienced DEs - what do you think about Pandas?\n\n*Thanks everyone who suggested Polars - definitely going to look into that", "author_fullname": "t2_54i19", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone else hate Pandas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146rj9m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686501478.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686482813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been in data for ~8 years - from DBA, Analyst, Business Intelligence, to Consultant. Through all this I finally found what I &lt;em&gt;actually&lt;/em&gt; enjoy doing and it\u2019s DE work.&lt;/p&gt;\n\n&lt;p&gt;With that said - I absolutely hate Pandas. It\u2019s almost like the developers of Pandas said \u201cHey. You know how everyone knows SQL? Let\u2019s make a program that uses completely different syntax. I\u2019m sure users will love it\u201d&lt;/p&gt;\n\n&lt;p&gt;Spark on the other hand did it right.&lt;/p&gt;\n\n&lt;p&gt;Curious for opinions from other experienced DEs - what do you think about Pandas?&lt;/p&gt;\n\n&lt;p&gt;*Thanks everyone who suggested Polars - definitely going to look into that&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146rj9m", "is_robot_indexable": true, "report_reasons": null, "author": "datingyourmom", "discussion_type": null, "num_comments": 94, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146rj9m/does_anyone_else_hate_pandas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146rj9m/does_anyone_else_hate_pandas/", "subreddit_subscribers": 110137, "created_utc": 1686482813.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "After reading some recommendations on [How do you guys ace your SQL skills? : dataengineering (reddit.com)](https://www.reddit.com/r/dataengineering/comments/vj10xz/how_do_you_guys_ace_your_sql_skills/) .\n\nI started reading the book T-SQL: Fundamentals. It\u2019s organized and packed it with lots of topics, such as joins, table expressions, window functions and so on.\n\nBut I haven\u2019t known exactly how will I apply those things in my upcoming Data Engineer position.\n\nI often ask myself:\n\n* What the point of learning CTEs?\n* Do I even need to master all kinds of joins as a Data Engineer?\n* How will I use window functions or stored procedures in my job?\n* \u2026\n\nI had minimal working experience, so here are my guesses:\n\n* Converting business rules, e.g. use mostly SELECT queries to calculate the total expense for each customer?\n* Building ETL pipeline, e.g.\n   * Extract: use SELECT to move data from Source tables to Staging Tables to store the query result temporarily.\n   * Transfrom + Load: use SELECT combined with aggregate/windows functions to transform and load (using MERGE? I guess) to the destination tables.\n* Probably implementing SCD type 1, 2\n\nAnd you see, my guesses are mostly related to merely using SELECT queries and not advanced SQL concepts.\n\n&gt;So my question is: ***How do you use SQL in daily tasks as a Data Engineer?***\n\nI did paste the entire question to chatGPT but I really want to know the actual use of SQL in real life and that's something only experienced Data Engineers out there can answer.\n\nThank you for reading. I hope you guys have a good day!", "author_fullname": "t2_l76nam8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83e\udd14\u2753How do you use SQL in daily tasks as a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146ifov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686456495.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686451422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After reading some recommendations on &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/vj10xz/how_do_you_guys_ace_your_sql_skills/\"&gt;How do you guys ace your SQL skills? : dataengineering (reddit.com)&lt;/a&gt; .&lt;/p&gt;\n\n&lt;p&gt;I started reading the book T-SQL: Fundamentals. It\u2019s organized and packed it with lots of topics, such as joins, table expressions, window functions and so on.&lt;/p&gt;\n\n&lt;p&gt;But I haven\u2019t known exactly how will I apply those things in my upcoming Data Engineer position.&lt;/p&gt;\n\n&lt;p&gt;I often ask myself:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What the point of learning CTEs?&lt;/li&gt;\n&lt;li&gt;Do I even need to master all kinds of joins as a Data Engineer?&lt;/li&gt;\n&lt;li&gt;How will I use window functions or stored procedures in my job?&lt;/li&gt;\n&lt;li&gt;\u2026&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I had minimal working experience, so here are my guesses:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Converting business rules, e.g. use mostly SELECT queries to calculate the total expense for each customer?&lt;/li&gt;\n&lt;li&gt;Building ETL pipeline, e.g.\n\n&lt;ul&gt;\n&lt;li&gt;Extract: use SELECT to move data from Source tables to Staging Tables to store the query result temporarily.&lt;/li&gt;\n&lt;li&gt;Transfrom + Load: use SELECT combined with aggregate/windows functions to transform and load (using MERGE? I guess) to the destination tables.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Probably implementing SCD type 1, 2&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;And you see, my guesses are mostly related to merely using SELECT queries and not advanced SQL concepts.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;So my question is: &lt;strong&gt;&lt;em&gt;How do you use SQL in daily tasks as a Data Engineer?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I did paste the entire question to chatGPT but I really want to know the actual use of SQL in real life and that&amp;#39;s something only experienced Data Engineers out there can answer.&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading. I hope you guys have a good day!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146ifov", "is_robot_indexable": true, "report_reasons": null, "author": "lLovl", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146ifov/how_do_you_use_sql_in_daily_tasks_as_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146ifov/how_do_you_use_sql_in_daily_tasks_as_a_data/", "subreddit_subscribers": 110137, "created_utc": 1686451422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The manager of the data team where I work recently decided to switch to a different department so that he could be more hands on, they wanted him to be more managerial and it was too much for him. To replace him they found someone who has a history of managing teams in the tech space but has no technical experience herself and wouldn\u2019t be able to do things like code reviews before deployment. \nOn one hand, we loved him because he had the same background and he knew our capabilities so he took a hard line with the business if something was unreasonable. On the other hand, now we have someone purely dedicated to management who I feel will represent us well to the business even without the technical knowledge but won\u2019t be able to answer the technical questions or take care of certain tasks. \nWhat\u2019s everyone\u2019s preferences with these types of scenarios? Is one inherently better than the other?", "author_fullname": "t2_bfa6tlx6p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Manager with or without technical skills? What\u2019s your preference?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146uka5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686491744.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The manager of the data team where I work recently decided to switch to a different department so that he could be more hands on, they wanted him to be more managerial and it was too much for him. To replace him they found someone who has a history of managing teams in the tech space but has no technical experience herself and wouldn\u2019t be able to do things like code reviews before deployment. \nOn one hand, we loved him because he had the same background and he knew our capabilities so he took a hard line with the business if something was unreasonable. On the other hand, now we have someone purely dedicated to management who I feel will represent us well to the business even without the technical knowledge but won\u2019t be able to answer the technical questions or take care of certain tasks. \nWhat\u2019s everyone\u2019s preferences with these types of scenarios? Is one inherently better than the other?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146uka5", "is_robot_indexable": true, "report_reasons": null, "author": "Lost_Source824", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146uka5/manager_with_or_without_technical_skills_whats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146uka5/manager_with_or_without_technical_skills_whats/", "subreddit_subscribers": 110137, "created_utc": 1686491744.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I am a DE with 5 yrs experience now, I have majorly worked on building datapipelines and architectures using Aws services, Databricks and some apache airflow. I am a good python programmer and knows sql to moderate extent. \nAlso, I am Aws certified Solution Architect Associate. \n\nI am planning for a change of organization. \nHow should I prepare for the Interview. \nWhat are the areas I should concentrate. \nInterview resources I should refer. \nAny mock interview or screener portal I should try? \n\nI have 60 days for planning and preparation.", "author_fullname": "t2_nie4cn9s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE interview preparation guide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146qptn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686480094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I am a DE with 5 yrs experience now, I have majorly worked on building datapipelines and architectures using Aws services, Databricks and some apache airflow. I am a good python programmer and knows sql to moderate extent. \nAlso, I am Aws certified Solution Architect Associate. &lt;/p&gt;\n\n&lt;p&gt;I am planning for a change of organization. \nHow should I prepare for the Interview. \nWhat are the areas I should concentrate. \nInterview resources I should refer. \nAny mock interview or screener portal I should try? &lt;/p&gt;\n\n&lt;p&gt;I have 60 days for planning and preparation.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146qptn", "is_robot_indexable": true, "report_reasons": null, "author": "sds66", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146qptn/de_interview_preparation_guide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146qptn/de_interview_preparation_guide/", "subreddit_subscribers": 110137, "created_utc": 1686480094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\n&amp;#x200B;\n\nHello everyone,\n\n&amp;#x200B;\n\nI recently joined a new data engineering team, and I've noticed a few areas where we seem to be lacking a solid framework or best practices. I would greatly appreciate your suggestions and advice on how to address these challenges. Here are my observations:\n\n&amp;#x200B;\n\n1. Lack of Development Architecture: Our current approach to building pipelines involves using Python scripts as standalone jobs in Jenkins. However, we lack an orchestrator or a clear framework to separate the ETL process. As a result, our pipelines are not well-structured or easily manageable.\n\n&amp;#x200B;\n\n2. Internal API Dependency: We heavily rely on internal APIs as data sources, and more recently, we've started integrating streaming event data from Kafka topics. While the current approach provides us with data, it also means that we have a complex dependency on these APIs, which can introduce potential bottlenecks and fragility.\n\n&amp;#x200B;\n\n3. Repetition and Lack of Abstractions: I've noticed a significant amount of repetitive logic across our pipelines, including common modules. Additionally, the absence of wrappers or abstractions for consistently pulling data from our APIs leads to redundant code and increased maintenance overhead. Except for SQL Alchemy related functions, the logic in each pipeline is bespoke, making it challenging to maintain consistency.\n\n&amp;#x200B;\n\n4. Overreliance on Pandas: The data transformations performed by the Data Engineers heavily rely on pandas, resulting in complex and unorganized code. It becomes difficult to trace back where the output tables are generated from, as the logic spans hundreds of lines and often outputs multiple tables. This lack of modularity and structure makes it harder for others to understand and maintain the code.\n\n&amp;#x200B;\n\n5. Inconsistent SQL Integration: The SQL code is fragmented within the Python scripts, with SQL queries embedded by calling other Python scripts. This approach makes it harder to manage and understand the SQL codebase, leading to potential issues in data consistency and maintainability.\n\n&amp;#x200B;\n\nTo address these challenges, I have started by refactoring the common modules and introducing dbt. I believe it is crucial to abstract the Python code by introducing a layer or two, ensuring that all our ingestion processes follow a consistent pattern and output structure. Dbt has started providing better visibility and control over data transformations, replacing some of the complex pandas logic. However, I'm facing pushback from an experienced team member who prefers a more simplistic approach with a single table output per ingestion process. I find this approach to be an antipattern, but I'm struggling to clearly articulate the problems it can introduce.\n\n&amp;#x200B;\n\nMy background lies in working with dagster, dbt, and Snowflake, and I believe we have the resources to adopt a more scalable solution like Airflow, considering we are currently using PostgreSQL.\n\n&amp;#x200B;\n\nI would greatly appreciate your guidance on how to explain the flaws in our current approach to my team members. Any advice or suggestions on best practices, frameworks, or approaches would be highly valuable.\n\n&amp;#x200B;\n\nThank you in advance for your help and insights!", "author_fullname": "t2_10wjqv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice: Identifying and Addressing Data Engineering Challenges in My New Team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146mdqk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686464513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I recently joined a new data engineering team, and I&amp;#39;ve noticed a few areas where we seem to be lacking a solid framework or best practices. I would greatly appreciate your suggestions and advice on how to address these challenges. Here are my observations:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Lack of Development Architecture: Our current approach to building pipelines involves using Python scripts as standalone jobs in Jenkins. However, we lack an orchestrator or a clear framework to separate the ETL process. As a result, our pipelines are not well-structured or easily manageable.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Internal API Dependency: We heavily rely on internal APIs as data sources, and more recently, we&amp;#39;ve started integrating streaming event data from Kafka topics. While the current approach provides us with data, it also means that we have a complex dependency on these APIs, which can introduce potential bottlenecks and fragility.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Repetition and Lack of Abstractions: I&amp;#39;ve noticed a significant amount of repetitive logic across our pipelines, including common modules. Additionally, the absence of wrappers or abstractions for consistently pulling data from our APIs leads to redundant code and increased maintenance overhead. Except for SQL Alchemy related functions, the logic in each pipeline is bespoke, making it challenging to maintain consistency.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Overreliance on Pandas: The data transformations performed by the Data Engineers heavily rely on pandas, resulting in complex and unorganized code. It becomes difficult to trace back where the output tables are generated from, as the logic spans hundreds of lines and often outputs multiple tables. This lack of modularity and structure makes it harder for others to understand and maintain the code.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Inconsistent SQL Integration: The SQL code is fragmented within the Python scripts, with SQL queries embedded by calling other Python scripts. This approach makes it harder to manage and understand the SQL codebase, leading to potential issues in data consistency and maintainability.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To address these challenges, I have started by refactoring the common modules and introducing dbt. I believe it is crucial to abstract the Python code by introducing a layer or two, ensuring that all our ingestion processes follow a consistent pattern and output structure. Dbt has started providing better visibility and control over data transformations, replacing some of the complex pandas logic. However, I&amp;#39;m facing pushback from an experienced team member who prefers a more simplistic approach with a single table output per ingestion process. I find this approach to be an antipattern, but I&amp;#39;m struggling to clearly articulate the problems it can introduce.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My background lies in working with dagster, dbt, and Snowflake, and I believe we have the resources to adopt a more scalable solution like Airflow, considering we are currently using PostgreSQL.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate your guidance on how to explain the flaws in our current approach to my team members. Any advice or suggestions on best practices, frameworks, or approaches would be highly valuable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your help and insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "146mdqk", "is_robot_indexable": true, "report_reasons": null, "author": "branllywd", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146mdqk/seeking_advice_identifying_and_addressing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146mdqk/seeking_advice_identifying_and_addressing_data/", "subreddit_subscribers": 110137, "created_utc": 1686464513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Seems to be a mishmash of stuff on YouTube, with dubious signal to noise.\n\nHoping someone could gently point me in the right direction.\n\nPS. I want to learn both approaches to pipelines: **low-code** (ADF/Data Flows GUI) and **pro-code** (SQL development).", "author_fullname": "t2_6fifg4n4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best bet for learning Azure Data Factory/Synapse Pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1467rq8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686422645.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Seems to be a mishmash of stuff on YouTube, with dubious signal to noise.&lt;/p&gt;\n\n&lt;p&gt;Hoping someone could gently point me in the right direction.&lt;/p&gt;\n\n&lt;p&gt;PS. I want to learn both approaches to pipelines: &lt;strong&gt;low-code&lt;/strong&gt; (ADF/Data Flows GUI) and &lt;strong&gt;pro-code&lt;/strong&gt; (SQL development).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1467rq8", "is_robot_indexable": true, "report_reasons": null, "author": "icysandstone", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1467rq8/best_bet_for_learning_azure_data_factorysynapse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1467rq8/best_bet_for_learning_azure_data_factorysynapse/", "subreddit_subscribers": 110137, "created_utc": 1686422645.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently working on my beginner DE side project and have come to a fork in the road for my solution architecture. Currently my python script scrapes a web site, generates a lot of small json records and now I would like to store the records for analytics. I would be generating about 25,000 unique records (in chunks) on a weekly basis. Schemas are the same or nearly the same between all the records.  \n\n&amp;nbsp;\n\n I\u2019m familiar with NoSQL but have never used it for a project and could see this as a good opportunity to learn it in a form such as MongoDB especially as the data is already in JSON.  \n\n&amp;nbsp;\n\nOn the other hand, with a little extra regular expression work I could transform the data into something more suitable for a relational database. I\u2019m already familiar with PostgreSQL. This could be a good option as I could then learn dbt. Or I could try to use both in my data pipeline? \n\n&amp;nbsp;\n\nThoughts?", "author_fullname": "t2_5bha3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solution architecture - MongoDB or PostgreSQL?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146trgq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686490391.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686489532.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently working on my beginner DE side project and have come to a fork in the road for my solution architecture. Currently my python script scrapes a web site, generates a lot of small json records and now I would like to store the records for analytics. I would be generating about 25,000 unique records (in chunks) on a weekly basis. Schemas are the same or nearly the same between all the records.  &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;I\u2019m familiar with NoSQL but have never used it for a project and could see this as a good opportunity to learn it in a form such as MongoDB especially as the data is already in JSON.  &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;On the other hand, with a little extra regular expression work I could transform the data into something more suitable for a relational database. I\u2019m already familiar with PostgreSQL. This could be a good option as I could then learn dbt. Or I could try to use both in my data pipeline? &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146trgq", "is_robot_indexable": true, "report_reasons": null, "author": "GreenSquid", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146trgq/solution_architecture_mongodb_or_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146trgq/solution_architecture_mongodb_or_postgresql/", "subreddit_subscribers": 110137, "created_utc": 1686489532.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, all! I would appreciate your insights and advice on designing a data warehouse architecture for my project. Currently, we are bringing data from three different sources and dumping it as-is into an Azure SQL database. We then connect Power BI to this database to build reports. However, we now plan to implement a well-designed data warehouse with proper dimensional modeling.\n\nMy current idea is to create an Azure SQL database with two databases: one serving as a staging area and the other containing dimensionally modeled data. I believe this approach is suitable since our data size is under 1 TB, and using Synapse might not be necessary. However, I have a couple of concerns\n\n1. Can I use Azure Data Lake Storage (ADLS) as a staging area instead of Azure SQL database? My rationale behind this is that I can leverage CSV or Parquet files, but I am unsure if ADLS is an appropriate choice as a staging area without external tables to query the files.\n2. if i want to use adls i think iIshould go with synapse, so what is the cost difference going to be between azure sql db and serverless/dedicated sql pool in synapse. I understand it depends on many factors but please let me know if it is even worth considering synapse for my case\n\n&amp;#x200B;\n\nAre there any alternative architecture suggestions that you would recommend for my scenario?", "author_fullname": "t2_v1vre9oi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Designing a Data Warehouse Architecture for Azure: Need Advice on Approach and Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146j6yq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686453797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, all! I would appreciate your insights and advice on designing a data warehouse architecture for my project. Currently, we are bringing data from three different sources and dumping it as-is into an Azure SQL database. We then connect Power BI to this database to build reports. However, we now plan to implement a well-designed data warehouse with proper dimensional modeling.&lt;/p&gt;\n\n&lt;p&gt;My current idea is to create an Azure SQL database with two databases: one serving as a staging area and the other containing dimensionally modeled data. I believe this approach is suitable since our data size is under 1 TB, and using Synapse might not be necessary. However, I have a couple of concerns&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can I use Azure Data Lake Storage (ADLS) as a staging area instead of Azure SQL database? My rationale behind this is that I can leverage CSV or Parquet files, but I am unsure if ADLS is an appropriate choice as a staging area without external tables to query the files.&lt;/li&gt;\n&lt;li&gt;if i want to use adls i think iIshould go with synapse, so what is the cost difference going to be between azure sql db and serverless/dedicated sql pool in synapse. I understand it depends on many factors but please let me know if it is even worth considering synapse for my case&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Are there any alternative architecture suggestions that you would recommend for my scenario?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "146j6yq", "is_robot_indexable": true, "report_reasons": null, "author": "sach_mess10", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146j6yq/designing_a_data_warehouse_architecture_for_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146j6yq/designing_a_data_warehouse_architecture_for_azure/", "subreddit_subscribers": 110137, "created_utc": 1686453797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Might sounds like stupid question, but it's serious.\n\nWhat configuration did they do in order for websites to be able to distinguish them from other bots ?", "author_fullname": "t2_w7jxc6wu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does Google Spider crawl ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146vg8h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686494006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Might sounds like stupid question, but it&amp;#39;s serious.&lt;/p&gt;\n\n&lt;p&gt;What configuration did they do in order for websites to be able to distinguish them from other bots ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146vg8h", "is_robot_indexable": true, "report_reasons": null, "author": "ParlayOptionsGambler", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146vg8h/how_does_google_spider_crawl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146vg8h/how_does_google_spider_crawl/", "subreddit_subscribers": 110137, "created_utc": 1686494006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Good people of Reddit... would love any feedback on our current website. [www.distilleddata.io](https://www.distilleddata.io) \n\nWe're a small but scrappy ELT data integration company and have completed 2 versions of our website. (on a very small $ budget) Would super appreciate any comments as we are preparing to start V3. Additionally we're looking to start integrating with ChatGPT to easily enable unstructured data inputs and outputs for day-to-day business use. Any/all thoughts or comments are super appreciated. Thanks in advance and cheers!", "author_fullname": "t2_mqw208jg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Pipeline ELT Framework - for data science or business intelligence", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_146zxvq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686504923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good people of Reddit... would love any feedback on our current website. &lt;a href=\"https://www.distilleddata.io\"&gt;www.distilleddata.io&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re a small but scrappy ELT data integration company and have completed 2 versions of our website. (on a very small $ budget) Would super appreciate any comments as we are preparing to start V3. Additionally we&amp;#39;re looking to start integrating with ChatGPT to easily enable unstructured data inputs and outputs for day-to-day business use. Any/all thoughts or comments are super appreciated. Thanks in advance and cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/4R3AuFlkErwq5bkzbp5IrDwnOhDOnE12TdFdyaRqEfs.jpg?auto=webp&amp;v=enabled&amp;s=03483723990b16906a915cabb9c1900813093ea2", "width": 900, "height": 598}, "resolutions": [{"url": "https://external-preview.redd.it/4R3AuFlkErwq5bkzbp5IrDwnOhDOnE12TdFdyaRqEfs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=88f702a57a97746b71ecdaa4a805ce04a0329712", "width": 108, "height": 71}, {"url": "https://external-preview.redd.it/4R3AuFlkErwq5bkzbp5IrDwnOhDOnE12TdFdyaRqEfs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=358f215d4cd74c013b01912b5387182826760474", "width": 216, "height": 143}, {"url": "https://external-preview.redd.it/4R3AuFlkErwq5bkzbp5IrDwnOhDOnE12TdFdyaRqEfs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fd6115e1fa1f5dc8e7a65792425d2ea917210b2", "width": 320, "height": 212}, {"url": "https://external-preview.redd.it/4R3AuFlkErwq5bkzbp5IrDwnOhDOnE12TdFdyaRqEfs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f45326f7bffe331a3fb0d1f87fa505f85c4f4af6", "width": 640, "height": 425}], "variants": {}, "id": "A0pThwrjBLALe7Am4LYLSw-Rr97YN2CfwTE57pP4drE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146zxvq", "is_robot_indexable": true, "report_reasons": null, "author": "Data_Engineering411", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146zxvq/data_pipeline_elt_framework_for_data_science_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146zxvq/data_pipeline_elt_framework_for_data_science_or/", "subreddit_subscribers": 110137, "created_utc": 1686504923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "DEs with 10+ years of experience, what opportunities do your companies provide for professional growth (promotions, raises, etc)?\n\nI\u2019m at an org where the only promotion opportunities available for senior devs are into person  management. Otherwise you\u2019re stuck with a 3% yearly raise. I took a management position but I really miss writing code. Are there companies that provide for meaningful growth along an individual contributor track?", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Career Growth", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146x380", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686498026.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;DEs with 10+ years of experience, what opportunities do your companies provide for professional growth (promotions, raises, etc)?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m at an org where the only promotion opportunities available for senior devs are into person  management. Otherwise you\u2019re stuck with a 3% yearly raise. I took a management position but I really miss writing code. Are there companies that provide for meaningful growth along an individual contributor track?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "146x380", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146x380/de_career_growth/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146x380/de_career_growth/", "subreddit_subscribers": 110137, "created_utc": 1686498026.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "i have passed a coding challenge for a summer internship the coding challenge include questions in sql,python,spark and elastic search what do you think i need to prepare for the interview. if you any ressource that can help please share it with me.", "author_fullname": "t2_feara4tb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "interview help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146bou7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686432600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have passed a coding challenge for a summer internship the coding challenge include questions in sql,python,spark and elastic search what do you think i need to prepare for the interview. if you any ressource that can help please share it with me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "146bou7", "is_robot_indexable": true, "report_reasons": null, "author": "Kratos_1412", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146bou7/interview_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146bou7/interview_help/", "subreddit_subscribers": 110137, "created_utc": 1686432600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Chief Information Officers (CIO) lead the charge in implementing cutting-edge automation initiatives that not only work in the present but also safeguard the future. But success is far from guaranteed - the key lies in establishing a rock-solid business case from the outset. \n\nThe real challenge here is ensuring that processes that require modernization and automation align with the end goal of operational efficiency. For years, organizations have strived to modernize their core systems for optimal performance, but all too often, the business case falls short. This article delves into the critical importance of a robust business case for streamlining and automating processes - ultimately leading to an improved end-user experience.\n\n## CIOs on automation\n\nAutomation is a critical tool in any CIO's arsenal, as it can help improve KPIs and create new channels to enhance the end-user experience. \n\nHowever, ensuring that automation doesn't simply put a band-aid on legacy, bureaucratic manual processes is crucial. Short-term gains are not enough - durable value must be delivered. As one of AINSYS experts put it, automation cannot be done to the business but must be done with it. Let's take a look at a few examples: \n\n* At Cardinal Health, a healthcare provider, the IT department closely collaborates with business leaders to identify pain points and determine the right processes to automate. The impact of automation initiatives is quantified through before-and-after business metrics, and an agile and innovative approach enables quick pivots in a dynamic healthcare environment. \n* CIOs in financial institutions face the challenge of redefining entire business processes while delighting clients and maintaining compliance. The benefits of combining automation with AI are clear - faster decisions, optimized processes, and higher efficiency rates. Ultimately, businesses must prioritize the central consideration of automation efforts: the company itself. \n* At Northwestern Mutual, the mission to alleviate financial anxiety drives all business priorities, with automation solutions applied where they can have a meaningful impact and be measured by business outcomes.\n\n## CIOs' priorities\n\nThe priorities of CIOs are clear: automation of complex workflows is essential for business success. Let's see what these specialists say about automation:\n\n1. Petr Baudis, CTO and chief AI architect at Rossum, predicts that AI-enabled data capture will help enterprises scale automation projects beyond departmental silos. He suggests fast and accurate data extraction is foundational to business intelligence and data analytics, enabling better collaboration and B2B communications. RPA, process, and task mining are seen as vital automation technologies as enterprises attempt to scale their automation projects;\n2. Other companies are making significant progress in automation as well. Adani Electricity is implementing advanced distribution management and a cloud-based data lake and analytics solution to improve the customer experience. The company has also improved its forecast accuracy with SAS' AI/ML-based energy forecasting solution, reducing estimated readings for customers from 2.2% to 0.3%;\n3. At Cardinal Health, warehouse automation is a top priority to serve customers better. The University of Phoenix is developing an enterprise platform that will enable increased use of ML and automation across a wide range of student and staff journeys, providing truly individualized student support.\n\nCIOs also recognize that automation combined with AI has the potential to improve business KPIs through auto-detect and auto-heal solutions, as well as create new channels to enhance the end-user experience. To ensure that automation projects are effective, CIOs must prioritize infrastructure as code, continuous integration and deployment, and AI operations. By automating increasingly complex tasks in matriculation, transcript processing, and student financial aid, CIOs are creating platforms and systems that scale and govern automation safely and reliably, ultimately improving business processes and driving higher efficiency rates.\n\n I share these and other tips on building robust IT architecture in my blog:  [https://ainsys.com/blog/2023/03/15/cios-automation/?utm\\_source=linkedin&amp;utm\\_medium=social&amp;utm\\_campaign=data\\_engineering&amp;utm\\_content=automation\\_approach&amp;utm\\_term=Automation](https://ainsys.com/blog/2023/03/15/cios-automation/?utm_source=linkedin&amp;utm_medium=social&amp;utm_campaign=data_engineering&amp;utm_content=automation_approach&amp;utm_term=Automation)", "author_fullname": "t2_ct09rz3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How CIOs approach automation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_146yzed", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686502668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Chief Information Officers (CIO) lead the charge in implementing cutting-edge automation initiatives that not only work in the present but also safeguard the future. But success is far from guaranteed - the key lies in establishing a rock-solid business case from the outset. &lt;/p&gt;\n\n&lt;p&gt;The real challenge here is ensuring that processes that require modernization and automation align with the end goal of operational efficiency. For years, organizations have strived to modernize their core systems for optimal performance, but all too often, the business case falls short. This article delves into the critical importance of a robust business case for streamlining and automating processes - ultimately leading to an improved end-user experience.&lt;/p&gt;\n\n&lt;h2&gt;CIOs on automation&lt;/h2&gt;\n\n&lt;p&gt;Automation is a critical tool in any CIO&amp;#39;s arsenal, as it can help improve KPIs and create new channels to enhance the end-user experience. &lt;/p&gt;\n\n&lt;p&gt;However, ensuring that automation doesn&amp;#39;t simply put a band-aid on legacy, bureaucratic manual processes is crucial. Short-term gains are not enough - durable value must be delivered. As one of AINSYS experts put it, automation cannot be done to the business but must be done with it. Let&amp;#39;s take a look at a few examples: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;At Cardinal Health, a healthcare provider, the IT department closely collaborates with business leaders to identify pain points and determine the right processes to automate. The impact of automation initiatives is quantified through before-and-after business metrics, and an agile and innovative approach enables quick pivots in a dynamic healthcare environment. &lt;/li&gt;\n&lt;li&gt;CIOs in financial institutions face the challenge of redefining entire business processes while delighting clients and maintaining compliance. The benefits of combining automation with AI are clear - faster decisions, optimized processes, and higher efficiency rates. Ultimately, businesses must prioritize the central consideration of automation efforts: the company itself. &lt;/li&gt;\n&lt;li&gt;At Northwestern Mutual, the mission to alleviate financial anxiety drives all business priorities, with automation solutions applied where they can have a meaningful impact and be measured by business outcomes.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;CIOs&amp;#39; priorities&lt;/h2&gt;\n\n&lt;p&gt;The priorities of CIOs are clear: automation of complex workflows is essential for business success. Let&amp;#39;s see what these specialists say about automation:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Petr Baudis, CTO and chief AI architect at Rossum, predicts that AI-enabled data capture will help enterprises scale automation projects beyond departmental silos. He suggests fast and accurate data extraction is foundational to business intelligence and data analytics, enabling better collaboration and B2B communications. RPA, process, and task mining are seen as vital automation technologies as enterprises attempt to scale their automation projects;&lt;/li&gt;\n&lt;li&gt;Other companies are making significant progress in automation as well. Adani Electricity is implementing advanced distribution management and a cloud-based data lake and analytics solution to improve the customer experience. The company has also improved its forecast accuracy with SAS&amp;#39; AI/ML-based energy forecasting solution, reducing estimated readings for customers from 2.2% to 0.3%;&lt;/li&gt;\n&lt;li&gt;At Cardinal Health, warehouse automation is a top priority to serve customers better. The University of Phoenix is developing an enterprise platform that will enable increased use of ML and automation across a wide range of student and staff journeys, providing truly individualized student support.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;CIOs also recognize that automation combined with AI has the potential to improve business KPIs through auto-detect and auto-heal solutions, as well as create new channels to enhance the end-user experience. To ensure that automation projects are effective, CIOs must prioritize infrastructure as code, continuous integration and deployment, and AI operations. By automating increasingly complex tasks in matriculation, transcript processing, and student financial aid, CIOs are creating platforms and systems that scale and govern automation safely and reliably, ultimately improving business processes and driving higher efficiency rates.&lt;/p&gt;\n\n&lt;p&gt;I share these and other tips on building robust IT architecture in my blog:  &lt;a href=\"https://ainsys.com/blog/2023/03/15/cios-automation/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=data_engineering&amp;amp;utm_content=automation_approach&amp;amp;utm_term=Automation\"&gt;https://ainsys.com/blog/2023/03/15/cios-automation/?utm_source=linkedin&amp;amp;utm_medium=social&amp;amp;utm_campaign=data_engineering&amp;amp;utm_content=automation_approach&amp;amp;utm_term=Automation&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I3xJj8ELsQOmy2H-NeHKFmGnh2tKVfHX1i7SJ1O1qwE.jpg?auto=webp&amp;v=enabled&amp;s=a857d06fc3f1362c48ce1ce4e18be17b3a3dc051", "width": 79, "height": 86}, "resolutions": [], "variants": {}, "id": "fKkAw45B6Aa1K9gfC0CvmXNzCjb0F-J2wvKUvaKf1Vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "146yzed", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Speech36", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146yzed/how_cios_approach_automation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146yzed/how_cios_approach_automation/", "subreddit_subscribers": 110137, "created_utc": 1686502668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\nI'm curious how many Data and DataOps engineers are in the world?\nThank you", "author_fullname": "t2_7b8t7ihk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many Data and DataOps engineers are in the world?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_146woyo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686497059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nI&amp;#39;m curious how many Data and DataOps engineers are in the world?\nThank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "146woyo", "is_robot_indexable": true, "report_reasons": null, "author": "satantine", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/146woyo/how_many_data_and_dataops_engineers_are_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/146woyo/how_many_data_and_dataops_engineers_are_in_the/", "subreddit_subscribers": 110137, "created_utc": 1686497059.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}