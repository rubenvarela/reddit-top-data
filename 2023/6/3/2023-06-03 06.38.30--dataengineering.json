{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Doesn\u2019t necessarily have to be technical. But things that helped you with productivity, communication, or business. I feel like my technical skills are growing but my business acumen, time management, and communication skills are falling behind. \n\nI want to ensure I have a long career.", "author_fullname": "t2_5bpuf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some books that had an impact on your career?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y5aks", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 107, "total_awards_received": 2, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 107, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {"gid_1": 1}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685688434.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Doesn\u2019t necessarily have to be technical. But things that helped you with productivity, communication, or business. I feel like my technical skills are growing but my business acumen, time management, and communication skills are falling behind. &lt;/p&gt;\n\n&lt;p&gt;I want to ensure I have a long career.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [{"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 100, "id": "gid_1", "penny_donate": null, "award_sub_type": "GLOBAL", "coin_reward": 0, "icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_width": 512, "static_icon_width": 512, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "Shows the Silver Award... and that's it.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 0, "count": 1, "static_icon_height": 512, "name": "Silver", "resized_static_icons": [{"url": "https://www.redditstatic.com/gold/awards/icon/silver_16.png", "width": 16, "height": 16}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_32.png", "width": 32, "height": 32}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_48.png", "width": 48, "height": 48}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_64.png", "width": 64, "height": 64}, {"url": "https://www.redditstatic.com/gold/awards/icon/silver_128.png", "width": 128, "height": 128}], "icon_format": null, "icon_height": 512, "penny_price": null, "award_type": "global", "static_icon_url": "https://www.redditstatic.com/gold/awards/icon/silver_512.png"}, {"giver_coin_reward": null, "subreddit_id": null, "is_new": false, "days_of_drip_extension": null, "coin_price": 250, "id": "award_a67d649d-5aa5-407e-a98b-32fd9e3a9696", "penny_donate": null, "award_sub_type": "APPRECIATION", "coin_reward": 100, "icon_url": "https://i.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png", "days_of_premium": null, "tiers_by_required_awardings": null, "resized_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=b0fc6c7d2285e538ecae47fdbbe9772fdbc3a282", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=dbffe82e3fce6160d908e52dcd74bfa77e9fcd63", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=5d33f2655adcc8b1b31e18fed59d6ac9394baf2c", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=f58ebd214a9668ad9c2d680ce396c2f209bbb37a", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=549c7e4359a14fe2877e91162c3f1941fc8c6711", "width": 128, "height": 128}], "icon_width": 2048, "static_icon_width": 2048, "start_date": null, "is_enabled": true, "awardings_required_to_grant_benefits": null, "description": "The more you know... Gives %{coin_symbol}100 Coins to both the author and the community.", "end_date": null, "sticky_duration_seconds": null, "subreddit_coin_reward": 100, "count": 1, "static_icon_height": 2048, "name": "Today I Learned", "resized_static_icons": [{"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=16&amp;height=16&amp;auto=webp&amp;v=enabled&amp;s=b0fc6c7d2285e538ecae47fdbbe9772fdbc3a282", "width": 16, "height": 16}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=32&amp;height=32&amp;auto=webp&amp;v=enabled&amp;s=dbffe82e3fce6160d908e52dcd74bfa77e9fcd63", "width": 32, "height": 32}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=48&amp;height=48&amp;auto=webp&amp;v=enabled&amp;s=5d33f2655adcc8b1b31e18fed59d6ac9394baf2c", "width": 48, "height": 48}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=64&amp;height=64&amp;auto=webp&amp;v=enabled&amp;s=f58ebd214a9668ad9c2d680ce396c2f209bbb37a", "width": 64, "height": 64}, {"url": "https://preview.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png?width=128&amp;height=128&amp;auto=webp&amp;v=enabled&amp;s=549c7e4359a14fe2877e91162c3f1941fc8c6711", "width": 128, "height": 128}], "icon_format": null, "icon_height": 2048, "penny_price": null, "award_type": "global", "static_icon_url": "https://i.redd.it/award_images/t5_22cerq/bph2png4ajz31_TodayILearned.png"}], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13y5aks", "is_robot_indexable": true, "report_reasons": null, "author": "cheanerman", "discussion_type": null, "num_comments": 64, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y5aks/what_are_some_books_that_had_an_impact_on_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y5aks/what_are_some_books_that_had_an_impact_on_your/", "subreddit_subscribers": 108646, "created_utc": 1685688434.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Coming from a traditional modeling background I still don\u2019t fully understand data vault. Is there a good course and example database out there to help me understand it better?", "author_fullname": "t2_a0qsnkph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data vault learning resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y8vg5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685701550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Coming from a traditional modeling background I still don\u2019t fully understand data vault. Is there a good course and example database out there to help me understand it better?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y8vg5", "is_robot_indexable": true, "report_reasons": null, "author": "Minimum-Membership-8", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y8vg5/data_vault_learning_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y8vg5/data_vault_learning_resources/", "subreddit_subscribers": 108646, "created_utc": 1685701550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "And if they don't, would it make sense to do so? I feel like it would allow them to increase rate limits and sell their data in greater quantity with less strain on the site itself.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do websites have separate (duplicate) databases for use with APIs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yywky", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685761918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;And if they don&amp;#39;t, would it make sense to do so? I feel like it would allow them to increase rate limits and sell their data in greater quantity with less strain on the site itself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yywky", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yywky/do_websites_have_separate_duplicate_databases_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yywky/do_websites_have_separate_duplicate_databases_for/", "subreddit_subscribers": 108646, "created_utc": 1685761918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm struggling to find a service that at least gives me more that 80 cities in the UK. \n\nWhat I'm looking for is this type of data:\n\n&amp;#x200B;\n\n|country|region|district/city|longitude|latitude|\n|:-|:-|:-|:-|:-|\n|England|North West|Liverpool|\\-29.09|34.00|\n\nLong and Lat are wrong, just place holder data.   \n\n\nSeems a lot of places I've been looking only have like 300 locations or even 80.   \n\n\nAnyone found a good free API for this at all?", "author_fullname": "t2_al2yxww8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone got any information on how to retrieve all longitude and latitude data for each city in the UK (including Scotland, Wales, Northern Ireland)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y8g9g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685700107.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m struggling to find a service that at least gives me more that 80 cities in the UK. &lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m looking for is this type of data:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;country&lt;/th&gt;\n&lt;th align=\"left\"&gt;region&lt;/th&gt;\n&lt;th align=\"left\"&gt;district/city&lt;/th&gt;\n&lt;th align=\"left\"&gt;longitude&lt;/th&gt;\n&lt;th align=\"left\"&gt;latitude&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;England&lt;/td&gt;\n&lt;td align=\"left\"&gt;North West&lt;/td&gt;\n&lt;td align=\"left\"&gt;Liverpool&lt;/td&gt;\n&lt;td align=\"left\"&gt;-29.09&lt;/td&gt;\n&lt;td align=\"left\"&gt;34.00&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Long and Lat are wrong, just place holder data.   &lt;/p&gt;\n\n&lt;p&gt;Seems a lot of places I&amp;#39;ve been looking only have like 300 locations or even 80.   &lt;/p&gt;\n\n&lt;p&gt;Anyone found a good free API for this at all?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y8g9g", "is_robot_indexable": true, "report_reasons": null, "author": "The-Engineer-93", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y8g9g/has_anyone_got_any_information_on_how_to_retrieve/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y8g9g/has_anyone_got_any_information_on_how_to_retrieve/", "subreddit_subscribers": 108646, "created_utc": 1685700107.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What work did you do as interns/junior-level DEs and how did it change as you progressed?", "author_fullname": "t2_ens6kw85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A question for all data engineers:", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yelms", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685716828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What work did you do as interns/junior-level DEs and how did it change as you progressed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13yelms", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent-Tadpole-564", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yelms/a_question_for_all_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yelms/a_question_for_all_data_engineers/", "subreddit_subscribers": 108646, "created_utc": 1685716828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to update records on Delta live tables with the incoming stream? \n\nBusiness case: We are getting data from our client every 15 minutes. Usually, some records needs to be updated while others should be simply appended. \n\nI have read some articles from the official Databricks documentation, but for me those are more tailored to delta tables, not delta live tables.", "author_fullname": "t2_feq227wn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Upsert on Delta Live Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y5nvm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685689773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to update records on Delta live tables with the incoming stream? &lt;/p&gt;\n\n&lt;p&gt;Business case: We are getting data from our client every 15 minutes. Usually, some records needs to be updated while others should be simply appended. &lt;/p&gt;\n\n&lt;p&gt;I have read some articles from the official Databricks documentation, but for me those are more tailored to delta tables, not delta live tables.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y5nvm", "is_robot_indexable": true, "report_reasons": null, "author": "qki_machine", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y5nvm/databricks_upsert_on_delta_live_tables/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y5nvm/databricks_upsert_on_delta_live_tables/", "subreddit_subscribers": 108646, "created_utc": 1685689773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for examples of minimal ETL-pipeline templates that confirm to most best practices:\n\n- modularity\n- Logging/Error Handling\n- Tests/Data Validation Tests\n- Few dependencies in addition to pandas/polars\n- no prefect/airflow/dagster\n- bonus is simplistic data flow tracking\n\nExemplary use case: e.g. simple etl pipeline running on databricks\n\nInterested in seeing various approaches to the most basic form of etl pipeline in python.", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Minimal Python ETL-pipeline-template", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y8pu2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685701014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for examples of minimal ETL-pipeline templates that confirm to most best practices:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;modularity&lt;/li&gt;\n&lt;li&gt;Logging/Error Handling&lt;/li&gt;\n&lt;li&gt;Tests/Data Validation Tests&lt;/li&gt;\n&lt;li&gt;Few dependencies in addition to pandas/polars&lt;/li&gt;\n&lt;li&gt;no prefect/airflow/dagster&lt;/li&gt;\n&lt;li&gt;bonus is simplistic data flow tracking&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Exemplary use case: e.g. simple etl pipeline running on databricks&lt;/p&gt;\n\n&lt;p&gt;Interested in seeing various approaches to the most basic form of etl pipeline in python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y8pu2", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y8pu2/minimal_python_etlpipelinetemplate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y8pu2/minimal_python_etlpipelinetemplate/", "subreddit_subscribers": 108646, "created_utc": 1685701014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's the trade off to consider moving SAP BW4HANA views to datalake architecture given 20 years of data with 2000 reports. I am still positive to move the views or recreate the views in DWH \\[ Datalake\\] but this entails huge risk of copying the data. I wonder if i should consider having a compute engine \\[ DREMIO \\] sitting on top of SAP BW4HANA or take the data to Datalake.", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datalake Vs SAP BW4HANA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13z09ad", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685765336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the trade off to consider moving SAP BW4HANA views to datalake architecture given 20 years of data with 2000 reports. I am still positive to move the views or recreate the views in DWH [ Datalake] but this entails huge risk of copying the data. I wonder if i should consider having a compute engine [ DREMIO ] sitting on top of SAP BW4HANA or take the data to Datalake.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13z09ad", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13z09ad/datalake_vs_sap_bw4hana/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13z09ad/datalake_vs_sap_bw4hana/", "subreddit_subscribers": 108646, "created_utc": 1685765336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's is the community's take on story points in Data engineering?  If you use story points how do account for a lot of the unknowns or hard to estimate complexity in data pipeline work when assessing points to complete a new pipeline?  Any norms you guys have settled on for estimating points during PI planning?  How long do you generally estimate each phase of a project will take from discovery and modeling to development and testing to final production deployment?\n\nI should add I don't like story points for DE work so if you don't use them, what is your approach?", "author_fullname": "t2_puuzgu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Story point norms in DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yr4ph", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685744842.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685743759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s is the community&amp;#39;s take on story points in Data engineering?  If you use story points how do account for a lot of the unknowns or hard to estimate complexity in data pipeline work when assessing points to complete a new pipeline?  Any norms you guys have settled on for estimating points during PI planning?  How long do you generally estimate each phase of a project will take from discovery and modeling to development and testing to final production deployment?&lt;/p&gt;\n\n&lt;p&gt;I should add I don&amp;#39;t like story points for DE work so if you don&amp;#39;t use them, what is your approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yr4ph", "is_robot_indexable": true, "report_reasons": null, "author": "getafterit123", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yr4ph/story_point_norms_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yr4ph/story_point_norms_in_de/", "subreddit_subscribers": 108646, "created_utc": 1685743759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. I am migrating code to Databricks/pyspark, which requires reading a bunch of Snowflake tables and views. Then a bunch of joins and such. \n\nIt generally works but some statements are not finishing with larger tables. I tried to troubleshoot one like this: \n\nsome\\_query = \"select \\~50 columns from Snowflake view with 1400 columns and 235m rows\"\n\ndf = spark.read.format(\"snowflake\").options(\\*\\*sfOptions).option(\"query\", some\\_query).load()\n\ndf.explain()\n\nAnd it's been going for 50 minutes now. Is it normal?\n\nSomeone suggested I go to Snowflake and look at Query History. That helps, but sometimes I don't even see the query there, so I don't know what's going on. \n\nI went to the cluster and just clicking around, like the Spark UI tab &gt; Executors, and the \"Active tasks\" is  0. So is it doing anything?? Driver logs don't show errors. \n\nWould love some tips on how to confirm what a query is doing. Thanks.", "author_fullname": "t2_2o0q5m4h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking tips to troubleshoot Databricks queries of large Snowflake tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ymkox", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685734584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I am migrating code to Databricks/pyspark, which requires reading a bunch of Snowflake tables and views. Then a bunch of joins and such. &lt;/p&gt;\n\n&lt;p&gt;It generally works but some statements are not finishing with larger tables. I tried to troubleshoot one like this: &lt;/p&gt;\n\n&lt;p&gt;some_query = &amp;quot;select ~50 columns from Snowflake view with 1400 columns and 235m rows&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;df = spark.read.format(&amp;quot;snowflake&amp;quot;).options(**sfOptions).option(&amp;quot;query&amp;quot;, some_query).load()&lt;/p&gt;\n\n&lt;p&gt;df.explain()&lt;/p&gt;\n\n&lt;p&gt;And it&amp;#39;s been going for 50 minutes now. Is it normal?&lt;/p&gt;\n\n&lt;p&gt;Someone suggested I go to Snowflake and look at Query History. That helps, but sometimes I don&amp;#39;t even see the query there, so I don&amp;#39;t know what&amp;#39;s going on. &lt;/p&gt;\n\n&lt;p&gt;I went to the cluster and just clicking around, like the Spark UI tab &amp;gt; Executors, and the &amp;quot;Active tasks&amp;quot; is  0. So is it doing anything?? Driver logs don&amp;#39;t show errors. &lt;/p&gt;\n\n&lt;p&gt;Would love some tips on how to confirm what a query is doing. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ymkox", "is_robot_indexable": true, "report_reasons": null, "author": "rotterdamn8", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ymkox/seeking_tips_to_troubleshoot_databricks_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ymkox/seeking_tips_to_troubleshoot_databricks_queries/", "subreddit_subscribers": 108646, "created_utc": 1685734584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys. I currently work in research in the field of crypto/web 3. (Glorified way to say that I write on crypto topics for my employer.)\n\nI'm considering learning Dune (formerly called Dune Analytics) since it helps extract onchain data better and is a valuable skill that pays well. \n\nIs there anyone here who has dabbled with Dune and is sufficiently proficient in it?  Or were you able to land projects/jobs because you know your way around it? Would love to get in touch with you for some help and guidance.", "author_fullname": "t2_qj1xoq0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Dune wizards here?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ylfgz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685732240.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. I currently work in research in the field of crypto/web 3. (Glorified way to say that I write on crypto topics for my employer.)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m considering learning Dune (formerly called Dune Analytics) since it helps extract onchain data better and is a valuable skill that pays well. &lt;/p&gt;\n\n&lt;p&gt;Is there anyone here who has dabbled with Dune and is sufficiently proficient in it?  Or were you able to land projects/jobs because you know your way around it? Would love to get in touch with you for some help and guidance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ylfgz", "is_robot_indexable": true, "report_reasons": null, "author": "heeguunte", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ylfgz/any_dune_wizards_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ylfgz/any_dune_wizards_here/", "subreddit_subscribers": 108646, "created_utc": 1685732240.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can anyone please help me find the best authentic physical conference related to Data Engineering or Software Engineer anywhere in Canada?\nIt can be any re:invent also. Anything which can add value. \nThanks in advance", "author_fullname": "t2_7r5xenrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering conference in Canada (anywhere)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ygpe4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685721746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can anyone please help me find the best authentic physical conference related to Data Engineering or Software Engineer anywhere in Canada?\nIt can be any re:invent also. Anything which can add value. \nThanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13ygpe4", "is_robot_indexable": true, "report_reasons": null, "author": "Heavy_End_2971", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ygpe4/data_engineering_conference_in_canada_anywhere/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ygpe4/data_engineering_conference_in_canada_anywhere/", "subreddit_subscribers": 108646, "created_utc": 1685721746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_r6aazfpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Types of NoSQL Databases: Deep Dive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_13ygmj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/tbjolvjcd4pFGYwrUy21pTO8xhj6HfhJnXoILsY07vY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685721582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "memgraph.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://memgraph.com/blog/types-of-nosql-databases-deep-dive", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?auto=webp&amp;v=enabled&amp;s=30a10ec625bb545da69ce94ff3eaecf423192ffb", "width": 2400, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2cb781c8024b80019cbb4d8671b9ac82ce55239a", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3019c8983a64031de7cc3d528cc1a4082b979ce3", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8c14465cc9cf34e73a9dfcd9cee8f25a2024ac4f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=855bc3dfe0b174024f1952f236e466bf3704d9aa", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e348a1a0827d26c78592ce17c4f91f62d1984ae2", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/80tNcHNbIRQjfde08NBFmc9ZPdlpjJmzmxjr5RwfcDA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=21faf68b901e2ba8bc3816beedccedea6c06e79f", "width": 1080, "height": 540}], "variants": {}, "id": "M2IsBpOmOWUv3ZenklBzRFx5hxz60Ew2I2gjTGE5GCg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13ygmj4", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Cap6526", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ygmj4/types_of_nosql_databases_deep_dive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://memgraph.com/blog/types-of-nosql-databases-deep-dive", "subreddit_subscribers": 108646, "created_utc": 1685721582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are currently building our pipeline from scratch with plain old Python and began to invest a little bit too much in the \"frameworkisation\" of our stuff. So we are looking for a fashionable framework to handle stream of events from PubSub and doing a little bit of lookup in some PostgreSQL instances.\n\nWhat would have been your primary choice of framework for this kind of project in Python?", "author_fullname": "t2_flv2knd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stream processing framework for a new project in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yftqn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685719716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are currently building our pipeline from scratch with plain old Python and began to invest a little bit too much in the &amp;quot;frameworkisation&amp;quot; of our stuff. So we are looking for a fashionable framework to handle stream of events from PubSub and doing a little bit of lookup in some PostgreSQL instances.&lt;/p&gt;\n\n&lt;p&gt;What would have been your primary choice of framework for this kind of project in Python?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yftqn", "is_robot_indexable": true, "report_reasons": null, "author": "Hashrann", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yftqn/stream_processing_framework_for_a_new_project_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yftqn/stream_processing_framework_for_a_new_project_in/", "subreddit_subscribers": 108646, "created_utc": 1685719716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am looking for a sample database with interesting business data to analyze.\n\nIt shouldn't be one table (as most of datasets on kaggle), it should be more like Adventure Works sample database with many tables but more interesting (in AW database the sales trends are boring).\n\nIt can be a sample of accounting entries, or an insurance company database, any industry, actually.\n\nI will use this DB for demo dashboards and teaching analytics and data engineering.  \nThanks", "author_fullname": "t2_924si4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sample dataset/database with business data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13y93cq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685702285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a sample database with interesting business data to analyze.&lt;/p&gt;\n\n&lt;p&gt;It shouldn&amp;#39;t be one table (as most of datasets on kaggle), it should be more like Adventure Works sample database with many tables but more interesting (in AW database the sales trends are boring).&lt;/p&gt;\n\n&lt;p&gt;It can be a sample of accounting entries, or an insurance company database, any industry, actually.&lt;/p&gt;\n\n&lt;p&gt;I will use this DB for demo dashboards and teaching analytics and data engineering.&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13y93cq", "is_robot_indexable": true, "report_reasons": null, "author": "mshparber", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13y93cq/sample_datasetdatabase_with_business_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13y93cq/sample_datasetdatabase_with_business_data/", "subreddit_subscribers": 108646, "created_utc": 1685702285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have experience with doing test on the ref function? For example that the intermediate layer does not ref the mart layer but only staging?\n\nModel: intermediate_table1\nselect * from {{ ref(\u2018mart_table1\u2019) }}\n\nTest: fail\n\nModel: intermediate_table1\nselect * from {{ ref(\u2018staging_table1\u2019) }}\n\nTest: pass", "author_fullname": "t2_1j8f19jc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt QA on the ref function", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13z2hlk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685771274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have experience with doing test on the ref function? For example that the intermediate layer does not ref the mart layer but only staging?&lt;/p&gt;\n\n&lt;p&gt;Model: intermediate_table1\nselect * from {{ ref(\u2018mart_table1\u2019) }}&lt;/p&gt;\n\n&lt;p&gt;Test: fail&lt;/p&gt;\n\n&lt;p&gt;Model: intermediate_table1\nselect * from {{ ref(\u2018staging_table1\u2019) }}&lt;/p&gt;\n\n&lt;p&gt;Test: pass&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13z2hlk", "is_robot_indexable": true, "report_reasons": null, "author": "bgarcevic", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13z2hlk/dbt_qa_on_the_ref_function/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13z2hlk/dbt_qa_on_the_ref_function/", "subreddit_subscribers": 108646, "created_utc": 1685771274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I'm curious to hear your opinions on Cloudera's decision to transition from using the Spark engine with Hive to Tez engine with Hive. \n\nI've been using Hive on Tez recently and it appears to be slower compared to Hive on Spark. Even though big SQL queries have similar run times after optimizing the queue on Hive with Tez (Hive on Spark still outperforms it), smaller queries are significantly slower on Hive with Tez.\n\nI know Tez has some use cases and would be great if someone was using MapReduce and then transitioned to Tez. However, it can be challenging for someone who was previously using Spark engine and now moved to Tez engine.\n\nWould love to hear your thoughts\u2026", "author_fullname": "t2_658ryj26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hive on Tez engine vs Spark engine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yzd1z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685763039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m curious to hear your opinions on Cloudera&amp;#39;s decision to transition from using the Spark engine with Hive to Tez engine with Hive. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using Hive on Tez recently and it appears to be slower compared to Hive on Spark. Even though big SQL queries have similar run times after optimizing the queue on Hive with Tez (Hive on Spark still outperforms it), smaller queries are significantly slower on Hive with Tez.&lt;/p&gt;\n\n&lt;p&gt;I know Tez has some use cases and would be great if someone was using MapReduce and then transitioned to Tez. However, it can be challenging for someone who was previously using Spark engine and now moved to Tez engine.&lt;/p&gt;\n\n&lt;p&gt;Would love to hear your thoughts\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yzd1z", "is_robot_indexable": true, "report_reasons": null, "author": "Different-Ad-2901", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yzd1z/hive_on_tez_engine_vs_spark_engine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yzd1z/hive_on_tez_engine_vs_spark_engine/", "subreddit_subscribers": 108646, "created_utc": 1685763039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm familiar with the OBT world and BQ in particular.\nA client I started work for make use of various star schemas in their legacy on prem database.\n\nAs they're migrating to the cloud I'm wondering how to best represent those one to many relationships in OBT ?\nObviously I'm thinking of structs and arrays , but will they be 100% compatible with the most famous visualisation tools out there?", "author_fullname": "t2_4v8mesko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you create one to many relationships in OBT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yc68h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685710964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m familiar with the OBT world and BQ in particular.\nA client I started work for make use of various star schemas in their legacy on prem database.&lt;/p&gt;\n\n&lt;p&gt;As they&amp;#39;re migrating to the cloud I&amp;#39;m wondering how to best represent those one to many relationships in OBT ?\nObviously I&amp;#39;m thinking of structs and arrays , but will they be 100% compatible with the most famous visualisation tools out there?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yc68h", "is_robot_indexable": true, "report_reasons": null, "author": "_thetrue_SpaceTofu", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yc68h/how_do_you_create_one_to_many_relationships_in_obt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yc68h/how_do_you_create_one_to_many_relationships_in_obt/", "subreddit_subscribers": 108646, "created_utc": 1685710964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Redditors!\n\nI thought this community might find it very useful that Databricks has partnered with [Cleanlab](https://cleanlab.ai/) to bring automated data correction and ML model improvement for both structured and unstructured datasets to all Databricks users.\n\nA big problem for companies on platforms like Databricks is underutilized data: data and label quality is often too poor to be useful input for reliable business intelligence, training of ML models, or fine-tuning of LLMs. Using the new partner integration for Databricks, users get more value out of their data with automated finding and fixing of outliers, label issues, and other data issues in image, text, and tabular datasets, enabling them to train more reliable models and derive more accurate analytics and insights.\n\nTo highlight what's possible with this new integration, their recent [blog](https://www.databricks.com/blog/better-llms-better-data-using-cleanlab-studio) shows how LLMs (Large Language Models) trained on Databricks data can be **boosted in test accuracy (by over 30%) using Cleanlab Studio** to train ML models on an improved text dataset. \n\nYou only need a couple of lines of code too:\n\n    cleanlab_studio.upload_dataset(dataset)\n    dataset_fixed = cleanlab_studio.apply_corrections(id, dataset)", "author_fullname": "t2_s0qucgfk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks users can now automatically correct data and improve ML models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yhf6e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685723424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Redditors!&lt;/p&gt;\n\n&lt;p&gt;I thought this community might find it very useful that Databricks has partnered with &lt;a href=\"https://cleanlab.ai/\"&gt;Cleanlab&lt;/a&gt; to bring automated data correction and ML model improvement for both structured and unstructured datasets to all Databricks users.&lt;/p&gt;\n\n&lt;p&gt;A big problem for companies on platforms like Databricks is underutilized data: data and label quality is often too poor to be useful input for reliable business intelligence, training of ML models, or fine-tuning of LLMs. Using the new partner integration for Databricks, users get more value out of their data with automated finding and fixing of outliers, label issues, and other data issues in image, text, and tabular datasets, enabling them to train more reliable models and derive more accurate analytics and insights.&lt;/p&gt;\n\n&lt;p&gt;To highlight what&amp;#39;s possible with this new integration, their recent &lt;a href=\"https://www.databricks.com/blog/better-llms-better-data-using-cleanlab-studio\"&gt;blog&lt;/a&gt; shows how LLMs (Large Language Models) trained on Databricks data can be &lt;strong&gt;boosted in test accuracy (by over 30%) using Cleanlab Studio&lt;/strong&gt; to train ML models on an improved text dataset. &lt;/p&gt;\n\n&lt;p&gt;You only need a couple of lines of code too:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;cleanlab_studio.upload_dataset(dataset)\ndataset_fixed = cleanlab_studio.apply_corrections(id, dataset)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?auto=webp&amp;v=enabled&amp;s=4fa344feec1203c5a3c8037ff4dc262b8199993c", "width": 1272, "height": 686}, "resolutions": [{"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=497bb037271a9f730fba0c9762fccfd03bc83854", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e9a92773876a44dff24033bb28bfcac23cc6be9", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d8289065076165108742e1f06e1eba13b2ba27e", "width": 320, "height": 172}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=860eca71c83a330feea1f4e293c3767498138aec", "width": 640, "height": 345}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29a33bb3ca9ee068da332d2221827e16765a2a4a", "width": 960, "height": 517}, {"url": "https://external-preview.redd.it/u93AAPorjY_6onZ2tzlt9podh1NWDKD3d0WUVvRJ3JU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9bd1c44daed0be645a75f28344e835d728418327", "width": 1080, "height": 582}], "variants": {}, "id": "ZToDd-YI1Es8iCGrsYQ-wSRxT7XW4KUdV7ki6pqFGdE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13yhf6e", "is_robot_indexable": true, "report_reasons": null, "author": "cmauck10", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yhf6e/databricks_users_can_now_automatically_correct/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yhf6e/databricks_users_can_now_automatically_correct/", "subreddit_subscribers": 108646, "created_utc": 1685723424.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}