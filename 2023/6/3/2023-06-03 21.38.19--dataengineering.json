{"kind": "Listing", "data": {"after": null, "dist": 20, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_v3vfbwzc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The growing pains of database architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "name": "t3_13zedmr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/XcSAEUlxVUY6I1TTbJ_4ntHlBUvCUCvL3vVJIYu9HUU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685802138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "figma.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.figma.com/blog/how-figma-scaled-to-multiple-databases/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?auto=webp&amp;v=enabled&amp;s=b5867ede39eeffae9d13f32e5d9b30e71b339385", "width": 1200, "height": 566}, "resolutions": [{"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10bcc126368cb1da8fbdd64265db8eb18cf03d3f", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b3f6fc670efbd4ee95002eb7f8808edfbc6d1062", "width": 216, "height": 101}, {"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0d64a54c5c6a5a5d66c764358a0b4d486ee9ba00", "width": 320, "height": 150}, {"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=93014cbd1a923d348a4887ff8c03ae75e03977a5", "width": 640, "height": 301}, {"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cfd7182f905c820ea77288801824630ec4bc932b", "width": 960, "height": 452}, {"url": "https://external-preview.redd.it/Z-2O8jcKuskmSejxB3LrYxX6aIoYImn6WeP3LNeIVBQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f5c6e864c52a3c9163365fc761d6fad048e7a918", "width": 1080, "height": 509}], "variants": {}, "id": "f4GO-Re6FLXwf8hsiG60ZlCbPm1yXOfOgWLuB_O23IE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13zedmr", "is_robot_indexable": true, "report_reasons": null, "author": "ThePullOutCouches", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zedmr/the_growing_pains_of_database_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.figma.com/blog/how-figma-scaled-to-multiple-databases/", "subreddit_subscribers": 108734, "created_utc": 1685802138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "And if they don't, would it make sense to do so? I feel like it would allow them to increase rate limits and sell their data in greater quantity with less strain on the site itself.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do websites have separate (duplicate) databases for use with APIs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yywky", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685761918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;And if they don&amp;#39;t, would it make sense to do so? I feel like it would allow them to increase rate limits and sell their data in greater quantity with less strain on the site itself.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yywky", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yywky/do_websites_have_separate_duplicate_databases_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yywky/do_websites_have_separate_duplicate_databases_for/", "subreddit_subscribers": 108734, "created_utc": 1685761918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How is data modelling solved in medallion/lakehouse data architecture? Bronze + silver layers are just plain tables, no relationships and gold is \u201cdata mart-ish\u201d with all the relationships? How about the normalization? Bronze + silver denormalized and gold normalized? Or? \n\nAlso, how do you actually make a normalization considering you are working with e.g. parquet files? In the database it is simple but with files?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Medallion/lakehouse architecture data modelling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13z9byl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685790484.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685790124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is data modelling solved in medallion/lakehouse data architecture? Bronze + silver layers are just plain tables, no relationships and gold is \u201cdata mart-ish\u201d with all the relationships? How about the normalization? Bronze + silver denormalized and gold normalized? Or? &lt;/p&gt;\n\n&lt;p&gt;Also, how do you actually make a normalization considering you are working with e.g. parquet files? In the database it is simple but with files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13z9byl", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13z9byl/medallionlakehouse_architecture_data_modelling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13z9byl/medallionlakehouse_architecture_data_modelling/", "subreddit_subscribers": 108734, "created_utc": 1685790124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are there any courses that detail how to be GDPR compliant on the cloud.", "author_fullname": "t2_t05ji4fs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Courses on implementing GDPR in cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13z6khq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685782684.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any courses that detail how to be GDPR compliant on the cloud.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13z6khq", "is_robot_indexable": true, "report_reasons": null, "author": "kkchn001", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13z6khq/courses_on_implementing_gdpr_in_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13z6khq/courses_on_implementing_gdpr_in_cloud/", "subreddit_subscribers": 108734, "created_utc": 1685782684.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's the trade off to consider moving SAP BW4HANA views to datalake architecture given 20 years of data with 2000 reports. I am still positive to move the views or recreate the views in DWH \\[ Datalake\\] but this entails huge risk of copying the data. I wonder if i should consider having a compute engine \\[ DREMIO \\] sitting on top of SAP BW4HANA or take the data to Datalake.", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datalake Vs SAP BW4HANA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13z09ad", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685765336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the trade off to consider moving SAP BW4HANA views to datalake architecture given 20 years of data with 2000 reports. I am still positive to move the views or recreate the views in DWH [ Datalake] but this entails huge risk of copying the data. I wonder if i should consider having a compute engine [ DREMIO ] sitting on top of SAP BW4HANA or take the data to Datalake.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13z09ad", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13z09ad/datalake_vs_sap_bw4hana/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13z09ad/datalake_vs_sap_bw4hana/", "subreddit_subscribers": 108734, "created_utc": 1685765336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi a recruiter reached out and asking detailed questions like this\n\n1. how many notebooks have you written that are in production?\n2. how did you source control your development of notebooks?\n3. how did you promote your notebooks to production?\n4. how do you organize your notebooks code?\n5. what is the biggest dataset you have created with data bricks?\n6. what is the longest running notebook you have created?\n7. what is the biggest cluster you have required?\n8. what external libraries have you used?\n9. what is the largest data frame you have broadcast?\n10. what rule of thumb do you have for performance?\n\nwhats the point of asking all these? would you not hire me if I dont use data size &gt; 6gb ;))", "author_fullname": "t2_3bj6xwvz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks detailed interrogation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zi2jm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685810182.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi a recruiter reached out and asking detailed questions like this&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;how many notebooks have you written that are in production?&lt;/li&gt;\n&lt;li&gt;how did you source control your development of notebooks?&lt;/li&gt;\n&lt;li&gt;how did you promote your notebooks to production?&lt;/li&gt;\n&lt;li&gt;how do you organize your notebooks code?&lt;/li&gt;\n&lt;li&gt;what is the biggest dataset you have created with data bricks?&lt;/li&gt;\n&lt;li&gt;what is the longest running notebook you have created?&lt;/li&gt;\n&lt;li&gt;what is the biggest cluster you have required?&lt;/li&gt;\n&lt;li&gt;what external libraries have you used?&lt;/li&gt;\n&lt;li&gt;what is the largest data frame you have broadcast?&lt;/li&gt;\n&lt;li&gt;what rule of thumb do you have for performance?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;whats the point of asking all these? would you not hire me if I dont use data size &amp;gt; 6gb ;))&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "13zi2jm", "is_robot_indexable": true, "report_reasons": null, "author": "Abject-Promise-2780", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zi2jm/databricks_detailed_interrogation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zi2jm/databricks_detailed_interrogation/", "subreddit_subscribers": 108734, "created_utc": 1685810182.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey /r/dataengineering,\n\nI've done some research on \"how to store large amounts of blockchain data for analysis and low-latency querying?\" and feel quite stumped - I can't seem to find a solution to; **analysis**, **low-latency querying** and **storing large amounts of data** (the Ethereum + Bitcoin blockchain is already 25\u201330TB).\n\nThe furthest I've gotten is:\n\n* Ethereum ETL into Parquet files (perhaps using Delta Lake too) in AWS S3\n* Spark to query these Parquet files\n\nThis allows for a nice way to store and run analytics on the blockchain data.\n\nThe problem I'm facing now is how do I make it queryable by an API in a reasonable amount of time (say &lt; 500ms).\n\nI'm thinking maybe there's a layer I can build on top of these files? Maybe I'm missing something here? Is this a good use-case for Elasticsearch?", "author_fullname": "t2_11os2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to store large amounts of blockchain data for analysis and low-latency querying?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13z4qzw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685777456.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/dataengineering\"&gt;/r/dataengineering&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve done some research on &amp;quot;how to store large amounts of blockchain data for analysis and low-latency querying?&amp;quot; and feel quite stumped - I can&amp;#39;t seem to find a solution to; &lt;strong&gt;analysis&lt;/strong&gt;, &lt;strong&gt;low-latency querying&lt;/strong&gt; and &lt;strong&gt;storing large amounts of data&lt;/strong&gt; (the Ethereum + Bitcoin blockchain is already 25\u201330TB).&lt;/p&gt;\n\n&lt;p&gt;The furthest I&amp;#39;ve gotten is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Ethereum ETL into Parquet files (perhaps using Delta Lake too) in AWS S3&lt;/li&gt;\n&lt;li&gt;Spark to query these Parquet files&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This allows for a nice way to store and run analytics on the blockchain data.&lt;/p&gt;\n\n&lt;p&gt;The problem I&amp;#39;m facing now is how do I make it queryable by an API in a reasonable amount of time (say &amp;lt; 500ms).&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking maybe there&amp;#39;s a layer I can build on top of these files? Maybe I&amp;#39;m missing something here? Is this a good use-case for Elasticsearch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13z4qzw", "is_robot_indexable": true, "report_reasons": null, "author": "PM_SQL_INJECTION", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13z4qzw/how_to_store_large_amounts_of_blockchain_data_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13z4qzw/how_to_store_large_amounts_of_blockchain_data_for/", "subreddit_subscribers": 108734, "created_utc": 1685777456.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Actively interviewing so I need some prep material for Data wrangling questions if there is a single source out there.\n\nI'm looking for a source around questions like:\n\n\\- Given a source data (JSON, CSV), derive insights to answer questions\n\n\\- Clean up a given dataset to answer questions etc.\n\n\\- Python dictionary / Json API response manipulation.\n\n&amp;#x200B;\n\nThank you.", "author_fullname": "t2_fy6g58f7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the Leetcode equivalent for Data Engineering?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13znm1j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685822212.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Actively interviewing so I need some prep material for Data wrangling questions if there is a single source out there.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for a source around questions like:&lt;/p&gt;\n\n&lt;p&gt;- Given a source data (JSON, CSV), derive insights to answer questions&lt;/p&gt;\n\n&lt;p&gt;- Clean up a given dataset to answer questions etc.&lt;/p&gt;\n\n&lt;p&gt;- Python dictionary / Json API response manipulation.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13znm1j", "is_robot_indexable": true, "report_reasons": null, "author": "WarriorData", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13znm1j/what_is_the_leetcode_equivalent_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13znm1j/what_is_the_leetcode_equivalent_for_data/", "subreddit_subscribers": 108734, "created_utc": 1685822212.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, looking to start storing event and impression data that my users generate. I'm starting from scratch here - I've got thousands of devices generating data and I'm currently not storing any of it at all. My dream service would give an endpoint to submit each event from the client. I could then generate aggregate metrics via API query when my users needed it. Real-time is not very important. Right now, I'm at the scale of 5-10 million events per day.\n\nAt this point, I'm just considering storing the data in Postgres but I'm hesitant about it filling up too fast and managing the aggregate tables is a lot of overhead. Historical raw data is not necessary at the event level - mostly just need the daily/hourly aggregate counts of events per user. Looking for any kind of tooling that could help me with this process. Thanks!", "author_fullname": "t2_3sz34", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Millions of events per day - one man team, where do I get started?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zilcx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685811313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, looking to start storing event and impression data that my users generate. I&amp;#39;m starting from scratch here - I&amp;#39;ve got thousands of devices generating data and I&amp;#39;m currently not storing any of it at all. My dream service would give an endpoint to submit each event from the client. I could then generate aggregate metrics via API query when my users needed it. Real-time is not very important. Right now, I&amp;#39;m at the scale of 5-10 million events per day.&lt;/p&gt;\n\n&lt;p&gt;At this point, I&amp;#39;m just considering storing the data in Postgres but I&amp;#39;m hesitant about it filling up too fast and managing the aggregate tables is a lot of overhead. Historical raw data is not necessary at the event level - mostly just need the daily/hourly aggregate counts of events per user. Looking for any kind of tooling that could help me with this process. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zilcx", "is_robot_indexable": true, "report_reasons": null, "author": "sicentendu", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zilcx/millions_of_events_per_day_one_man_team_where_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zilcx/millions_of_events_per_day_one_man_team_where_do/", "subreddit_subscribers": 108734, "created_utc": 1685811313.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Does anyone have experience with doing test on the ref function? For example that the intermediate layer does not ref the mart layer but only staging?\n\nModel: intermediate_table1\nselect * from {{ ref(\u2018mart_table1\u2019) }}\n\nTest: fail\n\nModel: intermediate_table1\nselect * from {{ ref(\u2018staging_table1\u2019) }}\n\nTest: pass", "author_fullname": "t2_1j8f19jc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt QA on the ref function", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13z2hlk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685771274.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have experience with doing test on the ref function? For example that the intermediate layer does not ref the mart layer but only staging?&lt;/p&gt;\n\n&lt;p&gt;Model: intermediate_table1\nselect * from {{ ref(\u2018mart_table1\u2019) }}&lt;/p&gt;\n\n&lt;p&gt;Test: fail&lt;/p&gt;\n\n&lt;p&gt;Model: intermediate_table1\nselect * from {{ ref(\u2018staging_table1\u2019) }}&lt;/p&gt;\n\n&lt;p&gt;Test: pass&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13z2hlk", "is_robot_indexable": true, "report_reasons": null, "author": "bgarcevic", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13z2hlk/dbt_qa_on_the_ref_function/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13z2hlk/dbt_qa_on_the_ref_function/", "subreddit_subscribers": 108734, "created_utc": 1685771274.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What's is the community's take on story points in Data engineering?  If you use story points how do account for a lot of the unknowns or hard to estimate complexity in data pipeline work when assessing points to complete a new pipeline?  Any norms you guys have settled on for estimating points during PI planning?  How long do you generally estimate each phase of a project will take from discovery and modeling to development and testing to final production deployment?\n\nI should add I don't like story points for DE work so if you don't use them, what is your approach?", "author_fullname": "t2_puuzgu6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Story point norms in DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yr4ph", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1685744842.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685743759.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s is the community&amp;#39;s take on story points in Data engineering?  If you use story points how do account for a lot of the unknowns or hard to estimate complexity in data pipeline work when assessing points to complete a new pipeline?  Any norms you guys have settled on for estimating points during PI planning?  How long do you generally estimate each phase of a project will take from discovery and modeling to development and testing to final production deployment?&lt;/p&gt;\n\n&lt;p&gt;I should add I don&amp;#39;t like story points for DE work so if you don&amp;#39;t use them, what is your approach?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yr4ph", "is_robot_indexable": true, "report_reasons": null, "author": "getafterit123", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yr4ph/story_point_norms_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yr4ph/story_point_norms_in_de/", "subreddit_subscribers": 108734, "created_utc": 1685743759.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone! I recently wrote a Medium article on how to create a sentiment analysis dashboard using Python, PostgreSQL, and PowerBI. In this tutorial, you'll learn how to:\n\n\\- Ingest data from a CSV file to a PostgreSQL database\n\n\\- Clean the data and perform sentiment analysis using Python\n\n\\- Connect the sentiment analysis table to a dashboard in PowerBI\n\nIf you're interested in data analysis or just want to learn some new skills, this tutorial is a great place to start! Check out my Medium article here: [LINK](https://medium.com/geekculture/from-zero-to-hero-how-to-create-your-first-sentiment-analysis-dashboard-cec74f9933c4)\n\nI hope you find it helpful and feel free to ask me any questions in the comments. Happy coding!", "author_fullname": "t2_dem14ic5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sentiment analysis dashboard data pipeline with Python Postgre SQL and PowerBI project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zjpll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1685813678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone! I recently wrote a Medium article on how to create a sentiment analysis dashboard using Python, PostgreSQL, and PowerBI. In this tutorial, you&amp;#39;ll learn how to:&lt;/p&gt;\n\n&lt;p&gt;- Ingest data from a CSV file to a PostgreSQL database&lt;/p&gt;\n\n&lt;p&gt;- Clean the data and perform sentiment analysis using Python&lt;/p&gt;\n\n&lt;p&gt;- Connect the sentiment analysis table to a dashboard in PowerBI&lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;re interested in data analysis or just want to learn some new skills, this tutorial is a great place to start! Check out my Medium article here: &lt;a href=\"https://medium.com/geekculture/from-zero-to-hero-how-to-create-your-first-sentiment-analysis-dashboard-cec74f9933c4\"&gt;LINK&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I hope you find it helpful and feel free to ask me any questions in the comments. Happy coding!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?auto=webp&amp;v=enabled&amp;s=bc9f825cf880b702429b5e90f6fc08be5fc85edc", "width": 1200, "height": 801}, "resolutions": [{"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fc80836ded13aa611d30d52a8d05a41770a07b7", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f8ed71be54947658b486c71565f59460fe3cf6ef", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1d87218c476f379a96d40781e508f3d1116c4dbc", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0653b6f59655caed6dd799986d829bfe09e79c6", "width": 640, "height": 427}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b068302c47f92858a263ee173778e7b2cb04e432", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/jClBd5SYZZYWEifNsMZclJHY3KgYbmnP4BQuAg1bE7Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=be4e263e7aea28cec215da06da7950944cf2f2ef", "width": 1080, "height": 720}], "variants": {}, "id": "OHBMApcHRfYRpKSJNJQkbefGPe_H09WVqcQN1zau9bE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13zjpll", "is_robot_indexable": true, "report_reasons": null, "author": "DataSynapse82", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zjpll/sentiment_analysis_dashboard_data_pipeline_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zjpll/sentiment_analysis_dashboard_data_pipeline_with/", "subreddit_subscribers": 108734, "created_utc": 1685813678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_dhgy4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udceb Building Framework on top of Great Expectations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "name": "t3_13zis26", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/5lDsPrzs2P8jEsxE5FVIvJ91zeE3ls5XqH48rH-pp24.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685811699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "junaideffendi.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.junaideffendi.com/blog/building-framework-on-top-of-great-expectations/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?auto=webp&amp;v=enabled&amp;s=0df29b05802d79950de2f1736933010fade72725", "width": 1224, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b3832e6cc67943bd48cf2d8bfeadc91e6903def", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=171fdd33ca5176d87697e5542bd9b28227198fde", "width": 216, "height": 141}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e4405df3ce3fb55738b245c2f75b61425a332633", "width": 320, "height": 209}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4b7081f69887063c87ddeeda8860246a2008a2d6", "width": 640, "height": 418}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c8d84d14c69a84b2bad277cc2700bfa3142bcb21", "width": 960, "height": 627}, {"url": "https://external-preview.redd.it/ONxojROoGUedePtqNw2iYs_bwtDmBlt8Pofq2ULXPBk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b327b775b269db4da0c7c002d6706464dd879f05", "width": 1080, "height": 705}], "variants": {}, "id": "06m3kQO6fQ6ey6Ti2otaAWFW4pO65oO_GVSJJLRM3d4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13zis26", "is_robot_indexable": true, "report_reasons": null, "author": "mjfnd", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zis26/building_framework_on_top_of_great_expectations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.junaideffendi.com/blog/building-framework-on-top-of-great-expectations/", "subreddit_subscribers": 108734, "created_utc": 1685811699.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHey everyone!\n\nWe are a group of design students currently conducting academic research on an intriguing topic: the democratization of data and its potential of data to benefits the public. We believe that data can play a vital role in improving people's lives outside the realm of business, and we would love to hear your thoughts and experiences on this subject.\n\nIf you have a moment, we kindly invite you to answer one or more of the following questions either privately or as a comment:\n\n**- Please share your most recent experience using datasets for self-- worth or public value (non-business purposes). For example, a project that makes data accessible or extracts insights that can help the general public?**\n\n**- Working on the project, what worked and what didn't work? Were there barriers and challenges that you can share?**\n\n**- Are there any insights or tips you would like to share following the project?**\n\n**- Do you have any insights or thoughts regarding the use or accessibility of data for the public good?**\n\nYour contribution can be as brief or as detailed as you like. We greatly appreciate any answers, thoughts, or perspectives you are willing to share.\n\nThank you all!", "author_fullname": "t2_ummt1ubq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Academic research: data for the public good", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zbgkq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685795509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;We are a group of design students currently conducting academic research on an intriguing topic: the democratization of data and its potential of data to benefits the public. We believe that data can play a vital role in improving people&amp;#39;s lives outside the realm of business, and we would love to hear your thoughts and experiences on this subject.&lt;/p&gt;\n\n&lt;p&gt;If you have a moment, we kindly invite you to answer one or more of the following questions either privately or as a comment:&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- Please share your most recent experience using datasets for self-- worth or public value (non-business purposes). For example, a project that makes data accessible or extracts insights that can help the general public?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- Working on the project, what worked and what didn&amp;#39;t work? Were there barriers and challenges that you can share?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- Are there any insights or tips you would like to share following the project?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;- Do you have any insights or thoughts regarding the use or accessibility of data for the public good?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Your contribution can be as brief or as detailed as you like. We greatly appreciate any answers, thoughts, or perspectives you are willing to share.&lt;/p&gt;\n\n&lt;p&gt;Thank you all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13zbgkq", "is_robot_indexable": true, "report_reasons": null, "author": "Direct-Goat-2072", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zbgkq/academic_research_data_for_the_public_good/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zbgkq/academic_research_data_for_the_public_good/", "subreddit_subscribers": 108734, "created_utc": 1685795509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Given the DBT pricing fiasco, would you suggest any new models these companies can follow? What could be the various pricing models that would work? \n\nAsking as a business school student trying to learn.", "author_fullname": "t2_a17g9w41", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How should data transformation tools be priced?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_13zoq1x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685824598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Given the DBT pricing fiasco, would you suggest any new models these companies can follow? What could be the various pricing models that would work? &lt;/p&gt;\n\n&lt;p&gt;Asking as a business school student trying to learn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13zoq1x", "is_robot_indexable": true, "report_reasons": null, "author": "Psychological_Lynx69", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zoq1x/how_should_data_transformation_tools_be_priced/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zoq1x/how_should_data_transformation_tools_be_priced/", "subreddit_subscribers": 108734, "created_utc": 1685824598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Help me out dataengineering. \n\nRecently implemented a reporting solution for some historical data using synapse serverless and parquet and it worked out extremely well. It's fast and cheap! So now I'm going down the dataengineering rabbithole trying to do the same thing but \"real time\"ish. \n\nI want to copy data from (slow)apis and incrementally update a \"cache\" for ad hoc reporting(sql).  \n\nThis is for SAAS software, the customer would own their own storage on azure(thousands of customers).\n\nNeed fresh-ish data, would like to update like every 5 minutes but flexible up to 30 minutes, maybe even an hour.\n\nThis must be on azure. We deal with lots of Microsoft software and customers use CRM(dataverse) and power BI. Synapse would be awesome for our powerbi customers.  \n\nI am dealing with smaller datasets, so a large table is maybe 10 gigs. Basically replicating business software data for reporting for smaller/small-medium sized businesses. \n\nThe end users aren't all that technical so need to be able to automate everything myself. Want to build this into software that's all C#, so SQL/ADO and rest apis would be the best way to do things. But not scared of python or scala if required for spark pipelines or something.\n\nThe most important things:  \n\nI just want to go fast!\n\nCheap(serverless). If the customer only needs to store a few gigs of data, it should cost dollars a month. \n\nI just need a storage solution that works well with incremental updates. No help with pipelines, data processing, or anything like that. \n\nSo basically how would you recommend that I make a cheap, fast, replicated data store on azure that I can do sql on for \"medium data\"? \nIs delta lake my solution or merge into?, should I use spark?\nOr am I confused and should just use a database?", "author_fullname": "t2_622qq2ku", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommend me a cheap fast azure storage layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zl932", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685817065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Help me out dataengineering. &lt;/p&gt;\n\n&lt;p&gt;Recently implemented a reporting solution for some historical data using synapse serverless and parquet and it worked out extremely well. It&amp;#39;s fast and cheap! So now I&amp;#39;m going down the dataengineering rabbithole trying to do the same thing but &amp;quot;real time&amp;quot;ish. &lt;/p&gt;\n\n&lt;p&gt;I want to copy data from (slow)apis and incrementally update a &amp;quot;cache&amp;quot; for ad hoc reporting(sql).  &lt;/p&gt;\n\n&lt;p&gt;This is for SAAS software, the customer would own their own storage on azure(thousands of customers).&lt;/p&gt;\n\n&lt;p&gt;Need fresh-ish data, would like to update like every 5 minutes but flexible up to 30 minutes, maybe even an hour.&lt;/p&gt;\n\n&lt;p&gt;This must be on azure. We deal with lots of Microsoft software and customers use CRM(dataverse) and power BI. Synapse would be awesome for our powerbi customers.  &lt;/p&gt;\n\n&lt;p&gt;I am dealing with smaller datasets, so a large table is maybe 10 gigs. Basically replicating business software data for reporting for smaller/small-medium sized businesses. &lt;/p&gt;\n\n&lt;p&gt;The end users aren&amp;#39;t all that technical so need to be able to automate everything myself. Want to build this into software that&amp;#39;s all C#, so SQL/ADO and rest apis would be the best way to do things. But not scared of python or scala if required for spark pipelines or something.&lt;/p&gt;\n\n&lt;p&gt;The most important things:  &lt;/p&gt;\n\n&lt;p&gt;I just want to go fast!&lt;/p&gt;\n\n&lt;p&gt;Cheap(serverless). If the customer only needs to store a few gigs of data, it should cost dollars a month. &lt;/p&gt;\n\n&lt;p&gt;I just need a storage solution that works well with incremental updates. No help with pipelines, data processing, or anything like that. &lt;/p&gt;\n\n&lt;p&gt;So basically how would you recommend that I make a cheap, fast, replicated data store on azure that I can do sql on for &amp;quot;medium data&amp;quot;? \nIs delta lake my solution or merge into?, should I use spark?\nOr am I confused and should just use a database?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zl932", "is_robot_indexable": true, "report_reasons": null, "author": "WMMMMMMMMMMMMMMMMMMW", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zl932/recommend_me_a_cheap_fast_azure_storage_layer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zl932/recommend_me_a_cheap_fast_azure_storage_layer/", "subreddit_subscribers": 108734, "created_utc": 1685817065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "When does it make sense to include kinesis into your data pipeline versus doing a micro batch with airflow? I have chosen to just use lambdas to pull social media data every 15 minutes into a S3 bucket. What volume or velocity would it make sense to add Kafka or Kinesis into the process? Right now, I just have a 20 million records. It could be millions of records a day as we grow. The requirement is near real time refresh rate.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Design question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13zk4rc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685814615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When does it make sense to include kinesis into your data pipeline versus doing a micro batch with airflow? I have chosen to just use lambdas to pull social media data every 15 minutes into a S3 bucket. What volume or velocity would it make sense to add Kafka or Kinesis into the process? Right now, I just have a 20 million records. It could be millions of records a day as we grow. The requirement is near real time refresh rate.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "13zk4rc", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zk4rc/design_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13zk4rc/design_question/", "subreddit_subscribers": 108734, "created_utc": 1685814615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a one year experienced engineer ( I can't say that I am truly a data engineer though my profile is). I have worked on two major projects.\n1. Automated time series forecasting tool.\n -  Where I worked on creating orchestrated jobs on databricks , ci cd setup on azure pipelines. I wrote python scripts for data health check, time series scenario simulator, automating environment setup of databricks through py scripts,etc [technology: mostly python , databricks, postgres, azure devops]\n\n2. LLM serving framework.\n - I have worked on serving open source LLMs through fastapi and host them on azure kubernetes service, setting up training environment to train LLMs, create openai type package to use the api service [ technology: kubernetes, docker, fastapi]\n\nI want to make a switch as my work environment is extremely toxic, but I am not sure about what my  work profile should be. Should I try to learn more core data emginner skills( like spark etc) or just try to move towards devops.\n\nSeeking guidance on what skills shall I work on and what should my intended work profile be.", "author_fullname": "t2_7oz5gwm6k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career guidance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13ze6ck", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685801694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a one year experienced engineer ( I can&amp;#39;t say that I am truly a data engineer though my profile is). I have worked on two major projects.\n1. Automated time series forecasting tool.\n -  Where I worked on creating orchestrated jobs on databricks , ci cd setup on azure pipelines. I wrote python scripts for data health check, time series scenario simulator, automating environment setup of databricks through py scripts,etc [technology: mostly python , databricks, postgres, azure devops]&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;LLM serving framework.\n\n&lt;ul&gt;\n&lt;li&gt;I have worked on serving open source LLMs through fastapi and host them on azure kubernetes service, setting up training environment to train LLMs, create openai type package to use the api service [ technology: kubernetes, docker, fastapi]&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I want to make a switch as my work environment is extremely toxic, but I am not sure about what my  work profile should be. Should I try to learn more core data emginner skills( like spark etc) or just try to move towards devops.&lt;/p&gt;\n\n&lt;p&gt;Seeking guidance on what skills shall I work on and what should my intended work profile be.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "13ze6ck", "is_robot_indexable": true, "report_reasons": null, "author": "saurabhgsingh", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13ze6ck/career_guidance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13ze6ck/career_guidance/", "subreddit_subscribers": 108734, "created_utc": 1685801694.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I'm curious to hear your opinions on Cloudera's decision to transition from using the Spark engine with Hive to Tez engine with Hive. \n\nI've been using Hive on Tez recently and it appears to be slower compared to Hive on Spark. Even though big SQL queries have similar run times after optimizing the queue on Hive with Tez (Hive on Spark still outperforms it), smaller queries are significantly slower on Hive with Tez.\n\nI know Tez has some use cases and would be great if someone was using MapReduce and then transitioned to Tez. However, it can be challenging for someone who was previously using Spark engine and now moved to Tez engine.\n\nWould love to hear your thoughts\u2026", "author_fullname": "t2_658ryj26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hive on Tez engine vs Spark engine", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_13yzd1z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1685763039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I&amp;#39;m curious to hear your opinions on Cloudera&amp;#39;s decision to transition from using the Spark engine with Hive to Tez engine with Hive. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using Hive on Tez recently and it appears to be slower compared to Hive on Spark. Even though big SQL queries have similar run times after optimizing the queue on Hive with Tez (Hive on Spark still outperforms it), smaller queries are significantly slower on Hive with Tez.&lt;/p&gt;\n\n&lt;p&gt;I know Tez has some use cases and would be great if someone was using MapReduce and then transitioned to Tez. However, it can be challenging for someone who was previously using Spark engine and now moved to Tez engine.&lt;/p&gt;\n\n&lt;p&gt;Would love to hear your thoughts\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "13yzd1z", "is_robot_indexable": true, "report_reasons": null, "author": "Different-Ad-2901", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13yzd1z/hive_on_tez_engine_vs_spark_engine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/13yzd1z/hive_on_tez_engine_vs_spark_engine/", "subreddit_subscribers": 108734, "created_utc": 1685763039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uu592ayo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ClickHouse &amp; Apache Doris in Keyword Searching by Response Time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 56, "top_awarded_type": null, "hide_score": false, "name": "t3_13zfuzo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3YNr8JBsDa-hTVz9X7Mg9ySDf2Gxaz7m4ztNjLjBBHI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1685805393.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/qv56puewjt3b1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/qv56puewjt3b1.png?auto=webp&amp;v=enabled&amp;s=a46bfc83ff38850db64463af7d32556d44fdd932", "width": 1546, "height": 626}, "resolutions": [{"url": "https://preview.redd.it/qv56puewjt3b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7d20308115c6aa037f522ccff1818eac2717a08", "width": 108, "height": 43}, {"url": "https://preview.redd.it/qv56puewjt3b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c749b2e3f23df617170980afdc803195d3a99eae", "width": 216, "height": 87}, {"url": "https://preview.redd.it/qv56puewjt3b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=458ecb686a46b3207b676f3d386cbf22b7582e91", "width": 320, "height": 129}, {"url": "https://preview.redd.it/qv56puewjt3b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fd78968c09959c5f75a71722198fc2748de3dd7f", "width": 640, "height": 259}, {"url": "https://preview.redd.it/qv56puewjt3b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00cd57910c1d39b65f44809409ba8ac5b648b963", "width": 960, "height": 388}, {"url": "https://preview.redd.it/qv56puewjt3b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1e321b06b84e0f9ec2547da86b87986d9e47ec4f", "width": 1080, "height": 437}], "variants": {}, "id": "1XU_zXzsbjj_W6qRR_YvNN37AggGG6mwMOPp23V2fbQ"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "13zfuzo", "is_robot_indexable": true, "report_reasons": null, "author": "Any_Opportunity1234", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/13zfuzo/clickhouse_apache_doris_in_keyword_searching_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/qv56puewjt3b1.png", "subreddit_subscribers": 108734, "created_utc": 1685805393.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}