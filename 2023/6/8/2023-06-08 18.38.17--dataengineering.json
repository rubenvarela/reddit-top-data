{"kind": "Listing", "data": {"after": "t3_144eg2h", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_al1087x2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"We have great datasets\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14442pi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 513, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 513, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ga_7RAoN8V433_JbVht6gqgSz82qr9tW8WqHe5FUDoE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686215302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/0bv7bxlsfr4b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/0bv7bxlsfr4b1.jpg?auto=webp&amp;v=enabled&amp;s=5299cc7847620be17e95e54c423ddb6a4ec889ef", "width": 657, "height": 1024}, "resolutions": [{"url": "https://preview.redd.it/0bv7bxlsfr4b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a252fcec0f4d26871e545eed29c5e4526d4dab5", "width": 108, "height": 168}, {"url": "https://preview.redd.it/0bv7bxlsfr4b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=43de77bc0dd46aa1a632fd532b0d693b1b77d803", "width": 216, "height": 336}, {"url": "https://preview.redd.it/0bv7bxlsfr4b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=996a092469a1fc28b11d9c4156d2680b6b613a7a", "width": 320, "height": 498}, {"url": "https://preview.redd.it/0bv7bxlsfr4b1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6563c0ae0a82d35d03c3054b9019d50d184b1cb9", "width": 640, "height": 997}], "variants": {}, "id": "2SEkdAR-fDYOrIf2zGGCVLGBI4-9-IByrrCjsdsFqhI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "14442pi", "is_robot_indexable": true, "report_reasons": null, "author": "OverratedDataScience", "discussion_type": null, "num_comments": 88, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14442pi/we_have_great_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/0bv7bxlsfr4b1.jpg", "subreddit_subscribers": 109605, "created_utc": 1686215302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our dashboards at work basically have powerbi doing all the merging and aggregation.\n\nI am not positive if it's done by query or after pointed to the sql tables.\n\nIs that normal, or best practices? I would have built a view and pointed to the view.", "author_fullname": "t2_m3d4ku9h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dashboards best practices - how much transformation should PowerBI or Tableau be doing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143t8vc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 64, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 64, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686182089.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our dashboards at work basically have powerbi doing all the merging and aggregation.&lt;/p&gt;\n\n&lt;p&gt;I am not positive if it&amp;#39;s done by query or after pointed to the sql tables.&lt;/p&gt;\n\n&lt;p&gt;Is that normal, or best practices? I would have built a view and pointed to the view.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "143t8vc", "is_robot_indexable": true, "report_reasons": null, "author": "DifficultyNext7666", "discussion_type": null, "num_comments": 44, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/143t8vc/dashboards_best_practices_how_much_transformation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/143t8vc/dashboards_best_practices_how_much_transformation/", "subreddit_subscribers": 109605, "created_utc": 1686182089.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I just finished a technical interview for a lead data engineer position. It is an hour long interview and spent the first half of it  going through SQL leetcode with complex window functions.\n\nAt around 40 mins mark I realised that they are just looking for a SQL guru and ignoring the facts that I have more to offers eg knowledge about AWS services, Terraforming infrastructure, data architecture, etc.\n\nIs this data engineering all about (being great with SQL) or did i make a good decision and asked to stop the interview at minute 45? What are your thoughts?", "author_fullname": "t2_8n43xmar", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interviewing for lead data engineer position.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143wn2y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686191104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I just finished a technical interview for a lead data engineer position. It is an hour long interview and spent the first half of it  going through SQL leetcode with complex window functions.&lt;/p&gt;\n\n&lt;p&gt;At around 40 mins mark I realised that they are just looking for a SQL guru and ignoring the facts that I have more to offers eg knowledge about AWS services, Terraforming infrastructure, data architecture, etc.&lt;/p&gt;\n\n&lt;p&gt;Is this data engineering all about (being great with SQL) or did i make a good decision and asked to stop the interview at minute 45? What are your thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "143wn2y", "is_robot_indexable": true, "report_reasons": null, "author": "Fun-River1467", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/143wn2y/interviewing_for_lead_data_engineer_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/143wn2y/interviewing_for_lead_data_engineer_position/", "subreddit_subscribers": 109605, "created_utc": 1686191104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most companies are rushing to build or incorporate #gpt in their value chain. #genai. Do you agree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 135, "top_awarded_type": null, "hide_score": false, "name": "t3_1449ezb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ql36a1u5XiI16sn5HqRzdhG8zw_inVMLnQL9oCUH2rM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686231137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/228ijxavqs4b1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/228ijxavqs4b1.jpg?auto=webp&amp;v=enabled&amp;s=ade6d01ef12f1c754f0f21503c425dabd1f616e7", "width": 508, "height": 491}, "resolutions": [{"url": "https://preview.redd.it/228ijxavqs4b1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=5987f1e009464ea5b5f7dcc2cb75030621336611", "width": 108, "height": 104}, {"url": "https://preview.redd.it/228ijxavqs4b1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ef2b8d9f551a5174cc3c049aa498b7ea63e1485", "width": 216, "height": 208}, {"url": "https://preview.redd.it/228ijxavqs4b1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cf109415d50e8e1b020bdc9840e1e30f9b0cea6a", "width": 320, "height": 309}], "variants": {}, "id": "ef1ShIJxSr2mp7vHw6SFkjRj1YADOVuW0kbsWj4Buyo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "1449ezb", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1449ezb/most_companies_are_rushing_to_build_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/228ijxavqs4b1.jpg", "subreddit_subscribers": 109605, "created_utc": 1686231137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6lg1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airbyte 0.50: Introducing Checkpointing, Column Selection, and Schema Propagation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_144br5h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-DyZAnfRrMkV5t8ipBovTsZAY3U6hdENANp0mqMpsec.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686236784.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "airbyte.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://airbyte.com/blog/announcing-airbyte-0-50-checkpointing-column-selection-and-schema-propagation", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-3U4WuN6oTE3jeqsFl9vdpMaeXFvbDeGTSb1CIwyZg8.jpg?auto=webp&amp;v=enabled&amp;s=f89bb48d85b033c506d0ec07110eeab11312351f", "width": 2400, "height": 1256}, "resolutions": [{"url": "https://external-preview.redd.it/-3U4WuN6oTE3jeqsFl9vdpMaeXFvbDeGTSb1CIwyZg8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb722b51d518ae6f493d0003ce82fa1d44ac547e", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/-3U4WuN6oTE3jeqsFl9vdpMaeXFvbDeGTSb1CIwyZg8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=748a6aedb97c7d4512995e93ab98bb027a13840b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/-3U4WuN6oTE3jeqsFl9vdpMaeXFvbDeGTSb1CIwyZg8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d2dda26256ffbc65c6320271db84cb42ae378d2", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/-3U4WuN6oTE3jeqsFl9vdpMaeXFvbDeGTSb1CIwyZg8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=994fdf502f0814c2545e6fdea10e025e19e39ce1", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/-3U4WuN6oTE3jeqsFl9vdpMaeXFvbDeGTSb1CIwyZg8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=32b7170ec371b56ae4aceaa92c8fd9ab0de70f25", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/-3U4WuN6oTE3jeqsFl9vdpMaeXFvbDeGTSb1CIwyZg8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=fafe44574f8a0b5956aeb84b682c6dc4a22e0643", "width": 1080, "height": 565}], "variants": {}, "id": "HCnX-381bCXm4BTZJDB__gImXB-fG7zq42d3ULpDpPg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "144br5h", "is_robot_indexable": true, "report_reasons": null, "author": "evantahler", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/144br5h/airbyte_050_introducing_checkpointing_column/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://airbyte.com/blog/announcing-airbyte-0-50-checkpointing-column-selection-and-schema-propagation", "subreddit_subscribers": 109605, "created_utc": 1686236784.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, I am a data/platform/software engineer with 3 YOE. I want to share my experience and challenges at work, and hopefully get some advice for my career in the next **2-4 years** from the community.\n\nI am hiding some of information to stay anonymous, but I think they should give a good idea of what my work is like.\n\n# Work experience / tech stack\n\nI was hired as a data engineer at first, but I only seriously worked on one data engineering project. In this 3 years, I worked on **a lot of stuff:**\n\n1. Serverless data serving system on AWS\n2. Airflow deployment / development / plugins / pipelines, I am the main guy supporting this platform \n3. CICD\n4. Python / Docker application\n5. FastAPI and ElasticSearch backend\n6. Python CPU/GPU image classification backend dev/testing (**I really enjoyed it** although it was mainly a previous senior's work)\n7. Webscraping \n8. Some Spark for unstructured data (batch)\n9. Snowflake / dbt (batch)\n10. Terraform / AWS CDK\n\nMy manager has a very wide range of work scope, so I follow his scope and worked on a lot of stuff, which is truly a blessing but I don't get very deep into these skills. Recently my work has been more and more on platform capabilities and enabling other engineers.\n\n# Team background / culture\n\nThe entire department is big enough for my work to make impact, but we are not a team with strong engineering background, most people are analytics/data science background. People/management are friendly and supportive.\n\nMy immediate team is a central platform team. My immediate teammates/managers are very good engineers, but our team's work scope is too wide so we are not focused enough. There are some more good engineers but we don't have a lot of knowledge sharing.\n\n# My challenges / concerns / struggles\n\n1. Starting to feel some politics\n2. Tech debts are not usually prioritised, not like some companies which will regularly dedicate sprints to fix tech debts. This leads to problems / inefficiency down the road\n3. Projects are not well planned, and designs can change on a daily basis, I was really stressed on some projects, because they progress slowly and time became tighter and tighter\n5. Tickets story points poorly estimated, usually because we are bringing new stuff to our projects and have less experience \n4. (might be the reason of 3) my immediate team has no project manager, and no proper analyst\n5. My work scope is too damn wide. I am not sure this is good or bad, I certainly learn so so much, and I continue to become important to the team. But I don't get a chance to be very good at something. And I get very distracted in context switching, and eventually stressed out.\n6. My manager is giving less code/implementation review, because he's working on higher level design, and some tech stack is also new for him.\n\n# Things I enjoy more\n\n1. Writing code, testing it, running it. **Things with short feedback loop (who doesn't like it)**.\n2. Building applications.\n\n# Things I enjoy less\n\nAnalytics and looking at graphs. I think analytical thinking is a crucial skill for any one any job at a high level, but actually doing analytic work is painful for me.\n\n# Salary\n\nAfter all, the paycheque is what ultimately matters for a job. According to \\[this collection\\]([https://www.reddit.com/r/dataengineering/comments/npxcqc/quarterly\\_salary\\_discussion/](https://www.reddit.com/r/dataengineering/comments/npxcqc/quarterly_salary_discussion/)), I am around / above median for engineers with my YOE in my country. I am quite happy with my pay now.\n\n# Things I want to get advice on\n\n1. Should I change job? If yes, should I aim for FANG/tier 1 companies, or smaller companies / consulting, or let's be bold, trading firms?\n2. Should I stay in data platform career? Or move into more pure data engineering? And I am interested in software/backend engineer role too\n   1. I actually got an offer as a software/backend engineer from a biggish tech company, but I rejected it due to multiple reasons, mostly job security. \n3. Stay or leave, what should I ask from manager to help me progress?\n4. Is it better for me to be in a more independent situation, or get more guidance / review from senior engineers?\n5. Should I keep a wide scope or more focused scope?\n6. Any other thought or advice you have\n\n# Finally\n\nThank you for reading and providing advice! Feel free to ask anything as well I will try to answer what I know.", "author_fullname": "t2_8zp9kjxy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career advice wanted - data/platform/software engineer with 3 YOE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1449g7y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686233339.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686231228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, I am a data/platform/software engineer with 3 YOE. I want to share my experience and challenges at work, and hopefully get some advice for my career in the next &lt;strong&gt;2-4 years&lt;/strong&gt; from the community.&lt;/p&gt;\n\n&lt;p&gt;I am hiding some of information to stay anonymous, but I think they should give a good idea of what my work is like.&lt;/p&gt;\n\n&lt;h1&gt;Work experience / tech stack&lt;/h1&gt;\n\n&lt;p&gt;I was hired as a data engineer at first, but I only seriously worked on one data engineering project. In this 3 years, I worked on &lt;strong&gt;a lot of stuff:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Serverless data serving system on AWS&lt;/li&gt;\n&lt;li&gt;Airflow deployment / development / plugins / pipelines, I am the main guy supporting this platform &lt;/li&gt;\n&lt;li&gt;CICD&lt;/li&gt;\n&lt;li&gt;Python / Docker application&lt;/li&gt;\n&lt;li&gt;FastAPI and ElasticSearch backend&lt;/li&gt;\n&lt;li&gt;Python CPU/GPU image classification backend dev/testing (&lt;strong&gt;I really enjoyed it&lt;/strong&gt; although it was mainly a previous senior&amp;#39;s work)&lt;/li&gt;\n&lt;li&gt;Webscraping &lt;/li&gt;\n&lt;li&gt;Some Spark for unstructured data (batch)&lt;/li&gt;\n&lt;li&gt;Snowflake / dbt (batch)&lt;/li&gt;\n&lt;li&gt;Terraform / AWS CDK&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;My manager has a very wide range of work scope, so I follow his scope and worked on a lot of stuff, which is truly a blessing but I don&amp;#39;t get very deep into these skills. Recently my work has been more and more on platform capabilities and enabling other engineers.&lt;/p&gt;\n\n&lt;h1&gt;Team background / culture&lt;/h1&gt;\n\n&lt;p&gt;The entire department is big enough for my work to make impact, but we are not a team with strong engineering background, most people are analytics/data science background. People/management are friendly and supportive.&lt;/p&gt;\n\n&lt;p&gt;My immediate team is a central platform team. My immediate teammates/managers are very good engineers, but our team&amp;#39;s work scope is too wide so we are not focused enough. There are some more good engineers but we don&amp;#39;t have a lot of knowledge sharing.&lt;/p&gt;\n\n&lt;h1&gt;My challenges / concerns / struggles&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Starting to feel some politics&lt;/li&gt;\n&lt;li&gt;Tech debts are not usually prioritised, not like some companies which will regularly dedicate sprints to fix tech debts. This leads to problems / inefficiency down the road&lt;/li&gt;\n&lt;li&gt;Projects are not well planned, and designs can change on a daily basis, I was really stressed on some projects, because they progress slowly and time became tighter and tighter&lt;/li&gt;\n&lt;li&gt;Tickets story points poorly estimated, usually because we are bringing new stuff to our projects and have less experience &lt;/li&gt;\n&lt;li&gt;(might be the reason of 3) my immediate team has no project manager, and no proper analyst&lt;/li&gt;\n&lt;li&gt;My work scope is too damn wide. I am not sure this is good or bad, I certainly learn so so much, and I continue to become important to the team. But I don&amp;#39;t get a chance to be very good at something. And I get very distracted in context switching, and eventually stressed out.&lt;/li&gt;\n&lt;li&gt;My manager is giving less code/implementation review, because he&amp;#39;s working on higher level design, and some tech stack is also new for him.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;Things I enjoy more&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Writing code, testing it, running it. &lt;strong&gt;Things with short feedback loop (who doesn&amp;#39;t like it)&lt;/strong&gt;.&lt;/li&gt;\n&lt;li&gt;Building applications.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;Things I enjoy less&lt;/h1&gt;\n\n&lt;p&gt;Analytics and looking at graphs. I think analytical thinking is a crucial skill for any one any job at a high level, but actually doing analytic work is painful for me.&lt;/p&gt;\n\n&lt;h1&gt;Salary&lt;/h1&gt;\n\n&lt;p&gt;After all, the paycheque is what ultimately matters for a job. According to [this collection](&lt;a href=\"https://www.reddit.com/r/dataengineering/comments/npxcqc/quarterly_salary_discussion/\"&gt;https://www.reddit.com/r/dataengineering/comments/npxcqc/quarterly_salary_discussion/&lt;/a&gt;), I am around / above median for engineers with my YOE in my country. I am quite happy with my pay now.&lt;/p&gt;\n\n&lt;h1&gt;Things I want to get advice on&lt;/h1&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Should I change job? If yes, should I aim for FANG/tier 1 companies, or smaller companies / consulting, or let&amp;#39;s be bold, trading firms?&lt;/li&gt;\n&lt;li&gt;Should I stay in data platform career? Or move into more pure data engineering? And I am interested in software/backend engineer role too\n\n&lt;ol&gt;\n&lt;li&gt;I actually got an offer as a software/backend engineer from a biggish tech company, but I rejected it due to multiple reasons, mostly job security. &lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Stay or leave, what should I ask from manager to help me progress?&lt;/li&gt;\n&lt;li&gt;Is it better for me to be in a more independent situation, or get more guidance / review from senior engineers?&lt;/li&gt;\n&lt;li&gt;Should I keep a wide scope or more focused scope?&lt;/li&gt;\n&lt;li&gt;Any other thought or advice you have&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h1&gt;Finally&lt;/h1&gt;\n\n&lt;p&gt;Thank you for reading and providing advice! Feel free to ask anything as well I will try to answer what I know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1449g7y", "is_robot_indexable": true, "report_reasons": null, "author": "Jazzlike-Pollution-4", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1449g7y/career_advice_wanted_dataplatformsoftware/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1449g7y/career_advice_wanted_dataplatformsoftware/", "subreddit_subscribers": 109605, "created_utc": 1686231228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "While there are some projects where you  can make a use case of their product and write a blog about it and you are a contributor. But are there any projects where you can contribute by building ETL pipelines for them?", "author_fullname": "t2_ens6kw85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it impossible to contribute to open source as a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143us7i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686186094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;While there are some projects where you  can make a use case of their product and write a blog about it and you are a contributor. But are there any projects where you can contribute by building ETL pipelines for them?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "143us7i", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent-Tadpole-564", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/143us7i/is_it_impossible_to_contribute_to_open_source_as/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/143us7i/is_it_impossible_to_contribute_to_open_source_as/", "subreddit_subscribers": 109605, "created_utc": 1686186094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm learning about Presto and Trino, and this term \"Interactive querying\" comes up a lot. I have a hard time wrapping my head around it.   \n\n\nIf you are using Presto or Trino, why do you use it, compared to Simple hive query, for example?", "author_fullname": "t2_8r6amwln", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What exactly is interactive querying? When do you need it? How is it different from running a couple of Hive SQL commands?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143ts6n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686183465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m learning about Presto and Trino, and this term &amp;quot;Interactive querying&amp;quot; comes up a lot. I have a hard time wrapping my head around it.   &lt;/p&gt;\n\n&lt;p&gt;If you are using Presto or Trino, why do you use it, compared to Simple hive query, for example?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "143ts6n", "is_robot_indexable": true, "report_reasons": null, "author": "money_noob_007", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/143ts6n/what_exactly_is_interactive_querying_when_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/143ts6n/what_exactly_is_interactive_querying_when_do_you/", "subreddit_subscribers": 109605, "created_utc": 1686183465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " In today's data-driven world, businesses need to have a solid data architecture in place to make informed decisions and drive growth. A well-designed data architecture allows for seamless data integration, efficient data processing, and scalable solutions. In this article, we'll discuss data architecture best practices based on the advice of Dan Sutherland, a managing director focusing on technology consulting. We'll also explore the different roles involved in building a modern data architecture, such as data architects, data modelers, data integration developers, and data engineers.\n\n## Seven Best Practices for Designing a Data Architecture\n\n1. Cloud-native Design: Modern data architecture should be designed to support scaling, high availability, and end-to-end security for data. This design allows for easy scalability without affecting performance.\n2. Scalable Data Pipelines: Data architectures should support real-time data streaming and micro-batch data bursts to handle spikes in data pipelines, such as seasonal fluctuations or quarter-end data flows.\n3. Seamless Data Integration: Data architectures should integrate with legacy applications using standard API interfaces, optimizing data sharing across systems and departments within an organization.\n4. Real-time Data Enablement: Enterprises need the ability to deploy automated and active data validations, classifications, management, and governance with complete and visible data lineage.\n5. Decoupled and Extensible Design: Data services provided to different organizations should not depend on one another, and it should be easy to add new capabilities and functionalities, such as adding data flow from Salesforce into your systems.\n6. Domain-driven Approach: Modern data architecture should be driven by common data domains, events, and microservices, centered around the common business information model.\n7. Balanced Investment: Consider the return on investment for your business when building a data architecture. There's no need to overinvest in modern data architecture environments and features if they're not needed for your business size and growth.\n\n## Roles Involved in Data Architecture\n\nA team of skilled professionals is essential for successfully executing these practices. Each member of the team brings their unique expertise to the table, ensuring that the organization's data strategy aligns with its overall goals. The key roles within a data engineering team include:\n\n* Data Architect: As a senior leader, the Data Architect is responsible for translating business requirements into technology requirements. They define the data architecture framework, standards, principles, and reference architecture, which serve as the foundation for the organization's data strategy. In this role, they collaborate and coordinate with multiple departments, stakeholders, partners, and external vendors to ensure seamless integration of data solutions.\n* Data Modeler: The Data Modeler creates conceptual, logical, or physical models of data sets, which provide a clear and consistent representation of the organization's data. By reverse-engineering databases, they identify standard labels and notations for use across departments, fostering consistency and streamlining communication between teams.\n* Data Integration Developer: These individuals are responsible for designing and implementing integrations between software platforms, programs, and applications. Working closely with the Data Architect, they ensure that the organization's data systems are interconnected and function seamlessly, enabling the extraction of maximum value from data assets.\n* Data Engineer: In situations where a Data Architect may not be present, such as in smaller companies, Data Engineers take on the responsibility of creating the vision designed by the Data Architect. They implement the data architecture framework, building the pipelines and infrastructure necessary to store, process, and analyze data effectively.\n\nBy leveraging the unique skills and expertise of each team member, a data engineering team can effectively execute an organization's data strategy, ultimately driving value and supporting data-driven decision-making across the company.\n\nBuilding a robust data architecture is crucial for businesses of all sizes. By following these best practices and understanding the different roles involved in data architecture, organizations can make better decisions, improve efficiency, and drive growth. When considering your current data architecture, think about which roles are present in your organization and whether they fulfill the responsibilities outlined in this article. As you plan and invest in your data architecture, remember to keep a balance between your business needs and the return on investment.\n\nI share these and other tips on building robust IT architecture in my blog: [https://ainsys.com/blog/2023/04/20/data-architecture-practices/?utm\\_source=reddit&amp;utm\\_medium=social&amp;utm\\_campaign=data\\_engineering&amp;utm\\_content=data\\_architecture&amp;utm\\_term=ITarchitecture](https://ainsys.com/blog/2023/04/20/data-architecture-practices/?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=data_engineering&amp;utm_content=data_architecture&amp;utm_term=ITarchitecture)", "author_fullname": "t2_ct09rz3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Architecture Best Practices: How to Build a Robust Data Infrastructure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_144en5h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686243492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In today&amp;#39;s data-driven world, businesses need to have a solid data architecture in place to make informed decisions and drive growth. A well-designed data architecture allows for seamless data integration, efficient data processing, and scalable solutions. In this article, we&amp;#39;ll discuss data architecture best practices based on the advice of Dan Sutherland, a managing director focusing on technology consulting. We&amp;#39;ll also explore the different roles involved in building a modern data architecture, such as data architects, data modelers, data integration developers, and data engineers.&lt;/p&gt;\n\n&lt;h2&gt;Seven Best Practices for Designing a Data Architecture&lt;/h2&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Cloud-native Design: Modern data architecture should be designed to support scaling, high availability, and end-to-end security for data. This design allows for easy scalability without affecting performance.&lt;/li&gt;\n&lt;li&gt;Scalable Data Pipelines: Data architectures should support real-time data streaming and micro-batch data bursts to handle spikes in data pipelines, such as seasonal fluctuations or quarter-end data flows.&lt;/li&gt;\n&lt;li&gt;Seamless Data Integration: Data architectures should integrate with legacy applications using standard API interfaces, optimizing data sharing across systems and departments within an organization.&lt;/li&gt;\n&lt;li&gt;Real-time Data Enablement: Enterprises need the ability to deploy automated and active data validations, classifications, management, and governance with complete and visible data lineage.&lt;/li&gt;\n&lt;li&gt;Decoupled and Extensible Design: Data services provided to different organizations should not depend on one another, and it should be easy to add new capabilities and functionalities, such as adding data flow from Salesforce into your systems.&lt;/li&gt;\n&lt;li&gt;Domain-driven Approach: Modern data architecture should be driven by common data domains, events, and microservices, centered around the common business information model.&lt;/li&gt;\n&lt;li&gt;Balanced Investment: Consider the return on investment for your business when building a data architecture. There&amp;#39;s no need to overinvest in modern data architecture environments and features if they&amp;#39;re not needed for your business size and growth.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;h2&gt;Roles Involved in Data Architecture&lt;/h2&gt;\n\n&lt;p&gt;A team of skilled professionals is essential for successfully executing these practices. Each member of the team brings their unique expertise to the table, ensuring that the organization&amp;#39;s data strategy aligns with its overall goals. The key roles within a data engineering team include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Data Architect: As a senior leader, the Data Architect is responsible for translating business requirements into technology requirements. They define the data architecture framework, standards, principles, and reference architecture, which serve as the foundation for the organization&amp;#39;s data strategy. In this role, they collaborate and coordinate with multiple departments, stakeholders, partners, and external vendors to ensure seamless integration of data solutions.&lt;/li&gt;\n&lt;li&gt;Data Modeler: The Data Modeler creates conceptual, logical, or physical models of data sets, which provide a clear and consistent representation of the organization&amp;#39;s data. By reverse-engineering databases, they identify standard labels and notations for use across departments, fostering consistency and streamlining communication between teams.&lt;/li&gt;\n&lt;li&gt;Data Integration Developer: These individuals are responsible for designing and implementing integrations between software platforms, programs, and applications. Working closely with the Data Architect, they ensure that the organization&amp;#39;s data systems are interconnected and function seamlessly, enabling the extraction of maximum value from data assets.&lt;/li&gt;\n&lt;li&gt;Data Engineer: In situations where a Data Architect may not be present, such as in smaller companies, Data Engineers take on the responsibility of creating the vision designed by the Data Architect. They implement the data architecture framework, building the pipelines and infrastructure necessary to store, process, and analyze data effectively.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;By leveraging the unique skills and expertise of each team member, a data engineering team can effectively execute an organization&amp;#39;s data strategy, ultimately driving value and supporting data-driven decision-making across the company.&lt;/p&gt;\n\n&lt;p&gt;Building a robust data architecture is crucial for businesses of all sizes. By following these best practices and understanding the different roles involved in data architecture, organizations can make better decisions, improve efficiency, and drive growth. When considering your current data architecture, think about which roles are present in your organization and whether they fulfill the responsibilities outlined in this article. As you plan and invest in your data architecture, remember to keep a balance between your business needs and the return on investment.&lt;/p&gt;\n\n&lt;p&gt;I share these and other tips on building robust IT architecture in my blog: &lt;a href=\"https://ainsys.com/blog/2023/04/20/data-architecture-practices/?utm_source=reddit&amp;amp;utm_medium=social&amp;amp;utm_campaign=data_engineering&amp;amp;utm_content=data_architecture&amp;amp;utm_term=ITarchitecture\"&gt;https://ainsys.com/blog/2023/04/20/data-architecture-practices/?utm_source=reddit&amp;amp;utm_medium=social&amp;amp;utm_campaign=data_engineering&amp;amp;utm_content=data_architecture&amp;amp;utm_term=ITarchitecture&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/I3xJj8ELsQOmy2H-NeHKFmGnh2tKVfHX1i7SJ1O1qwE.jpg?auto=webp&amp;v=enabled&amp;s=a857d06fc3f1362c48ce1ce4e18be17b3a3dc051", "width": 79, "height": 86}, "resolutions": [], "variants": {}, "id": "fKkAw45B6Aa1K9gfC0CvmXNzCjb0F-J2wvKUvaKf1Vk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "144en5h", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Speech36", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/144en5h/data_architecture_best_practices_how_to_build_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/144en5h/data_architecture_best_practices_how_to_build_a/", "subreddit_subscribers": 109605, "created_utc": 1686243492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_bc2rrdnd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free Tool for NoSQL Data Modelling to get a visualization like seen here?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "name": "t3_144bqls", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/YGLZC-Wtwnxxq7lEhGGxM_fS3pHPUwe3D-VXkSYTsTU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686236751.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/e5x6cppl7t4b1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/e5x6cppl7t4b1.png?auto=webp&amp;v=enabled&amp;s=2c9d290ece4bc04a4a37366cebd81ddae57b1506", "width": 1361, "height": 948}, "resolutions": [{"url": "https://preview.redd.it/e5x6cppl7t4b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7b21ef0b07cda2f37eeaa1ffe82eaf5752ce0d14", "width": 108, "height": 75}, {"url": "https://preview.redd.it/e5x6cppl7t4b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bd5e43803319b1555fc40f0cffa4647443713c9d", "width": 216, "height": 150}, {"url": "https://preview.redd.it/e5x6cppl7t4b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=204d4af49bd604bc2c063c9dca5533a5d6569e8c", "width": 320, "height": 222}, {"url": "https://preview.redd.it/e5x6cppl7t4b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b43fbadd2493af1adec74e0d15fa904af947ab91", "width": 640, "height": 445}, {"url": "https://preview.redd.it/e5x6cppl7t4b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=771904e03b81f656e9263071ec0624f96c482866", "width": 960, "height": 668}, {"url": "https://preview.redd.it/e5x6cppl7t4b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eb3c2b594cee466669790b8555a9b149f1f6899c", "width": 1080, "height": 752}], "variants": {}, "id": "TaOjWvvsrofzkwX3kq_CdTOI1vUTv2RIhlc6CMtXSVc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "144bqls", "is_robot_indexable": true, "report_reasons": null, "author": "AndyMacht58", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/144bqls/free_tool_for_nosql_data_modelling_to_get_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/e5x6cppl7t4b1.png", "subreddit_subscribers": 109605, "created_utc": 1686236751.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious - how big are the data lakes you're actively maintaining? Daily input/output? Mostly static or always being queried? What are you using for it? What works, what doesn't?\n\nForget the buzzwords - data lake, data lakehouse, data marsh, whatever you call it - the thing that isn't a data warehouse that people use to query", "author_fullname": "t2_40buwhod", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time to Flex - How Big is your Data Lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143x8kz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686196635.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686192800.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious - how big are the data lakes you&amp;#39;re actively maintaining? Daily input/output? Mostly static or always being queried? What are you using for it? What works, what doesn&amp;#39;t?&lt;/p&gt;\n\n&lt;p&gt;Forget the buzzwords - data lake, data lakehouse, data marsh, whatever you call it - the thing that isn&amp;#39;t a data warehouse that people use to query&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "143x8kz", "is_robot_indexable": true, "report_reasons": null, "author": "DrZachman", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/143x8kz/time_to_flex_how_big_is_your_data_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/143x8kz/time_to_flex_how_big_is_your_data_lake/", "subreddit_subscribers": 109605, "created_utc": 1686192800.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently learning elastic search..", "author_fullname": "t2_ur0ro3ju", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any good resource or blogs for Elastic Search ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143ws10", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686191476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently learning elastic search..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "143ws10", "is_robot_indexable": true, "report_reasons": null, "author": "chaddlb0", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/143ws10/any_good_resource_or_blogs_for_elastic_search/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/143ws10/any_good_resource_or_blogs_for_elastic_search/", "subreddit_subscribers": 109605, "created_utc": 1686191476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As in what the resources could be.  \nI want to learn more about the back story from the ground up. I want to learn about parallel programming and  high efficient processing of large data.  Any comprehensive theoretical textbook would be fine with me, although not limited to not just 0theory.", "author_fullname": "t2_ftuqk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I learn in depth about distributed systems and distributed computing from a traditional computer science perspective?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1442sti", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686210642.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As in what the resources could be.&lt;br/&gt;\nI want to learn more about the back story from the ground up. I want to learn about parallel programming and  high efficient processing of large data.  Any comprehensive theoretical textbook would be fine with me, although not limited to not just 0theory.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1442sti", "is_robot_indexable": true, "report_reasons": null, "author": "philonoist", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1442sti/where_can_i_learn_in_depth_about_distributed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1442sti/where_can_i_learn_in_depth_about_distributed/", "subreddit_subscribers": 109605, "created_utc": 1686210642.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My background is mostly in Microsoft and Azure products, but I have a potential contract opportunity working with GCP.  Not sure if I'll be successful or not, so it's potentially a moot point.  But the opportunity to get away from the Microsoft treadmill is appealing... I'd be more than happy if I never saw ADF/Synapse ever again.  \n\nCan anyone talk about the pros and cons of Google's stack... and particularly how it lines up against Azure?", "author_fullname": "t2_5txrt2ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure to GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143ubuc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686184898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My background is mostly in Microsoft and Azure products, but I have a potential contract opportunity working with GCP.  Not sure if I&amp;#39;ll be successful or not, so it&amp;#39;s potentially a moot point.  But the opportunity to get away from the Microsoft treadmill is appealing... I&amp;#39;d be more than happy if I never saw ADF/Synapse ever again.  &lt;/p&gt;\n\n&lt;p&gt;Can anyone talk about the pros and cons of Google&amp;#39;s stack... and particularly how it lines up against Azure?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "143ubuc", "is_robot_indexable": true, "report_reasons": null, "author": "tarzanboy76", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/143ubuc/azure_to_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/143ubuc/azure_to_gcp/", "subreddit_subscribers": 109605, "created_utc": 1686184898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Tech stack: \nAzure data lake gen 2 storage ;\nAzure data factory ;\nDatabricks premium ;\nMedallion Architecture ;\n\nTo preface: my organization has 20 different source systems across 15 different servers. Each server has a SQL DB with like data.  That data is extracted from the source sql db and stored in bronze layer as parquet files. \n\n\nI then have 1 silver databricks transformation notebook that the source system name is passed through from an ADF parameter to filter the source and target data.  \n\nAt the end of the procedure, I complete a merge into (update and insert) into a delta table that is partitioned by source system.  \n\nIn the merge into routine I am filtering the source AND target by the source system parameter. \n\nI have 1 pipeline that is triggered by the source system name (20 different triggers that all start at the same time, but with a different source system parameter). \n\nEven though my delta table is partitioned by source system and my notebook is being passed a source system, I still receive an error: files were added to partition source system = x , by a concurrent update. \n\n#my question\nIs there any way around this without creating a silver.deltatable_sourcesystem?\n\n\n\n\nThis is my redacted merge into code: \n\np_sourceSystemName = 'SourceSystem1'\n\ndeltaTable =  f\"delta.`abfss://pathtotable/Silver_mytable`\"\n\n-Get the list of column names for the source table\nsource_cols = spark.table(\"test\").columns\n\n-Create a temporary table with distinct records from the source table\nspark.table(\"test\").select(source_cols).distinct().createOrReplaceTempView(\"temp_source\")\n\n\n-Update existing records\nsql_update = f\"\"\"MERGE INTO {deltaTable} AS target\nUSING (\nSELECT\n*\nFROM temp_source S\nWHERE S.SourceSystem = '{p_sourceSystemName}'\n) AS source\n\nON target.CoIDPatNo = source.CoIDPatNo\nAND target.HashValue != source.HashValue\nAND target.currentIndicator = 'Y'\nAND target.SourceSystem = '{p_sourceSystemName}'\n\nWHEN MATCHED THEN\n    UPDATE SET\n        currentIndicator = 'N',\n        ValidToTs = current_timestamp,\n        actionType = 'Update'\n\"\"\"\n- insert new records\nsql_insert = f\"\"\"MERGE INTO {deltaTable} AS target\nUSING (\nSELECT\n*\nFROM temp_source S\nWHERE S.SourceSystem = '{p_sourceSystemName}'\n) AS source\nON target.CoIDPatNo = source.CoIDPatNo\nAND target.HashValue = source.HashValue\nAND target.currentIndicator = 'Y'\nAND target.SourceSystem = '{p_sourceSystemName}'\n\nWHEN NOT MATCHED THEN\n    INSERT ({\", \".join(source_cols)}) -- dynamically construct the column list\n    VALUES ({\", \".join([\"source.\" + col for col in source_cols])});  -- dynamically construct the value list\n\"\"\"\n\n- Execute the update and insert statements\nspark.sql(sql_update)\nspark.sql(sql_insert)", "author_fullname": "t2_uf4ne7uq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Merge into", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143pi7b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686173956.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686173087.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Tech stack: \nAzure data lake gen 2 storage ;\nAzure data factory ;\nDatabricks premium ;\nMedallion Architecture ;&lt;/p&gt;\n\n&lt;p&gt;To preface: my organization has 20 different source systems across 15 different servers. Each server has a SQL DB with like data.  That data is extracted from the source sql db and stored in bronze layer as parquet files. &lt;/p&gt;\n\n&lt;p&gt;I then have 1 silver databricks transformation notebook that the source system name is passed through from an ADF parameter to filter the source and target data.  &lt;/p&gt;\n\n&lt;p&gt;At the end of the procedure, I complete a merge into (update and insert) into a delta table that is partitioned by source system.  &lt;/p&gt;\n\n&lt;p&gt;In the merge into routine I am filtering the source AND target by the source system parameter. &lt;/p&gt;\n\n&lt;p&gt;I have 1 pipeline that is triggered by the source system name (20 different triggers that all start at the same time, but with a different source system parameter). &lt;/p&gt;\n\n&lt;p&gt;Even though my delta table is partitioned by source system and my notebook is being passed a source system, I still receive an error: files were added to partition source system = x , by a concurrent update. &lt;/p&gt;\n\n&lt;h1&gt;my question&lt;/h1&gt;\n\n&lt;p&gt;Is there any way around this without creating a silver.deltatable_sourcesystem?&lt;/p&gt;\n\n&lt;p&gt;This is my redacted merge into code: &lt;/p&gt;\n\n&lt;p&gt;p_sourceSystemName = &amp;#39;SourceSystem1&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;deltaTable =  f&amp;quot;delta.&lt;code&gt;abfss://pathtotable/Silver_mytable&lt;/code&gt;&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;-Get the list of column names for the source table\nsource_cols = spark.table(&amp;quot;test&amp;quot;).columns&lt;/p&gt;\n\n&lt;p&gt;-Create a temporary table with distinct records from the source table\nspark.table(&amp;quot;test&amp;quot;).select(source_cols).distinct().createOrReplaceTempView(&amp;quot;temp_source&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;-Update existing records\nsql_update = f&amp;quot;&amp;quot;&amp;quot;MERGE INTO {deltaTable} AS target\nUSING (\nSELECT\n*\nFROM temp_source S\nWHERE S.SourceSystem = &amp;#39;{p_sourceSystemName}&amp;#39;\n) AS source&lt;/p&gt;\n\n&lt;p&gt;ON target.CoIDPatNo = source.CoIDPatNo\nAND target.HashValue != source.HashValue\nAND target.currentIndicator = &amp;#39;Y&amp;#39;\nAND target.SourceSystem = &amp;#39;{p_sourceSystemName}&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;WHEN MATCHED THEN\n    UPDATE SET\n        currentIndicator = &amp;#39;N&amp;#39;,\n        ValidToTs = current_timestamp,\n        actionType = &amp;#39;Update&amp;#39;\n&amp;quot;&amp;quot;&amp;quot;\n- insert new records\nsql_insert = f&amp;quot;&amp;quot;&amp;quot;MERGE INTO {deltaTable} AS target\nUSING (\nSELECT\n*\nFROM temp_source S\nWHERE S.SourceSystem = &amp;#39;{p_sourceSystemName}&amp;#39;\n) AS source\nON target.CoIDPatNo = source.CoIDPatNo\nAND target.HashValue = source.HashValue\nAND target.currentIndicator = &amp;#39;Y&amp;#39;\nAND target.SourceSystem = &amp;#39;{p_sourceSystemName}&amp;#39;&lt;/p&gt;\n\n&lt;p&gt;WHEN NOT MATCHED THEN\n    INSERT ({&amp;quot;, &amp;quot;.join(source_cols)}) -- dynamically construct the column list\n    VALUES ({&amp;quot;, &amp;quot;.join([&amp;quot;source.&amp;quot; + col for col in source_cols])});  -- dynamically construct the value list\n&amp;quot;&amp;quot;&amp;quot;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Execute the update and insert statements\nspark.sql(sql_update)\nspark.sql(sql_insert)&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "143pi7b", "is_robot_indexable": true, "report_reasons": null, "author": "NipsAhoy2", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/143pi7b/databricks_merge_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/143pi7b/databricks_merge_into/", "subreddit_subscribers": 109605, "created_utc": 1686173087.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone got some best practice github gist for a load module/function (using sqlalchemy/etc +x). Assume simple single node compute: dataframe to database table. \n\n- criteria: performant, parameterized/injection safe, requires specification of schema/dtypes (if pandas helper is used), etc.\n\nIf you dont have one at hand, I also welcome some bullet points on best practices. Elaborate implementations welcome. Trying to sanity check.", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Example of best-practice python load function/module", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_144e5wo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686249245.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686242389.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone got some best practice github gist for a load module/function (using sqlalchemy/etc +x). Assume simple single node compute: dataframe to database table. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;criteria: performant, parameterized/injection safe, requires specification of schema/dtypes (if pandas helper is used), etc.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you dont have one at hand, I also welcome some bullet points on best practices. Elaborate implementations welcome. Trying to sanity check.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "144e5wo", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/144e5wo/example_of_bestpractice_python_load_functionmodule/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/144e5wo/example_of_bestpractice_python_load_functionmodule/", "subreddit_subscribers": 109605, "created_utc": 1686242389.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! I was thinking about using MySQL to host a database, but wanted to know if it was server based / on premise or could be cloud based?\n\nI've heard people reference Google Cloud services for serverless DBMS? ", "author_fullname": "t2_7ox5swxh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I share a MySQL database over the cloud with someone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1449cpz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686231274.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686230989.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I was thinking about using MySQL to host a database, but wanted to know if it was server based / on premise or could be cloud based?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard people reference Google Cloud services for serverless DBMS? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1449cpz", "is_robot_indexable": true, "report_reasons": null, "author": "Use_Clean", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1449cpz/can_i_share_a_mysql_database_over_the_cloud_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1449cpz/can_i_share_a_mysql_database_over_the_cloud_with/", "subreddit_subscribers": 109605, "created_utc": 1686230989.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Im a very junir data engineer and need to set up a flow in ADF, but im having a hard time finding a solid enough logic for identifying unique rows and how the update logic will work.  \n\n\nEssentially what we get from our API query is: \n\n\\- Article\\_ID   \n\\- Store\\_Id  \n\\- ChckReasonCode  \n\\- Reception\\_Date  \n\\- Days  \n\n\nWhat we want to measure is \"Days\", which basically tells us how many days an Article has been in the stores list.   \n\n\nEvery day we get new data from an API. Problem is that one unique row can have the same Article\\_id, Store\\_id and CheckReasonCode, but the Reception\\_Date value will always reflect current day.  \n\n\nSo how can I update the dwh row, if I cannot link the newly added data already exisiting rows?  \n\n\nI was thinking of doing something of a check where Article\\_ID,Store\\_Id, and ChkReasonCode is grouped, and something like a \"If Reception date is only +1 from already existing dwh row\", update dwh row with new \"Days\" value.  \n\n\nHowever, this is not very good in terms of error handling, but I cannot find a different approach.  \n\n\nAny help will be much appreciated.  If anything is unclear ill be happy to try to explain it more thoroughly.", "author_fullname": "t2_xcbzsw9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Slowly Changing Dimensions Update logic", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1447vf6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686227173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Im a very junir data engineer and need to set up a flow in ADF, but im having a hard time finding a solid enough logic for identifying unique rows and how the update logic will work.  &lt;/p&gt;\n\n&lt;p&gt;Essentially what we get from our API query is: &lt;/p&gt;\n\n&lt;p&gt;- Article_ID&lt;br/&gt;\n- Store_Id&lt;br/&gt;\n- ChckReasonCode&lt;br/&gt;\n- Reception_Date&lt;br/&gt;\n- Days  &lt;/p&gt;\n\n&lt;p&gt;What we want to measure is &amp;quot;Days&amp;quot;, which basically tells us how many days an Article has been in the stores list.   &lt;/p&gt;\n\n&lt;p&gt;Every day we get new data from an API. Problem is that one unique row can have the same Article_id, Store_id and CheckReasonCode, but the Reception_Date value will always reflect current day.  &lt;/p&gt;\n\n&lt;p&gt;So how can I update the dwh row, if I cannot link the newly added data already exisiting rows?  &lt;/p&gt;\n\n&lt;p&gt;I was thinking of doing something of a check where Article_ID,Store_Id, and ChkReasonCode is grouped, and something like a &amp;quot;If Reception date is only +1 from already existing dwh row&amp;quot;, update dwh row with new &amp;quot;Days&amp;quot; value.  &lt;/p&gt;\n\n&lt;p&gt;However, this is not very good in terms of error handling, but I cannot find a different approach.  &lt;/p&gt;\n\n&lt;p&gt;Any help will be much appreciated.  If anything is unclear ill be happy to try to explain it more thoroughly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1447vf6", "is_robot_indexable": true, "report_reasons": null, "author": "useyourname89", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1447vf6/slowly_changing_dimensions_update_logic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1447vf6/slowly_changing_dimensions_update_logic/", "subreddit_subscribers": 109605, "created_utc": 1686227173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks, I'm a data engineer worked on both cloud and on-prem solutions, my current mission is to Migrate from Hortonworks to Cloudera (Hadoop storage , Spark workloads, Kafka brokers, Flink, ... ) and wondering what is the future of On-prem solution in the Data Engineering Space ?\nI'm assuming that with big companies like banks, insurance, ... that are very picky about owning their data instead of hosting it in a 3 party storage provider will still use it. \nAlso is it true that sometimes Cloud Data Architecture might become more expensive that those On-prem ?", "author_fullname": "t2_dkcukl0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Future of On-prem Big Data Solution ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1444ote", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686217430.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks, I&amp;#39;m a data engineer worked on both cloud and on-prem solutions, my current mission is to Migrate from Hortonworks to Cloudera (Hadoop storage , Spark workloads, Kafka brokers, Flink, ... ) and wondering what is the future of On-prem solution in the Data Engineering Space ?\nI&amp;#39;m assuming that with big companies like banks, insurance, ... that are very picky about owning their data instead of hosting it in a 3 party storage provider will still use it. \nAlso is it true that sometimes Cloud Data Architecture might become more expensive that those On-prem ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1444ote", "is_robot_indexable": true, "report_reasons": null, "author": "Emotional-Wheel-7854", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1444ote/future_of_onprem_big_data_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1444ote/future_of_onprem_big_data_solution/", "subreddit_subscribers": 109605, "created_utc": 1686217430.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,   \n\n\njust thinking about developer experience of building data pipeline(s). Nowadays, if I want to build a new data pipeline, I use Meltano to extract data, and dbt to transform it. I load everything to PostgreSQL, or Snowflake.   \n\n\nI usually build quite simple pipelines (just a few data sources - hubspot, GA, etc.), and therefore I run them in GitLab CI/CD, or GitHub actions.    \n\n\nI wanted to create some tool for it where I would just say \"hey, i want this data source and this data source, i want to load it there, and connect there\" but I ended up that it would be just \"configuration for configuration\". \ud83d\ude03 Maybe, I have just tunel view, or not enough experience w/ data engineering (since I was full stack dev for \\~6 years and to data engineering I switched recently) but is there a batter way on how to start projects without need to write tons of \"boilerplate\" code/configuration in tools like Meltano, dbt, YAML(s) for GitLab/GitHub, etc.?", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The best experience for building data pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1443xy8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686214858.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,   &lt;/p&gt;\n\n&lt;p&gt;just thinking about developer experience of building data pipeline(s). Nowadays, if I want to build a new data pipeline, I use Meltano to extract data, and dbt to transform it. I load everything to PostgreSQL, or Snowflake.   &lt;/p&gt;\n\n&lt;p&gt;I usually build quite simple pipelines (just a few data sources - hubspot, GA, etc.), and therefore I run them in GitLab CI/CD, or GitHub actions.    &lt;/p&gt;\n\n&lt;p&gt;I wanted to create some tool for it where I would just say &amp;quot;hey, i want this data source and this data source, i want to load it there, and connect there&amp;quot; but I ended up that it would be just &amp;quot;configuration for configuration&amp;quot;. \ud83d\ude03 Maybe, I have just tunel view, or not enough experience w/ data engineering (since I was full stack dev for ~6 years and to data engineering I switched recently) but is there a batter way on how to start projects without need to write tons of &amp;quot;boilerplate&amp;quot; code/configuration in tools like Meltano, dbt, YAML(s) for GitLab/GitHub, etc.?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1443xy8", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1443xy8/the_best_experience_for_building_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1443xy8/the_best_experience_for_building_data_pipelines/", "subreddit_subscribers": 109605, "created_utc": 1686214858.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Found this article describing an ELT pipeline.  It\u2019s a good read, but I\u2019m struggling to understand why you would store a data frame as parquet and store on Google Cloud Storage and then use a BQ Load Job to put it into BQ to transform and store in a BQ table.  Why not cut out the Cloud Storage step and put it directly into BQ?  Any ideas?", "author_fullname": "t2_5065w9mg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sky-Pipe: Prefect-GCP-dbt Data Pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_143xvwc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TDhxRwWd7jcI-b7f-ZC7F5SXgnQBJuw5gYXtCXmDPWw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686194639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "jackskylord.medium.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Found this article describing an ELT pipeline.  It\u2019s a good read, but I\u2019m struggling to understand why you would store a data frame as parquet and store on Google Cloud Storage and then use a BQ Load Job to put it into BQ to transform and store in a BQ table.  Why not cut out the Cloud Storage step and put it directly into BQ?  Any ideas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://jackskylord.medium.com/sky-pipe-prefect-gcp-dbt-data-pipeline-80561107c38f", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/vOIWIfrqqX9dM0GiVvgptRDC-7_AXqGmV1dpW7XnBjg.jpg?auto=webp&amp;v=enabled&amp;s=6a57dfcad039d0ec448dad3dbd92f7a5a5aa2c2a", "width": 1200, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/vOIWIfrqqX9dM0GiVvgptRDC-7_AXqGmV1dpW7XnBjg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=89a2f638491c9ddae01840225c197c4359dab5ce", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/vOIWIfrqqX9dM0GiVvgptRDC-7_AXqGmV1dpW7XnBjg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=02237bea5a4ec78593ba28526a6ad716e1b65d7d", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/vOIWIfrqqX9dM0GiVvgptRDC-7_AXqGmV1dpW7XnBjg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e16472eb10e9a958c2e3a0c07053b944d0a9e0df", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/vOIWIfrqqX9dM0GiVvgptRDC-7_AXqGmV1dpW7XnBjg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ed293de1c2af0ca87d5a1cbc954125aad24a4d03", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/vOIWIfrqqX9dM0GiVvgptRDC-7_AXqGmV1dpW7XnBjg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8a1e127fea200ccf0eab8fb901c422825c05ede4", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/vOIWIfrqqX9dM0GiVvgptRDC-7_AXqGmV1dpW7XnBjg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f4ff12c625dc37c1a955168358b0644794f12c0b", "width": 1080, "height": 810}], "variants": {}, "id": "6V3XW5iiLUmun0rfq3Lz5QlX4QVzL7-Y8JQI4TRZuDI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "143xvwc", "is_robot_indexable": true, "report_reasons": null, "author": "kvotheTHEinquisitor", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/143xvwc/skypipe_prefectgcpdbt_data_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://jackskylord.medium.com/sky-pipe-prefect-gcp-dbt-data-pipeline-80561107c38f", "subreddit_subscribers": 109605, "created_utc": 1686194639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm using this custom data validation library called Cerberus. Cerberus has a pre-built function, validate(), that validates data based on a table schema and set of validation rules that you give it. The function can either take in a row(in the form of a dictionary), or an entire pandas dataframe. \n\nThe function itself can take a really long time if the amount of data is large. Is there any way that I can partition the data and run the function against the partitions on multiple clusters in parallel?\n\nI've tried looking at many of Sparks features and couldn't figure out a solution ):", "author_fullname": "t2_8x16rrzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need some help integrating Spark with an open source data validation library.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143meqi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686166010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using this custom data validation library called Cerberus. Cerberus has a pre-built function, validate(), that validates data based on a table schema and set of validation rules that you give it. The function can either take in a row(in the form of a dictionary), or an entire pandas dataframe. &lt;/p&gt;\n\n&lt;p&gt;The function itself can take a really long time if the amount of data is large. Is there any way that I can partition the data and run the function against the partitions on multiple clusters in parallel?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried looking at many of Sparks features and couldn&amp;#39;t figure out a solution ):&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "143meqi", "is_robot_indexable": true, "report_reasons": null, "author": "Justanotherguy2022", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/143meqi/need_some_help_integrating_spark_with_an_open/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/143meqi/need_some_help_integrating_spark_with_an_open/", "subreddit_subscribers": 109605, "created_utc": 1686166010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI am currently searching an affordable alternative for an aging Hadoop cluster. We already have some stuff in Athena (parquet + S3 + Glue) but it is not very well structured.\n\nToday I tested Trino on EMR vs Athena with and without tables stored in the Iceberg format.\n\nThe overall experience with Athena was much better. Queries where faster and they worked out of the box. Trino was much slower, scaling didn't worked and sometimes it was not able to read the parquet files without specifying a proper error message.\n\nI cannot wrap my head around why most people seem to use Trino over Athena? It seems to be much more expensive, slower and less robust. (Albeit, the last point might originate from my limited experience).\n\nCan someone who is using both technologies give me a more refined report on the experience? We definitely do not want to use other SaaS technologies (we are solely on AWS, so GCP/BigQuery and Azure is not on the table anyways; Snowflake is so intransparent with their pricing; Databricks seems overkill)\n\nCheers,\n\nMatt", "author_fullname": "t2_5o9ebpsl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Questions about Athena, Trino and Iceberg", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_144gd06", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686247408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am currently searching an affordable alternative for an aging Hadoop cluster. We already have some stuff in Athena (parquet + S3 + Glue) but it is not very well structured.&lt;/p&gt;\n\n&lt;p&gt;Today I tested Trino on EMR vs Athena with and without tables stored in the Iceberg format.&lt;/p&gt;\n\n&lt;p&gt;The overall experience with Athena was much better. Queries where faster and they worked out of the box. Trino was much slower, scaling didn&amp;#39;t worked and sometimes it was not able to read the parquet files without specifying a proper error message.&lt;/p&gt;\n\n&lt;p&gt;I cannot wrap my head around why most people seem to use Trino over Athena? It seems to be much more expensive, slower and less robust. (Albeit, the last point might originate from my limited experience).&lt;/p&gt;\n\n&lt;p&gt;Can someone who is using both technologies give me a more refined report on the experience? We definitely do not want to use other SaaS technologies (we are solely on AWS, so GCP/BigQuery and Azure is not on the table anyways; Snowflake is so intransparent with their pricing; Databricks seems overkill)&lt;/p&gt;\n\n&lt;p&gt;Cheers,&lt;/p&gt;\n\n&lt;p&gt;Matt&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "144gd06", "is_robot_indexable": true, "report_reasons": null, "author": "mosquitsch", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/144gd06/questions_about_athena_trino_and_iceberg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/144gd06/questions_about_athena_trino_and_iceberg/", "subreddit_subscribers": 109605, "created_utc": 1686247408.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nOur ERP provided by a software publisher integrates an Oracle database. The Oracle ESL license prohibits us from accessing the database directly. Has anyone ever encountered this problem when loading data to a datawarehouse?", "author_fullname": "t2_f4isuvrv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Load data from Oracle DB to DW when Oracle is ESL licencing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_144epun", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686243652.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Our ERP provided by a software publisher integrates an Oracle database. The Oracle ESL license prohibits us from accessing the database directly. Has anyone ever encountered this problem when loading data to a datawarehouse?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "144epun", "is_robot_indexable": true, "report_reasons": null, "author": "SanctisDeusRex", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/144epun/load_data_from_oracle_db_to_dw_when_oracle_is_esl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/144epun/load_data_from_oracle_db_to_dw_when_oracle_is_esl/", "subreddit_subscribers": 109605, "created_utc": 1686243652.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Really amazing blog post by some of my colleagues/ClickHouse contributors.\n\nThe TL;DR is that with some of the recent changes in ClickHouse, the possibility of distributing super complex queries containing JOINs across many machines in a cluster using zero-copy replication is now possible. The implications are pretty massive if you're a ClickHouse user. ClickHouse is already really fast even on a single machine, but with these changes, you could feasibly run complex JOINing queries over **trillions** of rows in under a second, which is pretty mind-boggling. We're not there yet, but the work discussed in this blog post is a strong start.\n\nWould love to hear all your thoughts about it: [tbrd.co/joinsrd](https://tbrd.co/joinsrd) \n\nAnd in case it wasn't clear above, I do work for Tinybird, who published this post. But the content is more geared toward ClickHouse in general, so I hope this doesn't come off as a shill!", "author_fullname": "t2_o09cwtfl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adding JOIN support to parallel replicas on ClickHouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_144eg2h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686243033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Really amazing blog post by some of my colleagues/ClickHouse contributors.&lt;/p&gt;\n\n&lt;p&gt;The TL;DR is that with some of the recent changes in ClickHouse, the possibility of distributing super complex queries containing JOINs across many machines in a cluster using zero-copy replication is now possible. The implications are pretty massive if you&amp;#39;re a ClickHouse user. ClickHouse is already really fast even on a single machine, but with these changes, you could feasibly run complex JOINing queries over &lt;strong&gt;trillions&lt;/strong&gt; of rows in under a second, which is pretty mind-boggling. We&amp;#39;re not there yet, but the work discussed in this blog post is a strong start.&lt;/p&gt;\n\n&lt;p&gt;Would love to hear all your thoughts about it: &lt;a href=\"https://tbrd.co/joinsrd\"&gt;tbrd.co/joinsrd&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;And in case it wasn&amp;#39;t clear above, I do work for Tinybird, who published this post. But the content is more geared toward ClickHouse in general, so I hope this doesn&amp;#39;t come off as a shill!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/biDVvmIeRSy8w8mCNC8iwH3BOQLMopm3j7QbJBZlIt8.jpg?auto=webp&amp;v=enabled&amp;s=410402aa5be06f11fb58a09bf5ee8b22305ce198", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/biDVvmIeRSy8w8mCNC8iwH3BOQLMopm3j7QbJBZlIt8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=6fa5a294307c9e936f6a098f750a3ac7e49eb986", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/biDVvmIeRSy8w8mCNC8iwH3BOQLMopm3j7QbJBZlIt8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=aced700afbfd5d047445e1a02f5e235ba4df6c1b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/biDVvmIeRSy8w8mCNC8iwH3BOQLMopm3j7QbJBZlIt8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d7d231b868191029dede5426a1678bcb375564ef", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/biDVvmIeRSy8w8mCNC8iwH3BOQLMopm3j7QbJBZlIt8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b48d0391248d6c74e57633fa8f4337f9d343fc7f", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/biDVvmIeRSy8w8mCNC8iwH3BOQLMopm3j7QbJBZlIt8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=756443144012f3ca5d8e6e8c0da3285a43f8d2b3", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/biDVvmIeRSy8w8mCNC8iwH3BOQLMopm3j7QbJBZlIt8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4d33a5dfb603ecdb02117acf564f33d2ca23eb5e", "width": 1080, "height": 567}], "variants": {}, "id": "4mCXT7Z7iPa7UFM0muDZwUheEFVlOu7H1swJZD-iBMs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "144eg2h", "is_robot_indexable": true, "report_reasons": null, "author": "itty-bitty-birdy-tb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/144eg2h/adding_join_support_to_parallel_replicas_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/144eg2h/adding_join_support_to_parallel_replicas_on/", "subreddit_subscribers": 109605, "created_utc": 1686243033.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}