{"kind": "Listing", "data": {"after": "t3_1443fae", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I found a program named Reddsaver but not sure it can download posts with all the comments. Since most of my saved posts are some kind of tutorial (some comments are also useful there), they're mostly texts but some has videos or galleries too. It would be nice if I can pull them preferably as markdown.", "author_fullname": "t2_vemre", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I download all my saved posts on Reddit?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143lal5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 288, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 288, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686163420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found a program named Reddsaver but not sure it can download posts with all the comments. Since most of my saved posts are some kind of tutorial (some comments are also useful there), they&amp;#39;re mostly texts but some has videos or galleries too. It would be nice if I can pull them preferably as markdown.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143lal5", "is_robot_indexable": true, "report_reasons": null, "author": "muhyb", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143lal5/how_can_i_download_all_my_saved_posts_on_reddit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143lal5/how_can_i_download_all_my_saved_posts_on_reddit/", "subreddit_subscribers": 686575, "created_utc": 1686163420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I came across these guys when working to save all of pikamee's youtube channel before it was deleted. They had already been saving everything as it was released. The site hosts over 200,000 videos. \n\nThe stated closure date is \"on or before July 24, 2023.\"\n\nAccording to the letter posted about the issue, they were using a Google Workspaces team drive with no backup. Apparently, Google is cracking down on their storage policies and a 1.38 PB teams drive is understandably pretty high up on their priority list.\n\nThis post is my warning to check for and save anything you care about that may be lost before the site is gone forever.\n\n[this is their website](https://archive.ragtag.moe/)", "author_fullname": "t2_tglchi0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ragtag Archive is going offline - 1.38 PB of vtuber archives will be gone, many of which do not exist elsewhere", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143zvuh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 183, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 183, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686200596.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I came across these guys when working to save all of pikamee&amp;#39;s youtube channel before it was deleted. They had already been saving everything as it was released. The site hosts over 200,000 videos. &lt;/p&gt;\n\n&lt;p&gt;The stated closure date is &amp;quot;on or before July 24, 2023.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;According to the letter posted about the issue, they were using a Google Workspaces team drive with no backup. Apparently, Google is cracking down on their storage policies and a 1.38 PB teams drive is understandably pretty high up on their priority list.&lt;/p&gt;\n\n&lt;p&gt;This post is my warning to check for and save anything you care about that may be lost before the site is gone forever.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://archive.ragtag.moe/\"&gt;this is their website&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/J3ulZhU6El7W3BDobcSf5krdmci61XUB1sYrTg3P4N4.jpg?auto=webp&amp;v=enabled&amp;s=6965c765e274449bdf42d3e1ee8713323b9e4172", "width": 1606, "height": 1625}, "resolutions": [{"url": "https://external-preview.redd.it/J3ulZhU6El7W3BDobcSf5krdmci61XUB1sYrTg3P4N4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=cb55a6beb91f37fd66ed1f6d5a5832ad175f44ea", "width": 108, "height": 109}, {"url": "https://external-preview.redd.it/J3ulZhU6El7W3BDobcSf5krdmci61XUB1sYrTg3P4N4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b8bd3ab6a5847f5a67c0df948a8539981014dc1f", "width": 216, "height": 218}, {"url": "https://external-preview.redd.it/J3ulZhU6El7W3BDobcSf5krdmci61XUB1sYrTg3P4N4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=19caf8d55f164ee26441b77fc627cf22bb60f290", "width": 320, "height": 323}, {"url": "https://external-preview.redd.it/J3ulZhU6El7W3BDobcSf5krdmci61XUB1sYrTg3P4N4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=a7c64f85d5cf1290838552a8c1801d5138faa55b", "width": 640, "height": 647}, {"url": "https://external-preview.redd.it/J3ulZhU6El7W3BDobcSf5krdmci61XUB1sYrTg3P4N4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9df107ea0a4fa460ee2d124246813a1c9aa132fa", "width": 960, "height": 971}, {"url": "https://external-preview.redd.it/J3ulZhU6El7W3BDobcSf5krdmci61XUB1sYrTg3P4N4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b774fd9ccae178fe28e60ff981e6cf41ff694714", "width": 1080, "height": 1092}], "variants": {}, "id": "xjNVVn9Si3HT9w46y-2tNSDqP-BvogIS9gJZJgKG7XI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143zvuh", "is_robot_indexable": true, "report_reasons": null, "author": "avypath", "discussion_type": null, "num_comments": 56, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143zvuh/ragtag_archive_is_going_offline_138_pb_of_vtuber/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143zvuh/ragtag_archive_is_going_offline_138_pb_of_vtuber/", "subreddit_subscribers": 686575, "created_utc": 1686200596.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 8tb drive that is probably 5+ years old that appears to be corrupt. I have tons of files on it and this morning when I open a folder and click on a video file, I get a \"file missing\" message. However I can see the file and click on its properties as well. Another odd thing, I some files simply vanished, I clicked on a certain movie and got that error message, when I search for the file again its gone, as if i deleted it. My best guess is that this HD just crapped out. Luckily I have a back up, my questions are, is there a way to fix this damaged HD? can formatting it fix it? is is it time to buy a  new one? or is there another option ?\n\n&amp;#x200B;\n\nupdate: Crystal Disk info [https://ibb.co/VH9W7q4](https://ibb.co/VH9W7q4)", "author_fullname": "t2_8x1jz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "8tb hard drive just died on me.....", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1442krz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686224586.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686209812.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 8tb drive that is probably 5+ years old that appears to be corrupt. I have tons of files on it and this morning when I open a folder and click on a video file, I get a &amp;quot;file missing&amp;quot; message. However I can see the file and click on its properties as well. Another odd thing, I some files simply vanished, I clicked on a certain movie and got that error message, when I search for the file again its gone, as if i deleted it. My best guess is that this HD just crapped out. Luckily I have a back up, my questions are, is there a way to fix this damaged HD? can formatting it fix it? is is it time to buy a  new one? or is there another option ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;update: Crystal Disk info &lt;a href=\"https://ibb.co/VH9W7q4\"&gt;https://ibb.co/VH9W7q4&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/lS047YPqvwi81Rd7g0oZgBmqQO5Iu9HYJZEpBkJj11Q.jpg?auto=webp&amp;v=enabled&amp;s=2f8bdfe5473e821beafe8890b10931458ccb2f8b", "width": 1017, "height": 982}, "resolutions": [{"url": "https://external-preview.redd.it/lS047YPqvwi81Rd7g0oZgBmqQO5Iu9HYJZEpBkJj11Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1d0e929568bcf474623d885d0cc9ad342bea504b", "width": 108, "height": 104}, {"url": "https://external-preview.redd.it/lS047YPqvwi81Rd7g0oZgBmqQO5Iu9HYJZEpBkJj11Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7f097589251a1479fae1088ee8022b226747c85b", "width": 216, "height": 208}, {"url": "https://external-preview.redd.it/lS047YPqvwi81Rd7g0oZgBmqQO5Iu9HYJZEpBkJj11Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3516d4e879b225c078f593e080428101b4ea3788", "width": 320, "height": 308}, {"url": "https://external-preview.redd.it/lS047YPqvwi81Rd7g0oZgBmqQO5Iu9HYJZEpBkJj11Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d8a83255272b42b868c62bfc79990044f13088a6", "width": 640, "height": 617}, {"url": "https://external-preview.redd.it/lS047YPqvwi81Rd7g0oZgBmqQO5Iu9HYJZEpBkJj11Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=885d0a36484824a76843295711e9864cbc486c34", "width": 960, "height": 926}], "variants": {}, "id": "eVDXWjO_hVosDSjRMsDHbyUi2L7SWPUtnocTGivdmD8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1442krz", "is_robot_indexable": true, "report_reasons": null, "author": "FackJooBish", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1442krz/8tb_hard_drive_just_died_on_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1442krz/8tb_hard_drive_just_died_on_me/", "subreddit_subscribers": 686575, "created_utc": 1686209812.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello!\n\nWhat solution are you guys using to host/browse downloaded reddit content?\n\nI am working with the ZST files downloaded from Pushshift and sorted into subreddits by the lovely u/watchful1 [here](https://academictorrents.com/details/c398a571976c78d346c325bd75c47b82edf6124e). ZST is too compressed to browse on its own but using scripts like [this one](https://github.com/Watchful1/PushshiftDumps) you can process them into readable NDJSON files. From there im not sure what to do. I would like to have a self hosted reddit-clone that i can import these dumps into and browse freely.\n\nI'm thinking i will have to get a project like [redarc](https://github.com/Yakabuff/redarc) or [BDFR-to-HTML](https://github.com/BlipRanger/bdfr-html) or much more likely [Pushshift-Importer](https://github.com/Paul-E/Pushshift-Importer) which allows you to import pushshift downloads into a SQLite database. From there i would have to hook up the database to a reddit-like frontend.\n\nIs there a solution for this already?", "author_fullname": "t2_gn46ie9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are you using to browse/self host downloaded reddit?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143vpsm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686188612.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello!&lt;/p&gt;\n\n&lt;p&gt;What solution are you guys using to host/browse downloaded reddit content?&lt;/p&gt;\n\n&lt;p&gt;I am working with the ZST files downloaded from Pushshift and sorted into subreddits by the lovely &lt;a href=\"/u/watchful1\"&gt;u/watchful1&lt;/a&gt; &lt;a href=\"https://academictorrents.com/details/c398a571976c78d346c325bd75c47b82edf6124e\"&gt;here&lt;/a&gt;. ZST is too compressed to browse on its own but using scripts like &lt;a href=\"https://github.com/Watchful1/PushshiftDumps\"&gt;this one&lt;/a&gt; you can process them into readable NDJSON files. From there im not sure what to do. I would like to have a self hosted reddit-clone that i can import these dumps into and browse freely.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking i will have to get a project like &lt;a href=\"https://github.com/Yakabuff/redarc\"&gt;redarc&lt;/a&gt; or &lt;a href=\"https://github.com/BlipRanger/bdfr-html\"&gt;BDFR-to-HTML&lt;/a&gt; or much more likely &lt;a href=\"https://github.com/Paul-E/Pushshift-Importer\"&gt;Pushshift-Importer&lt;/a&gt; which allows you to import pushshift downloads into a SQLite database. From there i would have to hook up the database to a reddit-like frontend.&lt;/p&gt;\n\n&lt;p&gt;Is there a solution for this already?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?auto=webp&amp;v=enabled&amp;s=918b2eeb77d118fd8f4ba293fa5244eb3286a9c4", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=ff569e6656835558df2eb771cd6c91a6cf219c17", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=73b26d33631721450780f7ec8348b184ec52bb60", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=3b6563332be0778922ae7d781b4de71ae36c5970", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d0a85df145bd3584118bc59eecc1952652f8e1e5", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0bb05ca3c8192d78215c635f3bff8a98f332659c", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/AYlmrg-S8gXHsPLzgCLVzSw4nR2HKCQTGEUKOVSQpNU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=427bc2290a0c6c1b2004e5dadd7d6573f8b74411", "width": 1080, "height": 567}], "variants": {}, "id": "9ZQzIXgHwWUMmDwxygJ-VDFa1eAMjAGg-cgqxWhg4Js"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143vpsm", "is_robot_indexable": true, "report_reasons": null, "author": "pm_me_xenomorphs", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143vpsm/what_are_you_using_to_browseself_host_downloaded/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143vpsm/what_are_you_using_to_browseself_host_downloaded/", "subreddit_subscribers": 686575, "created_utc": 1686188612.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey folks, \n\nI'm the sad owner of a broken Raritan PX-5514 (a 0U vertical PDU) that's gone EOL and EOS a long time ago. Unfortunately, the seller appears to have botched a firmware upgrade and then passed it on to me, because the unit does not progress past the self-test phase.\n\nAccording to Raritan's manuals, there was a PDU recovery tool that could be used to rescue bad firmware flashes. However, Raritan themselves claim to no longer have any copies of the tool on hand and is therefore unable to help me.\n\nWould any of you happen to have a copy on hand, or know of someone who might have one squirreled away somewhere? I'd be extermely grateful for any leads.", "author_fullname": "t2_90lnp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a copy of Raritan's PDU Recovery Tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143h63i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686153743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m the sad owner of a broken Raritan PX-5514 (a 0U vertical PDU) that&amp;#39;s gone EOL and EOS a long time ago. Unfortunately, the seller appears to have botched a firmware upgrade and then passed it on to me, because the unit does not progress past the self-test phase.&lt;/p&gt;\n\n&lt;p&gt;According to Raritan&amp;#39;s manuals, there was a PDU recovery tool that could be used to rescue bad firmware flashes. However, Raritan themselves claim to no longer have any copies of the tool on hand and is therefore unable to help me.&lt;/p&gt;\n\n&lt;p&gt;Would any of you happen to have a copy on hand, or know of someone who might have one squirreled away somewhere? I&amp;#39;d be extermely grateful for any leads.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "50TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143h63i", "is_robot_indexable": true, "report_reasons": null, "author": "JargonTheRed", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/143h63i/looking_for_a_copy_of_raritans_pdu_recovery_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143h63i/looking_for_a_copy_of_raritans_pdu_recovery_tool/", "subreddit_subscribers": 686575, "created_utc": 1686153743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_mvvjw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have a good solution to replace the clunky power bricks with possibly a USB C for my D2 hard drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_143fv9u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TtMM_bLhWvip2byhyPIuPtlg32sX0_GM2-rnbqASUUE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686150724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "imgur.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://imgur.com/a/saxwuSr/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BNlKILfv3sD9KBuEybmWpPFxmIcD6JrTyurD8w9aIaM.jpg?auto=webp&amp;v=enabled&amp;s=b3f038c435f6743c47ab7fea8e9284b074b5ecaa", "width": 2000, "height": 1500}, "resolutions": [{"url": "https://external-preview.redd.it/BNlKILfv3sD9KBuEybmWpPFxmIcD6JrTyurD8w9aIaM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9ffff85e53598b6ac89ea3dbfde22774340bc095", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/BNlKILfv3sD9KBuEybmWpPFxmIcD6JrTyurD8w9aIaM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488b1ff8856521c9f6e3a66cde9ce1af41ecd78a", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/BNlKILfv3sD9KBuEybmWpPFxmIcD6JrTyurD8w9aIaM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9804ba8c79339299734afdec1744bd89447a7c68", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/BNlKILfv3sD9KBuEybmWpPFxmIcD6JrTyurD8w9aIaM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=29f69a8e08795da4104832afd5c929d6ae5a8001", "width": 640, "height": 480}, {"url": "https://external-preview.redd.it/BNlKILfv3sD9KBuEybmWpPFxmIcD6JrTyurD8w9aIaM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2d1b538689c41ac9f0899a4b07d0297ddd68b312", "width": 960, "height": 720}, {"url": "https://external-preview.redd.it/BNlKILfv3sD9KBuEybmWpPFxmIcD6JrTyurD8w9aIaM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dc2971c0555d72104b82bed4421ecfe38746b8a5", "width": 1080, "height": 810}], "variants": {}, "id": "8r-o0Ir09e8_BtLns3BacUy30j8Ubz-LqRogi1evhms"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143fv9u", "is_robot_indexable": true, "report_reasons": null, "author": "drawcody", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143fv9u/does_anyone_have_a_good_solution_to_replace_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://imgur.com/a/saxwuSr/", "subreddit_subscribers": 686575, "created_utc": 1686150724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a Synology system with about 160TB, and back up 100tb of that to google, until recently.  Deep archive sounded like a solution until I looked at restore and download costs, so I want to take the plunge into tape.\n\nLooks like a tape library would be the best option.  Since transfer speed is not a big issue to me (anything onsite will be faster than going to the cloud), I thought a refurbished LTO-5 library would be good, but looks like I might need 3 of those to back everything up.   I could go bigger with HPE LTO-7 with library that holds 40 tapes and expandable, but before the tape cost, that is $8k.  \n\nAre there other options I have not found yet?\n\nWhat tape system are you using?", "author_fullname": "t2_tix5tw2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "moving from google to tape, there are SO many options tho.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143oesz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686170633.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a Synology system with about 160TB, and back up 100tb of that to google, until recently.  Deep archive sounded like a solution until I looked at restore and download costs, so I want to take the plunge into tape.&lt;/p&gt;\n\n&lt;p&gt;Looks like a tape library would be the best option.  Since transfer speed is not a big issue to me (anything onsite will be faster than going to the cloud), I thought a refurbished LTO-5 library would be good, but looks like I might need 3 of those to back everything up.   I could go bigger with HPE LTO-7 with library that holds 40 tapes and expandable, but before the tape cost, that is $8k.  &lt;/p&gt;\n\n&lt;p&gt;Are there other options I have not found yet?&lt;/p&gt;\n\n&lt;p&gt;What tape system are you using?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143oesz", "is_robot_indexable": true, "report_reasons": null, "author": "webshammo", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143oesz/moving_from_google_to_tape_there_are_so_many/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143oesz/moving_from_google_to_tape_there_are_so_many/", "subreddit_subscribers": 686575, "created_utc": 1686170633.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't have a NAS. My Plex setup is simply my 5TB external seagate plugged to my laptop. My 5TB drive is full, so I'm looking to expand my storage. I know that all drives will fail eventually, but I still want the best I can get. I was originally looking for another external HDD (around 10-15 TB), but then I started reading more about them and how the drive that's inside them isn't usually the best. So I'm starting to think that it'd be better to get something like a 12TB WD gold or red pro, and put it in an enclosure, for close to the same price (compared to the external hdd).\n\nWhat do you guys think? Also if getting an internal HDD with an enclosure is better, what would be the \"best\" HDD? I'm mainly looking at the WD red pro (they're supposedly made for NAS in mind, whatever that means, and are quiet), the WD gold (supposedly the best WD has, but loud), or something from seagate. But I'm a bit confused by the seagate naming convention of their drives. They have their X and E series which seem to be their best (?), or I could get an ironwolf, but it's apparently a lot louder than the wd red pro. I also don't know how much noise is too noisy. My 5TB seagate external makes some noise but I need to focus on it to hear it. But I'm not sure how much louder a WD gold is.\n\nMoney isn't too much an issue, and I don't care about read or write speed, or any other metrics (except longevity). 95% of my data are .mkv files that will be written once, and only read after with plex, and the remaining 5% are photos, documents, and game setup files (not the actual game, just the files for the setup, the game installation will be on another drive) that will also be written once, and rarely read after.", "author_fullname": "t2_4bxhznee", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External HDD vs internal HDD with enclosure mainly for plex.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143mb6t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686165782.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t have a NAS. My Plex setup is simply my 5TB external seagate plugged to my laptop. My 5TB drive is full, so I&amp;#39;m looking to expand my storage. I know that all drives will fail eventually, but I still want the best I can get. I was originally looking for another external HDD (around 10-15 TB), but then I started reading more about them and how the drive that&amp;#39;s inside them isn&amp;#39;t usually the best. So I&amp;#39;m starting to think that it&amp;#39;d be better to get something like a 12TB WD gold or red pro, and put it in an enclosure, for close to the same price (compared to the external hdd).&lt;/p&gt;\n\n&lt;p&gt;What do you guys think? Also if getting an internal HDD with an enclosure is better, what would be the &amp;quot;best&amp;quot; HDD? I&amp;#39;m mainly looking at the WD red pro (they&amp;#39;re supposedly made for NAS in mind, whatever that means, and are quiet), the WD gold (supposedly the best WD has, but loud), or something from seagate. But I&amp;#39;m a bit confused by the seagate naming convention of their drives. They have their X and E series which seem to be their best (?), or I could get an ironwolf, but it&amp;#39;s apparently a lot louder than the wd red pro. I also don&amp;#39;t know how much noise is too noisy. My 5TB seagate external makes some noise but I need to focus on it to hear it. But I&amp;#39;m not sure how much louder a WD gold is.&lt;/p&gt;\n\n&lt;p&gt;Money isn&amp;#39;t too much an issue, and I don&amp;#39;t care about read or write speed, or any other metrics (except longevity). 95% of my data are .mkv files that will be written once, and only read after with plex, and the remaining 5% are photos, documents, and game setup files (not the actual game, just the files for the setup, the game installation will be on another drive) that will also be written once, and rarely read after.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143mb6t", "is_robot_indexable": true, "report_reasons": null, "author": "MoonlessNightss", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143mb6t/external_hdd_vs_internal_hdd_with_enclosure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143mb6t/external_hdd_vs_internal_hdd_with_enclosure/", "subreddit_subscribers": 686575, "created_utc": 1686165782.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://github.com/hamsterbase/hamsterbase-highlighter](https://github.com/hamsterbase/hamsterbase-highlighter)  \n\n\nPresenting an open-source Chrome extension that allows you to annotate and take notes directly on web pages. The best part? Your data remains intact even after refreshing the page.\n\nThe backend is highly flexible and can be easily switched, with current support for Hamsterbase and Notion. Future updates will include support for GitHub as well.\n\nWhen you choose to save your annotations to Hamsterbase, a convenient feature automatically captures a snapshot of the web page for your reference.\n\n**Notes:**\n\n1. The extension is entirely open-source and does not rely on Hamsterbase. It will remain free and open-source for the foreseeable future.\n2. Hamsterbase is a closed-source software developed by me. It is currently available as a Docker image and a desktop app.", "author_fullname": "t2_m9f6hryu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a opensource web highlighter for notion and hamsterbase.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143hlez", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686154707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/hamsterbase/hamsterbase-highlighter\"&gt;https://github.com/hamsterbase/hamsterbase-highlighter&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Presenting an open-source Chrome extension that allows you to annotate and take notes directly on web pages. The best part? Your data remains intact even after refreshing the page.&lt;/p&gt;\n\n&lt;p&gt;The backend is highly flexible and can be easily switched, with current support for Hamsterbase and Notion. Future updates will include support for GitHub as well.&lt;/p&gt;\n\n&lt;p&gt;When you choose to save your annotations to Hamsterbase, a convenient feature automatically captures a snapshot of the web page for your reference.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Notes:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The extension is entirely open-source and does not rely on Hamsterbase. It will remain free and open-source for the foreseeable future.&lt;/li&gt;\n&lt;li&gt;Hamsterbase is a closed-source software developed by me. It is currently available as a Docker image and a desktop app.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TSUC0Y5JB5RX0Z1plDtGBT-Tgcn9rGkQDCbgB03Yaus.jpg?auto=webp&amp;v=enabled&amp;s=2640dc46f1ae50315815ae358f9ce50e7a89341f", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/TSUC0Y5JB5RX0Z1plDtGBT-Tgcn9rGkQDCbgB03Yaus.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b526d74290187df8224354b864444bef7ddf58e5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/TSUC0Y5JB5RX0Z1plDtGBT-Tgcn9rGkQDCbgB03Yaus.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=264bb12f61e570fb292bb8981eff1b1edf51804a", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/TSUC0Y5JB5RX0Z1plDtGBT-Tgcn9rGkQDCbgB03Yaus.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=075bb02613db0998468224d3f12b3e6a2a6915ec", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/TSUC0Y5JB5RX0Z1plDtGBT-Tgcn9rGkQDCbgB03Yaus.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=7d8b7abc75279a9ec1ca9e3bdd4b668a39cb0983", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/TSUC0Y5JB5RX0Z1plDtGBT-Tgcn9rGkQDCbgB03Yaus.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9a3b0dc6ca70ee29f7ecd5d9e827ffd34c1fced9", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/TSUC0Y5JB5RX0Z1plDtGBT-Tgcn9rGkQDCbgB03Yaus.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=9c5cf182f1a46c5f5f249d293a418af06791fffa", "width": 1080, "height": 540}], "variants": {}, "id": "DoA6h_gRJCQfhJ1glv3gsPpLDuFzXlaqck0HZ2RAt6c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143hlez", "is_robot_indexable": true, "report_reasons": null, "author": "HamsterBaseMaster", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143hlez/i_made_a_opensource_web_highlighter_for_notion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143hlez/i_made_a_opensource_web_highlighter_for_notion/", "subreddit_subscribers": 686575, "created_utc": 1686154707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I made a Mobage account yesterday so I could try to preserve Mobage games. Posting because I need some help working out how to go about preserving these games.\n\nThe games are all hosted in different places, but one common thing would be all use server-side code and all of the images don't need cookies or a mobile user agent to mirror\n\nMost of the games I've tried need mobage login cookies and all need an Android user agent\n\nI'm just kind of overwhelmed on where to start here", "author_fullname": "t2_d9gcu53d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "archiving Mobage games", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143dxvc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686146077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I made a Mobage account yesterday so I could try to preserve Mobage games. Posting because I need some help working out how to go about preserving these games.&lt;/p&gt;\n\n&lt;p&gt;The games are all hosted in different places, but one common thing would be all use server-side code and all of the images don&amp;#39;t need cookies or a mobile user agent to mirror&lt;/p&gt;\n\n&lt;p&gt;Most of the games I&amp;#39;ve tried need mobage login cookies and all need an Android user agent&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just kind of overwhelmed on where to start here&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143dxvc", "is_robot_indexable": true, "report_reasons": null, "author": "gosc_reddit", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143dxvc/archiving_mobage_games/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143dxvc/archiving_mobage_games/", "subreddit_subscribers": 686575, "created_utc": 1686146077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My children's school regularly posts photos and videos of school life to their twitter account. I have been using gallery-dl to archive these images. I tend to donwload a month at a time, but recently it has stopped working, can anyone please help me?  \n\n\nHere is the command I usually issue (using google instead of real account):\n\n    PS C:\\Users\\me\\Downloads&gt; .\\gallery-dl --dest gallery-dl/twitter/2023-04 \"https://twitter.com/search?q=(from%3Agoogle)%20until%3A2023-05-01%20since%3A2023-04-01\"\n    [twitter][info] Requesting guest token\n    [twitter][error] 403 Forbidden (Forbidden.)\n\nAnd here is one without the date constraints:\n\n    PS C:\\Users\\me\\Downloads\\&gt; .\\gallery-dl --dest gallery-dl/twitter \"https://twitter.com/search?q=from:google\"\n    [twitter][info] Requesting guest token\n    [twitter][error] 403 Forbidden (Forbidden.)\n\nNeither command works anymore.\n\nHowever, if I run it without using the search, it still works, but then I can't filter a month or year at a time.\n\n    PS C:\\Users\\me\\Downloads&gt; .\\gallery-dl --dest gallery-dl/twitter \"http://twitter.com/google\"\n    * gallery-dl\\twitter\\2023-04\\twitter\\Google\\1666183917177536512_1.mp4\n\nIs this something to do with recent changes to the Twitter API?  \n\n\nThank you", "author_fullname": "t2_stw7a9lt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "gallery-dl Twitter no longer working", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1447t5w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686226996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My children&amp;#39;s school regularly posts photos and videos of school life to their twitter account. I have been using gallery-dl to archive these images. I tend to donwload a month at a time, but recently it has stopped working, can anyone please help me?  &lt;/p&gt;\n\n&lt;p&gt;Here is the command I usually issue (using google instead of real account):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;PS C:\\Users\\me\\Downloads&amp;gt; .\\gallery-dl --dest gallery-dl/twitter/2023-04 &amp;quot;https://twitter.com/search?q=(from%3Agoogle)%20until%3A2023-05-01%20since%3A2023-04-01&amp;quot;\n[twitter][info] Requesting guest token\n[twitter][error] 403 Forbidden (Forbidden.)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And here is one without the date constraints:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;PS C:\\Users\\me\\Downloads\\&amp;gt; .\\gallery-dl --dest gallery-dl/twitter &amp;quot;https://twitter.com/search?q=from:google&amp;quot;\n[twitter][info] Requesting guest token\n[twitter][error] 403 Forbidden (Forbidden.)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Neither command works anymore.&lt;/p&gt;\n\n&lt;p&gt;However, if I run it without using the search, it still works, but then I can&amp;#39;t filter a month or year at a time.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;PS C:\\Users\\me\\Downloads&amp;gt; .\\gallery-dl --dest gallery-dl/twitter &amp;quot;http://twitter.com/google&amp;quot;\n* gallery-dl\\twitter\\2023-04\\twitter\\Google\\1666183917177536512_1.mp4\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Is this something to do with recent changes to the Twitter API?  &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1447t5w", "is_robot_indexable": true, "report_reasons": null, "author": "InfamousLibrarian518", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1447t5w/gallerydl_twitter_no_longer_working/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1447t5w/gallerydl_twitter_no_longer_working/", "subreddit_subscribers": 686575, "created_utc": 1686226996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know this is a little off topic but I hope it's close enough and there will be some people who have some ideas. For those of you who run media servers and have shows or movies that you can only get in 480p, have you all found good ways of upscaling them? I would be interested in looking at open source software that could this well or if anyone has tried some of the newer AI solutions and if they are any good. Currently want to get a more HD version of Star Trek DS9 which seems to have only ever been produced on DVD.", "author_fullname": "t2_12kajv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best ways to upscale 480p video to 1080p?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143vhu6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686187995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is a little off topic but I hope it&amp;#39;s close enough and there will be some people who have some ideas. For those of you who run media servers and have shows or movies that you can only get in 480p, have you all found good ways of upscaling them? I would be interested in looking at open source software that could this well or if anyone has tried some of the newer AI solutions and if they are any good. Currently want to get a more HD version of Star Trek DS9 which seems to have only ever been produced on DVD.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143vhu6", "is_robot_indexable": true, "report_reasons": null, "author": "dev_richard", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143vhu6/best_ways_to_upscale_480p_video_to_1080p/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143vhu6/best_ways_to_upscale_480p_video_to_1080p/", "subreddit_subscribers": 686575, "created_utc": 1686187995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows (11/10) incremental backup solution", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143tz5f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.46, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "author_fullname": "t2_a65nr", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "WindowsHelp", "selftext": "What backup solution do you use for windows and why? If it\u2019s still sold, how much does a lifetime license cost and does it get free upgrades?\n\nGot fed up with Windows Backup and looking for a replacement that doesn\u2019t cost too much.", "author_fullname": "t2_a65nr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows (11/10) incremental backup solution", "link_flair_richtext": [{"e": "text", "t": "Windows 11"}], "subreddit_name_prefixed": "r/WindowsHelp", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143m6cj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Windows 11", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686165481.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.WindowsHelp", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What backup solution do you use for windows and why? If it\u2019s still sold, how much does a lifetime license cost and does it get free upgrades?&lt;/p&gt;\n\n&lt;p&gt;Got fed up with Windows Backup and looking for a replacement that doesn\u2019t cost too much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1a63a5a8-d28d-11eb-b580-0e2e73aaec5d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_38hjl", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00adef", "id": "143m6cj", "is_robot_indexable": true, "report_reasons": null, "author": "Gymnastboatman", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/WindowsHelp/comments/143m6cj/windows_1110_incremental_backup_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/WindowsHelp/comments/143m6cj/windows_1110_incremental_backup_solution/", "subreddit_subscribers": 18312, "created_utc": 1686165481.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1686183974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.WindowsHelp", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/WindowsHelp/comments/143m6cj/windows_1110_incremental_backup_solution/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "20TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143tz5f", "is_robot_indexable": true, "report_reasons": null, "author": "Gymnastboatman", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_143m6cj", "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/143tz5f/windows_1110_incremental_backup_solution/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/WindowsHelp/comments/143m6cj/windows_1110_incremental_backup_solution/", "subreddit_subscribers": 686575, "created_utc": 1686183974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "has anyone done a warranty claim with serverpartdeals?\n\ni want to buy a few WD 14TB drives.  the manufacture refurbs are out of stock; the seller refurbs are in stock.  both have a 2 year warranty.\n\nif the WD manufacturer refurb drive goes bad within 2 years, i assume i don't go thru WD but instead thru the seller -- serverpartdeals  -- for warranty claim, right?\n\nif so what would be the diff, from a warranty perspective, btw the 2 refurb types?\n\nany help appreciated.", "author_fullname": "t2_5vej5jn5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "warranty on serverpartdeals' manufacturer vs seller refurbished drives ...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143qrus", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686176016.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;has anyone done a warranty claim with serverpartdeals?&lt;/p&gt;\n\n&lt;p&gt;i want to buy a few WD 14TB drives.  the manufacture refurbs are out of stock; the seller refurbs are in stock.  both have a 2 year warranty.&lt;/p&gt;\n\n&lt;p&gt;if the WD manufacturer refurb drive goes bad within 2 years, i assume i don&amp;#39;t go thru WD but instead thru the seller -- serverpartdeals  -- for warranty claim, right?&lt;/p&gt;\n\n&lt;p&gt;if so what would be the diff, from a warranty perspective, btw the 2 refurb types?&lt;/p&gt;\n\n&lt;p&gt;any help appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143qrus", "is_robot_indexable": true, "report_reasons": null, "author": "redditmail9999", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143qrus/warranty_on_serverpartdeals_manufacturer_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143qrus/warranty_on_serverpartdeals_manufacturer_vs/", "subreddit_subscribers": 686575, "created_utc": 1686176016.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'll be using it for Plex, Hoarding, Backup, and some light server tasks. Probably Ubuntu and ZFS set up so I can rebuild if I loose a disk. Mostly concerned that I may not have picked good drives for the tasks or that the MB won't handle so many disks well but open to any suggestions. \n\n[PCPartPicker Part List](https://pcpartpicker.com/list/6CZcd9)\n\nType|Item|Price\n:----|:----|:----\n**CPU** | [AMD Ryzen 5 5600G 3.9 GHz 6-Core Processor](https://pcpartpicker.com/product/sYmmP6/amd-ryzen-5-5600g-39-ghz-6-core-processor-100-100000252box) | $121.66 @ Amazon \n**Motherboard** | [\\*ASRock B550 Phantom Gaming 4 ATX AM4 Motherboard](https://pcpartpicker.com/product/4mjNnQ/asrock-b550-phantom-gaming-4-atx-am4-motherboard-b550-phantom-gaming-4) | $99.99 @ Newegg \n**Memory** | [\\*Patriot Viper Steel 16 GB (2 x 8 GB) DDR4-3733 CL17 Memory](https://pcpartpicker.com/product/hkTzK8/patriot-viper-steel-16-gb-2-x-8-gb-ddr4-3733-cl17-memory-pvs416g373c7k) | $46.99 @ Amazon \n**Storage** | [\\*Western Digital Green SN350 1 TB M.2-2280 PCIe 3.0 X4 NVME Solid State Drive](https://pcpartpicker.com/product/zRnypg/western-digital-green-sn350-1-tb-m2-2280-nvme-solid-state-drive-wds100t3g0c) | $40.50 @ Newegg \n**Storage** | [\\*Seagate ST4000NM0024 4 TB 3.5\" 7200 RPM Internal Hard Drive](https://pcpartpicker.com/product/cFw323/seagate-internal-hard-drive-st4000nm0024) | $53.50 @ Amazon \n**Storage** | [\\*Seagate ST4000NM0024 4 TB 3.5\" 7200 RPM Internal Hard Drive](https://pcpartpicker.com/product/cFw323/seagate-internal-hard-drive-st4000nm0024) | $53.50 @ Amazon \n**Storage** | [\\*Seagate ST4000NM0024 4 TB 3.5\" 7200 RPM Internal Hard Drive](https://pcpartpicker.com/product/cFw323/seagate-internal-hard-drive-st4000nm0024) | $53.50 @ Amazon \n**Storage** | [\\*Seagate ST4000NM0024 4 TB 3.5\" 7200 RPM Internal Hard Drive](https://pcpartpicker.com/product/cFw323/seagate-internal-hard-drive-st4000nm0024) | $53.50 @ Amazon \n**Storage** | [\\*Seagate ST4000NM0024 4 TB 3.5\" 7200 RPM Internal Hard Drive](https://pcpartpicker.com/product/cFw323/seagate-internal-hard-drive-st4000nm0024) | $53.50 @ Amazon \n**Case** | [Cooler Master N400 ATX Mid Tower Case](https://pcpartpicker.com/product/wNrG3C/cooler-master-case-nse400kkn2) | $93.98 @ Newegg \n**Power Supply** | [\\*Thermaltake Smart BM2 550 W 80+ Bronze Certified Semi-modular ATX Power Supply](https://pcpartpicker.com/product/xQpmP6/thermaltake-smart-bm2-550-w-80-bronze-certified-semi-modular-atx-power-supply-ps-spd-0550mnfabu-1) | $60.99 @ Amazon \n | *Prices include shipping, taxes, rebates, and discounts* |\n | **Total** | **$731.61**\n | \\*Lowest price parts chosen from parametric criteria |\n | Generated by [PCPartPicker](https://pcpartpicker.com) 2023-06-07 14:17 EDT-0400 |", "author_fullname": "t2_9s66x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Build advice/thoughts for future NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143kpva", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686171088.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686162041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ll be using it for Plex, Hoarding, Backup, and some light server tasks. Probably Ubuntu and ZFS set up so I can rebuild if I loose a disk. Mostly concerned that I may not have picked good drives for the tasks or that the MB won&amp;#39;t handle so many disks well but open to any suggestions. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pcpartpicker.com/list/6CZcd9\"&gt;PCPartPicker Part List&lt;/a&gt;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Type&lt;/th&gt;\n&lt;th align=\"left\"&gt;Item&lt;/th&gt;\n&lt;th align=\"left\"&gt;Price&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;CPU&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://pcpartpicker.com/product/sYmmP6/amd-ryzen-5-5600g-39-ghz-6-core-processor-100-100000252box\"&gt;AMD Ryzen 5 5600G 3.9 GHz 6-Core Processor&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;$121.66 @ Amazon&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Motherboard&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://pcpartpicker.com/product/4mjNnQ/asrock-b550-phantom-gaming-4-atx-am4-motherboard-b550-phantom-gaming-4\"&gt;*ASRock B550 Phantom Gaming 4 ATX AM4 Motherboard&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;$99.99 @ Newegg&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Memory&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://pcpartpicker.com/product/hkTzK8/patriot-viper-steel-16-gb-2-x-8-gb-ddr4-3733-cl17-memory-pvs416g373c7k\"&gt;*Patriot Viper Steel 16 GB (2 x 8 GB) DDR4-3733 CL17 Memory&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;$46.99 @ Amazon&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://pcpartpicker.com/product/zRnypg/western-digital-green-sn350-1-tb-m2-2280-nvme-solid-state-drive-wds100t3g0c\"&gt;*Western Digital Green SN350 1 TB M.2-2280 PCIe 3.0 X4 NVME Solid State Drive&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;$40.50 @ Newegg&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://pcpartpicker.com/product/cFw323/seagate-internal-hard-drive-st4000nm0024\"&gt;*Seagate ST4000NM0024 4 TB 3.5&amp;quot; 7200 RPM Internal Hard Drive&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;$53.50 @ Amazon&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://pcpartpicker.com/product/cFw323/seagate-internal-hard-drive-st4000nm0024\"&gt;*Seagate ST4000NM0024 4 TB 3.5&amp;quot; 7200 RPM Internal Hard Drive&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;$53.50 @ Amazon&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://pcpartpicker.com/product/cFw323/seagate-internal-hard-drive-st4000nm0024\"&gt;*Seagate ST4000NM0024 4 TB 3.5&amp;quot; 7200 RPM Internal Hard Drive&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;$53.50 @ Amazon&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://pcpartpicker.com/product/cFw323/seagate-internal-hard-drive-st4000nm0024\"&gt;*Seagate ST4000NM0024 4 TB 3.5&amp;quot; 7200 RPM Internal Hard Drive&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;$53.50 @ Amazon&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://pcpartpicker.com/product/cFw323/seagate-internal-hard-drive-st4000nm0024\"&gt;*Seagate ST4000NM0024 4 TB 3.5&amp;quot; 7200 RPM Internal Hard Drive&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;$53.50 @ Amazon&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Case&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://pcpartpicker.com/product/wNrG3C/cooler-master-case-nse400kkn2\"&gt;Cooler Master N400 ATX Mid Tower Case&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;$93.98 @ Newegg&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Power Supply&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;a href=\"https://pcpartpicker.com/product/xQpmP6/thermaltake-smart-bm2-550-w-80-bronze-certified-semi-modular-atx-power-supply-ps-spd-0550mnfabu-1\"&gt;*Thermaltake Smart BM2 550 W 80+ Bronze Certified Semi-modular ATX Power Supply&lt;/a&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;$60.99 @ Amazon&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;em&gt;Prices include shipping, taxes, rebates, and discounts&lt;/em&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;Total&lt;/strong&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;strong&gt;$731.61&lt;/strong&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;*Lowest price parts chosen from parametric criteria&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;td align=\"left\"&gt;Generated by &lt;a href=\"https://pcpartpicker.com\"&gt;PCPartPicker&lt;/a&gt; 2023-06-07 14:17 EDT-0400&lt;/td&gt;\n&lt;td align=\"left\"&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143kpva", "is_robot_indexable": true, "report_reasons": null, "author": "xaocon", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143kpva/build_advicethoughts_for_future_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143kpva/build_advicethoughts_for_future_nas/", "subreddit_subscribers": 686575, "created_utc": 1686162041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How do I archive a mediawiki site with wget? I'm currently running `wget -mkxpKE --user-agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/114.0\" -e robots=off --reject=\"*Special:*\" --reject=\"*User:*\" [URL]` but I always end up with thousands of requests that look like this\n\n```\n2023-06-07 22:53:08 (9.92 MB/s) - \u2018diyhrt.cafe/index.php?title=Special:CreateAccount&amp;returnto=Main+Page&amp;returntoquery=oldid=843.tmp.html\u2019 saved [90731] \n\nRemoving diyhrt.cafe/index.php?title=Special:CreateAccount&amp;returnto=Main+Page&amp;returntoquery=oldid=843.tmp.html since it should be rejected.\n```\n\nIs it possible to skip all of these pages instead of downloading, then removing them? Is there a different tool I should be using?", "author_fullname": "t2_66jgtbcp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mediawiki with wget", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143rvwc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686179937.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686178718.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do I archive a mediawiki site with wget? I&amp;#39;m currently running &lt;code&gt;wget -mkxpKE --user-agent=&amp;quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/114.0&amp;quot; -e robots=off --reject=&amp;quot;*Special:*&amp;quot; --reject=&amp;quot;*User:*&amp;quot; [URL]&lt;/code&gt; but I always end up with thousands of requests that look like this&lt;/p&gt;\n\n&lt;p&gt;```\n2023-06-07 22:53:08 (9.92 MB/s) - \u2018diyhrt.cafe/index.php?title=Special:CreateAccount&amp;amp;returnto=Main+Page&amp;amp;returntoquery=oldid=843.tmp.html\u2019 saved [90731] &lt;/p&gt;\n\n&lt;p&gt;Removing diyhrt.cafe/index.php?title=Special:CreateAccount&amp;amp;returnto=Main+Page&amp;amp;returntoquery=oldid=843.tmp.html since it should be rejected.\n```&lt;/p&gt;\n\n&lt;p&gt;Is it possible to skip all of these pages instead of downloading, then removing them? Is there a different tool I should be using?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143rvwc", "is_robot_indexable": true, "report_reasons": null, "author": "uGoldfish", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143rvwc/mediawiki_with_wget/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143rvwc/mediawiki_with_wget/", "subreddit_subscribers": 686575, "created_utc": 1686178718.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was thinking of grabbing one of these with a 6500 Intel and installing  a sata card for all my drive in JBOD. I have 5 drives so far in asst sizes (3 are 2.5 and 2 are 3.5 drives)\n\nWill this motherboard w/16gb of ram run a  server for 2 people?\n\nWhat would the projected wattage draw be? Can i put all drives to sleep and only wake when requested? Better yet, can i put whole computer to sleep and wake when needed?", "author_fullname": "t2_lzwh7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HP ProDesk 600 G3 SFF motherboard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143r2iv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686176713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was thinking of grabbing one of these with a 6500 Intel and installing  a sata card for all my drive in JBOD. I have 5 drives so far in asst sizes (3 are 2.5 and 2 are 3.5 drives)&lt;/p&gt;\n\n&lt;p&gt;Will this motherboard w/16gb of ram run a  server for 2 people?&lt;/p&gt;\n\n&lt;p&gt;What would the projected wattage draw be? Can i put all drives to sleep and only wake when requested? Better yet, can i put whole computer to sleep and wake when needed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143r2iv", "is_robot_indexable": true, "report_reasons": null, "author": "cmdrmcgarrett", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143r2iv/hp_prodesk_600_g3_sff_motherboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143r2iv/hp_prodesk_600_g3_sff_motherboard/", "subreddit_subscribers": 686575, "created_utc": 1686176713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Title as it says. I found our old tapes recently, some we recorded and others we bought. I'd like to get all of them transfered, as some of the commercial tapes stick out in one way or another. I have a capture card and a RT5X, so I can rip them if I want, but I trust a service more since they probably have a cleaner way to rip them.", "author_fullname": "t2_1ghhtckn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do VHS Tranfer Companies Typically Transfer Commcercial Tapes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1444103", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.2, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686215129.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Title as it says. I found our old tapes recently, some we recorded and others we bought. I&amp;#39;d like to get all of them transfered, as some of the commercial tapes stick out in one way or another. I have a capture card and a RT5X, so I can rip them if I want, but I trust a service more since they probably have a cleaner way to rip them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1444103", "is_robot_indexable": true, "report_reasons": null, "author": "KevinPike87", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1444103/do_vhs_tranfer_companies_typically_transfer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1444103/do_vhs_tranfer_companies_typically_transfer/", "subreddit_subscribers": 686575, "created_utc": 1686215129.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I tried using google colab using some scripts that I've found online and I managed to transferred 80GB of files from my google drive to my mega account. But after that, it doesn't worked anymore, the error seems happening on Mega's end, or not sure if there are limitations or restrictions in using that?\n\nThere's another option I've found using rclone, but the problem with this is very slow and it using my internet bandwidth to transfer data (download and upload) compare to the scripts using google colab which transfer is happening from server to server (80GB took only 15min more or less).  \n\n\nAre there any other options out there? There are also paid services available but I'm not keen on availing that.", "author_fullname": "t2_8c5s3s58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud transfer Google Drive to Mega", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1443cuq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686212690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried using google colab using some scripts that I&amp;#39;ve found online and I managed to transferred 80GB of files from my google drive to my mega account. But after that, it doesn&amp;#39;t worked anymore, the error seems happening on Mega&amp;#39;s end, or not sure if there are limitations or restrictions in using that?&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s another option I&amp;#39;ve found using rclone, but the problem with this is very slow and it using my internet bandwidth to transfer data (download and upload) compare to the scripts using google colab which transfer is happening from server to server (80GB took only 15min more or less).  &lt;/p&gt;\n\n&lt;p&gt;Are there any other options out there? There are also paid services available but I&amp;#39;m not keen on availing that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1443cuq", "is_robot_indexable": true, "report_reasons": null, "author": "elryoma", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1443cuq/cloud_transfer_google_drive_to_mega/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1443cuq/cloud_transfer_google_drive_to_mega/", "subreddit_subscribers": 686575, "created_utc": 1686212690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Would love to get advice on using Dupeblocker to setup de-duplication rules on Salesforce!", "author_fullname": "t2_pim2ct6c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using Dupeblocker?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1441p2n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686206730.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would love to get advice on using Dupeblocker to setup de-duplication rules on Salesforce!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1441p2n", "is_robot_indexable": true, "report_reasons": null, "author": "SuccessfulDevice3493", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1441p2n/using_dupeblocker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1441p2n/using_dupeblocker/", "subreddit_subscribers": 686575, "created_utc": 1686206730.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "But can I run multiple dockers at the same time with 6 being the max downloads each", "author_fullname": "t2_l6hsy91", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So I know you can run Archive Team with 6 downloads in docker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143sjwj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686180345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;But can I run multiple dockers at the same time with 6 being the max downloads each&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "100TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143sjwj", "is_robot_indexable": true, "report_reasons": null, "author": "Jacksharkben", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/143sjwj/so_i_know_you_can_run_archive_team_with_6/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143sjwj/so_i_know_you_can_run_archive_team_with_6/", "subreddit_subscribers": 686575, "created_utc": 1686180345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using the admirable RedditScrape and reddit-save projects to download my own upvotes/saves, as well as individual subs.  What I'd like to do, though, is download all my friends' posts.  The /r/friends \"sub\" has all of that, but it shows up as an invalid sub in the scrape/save tools.  Does anyone know of a tool that does work for /r/friends?", "author_fullname": "t2_e9xgs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a tool for downloading all of friends' posts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143mg7o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686166109.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using the admirable RedditScrape and reddit-save projects to download my own upvotes/saves, as well as individual subs.  What I&amp;#39;d like to do, though, is download all my friends&amp;#39; posts.  The &lt;a href=\"/r/friends\"&gt;/r/friends&lt;/a&gt; &amp;quot;sub&amp;quot; has all of that, but it shows up as an invalid sub in the scrape/save tools.  Does anyone know of a tool that does work for &lt;a href=\"/r/friends\"&gt;/r/friends&lt;/a&gt;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143mg7o", "is_robot_indexable": true, "report_reasons": null, "author": "oozforashag", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143mg7o/is_there_a_tool_for_downloading_all_of_friends/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143mg7o/is_there_a_tool_for_downloading_all_of_friends/", "subreddit_subscribers": 686575, "created_utc": 1686166109.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i need help!\n\ni want to clone windows to a SSD without losing the already existing data in that ssd, is it possible? and how to do that\\*?", "author_fullname": "t2_a6onqhglm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "cloning without losing data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143kkxt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686161714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i need help!&lt;/p&gt;\n\n&lt;p&gt;i want to clone windows to a SSD without losing the already existing data in that ssd, is it possible? and how to do that*?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143kkxt", "is_robot_indexable": true, "report_reasons": null, "author": "ChickenTajine", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143kkxt/cloning_without_losing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143kkxt/cloning_without_losing_data/", "subreddit_subscribers": 686575, "created_utc": 1686161714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a large library of stuff gathered throughout the years. I have been paid to gather some elements for a company and Im going to be sending a lot of old stuff, as if I had just gathered it now. They are paying me to gather these, and I don\u00b4t think it would sit well if they see 80% of it is recycled.\n\n&amp;#x200B;\n\nI don\u00b4t want it to keep the \"date created\" and for it to show it\u00b4s actually from a year ago.\n\n&amp;#x200B;\n\nIf I paste these files in a new folder, will it appear that they were created on the day of the copy? If not, how about if I WeTransfer the files to myself and re-download them?\n\n&amp;#x200B;\n\nPlease help me out ! I know they won\u00b4t go using fancy softwares to detect the original date, but I don\u00b4t want it to appear on the files", "author_fullname": "t2_90me57qk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does sending a WeTransfer remove date of creation of files?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_143k206", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686160495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a large library of stuff gathered throughout the years. I have been paid to gather some elements for a company and Im going to be sending a lot of old stuff, as if I had just gathered it now. They are paying me to gather these, and I don\u00b4t think it would sit well if they see 80% of it is recycled.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I don\u00b4t want it to keep the &amp;quot;date created&amp;quot; and for it to show it\u00b4s actually from a year ago.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;If I paste these files in a new folder, will it appear that they were created on the day of the copy? If not, how about if I WeTransfer the files to myself and re-download them?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Please help me out ! I know they won\u00b4t go using fancy softwares to detect the original date, but I don\u00b4t want it to appear on the files&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "143k206", "is_robot_indexable": true, "report_reasons": null, "author": "Powerful-Employer-20", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/143k206/does_sending_a_wetransfer_remove_date_of_creation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/143k206/does_sending_a_wetransfer_remove_date_of_creation/", "subreddit_subscribers": 686575, "created_utc": 1686160495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Friend of mine is a PhD student and one backup option for her PhD thesis and data is Dropbox. She also has the Desktop app and the files are also stored locally. Now, she is a bit afraid of the case that all of a sudden Dropbox decides to close/ban her account. Would she still be able to at least access her local files?", "author_fullname": "t2_6qim215i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I still access my local Dropbox folder and files when Dropbox bans my account?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1443fae", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.13, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686212952.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Friend of mine is a PhD student and one backup option for her PhD thesis and data is Dropbox. She also has the Desktop app and the files are also stored locally. Now, she is a bit afraid of the case that all of a sudden Dropbox decides to close/ban her account. Would she still be able to at least access her local files?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1443fae", "is_robot_indexable": true, "report_reasons": null, "author": "polarbeer1307", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1443fae/can_i_still_access_my_local_dropbox_folder_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1443fae/can_i_still_access_my_local_dropbox_folder_and/", "subreddit_subscribers": 686575, "created_utc": 1686212952.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}