{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is something that's bothered me since I started my DS journey.  \n   \nI almost always use median over average to for comparisons because I've learned over the years that most data is skewed and not evenly disturbed. However, I feel like I'm the only person that does this....  even though basic stats teach to use median.  \n  \nThoughts?", "author_fullname": "t2_9p4skdeg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is it so common to use average/mean instead of median when most datasets are skewed and not evenly distributed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g557m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 161, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 161, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687444350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is something that&amp;#39;s bothered me since I started my DS journey.  &lt;/p&gt;\n\n&lt;p&gt;I almost always use median over average to for comparisons because I&amp;#39;ve learned over the years that most data is skewed and not evenly disturbed. However, I feel like I&amp;#39;m the only person that does this....  even though basic stats teach to use median.  &lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g557m", "is_robot_indexable": true, "report_reasons": null, "author": "startup_biz_36", "discussion_type": null, "num_comments": 118, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g557m/why_is_it_so_common_to_use_averagemean_instead_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g557m/why_is_it_so_common_to_use_averagemean_instead_of/", "subreddit_subscribers": 929432, "created_utc": 1687444350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was just on a store's website and switched over to Reddit and, when I did, there was an ad for the exact store I'd been looking at right there in my Reddit feed.\n\nI get that Google Ads can track me through Chrome and Facebook can track me with their app, but I don't have the Reddit app. I only ever visit it through a browser. How are they tracking my behavior on other websites?\n\nI am killing myself trying to get basic, reliable attribution in place for my clients, so I'm super curious how Reddit is pulling that off.\n\n*Edit: Alright, this was a stupid question.*", "author_fullname": "t2_bxdnw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELI5: How is Reddit tracking my behavior on other websites when I don't have the app? And how can I do that too?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g4r95", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687444105.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687443437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was just on a store&amp;#39;s website and switched over to Reddit and, when I did, there was an ad for the exact store I&amp;#39;d been looking at right there in my Reddit feed.&lt;/p&gt;\n\n&lt;p&gt;I get that Google Ads can track me through Chrome and Facebook can track me with their app, but I don&amp;#39;t have the Reddit app. I only ever visit it through a browser. How are they tracking my behavior on other websites?&lt;/p&gt;\n\n&lt;p&gt;I am killing myself trying to get basic, reliable attribution in place for my clients, so I&amp;#39;m super curious how Reddit is pulling that off.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Edit: Alright, this was a stupid question.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g4r95", "is_robot_indexable": true, "report_reasons": null, "author": "takenorinvalid", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g4r95/eli5_how_is_reddit_tracking_my_behavior_on_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g4r95/eli5_how_is_reddit_tracking_my_behavior_on_other/", "subreddit_subscribers": 929432, "created_utc": 1687443437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_kv54kocp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding Gradient Descent in Regression Before you dive into Neural Networks!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14gbbzi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6wVtQEvRoo6UZUqz3Tqo29kdd3DgRqSYd6FVhAEdaZU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687459399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@ilyasaoudata/you-should-understand-backpropagation-in-regression-before-diving-into-neural-networks-5e08d48d69e6", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?auto=webp&amp;v=enabled&amp;s=1fe9b3de72c85fc98d414b6fa25b20d3309342e7", "width": 699, "height": 393}, "resolutions": [{"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26ffc3355391683a428d3f4a57a1ae1e48d4db63", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eed54e80ca02f3ebe41b1c4cca5647cb81816d53", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33297d5ff4287de59cb9fd2bf47a64ba9dbe22dc", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2b103c6423dc869ed624d3a26762fa04f4fb39d", "width": 640, "height": 359}], "variants": {}, "id": "GEtK8rTmTJ9Gfqr6ofB3NKxdlBPmFKQDAxUO4HBYv_0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gbbzi", "is_robot_indexable": true, "report_reasons": null, "author": "AIandSTUFF", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gbbzi/understanding_gradient_descent_in_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@ilyasaoudata/you-should-understand-backpropagation-in-regression-before-diving-into-neural-networks-5e08d48d69e6", "subreddit_subscribers": 929432, "created_utc": 1687459399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I use ChatGPT a lot for getting code snippets and examples, especially for things like matplotlib where I mostly care about just getting the plot I want. I thought it might be nice to run that code right in ChatGPT to see the output and verify that it does what I want.\n\nI hope it may be helpful to others, too!\n\n[Here is the extension](https://chrome.google.com/webstore/detail/jpt/hhpkcgbmfdclebniepgkgnfmpbgijoaf)", "author_fullname": "t2_8fn70sz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a chrome extension that runs Python code in ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g7xn8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687487025.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687450982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use ChatGPT a lot for getting code snippets and examples, especially for things like matplotlib where I mostly care about just getting the plot I want. I thought it might be nice to run that code right in ChatGPT to see the output and verify that it does what I want.&lt;/p&gt;\n\n&lt;p&gt;I hope it may be helpful to others, too!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://chrome.google.com/webstore/detail/jpt/hhpkcgbmfdclebniepgkgnfmpbgijoaf\"&gt;Here is the extension&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zRLXytsXkAvondQg2jm8V5kwxKCVibE9ljSMnJvHCSE.jpg?auto=webp&amp;v=enabled&amp;s=06402b97b9b26da308c389030ab6494da6e8f36e", "width": 128, "height": 128}, "resolutions": [{"url": "https://external-preview.redd.it/zRLXytsXkAvondQg2jm8V5kwxKCVibE9ljSMnJvHCSE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4a18e2981ad62e200bc914369df4e06af57ac16f", "width": 108, "height": 108}], "variants": {}, "id": "J7xyO_09AUlVqVCQPbKxunwW_tcG77lglYyot720LJM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g7xn8", "is_robot_indexable": true, "report_reasons": null, "author": "latticepath", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g7xn8/i_made_a_chrome_extension_that_runs_python_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g7xn8/i_made_a_chrome_extension_that_runs_python_code/", "subreddit_subscribers": 929432, "created_utc": 1687450982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Context: I am effectively the only data scientist in my department, and I have been in this role for a year. It's my first data science position. \n\n\nGoal: Build a churn model with 80%+ accuracy and false negative rate under 25%. Ideally false positive rate under 10%.\n\n\nProblem: With everything I do, accuracy and F1/FNR appear to be inversely related. This made sense when I was working on statistical models, but now that I've been building neural nets, the same thing is happening, and I'm at a loss. The models appear to be critically underfit.\n\n\nData: (tabular) 27k records and 300 variables, 100 of which are not highly correlated so I have mostly only been using just those 100 variables. Data is already standardized and one-hot encoded. One class is 90% and one is 10%.\n\n\nThings I've tried:\n\n\n* increasing number of hidden layers (increases F1, decreases accuracy)\n\n\n* decreasing number of hidden layers (decreases F1, increases accuracy)\n\n\n* introducing class weights (increases F1, decreases accuracy)\n\n\n* oversampling the minority class (same results as above)\n\n\n* using all 300 variables (no significant change)\n\n\nThings I will try:\n\n\n* increase training samples from 27k to 50k (more than that is not really possible as data would be too old)\n\n\n* turn this into a probability problem rather than a classification problem with a softmax output layer\n\n\n* try a CNN or other type of network \n\n\nAny general pointers on where to go from here would be helpful. I already spent a couple of months on feature engineering and feel like I've exhausted the possibilities with my 300 variables, but I will revisit that if nothing else works. Everything I'm reading online says change the network topology and balance the dataset, but that hasn't worked yet, so I am stumped.\n\n\nMy best-performing model structure is an input later with 100 inputs, 4 hidden layers with 80, 60, 40, and 20 neurons (all using relu activation) and a sigmoid output layer. \n\n\nAny help is greatly appreciated.", "author_fullname": "t2_rswxz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pointers to reduce false negatives while not sacrificing accuracy in deep learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g56ho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687444441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I am effectively the only data scientist in my department, and I have been in this role for a year. It&amp;#39;s my first data science position. &lt;/p&gt;\n\n&lt;p&gt;Goal: Build a churn model with 80%+ accuracy and false negative rate under 25%. Ideally false positive rate under 10%.&lt;/p&gt;\n\n&lt;p&gt;Problem: With everything I do, accuracy and F1/FNR appear to be inversely related. This made sense when I was working on statistical models, but now that I&amp;#39;ve been building neural nets, the same thing is happening, and I&amp;#39;m at a loss. The models appear to be critically underfit.&lt;/p&gt;\n\n&lt;p&gt;Data: (tabular) 27k records and 300 variables, 100 of which are not highly correlated so I have mostly only been using just those 100 variables. Data is already standardized and one-hot encoded. One class is 90% and one is 10%.&lt;/p&gt;\n\n&lt;p&gt;Things I&amp;#39;ve tried:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;increasing number of hidden layers (increases F1, decreases accuracy)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;decreasing number of hidden layers (decreases F1, increases accuracy)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;introducing class weights (increases F1, decreases accuracy)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;oversampling the minority class (same results as above)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;using all 300 variables (no significant change)&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Things I will try:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;increase training samples from 27k to 50k (more than that is not really possible as data would be too old)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;turn this into a probability problem rather than a classification problem with a softmax output layer&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;try a CNN or other type of network &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any general pointers on where to go from here would be helpful. I already spent a couple of months on feature engineering and feel like I&amp;#39;ve exhausted the possibilities with my 300 variables, but I will revisit that if nothing else works. Everything I&amp;#39;m reading online says change the network topology and balance the dataset, but that hasn&amp;#39;t worked yet, so I am stumped.&lt;/p&gt;\n\n&lt;p&gt;My best-performing model structure is an input later with 100 inputs, 4 hidden layers with 80, 60, 40, and 20 neurons (all using relu activation) and a sigmoid output layer. &lt;/p&gt;\n\n&lt;p&gt;Any help is greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g56ho", "is_robot_indexable": true, "report_reasons": null, "author": "goatsnboots", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g56ho/pointers_to_reduce_false_negatives_while_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g56ho/pointers_to_reduce_false_negatives_while_not/", "subreddit_subscribers": 929432, "created_utc": 1687444441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work as a data science intern for a financial group that mostly deals with annuities. Let\u2019s say I have a dataframe with 170,000 observations. And each observation represents a financial professional that could prospectively sell our products. I have mostly categorical data on these financial professionals that was collected at insurance conferences. So I have collected all of the categorical variables that have a reasonable number of categories and not a lot of null values and am prepping them for insertion into kmodes. My question is regarding category distribution. Let\u2019s say I have a category that indicates whether or not the financial professional has preferences on receiving updates from our firm. And the categories are true and false. There are 134,346 true values, 30,348 false values, and 5411 null values. I can fill the null values with \u201cunknown\u201d or the mode of True. But does the uneven distribution of this category mean that this category is not useful to kmodes?", "author_fullname": "t2_7a9ejl0y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about kmodes\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g3e1f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687440013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a data science intern for a financial group that mostly deals with annuities. Let\u2019s say I have a dataframe with 170,000 observations. And each observation represents a financial professional that could prospectively sell our products. I have mostly categorical data on these financial professionals that was collected at insurance conferences. So I have collected all of the categorical variables that have a reasonable number of categories and not a lot of null values and am prepping them for insertion into kmodes. My question is regarding category distribution. Let\u2019s say I have a category that indicates whether or not the financial professional has preferences on receiving updates from our firm. And the categories are true and false. There are 134,346 true values, 30,348 false values, and 5411 null values. I can fill the null values with \u201cunknown\u201d or the mode of True. But does the uneven distribution of this category mean that this category is not useful to kmodes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g3e1f", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Condition560", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g3e1f/question_about_kmodes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g3e1f/question_about_kmodes/", "subreddit_subscribers": 929432, "created_utc": 1687440013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have two data sets and they both have the same column names. One of the data sets is an excel file and contains historical data up until April. The second data set is linked to a database but will only ever contain 6 rolling months' worth of data. I am appending the two datasets and removing duplicates in PowerBI Power Query. I'd like to prioritise the data from the live source, but also ensure that the data doesn't get lost.Eg. what will happen to May data in 14 months from now, since it is not in the current excel data set, and it will not be in the live data set? I'd like to ensure that May data doesn't disappear in 14 months' time?\n\nHow do I automate preservation of data in Excel file so it doesn\u2019t \"roll off\"", "author_fullname": "t2_sie27959", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to automate preservation of data so it doesn\u2019t \"roll off\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14fyeo0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687425066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two data sets and they both have the same column names. One of the data sets is an excel file and contains historical data up until April. The second data set is linked to a database but will only ever contain 6 rolling months&amp;#39; worth of data. I am appending the two datasets and removing duplicates in PowerBI Power Query. I&amp;#39;d like to prioritise the data from the live source, but also ensure that the data doesn&amp;#39;t get lost.Eg. what will happen to May data in 14 months from now, since it is not in the current excel data set, and it will not be in the live data set? I&amp;#39;d like to ensure that May data doesn&amp;#39;t disappear in 14 months&amp;#39; time?&lt;/p&gt;\n\n&lt;p&gt;How do I automate preservation of data in Excel file so it doesn\u2019t &amp;quot;roll off&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14fyeo0", "is_robot_indexable": true, "report_reasons": null, "author": "Acrobatic-Chapter959", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14fyeo0/how_to_automate_preservation_of_data_so_it_doesnt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14fyeo0/how_to_automate_preservation_of_data_so_it_doesnt/", "subreddit_subscribers": 929432, "created_utc": 1687425066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a data analyst, considering furthering my education to work in data science. I currently work for a very well established company that has absolutely atrocious data due to poor IT infrastructure. For example, a visitor will click a tab on their website but due to site latency, the click will be recorded 18 times. I spend all day controlling for messes like this on the reporting side, instead of doing actual real analysis, because the company will not pay for IT to fix the root cause of the problem. \n\nI know some data clean up is part of the field, but I don\u2019t want to spend the rest of my career dealing with this level of incompetence, and if that\u2019s going to be a big part of this job no matter where I go, I don\u2019t know if it\u2019s the right field for me. \n\nI don\u2019t know anyone else outside of my company who works in this kind of field, so can others weigh in here as to whether it\u2019s common to spend your day essentially functioning as a cheaper workaround to major IT issues like this?", "author_fullname": "t2_tepj9g73", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How common is it for data at an established company to be a complete disaster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14glots", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687485295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data analyst, considering furthering my education to work in data science. I currently work for a very well established company that has absolutely atrocious data due to poor IT infrastructure. For example, a visitor will click a tab on their website but due to site latency, the click will be recorded 18 times. I spend all day controlling for messes like this on the reporting side, instead of doing actual real analysis, because the company will not pay for IT to fix the root cause of the problem. &lt;/p&gt;\n\n&lt;p&gt;I know some data clean up is part of the field, but I don\u2019t want to spend the rest of my career dealing with this level of incompetence, and if that\u2019s going to be a big part of this job no matter where I go, I don\u2019t know if it\u2019s the right field for me. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t know anyone else outside of my company who works in this kind of field, so can others weigh in here as to whether it\u2019s common to spend your day essentially functioning as a cheaper workaround to major IT issues like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14glots", "is_robot_indexable": true, "report_reasons": null, "author": "ItsaShoreThing1", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14glots/how_common_is_it_for_data_at_an_established/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14glots/how_common_is_it_for_data_at_an_established/", "subreddit_subscribers": 929432, "created_utc": 1687485295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I read a bit of a thesis paper discussing the idea that using PCA to pre-whiten before ICA should not include any form of principle component reduction due to the appearance of \"eiganspecters\" which they identify as artifacts that appear as a result of the aforementioned reduction. I haven't seen much discussion on this so I wanted to ask what you all thought about this in particular. The thesis is below: \n\n[https://ourarchive.otago.ac.nz/handle/10523/4459](https://ourarchive.otago.ac.nz/handle/10523/4459)\n\n&amp;#x200B;", "author_fullname": "t2_l0f5k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are eiganspecters an actual issue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gkzw6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687483346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read a bit of a thesis paper discussing the idea that using PCA to pre-whiten before ICA should not include any form of principle component reduction due to the appearance of &amp;quot;eiganspecters&amp;quot; which they identify as artifacts that appear as a result of the aforementioned reduction. I haven&amp;#39;t seen much discussion on this so I wanted to ask what you all thought about this in particular. The thesis is below: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ourarchive.otago.ac.nz/handle/10523/4459\"&gt;https://ourarchive.otago.ac.nz/handle/10523/4459&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gkzw6", "is_robot_indexable": true, "report_reasons": null, "author": "figgedy1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gkzw6/are_eiganspecters_an_actual_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gkzw6/are_eiganspecters_an_actual_issue/", "subreddit_subscribers": 929432, "created_utc": 1687483346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI\u2019m an incoming graduate student getting my masters in DS. My program offers a few specializations: \n1. Analytics and Modeling (focuses on predictive modeling) \n2. Analytics Management (focuses on business operations) \n3. Artificial Intelligence \n4. Data Engineering \n\nI was wondering given the job market, which specialization should I choose to be exposed to the most job opportunities?", "author_fullname": "t2_diaem5eh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Specialization for MSDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gksyf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687482821.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m an incoming graduate student getting my masters in DS. My program offers a few specializations: \n1. Analytics and Modeling (focuses on predictive modeling) \n2. Analytics Management (focuses on business operations) \n3. Artificial Intelligence \n4. Data Engineering &lt;/p&gt;\n\n&lt;p&gt;I was wondering given the job market, which specialization should I choose to be exposed to the most job opportunities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gksyf", "is_robot_indexable": true, "report_reasons": null, "author": "eggsbaconcheeze", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gksyf/specialization_for_msds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gksyf/specialization_for_msds/", "subreddit_subscribers": 929432, "created_utc": 1687482821.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know how to read code. I can write scripts. I am just slow as shit. I have been using GPT4 for data science lately. I am able to iterate through to create a full massive set of code within 1-2 hours which would have taken me 10 hours to write. I just used it to create a code to create about 600  individualized 20 page reports. It worked it was accurate. I am able to catch when it messes up, and I am able to redirect it or tell it to get it's shit together.\n\n Everyone in my dept acknowledges that my productivity has soared and they are even talking about promoting me. GPT4 is a crutch, but it's also enabling me to get through so much. It also helps me structure my thoughts. Like I have an analysis in mind and I write down the analysis and tell it to structure the plan around the analysis and it gives me where I should start and when I should stop.\n\nDoes this make me less of a data scientist? Am I less qualified?", "author_fullname": "t2_kw1h2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Slow coder, reliant on GPT4. Am I doomed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gjebh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687478838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know how to read code. I can write scripts. I am just slow as shit. I have been using GPT4 for data science lately. I am able to iterate through to create a full massive set of code within 1-2 hours which would have taken me 10 hours to write. I just used it to create a code to create about 600  individualized 20 page reports. It worked it was accurate. I am able to catch when it messes up, and I am able to redirect it or tell it to get it&amp;#39;s shit together.&lt;/p&gt;\n\n&lt;p&gt;Everyone in my dept acknowledges that my productivity has soared and they are even talking about promoting me. GPT4 is a crutch, but it&amp;#39;s also enabling me to get through so much. It also helps me structure my thoughts. Like I have an analysis in mind and I write down the analysis and tell it to structure the plan around the analysis and it gives me where I should start and when I should stop.&lt;/p&gt;\n\n&lt;p&gt;Does this make me less of a data scientist? Am I less qualified?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gjebh", "is_robot_indexable": true, "report_reasons": null, "author": "frescoj10", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gjebh/slow_coder_reliant_on_gpt4_am_i_doomed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gjebh/slow_coder_reliant_on_gpt4_am_i_doomed/", "subreddit_subscribers": 929432, "created_utc": 1687478838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\nI'm working on a project with a common kaggle dataset, trying to use a random forest to predict a binary feature from ~20 binary, numerical and one categorical variable with 3 ordinal categories.\nTarget variable is pretty balanced, but one particular binary predictor and the 3-level categorical variable are kinda imbalanced, 80-20 % and 45-10-45 %, respectively.\nWhat is the impact of this imbalance? If I were to train my data on this set, would the model be negatively affected? Note that the dataset is pretty large, we're talking 100k observations for the training set alone. Is there need to resample my dataset?\n\n---Dumbly Afraid To Ask", "author_fullname": "t2_2p4jjqle", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imbalance in predictors: what to do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gg47c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687470489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nI&amp;#39;m working on a project with a common kaggle dataset, trying to use a random forest to predict a binary feature from ~20 binary, numerical and one categorical variable with 3 ordinal categories.\nTarget variable is pretty balanced, but one particular binary predictor and the 3-level categorical variable are kinda imbalanced, 80-20 % and 45-10-45 %, respectively.\nWhat is the impact of this imbalance? If I were to train my data on this set, would the model be negatively affected? Note that the dataset is pretty large, we&amp;#39;re talking 100k observations for the training set alone. Is there need to resample my dataset?&lt;/p&gt;\n\n&lt;p&gt;---Dumbly Afraid To Ask&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gg47c", "is_robot_indexable": true, "report_reasons": null, "author": "aceofmaz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gg47c/imbalance_in_predictors_what_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gg47c/imbalance_in_predictors_what_to_do/", "subreddit_subscribers": 929432, "created_utc": 1687470489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "That are **not**, I repeat **not** written by Taleb.", "author_fullname": "t2_ad5yokml", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for recommended readings/lectures/materials on extreme value theory, and risk in data science.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gctgp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687462874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;That are &lt;strong&gt;not&lt;/strong&gt;, I repeat &lt;strong&gt;not&lt;/strong&gt; written by Taleb.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gctgp", "is_robot_indexable": true, "report_reasons": null, "author": "antichain", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gctgp/looking_for_recommended_readingslecturesmaterials/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gctgp/looking_for_recommended_readingslecturesmaterials/", "subreddit_subscribers": 929432, "created_utc": 1687462874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys. \nTLDR: I have an image classification problem for fraud detection. But the thing is, my targets for images are not correct(&gt;50%) times. How should I go about it? Any suggestions to read/explore about things.\n\nLong read below:\nThe use case is for identifying frauds. In a certain setup, an agency is required to build some public assets - like ponds, houses, dams, roads etc.  And the agency is required to submit photos as proof. So we are kind of checker, want to build a model that should flag when photo is suspicious, not of right category . One approach is to classify the image, and if the model predicted category is different then we can flag. We are going with this one for now. So for this approach we need Labelled dataset. We have million of images that have been uploaded so far , but our image, category pair may not be correct  in case there have been frauds. And frauds percentage is upto 60-70%. So you see our label is kind of noisy.\n\nSo which approaches are out there for learning from noisy labels? Some sort of Self supervised learning, or other learning paradigm is what I could think of.\n\nThanks.", "author_fullname": "t2_9yo5phby", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Image classification with noisy labels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g8i0k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687452813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. \nTLDR: I have an image classification problem for fraud detection. But the thing is, my targets for images are not correct(&amp;gt;50%) times. How should I go about it? Any suggestions to read/explore about things.&lt;/p&gt;\n\n&lt;p&gt;Long read below:\nThe use case is for identifying frauds. In a certain setup, an agency is required to build some public assets - like ponds, houses, dams, roads etc.  And the agency is required to submit photos as proof. So we are kind of checker, want to build a model that should flag when photo is suspicious, not of right category . One approach is to classify the image, and if the model predicted category is different then we can flag. We are going with this one for now. So for this approach we need Labelled dataset. We have million of images that have been uploaded so far , but our image, category pair may not be correct  in case there have been frauds. And frauds percentage is upto 60-70%. So you see our label is kind of noisy.&lt;/p&gt;\n\n&lt;p&gt;So which approaches are out there for learning from noisy labels? Some sort of Self supervised learning, or other learning paradigm is what I could think of.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g8i0k", "is_robot_indexable": true, "report_reasons": null, "author": "EducatorDiligent5114", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g8i0k/image_classification_with_noisy_labels/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g8i0k/image_classification_with_noisy_labels/", "subreddit_subscribers": 929432, "created_utc": 1687452813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone!\n\nI hope you're all doing well. I wanted to reach out to those of you who have worked or are currently working as interns in product-based companies. I have a couple of questions and would greatly appreciate your insights and experiences.\n\nThank you so much in advance! Looking forward to your responses and discussions", "author_fullname": "t2_7w8cmdht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interning at Product-Based Companies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g7z1b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687451084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all doing well. I wanted to reach out to those of you who have worked or are currently working as interns in product-based companies. I have a couple of questions and would greatly appreciate your insights and experiences.&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance! Looking forward to your responses and discussions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g7z1b", "is_robot_indexable": true, "report_reasons": null, "author": "Batman_bruce_wayne0", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g7z1b/interning_at_productbased_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g7z1b/interning_at_productbased_companies/", "subreddit_subscribers": 929432, "created_utc": 1687451084.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My team has created a few webhooks into data tools like Datadog, Sentry, AWS etc. We don't personally use these tools, but need a way to test the success/failure of the webhooks. Does anyone know of any way to test these webhooks without our own account? Snyk offers a Postman testing solution but I haven't seen any other methods. There are a ton of tools in this space (Hex, Mode, Equals etc) so there has to be a solution i'm missing!", "author_fullname": "t2_g400fo1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing Webhook connection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g6ipk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687447635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team has created a few webhooks into data tools like Datadog, Sentry, AWS etc. We don&amp;#39;t personally use these tools, but need a way to test the success/failure of the webhooks. Does anyone know of any way to test these webhooks without our own account? Snyk offers a Postman testing solution but I haven&amp;#39;t seen any other methods. There are a ton of tools in this space (Hex, Mode, Equals etc) so there has to be a solution i&amp;#39;m missing!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g6ipk", "is_robot_indexable": true, "report_reasons": null, "author": "rmilaz18", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g6ipk/testing_webhook_connection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g6ipk/testing_webhook_connection/", "subreddit_subscribers": 929432, "created_utc": 1687447635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, i'm a fresh data science graduate, i applied to a job that states data engineer, but i was surprised on the interview invitation that it's a data officer role,\n\ni have never studied or worked in such area, nor there's enough information online to read, i don't know what the hell they gonna ask me on the interview, i was thinking of backing off, but it looks like a very big company , plus, i need the experience in this stage,\n\nthe interview is in 3 days\n\nis that enough to learn about this? and if yes, can you guys suggest any good sources about this? a last question, it might sound dumb, but, is it harder than other data science roles (analyst, administrator, engineer )?", "author_fullname": "t2_55642ldz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data officer job interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gjldo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687479390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, i&amp;#39;m a fresh data science graduate, i applied to a job that states data engineer, but i was surprised on the interview invitation that it&amp;#39;s a data officer role,&lt;/p&gt;\n\n&lt;p&gt;i have never studied or worked in such area, nor there&amp;#39;s enough information online to read, i don&amp;#39;t know what the hell they gonna ask me on the interview, i was thinking of backing off, but it looks like a very big company , plus, i need the experience in this stage,&lt;/p&gt;\n\n&lt;p&gt;the interview is in 3 days&lt;/p&gt;\n\n&lt;p&gt;is that enough to learn about this? and if yes, can you guys suggest any good sources about this? a last question, it might sound dumb, but, is it harder than other data science roles (analyst, administrator, engineer )?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gjldo", "is_robot_indexable": true, "report_reasons": null, "author": "ARA-GOD", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gjldo/data_officer_job_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gjldo/data_officer_job_interview/", "subreddit_subscribers": 929432, "created_utc": 1687479390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "The one in the link. It can be from a previous year: \n\n[Liveability Data | The Economist Intelligence Unit (eiu.com)](https://store.eiu.com/product/global-liveability-matrix/) \n\n&amp;#x200B;", "author_fullname": "t2_c8nsowrc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone know how I can get the Economist Livability Index full data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ggdeh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687471097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The one in the link. It can be from a previous year: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://store.eiu.com/product/global-liveability-matrix/\"&gt;Liveability Data | The Economist Intelligence Unit (eiu.com)&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ggdeh", "is_robot_indexable": true, "report_reasons": null, "author": "TristanMoreno_Tuc", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ggdeh/does_anyone_know_how_i_can_get_the_economist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ggdeh/does_anyone_know_how_i_can_get_the_economist/", "subreddit_subscribers": 929432, "created_utc": 1687471097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I\u2019m new to data science and I\u2019m working in a kaggle notebook. I\u2019m trying to sort aggregated data in a data frame. In convert the column to a category and then sort. The sorting works fine, but then I lose all aggregated data. I can send the code snippet in a bit, if anyone is willing to help or knows the best place to go to help. \n\nFYI: Chatgpt, stackoverflow, Google and a few hours of different methods and yet no solutions. :/\n\nI should say I\u2019m sorting by the column and row level values in the column. In sql it would be an order by case column name when x then 1 when y then 2 etc.\n\nHere\u2019s one of the iterations of my script. I accidentally deleted the other one. :/ \n\ndf2=df.groupby([\u2018colname\u2019,\u2019col2\u2019])[col3].mean().unstack.fillna(0)\n\ndf3= df2.sort_values(by = [\u2018val1\u2019,\u2019val2\u2019,\u2019val3\u2019])\n\ndf3", "author_fullname": "t2_91slmnig", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g9zxt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687458463.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687456281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I\u2019m new to data science and I\u2019m working in a kaggle notebook. I\u2019m trying to sort aggregated data in a data frame. In convert the column to a category and then sort. The sorting works fine, but then I lose all aggregated data. I can send the code snippet in a bit, if anyone is willing to help or knows the best place to go to help. &lt;/p&gt;\n\n&lt;p&gt;FYI: Chatgpt, stackoverflow, Google and a few hours of different methods and yet no solutions. :/&lt;/p&gt;\n\n&lt;p&gt;I should say I\u2019m sorting by the column and row level values in the column. In sql it would be an order by case column name when x then 1 when y then 2 etc.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s one of the iterations of my script. I accidentally deleted the other one. :/ &lt;/p&gt;\n\n&lt;p&gt;df2=df.groupby([\u2018colname\u2019,\u2019col2\u2019])[col3].mean().unstack.fillna(0)&lt;/p&gt;\n\n&lt;p&gt;df3= df2.sort_values(by = [\u2018val1\u2019,\u2019val2\u2019,\u2019val3\u2019])&lt;/p&gt;\n\n&lt;p&gt;df3&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g9zxt", "is_robot_indexable": true, "report_reasons": null, "author": "Adept_Car_9997", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g9zxt/new_to_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g9zxt/new_to_data_science/", "subreddit_subscribers": 929432, "created_utc": 1687456281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello All, \n\nI am new to this Sub. I am working as a BI developer for long time. I am also having certification/experience in AWS, Python, Dev-ops technologies. I am planning to take MS in Data science in Bellevue University via employer sponsorship. Did any one is having experience with this program with Bellevue?   Thanks ", "author_fullname": "t2_396ytpa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bellevue MS in Data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g7xhv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687450971.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All, &lt;/p&gt;\n\n&lt;p&gt;I am new to this Sub. I am working as a BI developer for long time. I am also having certification/experience in AWS, Python, Dev-ops technologies. I am planning to take MS in Data science in Bellevue University via employer sponsorship. Did any one is having experience with this program with Bellevue?   Thanks &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g7xhv", "is_robot_indexable": true, "report_reasons": null, "author": "surensail54", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g7xhv/bellevue_ms_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g7xhv/bellevue_ms_in_data_science/", "subreddit_subscribers": 929432, "created_utc": 1687450971.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a non-US resident who has been working as a contractor for US companies for just under a year. I was laid off during the massive layoffs at the end of April. Since then, I have found it difficult to secure a remote Data Scientist position in the US as a contractor (currently residing in Latin America).\n\n1) Most US non-residents open positions I have found are only US-remote (for US residents), or for Data Engineers, heavy MLE roles, or Sofware Developers with React/Node.js. Is that right or am I looking in the wrong place?\n\n2) I am wondering if it's my CV/profile or if it's the US market for contractors/non-US residents. Are there any hiring managers who can provide their opinions? \n\n3) Given my profile, what do you recommend me to work with looking into the future? If it's MLOps, could you give a small path/guideline?\n\nHere is a summary of my profile: \n\n**Strengths**:\n\n* Over 4 years of experience in designing and developing end-to-end ML models, with a total of 5 years in Data Analytics-related roles.\n* My undergraduate degree combines backgrounds in Engineering and Business Administration. To fill in some gaps in statistics, I completed the MicroMasters in Statistics and Data Science from MIT (highly recommended if you lack a stats background, but you need good maths background).\n* My specialization lies in defining and transforming business problems into machine-learning solutions.\n* I excel at explaining technical concepts to non-technical stakeholders. I have received positive feedback on how easy it is to follow my presentations, showcasing my thinking and decision process while developing an ML model and receiving and including input from non-technical folks.\n* I have experience coaching junior Data Scientists/Analysts from both technical and business applications perspectives, teaching them how to identify and solve business opportunities/problems using ML.\n* Most of my projects have involved tree-based models, as they are easier to explain to non-technical stakeholders and convince them to use/adopt the final ML model. I also have experience with time-series analysis, Reinforcement Learning/Hidden Markov Models, and a bit with recommendation systems.\n* I have worked in the insurance, banking, advertising, retail, and aeronautics industries.\n* I am proficient in English, Spanish, and Portuguese.\n* I get things done. This is the stuff I most like about Data Science: Sometimes I will face a business problem where I don't have the answer so I go into research for a good solution proposal.\n\n**Weaknesses**:\n\n* I do not possess a Master's or PhD degree (The MicroMasters from MIT I don't think counts as a full-master degree)\n* non-US resident? does it affect me even as a contractor? (Because I don't require a VISA to work as a contractor)\n* I have below-average experience using cloud platforms, with only one year of experience using GCP. Consequently, I am pursuing the Data Scientist Associate Certificate from Azure (DP-100).\n* Never used Spark/Hadoop or any kind of distributed computing/storage.\n* Although I have no direct experience with NLP, deep neural networks, or Computer Vision, I have achieved top-three rankings in internal NLP competitions (but it was three years ago). Additionally, I have developed an application using Chat GPT (utilizing the OpenAI API) to optimize business processes.\n* I have limited knowledge of MLE. In instances where I have deployed a model, I have typically relied on the support of an MLE. I have been attempting to gain a better understanding of this field, but the multitude of tools available often overwhelms me, and it is very challenging to gain practical experience. I feel that studying without practice is a waste of time, especially considering the multitude of tools available for various MLE problems. It becomes even more challenging when different companies utilize and demand distinct sets of tools for the same MLE problem. Any guidelines to kill this weakness?\n\n&amp;#x200B;", "author_fullname": "t2_3vzap1d5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Applications for Non-US Residents? Mostly DE/MLE and SD with React/Node.js", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g4d7b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687442487.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a non-US resident who has been working as a contractor for US companies for just under a year. I was laid off during the massive layoffs at the end of April. Since then, I have found it difficult to secure a remote Data Scientist position in the US as a contractor (currently residing in Latin America).&lt;/p&gt;\n\n&lt;p&gt;1) Most US non-residents open positions I have found are only US-remote (for US residents), or for Data Engineers, heavy MLE roles, or Sofware Developers with React/Node.js. Is that right or am I looking in the wrong place?&lt;/p&gt;\n\n&lt;p&gt;2) I am wondering if it&amp;#39;s my CV/profile or if it&amp;#39;s the US market for contractors/non-US residents. Are there any hiring managers who can provide their opinions? &lt;/p&gt;\n\n&lt;p&gt;3) Given my profile, what do you recommend me to work with looking into the future? If it&amp;#39;s MLOps, could you give a small path/guideline?&lt;/p&gt;\n\n&lt;p&gt;Here is a summary of my profile: &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Strengths&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Over 4 years of experience in designing and developing end-to-end ML models, with a total of 5 years in Data Analytics-related roles.&lt;/li&gt;\n&lt;li&gt;My undergraduate degree combines backgrounds in Engineering and Business Administration. To fill in some gaps in statistics, I completed the MicroMasters in Statistics and Data Science from MIT (highly recommended if you lack a stats background, but you need good maths background).&lt;/li&gt;\n&lt;li&gt;My specialization lies in defining and transforming business problems into machine-learning solutions.&lt;/li&gt;\n&lt;li&gt;I excel at explaining technical concepts to non-technical stakeholders. I have received positive feedback on how easy it is to follow my presentations, showcasing my thinking and decision process while developing an ML model and receiving and including input from non-technical folks.&lt;/li&gt;\n&lt;li&gt;I have experience coaching junior Data Scientists/Analysts from both technical and business applications perspectives, teaching them how to identify and solve business opportunities/problems using ML.&lt;/li&gt;\n&lt;li&gt;Most of my projects have involved tree-based models, as they are easier to explain to non-technical stakeholders and convince them to use/adopt the final ML model. I also have experience with time-series analysis, Reinforcement Learning/Hidden Markov Models, and a bit with recommendation systems.&lt;/li&gt;\n&lt;li&gt;I have worked in the insurance, banking, advertising, retail, and aeronautics industries.&lt;/li&gt;\n&lt;li&gt;I am proficient in English, Spanish, and Portuguese.&lt;/li&gt;\n&lt;li&gt;I get things done. This is the stuff I most like about Data Science: Sometimes I will face a business problem where I don&amp;#39;t have the answer so I go into research for a good solution proposal.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Weaknesses&lt;/strong&gt;:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;I do not possess a Master&amp;#39;s or PhD degree (The MicroMasters from MIT I don&amp;#39;t think counts as a full-master degree)&lt;/li&gt;\n&lt;li&gt;non-US resident? does it affect me even as a contractor? (Because I don&amp;#39;t require a VISA to work as a contractor)&lt;/li&gt;\n&lt;li&gt;I have below-average experience using cloud platforms, with only one year of experience using GCP. Consequently, I am pursuing the Data Scientist Associate Certificate from Azure (DP-100).&lt;/li&gt;\n&lt;li&gt;Never used Spark/Hadoop or any kind of distributed computing/storage.&lt;/li&gt;\n&lt;li&gt;Although I have no direct experience with NLP, deep neural networks, or Computer Vision, I have achieved top-three rankings in internal NLP competitions (but it was three years ago). Additionally, I have developed an application using Chat GPT (utilizing the OpenAI API) to optimize business processes.&lt;/li&gt;\n&lt;li&gt;I have limited knowledge of MLE. In instances where I have deployed a model, I have typically relied on the support of an MLE. I have been attempting to gain a better understanding of this field, but the multitude of tools available often overwhelms me, and it is very challenging to gain practical experience. I feel that studying without practice is a waste of time, especially considering the multitude of tools available for various MLE problems. It becomes even more challenging when different companies utilize and demand distinct sets of tools for the same MLE problem. Any guidelines to kill this weakness?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g4d7b", "is_robot_indexable": true, "report_reasons": null, "author": "conlake", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g4d7b/data_science_applications_for_nonus_residents/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g4d7b/data_science_applications_for_nonus_residents/", "subreddit_subscribers": 929432, "created_utc": 1687442487.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}