{"kind": "Listing", "data": {"after": "t3_14gjldo", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a data analyst, considering furthering my education to work in data science. I currently work for a very well established company that has absolutely atrocious data due to poor IT infrastructure. For example, a visitor will click a tab on their website but due to site latency, the click will be recorded 18 times. I spend all day controlling for messes like this on the reporting side, instead of doing actual real analysis, because the company will not pay for IT to fix the root cause of the problem. \n\nI know some data clean up is part of the field, but I don\u2019t want to spend the rest of my career dealing with this level of incompetence, and if that\u2019s going to be a big part of this job no matter where I go, I don\u2019t know if it\u2019s the right field for me. \n\nI don\u2019t know anyone else outside of my company who works in this kind of field, so can others weigh in here as to whether it\u2019s common to spend your day essentially functioning as a cheaper workaround to major IT issues like this?", "author_fullname": "t2_tepj9g73", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How common is it for data at an established company to be a complete disaster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14glots", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 241, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 241, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687485295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data analyst, considering furthering my education to work in data science. I currently work for a very well established company that has absolutely atrocious data due to poor IT infrastructure. For example, a visitor will click a tab on their website but due to site latency, the click will be recorded 18 times. I spend all day controlling for messes like this on the reporting side, instead of doing actual real analysis, because the company will not pay for IT to fix the root cause of the problem. &lt;/p&gt;\n\n&lt;p&gt;I know some data clean up is part of the field, but I don\u2019t want to spend the rest of my career dealing with this level of incompetence, and if that\u2019s going to be a big part of this job no matter where I go, I don\u2019t know if it\u2019s the right field for me. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t know anyone else outside of my company who works in this kind of field, so can others weigh in here as to whether it\u2019s common to spend your day essentially functioning as a cheaper workaround to major IT issues like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14glots", "is_robot_indexable": true, "report_reasons": null, "author": "ItsaShoreThing1", "discussion_type": null, "num_comments": 159, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14glots/how_common_is_it_for_data_at_an_established/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14glots/how_common_is_it_for_data_at_an_established/", "subreddit_subscribers": 930002, "created_utc": 1687485295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_131vu3d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ryxcommar's tweet thread on why 2023 is a bad year to bootcamp your way to a data science job.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14h4gqy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": "", "ups": 72, "total_awards_received": 0, "media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;&amp;quot;OK so what should I do if I want a data scientist job&amp;quot;. you have a few options. pick one or more out of the following:&lt;br&gt;&lt;br&gt;- start as a data analyst, BI analyst, or consultant&lt;br&gt;- get a STEM degree&lt;br&gt;- get a masters or PhD&lt;br&gt;- do code side projects and build a portfolio&lt;br&gt;- study &lt;a href=\"https://t.co/nT7KnN67PD\"&gt;https://t.co/nT7KnN67PD&lt;/a&gt;&lt;/p&gt;&amp;mdash; Senior PowerPoint Engineer (@ryxcommar) &lt;a href=\"https://twitter.com/ryxcommar/status/1672265739527417865?ref_src=twsrc%5Etfw\"&gt;June 23, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/ryxcommar/status/1672265739527417865", "author_name": "Senior PowerPoint Engineer", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;&amp;quot;OK so what should I do if I want a data scientist job&amp;quot;. you have a few options. pick one or more out of the following:&lt;br&gt;&lt;br&gt;- start as a data analyst, BI analyst, or consultant&lt;br&gt;- get a STEM degree&lt;br&gt;- get a masters or PhD&lt;br&gt;- do code side projects and build a portfolio&lt;br&gt;- study &lt;a href=\"https://t.co/nT7KnN67PD\"&gt;https://t.co/nT7KnN67PD&lt;/a&gt;&lt;/p&gt;&amp;mdash; Senior PowerPoint Engineer (@ryxcommar) &lt;a href=\"https://twitter.com/ryxcommar/status/1672265739527417865?ref_src=twsrc%5Etfw\"&gt;June 23, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/ryxcommar", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;&amp;quot;OK so what should I do if I want a data scientist job&amp;quot;. you have a few options. pick one or more out of the following:&lt;br&gt;&lt;br&gt;- start as a data analyst, BI analyst, or consultant&lt;br&gt;- get a STEM degree&lt;br&gt;- get a masters or PhD&lt;br&gt;- do code side projects and build a portfolio&lt;br&gt;- study &lt;a href=\"https://t.co/nT7KnN67PD\"&gt;https://t.co/nT7KnN67PD&lt;/a&gt;&lt;/p&gt;&amp;mdash; Senior PowerPoint Engineer (@ryxcommar) &lt;a href=\"https://twitter.com/ryxcommar/status/1672265739527417865?ref_src=twsrc%5Etfw\"&gt;June 23, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "width": 350, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/14h4gqy", "height": 200}, "link_flair_text": "Career", "can_mod_post": false, "score": 72, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/CdhYxgv1vv6in4koN6HHANoro5H5vteTMdzx-fgT874.jpg", "edited": false, "author_flair_css_class": "modflair", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687541313.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "twitter.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://twitter.com/ryxcommar/status/1672265739527417865", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dIiKWoknZVqi_GQxjHi3vZ201DjTJpmdzbdqIjkIDt4.jpg?auto=webp&amp;v=enabled&amp;s=a06f61254d6624c8b30f40ecb6cf58d89aec2318", "width": 140, "height": 140}, "resolutions": [{"url": "https://external-preview.redd.it/dIiKWoknZVqi_GQxjHi3vZ201DjTJpmdzbdqIjkIDt4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e9588f75aec5af73edffcd811f563795a506bf25", "width": 108, "height": 108}], "variants": {}, "id": "TuDwyI8_m7Pg6t7qbs8_q4qdw-4t50c_SanYJOq9bEg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14h4gqy", "is_robot_indexable": true, "report_reasons": null, "author": "__compactsupport__", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/14h4gqy/ryxcommars_tweet_thread_on_why_2023_is_a_bad_year/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://twitter.com/ryxcommar/status/1672265739527417865", "subreddit_subscribers": 930002, "created_utc": 1687541313.0, "num_crossposts": 0, "media": {"type": "twitter.com", "oembed": {"provider_url": "https://twitter.com", "version": "1.0", "url": "https://twitter.com/ryxcommar/status/1672265739527417865", "author_name": "Senior PowerPoint Engineer", "height": null, "width": 350, "html": "&lt;blockquote class=\"twitter-video\"&gt;&lt;p lang=\"en\" dir=\"ltr\"&gt;&amp;quot;OK so what should I do if I want a data scientist job&amp;quot;. you have a few options. pick one or more out of the following:&lt;br&gt;&lt;br&gt;- start as a data analyst, BI analyst, or consultant&lt;br&gt;- get a STEM degree&lt;br&gt;- get a masters or PhD&lt;br&gt;- do code side projects and build a portfolio&lt;br&gt;- study &lt;a href=\"https://t.co/nT7KnN67PD\"&gt;https://t.co/nT7KnN67PD&lt;/a&gt;&lt;/p&gt;&amp;mdash; Senior PowerPoint Engineer (@ryxcommar) &lt;a href=\"https://twitter.com/ryxcommar/status/1672265739527417865?ref_src=twsrc%5Etfw\"&gt;June 23, 2023&lt;/a&gt;&lt;/blockquote&gt;\n&lt;script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n", "author_url": "https://twitter.com/ryxcommar", "provider_name": "Twitter", "cache_age": 3153600000, "type": "rich"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a data scientist, at least that\u2019s what my job title says. In my company I have worked on traditional ML modelling, building vision models on azure and also some big data stuff using kafka, graph db. I don\u2019t know what skills/ expertise do I need to have to work at these large tech companies or earn high salary.\nSometimes it feels like I can do any type of work thrown at me but other times I still feel incomplete in my ds, ml skills.", "author_fullname": "t2_ifsmh8cn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of different work do highly paid data scientists and ML engineers do than those with low to medium salaries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gnnmq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687491058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data scientist, at least that\u2019s what my job title says. In my company I have worked on traditional ML modelling, building vision models on azure and also some big data stuff using kafka, graph db. I don\u2019t know what skills/ expertise do I need to have to work at these large tech companies or earn high salary.\nSometimes it feels like I can do any type of work thrown at me but other times I still feel incomplete in my ds, ml skills.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gnnmq", "is_robot_indexable": true, "report_reasons": null, "author": "Quest_to_peace", "discussion_type": null, "num_comments": 72, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gnnmq/what_kind_of_different_work_do_highly_paid_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gnnmq/what_kind_of_different_work_do_highly_paid_data/", "subreddit_subscribers": 930002, "created_utc": 1687491058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If yes, what tricks do you have to make it work smoothly? I had to resolve some conflicts in an notebook once and it was an awful experience\u2026", "author_fullname": "t2_ze1nira", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you git commit jupyter notebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gra17", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687502982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If yes, what tricks do you have to make it work smoothly? I had to resolve some conflicts in an notebook once and it was an awful experience\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gra17", "is_robot_indexable": true, "report_reasons": null, "author": "old_enough_to_drink", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gra17/do_you_git_commit_jupyter_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gra17/do_you_git_commit_jupyter_notebooks/", "subreddit_subscribers": 930002, "created_utc": 1687502982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "i am about to finish my first year as a junior ds.  I am not satisfied with what I learned in the company.  (We dont have a senior and i have to act like mid level DS from time 2 time)\n\nI am investing my time to learn SOTA generative ai technologies. I am interested in GANs and diffusion models. I want to be able custom train these models for any relevant solution. \n\n I am wondering if I am being unrealistic by doing this.  What you guys think?\n\nnote: i have a startup idea which solves a common problem.  i might go for it in the end.", "author_fullname": "t2_qzy7otr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does learning Gen AI in terms of career development makes sense?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gyxyd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687527788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i am about to finish my first year as a junior ds.  I am not satisfied with what I learned in the company.  (We dont have a senior and i have to act like mid level DS from time 2 time)&lt;/p&gt;\n\n&lt;p&gt;I am investing my time to learn SOTA generative ai technologies. I am interested in GANs and diffusion models. I want to be able custom train these models for any relevant solution. &lt;/p&gt;\n\n&lt;p&gt;I am wondering if I am being unrealistic by doing this.  What you guys think?&lt;/p&gt;\n\n&lt;p&gt;note: i have a startup idea which solves a common problem.  i might go for it in the end.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gyxyd", "is_robot_indexable": true, "report_reasons": null, "author": "karaposu", "discussion_type": null, "num_comments": 38, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gyxyd/does_learning_gen_ai_in_terms_of_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gyxyd/does_learning_gen_ai_in_terms_of_career/", "subreddit_subscribers": 930002, "created_utc": 1687527788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm not looking for a new job now, but let's say that when I do, I'll have 4 years experience as a data scientist. 1 in tech and 3 in insurance. My job title is Senior Data Scientist but my role and responsibilities are more akin to Senior Data Analyst. You know, Tableau work, creating and maintain slick dashboards, stuff like that. Which means that I would be eligible for both types of jobs, if I take the time to study on my own the stuff that actual, real data scientists know.\n\nMy question is, will it be just as easy to get a Data Science or Data Analyst role *outside* of insurance? Will the hiring manager be like \"you got 4 years of data science experience, hell yeah, you'll fit right in\"?\n\nOr will they be like, \"well, I see you got 4 years data science experience in *your* industry, but do you have any experience in our industry? No? Well... maybe we'll give you a call\" and then they proceed to extend an offer to the candidate with only 2 years data science experience, but that experience is entirely within the company's industry.", "author_fullname": "t2_4ckw169q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it easy to move to a different industry within Data Science? Or is it difficult, almost akin to a career change?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14h9l51", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687553905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m not looking for a new job now, but let&amp;#39;s say that when I do, I&amp;#39;ll have 4 years experience as a data scientist. 1 in tech and 3 in insurance. My job title is Senior Data Scientist but my role and responsibilities are more akin to Senior Data Analyst. You know, Tableau work, creating and maintain slick dashboards, stuff like that. Which means that I would be eligible for both types of jobs, if I take the time to study on my own the stuff that actual, real data scientists know.&lt;/p&gt;\n\n&lt;p&gt;My question is, will it be just as easy to get a Data Science or Data Analyst role &lt;em&gt;outside&lt;/em&gt; of insurance? Will the hiring manager be like &amp;quot;you got 4 years of data science experience, hell yeah, you&amp;#39;ll fit right in&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;Or will they be like, &amp;quot;well, I see you got 4 years data science experience in &lt;em&gt;your&lt;/em&gt; industry, but do you have any experience in our industry? No? Well... maybe we&amp;#39;ll give you a call&amp;quot; and then they proceed to extend an offer to the candidate with only 2 years data science experience, but that experience is entirely within the company&amp;#39;s industry.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14h9l51", "is_robot_indexable": true, "report_reasons": null, "author": "valkaress", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14h9l51/is_it_easy_to_move_to_a_different_industry_within/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14h9l51/is_it_easy_to_move_to_a_different_industry_within/", "subreddit_subscribers": 930002, "created_utc": 1687553905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nSorry if this is the wrong place to ask, please let me know if there's a better subreddit. \n\nI am relatively new into the data field and began learning SQL on the job about 2 years ago. I started taking courses learning python about 6 months ago and wanted to find an applicable use in my role. We currently have a vendor where we obtain their data via a spreadsheet that corrupts frequently. The vendor has an API but at this point no one has attempted that method until I started learning python.\n\nI am currently at the point where I am obtaining data via the API and have gone through the whole oauth process, but it has been very manual. My issue is that I am having trouble automating this, and I will break down the steps I received from the vendor.\n\n&amp;#x200B;\n\n1. The initial API call must be done via a browser that authenticates the account I have with the vendor. An auth code is then provided via the browser URL that you are directed to.\n2. That auth code is then passed in the post request and an access token/refresh token is retrieved from the result set. The refresh token lasts for 30 days. The auth code that is initially provided expires after 10 minutes and is only good for one attempt, so I do not want to call that via that method again.\n3. Subsequent API calls can be used using the refresh token (via a different grant type), after approx 13 days they will send a a new refresh token in the results.\n4. We are storing the refresh token in an azure secret to reference it.\n\nSince this is my first time utilizing this method to obtain data, I am not sure the most efficient way/best practices to go about this.\n\nIdeally, I would like this to be as automated as possible. I want to avoid the \"auth code\"/browser api call and just want to utilize the refresh token grant type. Below is a basic outline of my code.\n\n&amp;#x200B;\n\nimport libraries\n\ndef function initial\\_call()\n\ndef function refresh\\_call()\n\nvariable to skip initial call (I am manually changing this after the initial call)\n\ninitial\\_call() returns refresh token\n\nrefresh\\_token = initialcall()\n\nrefresh\\_call() (this references the refresh\\_token from the initial call)  \n\n\naccess\\_token is retrieved and then passed to the api call for data  \n\n\nWhat is the best way skip the initial call once it has been done? Also - I will need to update the refresh token once we receive a new one from the refresh\\_call(), the issue is they only send it in the response when it is updated (after 13 days).\n\n&amp;#x200B;\n\nThanks for any help/insight. \n\n&amp;#x200B;", "author_fullname": "t2_5rj9fmzhq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Obtaining Data via API Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gmh88", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687487541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Sorry if this is the wrong place to ask, please let me know if there&amp;#39;s a better subreddit. &lt;/p&gt;\n\n&lt;p&gt;I am relatively new into the data field and began learning SQL on the job about 2 years ago. I started taking courses learning python about 6 months ago and wanted to find an applicable use in my role. We currently have a vendor where we obtain their data via a spreadsheet that corrupts frequently. The vendor has an API but at this point no one has attempted that method until I started learning python.&lt;/p&gt;\n\n&lt;p&gt;I am currently at the point where I am obtaining data via the API and have gone through the whole oauth process, but it has been very manual. My issue is that I am having trouble automating this, and I will break down the steps I received from the vendor.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The initial API call must be done via a browser that authenticates the account I have with the vendor. An auth code is then provided via the browser URL that you are directed to.&lt;/li&gt;\n&lt;li&gt;That auth code is then passed in the post request and an access token/refresh token is retrieved from the result set. The refresh token lasts for 30 days. The auth code that is initially provided expires after 10 minutes and is only good for one attempt, so I do not want to call that via that method again.&lt;/li&gt;\n&lt;li&gt;Subsequent API calls can be used using the refresh token (via a different grant type), after approx 13 days they will send a a new refresh token in the results.&lt;/li&gt;\n&lt;li&gt;We are storing the refresh token in an azure secret to reference it.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Since this is my first time utilizing this method to obtain data, I am not sure the most efficient way/best practices to go about this.&lt;/p&gt;\n\n&lt;p&gt;Ideally, I would like this to be as automated as possible. I want to avoid the &amp;quot;auth code&amp;quot;/browser api call and just want to utilize the refresh token grant type. Below is a basic outline of my code.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;import libraries&lt;/p&gt;\n\n&lt;p&gt;def function initial_call()&lt;/p&gt;\n\n&lt;p&gt;def function refresh_call()&lt;/p&gt;\n\n&lt;p&gt;variable to skip initial call (I am manually changing this after the initial call)&lt;/p&gt;\n\n&lt;p&gt;initial_call() returns refresh token&lt;/p&gt;\n\n&lt;p&gt;refresh_token = initialcall()&lt;/p&gt;\n\n&lt;p&gt;refresh_call() (this references the refresh_token from the initial call)  &lt;/p&gt;\n\n&lt;p&gt;access_token is retrieved and then passed to the api call for data  &lt;/p&gt;\n\n&lt;p&gt;What is the best way skip the initial call once it has been done? Also - I will need to update the refresh token once we receive a new one from the refresh_call(), the issue is they only send it in the response when it is updated (after 13 days).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help/insight. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gmh88", "is_robot_indexable": true, "report_reasons": null, "author": "Brave-Carrot5429", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gmh88/obtaining_data_via_api_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gmh88/obtaining_data_via_api_question/", "subreddit_subscribers": 930002, "created_utc": 1687487541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I read a bit of a thesis paper discussing the idea that using PCA to pre-whiten before ICA should not include any form of principle component reduction due to the appearance of \"eiganspecters\" which they identify as artifacts that appear as a result of the aforementioned reduction. I haven't seen much discussion on this so I wanted to ask what you all thought about this in particular. The thesis is below: \n\n[https://ourarchive.otago.ac.nz/handle/10523/4459](https://ourarchive.otago.ac.nz/handle/10523/4459)\n\n&amp;#x200B;", "author_fullname": "t2_l0f5k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are eiganspecters an actual issue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gkzw6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687483346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read a bit of a thesis paper discussing the idea that using PCA to pre-whiten before ICA should not include any form of principle component reduction due to the appearance of &amp;quot;eiganspecters&amp;quot; which they identify as artifacts that appear as a result of the aforementioned reduction. I haven&amp;#39;t seen much discussion on this so I wanted to ask what you all thought about this in particular. The thesis is below: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ourarchive.otago.ac.nz/handle/10523/4459\"&gt;https://ourarchive.otago.ac.nz/handle/10523/4459&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gkzw6", "is_robot_indexable": true, "report_reasons": null, "author": "figgedy1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gkzw6/are_eiganspecters_an_actual_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gkzw6/are_eiganspecters_an_actual_issue/", "subreddit_subscribers": 930002, "created_utc": 1687483346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I noticed that I spend 100% of my working hours working non-stoping and that's due to the fact our team is small and there are a lot of expectations from me which makes me feel responsible for the whole product.\n\n&amp;#x200B;\n\nI never say no to tasks or give me more time, but I always try to get whatever done as soon as possible. Am I managing my time wrong? What do you do and how do you manage your time? How do you find time for learning at work (Or I shouldn't expect to have time for learning at work?)", "author_fullname": "t2_3ezuav96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you learn while working?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14hbobi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687558996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I noticed that I spend 100% of my working hours working non-stoping and that&amp;#39;s due to the fact our team is small and there are a lot of expectations from me which makes me feel responsible for the whole product.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I never say no to tasks or give me more time, but I always try to get whatever done as soon as possible. Am I managing my time wrong? What do you do and how do you manage your time? How do you find time for learning at work (Or I shouldn&amp;#39;t expect to have time for learning at work?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14hbobi", "is_robot_indexable": true, "report_reasons": null, "author": "AhMeDxHaMiDo", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14hbobi/do_you_learn_while_working/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14hbobi/do_you_learn_while_working/", "subreddit_subscribers": 930002, "created_utc": 1687558996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone, \n\nI'm struggling to find an accurate way of determining average customer life span for one of my e-comm's. In the past I have used churn rate, however the buying of cycle of my client base can be over 1 year, resulting in some clients being considered churned, yet they aren't. \n\nI have 5 years worth of data, unfortunately I don't have a clean way of determining time between 1st and last order either. \n\nWhat method should I be using to determine this? \n\nThanks for the help.", "author_fullname": "t2_42s9h6v6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to determine average customer life span?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14h7hl5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687548767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m struggling to find an accurate way of determining average customer life span for one of my e-comm&amp;#39;s. In the past I have used churn rate, however the buying of cycle of my client base can be over 1 year, resulting in some clients being considered churned, yet they aren&amp;#39;t. &lt;/p&gt;\n\n&lt;p&gt;I have 5 years worth of data, unfortunately I don&amp;#39;t have a clean way of determining time between 1st and last order either. &lt;/p&gt;\n\n&lt;p&gt;What method should I be using to determine this? &lt;/p&gt;\n\n&lt;p&gt;Thanks for the help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14h7hl5", "is_robot_indexable": true, "report_reasons": null, "author": "Nscocean", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14h7hl5/how_to_determine_average_customer_life_span/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14h7hl5/how_to_determine_average_customer_life_span/", "subreddit_subscribers": 930002, "created_utc": 1687548767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "TLDR: I never worked as a true consultant, but this role assumes only internal stakeholders. I like focused work, but also communication with others (though, mostly technically savvy people). Not an entrepreneur myself, but these idea-generating colleagues usually like to work with me.  \nTell me what you think it will be like.\n\n\\- how much technically advanced can it be? Will I stay up to date as a DS expert? They ask for somewhat standard set of Python, SQL, Databricks; mention NLP, recommender systems.\n\n  \n\\- how much typical consultancy (bs) duties there will be? It shouldn't be just PM / PO mish-mash with 8 hours meetings per day, right? Will it include focused work? They mention contributing to business workshops, working on prototypes...\n\n  \n\\- how beneficial career-wise does it look to work in Innovation Management as a DS? Should I negotiate a salary bump if I stay on the same job level and assuming I have no consultancy experience?\n\n  \n\\- which skills should I exhibit for the interviews - it seems like they will value DS expertise for 5%, what will be the rest? How do I best pitch myself? \n\n  \n\\- would you move? ", "author_fullname": "t2_f3y80e7s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "As a DS and research engineer, I want to apply internally for a Consultant DS role within the Innovation Management department. How will it feel like?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14h0xko", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687532695.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: I never worked as a true consultant, but this role assumes only internal stakeholders. I like focused work, but also communication with others (though, mostly technically savvy people). Not an entrepreneur myself, but these idea-generating colleagues usually like to work with me.&lt;br/&gt;\nTell me what you think it will be like.&lt;/p&gt;\n\n&lt;p&gt;- how much technically advanced can it be? Will I stay up to date as a DS expert? They ask for somewhat standard set of Python, SQL, Databricks; mention NLP, recommender systems.&lt;/p&gt;\n\n&lt;p&gt;- how much typical consultancy (bs) duties there will be? It shouldn&amp;#39;t be just PM / PO mish-mash with 8 hours meetings per day, right? Will it include focused work? They mention contributing to business workshops, working on prototypes...&lt;/p&gt;\n\n&lt;p&gt;- how beneficial career-wise does it look to work in Innovation Management as a DS? Should I negotiate a salary bump if I stay on the same job level and assuming I have no consultancy experience?&lt;/p&gt;\n\n&lt;p&gt;- which skills should I exhibit for the interviews - it seems like they will value DS expertise for 5%, what will be the rest? How do I best pitch myself? &lt;/p&gt;\n\n&lt;p&gt;- would you move? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14h0xko", "is_robot_indexable": true, "report_reasons": null, "author": "docoja1739", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14h0xko/as_a_ds_and_research_engineer_i_want_to_apply/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14h0xko/as_a_ds_and_research_engineer_i_want_to_apply/", "subreddit_subscribers": 930002, "created_utc": 1687532695.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to use a chat LLM on my website. I\u2019m a full stack dev. I\u2019m confused about the AI stack.\n\nFrom my front end, where do I send the API request to the llm ? Can I Host the model on Hugging Face and api in, or do I need to host it elsewhere (presumably I do) with a gpu cloud provider like vast.ai?", "author_fullname": "t2_mfnoqbm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to host model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gzk4b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687529351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to use a chat LLM on my website. I\u2019m a full stack dev. I\u2019m confused about the AI stack.&lt;/p&gt;\n\n&lt;p&gt;From my front end, where do I send the API request to the llm ? Can I Host the model on Hugging Face and api in, or do I need to host it elsewhere (presumably I do) with a gpu cloud provider like vast.ai?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gzk4b", "is_robot_indexable": true, "report_reasons": null, "author": "phas0ruk1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gzk4b/where_to_host_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gzk4b/where_to_host_model/", "subreddit_subscribers": 930002, "created_utc": 1687529351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So every six months I get an brain MRI and annually I get a spinal MRI.  And at this point I think there are about 1 million Americans with MS and statistically about 1:100,000 people have it.\n\nYet, when I ask my MS Specialist at the Shepherd Center in Atlanta what a particular lesion might actually cause I don\u2019t get a very convincing answer.  \n\nBut every six months we do a new MRI and a new physical exam and we go over all my symptoms like I\u2019m sure a huge number of us do.  \n\nIf they were all in one database I feel like statistically we could associate a level of disability with number and size of lesions.  We could map symptoms to locations better than what we have now.  \n\nDoes anybody know of an existing database of MRIs where this work is happening or any studies that go over this?", "author_fullname": "t2_5mr7f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does an MS MRI database exist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gv4dx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687516626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So every six months I get an brain MRI and annually I get a spinal MRI.  And at this point I think there are about 1 million Americans with MS and statistically about 1:100,000 people have it.&lt;/p&gt;\n\n&lt;p&gt;Yet, when I ask my MS Specialist at the Shepherd Center in Atlanta what a particular lesion might actually cause I don\u2019t get a very convincing answer.  &lt;/p&gt;\n\n&lt;p&gt;But every six months we do a new MRI and a new physical exam and we go over all my symptoms like I\u2019m sure a huge number of us do.  &lt;/p&gt;\n\n&lt;p&gt;If they were all in one database I feel like statistically we could associate a level of disability with number and size of lesions.  We could map symptoms to locations better than what we have now.  &lt;/p&gt;\n\n&lt;p&gt;Does anybody know of an existing database of MRIs where this work is happening or any studies that go over this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gv4dx", "is_robot_indexable": true, "report_reasons": null, "author": "Lochstar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gv4dx/does_an_ms_mri_database_exist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gv4dx/does_an_ms_mri_database_exist/", "subreddit_subscribers": 930002, "created_utc": 1687516626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Since a few month, I work in a company on event detection with time series. I would like some recommendations on how to organize my datascience project in Python. Some context : \n\n  \nThere was a datascientist before me, and some intern worked on this project. It's been 4 years since the model was updated, and at that time, they built a sophisticated (or just big) pipeline to run multiple tasks : \n\n* preprocess / filter / enrich data\n* train a classifier\n* compute metrics, print graphs, export a bunch of parameters in csv / json files\n* export the model in mobile-compatible formats (CoreML for iOS, json for Android)\n* store everything in archives, upload in on our server, git operations, ...\n* validate on a set of trusted data\n* and many other things\n\nI'm not sure if I want to perform the same tasks, the context is different now.\n\nWhat bugs me, with this pipeline, is the way data is shared / passed among functions. Each task, each function, is performed on a file, on disk. (there is no need for this, the data is not massive). For example, the `train_classifier` function have one parameter \"`project_dir_path`\", and inside that project directory, it loads parameters, arguments, various stuff, and export the results, metrics, classifier, everything, **inside** that directory.\n\nOf course, the  \"`project_dir_path`\" was a hidden directory, like '`.tmp/my_dataset`', not committed or saved anywhere.\n\nEvery function is like that. It's a hell to understand what is needed for each function, what are the data, etc. By the way, the \"pipeline\" is composed of two files, with 800+ lines each.\n\nAbout me : \n\n* It's my first Python Datascience job\n* Previously I was finishing my PhD, so my Python coding practices are ... inexistant\n* Before my PhD, I was a Java software engineer. I like typed languages, I like Object Oriented Programming, self-documenting code, etc. \n\n&amp;#x200B;\n\nMy question : how do I organize this mess ? Is it a good pattern ? Am I just impatient ? \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_8owvwc5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Code and Python project web practices for datascience pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gsow1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687508005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since a few month, I work in a company on event detection with time series. I would like some recommendations on how to organize my datascience project in Python. Some context : &lt;/p&gt;\n\n&lt;p&gt;There was a datascientist before me, and some intern worked on this project. It&amp;#39;s been 4 years since the model was updated, and at that time, they built a sophisticated (or just big) pipeline to run multiple tasks : &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;preprocess / filter / enrich data&lt;/li&gt;\n&lt;li&gt;train a classifier&lt;/li&gt;\n&lt;li&gt;compute metrics, print graphs, export a bunch of parameters in csv / json files&lt;/li&gt;\n&lt;li&gt;export the model in mobile-compatible formats (CoreML for iOS, json for Android)&lt;/li&gt;\n&lt;li&gt;store everything in archives, upload in on our server, git operations, ...&lt;/li&gt;\n&lt;li&gt;validate on a set of trusted data&lt;/li&gt;\n&lt;li&gt;and many other things&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if I want to perform the same tasks, the context is different now.&lt;/p&gt;\n\n&lt;p&gt;What bugs me, with this pipeline, is the way data is shared / passed among functions. Each task, each function, is performed on a file, on disk. (there is no need for this, the data is not massive). For example, the &lt;code&gt;train_classifier&lt;/code&gt; function have one parameter &amp;quot;&lt;code&gt;project_dir_path&lt;/code&gt;&amp;quot;, and inside that project directory, it loads parameters, arguments, various stuff, and export the results, metrics, classifier, everything, &lt;strong&gt;inside&lt;/strong&gt; that directory.&lt;/p&gt;\n\n&lt;p&gt;Of course, the  &amp;quot;&lt;code&gt;project_dir_path&lt;/code&gt;&amp;quot; was a hidden directory, like &amp;#39;&lt;code&gt;.tmp/my_dataset&lt;/code&gt;&amp;#39;, not committed or saved anywhere.&lt;/p&gt;\n\n&lt;p&gt;Every function is like that. It&amp;#39;s a hell to understand what is needed for each function, what are the data, etc. By the way, the &amp;quot;pipeline&amp;quot; is composed of two files, with 800+ lines each.&lt;/p&gt;\n\n&lt;p&gt;About me : &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;It&amp;#39;s my first Python Datascience job&lt;/li&gt;\n&lt;li&gt;Previously I was finishing my PhD, so my Python coding practices are ... inexistant&lt;/li&gt;\n&lt;li&gt;Before my PhD, I was a Java software engineer. I like typed languages, I like Object Oriented Programming, self-documenting code, etc. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question : how do I organize this mess ? Is it a good pattern ? Am I just impatient ? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gsow1", "is_robot_indexable": true, "report_reasons": null, "author": "This-Librarian3339", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gsow1/code_and_python_project_web_practices_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gsow1/code_and_python_project_web_practices_for/", "subreddit_subscribers": 930002, "created_utc": 1687508005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a choice to either choose CS(Data Science) or CS(AI and ML) at my college. Which one should I choose if my goal is to work at FAANG and maybe try for quant later in my career(probably after masters)?\n\nI might also go for masters right after undergrad, so which one will have less competition at top universities?", "author_fullname": "t2_7rru4w7j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I choose a specialisation in DSE or AIML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gpgsa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687496756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a choice to either choose CS(Data Science) or CS(AI and ML) at my college. Which one should I choose if my goal is to work at FAANG and maybe try for quant later in my career(probably after masters)?&lt;/p&gt;\n\n&lt;p&gt;I might also go for masters right after undergrad, so which one will have less competition at top universities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gpgsa", "is_robot_indexable": true, "report_reasons": null, "author": "the_card_dealer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gpgsa/should_i_choose_a_specialisation_in_dse_or_aiml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gpgsa/should_i_choose_a_specialisation_in_dse_or_aiml/", "subreddit_subscribers": 930002, "created_utc": 1687496756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, I know that this may not be the best place to ask this question, but I\u2019ll give it a try- I am about to buy a Mac for the very first time. I plan on using the Mac for programming and data work with extensive virtualization (docker and Parallels with Windows for data analysis stuff such as Power BI etc). I do NOT care about gaming, nor do I intend on doing video/audio/photo editing or other media related work.  which option would be better between the 15\" MacBook Air with 24GB RAM and 512GB storage or the base model MacBook Pro with 16GB RAM and 512GB storage? Both options are priced the same in Canada. Will I feel perceived different in performance? like the larger screen, but not at the expense of lacking performance. Thank you!", "author_fullname": "t2_g8z5mzez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MacBook Air 15\u201d 24gb/512gb vs Base 14\u201d Pro", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14hc5u9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687560261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I know that this may not be the best place to ask this question, but I\u2019ll give it a try- I am about to buy a Mac for the very first time. I plan on using the Mac for programming and data work with extensive virtualization (docker and Parallels with Windows for data analysis stuff such as Power BI etc). I do NOT care about gaming, nor do I intend on doing video/audio/photo editing or other media related work.  which option would be better between the 15&amp;quot; MacBook Air with 24GB RAM and 512GB storage or the base model MacBook Pro with 16GB RAM and 512GB storage? Both options are priced the same in Canada. Will I feel perceived different in performance? like the larger screen, but not at the expense of lacking performance. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14hc5u9", "is_robot_indexable": true, "report_reasons": null, "author": "New-Day-6322", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14hc5u9/macbook_air_15_24gb512gb_vs_base_14_pro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14hc5u9/macbook_air_15_24gb512gb_vs_base_14_pro/", "subreddit_subscribers": 930002, "created_utc": 1687560261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone,\r  \n\r  \nWe're hosting a free-to-enter, virtual hackathon, All Inclusive Hacks, centered on fostering creative solutions to strengthen inclusivity in AI development. It will be hosted during mid to late August and we expect the prize pool to be in the range of $200k to $300k and to be sponsored by major tech corporations, including Google, OpenAI(creator of ChatGPT), and Microsoft. This is open to all aged 13+ regardless of experience in programming. We will have workshops to provide educational resources for our participants.\r  \n\r  \nWhy Should You Join This Hackathon?\r  \n\r  \nThis hackathon is a great opportunity to...\r  \n\r  \nEarn loads of prizes\r  \n\r  \nMeet peers with similar interests\r  \n\r  \nImprove one's resume for jobs, internships, and college or grad school admissions\r  \n\r  \nImprove one's grasp of artificial intelligence(this especially important due to the increasing prevalence of AI in the industry)\r  \n\r  \nLearn from our workshops that will be hosted by leading figures in artificial intelligence\r  \n\r  \nSign Up Link: https://all-inclusive-hacks.devpost.com/", "author_fullname": "t2_dfcjm8gnk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Projected $200,000 in Prizes AI Hackathon (Free to Enter)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14ha0sj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687554925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re hosting a free-to-enter, virtual hackathon, All Inclusive Hacks, centered on fostering creative solutions to strengthen inclusivity in AI development. It will be hosted during mid to late August and we expect the prize pool to be in the range of $200k to $300k and to be sponsored by major tech corporations, including Google, OpenAI(creator of ChatGPT), and Microsoft. This is open to all aged 13+ regardless of experience in programming. We will have workshops to provide educational resources for our participants.&lt;/p&gt;\n\n&lt;p&gt;Why Should You Join This Hackathon?&lt;/p&gt;\n\n&lt;p&gt;This hackathon is a great opportunity to...&lt;/p&gt;\n\n&lt;p&gt;Earn loads of prizes&lt;/p&gt;\n\n&lt;p&gt;Meet peers with similar interests&lt;/p&gt;\n\n&lt;p&gt;Improve one&amp;#39;s resume for jobs, internships, and college or grad school admissions&lt;/p&gt;\n\n&lt;p&gt;Improve one&amp;#39;s grasp of artificial intelligence(this especially important due to the increasing prevalence of AI in the industry)&lt;/p&gt;\n\n&lt;p&gt;Learn from our workshops that will be hosted by leading figures in artificial intelligence&lt;/p&gt;\n\n&lt;p&gt;Sign Up Link: &lt;a href=\"https://all-inclusive-hacks.devpost.com/\"&gt;https://all-inclusive-hacks.devpost.com/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/b1QDuKROgpRC3HTpJSHW5JrFzQyvW-Uvc2VpPQjO0sU.jpg?auto=webp&amp;v=enabled&amp;s=6704dfe78599a146e6a4116e366a624a91f5a53c", "width": 518, "height": 478}, "resolutions": [{"url": "https://external-preview.redd.it/b1QDuKROgpRC3HTpJSHW5JrFzQyvW-Uvc2VpPQjO0sU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=220d04d3513568acaa174bd86f214c0e2431bd80", "width": 108, "height": 99}, {"url": "https://external-preview.redd.it/b1QDuKROgpRC3HTpJSHW5JrFzQyvW-Uvc2VpPQjO0sU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=800259dad38ece532e00e0a47ab37d305b7a8c8b", "width": 216, "height": 199}, {"url": "https://external-preview.redd.it/b1QDuKROgpRC3HTpJSHW5JrFzQyvW-Uvc2VpPQjO0sU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2a712b9286be9ecec816bc6f7780dd12ed3a3be8", "width": 320, "height": 295}], "variants": {}, "id": "aq3DlaWNARS2L2mhnH3TdUlfYvK4Gj48uHsY8cSiQxE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14ha0sj", "is_robot_indexable": true, "report_reasons": null, "author": "AllInclusiveHacks", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14ha0sj/projected_200000_in_prizes_ai_hackathon_free_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14ha0sj/projected_200000_in_prizes_ai_hackathon_free_to/", "subreddit_subscribers": 930002, "created_utc": 1687554925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nNew to the thread. I was hoping if anyone had a script that would retrive the labels of a precomputed distance matrix?\n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_6cixwm8a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get labels of precomputed matrix", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14h8e18", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687550998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;New to the thread. I was hoping if anyone had a script that would retrive the labels of a precomputed distance matrix?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14h8e18", "is_robot_indexable": true, "report_reasons": null, "author": "AdAffectionate1589", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14h8e18/how_to_get_labels_of_precomputed_matrix/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14h8e18/how_to_get_labels_of_precomputed_matrix/", "subreddit_subscribers": 930002, "created_utc": 1687550998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know that some schools, such as business school departments hire DS or DEs for their research or data engineering.  I mainly want to work for a university as I'd like to take free classes and get involved with academic research.", "author_fullname": "t2_s5wnr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Anyone a Data Scientist at a University?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14h5xfb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687544961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know that some schools, such as business school departments hire DS or DEs for their research or data engineering.  I mainly want to work for a university as I&amp;#39;d like to take free classes and get involved with academic research.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14h5xfb", "is_robot_indexable": true, "report_reasons": null, "author": "combrade", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14h5xfb/is_anyone_a_data_scientist_at_a_university/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14h5xfb/is_anyone_a_data_scientist_at_a_university/", "subreddit_subscribers": 930002, "created_utc": 1687544961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a file for which I have to predict the future values. I have three variables, yearly data, stations, and values for each station. How do I model an ARIMA with only data from 2013 to 2019? I will have only seven years data for each station. It would also be best if the model didn't consider individual stations and ran the data as a whole. ", "author_fullname": "t2_3j8fec8j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ARIMA Model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14h5l38", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687544082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a file for which I have to predict the future values. I have three variables, yearly data, stations, and values for each station. How do I model an ARIMA with only data from 2013 to 2019? I will have only seven years data for each station. It would also be best if the model didn&amp;#39;t consider individual stations and ran the data as a whole. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14h5l38", "is_robot_indexable": true, "report_reasons": null, "author": "4ashes4", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14h5l38/arima_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14h5l38/arima_model/", "subreddit_subscribers": 930002, "created_utc": 1687544082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking for weather data on 4500 cities throughout the world for 2022 and 2023 for a school project. Is there a way to get this for free? I can see it according to weather stations, but that might be too much to compile. Is there anything city level directly available?", "author_fullname": "t2_cax2jvgb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weather data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14h2e9j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687536291.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for weather data on 4500 cities throughout the world for 2022 and 2023 for a school project. Is there a way to get this for free? I can see it according to weather stations, but that might be too much to compile. Is there anything city level directly available?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14h2e9j", "is_robot_indexable": true, "report_reasons": null, "author": "Scared_Low_2513", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14h2e9j/weather_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14h2e9j/weather_data/", "subreddit_subscribers": 930002, "created_utc": 1687536291.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Curious if anyone has done a comparison of traditional statistical forecasting techniques against deep learning techniques, such as CNN, RNN, etc. \n\nI\u2019ve seen some papers that show traditional techniques outperform these more computationally expensive ones. But, I\u2019d like to hear some opinions as to why you agree or disagree, and if you\u2019ve had personal experience with either techniques for a forecasting project.\n\nThanks!", "author_fullname": "t2_68kzkp6r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Forecasting techniques", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14h1w2o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687535064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious if anyone has done a comparison of traditional statistical forecasting techniques against deep learning techniques, such as CNN, RNN, etc. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve seen some papers that show traditional techniques outperform these more computationally expensive ones. But, I\u2019d like to hear some opinions as to why you agree or disagree, and if you\u2019ve had personal experience with either techniques for a forecasting project.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14h1w2o", "is_robot_indexable": true, "report_reasons": null, "author": "spicyRice-", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14h1w2o/forecasting_techniques/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14h1w2o/forecasting_techniques/", "subreddit_subscribers": 930002, "created_utc": 1687535064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everybody,\n\nI just wanted to start a discussion on here as a thought exercise but also to learn from you guys. As an early-career professional (I am finishing my MSc in wildlife biology but transitioning into data science), a debate that I've been having is finding the balance between efficacy and efficiency when developing models. \n\nMost of my experience has been academia, so my bosses/mentors emphasized causal inference when developing models. But now that I am transitioning into industry work, I have been learning that most \"real-world\" models and ML algorithms are a balancing act of different methods/objectives/timelines/etc... \n\nQuestion is... What are some of these considerations in your day-to-day work and how do you go about balancing them? ", "author_fullname": "t2_3iylg8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding the balance between efficacy and efficiency.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gp4zo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687495724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody,&lt;/p&gt;\n\n&lt;p&gt;I just wanted to start a discussion on here as a thought exercise but also to learn from you guys. As an early-career professional (I am finishing my MSc in wildlife biology but transitioning into data science), a debate that I&amp;#39;ve been having is finding the balance between efficacy and efficiency when developing models. &lt;/p&gt;\n\n&lt;p&gt;Most of my experience has been academia, so my bosses/mentors emphasized causal inference when developing models. But now that I am transitioning into industry work, I have been learning that most &amp;quot;real-world&amp;quot; models and ML algorithms are a balancing act of different methods/objectives/timelines/etc... &lt;/p&gt;\n\n&lt;p&gt;Question is... What are some of these considerations in your day-to-day work and how do you go about balancing them? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gp4zo", "is_robot_indexable": true, "report_reasons": null, "author": "WOCIII", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gp4zo/finding_the_balance_between_efficacy_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gp4zo/finding_the_balance_between_efficacy_and/", "subreddit_subscribers": 930002, "created_utc": 1687495724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI\u2019m an incoming graduate student getting my masters in DS. My program offers a few specializations: \n1. Analytics and Modeling (focuses on predictive modeling) \n2. Analytics Management (focuses on business operations) \n3. Artificial Intelligence \n4. Data Engineering \n\nI was wondering given the job market, which specialization should I choose to be exposed to the most job opportunities?", "author_fullname": "t2_diaem5eh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Specialization for MSDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gksyf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687482821.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m an incoming graduate student getting my masters in DS. My program offers a few specializations: \n1. Analytics and Modeling (focuses on predictive modeling) \n2. Analytics Management (focuses on business operations) \n3. Artificial Intelligence \n4. Data Engineering &lt;/p&gt;\n\n&lt;p&gt;I was wondering given the job market, which specialization should I choose to be exposed to the most job opportunities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gksyf", "is_robot_indexable": true, "report_reasons": null, "author": "eggsbaconcheeze", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gksyf/specialization_for_msds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gksyf/specialization_for_msds/", "subreddit_subscribers": 930002, "created_utc": 1687482821.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, i'm a fresh data science graduate, i applied to a job that states data engineer, but i was surprised on the interview invitation that it's a data officer role,\n\ni have never studied or worked in such area, nor there's enough information online to read, i don't know what the hell they gonna ask me on the interview, i was thinking of backing off, but it looks like a very big company , plus, i need the experience in this stage,\n\nthe interview is in 3 days\n\nis that enough to learn about this? and if yes, can you guys suggest any good sources about this? a last question, it might sound dumb, but, is it harder than other data science roles (analyst, administrator, engineer )?", "author_fullname": "t2_55642ldz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data officer job interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gjldo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687479390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, i&amp;#39;m a fresh data science graduate, i applied to a job that states data engineer, but i was surprised on the interview invitation that it&amp;#39;s a data officer role,&lt;/p&gt;\n\n&lt;p&gt;i have never studied or worked in such area, nor there&amp;#39;s enough information online to read, i don&amp;#39;t know what the hell they gonna ask me on the interview, i was thinking of backing off, but it looks like a very big company , plus, i need the experience in this stage,&lt;/p&gt;\n\n&lt;p&gt;the interview is in 3 days&lt;/p&gt;\n\n&lt;p&gt;is that enough to learn about this? and if yes, can you guys suggest any good sources about this? a last question, it might sound dumb, but, is it harder than other data science roles (analyst, administrator, engineer )?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gjldo", "is_robot_indexable": true, "report_reasons": null, "author": "ARA-GOD", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gjldo/data_officer_job_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gjldo/data_officer_job_interview/", "subreddit_subscribers": 930002, "created_utc": 1687479390.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}