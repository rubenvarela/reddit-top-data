{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_j1toq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Uncovering Stack Overflow's Shocking Architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_14g775a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 50, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/fKc050dvNIE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Uncovering Stack Overflow&amp;#39;s Shocking Architecture\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Uncovering Stack Overflow's Shocking Architecture", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/fKc050dvNIE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Uncovering Stack Overflow&amp;#39;s Shocking Architecture\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/fKc050dvNIE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/fKc050dvNIE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Uncovering Stack Overflow&amp;#39;s Shocking Architecture\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/14g775a", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/yoMm50fLX8cDIp6choKIGKe5W9RQKWeVPGMwIhrL-yE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687449255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=fKc050dvNIE", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/64fQ8qTHWxoEZ_Fwpo0wK9Qv0vOJh72hPR1YDg70QKs.jpg?auto=webp&amp;v=enabled&amp;s=65332583204e1b05d7033b57632bb1f2ec44f4d6", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/64fQ8qTHWxoEZ_Fwpo0wK9Qv0vOJh72hPR1YDg70QKs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1cd325b3407c83db4fe421e7792a4abf0c42f697", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/64fQ8qTHWxoEZ_Fwpo0wK9Qv0vOJh72hPR1YDg70QKs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4eace538ec055a445947ae965e267213ce6cf42e", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/64fQ8qTHWxoEZ_Fwpo0wK9Qv0vOJh72hPR1YDg70QKs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=931339ffcc856bd9a84cfdd33e4d82a138313dac", "width": 320, "height": 240}], "variants": {}, "id": "yTsw0sByiMAAmMy9juwEG9jZEX2AIKsGB_uxPFXgpzU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14g775a", "is_robot_indexable": true, "report_reasons": null, "author": "mjgcfb", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14g775a/uncovering_stack_overflows_shocking_architecture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=fKc050dvNIE", "subreddit_subscribers": 111801, "created_utc": 1687449255.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Uncovering Stack Overflow's Shocking Architecture", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/fKc050dvNIE?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Uncovering Stack Overflow&amp;#39;s Shocking Architecture\"&gt;&lt;/iframe&gt;", "author_name": "ByteByteGo", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/fKc050dvNIE/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@ByteByteGo"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So far I've made one airflow project: Airflow running on an EC2 instance pulls data from an API, transforms it and loads it to AWS S3. \n\nI am a CSE student learning DE, how much Airflow should be sufficient to be able to impress a recruiter or maybe a potential mentor? \n\nI already have some base built on the basics of DE and want to spend the next 1-2 weeks learning airflow. What projects should I make?", "author_fullname": "t2_ens6kw85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much Airflow do I learn as a student?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g58uf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687444604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So far I&amp;#39;ve made one airflow project: Airflow running on an EC2 instance pulls data from an API, transforms it and loads it to AWS S3. &lt;/p&gt;\n\n&lt;p&gt;I am a CSE student learning DE, how much Airflow should be sufficient to be able to impress a recruiter or maybe a potential mentor? &lt;/p&gt;\n\n&lt;p&gt;I already have some base built on the basics of DE and want to spend the next 1-2 weeks learning airflow. What projects should I make?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14g58uf", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent-Tadpole-564", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14g58uf/how_much_airflow_do_i_learn_as_a_student/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14g58uf/how_much_airflow_do_i_learn_as_a_student/", "subreddit_subscribers": 111801, "created_utc": 1687444604.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, i'm a fresh data science graduate, i applied to a job that states data engineer, but i was surprised on the interview invitation that it's a data officer role,\n\ni have never studied or worked in such area, nor there's enough information online to read, i don't know what the hell they gonna ask me on the interview, i was thinking of backing off, but it looks like a very big company , plus, i need the experience in this stage,\n\nthe interview is in 3 days\n\nis that enough to learn about this? and if yes, can you guys suggest any good sources about this? a last question, it might sound dumb, but, is it harder than other data science roles (analyst, administrator, engineer )?", "author_fullname": "t2_55642ldz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what the hell is a data officer ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gjlti", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687479422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, i&amp;#39;m a fresh data science graduate, i applied to a job that states data engineer, but i was surprised on the interview invitation that it&amp;#39;s a data officer role,&lt;/p&gt;\n\n&lt;p&gt;i have never studied or worked in such area, nor there&amp;#39;s enough information online to read, i don&amp;#39;t know what the hell they gonna ask me on the interview, i was thinking of backing off, but it looks like a very big company , plus, i need the experience in this stage,&lt;/p&gt;\n\n&lt;p&gt;the interview is in 3 days&lt;/p&gt;\n\n&lt;p&gt;is that enough to learn about this? and if yes, can you guys suggest any good sources about this? a last question, it might sound dumb, but, is it harder than other data science roles (analyst, administrator, engineer )?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14gjlti", "is_robot_indexable": true, "report_reasons": null, "author": "ARA-GOD", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14gjlti/what_the_hell_is_a_data_officer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14gjlti/what_the_hell_is_a_data_officer/", "subreddit_subscribers": 111801, "created_utc": 1687479422.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI-powered Data Experiences with Semantic Layers, or How to Prevent LLMs from Hallucinating", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_14g76w3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/orA9oXzWYt67Ba9ulUAeNoMxkUuNTRjDy8FxIEdEdB8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687449235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/semantic-layer-the-backbone-of-ai-powered-data-experiences", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fPeIoEkrbBg5PTdABtnKe5_Kd30PCkIstXx6BBcg0EU.jpg?auto=webp&amp;v=enabled&amp;s=67dcc1fe43e19d91b47e6ebb96e61e5f4ab5c982", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/fPeIoEkrbBg5PTdABtnKe5_Kd30PCkIstXx6BBcg0EU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d20f7414a707c8bdd656c3770afbf436482613d9", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/fPeIoEkrbBg5PTdABtnKe5_Kd30PCkIstXx6BBcg0EU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=96b4433b055900089ad9145852557986e806afd7", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/fPeIoEkrbBg5PTdABtnKe5_Kd30PCkIstXx6BBcg0EU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=0001dbc7c1d25381890b7632e6dacb6b13172232", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/fPeIoEkrbBg5PTdABtnKe5_Kd30PCkIstXx6BBcg0EU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d91ec8b048550e2bf24cef42613fe734084df5d7", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/fPeIoEkrbBg5PTdABtnKe5_Kd30PCkIstXx6BBcg0EU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8fd042a6cd87dc387d301df48da68ad398fa40a4", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/fPeIoEkrbBg5PTdABtnKe5_Kd30PCkIstXx6BBcg0EU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=dd265588f0abd8f6788380c109157e17a5ef10b9", "width": 1080, "height": 567}], "variants": {}, "id": "QfpFSHP8aypbw80FFqhIjy7PUgEl0k2jpslNwCYKaeU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14g76w3", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14g76w3/aipowered_data_experiences_with_semantic_layers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/semantic-layer-the-backbone-of-ai-powered-data-experiences", "subreddit_subscribers": 111801, "created_utc": 1687449235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Considering the importance od maintaining quality data in warehouse whats the best tool available in market", "author_fullname": "t2_s1yml2kq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which tool is the best to maintain data quality?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gh2dx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687472768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Considering the importance od maintaining quality data in warehouse whats the best tool available in market&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14gh2dx", "is_robot_indexable": true, "report_reasons": null, "author": "uk-lad-", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14gh2dx/which_tool_is_the_best_to_maintain_data_quality/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14gh2dx/which_tool_is_the_best_to_maintain_data_quality/", "subreddit_subscribers": 111801, "created_utc": 1687472768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What tools should I learn ?", "author_fullname": "t2_w7jxc6wu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to become a beast in Data Orchestration &amp; ETL/ELT ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14gucbi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687513981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What tools should I learn ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14gucbi", "is_robot_indexable": true, "report_reasons": null, "author": "ParlayOptionsGambler", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14gucbi/how_to_become_a_beast_in_data_orchestration_etlelt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14gucbi/how_to_become_a_beast_in_data_orchestration_etlelt/", "subreddit_subscribers": 111801, "created_utc": 1687513981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, hope I don\u2019t bother you with my stupid question. Currently I got multiple data engineering jobs open but I find it a hard time to find the right people. \n\nWhat are some key things that are important for a data engineer? What drives a data engineer to apply on a job add? What would attract you to a job add or message? \n\nOn a daily basis I send more then 40 inmails without any results \n\nHope you guys can help me out!\n\nThank you in advance", "author_fullname": "t2_a4oaxf06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Consultant asking for advise", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14galtx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687458874.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687457705.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, hope I don\u2019t bother you with my stupid question. Currently I got multiple data engineering jobs open but I find it a hard time to find the right people. &lt;/p&gt;\n\n&lt;p&gt;What are some key things that are important for a data engineer? What drives a data engineer to apply on a job add? What would attract you to a job add or message? &lt;/p&gt;\n\n&lt;p&gt;On a daily basis I send more then 40 inmails without any results &lt;/p&gt;\n\n&lt;p&gt;Hope you guys can help me out!&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14galtx", "is_robot_indexable": true, "report_reasons": null, "author": "King17zhc", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14galtx/consultant_asking_for_advise/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14galtx/consultant_asking_for_advise/", "subreddit_subscribers": 111801, "created_utc": 1687457705.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nIn Dbt, I have an incremental model called Test_a. I  have also a second model called Test_b that references model Test_a. I want the model Test_b to update only the rows that where updated in model Test_a. Can you help me?\n\nThanks", "author_fullname": "t2_5kcd2wet", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on DBT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g0n1v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687432326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;In Dbt, I have an incremental model called Test_a. I  have also a second model called Test_b that references model Test_a. I want the model Test_b to update only the rows that where updated in model Test_a. Can you help me?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14g0n1v", "is_robot_indexable": true, "report_reasons": null, "author": "redtiger2019", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14g0n1v/question_on_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14g0n1v/question_on_dbt/", "subreddit_subscribers": 111801, "created_utc": 1687432326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a code based on 10 stored procedurs which fills the same table. If is understand the dtb way correctly, I first should change this into 10 models (views or table). Then I need to make a final model which merge all these models together with union statments. And I choose to materialize these tables as view, the final merge statment will try to merge 10 views together, which has to become very very slow. \n\nWill this not be very slow? My experience with union is not great. If I choose to use vieAnother think is that it will make 10 tables/view that I did not have before, which will pollute our database. \n\nOr is it something I do not understand about DBT", "author_fullname": "t2_7hbs1ihu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dbt speed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gsiah", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687507344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a code based on 10 stored procedurs which fills the same table. If is understand the dtb way correctly, I first should change this into 10 models (views or table). Then I need to make a final model which merge all these models together with union statments. And I choose to materialize these tables as view, the final merge statment will try to merge 10 views together, which has to become very very slow. &lt;/p&gt;\n\n&lt;p&gt;Will this not be very slow? My experience with union is not great. If I choose to use vieAnother think is that it will make 10 tables/view that I did not have before, which will pollute our database. &lt;/p&gt;\n\n&lt;p&gt;Or is it something I do not understand about DBT&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14gsiah", "is_robot_indexable": true, "report_reasons": null, "author": "Wise-Ad-7492", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14gsiah/dbt_speed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14gsiah/dbt_speed/", "subreddit_subscribers": 111801, "created_utc": 1687507344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone done this before? Did you use a connector or Did you write a custom connector?", "author_fullname": "t2_1h4yf7ed", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Redis to Snowflake sync", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gev4r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687467574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone done this before? Did you use a connector or Did you write a custom connector?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14gev4r", "is_robot_indexable": true, "report_reasons": null, "author": "botmentor", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14gev4r/redis_to_snowflake_sync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14gev4r/redis_to_snowflake_sync/", "subreddit_subscribers": 111801, "created_utc": 1687467574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to add a final validation step to a pipeline that outputs a report each time it\u2019s run for compliance reasons.\n\nPart of the validation is to ensure that all of the records at the end of the pipeline correspond to records at the start of the pipeline, and we haven\u2019t had stuff go missing, slip through business rules etc.\n\nIn SQL I\u2019d just do this as a join between two tables with some appropriate conditions and check the output.\n\nIs GX right for doing this, or is it more appropriate for a different sort of validation?", "author_fullname": "t2_xr8z9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this the correct use case for Great Expectations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g53cn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687444238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to add a final validation step to a pipeline that outputs a report each time it\u2019s run for compliance reasons.&lt;/p&gt;\n\n&lt;p&gt;Part of the validation is to ensure that all of the records at the end of the pipeline correspond to records at the start of the pipeline, and we haven\u2019t had stuff go missing, slip through business rules etc.&lt;/p&gt;\n\n&lt;p&gt;In SQL I\u2019d just do this as a join between two tables with some appropriate conditions and check the output.&lt;/p&gt;\n\n&lt;p&gt;Is GX right for doing this, or is it more appropriate for a different sort of validation?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14g53cn", "is_robot_indexable": true, "report_reasons": null, "author": "NeuralHijacker", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14g53cn/is_this_the_correct_use_case_for_great/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14g53cn/is_this_the_correct_use_case_for_great/", "subreddit_subscribers": 111801, "created_utc": 1687444238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey , iam electromechanical engineering student and iam asking if i can land a job as data engineer or i have to have experiences in data analyst first?\n\n\nAnd data engineering is senior role basically", "author_fullname": "t2_hxue1umo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can i land data engineering job as junior?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gel0t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687466936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey , iam electromechanical engineering student and iam asking if i can land a job as data engineer or i have to have experiences in data analyst first?&lt;/p&gt;\n\n&lt;p&gt;And data engineering is senior role basically&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14gel0t", "is_robot_indexable": true, "report_reasons": null, "author": "Single-Sound-1865", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14gel0t/can_i_land_data_engineering_job_as_junior/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14gel0t/can_i_land_data_engineering_job_as_junior/", "subreddit_subscribers": 111801, "created_utc": 1687466936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Why? How? What did you do about egress costs and keeping lakes in sync if you had to serve the same data in two places? If you had to choose a vendor to build a core basic data lake from the major providers (AWS, Azure, GCP, Cloudflare (apparently no egress cost on R2 but low lake tooling)), which would you go with?", "author_fullname": "t2_uqrd0850", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone successfully implemented a multi cloud data lake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gcsly", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687462819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why? How? What did you do about egress costs and keeping lakes in sync if you had to serve the same data in two places? If you had to choose a vendor to build a core basic data lake from the major providers (AWS, Azure, GCP, Cloudflare (apparently no egress cost on R2 but low lake tooling)), which would you go with?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14gcsly", "is_robot_indexable": true, "report_reasons": null, "author": "IncognitoEmployee", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14gcsly/has_anyone_successfully_implemented_a_multi_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14gcsly/has_anyone_successfully_implemented_a_multi_cloud/", "subreddit_subscribers": 111801, "created_utc": 1687462819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,  \nData engineering is a pretty immature function at my current company with few best practices and tooling -- we have a lot of hand-rolled pipelines and monitoring alerts that might, for example, have a regularly scheduled spark instance grab newly ingested s3 files with a batch of records, perform transformations, and dump output to a redshift table. The few alerts we have are things like scheduled sql queries checking when the last record was added and alerting if that was more than X hours ago. I'm generally trying to implement best practices and get us to use industry-standard tooling that would help us do better, such as using an orchestration platform. \n\nMy focus in this post is on monitoring and observability. Our batch job pipelines operate on records that include an event timestamp. I'd like to get a slack alert if our output table ever has a gap in event time larger than, say, 15 minutes. Curious how you'd go about detecting and alerting such a gap. Right now I'm probably going to build a sql query triggered after each ingestion that uses a window function but maybe you have a different approach? Also, what are yall using to manage similar data quality, observability, and alerts?", "author_fullname": "t2_b4tn6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Detecting data gaps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gbfl3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687459630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;br/&gt;\nData engineering is a pretty immature function at my current company with few best practices and tooling -- we have a lot of hand-rolled pipelines and monitoring alerts that might, for example, have a regularly scheduled spark instance grab newly ingested s3 files with a batch of records, perform transformations, and dump output to a redshift table. The few alerts we have are things like scheduled sql queries checking when the last record was added and alerting if that was more than X hours ago. I&amp;#39;m generally trying to implement best practices and get us to use industry-standard tooling that would help us do better, such as using an orchestration platform. &lt;/p&gt;\n\n&lt;p&gt;My focus in this post is on monitoring and observability. Our batch job pipelines operate on records that include an event timestamp. I&amp;#39;d like to get a slack alert if our output table ever has a gap in event time larger than, say, 15 minutes. Curious how you&amp;#39;d go about detecting and alerting such a gap. Right now I&amp;#39;m probably going to build a sql query triggered after each ingestion that uses a window function but maybe you have a different approach? Also, what are yall using to manage similar data quality, observability, and alerts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14gbfl3", "is_robot_indexable": true, "report_reasons": null, "author": "acumenbeing", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14gbfl3/detecting_data_gaps/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14gbfl3/detecting_data_gaps/", "subreddit_subscribers": 111801, "created_utc": 1687459630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If I were to design a data warehouse table to capture Orders. Would the approach 1 or approach 2 be better? Please include your reasoning. I understand Kimball approach says go with the Fact table, but the Slowly changing approach can also solve the same problem. Or, am I missing anything here?\n\nhttps://preview.redd.it/yijknpy8gk7b1.png?width=1307&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9926e39ba023d4dce026832c987aaf28da62433d", "author_fullname": "t2_tov4xq2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ORDER_ACTIVITY_FACT or ORDER_SCD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 34, "top_awarded_type": null, "hide_score": false, "media_metadata": {"yijknpy8gk7b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 26, "x": 108, "u": "https://preview.redd.it/yijknpy8gk7b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=8f05c83a591c5cabc51fe1cff189fd6ef31820ba"}, {"y": 53, "x": 216, "u": "https://preview.redd.it/yijknpy8gk7b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1a41c4a75e9e85c621c65734b2feb4b904db1234"}, {"y": 78, "x": 320, "u": "https://preview.redd.it/yijknpy8gk7b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=422019322a4b3438aea8034fe6fe09f9a6ca6ba5"}, {"y": 157, "x": 640, "u": "https://preview.redd.it/yijknpy8gk7b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=712a41a90ab0bf081b4178a7c7fd72d71ef288d4"}, {"y": 235, "x": 960, "u": "https://preview.redd.it/yijknpy8gk7b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b81035381350bb9ceafab640c044063fdd127ad6"}, {"y": 265, "x": 1080, "u": "https://preview.redd.it/yijknpy8gk7b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4bac7648a121c95dab1976531c963f2a22130595"}], "s": {"y": 321, "x": 1307, "u": "https://preview.redd.it/yijknpy8gk7b1.png?width=1307&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=9926e39ba023d4dce026832c987aaf28da62433d"}, "id": "yijknpy8gk7b1"}}, "name": "t3_14g2rqb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xWmwLo1kOv2NY10f4ppJc0gzWk-GJ3sAAHj88pgTTAk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687438395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I were to design a data warehouse table to capture Orders. Would the approach 1 or approach 2 be better? Please include your reasoning. I understand Kimball approach says go with the Fact table, but the Slowly changing approach can also solve the same problem. Or, am I missing anything here?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/yijknpy8gk7b1.png?width=1307&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9926e39ba023d4dce026832c987aaf28da62433d\"&gt;https://preview.redd.it/yijknpy8gk7b1.png?width=1307&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=9926e39ba023d4dce026832c987aaf28da62433d&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14g2rqb", "is_robot_indexable": true, "report_reasons": null, "author": "nanksk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14g2rqb/order_activity_fact_or_order_scd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14g2rqb/order_activity_fact_or_order_scd/", "subreddit_subscribers": 111801, "created_utc": 1687438395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Throwing this out there as a question. We need a new JIRA prefix for our numbering sequence. The following have already gone:\n- DATA\n- PIPELINES \n- DP\n\nSo, what would you choose?", "author_fullname": "t2_87zfi59a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "JIRA prefix", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gu0x1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687512842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Throwing this out there as a question. We need a new JIRA prefix for our numbering sequence. The following have already gone:\n- DATA\n- PIPELINES \n- DP&lt;/p&gt;\n\n&lt;p&gt;So, what would you choose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14gu0x1", "is_robot_indexable": true, "report_reasons": null, "author": "Cool_Telephone", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14gu0x1/jira_prefix/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14gu0x1/jira_prefix/", "subreddit_subscribers": 111801, "created_utc": 1687512842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I found out today the airflow instance i have set up on an azure vm is not running. I wiped the images, containers,and volumes to launch a fresh copy using docker-compose up -d. But it looks like i am not able to the other services to run(webserver,scehduler). only \n\nCreating prod\\_airflow\\_postgres\\_1 ... done\n\nCreating prod\\_airflow\\_redis\\_1    ... done\n\nCreating prod\\_airflow\\_airflow-init\\_1 ... done\n\nit gets stuck here and sometimes loses connection to VM. \n\nanyone ran into this ?", "author_fullname": "t2_wcnw9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14go4i7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687492500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I found out today the airflow instance i have set up on an azure vm is not running. I wiped the images, containers,and volumes to launch a fresh copy using docker-compose up -d. But it looks like i am not able to the other services to run(webserver,scehduler). only &lt;/p&gt;\n\n&lt;p&gt;Creating prod_airflow_postgres_1 ... done&lt;/p&gt;\n\n&lt;p&gt;Creating prod_airflow_redis_1    ... done&lt;/p&gt;\n\n&lt;p&gt;Creating prod_airflow_airflow-init_1 ... done&lt;/p&gt;\n\n&lt;p&gt;it gets stuck here and sometimes loses connection to VM. &lt;/p&gt;\n\n&lt;p&gt;anyone ran into this ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14go4i7", "is_robot_indexable": true, "report_reasons": null, "author": "obokima", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14go4i7/airflow_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14go4i7/airflow_help/", "subreddit_subscribers": 111801, "created_utc": 1687492500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I am a \"Data Scientist\" at a big trucking company. I have built several SQL programs and did some minor data engineering related work which is what I want to do. Stats is my graduate degree, and I want to be a ML Engineer in 3 more years. Thus, my current focus is to build my software engineering skillset in data.\n\nThis first year, I feel like most days I did little to nothing. I asked my manager (he is a very great guy) for more work (like model building or any projects I can take on), but there is nothing I can own after the first major project that I mainly drove when coming to the company.\n\nI currently feel very useless and depressed. I am studying two certs - Azure Data Fundamentals and then Azure Data Engineering Associate so I can job hope before next year and work somewhere I can develop more skills in data engineering. Our company uses Azure, and I like the platform. I also have a Data Engineering friend who is guiding me on skills I can improve on and a ML Engineering coach I am paying to help guide a path for my future. I just feel lost since I am not developing experience at the company now.\n\n**Would I be lucky to get another role with this 1 year experience** (which mainly consisted of building brute-force SQL programs that I need to optimize more on for big data)? I really like data and want to improve and learn more, but I am not lucky with actual work experience. :/\n\nAny advice?", "author_fullname": "t2_c790qclzg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 year into role and I am worried", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gbseg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687460449.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a &amp;quot;Data Scientist&amp;quot; at a big trucking company. I have built several SQL programs and did some minor data engineering related work which is what I want to do. Stats is my graduate degree, and I want to be a ML Engineer in 3 more years. Thus, my current focus is to build my software engineering skillset in data.&lt;/p&gt;\n\n&lt;p&gt;This first year, I feel like most days I did little to nothing. I asked my manager (he is a very great guy) for more work (like model building or any projects I can take on), but there is nothing I can own after the first major project that I mainly drove when coming to the company.&lt;/p&gt;\n\n&lt;p&gt;I currently feel very useless and depressed. I am studying two certs - Azure Data Fundamentals and then Azure Data Engineering Associate so I can job hope before next year and work somewhere I can develop more skills in data engineering. Our company uses Azure, and I like the platform. I also have a Data Engineering friend who is guiding me on skills I can improve on and a ML Engineering coach I am paying to help guide a path for my future. I just feel lost since I am not developing experience at the company now.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Would I be lucky to get another role with this 1 year experience&lt;/strong&gt; (which mainly consisted of building brute-force SQL programs that I need to optimize more on for big data)? I really like data and want to improve and learn more, but I am not lucky with actual work experience. :/&lt;/p&gt;\n\n&lt;p&gt;Any advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14gbseg", "is_robot_indexable": true, "report_reasons": null, "author": "Big_Pitch_9175", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14gbseg/1_year_into_role_and_i_am_worried/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14gbseg/1_year_into_role_and_i_am_worried/", "subreddit_subscribers": 111801, "created_utc": 1687460449.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently I'm aware of describe history and querying the delta table according to version. I was wondering if there is a way to find history of a record based on its I'd efficiently. Currently I have to sift through all versions to find out the history.", "author_fullname": "t2_rthmzez0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I get SCD2 like output by using Delta table time travel feature?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g0y4x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687433283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently I&amp;#39;m aware of describe history and querying the delta table according to version. I was wondering if there is a way to find history of a record based on its I&amp;#39;d efficiently. Currently I have to sift through all versions to find out the history.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14g0y4x", "is_robot_indexable": true, "report_reasons": null, "author": "rainybuzz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14g0y4x/can_i_get_scd2_like_output_by_using_delta_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14g0y4x/can_i_get_scd2_like_output_by_using_delta_table/", "subreddit_subscribers": 111801, "created_utc": 1687433283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what's the most challenging within retail data infrastructure as a DE?", "author_fullname": "t2_a4oaxf06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Challenges in the retail data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gcqzp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687462708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what&amp;#39;s the most challenging within retail data infrastructure as a DE?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14gcqzp", "is_robot_indexable": true, "report_reasons": null, "author": "King17zhc", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14gcqzp/challenges_in_the_retail_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14gcqzp/challenges_in_the_retail_data/", "subreddit_subscribers": 111801, "created_utc": 1687462708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a pipeline in adf where source is hubspot API and sink is sql DB and during copy data activity, some values from incoming source contains empty value and while running this causes error as it does not converts to null value, how can I overcome it?", "author_fullname": "t2_ojm9jfyq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Empty value in source of copy data causing error", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g4zzs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687444021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a pipeline in adf where source is hubspot API and sink is sql DB and during copy data activity, some values from incoming source contains empty value and while running this causes error as it does not converts to null value, how can I overcome it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14g4zzs", "is_robot_indexable": true, "report_reasons": null, "author": "VaginaSuckingPuppy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14g4zzs/empty_value_in_source_of_copy_data_causing_error/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14g4zzs/empty_value_in_source_of_copy_data_causing_error/", "subreddit_subscribers": 111801, "created_utc": 1687444021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nFellow members, I am excited to announce that I will be starting a newsletter dedicated to helping individuals navigate the field of data engineering. In this newsletter, I will cover various topics such as how to break into the field of data engineering, transitioning from different roles to data engineering positions, job search tips and tricks, resume-building strategies, learning resources, sharing personal experiences, and many more.\n\nI would love to hear from all of you about what specific topics you would like me to address in my newsletters. Your input will guide the direction of the content and ensure that it is tailored to meet your needs. Whether you have specific questions, areas of interest, or challenges you'd like me to tackle, please share them in the comments below. Your valuable feedback will help shape the content and make it more relevant to our community.\n\nThank you all for your support, and I look forward to embarking on this exciting journey together!", "author_fullname": "t2_rrbmofj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Planning to start a Data Engineering Newsletter: Seeking Community Input!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g9fwd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687455004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;Fellow members, I am excited to announce that I will be starting a newsletter dedicated to helping individuals navigate the field of data engineering. In this newsletter, I will cover various topics such as how to break into the field of data engineering, transitioning from different roles to data engineering positions, job search tips and tricks, resume-building strategies, learning resources, sharing personal experiences, and many more.&lt;/p&gt;\n\n&lt;p&gt;I would love to hear from all of you about what specific topics you would like me to address in my newsletters. Your input will guide the direction of the content and ensure that it is tailored to meet your needs. Whether you have specific questions, areas of interest, or challenges you&amp;#39;d like me to tackle, please share them in the comments below. Your valuable feedback will help shape the content and make it more relevant to our community.&lt;/p&gt;\n\n&lt;p&gt;Thank you all for your support, and I look forward to embarking on this exciting journey together!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14g9fwd", "is_robot_indexable": true, "report_reasons": null, "author": "Anishekkamal", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14g9fwd/planning_to_start_a_data_engineering_newsletter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14g9fwd/planning_to_start_a_data_engineering_newsletter/", "subreddit_subscribers": 111801, "created_utc": 1687455004.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}