{"kind": "Listing", "data": {"after": "t3_14g9zxt", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a data analyst, considering furthering my education to work in data science. I currently work for a very well established company that has absolutely atrocious data due to poor IT infrastructure. For example, a visitor will click a tab on their website but due to site latency, the click will be recorded 18 times. I spend all day controlling for messes like this on the reporting side, instead of doing actual real analysis, because the company will not pay for IT to fix the root cause of the problem. \n\nI know some data clean up is part of the field, but I don\u2019t want to spend the rest of my career dealing with this level of incompetence, and if that\u2019s going to be a big part of this job no matter where I go, I don\u2019t know if it\u2019s the right field for me. \n\nI don\u2019t know anyone else outside of my company who works in this kind of field, so can others weigh in here as to whether it\u2019s common to spend your day essentially functioning as a cheaper workaround to major IT issues like this?", "author_fullname": "t2_tepj9g73", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How common is it for data at an established company to be a complete disaster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14glots", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 176, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 176, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687485295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data analyst, considering furthering my education to work in data science. I currently work for a very well established company that has absolutely atrocious data due to poor IT infrastructure. For example, a visitor will click a tab on their website but due to site latency, the click will be recorded 18 times. I spend all day controlling for messes like this on the reporting side, instead of doing actual real analysis, because the company will not pay for IT to fix the root cause of the problem. &lt;/p&gt;\n\n&lt;p&gt;I know some data clean up is part of the field, but I don\u2019t want to spend the rest of my career dealing with this level of incompetence, and if that\u2019s going to be a big part of this job no matter where I go, I don\u2019t know if it\u2019s the right field for me. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t know anyone else outside of my company who works in this kind of field, so can others weigh in here as to whether it\u2019s common to spend your day essentially functioning as a cheaper workaround to major IT issues like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14glots", "is_robot_indexable": true, "report_reasons": null, "author": "ItsaShoreThing1", "discussion_type": null, "num_comments": 124, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14glots/how_common_is_it_for_data_at_an_established/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14glots/how_common_is_it_for_data_at_an_established/", "subreddit_subscribers": 929749, "created_utc": 1687485295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a data scientist, at least that\u2019s what my job title says. In my company I have worked on traditional ML modelling, building vision models on azure and also some big data stuff using kafka, graph db. I don\u2019t know what skills/ expertise do I need to have to work at these large tech companies or earn high salary.\nSometimes it feels like I can do any type of work thrown at me but other times I still feel incomplete in my ds, ml skills.", "author_fullname": "t2_ifsmh8cn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of different work do highly paid data scientists and ML engineers do than those with low to medium salaries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gnnmq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687491058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data scientist, at least that\u2019s what my job title says. In my company I have worked on traditional ML modelling, building vision models on azure and also some big data stuff using kafka, graph db. I don\u2019t know what skills/ expertise do I need to have to work at these large tech companies or earn high salary.\nSometimes it feels like I can do any type of work thrown at me but other times I still feel incomplete in my ds, ml skills.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gnnmq", "is_robot_indexable": true, "report_reasons": null, "author": "Quest_to_peace", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gnnmq/what_kind_of_different_work_do_highly_paid_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gnnmq/what_kind_of_different_work_do_highly_paid_data/", "subreddit_subscribers": 929749, "created_utc": 1687491058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If yes, what tricks do you have to make it work smoothly? I had to resolve some conflicts in an notebook once and it was an awful experience\u2026", "author_fullname": "t2_ze1nira", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you git commit jupyter notebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gra17", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687502982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If yes, what tricks do you have to make it work smoothly? I had to resolve some conflicts in an notebook once and it was an awful experience\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gra17", "is_robot_indexable": true, "report_reasons": null, "author": "old_enough_to_drink", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gra17/do_you_git_commit_jupyter_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gra17/do_you_git_commit_jupyter_notebooks/", "subreddit_subscribers": 929749, "created_utc": 1687502982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "i am about to finish my first year as a junior ds.  I am not satisfied with what I learned in the company.  (We dont have a senior and i have to act like mid level DS from time 2 time)\n\nI am investing my time to learn SOTA generative ai technologies. I am interested in GANs and diffusion models. I want to be able custom train these models for any relevant solution. \n\n I am wondering if I am being unrealistic by doing this.  What you guys think?\n\nnote: i have a startup idea which solves a common problem.  i might go for it in the end.", "author_fullname": "t2_qzy7otr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does learning Gen AI in terms of career development makes sense?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14gyxyd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687527788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i am about to finish my first year as a junior ds.  I am not satisfied with what I learned in the company.  (We dont have a senior and i have to act like mid level DS from time 2 time)&lt;/p&gt;\n\n&lt;p&gt;I am investing my time to learn SOTA generative ai technologies. I am interested in GANs and diffusion models. I want to be able custom train these models for any relevant solution. &lt;/p&gt;\n\n&lt;p&gt;I am wondering if I am being unrealistic by doing this.  What you guys think?&lt;/p&gt;\n\n&lt;p&gt;note: i have a startup idea which solves a common problem.  i might go for it in the end.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gyxyd", "is_robot_indexable": true, "report_reasons": null, "author": "karaposu", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gyxyd/does_learning_gen_ai_in_terms_of_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gyxyd/does_learning_gen_ai_in_terms_of_career/", "subreddit_subscribers": 929749, "created_utc": 1687527788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nSorry if this is the wrong place to ask, please let me know if there's a better subreddit. \n\nI am relatively new into the data field and began learning SQL on the job about 2 years ago. I started taking courses learning python about 6 months ago and wanted to find an applicable use in my role. We currently have a vendor where we obtain their data via a spreadsheet that corrupts frequently. The vendor has an API but at this point no one has attempted that method until I started learning python.\n\nI am currently at the point where I am obtaining data via the API and have gone through the whole oauth process, but it has been very manual. My issue is that I am having trouble automating this, and I will break down the steps I received from the vendor.\n\n&amp;#x200B;\n\n1. The initial API call must be done via a browser that authenticates the account I have with the vendor. An auth code is then provided via the browser URL that you are directed to.\n2. That auth code is then passed in the post request and an access token/refresh token is retrieved from the result set. The refresh token lasts for 30 days. The auth code that is initially provided expires after 10 minutes and is only good for one attempt, so I do not want to call that via that method again.\n3. Subsequent API calls can be used using the refresh token (via a different grant type), after approx 13 days they will send a a new refresh token in the results.\n4. We are storing the refresh token in an azure secret to reference it.\n\nSince this is my first time utilizing this method to obtain data, I am not sure the most efficient way/best practices to go about this.\n\nIdeally, I would like this to be as automated as possible. I want to avoid the \"auth code\"/browser api call and just want to utilize the refresh token grant type. Below is a basic outline of my code.\n\n&amp;#x200B;\n\nimport libraries\n\ndef function initial\\_call()\n\ndef function refresh\\_call()\n\nvariable to skip initial call (I am manually changing this after the initial call)\n\ninitial\\_call() returns refresh token\n\nrefresh\\_token = initialcall()\n\nrefresh\\_call() (this references the refresh\\_token from the initial call)  \n\n\naccess\\_token is retrieved and then passed to the api call for data  \n\n\nWhat is the best way skip the initial call once it has been done? Also - I will need to update the refresh token once we receive a new one from the refresh\\_call(), the issue is they only send it in the response when it is updated (after 13 days).\n\n&amp;#x200B;\n\nThanks for any help/insight. \n\n&amp;#x200B;", "author_fullname": "t2_5rj9fmzhq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Obtaining Data via API Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gmh88", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687487541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Sorry if this is the wrong place to ask, please let me know if there&amp;#39;s a better subreddit. &lt;/p&gt;\n\n&lt;p&gt;I am relatively new into the data field and began learning SQL on the job about 2 years ago. I started taking courses learning python about 6 months ago and wanted to find an applicable use in my role. We currently have a vendor where we obtain their data via a spreadsheet that corrupts frequently. The vendor has an API but at this point no one has attempted that method until I started learning python.&lt;/p&gt;\n\n&lt;p&gt;I am currently at the point where I am obtaining data via the API and have gone through the whole oauth process, but it has been very manual. My issue is that I am having trouble automating this, and I will break down the steps I received from the vendor.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The initial API call must be done via a browser that authenticates the account I have with the vendor. An auth code is then provided via the browser URL that you are directed to.&lt;/li&gt;\n&lt;li&gt;That auth code is then passed in the post request and an access token/refresh token is retrieved from the result set. The refresh token lasts for 30 days. The auth code that is initially provided expires after 10 minutes and is only good for one attempt, so I do not want to call that via that method again.&lt;/li&gt;\n&lt;li&gt;Subsequent API calls can be used using the refresh token (via a different grant type), after approx 13 days they will send a a new refresh token in the results.&lt;/li&gt;\n&lt;li&gt;We are storing the refresh token in an azure secret to reference it.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Since this is my first time utilizing this method to obtain data, I am not sure the most efficient way/best practices to go about this.&lt;/p&gt;\n\n&lt;p&gt;Ideally, I would like this to be as automated as possible. I want to avoid the &amp;quot;auth code&amp;quot;/browser api call and just want to utilize the refresh token grant type. Below is a basic outline of my code.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;import libraries&lt;/p&gt;\n\n&lt;p&gt;def function initial_call()&lt;/p&gt;\n\n&lt;p&gt;def function refresh_call()&lt;/p&gt;\n\n&lt;p&gt;variable to skip initial call (I am manually changing this after the initial call)&lt;/p&gt;\n\n&lt;p&gt;initial_call() returns refresh token&lt;/p&gt;\n\n&lt;p&gt;refresh_token = initialcall()&lt;/p&gt;\n\n&lt;p&gt;refresh_call() (this references the refresh_token from the initial call)  &lt;/p&gt;\n\n&lt;p&gt;access_token is retrieved and then passed to the api call for data  &lt;/p&gt;\n\n&lt;p&gt;What is the best way skip the initial call once it has been done? Also - I will need to update the refresh token once we receive a new one from the refresh_call(), the issue is they only send it in the response when it is updated (after 13 days).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help/insight. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gmh88", "is_robot_indexable": true, "report_reasons": null, "author": "Brave-Carrot5429", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gmh88/obtaining_data_via_api_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gmh88/obtaining_data_via_api_question/", "subreddit_subscribers": 929749, "created_utc": 1687487541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I read a bit of a thesis paper discussing the idea that using PCA to pre-whiten before ICA should not include any form of principle component reduction due to the appearance of \"eiganspecters\" which they identify as artifacts that appear as a result of the aforementioned reduction. I haven't seen much discussion on this so I wanted to ask what you all thought about this in particular. The thesis is below: \n\n[https://ourarchive.otago.ac.nz/handle/10523/4459](https://ourarchive.otago.ac.nz/handle/10523/4459)\n\n&amp;#x200B;", "author_fullname": "t2_l0f5k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are eiganspecters an actual issue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gkzw6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687483346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read a bit of a thesis paper discussing the idea that using PCA to pre-whiten before ICA should not include any form of principle component reduction due to the appearance of &amp;quot;eiganspecters&amp;quot; which they identify as artifacts that appear as a result of the aforementioned reduction. I haven&amp;#39;t seen much discussion on this so I wanted to ask what you all thought about this in particular. The thesis is below: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ourarchive.otago.ac.nz/handle/10523/4459\"&gt;https://ourarchive.otago.ac.nz/handle/10523/4459&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gkzw6", "is_robot_indexable": true, "report_reasons": null, "author": "figgedy1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gkzw6/are_eiganspecters_an_actual_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gkzw6/are_eiganspecters_an_actual_issue/", "subreddit_subscribers": 929749, "created_utc": 1687483346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_kv54kocp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding Gradient Descent in Regression Before you dive into Neural Networks!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14gbbzi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6wVtQEvRoo6UZUqz3Tqo29kdd3DgRqSYd6FVhAEdaZU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687459399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@ilyasaoudata/you-should-understand-backpropagation-in-regression-before-diving-into-neural-networks-5e08d48d69e6", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?auto=webp&amp;v=enabled&amp;s=1fe9b3de72c85fc98d414b6fa25b20d3309342e7", "width": 699, "height": 393}, "resolutions": [{"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26ffc3355391683a428d3f4a57a1ae1e48d4db63", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eed54e80ca02f3ebe41b1c4cca5647cb81816d53", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33297d5ff4287de59cb9fd2bf47a64ba9dbe22dc", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2b103c6423dc869ed624d3a26762fa04f4fb39d", "width": 640, "height": 359}], "variants": {}, "id": "GEtK8rTmTJ9Gfqr6ofB3NKxdlBPmFKQDAxUO4HBYv_0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gbbzi", "is_robot_indexable": true, "report_reasons": null, "author": "AIandSTUFF", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gbbzi/understanding_gradient_descent_in_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@ilyasaoudata/you-should-understand-backpropagation-in-regression-before-diving-into-neural-networks-5e08d48d69e6", "subreddit_subscribers": 929749, "created_utc": 1687459399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I use ChatGPT a lot for getting code snippets and examples, especially for things like matplotlib where I mostly care about just getting the plot I want. I thought it might be nice to run that code right in ChatGPT to see the output and verify that it does what I want.\n\nI hope it may be helpful to others, too!\n\n[Here is the extension](https://chrome.google.com/webstore/detail/jpt/hhpkcgbmfdclebniepgkgnfmpbgijoaf)", "author_fullname": "t2_8fn70sz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a chrome extension that runs Python code in ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g7xn8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687487025.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687450982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use ChatGPT a lot for getting code snippets and examples, especially for things like matplotlib where I mostly care about just getting the plot I want. I thought it might be nice to run that code right in ChatGPT to see the output and verify that it does what I want.&lt;/p&gt;\n\n&lt;p&gt;I hope it may be helpful to others, too!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://chrome.google.com/webstore/detail/jpt/hhpkcgbmfdclebniepgkgnfmpbgijoaf\"&gt;Here is the extension&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zRLXytsXkAvondQg2jm8V5kwxKCVibE9ljSMnJvHCSE.jpg?auto=webp&amp;v=enabled&amp;s=06402b97b9b26da308c389030ab6494da6e8f36e", "width": 128, "height": 128}, "resolutions": [{"url": "https://external-preview.redd.it/zRLXytsXkAvondQg2jm8V5kwxKCVibE9ljSMnJvHCSE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4a18e2981ad62e200bc914369df4e06af57ac16f", "width": 108, "height": 108}], "variants": {}, "id": "J7xyO_09AUlVqVCQPbKxunwW_tcG77lglYyot720LJM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g7xn8", "is_robot_indexable": true, "report_reasons": null, "author": "latticepath", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g7xn8/i_made_a_chrome_extension_that_runs_python_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g7xn8/i_made_a_chrome_extension_that_runs_python_code/", "subreddit_subscribers": 929749, "created_utc": 1687450982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Since a few month, I work in a company on event detection with time series. I would like some recommendations on how to organize my datascience project in Python. Some context : \n\n  \nThere was a datascientist before me, and some intern worked on this project. It's been 4 years since the model was updated, and at that time, they built a sophisticated (or just big) pipeline to run multiple tasks : \n\n* preprocess / filter / enrich data\n* train a classifier\n* compute metrics, print graphs, export a bunch of parameters in csv / json files\n* export the model in mobile-compatible formats (CoreML for iOS, json for Android)\n* store everything in archives, upload in on our server, git operations, ...\n* validate on a set of trusted data\n* and many other things\n\nI'm not sure if I want to perform the same tasks, the context is different now.\n\nWhat bugs me, with this pipeline, is the way data is shared / passed among functions. Each task, each function, is performed on a file, on disk. (there is no need for this, the data is not massive). For example, the `train_classifier` function have one parameter \"`project_dir_path`\", and inside that project directory, it loads parameters, arguments, various stuff, and export the results, metrics, classifier, everything, **inside** that directory.\n\nOf course, the  \"`project_dir_path`\" was a hidden directory, like '`.tmp/my_dataset`', not committed or saved anywhere.\n\nEvery function is like that. It's a hell to understand what is needed for each function, what are the data, etc. By the way, the \"pipeline\" is composed of two files, with 800+ lines each.\n\nAbout me : \n\n* It's my first Python Datascience job\n* Previously I was finishing my PhD, so my Python coding practices are ... inexistant\n* Before my PhD, I was a Java software engineer. I like typed languages, I like Object Oriented Programming, self-documenting code, etc. \n\n&amp;#x200B;\n\nMy question : how do I organize this mess ? Is it a good pattern ? Am I just impatient ? \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_8owvwc5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Code and Python project web practices for datascience pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gsow1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687508005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since a few month, I work in a company on event detection with time series. I would like some recommendations on how to organize my datascience project in Python. Some context : &lt;/p&gt;\n\n&lt;p&gt;There was a datascientist before me, and some intern worked on this project. It&amp;#39;s been 4 years since the model was updated, and at that time, they built a sophisticated (or just big) pipeline to run multiple tasks : &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;preprocess / filter / enrich data&lt;/li&gt;\n&lt;li&gt;train a classifier&lt;/li&gt;\n&lt;li&gt;compute metrics, print graphs, export a bunch of parameters in csv / json files&lt;/li&gt;\n&lt;li&gt;export the model in mobile-compatible formats (CoreML for iOS, json for Android)&lt;/li&gt;\n&lt;li&gt;store everything in archives, upload in on our server, git operations, ...&lt;/li&gt;\n&lt;li&gt;validate on a set of trusted data&lt;/li&gt;\n&lt;li&gt;and many other things&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if I want to perform the same tasks, the context is different now.&lt;/p&gt;\n\n&lt;p&gt;What bugs me, with this pipeline, is the way data is shared / passed among functions. Each task, each function, is performed on a file, on disk. (there is no need for this, the data is not massive). For example, the &lt;code&gt;train_classifier&lt;/code&gt; function have one parameter &amp;quot;&lt;code&gt;project_dir_path&lt;/code&gt;&amp;quot;, and inside that project directory, it loads parameters, arguments, various stuff, and export the results, metrics, classifier, everything, &lt;strong&gt;inside&lt;/strong&gt; that directory.&lt;/p&gt;\n\n&lt;p&gt;Of course, the  &amp;quot;&lt;code&gt;project_dir_path&lt;/code&gt;&amp;quot; was a hidden directory, like &amp;#39;&lt;code&gt;.tmp/my_dataset&lt;/code&gt;&amp;#39;, not committed or saved anywhere.&lt;/p&gt;\n\n&lt;p&gt;Every function is like that. It&amp;#39;s a hell to understand what is needed for each function, what are the data, etc. By the way, the &amp;quot;pipeline&amp;quot; is composed of two files, with 800+ lines each.&lt;/p&gt;\n\n&lt;p&gt;About me : &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;It&amp;#39;s my first Python Datascience job&lt;/li&gt;\n&lt;li&gt;Previously I was finishing my PhD, so my Python coding practices are ... inexistant&lt;/li&gt;\n&lt;li&gt;Before my PhD, I was a Java software engineer. I like typed languages, I like Object Oriented Programming, self-documenting code, etc. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question : how do I organize this mess ? Is it a good pattern ? Am I just impatient ? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gsow1", "is_robot_indexable": true, "report_reasons": null, "author": "This-Librarian3339", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gsow1/code_and_python_project_web_practices_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gsow1/code_and_python_project_web_practices_for/", "subreddit_subscribers": 929749, "created_utc": 1687508005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a choice to either choose CS(Data Science) or CS(AI and ML) at my college. Which one should I choose if my goal is to work at FAANG and maybe try for quant later in my career(probably after masters)?\n\nI might also go for masters right after undergrad, so which one will have less competition at top universities?", "author_fullname": "t2_7rru4w7j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I choose a specialisation in DSE or AIML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gpgsa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687496756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a choice to either choose CS(Data Science) or CS(AI and ML) at my college. Which one should I choose if my goal is to work at FAANG and maybe try for quant later in my career(probably after masters)?&lt;/p&gt;\n\n&lt;p&gt;I might also go for masters right after undergrad, so which one will have less competition at top universities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gpgsa", "is_robot_indexable": true, "report_reasons": null, "author": "the_card_dealer", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gpgsa/should_i_choose_a_specialisation_in_dse_or_aiml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gpgsa/should_i_choose_a_specialisation_in_dse_or_aiml/", "subreddit_subscribers": 929749, "created_utc": 1687496756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "That are **not**, I repeat **not** written by Taleb.", "author_fullname": "t2_ad5yokml", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for recommended readings/lectures/materials on extreme value theory, and risk in data science.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gctgp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687462874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;That are &lt;strong&gt;not&lt;/strong&gt;, I repeat &lt;strong&gt;not&lt;/strong&gt; written by Taleb.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gctgp", "is_robot_indexable": true, "report_reasons": null, "author": "antichain", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gctgp/looking_for_recommended_readingslecturesmaterials/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gctgp/looking_for_recommended_readingslecturesmaterials/", "subreddit_subscribers": 929749, "created_utc": 1687462874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to use a chat LLM on my website. I\u2019m a full stack dev. I\u2019m confused about the AI stack.\n\nFrom my front end, where do I send the API request to the llm ? Can I Host the model on Hugging Face and api in, or do I need to host it elsewhere (presumably I do) with a gpu cloud provider like vast.ai?", "author_fullname": "t2_mfnoqbm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to host model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14gzk4b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687529351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to use a chat LLM on my website. I\u2019m a full stack dev. I\u2019m confused about the AI stack.&lt;/p&gt;\n\n&lt;p&gt;From my front end, where do I send the API request to the llm ? Can I Host the model on Hugging Face and api in, or do I need to host it elsewhere (presumably I do) with a gpu cloud provider like vast.ai?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gzk4b", "is_robot_indexable": true, "report_reasons": null, "author": "phas0ruk1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gzk4b/where_to_host_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gzk4b/where_to_host_model/", "subreddit_subscribers": 929749, "created_utc": 1687529351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, \n\nIm looking for new friends with my business model for Development AI Databases. Im open for conversation and  gain funds for our goals in that structures.", "author_fullname": "t2_73yznu39", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Idea and Peoples", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gwt72", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687521860.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, &lt;/p&gt;\n\n&lt;p&gt;Im looking for new friends with my business model for Development AI Databases. Im open for conversation and  gain funds for our goals in that structures.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gwt72", "is_robot_indexable": true, "report_reasons": null, "author": "Maleficent_Height583", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gwt72/idea_and_peoples/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gwt72/idea_and_peoples/", "subreddit_subscribers": 929749, "created_utc": 1687521860.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So every six months I get an brain MRI and annually I get a spinal MRI.  And at this point I think there are about 1 million Americans with MS and statistically about 1:100,000 people have it.\n\nYet, when I ask my MS Specialist at the Shepherd Center in Atlanta what a particular lesion might actually cause I don\u2019t get a very convincing answer.  \n\nBut every six months we do a new MRI and a new physical exam and we go over all my symptoms like I\u2019m sure a huge number of us do.  \n\nIf they were all in one database I feel like statistically we could associate a level of disability with number and size of lesions.  We could map symptoms to locations better than what we have now.  \n\nDoes anybody know of an existing database of MRIs where this work is happening or any studies that go over this?", "author_fullname": "t2_5mr7f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does an MS MRI database exist?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gv4dx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687516626.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So every six months I get an brain MRI and annually I get a spinal MRI.  And at this point I think there are about 1 million Americans with MS and statistically about 1:100,000 people have it.&lt;/p&gt;\n\n&lt;p&gt;Yet, when I ask my MS Specialist at the Shepherd Center in Atlanta what a particular lesion might actually cause I don\u2019t get a very convincing answer.  &lt;/p&gt;\n\n&lt;p&gt;But every six months we do a new MRI and a new physical exam and we go over all my symptoms like I\u2019m sure a huge number of us do.  &lt;/p&gt;\n\n&lt;p&gt;If they were all in one database I feel like statistically we could associate a level of disability with number and size of lesions.  We could map symptoms to locations better than what we have now.  &lt;/p&gt;\n\n&lt;p&gt;Does anybody know of an existing database of MRIs where this work is happening or any studies that go over this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gv4dx", "is_robot_indexable": true, "report_reasons": null, "author": "Lochstar", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gv4dx/does_an_ms_mri_database_exist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gv4dx/does_an_ms_mri_database_exist/", "subreddit_subscribers": 929749, "created_utc": 1687516626.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everybody,\n\nI just wanted to start a discussion on here as a thought exercise but also to learn from you guys. As an early-career professional (I am finishing my MSc in wildlife biology but transitioning into data science), a debate that I've been having is finding the balance between efficacy and efficiency when developing models. \n\nMost of my experience has been academia, so my bosses/mentors emphasized causal inference when developing models. But now that I am transitioning into industry work, I have been learning that most \"real-world\" models and ML algorithms are a balancing act of different methods/objectives/timelines/etc... \n\nQuestion is... What are some of these considerations in your day-to-day work and how do you go about balancing them? ", "author_fullname": "t2_3iylg8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding the balance between efficacy and efficiency.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gp4zo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687495724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody,&lt;/p&gt;\n\n&lt;p&gt;I just wanted to start a discussion on here as a thought exercise but also to learn from you guys. As an early-career professional (I am finishing my MSc in wildlife biology but transitioning into data science), a debate that I&amp;#39;ve been having is finding the balance between efficacy and efficiency when developing models. &lt;/p&gt;\n\n&lt;p&gt;Most of my experience has been academia, so my bosses/mentors emphasized causal inference when developing models. But now that I am transitioning into industry work, I have been learning that most &amp;quot;real-world&amp;quot; models and ML algorithms are a balancing act of different methods/objectives/timelines/etc... &lt;/p&gt;\n\n&lt;p&gt;Question is... What are some of these considerations in your day-to-day work and how do you go about balancing them? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gp4zo", "is_robot_indexable": true, "report_reasons": null, "author": "WOCIII", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gp4zo/finding_the_balance_between_efficacy_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gp4zo/finding_the_balance_between_efficacy_and/", "subreddit_subscribers": 929749, "created_utc": 1687495724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI\u2019m an incoming graduate student getting my masters in DS. My program offers a few specializations: \n1. Analytics and Modeling (focuses on predictive modeling) \n2. Analytics Management (focuses on business operations) \n3. Artificial Intelligence \n4. Data Engineering \n\nI was wondering given the job market, which specialization should I choose to be exposed to the most job opportunities?", "author_fullname": "t2_diaem5eh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Specialization for MSDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gksyf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687482821.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m an incoming graduate student getting my masters in DS. My program offers a few specializations: \n1. Analytics and Modeling (focuses on predictive modeling) \n2. Analytics Management (focuses on business operations) \n3. Artificial Intelligence \n4. Data Engineering &lt;/p&gt;\n\n&lt;p&gt;I was wondering given the job market, which specialization should I choose to be exposed to the most job opportunities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gksyf", "is_robot_indexable": true, "report_reasons": null, "author": "eggsbaconcheeze", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gksyf/specialization_for_msds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gksyf/specialization_for_msds/", "subreddit_subscribers": 929749, "created_utc": 1687482821.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, i'm a fresh data science graduate, i applied to a job that states data engineer, but i was surprised on the interview invitation that it's a data officer role,\n\ni have never studied or worked in such area, nor there's enough information online to read, i don't know what the hell they gonna ask me on the interview, i was thinking of backing off, but it looks like a very big company , plus, i need the experience in this stage,\n\nthe interview is in 3 days\n\nis that enough to learn about this? and if yes, can you guys suggest any good sources about this? a last question, it might sound dumb, but, is it harder than other data science roles (analyst, administrator, engineer )?", "author_fullname": "t2_55642ldz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data officer job interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gjldo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687479390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, i&amp;#39;m a fresh data science graduate, i applied to a job that states data engineer, but i was surprised on the interview invitation that it&amp;#39;s a data officer role,&lt;/p&gt;\n\n&lt;p&gt;i have never studied or worked in such area, nor there&amp;#39;s enough information online to read, i don&amp;#39;t know what the hell they gonna ask me on the interview, i was thinking of backing off, but it looks like a very big company , plus, i need the experience in this stage,&lt;/p&gt;\n\n&lt;p&gt;the interview is in 3 days&lt;/p&gt;\n\n&lt;p&gt;is that enough to learn about this? and if yes, can you guys suggest any good sources about this? a last question, it might sound dumb, but, is it harder than other data science roles (analyst, administrator, engineer )?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gjldo", "is_robot_indexable": true, "report_reasons": null, "author": "ARA-GOD", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gjldo/data_officer_job_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gjldo/data_officer_job_interview/", "subreddit_subscribers": 929749, "created_utc": 1687479390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\nI'm working on a project with a common kaggle dataset, trying to use a random forest to predict a binary feature from ~20 binary, numerical and one categorical variable with 3 ordinal categories.\nTarget variable is pretty balanced, but one particular binary predictor and the 3-level categorical variable are kinda imbalanced, 80-20 % and 45-10-45 %, respectively.\nWhat is the impact of this imbalance? If I were to train my data on this set, would the model be negatively affected? Note that the dataset is pretty large, we're talking 100k observations for the training set alone. Is there need to resample my dataset?\n\n---Dumbly Afraid To Ask", "author_fullname": "t2_2p4jjqle", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imbalance in predictors: what to do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gg47c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687470489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nI&amp;#39;m working on a project with a common kaggle dataset, trying to use a random forest to predict a binary feature from ~20 binary, numerical and one categorical variable with 3 ordinal categories.\nTarget variable is pretty balanced, but one particular binary predictor and the 3-level categorical variable are kinda imbalanced, 80-20 % and 45-10-45 %, respectively.\nWhat is the impact of this imbalance? If I were to train my data on this set, would the model be negatively affected? Note that the dataset is pretty large, we&amp;#39;re talking 100k observations for the training set alone. Is there need to resample my dataset?&lt;/p&gt;\n\n&lt;p&gt;---Dumbly Afraid To Ask&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gg47c", "is_robot_indexable": true, "report_reasons": null, "author": "aceofmaz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gg47c/imbalance_in_predictors_what_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gg47c/imbalance_in_predictors_what_to_do/", "subreddit_subscribers": 929749, "created_utc": 1687470489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys. \nTLDR: I have an image classification problem for fraud detection. But the thing is, my targets for images are not correct(&gt;50%) times. How should I go about it? Any suggestions to read/explore about things.\n\nLong read below:\nThe use case is for identifying frauds. In a certain setup, an agency is required to build some public assets - like ponds, houses, dams, roads etc.  And the agency is required to submit photos as proof. So we are kind of checker, want to build a model that should flag when photo is suspicious, not of right category . One approach is to classify the image, and if the model predicted category is different then we can flag. We are going with this one for now. So for this approach we need Labelled dataset. We have million of images that have been uploaded so far , but our image, category pair may not be correct  in case there have been frauds. And frauds percentage is upto 60-70%. So you see our label is kind of noisy.\n\nSo which approaches are out there for learning from noisy labels? Some sort of Self supervised learning, or other learning paradigm is what I could think of.\n\nThanks.", "author_fullname": "t2_9yo5phby", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Image classification with noisy labels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g8i0k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687452813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. \nTLDR: I have an image classification problem for fraud detection. But the thing is, my targets for images are not correct(&amp;gt;50%) times. How should I go about it? Any suggestions to read/explore about things.&lt;/p&gt;\n\n&lt;p&gt;Long read below:\nThe use case is for identifying frauds. In a certain setup, an agency is required to build some public assets - like ponds, houses, dams, roads etc.  And the agency is required to submit photos as proof. So we are kind of checker, want to build a model that should flag when photo is suspicious, not of right category . One approach is to classify the image, and if the model predicted category is different then we can flag. We are going with this one for now. So for this approach we need Labelled dataset. We have million of images that have been uploaded so far , but our image, category pair may not be correct  in case there have been frauds. And frauds percentage is upto 60-70%. So you see our label is kind of noisy.&lt;/p&gt;\n\n&lt;p&gt;So which approaches are out there for learning from noisy labels? Some sort of Self supervised learning, or other learning paradigm is what I could think of.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g8i0k", "is_robot_indexable": true, "report_reasons": null, "author": "EducatorDiligent5114", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g8i0k/image_classification_with_noisy_labels/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g8i0k/image_classification_with_noisy_labels/", "subreddit_subscribers": 929749, "created_utc": 1687452813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone!\n\nI hope you're all doing well. I wanted to reach out to those of you who have worked or are currently working as interns in product-based companies. I have a couple of questions and would greatly appreciate your insights and experiences.\n\nThank you so much in advance! Looking forward to your responses and discussions", "author_fullname": "t2_7w8cmdht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interning at Product-Based Companies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g7z1b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687451084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all doing well. I wanted to reach out to those of you who have worked or are currently working as interns in product-based companies. I have a couple of questions and would greatly appreciate your insights and experiences.&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance! Looking forward to your responses and discussions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g7z1b", "is_robot_indexable": true, "report_reasons": null, "author": "Batman_bruce_wayne0", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g7z1b/interning_at_productbased_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g7z1b/interning_at_productbased_companies/", "subreddit_subscribers": 929749, "created_utc": 1687451084.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My team has created a few webhooks into data tools like Datadog, Sentry, AWS etc. We don't personally use these tools, but need a way to test the success/failure of the webhooks. Does anyone know of any way to test these webhooks without our own account? Snyk offers a Postman testing solution but I haven't seen any other methods. There are a ton of tools in this space (Hex, Mode, Equals etc) so there has to be a solution i'm missing!", "author_fullname": "t2_g400fo1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing Webhook connection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g6ipk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687447635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team has created a few webhooks into data tools like Datadog, Sentry, AWS etc. We don&amp;#39;t personally use these tools, but need a way to test the success/failure of the webhooks. Does anyone know of any way to test these webhooks without our own account? Snyk offers a Postman testing solution but I haven&amp;#39;t seen any other methods. There are a ton of tools in this space (Hex, Mode, Equals etc) so there has to be a solution i&amp;#39;m missing!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g6ipk", "is_robot_indexable": true, "report_reasons": null, "author": "rmilaz18", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g6ipk/testing_webhook_connection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g6ipk/testing_webhook_connection/", "subreddit_subscribers": 929749, "created_utc": 1687447635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently a GIS analyst at an electrical utility and looking to move towards a more data science focused role at my existing company (I like the company, but GIS there is a dead end career-wise while the DS team is doing some really innovative stuff).\n\nI\u2019ve done a little stats and data science as part of my GIS degree (masters) but not much in the 5 years since I graduated. Figured I would start by learning the tools I know the teams uses:\n- Python (I am already okay at Python in general- just need to brush up on DS specific  modules)\n- PowerBI (all I\u2019ve done with it thus far is use other peoples dashboards)\n- Microsoft SQL server\n- Oracle\n\nAny good resources for learning the above as well as general DS principles? (There\u2019s a lot of stuff to choose from) Ideally I\u2019d like to get to at least the level of an average new DS graduate. I have a decent grasp of an adjacent discipline coming from GIS so any way I could utilize my existing geostatstical knowledge would be useful. \n\nIf there is anyone working at an electrical utility in a DS role it would be really great to get some advice - the area I really want to get into is power quality monitoring and general power use monitoring. We are finally at the stage where we have enough real data that we can start doing decent stats to help the engineering teams (where I work currently).\n\nAppreciate any advice, not super keen to go get another MSc but need to upskill. I don\u2019t mind spending decent money if the training is worth it.", "author_fullname": "t2_4diy5obj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datascience basics coming from GIS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14gzd5v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687528883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a GIS analyst at an electrical utility and looking to move towards a more data science focused role at my existing company (I like the company, but GIS there is a dead end career-wise while the DS team is doing some really innovative stuff).&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve done a little stats and data science as part of my GIS degree (masters) but not much in the 5 years since I graduated. Figured I would start by learning the tools I know the teams uses:\n- Python (I am already okay at Python in general- just need to brush up on DS specific  modules)\n- PowerBI (all I\u2019ve done with it thus far is use other peoples dashboards)\n- Microsoft SQL server\n- Oracle&lt;/p&gt;\n\n&lt;p&gt;Any good resources for learning the above as well as general DS principles? (There\u2019s a lot of stuff to choose from) Ideally I\u2019d like to get to at least the level of an average new DS graduate. I have a decent grasp of an adjacent discipline coming from GIS so any way I could utilize my existing geostatstical knowledge would be useful. &lt;/p&gt;\n\n&lt;p&gt;If there is anyone working at an electrical utility in a DS role it would be really great to get some advice - the area I really want to get into is power quality monitoring and general power use monitoring. We are finally at the stage where we have enough real data that we can start doing decent stats to help the engineering teams (where I work currently).&lt;/p&gt;\n\n&lt;p&gt;Appreciate any advice, not super keen to go get another MSc but need to upskill. I don\u2019t mind spending decent money if the training is worth it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gzd5v", "is_robot_indexable": true, "report_reasons": null, "author": "Mirthgiver", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gzd5v/datascience_basics_coming_from_gis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gzd5v/datascience_basics_coming_from_gis/", "subreddit_subscribers": 929749, "created_utc": 1687528883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We are thinking about doing our dashboards with tableau, since we currently use a rather complicated tool now. We mainly want to switch so that employees who don't know a lot of SQL/Python can adjust the dashboards without any issues. Is tableau the right tool for this?", "author_fullname": "t2_6q7a2p0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone got experience with complex tableau dashboards?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14guq0e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687515314.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are thinking about doing our dashboards with tableau, since we currently use a rather complicated tool now. We mainly want to switch so that employees who don&amp;#39;t know a lot of SQL/Python can adjust the dashboards without any issues. Is tableau the right tool for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14guq0e", "is_robot_indexable": true, "report_reasons": null, "author": "jeffrey_56", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14guq0e/anyone_got_experience_with_complex_tableau/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14guq0e/anyone_got_experience_with_complex_tableau/", "subreddit_subscribers": 929749, "created_utc": 1687515314.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\n\nI am aware of rule 7 (about StackExchange), but I asked my question there and haven't received any answers so far, so I thought I'd try it here since it is a little time-sensitive.\n\nI have a dataframe with the columns date (datetime64), NDVI (float64) and field\\_id (object). I want to detect outliers in NDVI measurements using field\\_id as a grouping variable. This way, I hope the algorithm accepts aberrant behaviour specific to individual fields and marks as outliers mostly anomalies that affect multiple fields simultaneously.\n\nValues in field\\_id are formed of letters and numbers (examples: KM1, KM106, LM27, LM10). Of course, using such an object directly gives me the error:\n\n&gt;ValueError: could not convert string to float: 'LM10'\n\nI have read about two ways to use such values in machine learning: Label and One-Hot encoding. However, the IDs are completely independent of one another (discarding Label as an option) and I am hesitant to try One-Hot because I have about 165 unique IDs.\n\nWhat is the most practical way of using extensive object columns as variables in Isolation Forest?\n\nI am working with IsolationForest from sklearn.ensemble", "author_fullname": "t2_7x010xb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adding extensive object column as extra variable in Isolation Forest model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gqjzl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687500446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I am aware of rule 7 (about StackExchange), but I asked my question there and haven&amp;#39;t received any answers so far, so I thought I&amp;#39;d try it here since it is a little time-sensitive.&lt;/p&gt;\n\n&lt;p&gt;I have a dataframe with the columns date (datetime64), NDVI (float64) and field_id (object). I want to detect outliers in NDVI measurements using field_id as a grouping variable. This way, I hope the algorithm accepts aberrant behaviour specific to individual fields and marks as outliers mostly anomalies that affect multiple fields simultaneously.&lt;/p&gt;\n\n&lt;p&gt;Values in field_id are formed of letters and numbers (examples: KM1, KM106, LM27, LM10). Of course, using such an object directly gives me the error:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;ValueError: could not convert string to float: &amp;#39;LM10&amp;#39;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I have read about two ways to use such values in machine learning: Label and One-Hot encoding. However, the IDs are completely independent of one another (discarding Label as an option) and I am hesitant to try One-Hot because I have about 165 unique IDs.&lt;/p&gt;\n\n&lt;p&gt;What is the most practical way of using extensive object columns as variables in Isolation Forest?&lt;/p&gt;\n\n&lt;p&gt;I am working with IsolationForest from sklearn.ensemble&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gqjzl", "is_robot_indexable": true, "report_reasons": null, "author": "Cadillac-Blood", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gqjzl/adding_extensive_object_column_as_extra_variable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gqjzl/adding_extensive_object_column_as_extra_variable/", "subreddit_subscribers": 929749, "created_utc": 1687500446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, I\u2019m new to data science and I\u2019m working in a kaggle notebook. I\u2019m trying to sort aggregated data in a data frame. In convert the column to a category and then sort. The sorting works fine, but then I lose all aggregated data. I can send the code snippet in a bit, if anyone is willing to help or knows the best place to go to help. \n\nFYI: Chatgpt, stackoverflow, Google and a few hours of different methods and yet no solutions. :/\n\nI should say I\u2019m sorting by the column and row level values in the column. In sql it would be an order by case column name when x then 1 when y then 2 etc.\n\nHere\u2019s one of the iterations of my script. I accidentally deleted the other one. :/ \n\ndf2=df.groupby([\u2018colname\u2019,\u2019col2\u2019])[col3].mean().unstack.fillna(0)\n\ndf3= df2.sort_values(by = [\u2018val1\u2019,\u2019val2\u2019,\u2019val3\u2019])\n\ndf3", "author_fullname": "t2_91slmnig", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New to Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g9zxt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687458463.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687456281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I\u2019m new to data science and I\u2019m working in a kaggle notebook. I\u2019m trying to sort aggregated data in a data frame. In convert the column to a category and then sort. The sorting works fine, but then I lose all aggregated data. I can send the code snippet in a bit, if anyone is willing to help or knows the best place to go to help. &lt;/p&gt;\n\n&lt;p&gt;FYI: Chatgpt, stackoverflow, Google and a few hours of different methods and yet no solutions. :/&lt;/p&gt;\n\n&lt;p&gt;I should say I\u2019m sorting by the column and row level values in the column. In sql it would be an order by case column name when x then 1 when y then 2 etc.&lt;/p&gt;\n\n&lt;p&gt;Here\u2019s one of the iterations of my script. I accidentally deleted the other one. :/ &lt;/p&gt;\n\n&lt;p&gt;df2=df.groupby([\u2018colname\u2019,\u2019col2\u2019])[col3].mean().unstack.fillna(0)&lt;/p&gt;\n\n&lt;p&gt;df3= df2.sort_values(by = [\u2018val1\u2019,\u2019val2\u2019,\u2019val3\u2019])&lt;/p&gt;\n\n&lt;p&gt;df3&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g9zxt", "is_robot_indexable": true, "report_reasons": null, "author": "Adept_Car_9997", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g9zxt/new_to_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g9zxt/new_to_data_science/", "subreddit_subscribers": 929749, "created_utc": 1687456281.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}