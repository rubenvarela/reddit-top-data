{"kind": "Listing", "data": {"after": "t3_14g7z1b", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This is something that's bothered me since I started my DS journey.  \n   \nI almost always use median over average to for comparisons because I've learned over the years that most data is skewed and not evenly disturbed. However, I feel like I'm the only person that does this....  even though basic stats teach to use median.  \n  \nThoughts?", "author_fullname": "t2_9p4skdeg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is it so common to use average/mean instead of median when most datasets are skewed and not evenly distributed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g557m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 192, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 192, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687444350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is something that&amp;#39;s bothered me since I started my DS journey.  &lt;/p&gt;\n\n&lt;p&gt;I almost always use median over average to for comparisons because I&amp;#39;ve learned over the years that most data is skewed and not evenly disturbed. However, I feel like I&amp;#39;m the only person that does this....  even though basic stats teach to use median.  &lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g557m", "is_robot_indexable": true, "report_reasons": null, "author": "startup_biz_36", "discussion_type": null, "num_comments": 124, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g557m/why_is_it_so_common_to_use_averagemean_instead_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g557m/why_is_it_so_common_to_use_averagemean_instead_of/", "subreddit_subscribers": 929606, "created_utc": 1687444350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a data analyst, considering furthering my education to work in data science. I currently work for a very well established company that has absolutely atrocious data due to poor IT infrastructure. For example, a visitor will click a tab on their website but due to site latency, the click will be recorded 18 times. I spend all day controlling for messes like this on the reporting side, instead of doing actual real analysis, because the company will not pay for IT to fix the root cause of the problem. \n\nI know some data clean up is part of the field, but I don\u2019t want to spend the rest of my career dealing with this level of incompetence, and if that\u2019s going to be a big part of this job no matter where I go, I don\u2019t know if it\u2019s the right field for me. \n\nI don\u2019t know anyone else outside of my company who works in this kind of field, so can others weigh in here as to whether it\u2019s common to spend your day essentially functioning as a cheaper workaround to major IT issues like this?", "author_fullname": "t2_tepj9g73", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How common is it for data at an established company to be a complete disaster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14glots", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 92, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 92, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687485295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data analyst, considering furthering my education to work in data science. I currently work for a very well established company that has absolutely atrocious data due to poor IT infrastructure. For example, a visitor will click a tab on their website but due to site latency, the click will be recorded 18 times. I spend all day controlling for messes like this on the reporting side, instead of doing actual real analysis, because the company will not pay for IT to fix the root cause of the problem. &lt;/p&gt;\n\n&lt;p&gt;I know some data clean up is part of the field, but I don\u2019t want to spend the rest of my career dealing with this level of incompetence, and if that\u2019s going to be a big part of this job no matter where I go, I don\u2019t know if it\u2019s the right field for me. &lt;/p&gt;\n\n&lt;p&gt;I don\u2019t know anyone else outside of my company who works in this kind of field, so can others weigh in here as to whether it\u2019s common to spend your day essentially functioning as a cheaper workaround to major IT issues like this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14glots", "is_robot_indexable": true, "report_reasons": null, "author": "ItsaShoreThing1", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14glots/how_common_is_it_for_data_at_an_established/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14glots/how_common_is_it_for_data_at_an_established/", "subreddit_subscribers": 929606, "created_utc": 1687485295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was just on a store's website and switched over to Reddit and, when I did, there was an ad for the exact store I'd been looking at right there in my Reddit feed.\n\nI get that Google Ads can track me through Chrome and Facebook can track me with their app, but I don't have the Reddit app. I only ever visit it through a browser. How are they tracking my behavior on other websites?\n\nI am killing myself trying to get basic, reliable attribution in place for my clients, so I'm super curious how Reddit is pulling that off.\n\n*Edit: Alright, this was a stupid question.*", "author_fullname": "t2_bxdnw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ELI5: How is Reddit tracking my behavior on other websites when I don't have the app? And how can I do that too?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g4r95", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687444105.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687443437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was just on a store&amp;#39;s website and switched over to Reddit and, when I did, there was an ad for the exact store I&amp;#39;d been looking at right there in my Reddit feed.&lt;/p&gt;\n\n&lt;p&gt;I get that Google Ads can track me through Chrome and Facebook can track me with their app, but I don&amp;#39;t have the Reddit app. I only ever visit it through a browser. How are they tracking my behavior on other websites?&lt;/p&gt;\n\n&lt;p&gt;I am killing myself trying to get basic, reliable attribution in place for my clients, so I&amp;#39;m super curious how Reddit is pulling that off.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Edit: Alright, this was a stupid question.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g4r95", "is_robot_indexable": true, "report_reasons": null, "author": "takenorinvalid", "discussion_type": null, "num_comments": 45, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g4r95/eli5_how_is_reddit_tracking_my_behavior_on_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g4r95/eli5_how_is_reddit_tracking_my_behavior_on_other/", "subreddit_subscribers": 929606, "created_utc": 1687443437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a data scientist, at least that\u2019s what my job title says. In my company I have worked on traditional ML modelling, building vision models on azure and also some big data stuff using kafka, graph db. I don\u2019t know what skills/ expertise do I need to have to work at these large tech companies or earn high salary.\nSometimes it feels like I can do any type of work thrown at me but other times I still feel incomplete in my ds, ml skills.", "author_fullname": "t2_ifsmh8cn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What kind of different work do highly paid data scientists and ML engineers do than those with low to medium salaries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gnnmq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687491058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data scientist, at least that\u2019s what my job title says. In my company I have worked on traditional ML modelling, building vision models on azure and also some big data stuff using kafka, graph db. I don\u2019t know what skills/ expertise do I need to have to work at these large tech companies or earn high salary.\nSometimes it feels like I can do any type of work thrown at me but other times I still feel incomplete in my ds, ml skills.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gnnmq", "is_robot_indexable": true, "report_reasons": null, "author": "Quest_to_peace", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gnnmq/what_kind_of_different_work_do_highly_paid_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gnnmq/what_kind_of_different_work_do_highly_paid_data/", "subreddit_subscribers": 929606, "created_utc": 1687491058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I read a bit of a thesis paper discussing the idea that using PCA to pre-whiten before ICA should not include any form of principle component reduction due to the appearance of \"eiganspecters\" which they identify as artifacts that appear as a result of the aforementioned reduction. I haven't seen much discussion on this so I wanted to ask what you all thought about this in particular. The thesis is below: \n\n[https://ourarchive.otago.ac.nz/handle/10523/4459](https://ourarchive.otago.ac.nz/handle/10523/4459)\n\n&amp;#x200B;", "author_fullname": "t2_l0f5k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are eiganspecters an actual issue?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gkzw6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687483346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read a bit of a thesis paper discussing the idea that using PCA to pre-whiten before ICA should not include any form of principle component reduction due to the appearance of &amp;quot;eiganspecters&amp;quot; which they identify as artifacts that appear as a result of the aforementioned reduction. I haven&amp;#39;t seen much discussion on this so I wanted to ask what you all thought about this in particular. The thesis is below: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ourarchive.otago.ac.nz/handle/10523/4459\"&gt;https://ourarchive.otago.ac.nz/handle/10523/4459&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gkzw6", "is_robot_indexable": true, "report_reasons": null, "author": "figgedy1", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gkzw6/are_eiganspecters_an_actual_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gkzw6/are_eiganspecters_an_actual_issue/", "subreddit_subscribers": 929606, "created_utc": 1687483346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nSorry if this is the wrong place to ask, please let me know if there's a better subreddit. \n\nI am relatively new into the data field and began learning SQL on the job about 2 years ago. I started taking courses learning python about 6 months ago and wanted to find an applicable use in my role. We currently have a vendor where we obtain their data via a spreadsheet that corrupts frequently. The vendor has an API but at this point no one has attempted that method until I started learning python.\n\nI am currently at the point where I am obtaining data via the API and have gone through the whole oauth process, but it has been very manual. My issue is that I am having trouble automating this, and I will break down the steps I received from the vendor.\n\n&amp;#x200B;\n\n1. The initial API call must be done via a browser that authenticates the account I have with the vendor. An auth code is then provided via the browser URL that you are directed to.\n2. That auth code is then passed in the post request and an access token/refresh token is retrieved from the result set. The refresh token lasts for 30 days. The auth code that is initially provided expires after 10 minutes and is only good for one attempt, so I do not want to call that via that method again.\n3. Subsequent API calls can be used using the refresh token (via a different grant type), after approx 13 days they will send a a new refresh token in the results.\n4. We are storing the refresh token in an azure secret to reference it.\n\nSince this is my first time utilizing this method to obtain data, I am not sure the most efficient way/best practices to go about this.\n\nIdeally, I would like this to be as automated as possible. I want to avoid the \"auth code\"/browser api call and just want to utilize the refresh token grant type. Below is a basic outline of my code.\n\n&amp;#x200B;\n\nimport libraries\n\ndef function initial\\_call()\n\ndef function refresh\\_call()\n\nvariable to skip initial call (I am manually changing this after the initial call)\n\ninitial\\_call() returns refresh token\n\nrefresh\\_token = initialcall()\n\nrefresh\\_call() (this references the refresh\\_token from the initial call)  \n\n\naccess\\_token is retrieved and then passed to the api call for data  \n\n\nWhat is the best way skip the initial call once it has been done? Also - I will need to update the refresh token once we receive a new one from the refresh\\_call(), the issue is they only send it in the response when it is updated (after 13 days).\n\n&amp;#x200B;\n\nThanks for any help/insight. \n\n&amp;#x200B;", "author_fullname": "t2_5rj9fmzhq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Obtaining Data via API Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gmh88", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687487541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Sorry if this is the wrong place to ask, please let me know if there&amp;#39;s a better subreddit. &lt;/p&gt;\n\n&lt;p&gt;I am relatively new into the data field and began learning SQL on the job about 2 years ago. I started taking courses learning python about 6 months ago and wanted to find an applicable use in my role. We currently have a vendor where we obtain their data via a spreadsheet that corrupts frequently. The vendor has an API but at this point no one has attempted that method until I started learning python.&lt;/p&gt;\n\n&lt;p&gt;I am currently at the point where I am obtaining data via the API and have gone through the whole oauth process, but it has been very manual. My issue is that I am having trouble automating this, and I will break down the steps I received from the vendor.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The initial API call must be done via a browser that authenticates the account I have with the vendor. An auth code is then provided via the browser URL that you are directed to.&lt;/li&gt;\n&lt;li&gt;That auth code is then passed in the post request and an access token/refresh token is retrieved from the result set. The refresh token lasts for 30 days. The auth code that is initially provided expires after 10 minutes and is only good for one attempt, so I do not want to call that via that method again.&lt;/li&gt;\n&lt;li&gt;Subsequent API calls can be used using the refresh token (via a different grant type), after approx 13 days they will send a a new refresh token in the results.&lt;/li&gt;\n&lt;li&gt;We are storing the refresh token in an azure secret to reference it.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Since this is my first time utilizing this method to obtain data, I am not sure the most efficient way/best practices to go about this.&lt;/p&gt;\n\n&lt;p&gt;Ideally, I would like this to be as automated as possible. I want to avoid the &amp;quot;auth code&amp;quot;/browser api call and just want to utilize the refresh token grant type. Below is a basic outline of my code.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;import libraries&lt;/p&gt;\n\n&lt;p&gt;def function initial_call()&lt;/p&gt;\n\n&lt;p&gt;def function refresh_call()&lt;/p&gt;\n\n&lt;p&gt;variable to skip initial call (I am manually changing this after the initial call)&lt;/p&gt;\n\n&lt;p&gt;initial_call() returns refresh token&lt;/p&gt;\n\n&lt;p&gt;refresh_token = initialcall()&lt;/p&gt;\n\n&lt;p&gt;refresh_call() (this references the refresh_token from the initial call)  &lt;/p&gt;\n\n&lt;p&gt;access_token is retrieved and then passed to the api call for data  &lt;/p&gt;\n\n&lt;p&gt;What is the best way skip the initial call once it has been done? Also - I will need to update the refresh token once we receive a new one from the refresh_call(), the issue is they only send it in the response when it is updated (after 13 days).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks for any help/insight. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gmh88", "is_robot_indexable": true, "report_reasons": null, "author": "Brave-Carrot5429", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gmh88/obtaining_data_via_api_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gmh88/obtaining_data_via_api_question/", "subreddit_subscribers": 929606, "created_utc": 1687487541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know how to read code. I can write scripts. I am just slow as shit. I have been using GPT4 for data science lately. I am able to iterate through to create a full massive set of code within 1-2 hours which would have taken me 10 hours to write. I just used it to create a code to create about 600  individualized 20 page reports. It worked it was accurate. I am able to catch when it messes up, and I am able to redirect it or tell it to get it's shit together.\n\n Everyone in my dept acknowledges that my productivity has soared and they are even talking about promoting me. GPT4 is a crutch, but it's also enabling me to get through so much. It also helps me structure my thoughts. Like I have an analysis in mind and I write down the analysis and tell it to structure the plan around the analysis and it gives me where I should start and when I should stop.\n\nDoes this make me less of a data scientist? Am I less qualified?", "author_fullname": "t2_kw1h2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Slow coder, reliant on GPT4. Am I doomed?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gjebh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687478838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know how to read code. I can write scripts. I am just slow as shit. I have been using GPT4 for data science lately. I am able to iterate through to create a full massive set of code within 1-2 hours which would have taken me 10 hours to write. I just used it to create a code to create about 600  individualized 20 page reports. It worked it was accurate. I am able to catch when it messes up, and I am able to redirect it or tell it to get it&amp;#39;s shit together.&lt;/p&gt;\n\n&lt;p&gt;Everyone in my dept acknowledges that my productivity has soared and they are even talking about promoting me. GPT4 is a crutch, but it&amp;#39;s also enabling me to get through so much. It also helps me structure my thoughts. Like I have an analysis in mind and I write down the analysis and tell it to structure the plan around the analysis and it gives me where I should start and when I should stop.&lt;/p&gt;\n\n&lt;p&gt;Does this make me less of a data scientist? Am I less qualified?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gjebh", "is_robot_indexable": true, "report_reasons": null, "author": "frescoj10", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gjebh/slow_coder_reliant_on_gpt4_am_i_doomed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gjebh/slow_coder_reliant_on_gpt4_am_i_doomed/", "subreddit_subscribers": 929606, "created_utc": 1687478838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_kv54kocp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Understanding Gradient Descent in Regression Before you dive into Neural Networks!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_14gbbzi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6wVtQEvRoo6UZUqz3Tqo29kdd3DgRqSYd6FVhAEdaZU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1687459399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@ilyasaoudata/you-should-understand-backpropagation-in-regression-before-diving-into-neural-networks-5e08d48d69e6", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?auto=webp&amp;v=enabled&amp;s=1fe9b3de72c85fc98d414b6fa25b20d3309342e7", "width": 699, "height": 393}, "resolutions": [{"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=26ffc3355391683a428d3f4a57a1ae1e48d4db63", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=eed54e80ca02f3ebe41b1c4cca5647cb81816d53", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=33297d5ff4287de59cb9fd2bf47a64ba9dbe22dc", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/gal4NzyUTP9qYpSpSTyN555R9lU1BRGbMuy9X64UXmc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=e2b103c6423dc869ed624d3a26762fa04f4fb39d", "width": 640, "height": 359}], "variants": {}, "id": "GEtK8rTmTJ9Gfqr6ofB3NKxdlBPmFKQDAxUO4HBYv_0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gbbzi", "is_robot_indexable": true, "report_reasons": null, "author": "AIandSTUFF", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gbbzi/understanding_gradient_descent_in_regression/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@ilyasaoudata/you-should-understand-backpropagation-in-regression-before-diving-into-neural-networks-5e08d48d69e6", "subreddit_subscribers": 929606, "created_utc": 1687459399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I use ChatGPT a lot for getting code snippets and examples, especially for things like matplotlib where I mostly care about just getting the plot I want. I thought it might be nice to run that code right in ChatGPT to see the output and verify that it does what I want.\n\nI hope it may be helpful to others, too!\n\n[Here is the extension](https://chrome.google.com/webstore/detail/jpt/hhpkcgbmfdclebniepgkgnfmpbgijoaf)", "author_fullname": "t2_8fn70sz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I made a chrome extension that runs Python code in ChatGPT", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g7xn8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1687487025.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1687450982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I use ChatGPT a lot for getting code snippets and examples, especially for things like matplotlib where I mostly care about just getting the plot I want. I thought it might be nice to run that code right in ChatGPT to see the output and verify that it does what I want.&lt;/p&gt;\n\n&lt;p&gt;I hope it may be helpful to others, too!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://chrome.google.com/webstore/detail/jpt/hhpkcgbmfdclebniepgkgnfmpbgijoaf\"&gt;Here is the extension&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/zRLXytsXkAvondQg2jm8V5kwxKCVibE9ljSMnJvHCSE.jpg?auto=webp&amp;v=enabled&amp;s=06402b97b9b26da308c389030ab6494da6e8f36e", "width": 128, "height": 128}, "resolutions": [{"url": "https://external-preview.redd.it/zRLXytsXkAvondQg2jm8V5kwxKCVibE9ljSMnJvHCSE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4a18e2981ad62e200bc914369df4e06af57ac16f", "width": 108, "height": 108}], "variants": {}, "id": "J7xyO_09AUlVqVCQPbKxunwW_tcG77lglYyot720LJM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g7xn8", "is_robot_indexable": true, "report_reasons": null, "author": "latticepath", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g7xn8/i_made_a_chrome_extension_that_runs_python_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g7xn8/i_made_a_chrome_extension_that_runs_python_code/", "subreddit_subscribers": 929606, "created_utc": 1687450982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work as a data science intern for a financial group that mostly deals with annuities. Let\u2019s say I have a dataframe with 170,000 observations. And each observation represents a financial professional that could prospectively sell our products. I have mostly categorical data on these financial professionals that was collected at insurance conferences. So I have collected all of the categorical variables that have a reasonable number of categories and not a lot of null values and am prepping them for insertion into kmodes. My question is regarding category distribution. Let\u2019s say I have a category that indicates whether or not the financial professional has preferences on receiving updates from our firm. And the categories are true and false. There are 134,346 true values, 30,348 false values, and 5411 null values. I can fill the null values with \u201cunknown\u201d or the mode of True. But does the uneven distribution of this category mean that this category is not useful to kmodes?", "author_fullname": "t2_7a9ejl0y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about kmodes\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g3e1f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687440013.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a data science intern for a financial group that mostly deals with annuities. Let\u2019s say I have a dataframe with 170,000 observations. And each observation represents a financial professional that could prospectively sell our products. I have mostly categorical data on these financial professionals that was collected at insurance conferences. So I have collected all of the categorical variables that have a reasonable number of categories and not a lot of null values and am prepping them for insertion into kmodes. My question is regarding category distribution. Let\u2019s say I have a category that indicates whether or not the financial professional has preferences on receiving updates from our firm. And the categories are true and false. There are 134,346 true values, 30,348 false values, and 5411 null values. I can fill the null values with \u201cunknown\u201d or the mode of True. But does the uneven distribution of this category mean that this category is not useful to kmodes?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g3e1f", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Condition560", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g3e1f/question_about_kmodes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g3e1f/question_about_kmodes/", "subreddit_subscribers": 929606, "created_utc": 1687440013.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a choice to either choose CS(Data Science) or CS(AI and ML) at my college. Which one should I choose if my goal is to work at FAANG and maybe try for quant later in my career(probably after masters)?\n\nI might also go for masters right after undergrad, so which one will have less competition at top universities?", "author_fullname": "t2_7rru4w7j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I choose a specialisation in DSE or AIML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gpgsa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687496756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a choice to either choose CS(Data Science) or CS(AI and ML) at my college. Which one should I choose if my goal is to work at FAANG and maybe try for quant later in my career(probably after masters)?&lt;/p&gt;\n\n&lt;p&gt;I might also go for masters right after undergrad, so which one will have less competition at top universities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gpgsa", "is_robot_indexable": true, "report_reasons": null, "author": "the_card_dealer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gpgsa/should_i_choose_a_specialisation_in_dse_or_aiml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gpgsa/should_i_choose_a_specialisation_in_dse_or_aiml/", "subreddit_subscribers": 929606, "created_utc": 1687496756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Context: I am effectively the only data scientist in my department, and I have been in this role for a year. It's my first data science position. \n\n\nGoal: Build a churn model with 80%+ accuracy and false negative rate under 25%. Ideally false positive rate under 10%.\n\n\nProblem: With everything I do, accuracy and F1/FNR appear to be inversely related. This made sense when I was working on statistical models, but now that I've been building neural nets, the same thing is happening, and I'm at a loss. The models appear to be critically underfit.\n\n\nData: (tabular) 27k records and 300 variables, 100 of which are not highly correlated so I have mostly only been using just those 100 variables. Data is already standardized and one-hot encoded. One class is 90% and one is 10%.\n\n\nThings I've tried:\n\n\n* increasing number of hidden layers (increases F1, decreases accuracy)\n\n\n* decreasing number of hidden layers (decreases F1, increases accuracy)\n\n\n* introducing class weights (increases F1, decreases accuracy)\n\n\n* oversampling the minority class (same results as above)\n\n\n* using all 300 variables (no significant change)\n\n\nThings I will try:\n\n\n* increase training samples from 27k to 50k (more than that is not really possible as data would be too old)\n\n\n* turn this into a probability problem rather than a classification problem with a softmax output layer\n\n\n* try a CNN or other type of network \n\n\nAny general pointers on where to go from here would be helpful. I already spent a couple of months on feature engineering and feel like I've exhausted the possibilities with my 300 variables, but I will revisit that if nothing else works. Everything I'm reading online says change the network topology and balance the dataset, but that hasn't worked yet, so I am stumped.\n\n\nMy best-performing model structure is an input later with 100 inputs, 4 hidden layers with 80, 60, 40, and 20 neurons (all using relu activation) and a sigmoid output layer. \n\n\nAny help is greatly appreciated.", "author_fullname": "t2_rswxz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pointers to reduce false negatives while not sacrificing accuracy in deep learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g56ho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687444441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I am effectively the only data scientist in my department, and I have been in this role for a year. It&amp;#39;s my first data science position. &lt;/p&gt;\n\n&lt;p&gt;Goal: Build a churn model with 80%+ accuracy and false negative rate under 25%. Ideally false positive rate under 10%.&lt;/p&gt;\n\n&lt;p&gt;Problem: With everything I do, accuracy and F1/FNR appear to be inversely related. This made sense when I was working on statistical models, but now that I&amp;#39;ve been building neural nets, the same thing is happening, and I&amp;#39;m at a loss. The models appear to be critically underfit.&lt;/p&gt;\n\n&lt;p&gt;Data: (tabular) 27k records and 300 variables, 100 of which are not highly correlated so I have mostly only been using just those 100 variables. Data is already standardized and one-hot encoded. One class is 90% and one is 10%.&lt;/p&gt;\n\n&lt;p&gt;Things I&amp;#39;ve tried:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;increasing number of hidden layers (increases F1, decreases accuracy)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;decreasing number of hidden layers (decreases F1, increases accuracy)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;introducing class weights (increases F1, decreases accuracy)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;oversampling the minority class (same results as above)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;using all 300 variables (no significant change)&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Things I will try:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;increase training samples from 27k to 50k (more than that is not really possible as data would be too old)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;turn this into a probability problem rather than a classification problem with a softmax output layer&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;try a CNN or other type of network &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any general pointers on where to go from here would be helpful. I already spent a couple of months on feature engineering and feel like I&amp;#39;ve exhausted the possibilities with my 300 variables, but I will revisit that if nothing else works. Everything I&amp;#39;m reading online says change the network topology and balance the dataset, but that hasn&amp;#39;t worked yet, so I am stumped.&lt;/p&gt;\n\n&lt;p&gt;My best-performing model structure is an input later with 100 inputs, 4 hidden layers with 80, 60, 40, and 20 neurons (all using relu activation) and a sigmoid output layer. &lt;/p&gt;\n\n&lt;p&gt;Any help is greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g56ho", "is_robot_indexable": true, "report_reasons": null, "author": "goatsnboots", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g56ho/pointers_to_reduce_false_negatives_while_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g56ho/pointers_to_reduce_false_negatives_while_not/", "subreddit_subscribers": 929606, "created_utc": 1687444441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have two data sets and they both have the same column names. One of the data sets is an excel file and contains historical data up until April. The second data set is linked to a database but will only ever contain 6 rolling months' worth of data. I am appending the two datasets and removing duplicates in PowerBI Power Query. I'd like to prioritise the data from the live source, but also ensure that the data doesn't get lost.Eg. what will happen to May data in 14 months from now, since it is not in the current excel data set, and it will not be in the live data set? I'd like to ensure that May data doesn't disappear in 14 months' time?\n\nHow do I automate preservation of data in Excel file so it doesn\u2019t \"roll off\"", "author_fullname": "t2_sie27959", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to automate preservation of data so it doesn\u2019t \"roll off\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14fyeo0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687425066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have two data sets and they both have the same column names. One of the data sets is an excel file and contains historical data up until April. The second data set is linked to a database but will only ever contain 6 rolling months&amp;#39; worth of data. I am appending the two datasets and removing duplicates in PowerBI Power Query. I&amp;#39;d like to prioritise the data from the live source, but also ensure that the data doesn&amp;#39;t get lost.Eg. what will happen to May data in 14 months from now, since it is not in the current excel data set, and it will not be in the live data set? I&amp;#39;d like to ensure that May data doesn&amp;#39;t disappear in 14 months&amp;#39; time?&lt;/p&gt;\n\n&lt;p&gt;How do I automate preservation of data in Excel file so it doesn\u2019t &amp;quot;roll off&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14fyeo0", "is_robot_indexable": true, "report_reasons": null, "author": "Acrobatic-Chapter959", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14fyeo0/how_to_automate_preservation_of_data_so_it_doesnt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14fyeo0/how_to_automate_preservation_of_data_so_it_doesnt/", "subreddit_subscribers": 929606, "created_utc": 1687425066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you know any free online courses for data analysis in R which ends with a final project? I have prior knowledge in Python programming and data analysis but the last time I worked with R was years ago and I want to have solid skills in R for future job applications.\n\nI'm happy for any course recommendation!", "author_fullname": "t2_3m8f35t9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for a good R course with a final project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14gtfyt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687510805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you know any free online courses for data analysis in R which ends with a final project? I have prior knowledge in Python programming and data analysis but the last time I worked with R was years ago and I want to have solid skills in R for future job applications.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m happy for any course recommendation!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gtfyt", "is_robot_indexable": true, "report_reasons": null, "author": "kaisermax6020", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gtfyt/looking_for_a_good_r_course_with_a_final_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gtfyt/looking_for_a_good_r_course_with_a_final_project/", "subreddit_subscribers": 929606, "created_utc": 1687510805.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Since a few month, I work in a company on event detection with time series. I would like some recommendations on how to organize my datascience project in Python. Some context : \n\n  \nThere was a datascientist before me, and some intern worked on this project. It's been 4 years since the model was updated, and at that time, they built a sophisticated (or just big) pipeline to run multiple tasks : \n\n* preprocess / filter / enrich data\n* train a classifier\n* compute metrics, print graphs, export a bunch of parameters in csv / json files\n* export the model in mobile-compatible formats (CoreML for iOS, json for Android)\n* store everything in archives, upload in on our server, git operations, ...\n* validate on a set of trusted data\n* and many other things\n\nI'm not sure if I want to perform the same tasks, the context is different now.\n\nWhat bugs me, with this pipeline, is the way data is shared / passed among functions. Each task, each function, is performed on a file, on disk. (there is no need for this, the data is not massive). For example, the `train_classifier` function have one parameter \"`project_dir_path`\", and inside that project directory, it loads parameters, arguments, various stuff, and export the results, metrics, classifier, everything, **inside** that directory.\n\nOf course, the  \"`project_dir_path`\" was a hidden directory, like '`.tmp/my_dataset`', not committed or saved anywhere.\n\nEvery function is like that. It's a hell to understand what is needed for each function, what are the data, etc. By the way, the \"pipeline\" is composed of two files, with 800+ lines each.\n\nAbout me : \n\n* It's my first Python Datascience job\n* Previously I was finishing my PhD, so my Python coding practices are ... inexistant\n* Before my PhD, I was a Java software engineer. I like typed languages, I like Object Oriented Programming, self-documenting code, etc. \n\n&amp;#x200B;\n\nMy question : how do I organize this mess ? Is it a good pattern ? Am I just impatient ? \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_8owvwc5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Code and Python project web practices for datascience pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14gsow1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687508005.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Since a few month, I work in a company on event detection with time series. I would like some recommendations on how to organize my datascience project in Python. Some context : &lt;/p&gt;\n\n&lt;p&gt;There was a datascientist before me, and some intern worked on this project. It&amp;#39;s been 4 years since the model was updated, and at that time, they built a sophisticated (or just big) pipeline to run multiple tasks : &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;preprocess / filter / enrich data&lt;/li&gt;\n&lt;li&gt;train a classifier&lt;/li&gt;\n&lt;li&gt;compute metrics, print graphs, export a bunch of parameters in csv / json files&lt;/li&gt;\n&lt;li&gt;export the model in mobile-compatible formats (CoreML for iOS, json for Android)&lt;/li&gt;\n&lt;li&gt;store everything in archives, upload in on our server, git operations, ...&lt;/li&gt;\n&lt;li&gt;validate on a set of trusted data&lt;/li&gt;\n&lt;li&gt;and many other things&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if I want to perform the same tasks, the context is different now.&lt;/p&gt;\n\n&lt;p&gt;What bugs me, with this pipeline, is the way data is shared / passed among functions. Each task, each function, is performed on a file, on disk. (there is no need for this, the data is not massive). For example, the &lt;code&gt;train_classifier&lt;/code&gt; function have one parameter &amp;quot;&lt;code&gt;project_dir_path&lt;/code&gt;&amp;quot;, and inside that project directory, it loads parameters, arguments, various stuff, and export the results, metrics, classifier, everything, &lt;strong&gt;inside&lt;/strong&gt; that directory.&lt;/p&gt;\n\n&lt;p&gt;Of course, the  &amp;quot;&lt;code&gt;project_dir_path&lt;/code&gt;&amp;quot; was a hidden directory, like &amp;#39;&lt;code&gt;.tmp/my_dataset&lt;/code&gt;&amp;#39;, not committed or saved anywhere.&lt;/p&gt;\n\n&lt;p&gt;Every function is like that. It&amp;#39;s a hell to understand what is needed for each function, what are the data, etc. By the way, the &amp;quot;pipeline&amp;quot; is composed of two files, with 800+ lines each.&lt;/p&gt;\n\n&lt;p&gt;About me : &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;It&amp;#39;s my first Python Datascience job&lt;/li&gt;\n&lt;li&gt;Previously I was finishing my PhD, so my Python coding practices are ... inexistant&lt;/li&gt;\n&lt;li&gt;Before my PhD, I was a Java software engineer. I like typed languages, I like Object Oriented Programming, self-documenting code, etc. &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question : how do I organize this mess ? Is it a good pattern ? Am I just impatient ? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gsow1", "is_robot_indexable": true, "report_reasons": null, "author": "This-Librarian3339", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gsow1/code_and_python_project_web_practices_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gsow1/code_and_python_project_web_practices_for/", "subreddit_subscribers": 929606, "created_utc": 1687508005.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If yes, what tricks do you have to make it work smoothly? I had to resolve some conflicts in an notebook once and it was an awful experience\u2026", "author_fullname": "t2_ze1nira", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you git commit jupyter notebooks?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gra17", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687502982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If yes, what tricks do you have to make it work smoothly? I had to resolve some conflicts in an notebook once and it was an awful experience\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gra17", "is_robot_indexable": true, "report_reasons": null, "author": "old_enough_to_drink", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gra17/do_you_git_commit_jupyter_notebooks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gra17/do_you_git_commit_jupyter_notebooks/", "subreddit_subscribers": 929606, "created_utc": 1687502982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\n\nI am aware of rule 7 (about StackExchange), but I asked my question there and haven't received any answers so far, so I thought I'd try it here since it is a little time-sensitive.\n\nI have a dataframe with the columns date (datetime64), NDVI (float64) and field\\_id (object). I want to detect outliers in NDVI measurements using field\\_id as a grouping variable. This way, I hope the algorithm accepts aberrant behaviour specific to individual fields and marks as outliers mostly anomalies that affect multiple fields simultaneously.\n\nValues in field\\_id are formed of letters and numbers (examples: KM1, KM106, LM27, LM10). Of course, using such an object directly gives me the error:\n\n&gt;ValueError: could not convert string to float: 'LM10'\n\nI have read about two ways to use such values in machine learning: Label and One-Hot encoding. However, the IDs are completely independent of one another (discarding Label as an option) and I am hesitant to try One-Hot because I have about 165 unique IDs.\n\nWhat is the most practical way of using extensive object columns as variables in Isolation Forest?\n\nI am working with IsolationForest from sklearn.ensemble", "author_fullname": "t2_7x010xb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Adding extensive object column as extra variable in Isolation Forest model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gqjzl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687500446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I am aware of rule 7 (about StackExchange), but I asked my question there and haven&amp;#39;t received any answers so far, so I thought I&amp;#39;d try it here since it is a little time-sensitive.&lt;/p&gt;\n\n&lt;p&gt;I have a dataframe with the columns date (datetime64), NDVI (float64) and field_id (object). I want to detect outliers in NDVI measurements using field_id as a grouping variable. This way, I hope the algorithm accepts aberrant behaviour specific to individual fields and marks as outliers mostly anomalies that affect multiple fields simultaneously.&lt;/p&gt;\n\n&lt;p&gt;Values in field_id are formed of letters and numbers (examples: KM1, KM106, LM27, LM10). Of course, using such an object directly gives me the error:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;ValueError: could not convert string to float: &amp;#39;LM10&amp;#39;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I have read about two ways to use such values in machine learning: Label and One-Hot encoding. However, the IDs are completely independent of one another (discarding Label as an option) and I am hesitant to try One-Hot because I have about 165 unique IDs.&lt;/p&gt;\n\n&lt;p&gt;What is the most practical way of using extensive object columns as variables in Isolation Forest?&lt;/p&gt;\n\n&lt;p&gt;I am working with IsolationForest from sklearn.ensemble&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gqjzl", "is_robot_indexable": true, "report_reasons": null, "author": "Cadillac-Blood", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gqjzl/adding_extensive_object_column_as_extra_variable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gqjzl/adding_extensive_object_column_as_extra_variable/", "subreddit_subscribers": 929606, "created_utc": 1687500446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Not sure if this is the right sub, I tried posting on r/dataanalysis but apparently it's \"dark\".  \n\n\nI'm looking for feedback on these charts I made.\n\nhttps://preview.redd.it/zg08fow49p7b1.png?width=1189&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3405be5257d6ad2be85e6247655d1c8a3d1e62f9\n\nI have some questions,\n\n* Should I add axis labels?  (Like revenue, date etc)\n* Should I summarise the revenue axis to millions? - 6m, 8m etc\n* Where should I add the currency?\n* Are the titles appropriate?\n* Any improvements to colors?", "author_fullname": "t2_bxy2y5mq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on data viz", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 47, "top_awarded_type": null, "hide_score": false, "media_metadata": {"zg08fow49p7b1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 36, "x": 108, "u": "https://preview.redd.it/zg08fow49p7b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=05286c4583f61c15357b6b4cb53654a94da54496"}, {"y": 73, "x": 216, "u": "https://preview.redd.it/zg08fow49p7b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=b0cd8b9c313be41bdf9e268927a375d6fe08cd12"}, {"y": 109, "x": 320, "u": "https://preview.redd.it/zg08fow49p7b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=4ce4cbaee49bd99e6ca70e6643cb55f39476ee8a"}, {"y": 218, "x": 640, "u": "https://preview.redd.it/zg08fow49p7b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=00b5c37a978e342c0f07df0b53bfe3f0f2ad14a9"}, {"y": 327, "x": 960, "u": "https://preview.redd.it/zg08fow49p7b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2fac2719b0ff5dbe220c60d30239897cb47cf248"}, {"y": 368, "x": 1080, "u": "https://preview.redd.it/zg08fow49p7b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=bbdbfae693bfaf29610fc5139f01458e3565a222"}], "s": {"y": 406, "x": 1189, "u": "https://preview.redd.it/zg08fow49p7b1.png?width=1189&amp;format=png&amp;auto=webp&amp;v=enabled&amp;s=3405be5257d6ad2be85e6247655d1c8a3d1e62f9"}, "id": "zg08fow49p7b1"}}, "name": "t3_14gpiuh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/kNF5Vz5r4EiOj9AKH5UWhijv_Qdibe4sWlx7HBWC2RY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687496960.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if this is the right sub, I tried posting on &lt;a href=\"/r/dataanalysis\"&gt;r/dataanalysis&lt;/a&gt; but apparently it&amp;#39;s &amp;quot;dark&amp;quot;.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for feedback on these charts I made.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zg08fow49p7b1.png?width=1189&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3405be5257d6ad2be85e6247655d1c8a3d1e62f9\"&gt;https://preview.redd.it/zg08fow49p7b1.png?width=1189&amp;amp;format=png&amp;amp;auto=webp&amp;amp;v=enabled&amp;amp;s=3405be5257d6ad2be85e6247655d1c8a3d1e62f9&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I have some questions,&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Should I add axis labels?  (Like revenue, date etc)&lt;/li&gt;\n&lt;li&gt;Should I summarise the revenue axis to millions? - 6m, 8m etc&lt;/li&gt;\n&lt;li&gt;Where should I add the currency?&lt;/li&gt;\n&lt;li&gt;Are the titles appropriate?&lt;/li&gt;\n&lt;li&gt;Any improvements to colors?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gpiuh", "is_robot_indexable": true, "report_reasons": null, "author": "bb_avin", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gpiuh/feedback_on_data_viz/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gpiuh/feedback_on_data_viz/", "subreddit_subscribers": 929606, "created_utc": 1687496960.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everybody,\n\nI just wanted to start a discussion on here as a thought exercise but also to learn from you guys. As an early-career professional (I am finishing my MSc in wildlife biology but transitioning into data science), a debate that I've been having is finding the balance between efficacy and efficiency when developing models. \n\nMost of my experience has been academia, so my bosses/mentors emphasized causal inference when developing models. But now that I am transitioning into industry work, I have been learning that most \"real-world\" models and ML algorithms are a balancing act of different methods/objectives/timelines/etc... \n\nQuestion is... What are some of these considerations in your day-to-day work and how do you go about balancing them? ", "author_fullname": "t2_3iylg8o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finding the balance between efficacy and efficiency.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gp4zo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687495724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody,&lt;/p&gt;\n\n&lt;p&gt;I just wanted to start a discussion on here as a thought exercise but also to learn from you guys. As an early-career professional (I am finishing my MSc in wildlife biology but transitioning into data science), a debate that I&amp;#39;ve been having is finding the balance between efficacy and efficiency when developing models. &lt;/p&gt;\n\n&lt;p&gt;Most of my experience has been academia, so my bosses/mentors emphasized causal inference when developing models. But now that I am transitioning into industry work, I have been learning that most &amp;quot;real-world&amp;quot; models and ML algorithms are a balancing act of different methods/objectives/timelines/etc... &lt;/p&gt;\n\n&lt;p&gt;Question is... What are some of these considerations in your day-to-day work and how do you go about balancing them? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gp4zo", "is_robot_indexable": true, "report_reasons": null, "author": "WOCIII", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gp4zo/finding_the_balance_between_efficacy_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gp4zo/finding_the_balance_between_efficacy_and/", "subreddit_subscribers": 929606, "created_utc": 1687495724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,\n\nI\u2019m an incoming graduate student getting my masters in DS. My program offers a few specializations: \n1. Analytics and Modeling (focuses on predictive modeling) \n2. Analytics Management (focuses on business operations) \n3. Artificial Intelligence \n4. Data Engineering \n\nI was wondering given the job market, which specialization should I choose to be exposed to the most job opportunities?", "author_fullname": "t2_diaem5eh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Specialization for MSDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gksyf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687482821.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m an incoming graduate student getting my masters in DS. My program offers a few specializations: \n1. Analytics and Modeling (focuses on predictive modeling) \n2. Analytics Management (focuses on business operations) \n3. Artificial Intelligence \n4. Data Engineering &lt;/p&gt;\n\n&lt;p&gt;I was wondering given the job market, which specialization should I choose to be exposed to the most job opportunities?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gksyf", "is_robot_indexable": true, "report_reasons": null, "author": "eggsbaconcheeze", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gksyf/specialization_for_msds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gksyf/specialization_for_msds/", "subreddit_subscribers": 929606, "created_utc": 1687482821.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, i'm a fresh data science graduate, i applied to a job that states data engineer, but i was surprised on the interview invitation that it's a data officer role,\n\ni have never studied or worked in such area, nor there's enough information online to read, i don't know what the hell they gonna ask me on the interview, i was thinking of backing off, but it looks like a very big company , plus, i need the experience in this stage,\n\nthe interview is in 3 days\n\nis that enough to learn about this? and if yes, can you guys suggest any good sources about this? a last question, it might sound dumb, but, is it harder than other data science roles (analyst, administrator, engineer )?", "author_fullname": "t2_55642ldz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "data officer job interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "career", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gjldo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687479390.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, i&amp;#39;m a fresh data science graduate, i applied to a job that states data engineer, but i was surprised on the interview invitation that it&amp;#39;s a data officer role,&lt;/p&gt;\n\n&lt;p&gt;i have never studied or worked in such area, nor there&amp;#39;s enough information online to read, i don&amp;#39;t know what the hell they gonna ask me on the interview, i was thinking of backing off, but it looks like a very big company , plus, i need the experience in this stage,&lt;/p&gt;\n\n&lt;p&gt;the interview is in 3 days&lt;/p&gt;\n\n&lt;p&gt;is that enough to learn about this? and if yes, can you guys suggest any good sources about this? a last question, it might sound dumb, but, is it harder than other data science roles (analyst, administrator, engineer )?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a6ee6fa0-d780-11e7-b6d0-0e0bd8823a7e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gjldo", "is_robot_indexable": true, "report_reasons": null, "author": "ARA-GOD", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gjldo/data_officer_job_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gjldo/data_officer_job_interview/", "subreddit_subscribers": 929606, "created_utc": 1687479390.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\nI'm working on a project with a common kaggle dataset, trying to use a random forest to predict a binary feature from ~20 binary, numerical and one categorical variable with 3 ordinal categories.\nTarget variable is pretty balanced, but one particular binary predictor and the 3-level categorical variable are kinda imbalanced, 80-20 % and 45-10-45 %, respectively.\nWhat is the impact of this imbalance? If I were to train my data on this set, would the model be negatively affected? Note that the dataset is pretty large, we're talking 100k observations for the training set alone. Is there need to resample my dataset?\n\n---Dumbly Afraid To Ask", "author_fullname": "t2_2p4jjqle", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imbalance in predictors: what to do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gg47c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687470489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nI&amp;#39;m working on a project with a common kaggle dataset, trying to use a random forest to predict a binary feature from ~20 binary, numerical and one categorical variable with 3 ordinal categories.\nTarget variable is pretty balanced, but one particular binary predictor and the 3-level categorical variable are kinda imbalanced, 80-20 % and 45-10-45 %, respectively.\nWhat is the impact of this imbalance? If I were to train my data on this set, would the model be negatively affected? Note that the dataset is pretty large, we&amp;#39;re talking 100k observations for the training set alone. Is there need to resample my dataset?&lt;/p&gt;\n\n&lt;p&gt;---Dumbly Afraid To Ask&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gg47c", "is_robot_indexable": true, "report_reasons": null, "author": "aceofmaz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gg47c/imbalance_in_predictors_what_to_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gg47c/imbalance_in_predictors_what_to_do/", "subreddit_subscribers": 929606, "created_utc": 1687470489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "That are **not**, I repeat **not** written by Taleb.", "author_fullname": "t2_ad5yokml", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for recommended readings/lectures/materials on extreme value theory, and risk in data science.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "education", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14gctgp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687462874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;That are &lt;strong&gt;not&lt;/strong&gt;, I repeat &lt;strong&gt;not&lt;/strong&gt; written by Taleb.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "99f9652a-d780-11e7-b558-0e52cdd59ace", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14gctgp", "is_robot_indexable": true, "report_reasons": null, "author": "antichain", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14gctgp/looking_for_recommended_readingslecturesmaterials/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14gctgp/looking_for_recommended_readingslecturesmaterials/", "subreddit_subscribers": 929606, "created_utc": 1687462874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys. \nTLDR: I have an image classification problem for fraud detection. But the thing is, my targets for images are not correct(&gt;50%) times. How should I go about it? Any suggestions to read/explore about things.\n\nLong read below:\nThe use case is for identifying frauds. In a certain setup, an agency is required to build some public assets - like ponds, houses, dams, roads etc.  And the agency is required to submit photos as proof. So we are kind of checker, want to build a model that should flag when photo is suspicious, not of right category . One approach is to classify the image, and if the model predicted category is different then we can flag. We are going with this one for now. So for this approach we need Labelled dataset. We have million of images that have been uploaded so far , but our image, category pair may not be correct  in case there have been frauds. And frauds percentage is upto 60-70%. So you see our label is kind of noisy.\n\nSo which approaches are out there for learning from noisy labels? Some sort of Self supervised learning, or other learning paradigm is what I could think of.\n\nThanks.", "author_fullname": "t2_9yo5phby", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Image classification with noisy labels", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g8i0k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687452813.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys. \nTLDR: I have an image classification problem for fraud detection. But the thing is, my targets for images are not correct(&amp;gt;50%) times. How should I go about it? Any suggestions to read/explore about things.&lt;/p&gt;\n\n&lt;p&gt;Long read below:\nThe use case is for identifying frauds. In a certain setup, an agency is required to build some public assets - like ponds, houses, dams, roads etc.  And the agency is required to submit photos as proof. So we are kind of checker, want to build a model that should flag when photo is suspicious, not of right category . One approach is to classify the image, and if the model predicted category is different then we can flag. We are going with this one for now. So for this approach we need Labelled dataset. We have million of images that have been uploaded so far , but our image, category pair may not be correct  in case there have been frauds. And frauds percentage is upto 60-70%. So you see our label is kind of noisy.&lt;/p&gt;\n\n&lt;p&gt;So which approaches are out there for learning from noisy labels? Some sort of Self supervised learning, or other learning paradigm is what I could think of.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g8i0k", "is_robot_indexable": true, "report_reasons": null, "author": "EducatorDiligent5114", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g8i0k/image_classification_with_noisy_labels/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g8i0k/image_classification_with_noisy_labels/", "subreddit_subscribers": 929606, "created_utc": 1687452813.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey everyone!\n\nI hope you're all doing well. I wanted to reach out to those of you who have worked or are currently working as interns in product-based companies. I have a couple of questions and would greatly appreciate your insights and experiences.\n\nThank you so much in advance! Looking forward to your responses and discussions", "author_fullname": "t2_7w8cmdht", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interning at Product-Based Companies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14g7z1b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687451084.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all doing well. I wanted to reach out to those of you who have worked or are currently working as interns in product-based companies. I have a couple of questions and would greatly appreciate your insights and experiences.&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance! Looking forward to your responses and discussions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "14g7z1b", "is_robot_indexable": true, "report_reasons": null, "author": "Batman_bruce_wayne0", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/14g7z1b/interning_at_productbased_companies/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/14g7z1b/interning_at_productbased_companies/", "subreddit_subscribers": 929606, "created_utc": 1687451084.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}