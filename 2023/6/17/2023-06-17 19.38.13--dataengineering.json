{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m going to guess early to mid 20s.", "author_fullname": "t2_kytqh4tu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How old were you when you landed your first real data engineering job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14b5t87", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 76, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 76, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686944009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m going to guess early to mid 20s.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14b5t87", "is_robot_indexable": true, "report_reasons": null, "author": "SeriouslySally36", "discussion_type": null, "num_comments": 135, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14b5t87/how_old_were_you_when_you_landed_your_first_real/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14b5t87/how_old_were_you_when_you_landed_your_first_real/", "subreddit_subscribers": 110930, "created_utc": 1686944009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_a49okn69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Happy Father's Day, data engineers!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_14b7yl2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/Sl5mzne5DYIbwhxTi2qEII3ZkEaQz1Ou2HXwJC7WSI0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1686949266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/gv8fyeo72g6b1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/gv8fyeo72g6b1.png?auto=webp&amp;v=enabled&amp;s=a405764be344f4174597e60ae04e32667967016e", "width": 1200, "height": 1500}, "resolutions": [{"url": "https://preview.redd.it/gv8fyeo72g6b1.png?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=f0059acfcb203aa81fffbd0158ac07fea739a35d", "width": 108, "height": 135}, {"url": "https://preview.redd.it/gv8fyeo72g6b1.png?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c28feaea9d5706438dc1fb501df46b59cd73a717", "width": 216, "height": 270}, {"url": "https://preview.redd.it/gv8fyeo72g6b1.png?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=2503bca3436d416646111d0f00ed51f7f2ad470d", "width": 320, "height": 400}, {"url": "https://preview.redd.it/gv8fyeo72g6b1.png?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=941df641c128f37b6a37de589577db7a2f6c7e80", "width": 640, "height": 800}, {"url": "https://preview.redd.it/gv8fyeo72g6b1.png?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=328b95e457ff6dbfdb6da2f9629d9dae69e7cf89", "width": 960, "height": 1200}, {"url": "https://preview.redd.it/gv8fyeo72g6b1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=13151f090b4e7af9a6d05bf59e22293f1d2e617a", "width": 1080, "height": 1350}], "variants": {}, "id": "HPCRKmZuUHk-w5Gl_juNUl5814xnwImdyOk_Cp85yOI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "14b7yl2", "is_robot_indexable": true, "report_reasons": null, "author": "Top-Substance2185", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14b7yl2/happy_fathers_day_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/gv8fyeo72g6b1.png", "subreddit_subscribers": 110930, "created_utc": 1686949266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI was trying to read excel files residing on **AWS S3**. As I already had pyspark pipelines setup, I attempted to use **com.crealytics.spark.excel** for excel. It worked fine for files **&lt;10MB** however, with large files (50 to 150 MB excel files) I started getting job failure as follows:\n\n&gt;\"java.lang.OutOfMemoryError: Java heap space\"\n\nI referred to AWS Glue's docs and found the following troubleshooting guide: [AWS Glue OOM Heap Space](https://repost.aws/knowledge-center/glue-oom-java-heap-space-error)\n\nThis, however, only dealt with **large number of small file problems**, or other **driver intensive operations**, and the only suggestion it had for my situation is to **scale up**.\n\nFor **50 MB files**, I scaled up to **20-30 workers** and the job was successful, however, the **150 MB file** still could not be read.\n\nI approached the problem with a different toolset i.e. **boto3 &amp; pandas** or **awswrangler**. That did the job with just 4 workers in under 10 mins. I bet not even 3 are required.\n\nI wanted to know if I had done something incorrectly with crealytics, considering pyspark is supposed to be much more powerful, compute wise, considering its distributed nature. Also, if the above result is conclusive, could anyone guide me as to why this happened, based on how both work? Would be grateful for your responses.  \nI had posted a question on [stackoverflow](https://stackoverflow.com/questions/76464770/com-crealytics-spark-excel-vs-pandas-awswrangler/76465167#76465167), however, there was no comprehensive response.", "author_fullname": "t2_8ixxnnf4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pandas was faster and less memory intensive then crealytics pyspark. How is it possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14bn5fw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686996210.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was trying to read excel files residing on &lt;strong&gt;AWS S3&lt;/strong&gt;. As I already had pyspark pipelines setup, I attempted to use &lt;strong&gt;com.crealytics.spark.excel&lt;/strong&gt; for excel. It worked fine for files &lt;strong&gt;&amp;lt;10MB&lt;/strong&gt; however, with large files (50 to 150 MB excel files) I started getting job failure as follows:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&amp;quot;java.lang.OutOfMemoryError: Java heap space&amp;quot;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I referred to AWS Glue&amp;#39;s docs and found the following troubleshooting guide: &lt;a href=\"https://repost.aws/knowledge-center/glue-oom-java-heap-space-error\"&gt;AWS Glue OOM Heap Space&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This, however, only dealt with &lt;strong&gt;large number of small file problems&lt;/strong&gt;, or other &lt;strong&gt;driver intensive operations&lt;/strong&gt;, and the only suggestion it had for my situation is to &lt;strong&gt;scale up&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;For &lt;strong&gt;50 MB files&lt;/strong&gt;, I scaled up to &lt;strong&gt;20-30 workers&lt;/strong&gt; and the job was successful, however, the &lt;strong&gt;150 MB file&lt;/strong&gt; still could not be read.&lt;/p&gt;\n\n&lt;p&gt;I approached the problem with a different toolset i.e. &lt;strong&gt;boto3 &amp;amp; pandas&lt;/strong&gt; or &lt;strong&gt;awswrangler&lt;/strong&gt;. That did the job with just 4 workers in under 10 mins. I bet not even 3 are required.&lt;/p&gt;\n\n&lt;p&gt;I wanted to know if I had done something incorrectly with crealytics, considering pyspark is supposed to be much more powerful, compute wise, considering its distributed nature. Also, if the above result is conclusive, could anyone guide me as to why this happened, based on how both work? Would be grateful for your responses.&lt;br/&gt;\nI had posted a question on &lt;a href=\"https://stackoverflow.com/questions/76464770/com-crealytics-spark-excel-vs-pandas-awswrangler/76465167#76465167\"&gt;stackoverflow&lt;/a&gt;, however, there was no comprehensive response.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?auto=webp&amp;v=enabled&amp;s=96305e240e32ef61b596395e1bd74cdd2b5ddc9f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=668115d5116a9321c9d15551b8d546a68f75112b", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=488bc7dc46930436614152debfa68b6926b8196b", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=181b543f38a37bffa9070ec5c73a2cbcd66cc8f4", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=d81e093ae625b1e109af99de0c72a0ebea0f0088", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=10b559f8887295a4ee5c2790c34a42f8e3690847", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/hP3JsQBbdiWXwCXIY7kxszHzO6LbWjz8ZxP8CTk9bJs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=836e2bf75ddac523506ae28bf3813f47697700e2", "width": 1080, "height": 567}], "variants": {}, "id": "RUqh18uQTwuGJocqdUcC-6UfvfWS63SRDdr8AQqU3uM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14bn5fw", "is_robot_indexable": true, "report_reasons": null, "author": "mozakaak", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14bn5fw/pandas_was_faster_and_less_memory_intensive_then/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14bn5fw/pandas_was_faster_and_less_memory_intensive_then/", "subreddit_subscribers": 110930, "created_utc": 1686996210.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggests, i have been trying to get into data engineering and have no relevant experience of it. Everywhere I see, they expect the applicants to have certain years of experience in data engineering. I want to start from a junior role and then climb the ladder later to more senior positions. But it seems, in countries like India, you can't change your role mid way in your career. And it is the same for other roles as well. Please suggest, how I should tackle these situations. I really appreciate that in some countries you can freely choose your career and start afresh even in your late 30s.", "author_fullname": "t2_t09x3o4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is role change difficult in some countries like India?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14bgxk7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686974909.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggests, i have been trying to get into data engineering and have no relevant experience of it. Everywhere I see, they expect the applicants to have certain years of experience in data engineering. I want to start from a junior role and then climb the ladder later to more senior positions. But it seems, in countries like India, you can&amp;#39;t change your role mid way in your career. And it is the same for other roles as well. Please suggest, how I should tackle these situations. I really appreciate that in some countries you can freely choose your career and start afresh even in your late 30s.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14bgxk7", "is_robot_indexable": true, "report_reasons": null, "author": "frustratedhu", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14bgxk7/why_is_role_change_difficult_in_some_countries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14bgxk7/why_is_role_change_difficult_in_some_countries/", "subreddit_subscribers": 110930, "created_utc": 1686974909.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I recently started as a DE.  I am shocked how less the job involves programming and software development. \n\nFor me DE is SWE focused on data. At lot of time should be spent with databases and coding. Of course some time should also be meetings. \n\nIn reality it seems like my current job is sitting in meetings 80% of the time, waiting for ad hoc work and 20% coding.", "author_fullname": "t2_6fdt02qy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE really more Meetings than SWE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14bucxf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687016939.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently started as a DE.  I am shocked how less the job involves programming and software development. &lt;/p&gt;\n\n&lt;p&gt;For me DE is SWE focused on data. At lot of time should be spent with databases and coding. Of course some time should also be meetings. &lt;/p&gt;\n\n&lt;p&gt;In reality it seems like my current job is sitting in meetings 80% of the time, waiting for ad hoc work and 20% coding.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14bucxf", "is_robot_indexable": true, "report_reasons": null, "author": "Insighteous", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14bucxf/de_really_more_meetings_than_swe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14bucxf/de_really_more_meetings_than_swe/", "subreddit_subscribers": 110930, "created_utc": 1687016939.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. Looking for opinions on pulling data for a reasonably large api source. \n\nThe dataset is essentially 1000 requests (at daily intervals, or hourly, doesn\u2019t really matter) that I need to poll independently. \n\nEach call gets the latest date time in the db then requests from then forward.\n\nI can write this pretty easily in python but curious how to optimize this in dagster. Should I be sending off each stream to its own process (essentially spinning up 1000 processes), or is there a better way? \n\nEach state is essentially independent of all others so it\u2019s all parallelized easily, I just need to check for each stream in the db what it\u2019s current latest time is then gimmie gimmie data. \n\nThoughts? We also use Airbyte, but it doesn\u2019t seem very clean to do this without creating some duplication.", "author_fullname": "t2_ahu1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "API with 1000 endpoints", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14bdhvs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686964462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. Looking for opinions on pulling data for a reasonably large api source. &lt;/p&gt;\n\n&lt;p&gt;The dataset is essentially 1000 requests (at daily intervals, or hourly, doesn\u2019t really matter) that I need to poll independently. &lt;/p&gt;\n\n&lt;p&gt;Each call gets the latest date time in the db then requests from then forward.&lt;/p&gt;\n\n&lt;p&gt;I can write this pretty easily in python but curious how to optimize this in dagster. Should I be sending off each stream to its own process (essentially spinning up 1000 processes), or is there a better way? &lt;/p&gt;\n\n&lt;p&gt;Each state is essentially independent of all others so it\u2019s all parallelized easily, I just need to check for each stream in the db what it\u2019s current latest time is then gimmie gimmie data. &lt;/p&gt;\n\n&lt;p&gt;Thoughts? We also use Airbyte, but it doesn\u2019t seem very clean to do this without creating some duplication.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14bdhvs", "is_robot_indexable": true, "report_reasons": null, "author": "Namur007", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14bdhvs/api_with_1000_endpoints/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14bdhvs/api_with_1000_endpoints/", "subreddit_subscribers": 110930, "created_utc": 1686964462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m wondering because Data Analysis and Data Engineering are quite different, and if people who loved data analysis really end up liking data engineering. \n\nI\u2019m more into data analysis role, or bit mixed but don\u2019t use the fancy AWS, Apache, Azure and other tools. I like the other things I do (replication, transformations with complex SQL server stored procs and jobs, SSIS etc., used python in 1 project). DE is also more in demand, I\u2019m not so sure about putting the effort and making the change to be a DE.", "author_fullname": "t2_563z04ou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "For people who moved from being DA to DE, do you like the move?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14bu8cj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687016609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m wondering because Data Analysis and Data Engineering are quite different, and if people who loved data analysis really end up liking data engineering. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m more into data analysis role, or bit mixed but don\u2019t use the fancy AWS, Apache, Azure and other tools. I like the other things I do (replication, transformations with complex SQL server stored procs and jobs, SSIS etc., used python in 1 project). DE is also more in demand, I\u2019m not so sure about putting the effort and making the change to be a DE.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14bu8cj", "is_robot_indexable": true, "report_reasons": null, "author": "life_is_enjoy", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14bu8cj/for_people_who_moved_from_being_da_to_de_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14bu8cj/for_people_who_moved_from_being_da_to_de_do_you/", "subreddit_subscribers": 110930, "created_utc": 1687016609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So, I have been playing with dbt SCD using snapshot and stuck making relationship. I understood snapshot part of it, however snapshot scripts do not belong to model folder. If that's the case how do I make the relationship between fact table with SCD II (snapshot) dim table because I can't reference it?  \n\n\nAlso, Fivetran does not support running dbt snapshot in integrated mode ( I guess). Only option I could see is deploy deployment.yml which is really annoying because it runs on a fixed schedule. I want to run my transformation after the all referenced sources has been loaded which I can't gurantee via scheduled deployment.yml. Can someone help?", "author_fullname": "t2_hnxu1e2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran, dbt SCD II and Fact table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14bf8cb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686969639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, I have been playing with dbt SCD using snapshot and stuck making relationship. I understood snapshot part of it, however snapshot scripts do not belong to model folder. If that&amp;#39;s the case how do I make the relationship between fact table with SCD II (snapshot) dim table because I can&amp;#39;t reference it?  &lt;/p&gt;\n\n&lt;p&gt;Also, Fivetran does not support running dbt snapshot in integrated mode ( I guess). Only option I could see is deploy deployment.yml which is really annoying because it runs on a fixed schedule. I want to run my transformation after the all referenced sources has been loaded which I can&amp;#39;t gurantee via scheduled deployment.yml. Can someone help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14bf8cb", "is_robot_indexable": true, "report_reasons": null, "author": "boogie_woogie_100", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14bf8cb/fivetran_dbt_scd_ii_and_fact_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14bf8cb/fivetran_dbt_scd_ii_and_fact_table/", "subreddit_subscribers": 110930, "created_utc": 1686969639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team and I are trying to implement slim CI jobs on our pull requests into github and I've been tasked with setting up the configuration. I've read through the documentation on DBT's site and I believe things are set up correctly:\n\n* DBT account and github account are linked, DBT environments are also set up (DEV, UAT, PROD)\n* in the execution settings we're deferring to our production batch job that runs every 15 minutes\n* dbt command is \" dbt build --select state:modified+ \"\n* Triggers are set to run on PRs\n\nAll these settings according to DBT's documentation are correct and I'm able to initiate the slim CI job, but it's still attempting to run every single model within our project. Rather than just the modified model and the downstream dependencies like slim CI is designed to function. My only thought is that it's running all models because this job is set up in a separate DBT environment than our production run, which is what the deferral state is based off of.\n\nAnyone else experience similar issues, thanks in advance!", "author_fullname": "t2_71weyfry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Cloud Slim CI Job Not Working as Expected", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14bbgrg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686959031.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686958795.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team and I are trying to implement slim CI jobs on our pull requests into github and I&amp;#39;ve been tasked with setting up the configuration. I&amp;#39;ve read through the documentation on DBT&amp;#39;s site and I believe things are set up correctly:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;DBT account and github account are linked, DBT environments are also set up (DEV, UAT, PROD)&lt;/li&gt;\n&lt;li&gt;in the execution settings we&amp;#39;re deferring to our production batch job that runs every 15 minutes&lt;/li&gt;\n&lt;li&gt;dbt command is &amp;quot; dbt build --select state:modified+ &amp;quot;&lt;/li&gt;\n&lt;li&gt;Triggers are set to run on PRs&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;All these settings according to DBT&amp;#39;s documentation are correct and I&amp;#39;m able to initiate the slim CI job, but it&amp;#39;s still attempting to run every single model within our project. Rather than just the modified model and the downstream dependencies like slim CI is designed to function. My only thought is that it&amp;#39;s running all models because this job is set up in a separate DBT environment than our production run, which is what the deferral state is based off of.&lt;/p&gt;\n\n&lt;p&gt;Anyone else experience similar issues, thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14bbgrg", "is_robot_indexable": true, "report_reasons": null, "author": "DrunkenWhaler136", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14bbgrg/dbt_cloud_slim_ci_job_not_working_as_expected/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14bbgrg/dbt_cloud_slim_ci_job_not_working_as_expected/", "subreddit_subscribers": 110930, "created_utc": 1686958795.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my company we are currently use the \"alert\" feature of Metabase to keep an eye on certain metrics/tables that are important from a business POV, but through time a lot of alarms got created and now we have a little more than 400, many of them containing heavy/complex queries (joins, correlated subqueries, date functions)  that are evaluated every hour. \n\n&amp;#x200B;\n\nAlthough all of this queries are done against a read replica of our main DB, all of this constant queries  are obviously putting a lot of stress in this replica and doesn't seem to escalate in the future (users are requesting more and more alarms) .\n\n&amp;#x200B;\n\nCould any of you recommend me alternative arquitectures/ solutions for this type of \"alarming\" systems that consist on making queries to a DB (the read replica and the main DB are both MySQL databases hosted in AWS) and alerting based on the values of such queries? How do you manage alerts in your company?", "author_fullname": "t2_zn4k7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommended Infra for alerting system tied to a SQL DB", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14buvwi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687018259.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my company we are currently use the &amp;quot;alert&amp;quot; feature of Metabase to keep an eye on certain metrics/tables that are important from a business POV, but through time a lot of alarms got created and now we have a little more than 400, many of them containing heavy/complex queries (joins, correlated subqueries, date functions)  that are evaluated every hour. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Although all of this queries are done against a read replica of our main DB, all of this constant queries  are obviously putting a lot of stress in this replica and doesn&amp;#39;t seem to escalate in the future (users are requesting more and more alarms) .&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Could any of you recommend me alternative arquitectures/ solutions for this type of &amp;quot;alarming&amp;quot; systems that consist on making queries to a DB (the read replica and the main DB are both MySQL databases hosted in AWS) and alerting based on the values of such queries? How do you manage alerts in your company?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14buvwi", "is_robot_indexable": true, "report_reasons": null, "author": "DUM00", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14buvwi/recommended_infra_for_alerting_system_tied_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14buvwi/recommended_infra_for_alerting_system_tied_to_a/", "subreddit_subscribers": 110930, "created_utc": 1687018259.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are setting up a pipeline from AWS RDBMS to Databricks and evaluating how to continuously transform the data into a columnar store: [Databricks DLT jobs](https://www.databricks.com/blog/2022/04/25/simplifying-change-data-capture-with-databricks-delta-live-tables.html) or [AWS Glue/Lambdas/Kinesis/etc](https://aws.amazon.com/blogs/big-data/build-incremental-data-pipelines-to-load-transactional-data-changes-using-aws-dms-delta-2-0-and-amazon-emr-serverless/).\n\nDoes anyone have experience with fully automating the columnar transformation part of the pipeline? Is this possible?\n\nOverall, what we want to achieve is a low-maintenance system that can handle our ongoing RDBMS schema changes without additional intervention if possible. We don't have strong latency requirements at this time.\n\nThanks.", "author_fullname": "t2_dk4dxkd3g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CDC schema automation with Databricks DLT vs. AWS Glue/Lambdas?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14b9cm6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1686978624.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1686953317.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are setting up a pipeline from AWS RDBMS to Databricks and evaluating how to continuously transform the data into a columnar store: &lt;a href=\"https://www.databricks.com/blog/2022/04/25/simplifying-change-data-capture-with-databricks-delta-live-tables.html\"&gt;Databricks DLT jobs&lt;/a&gt; or &lt;a href=\"https://aws.amazon.com/blogs/big-data/build-incremental-data-pipelines-to-load-transactional-data-changes-using-aws-dms-delta-2-0-and-amazon-emr-serverless/\"&gt;AWS Glue/Lambdas/Kinesis/etc&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have experience with fully automating the columnar transformation part of the pipeline? Is this possible?&lt;/p&gt;\n\n&lt;p&gt;Overall, what we want to achieve is a low-maintenance system that can handle our ongoing RDBMS schema changes without additional intervention if possible. We don&amp;#39;t have strong latency requirements at this time.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XAc38jEPeQ2bo7Lal5Fy_p9QRa6z5eaI6wohF5POKOQ.jpg?auto=webp&amp;v=enabled&amp;s=ddff45fae01c06370c759b9931b9077847c6d361", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/XAc38jEPeQ2bo7Lal5Fy_p9QRa6z5eaI6wohF5POKOQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c6f2eb1bf83d14e6bd589bff4c1e7b1c5e47bcd8", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/XAc38jEPeQ2bo7Lal5Fy_p9QRa6z5eaI6wohF5POKOQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=afb6dbcfc1b4d767051677ffe770f7e58aebf520", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/XAc38jEPeQ2bo7Lal5Fy_p9QRa6z5eaI6wohF5POKOQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c98b115acd54fb4ad57766e9784aa21285058754", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/XAc38jEPeQ2bo7Lal5Fy_p9QRa6z5eaI6wohF5POKOQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=c32ee7f066f7b62484afd6decd874910f19c893f", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/XAc38jEPeQ2bo7Lal5Fy_p9QRa6z5eaI6wohF5POKOQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=1c67e25da31639aab18847655871a22985eea1d1", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/XAc38jEPeQ2bo7Lal5Fy_p9QRa6z5eaI6wohF5POKOQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;v=enabled&amp;s=03e7895da40e6d1c4c85a0e7c5efb2eb892f4d91", "width": 1080, "height": 565}], "variants": {}, "id": "ygY9JKKNhmxY0oZd2uwBDVmGqTQce4B1UZt1ribYLPM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14b9cm6", "is_robot_indexable": true, "report_reasons": null, "author": "ComprehensivePart288", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14b9cm6/cdc_schema_automation_with_databricks_dlt_vs_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14b9cm6/cdc_schema_automation_with_databricks_dlt_vs_aws/", "subreddit_subscribers": 110930, "created_utc": 1686953317.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What is the fastest way to run a small etl pipeline on a single node databricks cluster. \n\nUsing sqlalchemy and polars to read and wrangle is quite a bit faster than using the overhead of pyspark. The bottleneck is writing if data is smallish yet not tiny (e.g. 5 to 10 million rows).\n\nWhat is the best approach here? Pandas to_sql with sqlalchemy engine set to fast_executemany=True works okayish. Is molding the pandas df into a spark df and then using pyspark to export faster? Are there other faster options?", "author_fullname": "t2_72m7mvsq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Writing to Azure SQL server from single node DBX cluster", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14b7475", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686947215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the fastest way to run a small etl pipeline on a single node databricks cluster. &lt;/p&gt;\n\n&lt;p&gt;Using sqlalchemy and polars to read and wrangle is quite a bit faster than using the overhead of pyspark. The bottleneck is writing if data is smallish yet not tiny (e.g. 5 to 10 million rows).&lt;/p&gt;\n\n&lt;p&gt;What is the best approach here? Pandas to_sql with sqlalchemy engine set to fast_executemany=True works okayish. Is molding the pandas df into a spark df and then using pyspark to export faster? Are there other faster options?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14b7475", "is_robot_indexable": true, "report_reasons": null, "author": "Majestic-Weakness239", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14b7475/writing_to_azure_sql_server_from_single_node_dbx/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14b7475/writing_to_azure_sql_server_from_single_node_dbx/", "subreddit_subscribers": 110930, "created_utc": 1686947215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I overheard a conversation that data-oriented programming is old school and Data oriented programming is the better way to programming. \n\nCan I use DOP outside of game development? I really want to understand more", "author_fullname": "t2_8skbp1qj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "?? Server efficiency through Data Oriented Design??", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14b7nu4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686948543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I overheard a conversation that data-oriented programming is old school and Data oriented programming is the better way to programming. &lt;/p&gt;\n\n&lt;p&gt;Can I use DOP outside of game development? I really want to understand more&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14b7nu4", "is_robot_indexable": true, "report_reasons": null, "author": "Positive-Fly4773", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14b7nu4/server_efficiency_through_data_oriented_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14b7nu4/server_efficiency_through_data_oriented_design/", "subreddit_subscribers": 110930, "created_utc": 1686948543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've got a salary negotiation coming up for a lead role, and I'm aiming to secure the highest possible figure. Beyond this, I'm also looking for additional benefits and perks.\n\nAre there any unique benefits some of you receive and find worthwhile?\n\nI should mention I'm not really interested in standard perks like gym memberships. I'm seeking more substantial 'extras' - good pension contributions being an example. Any suggestions?  \n\n\nI am UK based.", "author_fullname": "t2_9xgjq37w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice on Salary Negotiation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14bwzlg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687023678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve got a salary negotiation coming up for a lead role, and I&amp;#39;m aiming to secure the highest possible figure. Beyond this, I&amp;#39;m also looking for additional benefits and perks.&lt;/p&gt;\n\n&lt;p&gt;Are there any unique benefits some of you receive and find worthwhile?&lt;/p&gt;\n\n&lt;p&gt;I should mention I&amp;#39;m not really interested in standard perks like gym memberships. I&amp;#39;m seeking more substantial &amp;#39;extras&amp;#39; - good pension contributions being an example. Any suggestions?  &lt;/p&gt;\n\n&lt;p&gt;I am UK based.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14bwzlg", "is_robot_indexable": true, "report_reasons": null, "author": "P_Cosmin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14bwzlg/seeking_advice_on_salary_negotiation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14bwzlg/seeking_advice_on_salary_negotiation/", "subreddit_subscribers": 110930, "created_utc": 1687023678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently a 30 year old branch manager at a regional bank and I am thinking about moving into a career working with big data. I made it halfway through a data analytics degree with WGU and I only have in Comptia A+ certification. Since I had so many IT classes already done I ended up getting a business administration, IT management degree. After getting that degree I had so many credits that I only needed to take a few more classes to end up with a finance degree as well. I thought the finance degree was appropriate given the fact that I have a few investment licenses and I am the branch manager of the bank. I thought it would be beneficial to know more about finance than what I already know now I\u2019m thinking I can combine my interest in IT with finance by moving in so big data and learning PowerBI or tableau. I was considering maybe taking the data plus Comptia certification, or maybe just getting certified as a powerBI data analyst or tableau analyst. Ive really grown to dislike retail banking and I\u2019m looking to move into working with data. If you were in my shoes, knowing what you know, where would you go from here?", "author_fullname": "t2_z4tgcp4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking advice on career change", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_14byf4e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687027399.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a 30 year old branch manager at a regional bank and I am thinking about moving into a career working with big data. I made it halfway through a data analytics degree with WGU and I only have in Comptia A+ certification. Since I had so many IT classes already done I ended up getting a business administration, IT management degree. After getting that degree I had so many credits that I only needed to take a few more classes to end up with a finance degree as well. I thought the finance degree was appropriate given the fact that I have a few investment licenses and I am the branch manager of the bank. I thought it would be beneficial to know more about finance than what I already know now I\u2019m thinking I can combine my interest in IT with finance by moving in so big data and learning PowerBI or tableau. I was considering maybe taking the data plus Comptia certification, or maybe just getting certified as a powerBI data analyst or tableau analyst. Ive really grown to dislike retail banking and I\u2019m looking to move into working with data. If you were in my shoes, knowing what you know, where would you go from here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14byf4e", "is_robot_indexable": true, "report_reasons": null, "author": "Kroger011", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14byf4e/seeking_advice_on_career_change/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14byf4e/seeking_advice_on_career_change/", "subreddit_subscribers": 110930, "created_utc": 1687027399.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm curious if anyone else has transitioned to data engineering from a non-data/software-engineering background. I enrolled at a reputable university twenty years ago in an IT program but after taking one quarter of Java programming, decided I wanted a career that involved more interaction with people, and switched to a liberal studies program. Even then, I've always possessed a high level of technological proficiency (fast learner, good troubleshooting skills).\n\nFast-forward two decades later and I have two Masters degrees in education, the latest focusing on instructional design. Unfortunately, I am feeling burnt out and wholly unmotivated to continue my trajectory in ID/education.\n\nOne thing I found myself most enjoying during my educational career was, surprisingly, use of Microsoft Excel. In the past year, I took it upon myself to learn Excel in-depth via an online course (Power Query, specifically) to do contract survey data work (cleaning, wrangling, and visualization). I loved it!\n\nUpon exploring new careers related to that sort of work, I came upon this subreddit. I've been trying a little bit of this and that (learning basics of SQL, reading the books Complete Reference of Star Schema and Designing Data-Intensive Applications) and also enjoyed my time dappling in those.\n\nSo, with my fascination with DE, I just picked up Fundamentals of Data Engineering and have set it upon myself to finish the whole book while also learning Python from scratch. I have two potential mentors that I'm meeting with soon (one a DE, and one HCI engineer who teaches Python). I'm also \\~40 years old, and an enthusiastic learner. I'm curious if you had any advice to share. Thank you!", "author_fullname": "t2_6gk31", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Change to DE from a Non-Data/Coding Career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14bvy46", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687021009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m curious if anyone else has transitioned to data engineering from a non-data/software-engineering background. I enrolled at a reputable university twenty years ago in an IT program but after taking one quarter of Java programming, decided I wanted a career that involved more interaction with people, and switched to a liberal studies program. Even then, I&amp;#39;ve always possessed a high level of technological proficiency (fast learner, good troubleshooting skills).&lt;/p&gt;\n\n&lt;p&gt;Fast-forward two decades later and I have two Masters degrees in education, the latest focusing on instructional design. Unfortunately, I am feeling burnt out and wholly unmotivated to continue my trajectory in ID/education.&lt;/p&gt;\n\n&lt;p&gt;One thing I found myself most enjoying during my educational career was, surprisingly, use of Microsoft Excel. In the past year, I took it upon myself to learn Excel in-depth via an online course (Power Query, specifically) to do contract survey data work (cleaning, wrangling, and visualization). I loved it!&lt;/p&gt;\n\n&lt;p&gt;Upon exploring new careers related to that sort of work, I came upon this subreddit. I&amp;#39;ve been trying a little bit of this and that (learning basics of SQL, reading the books Complete Reference of Star Schema and Designing Data-Intensive Applications) and also enjoyed my time dappling in those.&lt;/p&gt;\n\n&lt;p&gt;So, with my fascination with DE, I just picked up Fundamentals of Data Engineering and have set it upon myself to finish the whole book while also learning Python from scratch. I have two potential mentors that I&amp;#39;m meeting with soon (one a DE, and one HCI engineer who teaches Python). I&amp;#39;m also ~40 years old, and an enthusiastic learner. I&amp;#39;m curious if you had any advice to share. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "14bvy46", "is_robot_indexable": true, "report_reasons": null, "author": "bammerburn", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14bvy46/career_change_to_de_from_a_nondatacoding_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14bvy46/career_change_to_de_from_a_nondatacoding_career/", "subreddit_subscribers": 110930, "created_utc": 1687021009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What architecture are used by these websites to process such huge datas", "author_fullname": "t2_edd5jfxc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Explain me how websites like Dall-E, chatgpt, thispersondoesntexit process the user data so quickly", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14bufkt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687017127.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What architecture are used by these websites to process such huge datas&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "14bufkt", "is_robot_indexable": true, "report_reasons": null, "author": "bitch_lasagna_hehe", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14bufkt/explain_me_how_websites_like_dalle_chatgpt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14bufkt/explain_me_how_websites_like_dalle_chatgpt/", "subreddit_subscribers": 110930, "created_utc": 1687017127.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Disclaimer: I'm not a data engineer. I'm evaluating my concept and want to validate its feasibility. Please let me know if this makes sense or can be performed differently. I don't believe these are technical bug / error questions. If anything I'm determining if I understand the concept (s).\n\n\nHypothetical Scenario: \n1. Dataset created from output of EVA Work package  Progress measurements \n2. Excel CSV file extracted from shared folder- Leads submit files for work packages daily for work packages they are responsible for. \n3. Data within range values validated by type of data and number of characters. (Expected ranges are based on a 4 tier scale defined by an upper and lower control limit.)\n4. Business rules based on 17 sql logic statements using fuzzy adjectives. \n5. Staging database is \"Temp_table\" located in MS SQL server.\n6. Target table is \"WPPM_Production_Table\" in MS SQL server data warehouse.\n\nQuestions: \n\nA. Would this be considered an ETL pipeline \nwith data processed in batch from source databases?\n\nB. Is data extraction from CSV files necessary? Or would the MDS add on for Excel make this easier with numerous leads and work packages?\n\nC. Data validation--is it better to validate at the application level or data warehouse based on the scenario? And is one better than the other? Would use of MDS invalidate the need for data validation in Excel? \n\nD. Would this scenario require creating aggregates? \n\nE. Are triggers more advisable if MDS is not used? Or does that even matter? \n\nF. Is there a specific data model that describes this scenario? \n\nG. Is it good practice / acceptable to maintain the Staging database and data warehouse on the same platform (i.e. MS SQL?)", "author_fullname": "t2_ph1t3ewm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice from experts", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14bg2jh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1686972257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Disclaimer: I&amp;#39;m not a data engineer. I&amp;#39;m evaluating my concept and want to validate its feasibility. Please let me know if this makes sense or can be performed differently. I don&amp;#39;t believe these are technical bug / error questions. If anything I&amp;#39;m determining if I understand the concept (s).&lt;/p&gt;\n\n&lt;p&gt;Hypothetical Scenario: \n1. Dataset created from output of EVA Work package  Progress measurements \n2. Excel CSV file extracted from shared folder- Leads submit files for work packages daily for work packages they are responsible for. \n3. Data within range values validated by type of data and number of characters. (Expected ranges are based on a 4 tier scale defined by an upper and lower control limit.)\n4. Business rules based on 17 sql logic statements using fuzzy adjectives. \n5. Staging database is &amp;quot;Temp_table&amp;quot; located in MS SQL server.\n6. Target table is &amp;quot;WPPM_Production_Table&amp;quot; in MS SQL server data warehouse.&lt;/p&gt;\n\n&lt;p&gt;Questions: &lt;/p&gt;\n\n&lt;p&gt;A. Would this be considered an ETL pipeline \nwith data processed in batch from source databases?&lt;/p&gt;\n\n&lt;p&gt;B. Is data extraction from CSV files necessary? Or would the MDS add on for Excel make this easier with numerous leads and work packages?&lt;/p&gt;\n\n&lt;p&gt;C. Data validation--is it better to validate at the application level or data warehouse based on the scenario? And is one better than the other? Would use of MDS invalidate the need for data validation in Excel? &lt;/p&gt;\n\n&lt;p&gt;D. Would this scenario require creating aggregates? &lt;/p&gt;\n\n&lt;p&gt;E. Are triggers more advisable if MDS is not used? Or does that even matter? &lt;/p&gt;\n\n&lt;p&gt;F. Is there a specific data model that describes this scenario? &lt;/p&gt;\n\n&lt;p&gt;G. Is it good practice / acceptable to maintain the Staging database and data warehouse on the same platform (i.e. MS SQL?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "14bg2jh", "is_robot_indexable": true, "report_reasons": null, "author": "Kobalt13mm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14bg2jh/need_advice_from_experts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14bg2jh/need_advice_from_experts/", "subreddit_subscribers": 110930, "created_utc": 1686972257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "You can find the post here: [https://mertkavi.com/spark-is-still-a-safe-port-when-compared-to-duckdb-and-polars/](https://mertkavi.com/spark-is-still-a-safe-port-when-compared-to-duckdb-and-polars/)", "author_fullname": "t2_viac4r3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark is still a safe port when compared to DuckDB and Polars", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_14bvvhk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1687020818.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;You can find the post here: &lt;a href=\"https://mertkavi.com/spark-is-still-a-safe-port-when-compared-to-duckdb-and-polars/\"&gt;https://mertkavi.com/spark-is-still-a-safe-port-when-compared-to-duckdb-and-polars/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "14bvvhk", "is_robot_indexable": true, "report_reasons": null, "author": "mertkavi", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/14bvvhk/spark_is_still_a_safe_port_when_compared_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/14bvvhk/spark_is_still_a_safe_port_when_compared_to/", "subreddit_subscribers": 110930, "created_utc": 1687020818.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}