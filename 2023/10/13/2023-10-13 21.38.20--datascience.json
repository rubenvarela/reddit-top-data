{"kind": "Listing", "data": {"after": "t3_176rwg6", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I ended up getting laid off today from my role as a data scientist after a little more than a year. It was framed as a \"reorganization\" by a higher up and that my role had been eliminated.\n\nAnyways, they offered to help shop me around to some other internal teams and I'll be meeting with two other DS managers in the next week. Before I meet with them, I was wondering if anyone could offer any advice for the situation and how to proceed. I'd really appreciate it.\n\nDoes anyone have any advice for how to use these meetings to their fullest, and maximize my chance of landing another role? How direct should I be about wanting to join their teams? I know my biggest selling point is that there's no training period, I'm already familiar with all the datasets and industry. I'm going to spend tomorrow trying to summarize all the work I've done at the company since I got hired.\n\nSome other key details below:\n\n- Was told I was rehire eligible. They specifically said that severance wouldn't be impacted if I boomeranged unless I switched teams before final date (1 month).\n- Worked for over a year and have 2.5 years of experience in data science.\n- Probably was on the bottom half of performers, but I wasn't the worst. I was the most recent hire though. My boss's boss offered to write a letter of recommendation, probably was a casualty of money, seniority, and not being a top performer. Was given a large new project two weeks ago.\n- The company is large but has a small amount of tech and is about to lose a lot of money in the coming year. Could be a negative for staying if I find a new role.\n\nI'm going to keep the ranting to a minimum because this post is pretty identifiable, but I'm honestly at a loss of what to do. I moved across the country for the role (in-person) and turned down a higher paying offer as a quant. I finally got an ounce of stability after not having any for years and I got laid off without even a PIP or a warning. I guess that's life but god damn.", "author_fullname": "t2_lnimx58p7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got hit with a layoff today but they offered to shop me around internally, any advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176nzqe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 77, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 77, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697163196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ended up getting laid off today from my role as a data scientist after a little more than a year. It was framed as a &amp;quot;reorganization&amp;quot; by a higher up and that my role had been eliminated.&lt;/p&gt;\n\n&lt;p&gt;Anyways, they offered to help shop me around to some other internal teams and I&amp;#39;ll be meeting with two other DS managers in the next week. Before I meet with them, I was wondering if anyone could offer any advice for the situation and how to proceed. I&amp;#39;d really appreciate it.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any advice for how to use these meetings to their fullest, and maximize my chance of landing another role? How direct should I be about wanting to join their teams? I know my biggest selling point is that there&amp;#39;s no training period, I&amp;#39;m already familiar with all the datasets and industry. I&amp;#39;m going to spend tomorrow trying to summarize all the work I&amp;#39;ve done at the company since I got hired.&lt;/p&gt;\n\n&lt;p&gt;Some other key details below:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Was told I was rehire eligible. They specifically said that severance wouldn&amp;#39;t be impacted if I boomeranged unless I switched teams before final date (1 month).&lt;/li&gt;\n&lt;li&gt;Worked for over a year and have 2.5 years of experience in data science.&lt;/li&gt;\n&lt;li&gt;Probably was on the bottom half of performers, but I wasn&amp;#39;t the worst. I was the most recent hire though. My boss&amp;#39;s boss offered to write a letter of recommendation, probably was a casualty of money, seniority, and not being a top performer. Was given a large new project two weeks ago.&lt;/li&gt;\n&lt;li&gt;The company is large but has a small amount of tech and is about to lose a lot of money in the coming year. Could be a negative for staying if I find a new role.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m going to keep the ranting to a minimum because this post is pretty identifiable, but I&amp;#39;m honestly at a loss of what to do. I moved across the country for the role (in-person) and turned down a higher paying offer as a quant. I finally got an ounce of stability after not having any for years and I got laid off without even a PIP or a warning. I guess that&amp;#39;s life but god damn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176nzqe", "is_robot_indexable": true, "report_reasons": null, "author": "Smart_Donut_9558", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176nzqe/got_hit_with_a_layoff_today_but_they_offered_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176nzqe/got_hit_with_a_layoff_today_but_they_offered_to/", "subreddit_subscribers": 1083153, "created_utc": 1697163196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been in data science about 3 years and I\u2019m just miserable coding day in and day out. I\u2019ve applied to some manager jobs but haven\u2019t gotten and the ones that I have been offered pay less than what I make now.\n\nI\u2019m looking for something more business facing, that could be a good career transition for someone who enjoys tech but doesn\u2019t have his heart in programming after doing it since college 9 years ago, and doing it daily since.", "author_fullname": "t2_f50rnaa0x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jobs to switch to from Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176ndbd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 71, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 71, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697161208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been in data science about 3 years and I\u2019m just miserable coding day in and day out. I\u2019ve applied to some manager jobs but haven\u2019t gotten and the ones that I have been offered pay less than what I make now.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking for something more business facing, that could be a good career transition for someone who enjoys tech but doesn\u2019t have his heart in programming after doing it since college 9 years ago, and doing it daily since.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176ndbd", "is_robot_indexable": true, "report_reasons": null, "author": "Frequent_Anybody2984", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176ndbd/jobs_to_switch_to_from_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176ndbd/jobs_to_switch_to_from_data_science/", "subreddit_subscribers": 1083153, "created_utc": 1697161208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Two months ago, I was laid off from my role as a data scientist after 2 years. It was \"reduction in force\" and my role was affected. \n\nSome background:\n\n* Previous Role: Data Scientist 1\n* 2 yrs of xp, master's in statistics\n* Had a big tech company as long term client at previous role (13 months)\n* I was in top 10% of performers (98% billable hours and internal recognition for innovation)\n* Was confirmed for promotion.\n\nIt took me 5 years of studying and interviewing to get to my first position with this company, worked my butt off to get the long term client, and now I'm laid off. What should I do about this market? I barely see any positions open for someone like my self.", "author_fullname": "t2_7p8ba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "It's been two months since I was laid off as a DS. Any advice on how to deal with current market.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177479m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697218719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Two months ago, I was laid off from my role as a data scientist after 2 years. It was &amp;quot;reduction in force&amp;quot; and my role was affected. &lt;/p&gt;\n\n&lt;p&gt;Some background:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Previous Role: Data Scientist 1&lt;/li&gt;\n&lt;li&gt;2 yrs of xp, master&amp;#39;s in statistics&lt;/li&gt;\n&lt;li&gt;Had a big tech company as long term client at previous role (13 months)&lt;/li&gt;\n&lt;li&gt;I was in top 10% of performers (98% billable hours and internal recognition for innovation)&lt;/li&gt;\n&lt;li&gt;Was confirmed for promotion.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;It took me 5 years of studying and interviewing to get to my first position with this company, worked my butt off to get the long term client, and now I&amp;#39;m laid off. What should I do about this market? I barely see any positions open for someone like my self.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "177479m", "is_robot_indexable": true, "report_reasons": null, "author": "VodkaRain", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/177479m/its_been_two_months_since_i_was_laid_off_as_a_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/177479m/its_been_two_months_since_i_was_laid_off_as_a_ds/", "subreddit_subscribers": 1083153, "created_utc": 1697218719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Can't wait to read your comment!", "author_fullname": "t2_nk2pd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In your time working with data science at a corporation, what cool things did you pick up / learn that school didn't teach you?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1775fq0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697222068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can&amp;#39;t wait to read your comment!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1775fq0", "is_robot_indexable": true, "report_reasons": null, "author": "TheEnlightenedMan", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1775fq0/in_your_time_working_with_data_science_at_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1775fq0/in_your_time_working_with_data_science_at_a/", "subreddit_subscribers": 1083153, "created_utc": 1697222068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_85cmewqj1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "James Lamb (Light GBM) on getting into open source from a data science background", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_176zysn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CA5ljRcO8qhuajetWTxUkpOOaSXExPqx4uAGXdCqnjQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697207123.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/onceamaintainer/p/once-a-maintainer-james-lamb?r=2773u5&amp;utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/IGdfssSn73iVq388ZBmkl-YN6EuPfKdjIBmMvkHYPGE.jpg?auto=webp&amp;s=da316339b8949f4c2c7ecef0db4d2e9974f7af75", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/IGdfssSn73iVq388ZBmkl-YN6EuPfKdjIBmMvkHYPGE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6452db1aaa12574514c5c622bdd13914cae6fe59", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/IGdfssSn73iVq388ZBmkl-YN6EuPfKdjIBmMvkHYPGE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=04b808bb7428e5c8f536fae0a0bc25fa2feb2fdb", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/IGdfssSn73iVq388ZBmkl-YN6EuPfKdjIBmMvkHYPGE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a629ceb467c4cd1725c4cb7d304b4db6a5cf3f18", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/IGdfssSn73iVq388ZBmkl-YN6EuPfKdjIBmMvkHYPGE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=331d5384de9e17183b62cffde4e0a1bd10f2349b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/IGdfssSn73iVq388ZBmkl-YN6EuPfKdjIBmMvkHYPGE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f10f645f6860eb24ced1c613971a57ffdffa2c10", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/IGdfssSn73iVq388ZBmkl-YN6EuPfKdjIBmMvkHYPGE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=966f45695d5f7e5080d05b6ff25cd4aba83ddc56", "width": 1080, "height": 540}], "variants": {}, "id": "sxyDtyHf3JYD_wC19hncpBhaKtSTR01KZrVw39pqxi0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "176zysn", "is_robot_indexable": true, "report_reasons": null, "author": "rubiesordiamonds", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176zysn/james_lamb_light_gbm_on_getting_into_open_source/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/onceamaintainer/p/once-a-maintainer-james-lamb?r=2773u5&amp;utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 1083153, "created_utc": 1697207123.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\n\n\nFirst time posting here so not sure this is where it belongs.\n\n\n\nI do crime intelligence with data analytics at university and was lucky enough to score an internship. However, I've not had much experience in SQL or Power BI, neither of which the internship need either.\n\n\n\nI wanted to do a small project on the side to play around with these and learn some more. Can anyone help me with some ideas, or even just a starting point for this?\n\n\n\nNothing to publish, solely extra academic learning I can play with. Thanks !", "author_fullname": "t2_31tuq20y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to improve more!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1773x9b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697217932.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;First time posting here so not sure this is where it belongs.&lt;/p&gt;\n\n&lt;p&gt;I do crime intelligence with data analytics at university and was lucky enough to score an internship. However, I&amp;#39;ve not had much experience in SQL or Power BI, neither of which the internship need either.&lt;/p&gt;\n\n&lt;p&gt;I wanted to do a small project on the side to play around with these and learn some more. Can anyone help me with some ideas, or even just a starting point for this?&lt;/p&gt;\n\n&lt;p&gt;Nothing to publish, solely extra academic learning I can play with. Thanks !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1773x9b", "is_robot_indexable": true, "report_reasons": null, "author": "RebeccaMayy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1773x9b/i_want_to_improve_more/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1773x9b/i_want_to_improve_more/", "subreddit_subscribers": 1083153, "created_utc": 1697217932.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello guys and girls,\n\nI'm a State Veterinarian Officer in Brazil and work in a public agency that has as goal prevent, control or erradicate some diseases related to farm animals. In order to do that, we apply measures like restrict animal movement, culling, take samples, among others.\n\nAll this measures relly on a database system of all farms, animals movements between them and records of borns, deaths and other occurences. This database is mostly filled with information provided by farmers, what we call declaratory data.\n\nBut to ensure the quality and reliability of this data, one of our tasks is inspect farms in loco to correct any wrong or incomplete information. \n\nSo, I have this database with data not audited and data audited with it's outcomes: data needed to be corrected and don't.\n\nWe want to optimize this auditions by analysing the data and find wich farms are proner to have misleading data throught comparations to variables like: quantity of animals, quantity of animal movements, region, age of farmers, etc\n\nSo I would like advice to how to approach this problem. Like: methods, books, papers, authors, really, anything helps. One of major problems I see is, although I have outcomes to inspected farms, it's not representative as it's not a random sample, so how to look to it? \n\nObs.: I have skills with R, SQL and a bit of Python. And already conducted a project in my master degree with INLA.\n\nThanks in advance.", "author_fullname": "t2_2oa2pvy7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance to analyze data reliability and variables related", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176yuks", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697204435.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697203951.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys and girls,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a State Veterinarian Officer in Brazil and work in a public agency that has as goal prevent, control or erradicate some diseases related to farm animals. In order to do that, we apply measures like restrict animal movement, culling, take samples, among others.&lt;/p&gt;\n\n&lt;p&gt;All this measures relly on a database system of all farms, animals movements between them and records of borns, deaths and other occurences. This database is mostly filled with information provided by farmers, what we call declaratory data.&lt;/p&gt;\n\n&lt;p&gt;But to ensure the quality and reliability of this data, one of our tasks is inspect farms in loco to correct any wrong or incomplete information. &lt;/p&gt;\n\n&lt;p&gt;So, I have this database with data not audited and data audited with it&amp;#39;s outcomes: data needed to be corrected and don&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;We want to optimize this auditions by analysing the data and find wich farms are proner to have misleading data throught comparations to variables like: quantity of animals, quantity of animal movements, region, age of farmers, etc&lt;/p&gt;\n\n&lt;p&gt;So I would like advice to how to approach this problem. Like: methods, books, papers, authors, really, anything helps. One of major problems I see is, although I have outcomes to inspected farms, it&amp;#39;s not representative as it&amp;#39;s not a random sample, so how to look to it? &lt;/p&gt;\n\n&lt;p&gt;Obs.: I have skills with R, SQL and a bit of Python. And already conducted a project in my master degree with INLA.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176yuks", "is_robot_indexable": true, "report_reasons": null, "author": "lfelipecl", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176yuks/guidance_to_analyze_data_reliability_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176yuks/guidance_to_analyze_data_reliability_and/", "subreddit_subscribers": 1083153, "created_utc": 1697203951.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "During my PhD, I got increasingly into statistical computing and greatly benefited from Andy Field's \"Discovering Statistics Using R\" book. This was particularly useful as my background is in biomedical sciences and clinical trials. I ended up doing my PhD secondment in a computational biology lab, where I was programming in R and python every day. It was here that I started leaning more on tidyverse for my R analyses.\n\n  \nSeveral years later, I've left the academic world and I am a consultant in the pharma industry. I really need to go back and recap some fundamental statistics. Can anyone recommend alternatives to Andy Field's \"Discovering Statistics Using R\", which uses the tidyverse package? I know Andy himself is currently re-writing his book to include tidyverse but this is taking years to be released.\n\n  \nAs a secondary question / discussion point for those aficionados in the community: is it even a good idea for me to refresh my statistics knowledge through the tidyverse language? I know there is the debate in the community regarding base language vs tidyverse. But I don't know how much of that is reflective of the typical old generation vs new generation programmers. Thoughts?", "author_fullname": "t2_vje69p4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guides that explore statistical theory and concepts through analysis in R using tidyverse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176uhmx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697188094.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;During my PhD, I got increasingly into statistical computing and greatly benefited from Andy Field&amp;#39;s &amp;quot;Discovering Statistics Using R&amp;quot; book. This was particularly useful as my background is in biomedical sciences and clinical trials. I ended up doing my PhD secondment in a computational biology lab, where I was programming in R and python every day. It was here that I started leaning more on tidyverse for my R analyses.&lt;/p&gt;\n\n&lt;p&gt;Several years later, I&amp;#39;ve left the academic world and I am a consultant in the pharma industry. I really need to go back and recap some fundamental statistics. Can anyone recommend alternatives to Andy Field&amp;#39;s &amp;quot;Discovering Statistics Using R&amp;quot;, which uses the tidyverse package? I know Andy himself is currently re-writing his book to include tidyverse but this is taking years to be released.&lt;/p&gt;\n\n&lt;p&gt;As a secondary question / discussion point for those aficionados in the community: is it even a good idea for me to refresh my statistics knowledge through the tidyverse language? I know there is the debate in the community regarding base language vs tidyverse. But I don&amp;#39;t know how much of that is reflective of the typical old generation vs new generation programmers. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176uhmx", "is_robot_indexable": true, "report_reasons": null, "author": "FrancisGrant1", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176uhmx/guides_that_explore_statistical_theory_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176uhmx/guides_that_explore_statistical_theory_and/", "subreddit_subscribers": 1083153, "created_utc": 1697188094.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udcca\ud83d\udca1 Dive into a comprehensive guide on Multilinear Regression Model, covering each stage from data collection to evaluation! \ud83d\udcc8\ud83e\uddea", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_176tcip", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Multiple Linear Regression using python ( Regression Analysis )\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_roxmtd1o", "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Multiple Linear Regression using python ( Regression Analysis )", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Multiple Linear Regression using python ( Regression Analysis )\"&gt;&lt;/iframe&gt;", "author_name": "Machine Learning With me", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/SHa-58-n6ew/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MLwithme1617"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Multiple Linear Regression using python ( Regression Analysis )\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/176tcip", "height": 200}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1ZfJ-n84dSb-KJRzmBENcVvGKQAD5KWZx-jRs41x8mk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "learndatascience", "selftext": "", "author_fullname": "t2_roxmtd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udcca\ud83d\udca1 Dive into a comprehensive guide on Multilinear Regression Model, covering each stage from data collection to evaluation! \ud83d\udcc8\ud83e\uddea", "link_flair_richtext": [], "subreddit_name_prefixed": "r/learndatascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12k4vi1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Linear Regression (MLR) || EDA,  Feature engineering, Feature selection\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Linear Regression (MLR) || EDA,  Feature engineering, Feature selection", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Linear Regression (MLR) || EDA,  Feature engineering, Feature selection\"&gt;&lt;/iframe&gt;", "author_name": "Machine Learning With me", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/SHa-58-n6ew/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MLwithme1617"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Linear Regression (MLR) || EDA,  Feature engineering, Feature selection\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/12k4vi1", "height": 200}, "link_flair_text": "Original Content", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LJyavExHIjeTWAM2fdMCv1o2JI-NYp8a3wMtOt1FgkA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681344409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=SHa-58-n6ew", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?auto=webp&amp;s=e8ef5bb2c509762dfe2628fe6504fc18225fa5fe", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff2d73917a7d594a8d884c5ff9eb03a8c6894530", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3228adfc8081b0eecd3d28af77e2970bafc9b22f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5cc0c4df54c584d83a37f25b93f8dac9005e3150", "width": 320, "height": 240}], "variants": {}, "id": "BIz7RkTKofDIZ5k0s0nZfttlg7WqfKKwbxsmxxir82k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cc42d03c-a895-11ea-9782-0ef4de97b701", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_33xxb", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "12k4vi1", "is_robot_indexable": true, "report_reasons": null, "author": "MLwithMe1617", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/learndatascience/comments/12k4vi1/dive_into_a_comprehensive_guide_on_multilinear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=SHa-58-n6ew", "subreddit_subscribers": 14886, "created_utc": 1681344409.0, "num_crossposts": 1, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Linear Regression (MLR) || EDA,  Feature engineering, Feature selection", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Linear Regression (MLR) || EDA,  Feature engineering, Feature selection\"&gt;&lt;/iframe&gt;", "author_name": "Machine Learning With me", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/SHa-58-n6ew/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MLwithme1617"}}, "is_video": false}], "created": 1697183076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=SHa-58-n6ew", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?auto=webp&amp;s=e8ef5bb2c509762dfe2628fe6504fc18225fa5fe", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff2d73917a7d594a8d884c5ff9eb03a8c6894530", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3228adfc8081b0eecd3d28af77e2970bafc9b22f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5cc0c4df54c584d83a37f25b93f8dac9005e3150", "width": 320, "height": 240}], "variants": {}, "id": "BIz7RkTKofDIZ5k0s0nZfttlg7WqfKKwbxsmxxir82k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176tcip", "is_robot_indexable": true, "report_reasons": null, "author": "MLwithMe1617", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12k4vi1", "author_flair_text_color": null, "permalink": "/r/datascience/comments/176tcip/dive_into_a_comprehensive_guide_on_multilinear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=SHa-58-n6ew", "subreddit_subscribers": 1083153, "created_utc": 1697183076.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Multiple Linear Regression using python ( Regression Analysis )", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Multiple Linear Regression using python ( Regression Analysis )\"&gt;&lt;/iframe&gt;", "author_name": "Machine Learning With me", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/SHa-58-n6ew/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MLwithme1617"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI recently completed **Hyndman, R.J., &amp; Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition**. It's a great book for introducing time series analysis and forecasting in general and has in-depth examples with univariate time series analysis and forecasting exercises. It also introduces multivariate forecasting techniques briefly with dynamic regression models touching on VAR models. I wanted to continue on this and move on to understand multivariate time series analysis and modelling. Specifically, I'm looking for sources that focus more heavily on economic or financial time series analysis. Could you recommend any **books or video materials that also have comprehensive applications demonstrated in R for this (video lectures for this topic would be especially welcomed)**? Also, how much mathematics would be needed for the above material, and are there sources with less math-heavy content?", "author_fullname": "t2_vt5r7wi2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Recommendations for Multivariate Time Series Analysis Resources with a Focus on Economics/Finance and R Applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176t8at", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697182542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I recently completed &lt;strong&gt;Hyndman, R.J., &amp;amp; Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition&lt;/strong&gt;. It&amp;#39;s a great book for introducing time series analysis and forecasting in general and has in-depth examples with univariate time series analysis and forecasting exercises. It also introduces multivariate forecasting techniques briefly with dynamic regression models touching on VAR models. I wanted to continue on this and move on to understand multivariate time series analysis and modelling. Specifically, I&amp;#39;m looking for sources that focus more heavily on economic or financial time series analysis. Could you recommend any &lt;strong&gt;books or video materials that also have comprehensive applications demonstrated in R for this (video lectures for this topic would be especially welcomed)&lt;/strong&gt;? Also, how much mathematics would be needed for the above material, and are there sources with less math-heavy content?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176t8at", "is_robot_indexable": true, "report_reasons": null, "author": "Additional_Guide5439", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176t8at/seeking_recommendations_for_multivariate_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176t8at/seeking_recommendations_for_multivariate_time/", "subreddit_subscribers": 1083153, "created_utc": 1697182542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm working on a binary classification problem with all input features being categorical (and nominal).\n\nThe problem I'm facing is that each input example can contain multiple values of a feature and there are too many different values.\n\n(For example, multi-value feature being a 'Hobbies' feature that contains a list of strings:\n\n&gt;data = {'User': \\['User1', 'User2', 'User3'\\],'Hobbies': \\[\\['Soccer', 'Swimming', 'Hiking'\\],\\['Swimming', 'Cycling'\\],\\['Soccer', 'Hiking'\\]\\]}\n\n)\n\nI first tried one-hot encoding (for each single value instead of each list), but the feature dimension became too large with most of them being 0's.  I searched for other suggestions that address this issue and [this article](https://medium.com/swlh/stop-one-hot-encoding-your-categorical-features-avoid-curse-of-dimensionality-16743c32cea4) stands out. Basically, it suggests other encoding methods to reduce the dimensionality, namely frequency encoding, target encoding, and embedding.\n\nThe tricky part is that (to my knowledge) these approaches only work well for when each input example has a single value for each categorical feature. When it comes to my case, there still exists the risk of high dimensionality. Another way that I can try is to explode the examples for each feature so that each feature contains a single value, then proceed with encoding from there (and align the target labels accordingly). But I'm not sure about this approach.\n\nHow would you approach this kind of data? Any suggestion will be appreciated. Thank you! Sorry as I'm new to these concepts and if this question was asked before in one way or the other. All of my search for the topics doesn't address the multiple-value nature of the features.\n\n&amp;#x200B;", "author_fullname": "t2_34cofh7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On handling multi-label/multi-value categorical features and high cardinality.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176ojaz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697164921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m working on a binary classification problem with all input features being categorical (and nominal).&lt;/p&gt;\n\n&lt;p&gt;The problem I&amp;#39;m facing is that each input example can contain multiple values of a feature and there are too many different values.&lt;/p&gt;\n\n&lt;p&gt;(For example, multi-value feature being a &amp;#39;Hobbies&amp;#39; feature that contains a list of strings:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;data = {&amp;#39;User&amp;#39;: [&amp;#39;User1&amp;#39;, &amp;#39;User2&amp;#39;, &amp;#39;User3&amp;#39;],&amp;#39;Hobbies&amp;#39;: [[&amp;#39;Soccer&amp;#39;, &amp;#39;Swimming&amp;#39;, &amp;#39;Hiking&amp;#39;],[&amp;#39;Swimming&amp;#39;, &amp;#39;Cycling&amp;#39;],[&amp;#39;Soccer&amp;#39;, &amp;#39;Hiking&amp;#39;]]}&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;)&lt;/p&gt;\n\n&lt;p&gt;I first tried one-hot encoding (for each single value instead of each list), but the feature dimension became too large with most of them being 0&amp;#39;s.  I searched for other suggestions that address this issue and &lt;a href=\"https://medium.com/swlh/stop-one-hot-encoding-your-categorical-features-avoid-curse-of-dimensionality-16743c32cea4\"&gt;this article&lt;/a&gt; stands out. Basically, it suggests other encoding methods to reduce the dimensionality, namely frequency encoding, target encoding, and embedding.&lt;/p&gt;\n\n&lt;p&gt;The tricky part is that (to my knowledge) these approaches only work well for when each input example has a single value for each categorical feature. When it comes to my case, there still exists the risk of high dimensionality. Another way that I can try is to explode the examples for each feature so that each feature contains a single value, then proceed with encoding from there (and align the target labels accordingly). But I&amp;#39;m not sure about this approach.&lt;/p&gt;\n\n&lt;p&gt;How would you approach this kind of data? Any suggestion will be appreciated. Thank you! Sorry as I&amp;#39;m new to these concepts and if this question was asked before in one way or the other. All of my search for the topics doesn&amp;#39;t address the multiple-value nature of the features.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?auto=webp&amp;s=e4c05efb8e7eabb8fe5be7950cbdf8b7574039d0", "width": 1200, "height": 848}, "resolutions": [{"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e2bcbbcf5c954a81d766f837557ab8538d04464d", "width": 108, "height": 76}, {"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=719c3a6e89b80326515907eec8208713517d44fd", "width": 216, "height": 152}, {"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9c755cb79167278a421677a8ac39c82174e97aa", "width": 320, "height": 226}, {"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=31105cf933cfdaef26002492c8d5111b5e2c7334", "width": 640, "height": 452}, {"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=39339c6e244f4e1d9d334aeb2ecc02c6574a2e87", "width": 960, "height": 678}, {"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6f16efceb0e9e91b01f70242ea1cbfe247ab124a", "width": 1080, "height": 763}], "variants": {}, "id": "Vju-ktydPGpaa_K21sWwaMhKZihatZsNz7OW0Ec8tNQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176ojaz", "is_robot_indexable": true, "report_reasons": null, "author": "CheapBanana1050", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176ojaz/on_handling_multilabelmultivalue_categorical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176ojaz/on_handling_multilabelmultivalue_categorical/", "subreddit_subscribers": 1083153, "created_utc": 1697164921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Good day to everyone.  I started taking a course called \"Descriptive Statistics\" at university and I want to improve myself outside of class.  The professor recommended Cleff's \"Exploratory Data Analysis\" as a reference book, but I would also like to hear your opinions.  Thank you.", "author_fullname": "t2_f14jhhsn5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Book recommendations about Descriptive Statistics for an Economics freshman.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1778n6i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697230967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Good day to everyone.  I started taking a course called &amp;quot;Descriptive Statistics&amp;quot; at university and I want to improve myself outside of class.  The professor recommended Cleff&amp;#39;s &amp;quot;Exploratory Data Analysis&amp;quot; as a reference book, but I would also like to hear your opinions.  Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1778n6i", "is_robot_indexable": true, "report_reasons": null, "author": "elffuostnevel", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1778n6i/book_recommendations_about_descriptive_statistics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1778n6i/book_recommendations_about_descriptive_statistics/", "subreddit_subscribers": 1083153, "created_utc": 1697230967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all! I\u2019m in my last year of a biomedical anthropology PhD program and I\u2019m interested in going into data science. I\u2019m wondering if anyone has done something similar? Is there anyone with a graduate degree that is not from the typical \u201chard quantitative\u201d fields working as a data scientist now? What was that like?", "author_fullname": "t2_8qwjgs4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone working as a Data Scientist after transitioning from a Social Science/Humanities PhD?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1778e49", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697230275.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all! I\u2019m in my last year of a biomedical anthropology PhD program and I\u2019m interested in going into data science. I\u2019m wondering if anyone has done something similar? Is there anyone with a graduate degree that is not from the typical \u201chard quantitative\u201d fields working as a data scientist now? What was that like?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1778e49", "is_robot_indexable": true, "report_reasons": null, "author": "HipPaprika", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1778e49/anyone_working_as_a_data_scientist_after/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1778e49/anyone_working_as_a_data_scientist_after/", "subreddit_subscribers": 1083153, "created_utc": 1697230275.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey folks, I need help preparing for Interviews. Getting interview is not an issue, maybe because I've 7+ yoe in data field (data architect, BI analyst, etc.) in large corporations, and 5+ in DS/Analytics combined role. I got laid off because of disagreements with the new team I got moved into, and opted to take some much needed break, albeit at the wrong timing. Decided to take 2 months break, and have been interviewing for about 3 months now....\n\nI learned most data science while working as analyst/data engineer for data science teams. So, I'd say I have lot of practical experience with DS projects, but only sufficient theoretical knowledge to go alongwith.\n\nIn the past 2-3 years, I had started taking on lead roles, and handle end-to-end project responsibilities. You might ask why I didn't do this sooner .... I was pretty introverted towards the beginning of my career (partially due to heavy stutter). I overcame most of the stutter over many years of hard work. Although I enjoy data science, I also enjoy working with people, and was hoping to switch to a product managemnt/managerial role in the future. \n\nHowever, Interviews are not going the way I expected them to be. For most companies, I'm being selected for 2-3 rounds, and sometimes to the final rounds, but I always get rejected. I'm personable and respectful, I listen to the interviewer's question, and I feel like I give satisfactory answers. Usually most interviews end on a positive note. \n\nI also make sure to thank them and ask for feedback after the interview. I tend to pass most technical interviews, but it seems they're rejecting me after behavioral/use-case interviews.\n\nSo, My guess is that I'm missing some key trait or skill that the interviewers are looking for. How would you handle this situation? \n\nWould you recommend a dedicated interview training to fix any potential issues that the interviewers might be noticing (but I'm unable to) ... Any such resource that you'd recommend?", "author_fullname": "t2_94luqd4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources to prepare/practice behavioral Interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1776y1o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697226237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, I need help preparing for Interviews. Getting interview is not an issue, maybe because I&amp;#39;ve 7+ yoe in data field (data architect, BI analyst, etc.) in large corporations, and 5+ in DS/Analytics combined role. I got laid off because of disagreements with the new team I got moved into, and opted to take some much needed break, albeit at the wrong timing. Decided to take 2 months break, and have been interviewing for about 3 months now....&lt;/p&gt;\n\n&lt;p&gt;I learned most data science while working as analyst/data engineer for data science teams. So, I&amp;#39;d say I have lot of practical experience with DS projects, but only sufficient theoretical knowledge to go alongwith.&lt;/p&gt;\n\n&lt;p&gt;In the past 2-3 years, I had started taking on lead roles, and handle end-to-end project responsibilities. You might ask why I didn&amp;#39;t do this sooner .... I was pretty introverted towards the beginning of my career (partially due to heavy stutter). I overcame most of the stutter over many years of hard work. Although I enjoy data science, I also enjoy working with people, and was hoping to switch to a product managemnt/managerial role in the future. &lt;/p&gt;\n\n&lt;p&gt;However, Interviews are not going the way I expected them to be. For most companies, I&amp;#39;m being selected for 2-3 rounds, and sometimes to the final rounds, but I always get rejected. I&amp;#39;m personable and respectful, I listen to the interviewer&amp;#39;s question, and I feel like I give satisfactory answers. Usually most interviews end on a positive note. &lt;/p&gt;\n\n&lt;p&gt;I also make sure to thank them and ask for feedback after the interview. I tend to pass most technical interviews, but it seems they&amp;#39;re rejecting me after behavioral/use-case interviews.&lt;/p&gt;\n\n&lt;p&gt;So, My guess is that I&amp;#39;m missing some key trait or skill that the interviewers are looking for. How would you handle this situation? &lt;/p&gt;\n\n&lt;p&gt;Would you recommend a dedicated interview training to fix any potential issues that the interviewers might be noticing (but I&amp;#39;m unable to) ... Any such resource that you&amp;#39;d recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1776y1o", "is_robot_indexable": true, "report_reasons": null, "author": "walewaller", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1776y1o/resources_to_preparepractice_behavioral_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1776y1o/resources_to_preparepractice_behavioral_interviews/", "subreddit_subscribers": 1083153, "created_utc": 1697226237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to utlitze a gpt like language model for my company. I want to bascially search for patterns in data and notifiy us if their is an anomoly.  Does anyone know of any good resources to learn how to do this?  I'd preferably like to use an offline language model or one that would be safe to put in our code", "author_fullname": "t2_9e4tgkg2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance on Language Model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1775rtq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697222961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to utlitze a gpt like language model for my company. I want to bascially search for patterns in data and notifiy us if their is an anomoly.  Does anyone know of any good resources to learn how to do this?  I&amp;#39;d preferably like to use an offline language model or one that would be safe to put in our code&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1775rtq", "is_robot_indexable": true, "report_reasons": null, "author": "Aggravating_Sand352", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1775rtq/guidance_on_language_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1775rtq/guidance_on_language_model/", "subreddit_subscribers": 1083153, "created_utc": 1697222961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm implementing a data lake architecture on AWS, storing raw data in the bronze layer and transformed data in the silver layer. During the storage of data in the silver layer, I would like to append additional columns to hold metadata details such as \"created by\" and \"last modified by.\" For AWS Glue jobs, I want to retrieve details about the user who triggered the job. I'm aware of CloudTrail's Lookup Events API, but I'm looking for an alternative approach to retrieve this information from the server-side without using a client library.", "author_fullname": "t2_a6jhwhs16", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fetching User Details for Triggered AWS Glue Job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1775qrn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697222881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m implementing a data lake architecture on AWS, storing raw data in the bronze layer and transformed data in the silver layer. During the storage of data in the silver layer, I would like to append additional columns to hold metadata details such as &amp;quot;created by&amp;quot; and &amp;quot;last modified by.&amp;quot; For AWS Glue jobs, I want to retrieve details about the user who triggered the job. I&amp;#39;m aware of CloudTrail&amp;#39;s Lookup Events API, but I&amp;#39;m looking for an alternative approach to retrieve this information from the server-side without using a client library.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1775qrn", "is_robot_indexable": true, "report_reasons": null, "author": "TechSavvyGal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1775qrn/fetching_user_details_for_triggered_aws_glue_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1775qrn/fetching_user_details_for_triggered_aws_glue_job/", "subreddit_subscribers": 1083153, "created_utc": 1697222881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "https://preview.redd.it/ha6kw13ewztb1.png?width=966&amp;format=png&amp;auto=webp&amp;s=53c4b89cb5c003c689a1b0b1a62c8902e907c8df\n\n&amp;#x200B;", "author_fullname": "t2_c5tc2ovi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fraud Detection Machine learning project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 31, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ha6kw13ewztb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 24, "x": 108, "u": "https://preview.redd.it/ha6kw13ewztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9f1e6a41af2baa0371f3cc4f840b570b3b8d7ae5"}, {"y": 48, "x": 216, "u": "https://preview.redd.it/ha6kw13ewztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=2789925ee4b5d0b334949045fb55ff624f412b13"}, {"y": 71, "x": 320, "u": "https://preview.redd.it/ha6kw13ewztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a5401b76f38d9f72b43aaa3c85adbe90552075f5"}, {"y": 143, "x": 640, "u": "https://preview.redd.it/ha6kw13ewztb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=832a5553038634938362db66d7039620eb026e65"}, {"y": 214, "x": 960, "u": "https://preview.redd.it/ha6kw13ewztb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9e07c357093312ce4b83cc36e3cfef19898f7f8e"}], "s": {"y": 216, "x": 966, "u": "https://preview.redd.it/ha6kw13ewztb1.png?width=966&amp;format=png&amp;auto=webp&amp;s=53c4b89cb5c003c689a1b0b1a62c8902e907c8df"}, "id": "ha6kw13ewztb1"}}, "name": "t3_1772in6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/JQeeWPbpqA_pqiWH-L5lR8yEG3tB9PvhiW-ILwsdJ00.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697214034.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://preview.redd.it/ha6kw13ewztb1.png?width=966&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=53c4b89cb5c003c689a1b0b1a62c8902e907c8df\"&gt;https://preview.redd.it/ha6kw13ewztb1.png?width=966&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=53c4b89cb5c003c689a1b0b1a62c8902e907c8df&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1772in6", "is_robot_indexable": true, "report_reasons": null, "author": "ResearchShort4056", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1772in6/fraud_detection_machine_learning_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1772in6/fraud_detection_machine_learning_project/", "subreddit_subscribers": 1083153, "created_utc": 1697214034.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi All, \n\nI am doing a project that involves vehicle traffic data and need to know where I can find information regarding how many cars pass by a certain address (a restaurant) or nearby intersection or coordinate point, so I can estimate sales (how many customers does the store get vs how many cars pass by, etc.).\n\nI have store sales &amp; customer but need the traffic data. \n\nHow would one go about finding this information? I am okay with paying a modest amount for access to a database if I have to but would prefer other avenues (Google Maps API and the like?).\n\nI tried government data and websites and the information is available but not to the public and it isn't quite the information needed. \n\nWelcoming all suggestions, thanks everyone!", "author_fullname": "t2_hqo0dh0zu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Traffic Data Source for Senior Project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1771jsh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697211429.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All, &lt;/p&gt;\n\n&lt;p&gt;I am doing a project that involves vehicle traffic data and need to know where I can find information regarding how many cars pass by a certain address (a restaurant) or nearby intersection or coordinate point, so I can estimate sales (how many customers does the store get vs how many cars pass by, etc.).&lt;/p&gt;\n\n&lt;p&gt;I have store sales &amp;amp; customer but need the traffic data. &lt;/p&gt;\n\n&lt;p&gt;How would one go about finding this information? I am okay with paying a modest amount for access to a database if I have to but would prefer other avenues (Google Maps API and the like?).&lt;/p&gt;\n\n&lt;p&gt;I tried government data and websites and the information is available but not to the public and it isn&amp;#39;t quite the information needed. &lt;/p&gt;\n\n&lt;p&gt;Welcoming all suggestions, thanks everyone!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1771jsh", "is_robot_indexable": true, "report_reasons": null, "author": "Purple_Bite_9579", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1771jsh/traffic_data_source_for_senior_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1771jsh/traffic_data_source_for_senior_project/", "subreddit_subscribers": 1083153, "created_utc": 1697211429.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My experience as a candidate wasn't always great and I often felt that interviewers just asked random qs. I was wondering if any experienced interviewers can share their best practices to gauge a candidate's technical aptitude and work ethic on the job.", "author_fullname": "t2_75rv6bzh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the best practices for interviewing data science candidates?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1771460", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697210273.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My experience as a candidate wasn&amp;#39;t always great and I often felt that interviewers just asked random qs. I was wondering if any experienced interviewers can share their best practices to gauge a candidate&amp;#39;s technical aptitude and work ethic on the job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1771460", "is_robot_indexable": true, "report_reasons": null, "author": "Born_Buy7037", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1771460/what_are_the_best_practices_for_interviewing_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1771460/what_are_the_best_practices_for_interviewing_data/", "subreddit_subscribers": 1083153, "created_utc": 1697210273.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am facing a situation where I need to identify stores with very similar names within a radius of 100m from one another. Now, there are \\~ 150k stores in the dataset.\n\nI can distribute these into \\~21k regions with varying number of stores (max \\~5k) and search locally within and that aligns with the problem statement.\n\nMy current method involves:  \nLoop for region  \nCalculate distance of first store from all other stores  \nLoop for each store  \ndist col = dist col - dist store(current loop iteration)  \nfilter for dist col &lt;= 150m\n\nstore\\_ref = current loop iteration\n\ncheck if dist (store\\_ref and store in iteration &lt;=100m)\n\nif yes,\n\ncheck similarity,\n\nif similarity&gt;threshold, add to list/dataframe\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nThis is a 3 level loop of max \\~21k \\* 5k \\* 600 iterations and is taking too long. \n\nI understand that there could be a possibility doing this using KNN/ANN, but would need some specific steps to be able to implement it. Please offer suggestions, if any?  \n", "author_fullname": "t2_15nser", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alphanumeric Search Algorithm?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176tcyw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697183133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am facing a situation where I need to identify stores with very similar names within a radius of 100m from one another. Now, there are ~ 150k stores in the dataset.&lt;/p&gt;\n\n&lt;p&gt;I can distribute these into ~21k regions with varying number of stores (max ~5k) and search locally within and that aligns with the problem statement.&lt;/p&gt;\n\n&lt;p&gt;My current method involves:&lt;br/&gt;\nLoop for region&lt;br/&gt;\nCalculate distance of first store from all other stores&lt;br/&gt;\nLoop for each store&lt;br/&gt;\ndist col = dist col - dist store(current loop iteration)&lt;br/&gt;\nfilter for dist col &amp;lt;= 150m&lt;/p&gt;\n\n&lt;p&gt;store_ref = current loop iteration&lt;/p&gt;\n\n&lt;p&gt;check if dist (store_ref and store in iteration &amp;lt;=100m)&lt;/p&gt;\n\n&lt;p&gt;if yes,&lt;/p&gt;\n\n&lt;p&gt;check similarity,&lt;/p&gt;\n\n&lt;p&gt;if similarity&amp;gt;threshold, add to list/dataframe&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This is a 3 level loop of max ~21k * 5k * 600 iterations and is taking too long. &lt;/p&gt;\n\n&lt;p&gt;I understand that there could be a possibility doing this using KNN/ANN, but would need some specific steps to be able to implement it. Please offer suggestions, if any?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176tcyw", "is_robot_indexable": true, "report_reasons": null, "author": "sarafpiyush98", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176tcyw/alphanumeric_search_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176tcyw/alphanumeric_search_algorithm/", "subreddit_subscribers": 1083153, "created_utc": 1697183133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_5q1gdgbr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Two different ways to execute Python code on an EC2 instance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 90, "top_awarded_type": null, "hide_score": false, "name": "t3_176oxj5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/6QL3tswdBlTPVD7ef2Q5Uw0cgwuZc4a-fNIsznPY4SE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697166208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@hello_prism/running-a-python-script-on-an-ec2-instance-8691589b3080", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2F2omfJrXhCVaFFU5f5MasuZDcakdK3UiHcxkHlQ1zU.jpg?auto=webp&amp;s=d237d0784ea20047a6a3f5cc3aff3be7b5588b93", "width": 780, "height": 506}, "resolutions": [{"url": "https://external-preview.redd.it/2F2omfJrXhCVaFFU5f5MasuZDcakdK3UiHcxkHlQ1zU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=efbaa8a0ad0132f34232636b971fe89069697981", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/2F2omfJrXhCVaFFU5f5MasuZDcakdK3UiHcxkHlQ1zU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=823ab47db16c1e37615916a4aedf8e6c41846f95", "width": 216, "height": 140}, {"url": "https://external-preview.redd.it/2F2omfJrXhCVaFFU5f5MasuZDcakdK3UiHcxkHlQ1zU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f168972dd97161d7e843f1bd8b39076900224ba5", "width": 320, "height": 207}, {"url": "https://external-preview.redd.it/2F2omfJrXhCVaFFU5f5MasuZDcakdK3UiHcxkHlQ1zU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0e68f1db645d86599fd16da2abf68a6ca8080535", "width": 640, "height": 415}], "variants": {}, "id": "bsydDPd_OmytBlY8Hd4WnMgbfHoPnC6qodQcqhk7qtc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "176oxj5", "is_robot_indexable": true, "report_reasons": null, "author": "CharmingSurprise4939", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176oxj5/two_different_ways_to_execute_python_code_on_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@hello_prism/running-a-python-script-on-an-ec2-instance-8691589b3080", "subreddit_subscribers": 1083153, "created_utc": 1697166208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hi everyone! Forta, a decentralised threat intel for web3, is launching a new bounty to detect malicious smart contracts using machine learning.  Apply to earn $3,000 if you have data science and machine learning experience.  [https://forta.notion.site/Malicious-Smart-Contract-Machine-Learning-26d474eb14a445dda503d6088f6d5b80](https://forta.notion.site/Malicious-Smart-Contract-Machine-Learning-26d474eb14a445dda503d6088f6d5b80)", "author_fullname": "t2_gum9y8ey", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Forta Bounty - Web3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176ola2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697165099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi everyone! Forta, a decentralised threat intel for web3, is launching a new bounty to detect malicious smart contracts using machine learning.  Apply to earn $3,000 if you have data science and machine learning experience.  &lt;a href=\"https://forta.notion.site/Malicious-Smart-Contract-Machine-Learning-26d474eb14a445dda503d6088f6d5b80\"&gt;https://forta.notion.site/Malicious-Smart-Contract-Machine-Learning-26d474eb14a445dda503d6088f6d5b80&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?auto=webp&amp;s=befaedb8837d4a815bee94c86a6d7c52c2660f6c", "width": 2000, "height": 819}, "resolutions": [{"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5efbc6aa7f23fe48afab7275ccd99ebf0e5ecb0c", "width": 108, "height": 44}, {"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c5eac3b44017110115ad393ecf30d258abf40509", "width": 216, "height": 88}, {"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2c4ca5cc150bcfbe745793f00285c668b5aa0d17", "width": 320, "height": 131}, {"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=85df9260c2952f4cb60426a1e81a175bbdba9fe0", "width": 640, "height": 262}, {"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a3add95e23883a6f343515da42e45bd159bc976e", "width": 960, "height": 393}, {"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=15b29f8541b503726dc0cdcf03106b1fb43260aa", "width": 1080, "height": 442}], "variants": {}, "id": "WNAyWwEzxkmyOVI4y49N0veDK1zCjPWKAEO3RZIfv1s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176ola2", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious-Case3330", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176ola2/forta_bounty_web3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176ola2/forta_bounty_web3/", "subreddit_subscribers": 1083153, "created_utc": 1697165099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What do you think guys -&gt; [https://twitter.com/Cesar\\_Ges/status/1712541730053173280](https://twitter.com/Cesar_Ges/status/1712541730053173280)", "author_fullname": "t2_8c394a76", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ocean protocol", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1777d0q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697227436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What do you think guys -&amp;gt; &lt;a href=\"https://twitter.com/Cesar_Ges/status/1712541730053173280\"&gt;https://twitter.com/Cesar_Ges/status/1712541730053173280&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uaEkxKfEEmqieWhWWYlaJEtsm0vSmO6L4p4Jli39lJk.jpg?auto=webp&amp;s=7d6a9495d1d18aa744a3f7b0413cc6702b568e59", "width": 140, "height": 140}, "resolutions": [{"url": "https://external-preview.redd.it/uaEkxKfEEmqieWhWWYlaJEtsm0vSmO6L4p4Jli39lJk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e961ddc1f4365d14ad3a194c6482f2ca52f4639", "width": 108, "height": 108}], "variants": {}, "id": "yaJVivp8wwvjPUGEALqrUqrUgnEbxZzurDNhAzOTvD4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1777d0q", "is_robot_indexable": true, "report_reasons": null, "author": "Zestyclose-Ad-7154", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1777d0q/ocean_protocol/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1777d0q/ocean_protocol/", "subreddit_subscribers": 1083153, "created_utc": 1697227436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Perform Monte Carlo Simulation on the Stock Market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_17770fv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/O3K4nrXyqwc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How to Perform Monte Carlo Simulation on the Stock Market\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_2lt1q4pa", "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How to Perform Monte Carlo Simulation on the Stock Market", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/O3K4nrXyqwc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How to Perform Monte Carlo Simulation on the Stock Market\"&gt;&lt;/iframe&gt;", "author_name": "DataCrafters", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/O3K4nrXyqwc/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataWaveCrafters"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/O3K4nrXyqwc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How to Perform Monte Carlo Simulation on the Stock Market\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/17770fv", "height": 200}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TN3FeQXy-grJN0_QW3n_T6FWfY_7ivx_57q65WMJ6i8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "Python", "selftext": "", "author_fullname": "t2_2lt1q4pa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Perform Monte Carlo Simulation on the Stock Market", "link_flair_richtext": [{"e": "text", "t": "Tutorial"}], "subreddit_name_prefixed": "r/Python", "hidden": false, "pwls": 6, "link_flair_css_class": "tutorial", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_1776zzk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/O3K4nrXyqwc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How to Perform Monte Carlo Simulation on the Stock Market\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How to Perform Monte Carlo Simulation on the Stock Market", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/O3K4nrXyqwc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How to Perform Monte Carlo Simulation on the Stock Market\"&gt;&lt;/iframe&gt;", "author_name": "DataCrafters", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/O3K4nrXyqwc/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataWaveCrafters"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/O3K4nrXyqwc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How to Perform Monte Carlo Simulation on the Stock Market\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/1776zzk", "height": 200}, "link_flair_text": "Tutorial", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/TN3FeQXy-grJN0_QW3n_T6FWfY_7ivx_57q65WMJ6i8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697226388.0, "link_flair_type": "richtext", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=O3K4nrXyqwc", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dUAETZ42xwdMxZW3v90vBKlkKPE2qkoM2VFQSROS6v4.jpg?auto=webp&amp;s=1e85da7e7205b09470d29d9fb5163b2a9b0c5d13", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/dUAETZ42xwdMxZW3v90vBKlkKPE2qkoM2VFQSROS6v4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a7b42be81731941522f8138f1024308c7e617492", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/dUAETZ42xwdMxZW3v90vBKlkKPE2qkoM2VFQSROS6v4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=795cb0998f3621e7beaaa8acdca6fdec2c98f4b4", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/dUAETZ42xwdMxZW3v90vBKlkKPE2qkoM2VFQSROS6v4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f63362e4804c1d173c859fab2a3c23e670db4c7", "width": 320, "height": 240}], "variants": {}, "id": "EO81rs7kLv6PJdybTa4lW9yZSXBo75vEOpvmhPW4_9o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7987a74c-04d8-11eb-84ca-0e0ac8b5a78f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2qh0y", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1776zzk", "is_robot_indexable": true, "report_reasons": null, "author": "Kairo1004", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/Python/comments/1776zzk/how_to_perform_monte_carlo_simulation_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=O3K4nrXyqwc", "subreddit_subscribers": 1158875, "created_utc": 1697226388.0, "num_crossposts": 2, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How to Perform Monte Carlo Simulation on the Stock Market", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/O3K4nrXyqwc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How to Perform Monte Carlo Simulation on the Stock Market\"&gt;&lt;/iframe&gt;", "author_name": "DataCrafters", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/O3K4nrXyqwc/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataWaveCrafters"}}, "is_video": false}], "created": 1697226426.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=O3K4nrXyqwc", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dUAETZ42xwdMxZW3v90vBKlkKPE2qkoM2VFQSROS6v4.jpg?auto=webp&amp;s=1e85da7e7205b09470d29d9fb5163b2a9b0c5d13", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/dUAETZ42xwdMxZW3v90vBKlkKPE2qkoM2VFQSROS6v4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a7b42be81731941522f8138f1024308c7e617492", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/dUAETZ42xwdMxZW3v90vBKlkKPE2qkoM2VFQSROS6v4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=795cb0998f3621e7beaaa8acdca6fdec2c98f4b4", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/dUAETZ42xwdMxZW3v90vBKlkKPE2qkoM2VFQSROS6v4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2f63362e4804c1d173c859fab2a3c23e670db4c7", "width": 320, "height": 240}], "variants": {}, "id": "EO81rs7kLv6PJdybTa4lW9yZSXBo75vEOpvmhPW4_9o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17770fv", "is_robot_indexable": true, "report_reasons": null, "author": "Kairo1004", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1776zzk", "author_flair_text_color": null, "permalink": "/r/datascience/comments/17770fv/how_to_perform_monte_carlo_simulation_on_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=O3K4nrXyqwc", "subreddit_subscribers": 1083153, "created_utc": 1697226426.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "How to Perform Monte Carlo Simulation on the Stock Market", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/O3K4nrXyqwc?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"How to Perform Monte Carlo Simulation on the Stock Market\"&gt;&lt;/iframe&gt;", "author_name": "DataCrafters", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/O3K4nrXyqwc/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@DataWaveCrafters"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I've been thinking about the dynamics of high-performance teams lately, and a thought has been on my mind: just how important is it really for team members to truly KNOW and CARE about each other on a personal level to reach peak performance?\n\nI've heard arguments that strong personal connections within a team can lead to better collaboration, empathy, and an overall positive impact on performance. Others argue that it's all about the work, and personal connections might be secondary.\n\nI'd love to hear your thoughts and experiences on this matter:\n\n1. Have you been a part of a high-performance team where deep personal connections among team members played a significant role in its success?\n2. Conversely, have you been on a high-performance team where personal relationships weren't a focal point, yet it still excelled in achieving its goals?\n3. What are your thoughts on the balance between personal connections and professional performance within a team?\n4. Any tips or strategies for fostering a sense of knowing and caring about colleagues within a team without it feeling forced?\n\nFeel free to share your insights, anecdotes, or opinions. I'm genuinely curious to see the various perspectives on this topic. Let's have a meaningful discussion!\n\n ", "author_fullname": "t2_e2ahk9usw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High Performance Teams: Is the Balance of Personal and Professional Connections Vital for Team Synergy? Should you really KNOW and CARE about your colleagues?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176rwg6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697177100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been thinking about the dynamics of high-performance teams lately, and a thought has been on my mind: just how important is it really for team members to truly KNOW and CARE about each other on a personal level to reach peak performance?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve heard arguments that strong personal connections within a team can lead to better collaboration, empathy, and an overall positive impact on performance. Others argue that it&amp;#39;s all about the work, and personal connections might be secondary.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear your thoughts and experiences on this matter:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Have you been a part of a high-performance team where deep personal connections among team members played a significant role in its success?&lt;/li&gt;\n&lt;li&gt;Conversely, have you been on a high-performance team where personal relationships weren&amp;#39;t a focal point, yet it still excelled in achieving its goals?&lt;/li&gt;\n&lt;li&gt;What are your thoughts on the balance between personal connections and professional performance within a team?&lt;/li&gt;\n&lt;li&gt;Any tips or strategies for fostering a sense of knowing and caring about colleagues within a team without it feeling forced?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Feel free to share your insights, anecdotes, or opinions. I&amp;#39;m genuinely curious to see the various perspectives on this topic. Let&amp;#39;s have a meaningful discussion!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176rwg6", "is_robot_indexable": true, "report_reasons": null, "author": "Active_Cranberry7606", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176rwg6/high_performance_teams_is_the_balance_of_personal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176rwg6/high_performance_teams_is_the_balance_of_personal/", "subreddit_subscribers": 1083153, "created_utc": 1697177100.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}