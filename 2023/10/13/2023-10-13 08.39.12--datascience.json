{"kind": "Listing", "data": {"after": "t3_17686qn", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " If you were presented with such an offer for a remote position, would you accept it? Is there a risk of legal consequences if you were discovered? ", "author_fullname": "t2_5fbmh3va", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How ballsy do you have to be to take on the role of Senior Data Scientist at both McDonald's and Burger King simultaneously (remote)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17666j9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 243, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 243, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697114881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you were presented with such an offer for a remote position, would you accept it? Is there a risk of legal consequences if you were discovered? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17666j9", "is_robot_indexable": true, "report_reasons": null, "author": "Excellent_Cost170", "discussion_type": null, "num_comments": 117, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17666j9/how_ballsy_do_you_have_to_be_to_take_on_the_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17666j9/how_ballsy_do_you_have_to_be_to_take_on_the_role/", "subreddit_subscribers": 1082448, "created_utc": 1697114881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_b3hvfhlp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you were starting over again, How would you go about getting a Data Science job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1763k33", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 89, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 89, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697105924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1763k33", "is_robot_indexable": true, "report_reasons": null, "author": "Exotic_Avocado6164", "discussion_type": null, "num_comments": 57, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1763k33/if_you_were_starting_over_again_how_would_you_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1763k33/if_you_were_starting_over_again_how_would_you_go/", "subreddit_subscribers": 1082448, "created_utc": 1697105924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it still as crushing for entry level. I have a clear shot at an entry level position so I know I will get an entry level DS job in a Fortune 100 company. But I want to know if it is typical for those of you with more experience to struggle to get a mid level to management job.", "author_fullname": "t2_8esysayj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much of an effect does this job market have on people who were Data Scientists for a solid 3-5 years?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1767l3b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697118957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it still as crushing for entry level. I have a clear shot at an entry level position so I know I will get an entry level DS job in a Fortune 100 company. But I want to know if it is typical for those of you with more experience to struggle to get a mid level to management job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1767l3b", "is_robot_indexable": true, "report_reasons": null, "author": "LossFirst2657", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1767l3b/how_much_of_an_effect_does_this_job_market_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1767l3b/how_much_of_an_effect_does_this_job_market_have/", "subreddit_subscribers": 1082448, "created_utc": 1697118957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This can be something that you use around the house or something that you use personally at work. I am always coming up with new ideas for one off projects that would be cool to build for personal use, but I never seem to actually get around to building them.\n\n\nFor example, one project that I have been thinking about building for some time is around automatically buying groceries or other items that I buy regularly. The model would predict how often I buy each item, and then the variation in the cadence, to then add the item to my list/order it when it's likely the cheapest price in the interval that I should place the order.\n\n\nI'm currently getting my Masters in Data Science and working full-time (and trying to start a small business....) so I don't usually get to spend time working on these ideas, but interested in what projects others have done or thought about doing!", "author_fullname": "t2_81jpdz5w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a personal side project that you have worked on that has increased your efficiency or has saved you money?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176de18", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697134067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This can be something that you use around the house or something that you use personally at work. I am always coming up with new ideas for one off projects that would be cool to build for personal use, but I never seem to actually get around to building them.&lt;/p&gt;\n\n&lt;p&gt;For example, one project that I have been thinking about building for some time is around automatically buying groceries or other items that I buy regularly. The model would predict how often I buy each item, and then the variation in the cadence, to then add the item to my list/order it when it&amp;#39;s likely the cheapest price in the interval that I should place the order.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently getting my Masters in Data Science and working full-time (and trying to start a small business....) so I don&amp;#39;t usually get to spend time working on these ideas, but interested in what projects others have done or thought about doing!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176de18", "is_robot_indexable": true, "report_reasons": null, "author": "OutcomeSerious", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176de18/what_is_a_personal_side_project_that_you_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176de18/what_is_a_personal_side_project_that_you_have/", "subreddit_subscribers": 1082448, "created_utc": 1697134067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I ended up getting laid off today from my role as a data scientist after a little more than a year. It was framed as a \"reorganization\" by a higher up and that my role had been eliminated.\n\nAnyways, they offered to help shop me around to some other internal teams and I'll be meeting with two other DS managers in the next week. Before I meet with them, I was wondering if anyone could offer any advice for the situation and how to proceed. I'd really appreciate it.\n\nDoes anyone have any advice for how to use these meetings to their fullest, and maximize my chance of landing another role? How direct should I be about wanting to join their teams? I know my biggest selling point is that there's no training period, I'm already familiar with all the datasets and industry. I'm going to spend tomorrow trying to summarize all the work I've done at the company since I got hired.\n\nSome other key details below:\n\n- Was told I was rehire eligible. They specifically said that severance wouldn't be impacted if I boomeranged unless I switched teams before final date (1 month).\n- Worked for over a year and have 2.5 years of experience in data science.\n- Probably was on the bottom half of performers, but I wasn't the worst. I was the most recent hire though. My boss's boss offered to write a letter of recommendation, probably was a casualty of money, seniority, and not being a top performer. Was given a large new project two weeks ago.\n- The company is large but has a small amount of tech and is about to lose a lot of money in the coming year. Could be a negative for staying if I find a new role.\n\nI'm going to keep the ranting to a minimum because this post is pretty identifiable, but I'm honestly at a loss of what to do. I moved across the country for the role (in-person) and turned down a higher paying offer as a quant. I finally got an ounce of stability after not having any for years and I got laid off without even a PIP or a warning. I guess that's life but god damn.", "author_fullname": "t2_lnimx58p7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got hit with a layoff today but they offered to shop me around internally, any advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176nzqe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697163196.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ended up getting laid off today from my role as a data scientist after a little more than a year. It was framed as a &amp;quot;reorganization&amp;quot; by a higher up and that my role had been eliminated.&lt;/p&gt;\n\n&lt;p&gt;Anyways, they offered to help shop me around to some other internal teams and I&amp;#39;ll be meeting with two other DS managers in the next week. Before I meet with them, I was wondering if anyone could offer any advice for the situation and how to proceed. I&amp;#39;d really appreciate it.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any advice for how to use these meetings to their fullest, and maximize my chance of landing another role? How direct should I be about wanting to join their teams? I know my biggest selling point is that there&amp;#39;s no training period, I&amp;#39;m already familiar with all the datasets and industry. I&amp;#39;m going to spend tomorrow trying to summarize all the work I&amp;#39;ve done at the company since I got hired.&lt;/p&gt;\n\n&lt;p&gt;Some other key details below:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Was told I was rehire eligible. They specifically said that severance wouldn&amp;#39;t be impacted if I boomeranged unless I switched teams before final date (1 month).&lt;/li&gt;\n&lt;li&gt;Worked for over a year and have 2.5 years of experience in data science.&lt;/li&gt;\n&lt;li&gt;Probably was on the bottom half of performers, but I wasn&amp;#39;t the worst. I was the most recent hire though. My boss&amp;#39;s boss offered to write a letter of recommendation, probably was a casualty of money, seniority, and not being a top performer. Was given a large new project two weeks ago.&lt;/li&gt;\n&lt;li&gt;The company is large but has a small amount of tech and is about to lose a lot of money in the coming year. Could be a negative for staying if I find a new role.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I&amp;#39;m going to keep the ranting to a minimum because this post is pretty identifiable, but I&amp;#39;m honestly at a loss of what to do. I moved across the country for the role (in-person) and turned down a higher paying offer as a quant. I finally got an ounce of stability after not having any for years and I got laid off without even a PIP or a warning. I guess that&amp;#39;s life but god damn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176nzqe", "is_robot_indexable": true, "report_reasons": null, "author": "Smart_Donut_9558", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176nzqe/got_hit_with_a_layoff_today_but_they_offered_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176nzqe/got_hit_with_a_layoff_today_but_they_offered_to/", "subreddit_subscribers": 1082448, "created_utc": 1697163196.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ve been in data science about 3 years and I\u2019m just miserable coding day in and day out. I\u2019ve applied to some manager jobs but haven\u2019t gotten and the ones that I have been offered pay less than what I make now.\n\nI\u2019m looking for something more business facing, that could be a good career transition for someone who enjoys tech but doesn\u2019t have his heart in programming after doing it since college 9 years ago, and doing it daily since.", "author_fullname": "t2_f50rnaa0x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Jobs to switch to from Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176ndbd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697161208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been in data science about 3 years and I\u2019m just miserable coding day in and day out. I\u2019ve applied to some manager jobs but haven\u2019t gotten and the ones that I have been offered pay less than what I make now.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking for something more business facing, that could be a good career transition for someone who enjoys tech but doesn\u2019t have his heart in programming after doing it since college 9 years ago, and doing it daily since.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176ndbd", "is_robot_indexable": true, "report_reasons": null, "author": "Frequent_Anybody2984", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176ndbd/jobs_to_switch_to_from_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176ndbd/jobs_to_switch_to_from_data_science/", "subreddit_subscribers": 1082448, "created_utc": 1697161208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "    df.drop_duplicates()\n\n&amp;#x200B;", "author_fullname": "t2_7xuzntim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When your clients won't provide insight or feedback on why there are 4 different rows with the same unique ID...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1769ozf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697124584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;pre&gt;&lt;code&gt;df.drop_duplicates()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1769ozf", "is_robot_indexable": true, "report_reasons": null, "author": "Loose_Read_9400", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1769ozf/when_your_clients_wont_provide_insight_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1769ozf/when_your_clients_wont_provide_insight_or/", "subreddit_subscribers": 1082448, "created_utc": 1697124584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been working as a \"Data Scientist\" for a little over 2 years but in my company I'm primarily tasked with developing MVPs with the company's  AI technology for potential clients. Most of the coding we do is setting up API calls, setting up environments, and connecting the different parts of the company's technology. I loathe this. Many calls people are sharing their screen showing this API call code and I absolutely cannot focus for the life of me. Mentally, I feel a huge friction/resistance to setting up a coding environment. \n\nIn school, I took Mechanical Engineering and I was a pro making code to model engineering stuff and my programming logic was solid. I was the top of the class. But this environment set up stuff and API stuff just drives me insane.\n\nI'm trying to figure out if the problem is with this role or if I just am better off in a non-coding role, like product management?", "author_fullname": "t2_8cg2z0mf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coding sometimes scares me. Is this the wrong field for me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1769ler", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697124321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working as a &amp;quot;Data Scientist&amp;quot; for a little over 2 years but in my company I&amp;#39;m primarily tasked with developing MVPs with the company&amp;#39;s  AI technology for potential clients. Most of the coding we do is setting up API calls, setting up environments, and connecting the different parts of the company&amp;#39;s technology. I loathe this. Many calls people are sharing their screen showing this API call code and I absolutely cannot focus for the life of me. Mentally, I feel a huge friction/resistance to setting up a coding environment. &lt;/p&gt;\n\n&lt;p&gt;In school, I took Mechanical Engineering and I was a pro making code to model engineering stuff and my programming logic was solid. I was the top of the class. But this environment set up stuff and API stuff just drives me insane.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out if the problem is with this role or if I just am better off in a non-coding role, like product management?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1769ler", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate_Ebb3623", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1769ler/coding_sometimes_scares_me_is_this_the_wrong/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1769ler/coding_sometimes_scares_me_is_this_the_wrong/", "subreddit_subscribers": 1082448, "created_utc": 1697124321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For context, I work in a regulated industry where model interpretability has a large emphasis, from both the business and regulators. We use a lot linear models, like OLS, logistic regression, and GAMs to account for non-linear relationships. Recently, some of the data science leadership has been pushing us to explore machine learning models to see if and how large the predictive gains are. \n\nNot surprisingly, XGBoosts, Random Forests, among others, show a small increase in predictive accuracy compared to the linear models, as we spend a fair amount of time fine tuning the linear models. \n\nHowever, we still need to show that we understand how these models are making their predictions and I have come to the opinion that most of the explainable AI techniques out there do a poor job of explaining anything meaningful about the model or the data. \n\nThings like SHAP values of LIME are okay in some instances with a stable model, but we've seen that they often show bizarre relationships. For instance two observations that are theoretically close to each other in the data generating process, are close to each other in data itself, are very different from each other in the model space. In addition, these local interpretation techniques really fail to show anything about the model globally. \n\nThis blog post summarizes most of my thoughts clearly: https://randomeffect.net/post/2020/08/07/is-explainable-ai-anything-at-all/\n\nAnyways, I guess what I'm asking is are there practicioners out there that hold a different view? Are there advancements in this space that I'm unaware of? I know there's a lot of effort going into the explainable AI space right now, but I'm pessimistic that it's even possible for us to have a good explaination for many models. Thoughts?", "author_fullname": "t2_2x1e09nw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Explainable AI Scepticism", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176drw8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697135053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I work in a regulated industry where model interpretability has a large emphasis, from both the business and regulators. We use a lot linear models, like OLS, logistic regression, and GAMs to account for non-linear relationships. Recently, some of the data science leadership has been pushing us to explore machine learning models to see if and how large the predictive gains are. &lt;/p&gt;\n\n&lt;p&gt;Not surprisingly, XGBoosts, Random Forests, among others, show a small increase in predictive accuracy compared to the linear models, as we spend a fair amount of time fine tuning the linear models. &lt;/p&gt;\n\n&lt;p&gt;However, we still need to show that we understand how these models are making their predictions and I have come to the opinion that most of the explainable AI techniques out there do a poor job of explaining anything meaningful about the model or the data. &lt;/p&gt;\n\n&lt;p&gt;Things like SHAP values of LIME are okay in some instances with a stable model, but we&amp;#39;ve seen that they often show bizarre relationships. For instance two observations that are theoretically close to each other in the data generating process, are close to each other in data itself, are very different from each other in the model space. In addition, these local interpretation techniques really fail to show anything about the model globally. &lt;/p&gt;\n\n&lt;p&gt;This blog post summarizes most of my thoughts clearly: &lt;a href=\"https://randomeffect.net/post/2020/08/07/is-explainable-ai-anything-at-all/\"&gt;https://randomeffect.net/post/2020/08/07/is-explainable-ai-anything-at-all/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Anyways, I guess what I&amp;#39;m asking is are there practicioners out there that hold a different view? Are there advancements in this space that I&amp;#39;m unaware of? I know there&amp;#39;s a lot of effort going into the explainable AI space right now, but I&amp;#39;m pessimistic that it&amp;#39;s even possible for us to have a good explaination for many models. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176drw8", "is_robot_indexable": true, "report_reasons": null, "author": "a157reverse", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176drw8/explainable_ai_scepticism/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176drw8/explainable_ai_scepticism/", "subreddit_subscribers": 1082448, "created_utc": 1697135053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hi guys, i'm doing research on Pandas, and I've read various posts here and there on the web, but i haven't reached a definitive conclusion regarding the question i posed. I'd like to understand how Pandas stores indices and what the time complexity of lookup operations performed with **loc** is . Some claim that the indices are stored as hash tables, while others contradict this assertion.  I found this post on Stack Overflow, [https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas](https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas), which discusses the topic, but there's no concrete evidence that this is true. Can anyone help me? Thanks a lot.", "author_fullname": "t2_dlj2dqhje", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's Pandas .loc time complexity?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176di2y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697134354.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, i&amp;#39;m doing research on Pandas, and I&amp;#39;ve read various posts here and there on the web, but i haven&amp;#39;t reached a definitive conclusion regarding the question i posed. I&amp;#39;d like to understand how Pandas stores indices and what the time complexity of lookup operations performed with &lt;strong&gt;loc&lt;/strong&gt; is . Some claim that the indices are stored as hash tables, while others contradict this assertion.  I found this post on Stack Overflow, &lt;a href=\"https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas\"&gt;https://stackoverflow.com/questions/16626058/what-is-the-performance-impact-of-non-unique-indexes-in-pandas&lt;/a&gt;, which discusses the topic, but there&amp;#39;s no concrete evidence that this is true. Can anyone help me? Thanks a lot.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?auto=webp&amp;s=a70d21ce9f01f64670d2200ca9fc3f39b94a7e48", "width": 316, "height": 316}, "resolutions": [{"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0aad06750c23b98c9b7595343a8b54a42dc18851", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/yzSfTlKTSYGpEXeFgyDvHlfoLGOFQJqPuH_Y38RBz2U.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b66126834977e269be586d07464046049ed09138", "width": 216, "height": 216}], "variants": {}, "id": "nfayPavSUB5ngYv6-19UHNBThsXfcLIDQl4HkEe3Cv0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176di2y", "is_robot_indexable": true, "report_reasons": null, "author": "AlternativeSea4330", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176di2y/whats_pandas_loc_time_complexity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176di2y/whats_pandas_loc_time_complexity/", "subreddit_subscribers": 1082448, "created_utc": 1697134354.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Do you guys recommend grinding leetcode? Or doing personal projects and learning how to use tools?", "author_fullname": "t2_62sz58k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do when looking for a job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176c3gh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697130763.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you guys recommend grinding leetcode? Or doing personal projects and learning how to use tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176c3gh", "is_robot_indexable": true, "report_reasons": null, "author": "mangos5", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176c3gh/what_to_do_when_looking_for_a_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176c3gh/what_to_do_when_looking_for_a_job/", "subreddit_subscribers": 1082448, "created_utc": 1697130763.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in the very early stages of an investigatory project at my job (senior software engineer with a moderate amount of data mining and snowflake/star pattern ETL OLAP warehousing experience in SSAS from years ago, long before modern tools and platforms, who has somehow now been deemed the SME for all things \"AI\").\n\nBasically, I have a relational SQL Server database containing tens of millions of products, each with up to 20 categories of detail. I also now have usage data from our website that tracks customer interaction with these products, logging things like their account details and demographics as well as their IP, location, searches, where they clicked, how long they interacted, what they interacted with previously, what they interacted with next, etc.\n\nIf they wanted to run this in an old-school schema, I could work something up. I could probably even make some great reports in Power BI. But my bosses, of course, want to load this into a ChatGPT-type interface to ask natural language questions about the data.\n\nMy cursory research tells me I need to massage my data into a vector database first and foremost before I start worrying about Langchain, Llama, and OpenAI, and any specific platform or toolset. But I'm not sure where to start, and I'm getting hung up on that there doesn't seem to be any good examples of migrating existing data - everything is either too much hype and promise-selling language that is sparse on detail or is a very in-the-weeds, poorly documented, mostly-incoherent mess with no examples at all or uses examples that are so simplistic to be not relevant to anyone.\n\nI found some (albeit again very simplistic) examples from Milvus that show importing semi-structured JSON-formatted objects that roughly align with what I'd equate to, in my world, denormalized key/value pairs for various product properties. Cool, that makes sense. That's half of it. But I'm not sure about the other half - how much, if any, pre-aggregation do I need to do with the analytics data? Do I import essentially one object for every single piece of tracked data, or do I roll it up beforehand? I'm most interested in having this vector data be used to identify period-based trends, forecasts, and recommendations like \"Based on his individual product engagement tracking as well as the aggregate tracking of his demographically similar cohorts over the past week, what products should we surface for Bob Smith next?\"\n\nBasically, all this is a very long-winded, rambling way to get to three questions:\n\n1. Are there any examples of converting a remotely complex RDMS into a vector database?\n\n2. How much massaging beyond basic denormalization and pre-aggregation do I need to do?\n\n3. Is it sufficient to load data as lists of a buttload of key-value pairs, or would I do better to zhuzh it into wordy natural language descriptions of the data?", "author_fullname": "t2_32ls6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Existing relational database to new vector database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1761n34", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697098022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the very early stages of an investigatory project at my job (senior software engineer with a moderate amount of data mining and snowflake/star pattern ETL OLAP warehousing experience in SSAS from years ago, long before modern tools and platforms, who has somehow now been deemed the SME for all things &amp;quot;AI&amp;quot;).&lt;/p&gt;\n\n&lt;p&gt;Basically, I have a relational SQL Server database containing tens of millions of products, each with up to 20 categories of detail. I also now have usage data from our website that tracks customer interaction with these products, logging things like their account details and demographics as well as their IP, location, searches, where they clicked, how long they interacted, what they interacted with previously, what they interacted with next, etc.&lt;/p&gt;\n\n&lt;p&gt;If they wanted to run this in an old-school schema, I could work something up. I could probably even make some great reports in Power BI. But my bosses, of course, want to load this into a ChatGPT-type interface to ask natural language questions about the data.&lt;/p&gt;\n\n&lt;p&gt;My cursory research tells me I need to massage my data into a vector database first and foremost before I start worrying about Langchain, Llama, and OpenAI, and any specific platform or toolset. But I&amp;#39;m not sure where to start, and I&amp;#39;m getting hung up on that there doesn&amp;#39;t seem to be any good examples of migrating existing data - everything is either too much hype and promise-selling language that is sparse on detail or is a very in-the-weeds, poorly documented, mostly-incoherent mess with no examples at all or uses examples that are so simplistic to be not relevant to anyone.&lt;/p&gt;\n\n&lt;p&gt;I found some (albeit again very simplistic) examples from Milvus that show importing semi-structured JSON-formatted objects that roughly align with what I&amp;#39;d equate to, in my world, denormalized key/value pairs for various product properties. Cool, that makes sense. That&amp;#39;s half of it. But I&amp;#39;m not sure about the other half - how much, if any, pre-aggregation do I need to do with the analytics data? Do I import essentially one object for every single piece of tracked data, or do I roll it up beforehand? I&amp;#39;m most interested in having this vector data be used to identify period-based trends, forecasts, and recommendations like &amp;quot;Based on his individual product engagement tracking as well as the aggregate tracking of his demographically similar cohorts over the past week, what products should we surface for Bob Smith next?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Basically, all this is a very long-winded, rambling way to get to three questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Are there any examples of converting a remotely complex RDMS into a vector database?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How much massaging beyond basic denormalization and pre-aggregation do I need to do?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is it sufficient to load data as lists of a buttload of key-value pairs, or would I do better to zhuzh it into wordy natural language descriptions of the data?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1761n34", "is_robot_indexable": true, "report_reasons": null, "author": "ZebZ", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1761n34/existing_relational_database_to_new_vector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1761n34/existing_relational_database_to_new_vector/", "subreddit_subscribers": 1082448, "created_utc": 1697098022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI have a background in math + DS but little exposure to Monte Carlo methods. I find them interesting and potentially useful for my work and personal projects (sports betting models). I know the basics but am looking for more intermediate tutorials or literature that can educate me on how to build my own robust MC simulations in Python.\n\nThanks! Any advice would be appreciated.", "author_fullname": "t2_ds90qagip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources on Monte Carlo Simulations (Python)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176h4n3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697143923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I have a background in math + DS but little exposure to Monte Carlo methods. I find them interesting and potentially useful for my work and personal projects (sports betting models). I know the basics but am looking for more intermediate tutorials or literature that can educate me on how to build my own robust MC simulations in Python.&lt;/p&gt;\n\n&lt;p&gt;Thanks! Any advice would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176h4n3", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable-Farmer186", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176h4n3/resources_on_monte_carlo_simulations_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176h4n3/resources_on_monte_carlo_simulations_python/", "subreddit_subscribers": 1082448, "created_utc": 1697143923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to make a project in which I'm thinking of combining IoT devices, PCA, LDA and SVD but I want a problem statement for which there isn't already a solution however I'm not able to think of anything so I thought I should reach out onto reddit to see if I can get something from here. If y'all have any suggestions please let me know it'll be genuinely appreciated!", "author_fullname": "t2_spw388k1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need problem statements for a project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176aamb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697126138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to make a project in which I&amp;#39;m thinking of combining IoT devices, PCA, LDA and SVD but I want a problem statement for which there isn&amp;#39;t already a solution however I&amp;#39;m not able to think of anything so I thought I should reach out onto reddit to see if I can get something from here. If y&amp;#39;all have any suggestions please let me know it&amp;#39;ll be genuinely appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176aamb", "is_robot_indexable": true, "report_reasons": null, "author": "emotional-Limit-2000", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176aamb/need_problem_statements_for_a_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176aamb/need_problem_statements_for_a_project/", "subreddit_subscribers": 1082448, "created_utc": 1697126138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm interested in becoming a doing climate, GIS data/AI research and am intrigued by the postings at these big tech companies (Google, MSFT, IBM, etc.). I currently have a MS in Mechanical Engineering and 2 YOE as a Data Scientist in a big tech company.\n\nI wanted to know what you do as a Research Scientist. How much academic freedom do you have? Is it a lot of meetings or do you get more freedom to get into a deepwork headspace? Do you enjoy the role? Whats the work-life balance like?\n\nHow did you get the role? If I'm interested, do I need a PhD or is my MS + Professional Exp good enough? Will not having a PhD hurt me in the long run?", "author_fullname": "t2_8cg2z0mf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "can any research scientists share their experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1769z7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697125314.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in becoming a doing climate, GIS data/AI research and am intrigued by the postings at these big tech companies (Google, MSFT, IBM, etc.). I currently have a MS in Mechanical Engineering and 2 YOE as a Data Scientist in a big tech company.&lt;/p&gt;\n\n&lt;p&gt;I wanted to know what you do as a Research Scientist. How much academic freedom do you have? Is it a lot of meetings or do you get more freedom to get into a deepwork headspace? Do you enjoy the role? Whats the work-life balance like?&lt;/p&gt;\n\n&lt;p&gt;How did you get the role? If I&amp;#39;m interested, do I need a PhD or is my MS + Professional Exp good enough? Will not having a PhD hurt me in the long run?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1769z7v", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate_Ebb3623", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1769z7v/can_any_research_scientists_share_their_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1769z7v/can_any_research_scientists_share_their_experience/", "subreddit_subscribers": 1082448, "created_utc": 1697125314.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I\u2019m writing this post hoping to get some advice from everyone. I\u2019m studying for a Master's degree in Data Science and conducting scientific research to publish a paper in a conference or journal. My mentors are very supportive and kind. Currently, we have selected an already published paper to build upon. I've completed all the research, read many relevant papers, and my mentors have already provided guidance on how to proceed.\n\nHowever, in addition to their suggestions, they want me to identify other weaknesses in the paper and find solutions. I'm stuck at this stage; one month has passed, and I haven't been able to discover anything new beyond what they have pointed out. I'm really worried that I might disappoint my mentors, as they've been exceptionally good and supportive to me. Am I overthinking the situation? What should I do to uncover the weaknesses of the proposed method? I'm afraid that I might be slowing down the whole team :(", "author_fullname": "t2_ctixwjk2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel like I\u2019m stuck with my scientific research", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1769vr7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697125064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019m writing this post hoping to get some advice from everyone. I\u2019m studying for a Master&amp;#39;s degree in Data Science and conducting scientific research to publish a paper in a conference or journal. My mentors are very supportive and kind. Currently, we have selected an already published paper to build upon. I&amp;#39;ve completed all the research, read many relevant papers, and my mentors have already provided guidance on how to proceed.&lt;/p&gt;\n\n&lt;p&gt;However, in addition to their suggestions, they want me to identify other weaknesses in the paper and find solutions. I&amp;#39;m stuck at this stage; one month has passed, and I haven&amp;#39;t been able to discover anything new beyond what they have pointed out. I&amp;#39;m really worried that I might disappoint my mentors, as they&amp;#39;ve been exceptionally good and supportive to me. Am I overthinking the situation? What should I do to uncover the weaknesses of the proposed method? I&amp;#39;m afraid that I might be slowing down the whole team :(&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1769vr7", "is_robot_indexable": true, "report_reasons": null, "author": "ma-d-ghost", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1769vr7/i_feel_like_im_stuck_with_my_scientific_research/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1769vr7/i_feel_like_im_stuck_with_my_scientific_research/", "subreddit_subscribers": 1082448, "created_utc": 1697125064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am facing a situation where I need to identify stores with very similar names within a radius of 100m from one another. Now, there are \\~ 150k stores in the dataset.\n\nI can distribute these into \\~21k regions with varying number of stores (max \\~5k) and search locally within and that aligns with the problem statement.\n\nMy current method involves:  \nLoop for region  \nCalculate distance of first store from all other stores  \nLoop for each store  \ndist col = dist col - dist store(current loop iteration)  \nfilter for dist col &lt;= 150m\n\nstore\\_ref = current loop iteration\n\ncheck if dist (store\\_ref and store in iteration &lt;=100m)\n\nif yes,\n\ncheck similarity,\n\nif similarity&gt;threshold, add to list/dataframe\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nThis is a 3 level loop of max \\~21k \\* 5k \\* 600 iterations and is taking too long. \n\nI understand that there could be a possibility doing this using KNN/ANN, but would need some specific steps to be able to implement it. Please offer suggestions, if any?  \n", "author_fullname": "t2_15nser", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alphanumeric Search Algorithm?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_176tcyw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697183133.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am facing a situation where I need to identify stores with very similar names within a radius of 100m from one another. Now, there are ~ 150k stores in the dataset.&lt;/p&gt;\n\n&lt;p&gt;I can distribute these into ~21k regions with varying number of stores (max ~5k) and search locally within and that aligns with the problem statement.&lt;/p&gt;\n\n&lt;p&gt;My current method involves:&lt;br/&gt;\nLoop for region&lt;br/&gt;\nCalculate distance of first store from all other stores&lt;br/&gt;\nLoop for each store&lt;br/&gt;\ndist col = dist col - dist store(current loop iteration)&lt;br/&gt;\nfilter for dist col &amp;lt;= 150m&lt;/p&gt;\n\n&lt;p&gt;store_ref = current loop iteration&lt;/p&gt;\n\n&lt;p&gt;check if dist (store_ref and store in iteration &amp;lt;=100m)&lt;/p&gt;\n\n&lt;p&gt;if yes,&lt;/p&gt;\n\n&lt;p&gt;check similarity,&lt;/p&gt;\n\n&lt;p&gt;if similarity&amp;gt;threshold, add to list/dataframe&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This is a 3 level loop of max ~21k * 5k * 600 iterations and is taking too long. &lt;/p&gt;\n\n&lt;p&gt;I understand that there could be a possibility doing this using KNN/ANN, but would need some specific steps to be able to implement it. Please offer suggestions, if any?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176tcyw", "is_robot_indexable": true, "report_reasons": null, "author": "sarafpiyush98", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176tcyw/alphanumeric_search_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176tcyw/alphanumeric_search_algorithm/", "subreddit_subscribers": 1082448, "created_utc": 1697183133.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udcca\ud83d\udca1 Dive into a comprehensive guide on Multilinear Regression Model, covering each stage from data collection to evaluation! \ud83d\udcc8\ud83e\uddea", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_176tcip", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Multiple Linear Regression using python ( Regression Analysis )\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_roxmtd1o", "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Multiple Linear Regression using python ( Regression Analysis )", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Multiple Linear Regression using python ( Regression Analysis )\"&gt;&lt;/iframe&gt;", "author_name": "Machine Learning With me", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/SHa-58-n6ew/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MLwithme1617"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Multiple Linear Regression using python ( Regression Analysis )\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/176tcip", "height": 200}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/1ZfJ-n84dSb-KJRzmBENcVvGKQAD5KWZx-jRs41x8mk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "learndatascience", "selftext": "", "author_fullname": "t2_roxmtd1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\ud83d\udcca\ud83d\udca1 Dive into a comprehensive guide on Multilinear Regression Model, covering each stage from data collection to evaluation! \ud83d\udcc8\ud83e\uddea", "link_flair_richtext": [], "subreddit_name_prefixed": "r/learndatascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_12k4vi1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Linear Regression (MLR) || EDA,  Feature engineering, Feature selection\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Linear Regression (MLR) || EDA,  Feature engineering, Feature selection", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Linear Regression (MLR) || EDA,  Feature engineering, Feature selection\"&gt;&lt;/iframe&gt;", "author_name": "Machine Learning With me", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/SHa-58-n6ew/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MLwithme1617"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Linear Regression (MLR) || EDA,  Feature engineering, Feature selection\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/12k4vi1", "height": 200}, "link_flair_text": "Original Content", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LJyavExHIjeTWAM2fdMCv1o2JI-NYp8a3wMtOt1FgkA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1681344409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=SHa-58-n6ew", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?auto=webp&amp;s=e8ef5bb2c509762dfe2628fe6504fc18225fa5fe", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff2d73917a7d594a8d884c5ff9eb03a8c6894530", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3228adfc8081b0eecd3d28af77e2970bafc9b22f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5cc0c4df54c584d83a37f25b93f8dac9005e3150", "width": 320, "height": 240}], "variants": {}, "id": "BIz7RkTKofDIZ5k0s0nZfttlg7WqfKKwbxsmxxir82k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "cc42d03c-a895-11ea-9782-0ef4de97b701", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_33xxb", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "12k4vi1", "is_robot_indexable": true, "report_reasons": null, "author": "MLwithMe1617", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/learndatascience/comments/12k4vi1/dive_into_a_comprehensive_guide_on_multilinear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=SHa-58-n6ew", "subreddit_subscribers": 14880, "created_utc": 1681344409.0, "num_crossposts": 1, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Linear Regression (MLR) || EDA,  Feature engineering, Feature selection", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Linear Regression (MLR) || EDA,  Feature engineering, Feature selection\"&gt;&lt;/iframe&gt;", "author_name": "Machine Learning With me", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/SHa-58-n6ew/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MLwithme1617"}}, "is_video": false}], "created": 1697183076.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=SHa-58-n6ew", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?auto=webp&amp;s=e8ef5bb2c509762dfe2628fe6504fc18225fa5fe", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ff2d73917a7d594a8d884c5ff9eb03a8c6894530", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3228adfc8081b0eecd3d28af77e2970bafc9b22f", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/87JwpXkFhS3Va55CwoLtB9jlAGP84SBpSBgrVJlDaGU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5cc0c4df54c584d83a37f25b93f8dac9005e3150", "width": 320, "height": 240}], "variants": {}, "id": "BIz7RkTKofDIZ5k0s0nZfttlg7WqfKKwbxsmxxir82k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176tcip", "is_robot_indexable": true, "report_reasons": null, "author": "MLwithMe1617", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_12k4vi1", "author_flair_text_color": null, "permalink": "/r/datascience/comments/176tcip/dive_into_a_comprehensive_guide_on_multilinear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=SHa-58-n6ew", "subreddit_subscribers": 1082448, "created_utc": 1697183076.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Multiple Linear Regression using python ( Regression Analysis )", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/SHa-58-n6ew?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Multiple Linear Regression using python ( Regression Analysis )\"&gt;&lt;/iframe&gt;", "author_name": "Machine Learning With me", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/SHa-58-n6ew/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MLwithme1617"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone,\n\nI recently completed **Hyndman, R.J., &amp; Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition**. It's a great book for introducing time series analysis and forecasting in general and has in-depth examples with univariate time series analysis and forecasting exercises. It also introduces multivariate forecasting techniques briefly with dynamic regression models touching on VAR models. I wanted to continue on this and move on to understand multivariate time series analysis and modelling. Specifically, I'm looking for sources that focus more heavily on economic or financial time series analysis. Could you recommend any **books or video materials that also have comprehensive applications demonstrated in R for this (video lectures for this topic would be especially welcomed)**? Also, how much mathematics would be needed for the above material, and are there sources with less math-heavy content?", "author_fullname": "t2_vt5r7wi2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Recommendations for Multivariate Time Series Analysis Resources with a Focus on Economics/Finance and R Applications", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_176t8at", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697182542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I recently completed &lt;strong&gt;Hyndman, R.J., &amp;amp; Athanasopoulos, G. (2021) Forecasting: principles and practice, 3rd edition&lt;/strong&gt;. It&amp;#39;s a great book for introducing time series analysis and forecasting in general and has in-depth examples with univariate time series analysis and forecasting exercises. It also introduces multivariate forecasting techniques briefly with dynamic regression models touching on VAR models. I wanted to continue on this and move on to understand multivariate time series analysis and modelling. Specifically, I&amp;#39;m looking for sources that focus more heavily on economic or financial time series analysis. Could you recommend any &lt;strong&gt;books or video materials that also have comprehensive applications demonstrated in R for this (video lectures for this topic would be especially welcomed)&lt;/strong&gt;? Also, how much mathematics would be needed for the above material, and are there sources with less math-heavy content?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176t8at", "is_robot_indexable": true, "report_reasons": null, "author": "Additional_Guide5439", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176t8at/seeking_recommendations_for_multivariate_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176t8at/seeking_recommendations_for_multivariate_time/", "subreddit_subscribers": 1082448, "created_utc": 1697182542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I sense a generational divide in my job. My supervisor seems afraid of the very tool our organization spends gobs of money to retain. It feels counter to what I experienced in school where my professors encouraged me to think bigger.\n\nI understand that most people just want tables and charts. What is wrong with providing them in Tableau? It\u2019s so much better at viewing multiple tables together than Excel will likely ever be(all due respect to anyone making excel dashboards).\n\nI\u2019m slowly realizing that I\u2019ve had the tools for a data warehouse at my fingertips this whole time with tableau prep and our server, and I get the feeling my supervisor and boss will just poo-poo the work away. How do others deal with these road blocks constructively?", "author_fullname": "t2_kmjz8j1vy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Generational divide", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176qmdz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697172134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I sense a generational divide in my job. My supervisor seems afraid of the very tool our organization spends gobs of money to retain. It feels counter to what I experienced in school where my professors encouraged me to think bigger.&lt;/p&gt;\n\n&lt;p&gt;I understand that most people just want tables and charts. What is wrong with providing them in Tableau? It\u2019s so much better at viewing multiple tables together than Excel will likely ever be(all due respect to anyone making excel dashboards).&lt;/p&gt;\n\n&lt;p&gt;I\u2019m slowly realizing that I\u2019ve had the tools for a data warehouse at my fingertips this whole time with tableau prep and our server, and I get the feeling my supervisor and boss will just poo-poo the work away. How do others deal with these road blocks constructively?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176qmdz", "is_robot_indexable": true, "report_reasons": null, "author": "tableau_guy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176qmdz/generational_divide/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176qmdz/generational_divide/", "subreddit_subscribers": 1082448, "created_utc": 1697172134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hi everyone! Forta, a decentralised threat intel for web3, is launching a new bounty to detect malicious smart contracts using machine learning.  Apply to earn $3,000 if you have data science and machine learning experience.  [https://forta.notion.site/Malicious-Smart-Contract-Machine-Learning-26d474eb14a445dda503d6088f6d5b80](https://forta.notion.site/Malicious-Smart-Contract-Machine-Learning-26d474eb14a445dda503d6088f6d5b80)", "author_fullname": "t2_gum9y8ey", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Forta Bounty - Web3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176ola2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697165099.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi everyone! Forta, a decentralised threat intel for web3, is launching a new bounty to detect malicious smart contracts using machine learning.  Apply to earn $3,000 if you have data science and machine learning experience.  &lt;a href=\"https://forta.notion.site/Malicious-Smart-Contract-Machine-Learning-26d474eb14a445dda503d6088f6d5b80\"&gt;https://forta.notion.site/Malicious-Smart-Contract-Machine-Learning-26d474eb14a445dda503d6088f6d5b80&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?auto=webp&amp;s=befaedb8837d4a815bee94c86a6d7c52c2660f6c", "width": 2000, "height": 819}, "resolutions": [{"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5efbc6aa7f23fe48afab7275ccd99ebf0e5ecb0c", "width": 108, "height": 44}, {"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c5eac3b44017110115ad393ecf30d258abf40509", "width": 216, "height": 88}, {"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2c4ca5cc150bcfbe745793f00285c668b5aa0d17", "width": 320, "height": 131}, {"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=85df9260c2952f4cb60426a1e81a175bbdba9fe0", "width": 640, "height": 262}, {"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a3add95e23883a6f343515da42e45bd159bc976e", "width": 960, "height": 393}, {"url": "https://external-preview.redd.it/YUY0DGKNiddDxTBsvPVPfEe-t76mmZ2cgsUbgiEpgyg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=15b29f8541b503726dc0cdcf03106b1fb43260aa", "width": 1080, "height": 442}], "variants": {}, "id": "WNAyWwEzxkmyOVI4y49N0veDK1zCjPWKAEO3RZIfv1s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176ola2", "is_robot_indexable": true, "report_reasons": null, "author": "Suspicious-Case3330", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176ola2/forta_bounty_web3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176ola2/forta_bounty_web3/", "subreddit_subscribers": 1082448, "created_utc": 1697165099.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all, I'm working on a binary classification problem with all input features being categorical (and nominal).\n\nThe problem I'm facing is that each input example can contain multiple values of a feature and there are too many different values.\n\n(For example, multi-value feature being a 'Hobbies' feature that contains a list of strings:\n\n&gt;data = {'User': \\['User1', 'User2', 'User3'\\],'Hobbies': \\[\\['Soccer', 'Swimming', 'Hiking'\\],\\['Swimming', 'Cycling'\\],\\['Soccer', 'Hiking'\\]\\]}\n\n)\n\nI first tried one-hot encoding (for each single value instead of each list), but the feature dimension became too large with most of them being 0's.  I searched for other suggestions that address this issue and [this article](https://medium.com/swlh/stop-one-hot-encoding-your-categorical-features-avoid-curse-of-dimensionality-16743c32cea4) stands out. Basically, it suggests other encoding methods to reduce the dimensionality, namely frequency encoding, target encoding, and embedding.\n\nThe tricky part is that (to my knowledge) these approaches only work well for when each input example has a single value for each categorical feature. When it comes to my case, there still exists the risk of high dimensionality. Another way that I can try is to explode the examples for each feature so that each feature contains a single value, then proceed with encoding from there (and align the target labels accordingly). But I'm not sure about this approach.\n\nHow would you approach this kind of data? Any suggestion will be appreciated. Thank you! Sorry as I'm new to these concepts and if this question was asked before in one way or the other. All of my search for the topics doesn't address the multiple-value nature of the features.\n\n&amp;#x200B;", "author_fullname": "t2_34cofh7h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On handling multi-label/multi-value categorical features and high cardinality.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176ojaz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697164921.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I&amp;#39;m working on a binary classification problem with all input features being categorical (and nominal).&lt;/p&gt;\n\n&lt;p&gt;The problem I&amp;#39;m facing is that each input example can contain multiple values of a feature and there are too many different values.&lt;/p&gt;\n\n&lt;p&gt;(For example, multi-value feature being a &amp;#39;Hobbies&amp;#39; feature that contains a list of strings:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;data = {&amp;#39;User&amp;#39;: [&amp;#39;User1&amp;#39;, &amp;#39;User2&amp;#39;, &amp;#39;User3&amp;#39;],&amp;#39;Hobbies&amp;#39;: [[&amp;#39;Soccer&amp;#39;, &amp;#39;Swimming&amp;#39;, &amp;#39;Hiking&amp;#39;],[&amp;#39;Swimming&amp;#39;, &amp;#39;Cycling&amp;#39;],[&amp;#39;Soccer&amp;#39;, &amp;#39;Hiking&amp;#39;]]}&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;)&lt;/p&gt;\n\n&lt;p&gt;I first tried one-hot encoding (for each single value instead of each list), but the feature dimension became too large with most of them being 0&amp;#39;s.  I searched for other suggestions that address this issue and &lt;a href=\"https://medium.com/swlh/stop-one-hot-encoding-your-categorical-features-avoid-curse-of-dimensionality-16743c32cea4\"&gt;this article&lt;/a&gt; stands out. Basically, it suggests other encoding methods to reduce the dimensionality, namely frequency encoding, target encoding, and embedding.&lt;/p&gt;\n\n&lt;p&gt;The tricky part is that (to my knowledge) these approaches only work well for when each input example has a single value for each categorical feature. When it comes to my case, there still exists the risk of high dimensionality. Another way that I can try is to explode the examples for each feature so that each feature contains a single value, then proceed with encoding from there (and align the target labels accordingly). But I&amp;#39;m not sure about this approach.&lt;/p&gt;\n\n&lt;p&gt;How would you approach this kind of data? Any suggestion will be appreciated. Thank you! Sorry as I&amp;#39;m new to these concepts and if this question was asked before in one way or the other. All of my search for the topics doesn&amp;#39;t address the multiple-value nature of the features.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?auto=webp&amp;s=e4c05efb8e7eabb8fe5be7950cbdf8b7574039d0", "width": 1200, "height": 848}, "resolutions": [{"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e2bcbbcf5c954a81d766f837557ab8538d04464d", "width": 108, "height": 76}, {"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=719c3a6e89b80326515907eec8208713517d44fd", "width": 216, "height": 152}, {"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b9c755cb79167278a421677a8ac39c82174e97aa", "width": 320, "height": 226}, {"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=31105cf933cfdaef26002492c8d5111b5e2c7334", "width": 640, "height": 452}, {"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=39339c6e244f4e1d9d334aeb2ecc02c6574a2e87", "width": 960, "height": 678}, {"url": "https://external-preview.redd.it/qVaL6ORANmC-C7cky4SdxDfTni_12_GPuJeFweXtgqY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6f16efceb0e9e91b01f70242ea1cbfe247ab124a", "width": 1080, "height": 763}], "variants": {}, "id": "Vju-ktydPGpaa_K21sWwaMhKZihatZsNz7OW0Ec8tNQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176ojaz", "is_robot_indexable": true, "report_reasons": null, "author": "CheapBanana1050", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176ojaz/on_handling_multilabelmultivalue_categorical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176ojaz/on_handling_multilabelmultivalue_categorical/", "subreddit_subscribers": 1082448, "created_utc": 1697164921.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\\`cp.norm(weights, 1).is\\_dcp()\\` returns true. Then why this code works:\n\n&amp;#x200B;\n\n    import cvxpy as cp\n    import numpy as np\n    inputs = np.random.normal(0, 1, (100, 300))\n    inputs_mean = inputs.mean(axis=1) # shape (features,)\n    inputs_cov = np.asmatrix(np.cov(inputs)) # shape (features, features)\n    weights = cp.Variable(len(inputs))\n    risk = cp.quad_form(weights, inputs_cov)\n    constraints = [\n    # cp.norm(weights, 1) == 1.,\n    cp.sum(weights) == 1.,\n    ]\n    problem = cp.Problem(cp.Minimize(risk), constraints)\n    problem.solve(verbose=True)\n    weights.value\n\nBut if you use the first constraint (\\`cp.norm\\`) instead of the second, it does not:\n\n&amp;#x200B;\n\n    DCPError: Problem does not follow DCP rules. Specifically:\n    The following constraints are not DCP:\n    norm1(var456) == 1.0 , because the following subexpressions are not:\n    |-- norm1(var456) == 1.0\n\n&amp;#x200B;\n\nWhy is it not DCP-compliant? How can I troubleshoot it? Is there an alternative way to solve the problem of requiring the sum of abs weights to be 1? Thanks.\n\n&amp;#x200B;", "author_fullname": "t2_j34wfzb7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CVXPY: Why Norm constraint is not DCP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176fpo0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697140219.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;`cp.norm(weights, 1).is_dcp()` returns true. Then why this code works:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import cvxpy as cp\nimport numpy as np\ninputs = np.random.normal(0, 1, (100, 300))\ninputs_mean = inputs.mean(axis=1) # shape (features,)\ninputs_cov = np.asmatrix(np.cov(inputs)) # shape (features, features)\nweights = cp.Variable(len(inputs))\nrisk = cp.quad_form(weights, inputs_cov)\nconstraints = [\n# cp.norm(weights, 1) == 1.,\ncp.sum(weights) == 1.,\n]\nproblem = cp.Problem(cp.Minimize(risk), constraints)\nproblem.solve(verbose=True)\nweights.value\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;But if you use the first constraint (`cp.norm`) instead of the second, it does not:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;DCPError: Problem does not follow DCP rules. Specifically:\nThe following constraints are not DCP:\nnorm1(var456) == 1.0 , because the following subexpressions are not:\n|-- norm1(var456) == 1.0\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Why is it not DCP-compliant? How can I troubleshoot it? Is there an alternative way to solve the problem of requiring the sum of abs weights to be 1? Thanks.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176fpo0", "is_robot_indexable": true, "report_reasons": null, "author": "FierceTeletubby", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176fpo0/cvxpy_why_norm_constraint_is_not_dcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176fpo0/cvxpy_why_norm_constraint_is_not_dcp/", "subreddit_subscribers": 1082448, "created_utc": 1697140219.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What's the most creative exit or pivot you have done (or seen others do) after being a DS for some time?", "author_fullname": "t2_7zmoi25a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS exits or pivots", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1769fk8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697123889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the most creative exit or pivot you have done (or seen others do) after being a DS for some time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1769fk8", "is_robot_indexable": true, "report_reasons": null, "author": "ergodym", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1769fk8/ds_exits_or_pivots/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1769fk8/ds_exits_or_pivots/", "subreddit_subscribers": 1082448, "created_utc": 1697123889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, I am currently a penultimate uni student doing a double degree in business and data science (majoring in accounting). While doing uni, I balance a normal grocery store job for the past 2 years. I feel very burnt out with the workload and was wondering if its any better to take a gap year to find a full time job within my field (more so on the data science field), but I am not sure if I should just hang on another year and finish my degree. Another potential approach would be to go full time work and balance uni with 2 courses. What would be ideal and if so, what sort of IT job could I look for with no prior experience or qualifications in IT or data science?", "author_fullname": "t2_7wg5m7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career planning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17686qn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697120602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I am currently a penultimate uni student doing a double degree in business and data science (majoring in accounting). While doing uni, I balance a normal grocery store job for the past 2 years. I feel very burnt out with the workload and was wondering if its any better to take a gap year to find a full time job within my field (more so on the data science field), but I am not sure if I should just hang on another year and finish my degree. Another potential approach would be to go full time work and balance uni with 2 courses. What would be ideal and if so, what sort of IT job could I look for with no prior experience or qualifications in IT or data science?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17686qn", "is_robot_indexable": true, "report_reasons": null, "author": "Kenny9184", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17686qn/career_planning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17686qn/career_planning/", "subreddit_subscribers": 1082448, "created_utc": 1697120602.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}