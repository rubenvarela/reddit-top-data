{"kind": "Listing", "data": {"after": "t3_176js4y", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is UMortgage interview assessment. Reads to me like free work more than skills assessment.", "author_fullname": "t2_4ed4jwbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just do a quick 30min to 1hr take home test. \ud83e\udd21 \ud83e\udd21", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1767l40", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "ups": 328, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 328, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/L4dkpUvYTR8Wd0bbDwd9ICxvZwRdG_aH8fXf6p9O3wI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697118958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is UMortgage interview assessment. Reads to me like free work more than skills assessment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/fvlmf8qz1stb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/fvlmf8qz1stb1.jpg?auto=webp&amp;s=e871d23f6aa715d584d73d40a5ba71442dbf5563", "width": 828, "height": 1792}, "resolutions": [{"url": "https://preview.redd.it/fvlmf8qz1stb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3422d29cda16f2aa231f250bf350abf649ca055a", "width": 108, "height": 216}, {"url": "https://preview.redd.it/fvlmf8qz1stb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a20be752c3e865249cbb3690b32b7afd9c3232a1", "width": 216, "height": 432}, {"url": "https://preview.redd.it/fvlmf8qz1stb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2934becb569e26bd164a575f84f2723c02011b5c", "width": 320, "height": 640}, {"url": "https://preview.redd.it/fvlmf8qz1stb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2906c13c5d0b2a9f81fdd656e2ede38f3c4904e2", "width": 640, "height": 1280}], "variants": {}, "id": "wiOcOa2Zlt93AaPEsfspXz9hnOBXFMX02vZ8yBFLDoA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1767l40", "is_robot_indexable": true, "report_reasons": null, "author": "Dull_Biscotti7205", "discussion_type": null, "num_comments": 79, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1767l40/just_do_a_quick_30min_to_1hr_take_home_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/fvlmf8qz1stb1.jpg", "subreddit_subscribers": 133821, "created_utc": 1697118958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I graduated in 2023 and am working an analytics engineering job at a mid sized company. My manager is the worst manager you can think of, she consistently goes on vacations, has declined our weekly 1:1\u2019s less than 5 mins before the start or does not show up to them for the past 3 months, forgets group meetings, and does not give me any work to do. I have been doing almost nothing for the past couple of months and no one has noticed.\n\nThese past weeks, my manager gave me little context on a project they were working on because they were getting pressure to complete it by their boss. They gave it to me because they have 0 technical ability and mind you, they are a new manager with analytics engineering experience before. I have 0 context on the work and now the VP is messaging me about progress and I\u2019m the SME on a project I know nothing of. I message my manager consistently for guidance and they never respond or respond with simple \u201cgreat\u201d, \u201cask xyz\u201d, \u201csounds good.\u201d\n\nThis is completely frustrating. I have learned 0 from this job and I have been working here for 7 months. I am wasting my time. What do i do?", "author_fullname": "t2_qeq05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Horrible Manager as New Grad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176caqi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697131263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I graduated in 2023 and am working an analytics engineering job at a mid sized company. My manager is the worst manager you can think of, she consistently goes on vacations, has declined our weekly 1:1\u2019s less than 5 mins before the start or does not show up to them for the past 3 months, forgets group meetings, and does not give me any work to do. I have been doing almost nothing for the past couple of months and no one has noticed.&lt;/p&gt;\n\n&lt;p&gt;These past weeks, my manager gave me little context on a project they were working on because they were getting pressure to complete it by their boss. They gave it to me because they have 0 technical ability and mind you, they are a new manager with analytics engineering experience before. I have 0 context on the work and now the VP is messaging me about progress and I\u2019m the SME on a project I know nothing of. I message my manager consistently for guidance and they never respond or respond with simple \u201cgreat\u201d, \u201cask xyz\u201d, \u201csounds good.\u201d&lt;/p&gt;\n\n&lt;p&gt;This is completely frustrating. I have learned 0 from this job and I have been working here for 7 months. I am wasting my time. What do i do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176caqi", "is_robot_indexable": true, "report_reasons": null, "author": "therealhm2", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176caqi/horrible_manager_as_new_grad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176caqi/horrible_manager_as_new_grad/", "subreddit_subscribers": 133821, "created_utc": 1697131263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I had an interview with the CEO of this startup that is obviously too obsessed with generative AI and wants to build a \u201ccentacorn\u201d by doing stuff with AI. \nI will be coming in as a data engineer, working completely on AWS stack if everything goes well. Will be working on creating solutions to architect, model the data. \n The CEO said he wants \u201cbillions of rows of data\u201d so he can predict \u201cthe future.\u201d The company has around 50 employees, product and service based and been stable for a few years. \nGraduated last year, right now i am working as a DE in an ETL department, mostly just working on query/process optimization and migration process (locally). I don\u2019t think i am developing my skillset here that\u2019s why looking at different options. \nThis potential job offers a decent increment, good data stack and cloud of course but i am uncertain about the company after the meeting with the CEO. Market is horrible. Takes months to get a new job in chance of lay off and i cannot afford that. Is it worth the risk?", "author_fullname": "t2_4gt1sxma", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do i take this job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176gql9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697142901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had an interview with the CEO of this startup that is obviously too obsessed with generative AI and wants to build a \u201ccentacorn\u201d by doing stuff with AI. \nI will be coming in as a data engineer, working completely on AWS stack if everything goes well. Will be working on creating solutions to architect, model the data. \n The CEO said he wants \u201cbillions of rows of data\u201d so he can predict \u201cthe future.\u201d The company has around 50 employees, product and service based and been stable for a few years. \nGraduated last year, right now i am working as a DE in an ETL department, mostly just working on query/process optimization and migration process (locally). I don\u2019t think i am developing my skillset here that\u2019s why looking at different options. \nThis potential job offers a decent increment, good data stack and cloud of course but i am uncertain about the company after the meeting with the CEO. Market is horrible. Takes months to get a new job in chance of lay off and i cannot afford that. Is it worth the risk?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "176gql9", "is_robot_indexable": true, "report_reasons": null, "author": "hareuz", "discussion_type": null, "num_comments": 39, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176gql9/do_i_take_this_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176gql9/do_i_take_this_job/", "subreddit_subscribers": 133821, "created_utc": 1697142901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone. I am a \"data engineer\" in name, however my work has compromised mostly of on premise sql server and ssis development.  \n\nI am responsible for ETLing data from application warehouses (OLTP) databases into reporting analytical warehouses.  Our team currently runs our ETL every 15 minutes, so data is updated within \\~17 minutes: and the basic pattern is as follows.\n\n\\#1) get all the data that changed in the last 15 minutes using either CDC / CT / Timestamp columns \n\n\\#2) For each destination table, write a query against the source data that produces the desired output table for any records that we identified as changed in step #1. Compare this query to the destination table by loading destination table records into memory.  If any differences are found, issue an update statement to update the final output table.\n\nOur team is moving into snowflake for various reasons, and thus far it has made me have a few questions....\n\n&amp;#x200B;\n\nQuestion #1) It appears the standard in snowflake is to load data from source into a raw / stage table where every single record that changes is loaded each time it changes, but to keep all of the data and not blow out any of the previous records...  Is this a true statement, or is it common to find people using merges from stage to update records with upserts?\n\nExample: Say my source application is one table of \"loans\", and there are 3 columns as shown below.\n\nOn 10/09/2023 the list price of loan #1 was 20,000,  then the next day it changed to 30,000, and finally on 10/11/2023 it changed again to 50,000... In snowflake I imagine a table would exist that would have this same LoanID 3 different times, like below...   Then further logic within snowflake (Transform step using dbt / tasks / etc...) would choose which one of these records is the correct one to move forward into the final warehouse tables...\n\nIn our current world, there would only be one final table in the reporting warehouse \"named FactLoan\" and again we would note that loanID 1 changed, compare the values of loanID 1 against the final \"factloan\" table, identify a record changed and issue an update.  There would never be a history stored anywhere in any intermediary table.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n|LoanID|ListPrice|UpdatedDate|\n|:-|:-|:-|\n|1|20000|10/09/2023|\n|1|30000|10/10/2023|\n|1|50000|10/11/2023|\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nQuestion #2): What are the common tools / practices used to get data into snowflake from on premise sql servers.  From googling around a lot I've seen the following patterns, but curious if there are more.\n\na) Use python to pull data from source into snowflake using Airflow\n\nb) Python with pyspark to move data in, orchestrated on DataBricks clusters.\n\nc) An out of the box ETL tool like Matillion / etc..\n\nd) custom code where someone grabs the change records from the sql server, pushes them into a file, uploads to s3, and then runs a \"copy into\" command into the 'raw' table.\n\n&amp;#x200B;\n\nHopefully my questions make sense and thanks for the input! :-)\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_9ykvtaj8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question on ELT standard in Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176njry", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697161771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone. I am a &amp;quot;data engineer&amp;quot; in name, however my work has compromised mostly of on premise sql server and ssis development.  &lt;/p&gt;\n\n&lt;p&gt;I am responsible for ETLing data from application warehouses (OLTP) databases into reporting analytical warehouses.  Our team currently runs our ETL every 15 minutes, so data is updated within ~17 minutes: and the basic pattern is as follows.&lt;/p&gt;\n\n&lt;p&gt;#1) get all the data that changed in the last 15 minutes using either CDC / CT / Timestamp columns &lt;/p&gt;\n\n&lt;p&gt;#2) For each destination table, write a query against the source data that produces the desired output table for any records that we identified as changed in step #1. Compare this query to the destination table by loading destination table records into memory.  If any differences are found, issue an update statement to update the final output table.&lt;/p&gt;\n\n&lt;p&gt;Our team is moving into snowflake for various reasons, and thus far it has made me have a few questions....&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Question #1) It appears the standard in snowflake is to load data from source into a raw / stage table where every single record that changes is loaded each time it changes, but to keep all of the data and not blow out any of the previous records...  Is this a true statement, or is it common to find people using merges from stage to update records with upserts?&lt;/p&gt;\n\n&lt;p&gt;Example: Say my source application is one table of &amp;quot;loans&amp;quot;, and there are 3 columns as shown below.&lt;/p&gt;\n\n&lt;p&gt;On 10/09/2023 the list price of loan #1 was 20,000,  then the next day it changed to 30,000, and finally on 10/11/2023 it changed again to 50,000... In snowflake I imagine a table would exist that would have this same LoanID 3 different times, like below...   Then further logic within snowflake (Transform step using dbt / tasks / etc...) would choose which one of these records is the correct one to move forward into the final warehouse tables...&lt;/p&gt;\n\n&lt;p&gt;In our current world, there would only be one final table in the reporting warehouse &amp;quot;named FactLoan&amp;quot; and again we would note that loanID 1 changed, compare the values of loanID 1 against the final &amp;quot;factloan&amp;quot; table, identify a record changed and issue an update.  There would never be a history stored anywhere in any intermediary table.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;LoanID&lt;/th&gt;\n&lt;th align=\"left\"&gt;ListPrice&lt;/th&gt;\n&lt;th align=\"left\"&gt;UpdatedDate&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;20000&lt;/td&gt;\n&lt;td align=\"left\"&gt;10/09/2023&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;30000&lt;/td&gt;\n&lt;td align=\"left\"&gt;10/10/2023&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;1&lt;/td&gt;\n&lt;td align=\"left\"&gt;50000&lt;/td&gt;\n&lt;td align=\"left\"&gt;10/11/2023&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Question #2): What are the common tools / practices used to get data into snowflake from on premise sql servers.  From googling around a lot I&amp;#39;ve seen the following patterns, but curious if there are more.&lt;/p&gt;\n\n&lt;p&gt;a) Use python to pull data from source into snowflake using Airflow&lt;/p&gt;\n\n&lt;p&gt;b) Python with pyspark to move data in, orchestrated on DataBricks clusters.&lt;/p&gt;\n\n&lt;p&gt;c) An out of the box ETL tool like Matillion / etc..&lt;/p&gt;\n\n&lt;p&gt;d) custom code where someone grabs the change records from the sql server, pushes them into a file, uploads to s3, and then runs a &amp;quot;copy into&amp;quot; command into the &amp;#39;raw&amp;#39; table.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hopefully my questions make sense and thanks for the input! :-)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "176njry", "is_robot_indexable": true, "report_reasons": null, "author": "databasenoobie", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176njry/question_on_elt_standard_in_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176njry/question_on_elt_standard_in_snowflake/", "subreddit_subscribers": 133821, "created_utc": 1697161771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "IoT is pushing \\~10 records per second, sometimes over a million a day. It's growing. It's currently stored in AWS RDS Serverless MySQL. This is becoming a problem.   \n\n\nRight now it flows into DynamoDB where it is processed into an API which stores it in MySQL.  \n\n\nMy proposal:\n\n1. Keep DynamoDB -&gt; Lambda -&gt; API (limit MySQL data to most recent 100 rows -- call it an ODS)\n2. Lambda -&gt; new DynamoDB table (\"data\\_lake\\_monthly\\_staging\"?)\n3. DDB PITR every month -&gt; S3\n4. Glue converts S3 DDB backup into monthly parquet files\n5. Athena is used to query parquet files back into 100 historical \"summaries\" back into MySQL. (So MySQL gets a 100 record operational store + 100 record historical store.\n\n&amp;#x200B;\n\nNumber 3 and 4 are my biggest question marks. How does this sound? (Does Athena have something like Spark's \"sample\" that would make the historical summary easier?)", "author_fullname": "t2_504yq0ta", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Sanity Check] Moving 500 million rows out of MySQL RDS into S3 Parquet files -- how does this sound?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176fi3t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697139639.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;IoT is pushing ~10 records per second, sometimes over a million a day. It&amp;#39;s growing. It&amp;#39;s currently stored in AWS RDS Serverless MySQL. This is becoming a problem.   &lt;/p&gt;\n\n&lt;p&gt;Right now it flows into DynamoDB where it is processed into an API which stores it in MySQL.  &lt;/p&gt;\n\n&lt;p&gt;My proposal:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Keep DynamoDB -&amp;gt; Lambda -&amp;gt; API (limit MySQL data to most recent 100 rows -- call it an ODS)&lt;/li&gt;\n&lt;li&gt;Lambda -&amp;gt; new DynamoDB table (&amp;quot;data_lake_monthly_staging&amp;quot;?)&lt;/li&gt;\n&lt;li&gt;DDB PITR every month -&amp;gt; S3&lt;/li&gt;\n&lt;li&gt;Glue converts S3 DDB backup into monthly parquet files&lt;/li&gt;\n&lt;li&gt;Athena is used to query parquet files back into 100 historical &amp;quot;summaries&amp;quot; back into MySQL. (So MySQL gets a 100 record operational store + 100 record historical store.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Number 3 and 4 are my biggest question marks. How does this sound? (Does Athena have something like Spark&amp;#39;s &amp;quot;sample&amp;quot; that would make the historical summary easier?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176fi3t", "is_robot_indexable": true, "report_reasons": null, "author": "chmod-77", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176fi3t/sanity_check_moving_500_million_rows_out_of_mysql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176fi3t/sanity_check_moving_500_million_rows_out_of_mysql/", "subreddit_subscribers": 133821, "created_utc": 1697139639.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a recent graduate and I'm working at a e-commerce startup as a data analyst for 2 months . We use Zoho for pretty much everything, CRM, accounting, marketing etc. and analytics as well. Analytics just has the option to import data directly form the other apps and store it in seperate workspaces. This becomes a pain to deal with as we cannot query data between workspaces. Even with very little data, this results in complex joins.\nI feel like a data warehouse is what we need. But I'm not sure on how to go about it as I kinda stumbled into this job and I'm still learning. \nIt would be really helpful if you guys could help me out with the general procedure and the best tools for the job.Also, I am comfortable using SQL and python.", "author_fullname": "t2_w16t5qhn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help in building a data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176a6i2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697125844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a recent graduate and I&amp;#39;m working at a e-commerce startup as a data analyst for 2 months . We use Zoho for pretty much everything, CRM, accounting, marketing etc. and analytics as well. Analytics just has the option to import data directly form the other apps and store it in seperate workspaces. This becomes a pain to deal with as we cannot query data between workspaces. Even with very little data, this results in complex joins.\nI feel like a data warehouse is what we need. But I&amp;#39;m not sure on how to go about it as I kinda stumbled into this job and I&amp;#39;m still learning. \nIt would be really helpful if you guys could help me out with the general procedure and the best tools for the job.Also, I am comfortable using SQL and python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176a6i2", "is_robot_indexable": true, "report_reasons": null, "author": "booberrypie_", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/176a6i2/need_help_in_building_a_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176a6i2/need_help_in_building_a_data_warehouse/", "subreddit_subscribers": 133821, "created_utc": 1697125844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been using Stitch for a while. I know there are new players like Airbyte. Just want to learn about the community\u2019s experience. Thank you.\n\nThank you!", "author_fullname": "t2_hlf7js20w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for an ETL service for Shopify / Stripe", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176sjmh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697179746.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been using Stitch for a while. I know there are new players like Airbyte. Just want to learn about the community\u2019s experience. Thank you.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "176sjmh", "is_robot_indexable": true, "report_reasons": null, "author": "No-Dream-420", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176sjmh/looking_for_an_etl_service_for_shopify_stripe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176sjmh/looking_for_an_etl_service_for_shopify_stripe/", "subreddit_subscribers": 133821, "created_utc": 1697179746.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At work, I have different data sources where I need to sanitize, transform, and join them all into one giant table. This table will be used to generate reports with different dimensions and metrics on our website. However, we are not allowed to use redshift, clickhouse, etc to generate the materialized views for us. Is there a work around for this, to still have views and fast reports without using the popular tools?", "author_fullname": "t2_upu2xkfu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question om OLAP reports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176rklq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697175859.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At work, I have different data sources where I need to sanitize, transform, and join them all into one giant table. This table will be used to generate reports with different dimensions and metrics on our website. However, we are not allowed to use redshift, clickhouse, etc to generate the materialized views for us. Is there a work around for this, to still have views and fast reports without using the popular tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176rklq", "is_robot_indexable": true, "report_reasons": null, "author": "ieattreebranches", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176rklq/question_om_olap_reports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176rklq/question_om_olap_reports/", "subreddit_subscribers": 133821, "created_utc": 1697175859.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hii, guys! I have a really nested xml and I want to transform it into a nested parquet. The idea is to load the nested parquet into BigQuery.\nDo you have any idea about how I could do that? Everything I've tried flattens the data.", "author_fullname": "t2_78ttv0b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nested parquet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176exq2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697138148.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hii, guys! I have a really nested xml and I want to transform it into a nested parquet. The idea is to load the nested parquet into BigQuery.\nDo you have any idea about how I could do that? Everything I&amp;#39;ve tried flattens the data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176exq2", "is_robot_indexable": true, "report_reasons": null, "author": "marisol06", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176exq2/nested_parquet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176exq2/nested_parquet/", "subreddit_subscribers": 133821, "created_utc": 1697138148.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all\nCurrently i work as a data analyst and use power bi and sql mostly in my day to day work,\nI want to move into data engineering.\nI have been applying for  some positions but not getting shortlisted\nIs there anyone who moved to data engineering from data analytics, can someone share the guide path to become data engineer from data analyst????", "author_fullname": "t2_7ui8gfy2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Suggestion for career transition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176weop", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697195985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all\nCurrently i work as a data analyst and use power bi and sql mostly in my day to day work,\nI want to move into data engineering.\nI have been applying for  some positions but not getting shortlisted\nIs there anyone who moved to data engineering from data analytics, can someone share the guide path to become data engineer from data analyst????&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176weop", "is_robot_indexable": true, "report_reasons": null, "author": "Negi_DA", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176weop/suggestion_for_career_transition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176weop/suggestion_for_career_transition/", "subreddit_subscribers": 133821, "created_utc": 1697195985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there, I have really no experience creating pipelines and I'm really not sure where to start or what objects I need to used to do this. I'm honestly pretty overwhelmed and confused. Here is the basics of what I'm trying to do :\n\n1. I have an input file (xlsx) that is in an ADLS Gen 2 data lake. \n2. Need to take that file and format the contents of it into a JSON format that I have\n3. JSON is used in the body of an API POST message to an endpoint that I have\n4. Take the response and do \"something\" with the result that comes back from the API\n\nI've tried creating a data flow task to call the API but that seems to only work with HTML headers and doesnt have the BODY section I need. I then used a webhook object that looks like how I'm going to call the API but how do I get the data from my input into there is my question. Here's kind of what I'm looking at now:  \n\n\nhttps://preview.redd.it/1lbu9dzptttb1.png?width=1105&amp;format=png&amp;auto=webp&amp;s=eb640a860cf6ca94f496d2a61bbaac2cda2e6165", "author_fullname": "t2_ue5zuhx1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Not sure where to start -- Calling an API using input file", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 90, "top_awarded_type": null, "hide_score": false, "media_metadata": {"1lbu9dzptttb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 69, "x": 108, "u": "https://preview.redd.it/1lbu9dzptttb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=49f35f8d08d5e06134618aa34299202df13479ab"}, {"y": 139, "x": 216, "u": "https://preview.redd.it/1lbu9dzptttb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bd42b0a26c70459a1b3c979872de40b31ddaa701"}, {"y": 207, "x": 320, "u": "https://preview.redd.it/1lbu9dzptttb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=176b7b4e5d2f77f5a554c4ee661554afdc6381cd"}, {"y": 414, "x": 640, "u": "https://preview.redd.it/1lbu9dzptttb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e5b47530bf0cada9ce4732ef715a982680c188ec"}, {"y": 621, "x": 960, "u": "https://preview.redd.it/1lbu9dzptttb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=027981f4da2bb5c917b15e83be444d7da1c90c13"}, {"y": 698, "x": 1080, "u": "https://preview.redd.it/1lbu9dzptttb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=881ff77b28a3ee51bde2202213099fb2f72fdb33"}], "s": {"y": 715, "x": 1105, "u": "https://preview.redd.it/1lbu9dzptttb1.png?width=1105&amp;format=png&amp;auto=webp&amp;s=eb640a860cf6ca94f496d2a61bbaac2cda2e6165"}, "id": "1lbu9dzptttb1"}}, "name": "t3_176fs0r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/c-alnGUj30F20gUVeXOituIvmCxN8-PCaF1hFMotYxE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697140396.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, I have really no experience creating pipelines and I&amp;#39;m really not sure where to start or what objects I need to used to do this. I&amp;#39;m honestly pretty overwhelmed and confused. Here is the basics of what I&amp;#39;m trying to do :&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I have an input file (xlsx) that is in an ADLS Gen 2 data lake. &lt;/li&gt;\n&lt;li&gt;Need to take that file and format the contents of it into a JSON format that I have&lt;/li&gt;\n&lt;li&gt;JSON is used in the body of an API POST message to an endpoint that I have&lt;/li&gt;\n&lt;li&gt;Take the response and do &amp;quot;something&amp;quot; with the result that comes back from the API&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;ve tried creating a data flow task to call the API but that seems to only work with HTML headers and doesnt have the BODY section I need. I then used a webhook object that looks like how I&amp;#39;m going to call the API but how do I get the data from my input into there is my question. Here&amp;#39;s kind of what I&amp;#39;m looking at now:  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/1lbu9dzptttb1.png?width=1105&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eb640a860cf6ca94f496d2a61bbaac2cda2e6165\"&gt;https://preview.redd.it/1lbu9dzptttb1.png?width=1105&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=eb640a860cf6ca94f496d2a61bbaac2cda2e6165&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176fs0r", "is_robot_indexable": true, "report_reasons": null, "author": "Claerwall", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176fs0r/not_sure_where_to_start_calling_an_api_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176fs0r/not_sure_where_to_start_calling_an_api_using/", "subreddit_subscribers": 133821, "created_utc": 1697140396.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nI love the engineering side of data and I'm looking to break into ml engineering or data engineering roles.  \nI have about two years of experience in backend(.net and python) plus an internship in data science. My educational background is: BS in econ, Ms in pure math, Ma in econ. Heavily self-studied ML in my bachelor's and have done a few projects already(knowledge is a little bit outdated)\n\nWhat would be your advice here? Should I apply for internships? Do I have to learn anything before applying or I can learn in my internship? \n\nMy long-term goal is becoming an ML engineer but see it as a senior role and I'm lacking DE skills", "author_fullname": "t2_45mo3pla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking into the field as a backend engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1768ymf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697122679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I love the engineering side of data and I&amp;#39;m looking to break into ml engineering or data engineering roles.&lt;br/&gt;\nI have about two years of experience in backend(.net and python) plus an internship in data science. My educational background is: BS in econ, Ms in pure math, Ma in econ. Heavily self-studied ML in my bachelor&amp;#39;s and have done a few projects already(knowledge is a little bit outdated)&lt;/p&gt;\n\n&lt;p&gt;What would be your advice here? Should I apply for internships? Do I have to learn anything before applying or I can learn in my internship? &lt;/p&gt;\n\n&lt;p&gt;My long-term goal is becoming an ML engineer but see it as a senior role and I&amp;#39;m lacking DE skills&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1768ymf", "is_robot_indexable": true, "report_reasons": null, "author": "johnprynsky", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1768ymf/breaking_into_the_field_as_a_backend_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1768ymf/breaking_into_the_field_as_a_backend_engineer/", "subreddit_subscribers": 133821, "created_utc": 1697122679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m researching theoretical part since I\u2019m a mathematician - I really appreciate your opinion", "author_fullname": "t2_6yp3m1re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which database engineering related conference/journal is your fav &amp; why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1767uck", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697119682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m researching theoretical part since I\u2019m a mathematician - I really appreciate your opinion&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1767uck", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Beyond-1144", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1767uck/which_database_engineering_related/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1767uck/which_database_engineering_related/", "subreddit_subscribers": 133821, "created_utc": 1697119682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what should i spend 200$ on ? 199$ on yearly premium subscr-n on sql  interview questions or just do spark developer certification?", "author_fullname": "t2_e6wts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "200$ on yearly premium for data eng prep or spark cert?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_176wx1f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697197833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what should i spend 200$ on ? 199$ on yearly premium subscr-n on sql  interview questions or just do spark developer certification?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "176wx1f", "is_robot_indexable": true, "report_reasons": null, "author": "erjcan", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176wx1f/200_on_yearly_premium_for_data_eng_prep_or_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176wx1f/200_on_yearly_premium_for_data_eng_prep_or_spark/", "subreddit_subscribers": 133821, "created_utc": 1697197833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3dyum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ultimate Guide: 200+ Free Datasets for Data Science, Machine learning, AI, NLP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_176ugc8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/psAac2uk82w6tqDFuE-xQXhnyeq4ADtQtHzh4TQOzuE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697187936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bigdataanalyticsnews.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bigdataanalyticsnews.com/datasets/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mo6g6MsH4ezMt_jez90hg9OylBGm-OA3pEAfKH-yRlE.jpg?auto=webp&amp;s=53ec28897d016c0d862fddff65fd3ef33f0a83ea", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/mo6g6MsH4ezMt_jez90hg9OylBGm-OA3pEAfKH-yRlE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=feedc96585c8a837a53a0a347c16e4a9871b52be", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/mo6g6MsH4ezMt_jez90hg9OylBGm-OA3pEAfKH-yRlE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=271009c0452f81c6d9fbf42eb8f987e0b65de6a6", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/mo6g6MsH4ezMt_jez90hg9OylBGm-OA3pEAfKH-yRlE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f67782df471eda50c64747c387a87bb93ccd0e6", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/mo6g6MsH4ezMt_jez90hg9OylBGm-OA3pEAfKH-yRlE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2c0c86eb4de5d97cb769ace6100b502f0399136", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/mo6g6MsH4ezMt_jez90hg9OylBGm-OA3pEAfKH-yRlE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=25cd41166773d2dcd6549019a82768f0a7f9699a", "width": 960, "height": 960}], "variants": {}, "id": "sNRD7_-MRcoQfp8BL1rTdqBoi6ENy6krewqJaDbvrdU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "176ugc8", "is_robot_indexable": true, "report_reasons": null, "author": "Veerans", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176ugc8/ultimate_guide_200_free_datasets_for_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bigdataanalyticsnews.com/datasets/", "subreddit_subscribers": 133821, "created_utc": 1697187936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all! We just published this educational article on NVMe disks and hope you'll check it out. We're also doing a follow up post more specific to how to setup local persistent volume provisioners in AWS, GCP, DigitalOcean along with NVMe backed disks in the cloud.\n\n[https://medium.zeus.fyi/high-performance-disks-nvme-in-the-cloud-abb2bfc11fd9](https://medium.zeus.fyi/high-performance-disks-nvme-in-the-cloud-abb2bfc11fd9)", "author_fullname": "t2_tw7gr69w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "High Performance Disks: NVMe in the Cloud: How to use NVMe disks the right way before you spend $$$$", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176jwrv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697150890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! We just published this educational article on NVMe disks and hope you&amp;#39;ll check it out. We&amp;#39;re also doing a follow up post more specific to how to setup local persistent volume provisioners in AWS, GCP, DigitalOcean along with NVMe backed disks in the cloud.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.zeus.fyi/high-performance-disks-nvme-in-the-cloud-abb2bfc11fd9\"&gt;https://medium.zeus.fyi/high-performance-disks-nvme-in-the-cloud-abb2bfc11fd9&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/sxXDl7VFi-lI_dpYHYJlb-EuTcdpv95tk5Mw6OyVHik.jpg?auto=webp&amp;s=36c0567c9a21d8ccb63a917be6c95f6033b81e70", "width": 600, "height": 500}, "resolutions": [{"url": "https://external-preview.redd.it/sxXDl7VFi-lI_dpYHYJlb-EuTcdpv95tk5Mw6OyVHik.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=47fe393670ad8eba9c0966d978e1022e9c129ed1", "width": 108, "height": 90}, {"url": "https://external-preview.redd.it/sxXDl7VFi-lI_dpYHYJlb-EuTcdpv95tk5Mw6OyVHik.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8c08f88561f968ae49c3c6efa7fbf4b8ede9feff", "width": 216, "height": 180}, {"url": "https://external-preview.redd.it/sxXDl7VFi-lI_dpYHYJlb-EuTcdpv95tk5Mw6OyVHik.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d0983a4b552e2428de90ae1802eadc0fe7df34f2", "width": 320, "height": 266}], "variants": {}, "id": "4KXPZpCSo1gXU8nhM9yH0lVkSwK8CN_B9zws8kWaMt8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "176jwrv", "is_robot_indexable": true, "report_reasons": null, "author": "zeus-fyi", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176jwrv/high_performance_disks_nvme_in_the_cloud_how_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176jwrv/high_performance_disks_nvme_in_the_cloud_how_to/", "subreddit_subscribers": 133821, "created_utc": 1697150890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, so I wanted to ask is this syllabus good for learning DE and hopefully lead to jobs or do I need to add something to it ? Please so share your thoughts, thanks\n\n\nYou will build two different projects that will help you learn the basic and advanced concepts of Python, and other industry relevant tools such as the command line and version control tools, such as git and GitHub. In the first project you will create a command line assistant that helps you process multiple entries from IMDB. In the second project you build an implementation of the Hangman game using object oriented programming in Python.\n\n\nData Engineering\n\nLearn how to store, share and process various types of data at scale.\n\nBuild a complete data solution for a multinational organisation, from data acquisition to analysis . Write Python code to extract large datasets from multiple data sources. Utilise the power of Pandas to clean and analyse the data. Build a STAR based database schema for optimised data storage and access. Perform complex SQL data queries to extract valuable insights and make informed decisions for the organisation.\n\nBuild Pinterest's experiment analytics data pipeline which runs thousands of experiments per day and crunches billions of datapoints to provide valuable insights to improve the product.\n\nModule 1: Data Formats and Processing Libraries\nJSON, CSV, XLSX and YAML\nTabular Data\nPandas Dataframes\nAdvanced Dataframe Operations\nData Cleaning in Pandas\nNumpy\nMissing Data\n\nModule 2: Web APIs\nBasics of APIs and Communication Protocols\nWorking with API Requests\nFastAPI \nRouting with FastAPI\nSending Data to FastAPI\n\nModule 3: SQL\nWhat is SQL?\nSQL Setup\nSQL Tools Setup\nSQL Commands\nSQL best practices\nSELECT and Sorting\nThe WHERE Clause\nCRUD Creating Tables\nCRUD Altering Tables\nSQL JOINs\nSQL JOIN Types\nSQL Common Aggregations\nSQL GROUP BY\nCreating Subqueries\nTypes of Subqueries\nCRUD Subquery Operations\nCommon Table Expressions (CTEs)\npyscopg2 and SQLAlchemy\n\nModule 4: Essential Cloud Technology\nWhat is the Cloud\nEssential Cloud Concepts\nAWS Identity and Access Management\nAWS CLI\nIntroduction to Amazon S3\nS3 Objects and boto3\nAmazon EC2\nVirtual Private Cloud\nIAM Roles\nAmazon RDS\nBilling in AWS\n\nModule 5: Big Data Engineering Foundations\nThe Data Engineering Landscape \nData Pipelines\nData Ingestion and Data Storage\nEnterprise Data Warehouses\nBatch vs Real-Time Processing\nStructured, Unstructured and Complex Data\n\nModule 6: Data Ingestion\nPrinciples of Data Ingestion\nBatch Processing\nReal-Time Data Processing\nKafka Essentials\nKafka-Python\nStreaming in Kafka\n\nModule 7: Data wrangling and transformation\nData Transformations: ELT &amp; ETL\nApache Spark and Pyspark\nDistributed Processing with Spark\nIntegrating Spark &amp; Kafka\nIntegrating Spark &amp; AWS S3\nSpark Streaming\n\nModule 8: Data Orchestration\nApache Airflow\nIntegrating Airflow &amp; Spark\nModule 9: Advanced Cloud Technologies and Databricks\nMSK and MSK Connect\nAWS API Gateway\nIntegrating API Gateway with Kafka\nDatabricks Essentials\nIntegrating Databricks with Amazon S3\nAWS MWAA\nOrchestrating Databricks Workloads on MWAA\nAWS Kinesis\nIntegrating Databricks with AWS Kinesis\nIntegrating API Gateway with Kinesis", "author_fullname": "t2_4jsiips8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this syllabus good to learn DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176w8lf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697195333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, so I wanted to ask is this syllabus good for learning DE and hopefully lead to jobs or do I need to add something to it ? Please so share your thoughts, thanks&lt;/p&gt;\n\n&lt;p&gt;You will build two different projects that will help you learn the basic and advanced concepts of Python, and other industry relevant tools such as the command line and version control tools, such as git and GitHub. In the first project you will create a command line assistant that helps you process multiple entries from IMDB. In the second project you build an implementation of the Hangman game using object oriented programming in Python.&lt;/p&gt;\n\n&lt;p&gt;Data Engineering&lt;/p&gt;\n\n&lt;p&gt;Learn how to store, share and process various types of data at scale.&lt;/p&gt;\n\n&lt;p&gt;Build a complete data solution for a multinational organisation, from data acquisition to analysis . Write Python code to extract large datasets from multiple data sources. Utilise the power of Pandas to clean and analyse the data. Build a STAR based database schema for optimised data storage and access. Perform complex SQL data queries to extract valuable insights and make informed decisions for the organisation.&lt;/p&gt;\n\n&lt;p&gt;Build Pinterest&amp;#39;s experiment analytics data pipeline which runs thousands of experiments per day and crunches billions of datapoints to provide valuable insights to improve the product.&lt;/p&gt;\n\n&lt;p&gt;Module 1: Data Formats and Processing Libraries\nJSON, CSV, XLSX and YAML\nTabular Data\nPandas Dataframes\nAdvanced Dataframe Operations\nData Cleaning in Pandas\nNumpy\nMissing Data&lt;/p&gt;\n\n&lt;p&gt;Module 2: Web APIs\nBasics of APIs and Communication Protocols\nWorking with API Requests\nFastAPI \nRouting with FastAPI\nSending Data to FastAPI&lt;/p&gt;\n\n&lt;p&gt;Module 3: SQL\nWhat is SQL?\nSQL Setup\nSQL Tools Setup\nSQL Commands\nSQL best practices\nSELECT and Sorting\nThe WHERE Clause\nCRUD Creating Tables\nCRUD Altering Tables\nSQL JOINs\nSQL JOIN Types\nSQL Common Aggregations\nSQL GROUP BY\nCreating Subqueries\nTypes of Subqueries\nCRUD Subquery Operations\nCommon Table Expressions (CTEs)\npyscopg2 and SQLAlchemy&lt;/p&gt;\n\n&lt;p&gt;Module 4: Essential Cloud Technology\nWhat is the Cloud\nEssential Cloud Concepts\nAWS Identity and Access Management\nAWS CLI\nIntroduction to Amazon S3\nS3 Objects and boto3\nAmazon EC2\nVirtual Private Cloud\nIAM Roles\nAmazon RDS\nBilling in AWS&lt;/p&gt;\n\n&lt;p&gt;Module 5: Big Data Engineering Foundations\nThe Data Engineering Landscape \nData Pipelines\nData Ingestion and Data Storage\nEnterprise Data Warehouses\nBatch vs Real-Time Processing\nStructured, Unstructured and Complex Data&lt;/p&gt;\n\n&lt;p&gt;Module 6: Data Ingestion\nPrinciples of Data Ingestion\nBatch Processing\nReal-Time Data Processing\nKafka Essentials\nKafka-Python\nStreaming in Kafka&lt;/p&gt;\n\n&lt;p&gt;Module 7: Data wrangling and transformation\nData Transformations: ELT &amp;amp; ETL\nApache Spark and Pyspark\nDistributed Processing with Spark\nIntegrating Spark &amp;amp; Kafka\nIntegrating Spark &amp;amp; AWS S3\nSpark Streaming&lt;/p&gt;\n\n&lt;p&gt;Module 8: Data Orchestration\nApache Airflow\nIntegrating Airflow &amp;amp; Spark\nModule 9: Advanced Cloud Technologies and Databricks\nMSK and MSK Connect\nAWS API Gateway\nIntegrating API Gateway with Kafka\nDatabricks Essentials\nIntegrating Databricks with Amazon S3\nAWS MWAA\nOrchestrating Databricks Workloads on MWAA\nAWS Kinesis\nIntegrating Databricks with AWS Kinesis\nIntegrating API Gateway with Kinesis&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176w8lf", "is_robot_indexable": true, "report_reasons": null, "author": "saqi786x", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176w8lf/is_this_syllabus_good_to_learn_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176w8lf/is_this_syllabus_good_to_learn_de/", "subreddit_subscribers": 133821, "created_utc": 1697195333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lazy ass here... Is there any dbt package that allows  querying all the models the same way INFORMATION\\_SCHEMA.COLUMNS in SQL Server/PG/BigQuery allows us to? Sometimes I just need a list of all columns in a model or maybe I want to find in which models a specific columns was defined (without going to BigQuery, of course it's possible there)", "author_fullname": "t2_12p79", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt package allowing to query models metadata?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176jhgy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697149724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lazy ass here... Is there any dbt package that allows  querying all the models the same way INFORMATION_SCHEMA.COLUMNS in SQL Server/PG/BigQuery allows us to? Sometimes I just need a list of all columns in a model or maybe I want to find in which models a specific columns was defined (without going to BigQuery, of course it&amp;#39;s possible there)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "176jhgy", "is_robot_indexable": true, "report_reasons": null, "author": "virgilash", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176jhgy/dbt_package_allowing_to_query_models_metadata/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176jhgy/dbt_package_allowing_to_query_models_metadata/", "subreddit_subscribers": 133821, "created_utc": 1697149724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone have any resources for SQL and database concepts to develop curriculum for \u201cbrown bag\u201d lunches to teach business units these concepts?\n\nNot looking for technical depth, just some workbooks or materials I can put on my Corp card and handout to any staff that want to attend and learn a bit more about databases and data literacy. \n\nBasically just planning brown bag sessions to go over data stuff in my org. We are terribly lacking in data literacy and database use skills at even the most rudimentary levels. Target audience are non technical business users.", "author_fullname": "t2_d5gr1nxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL and Relational Database Curriculum for teaching others", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176eqwb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697137627.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have any resources for SQL and database concepts to develop curriculum for \u201cbrown bag\u201d lunches to teach business units these concepts?&lt;/p&gt;\n\n&lt;p&gt;Not looking for technical depth, just some workbooks or materials I can put on my Corp card and handout to any staff that want to attend and learn a bit more about databases and data literacy. &lt;/p&gt;\n\n&lt;p&gt;Basically just planning brown bag sessions to go over data stuff in my org. We are terribly lacking in data literacy and database use skills at even the most rudimentary levels. Target audience are non technical business users.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "176eqwb", "is_robot_indexable": true, "report_reasons": null, "author": "renok_archnmy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176eqwb/sql_and_relational_database_curriculum_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176eqwb/sql_and_relational_database_curriculum_for/", "subreddit_subscribers": 133821, "created_utc": 1697137627.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm using MySQL as a database and data warehouse. Weird, I know, but it mostly works for our small team and use cases. We're currently scheduling our MySQL jobs with a low code tool, which has never been ideal, but has become untenable because the complexity of our data model has grown.\n\nI've been testing out DBT Core (v1.1.5 + MySQL plugin v1.1.0) and it is working well in our MySQL db but DBT Cloud doesn't support it.\n\nI need a better solution  for searchability, scheduling, dependency tracking, and testing. I'm willing the replace DBT or host it elsewhere. I'm willing to consider migrating databases as a last resort, but hoping for an easier solution. My goal is to minimize complexity and tool sprawl. What should I consider? \n\nThanks!", "author_fullname": "t2_aindslqn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT alternative for MySQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17688yu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697120770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using MySQL as a database and data warehouse. Weird, I know, but it mostly works for our small team and use cases. We&amp;#39;re currently scheduling our MySQL jobs with a low code tool, which has never been ideal, but has become untenable because the complexity of our data model has grown.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been testing out DBT Core (v1.1.5 + MySQL plugin v1.1.0) and it is working well in our MySQL db but DBT Cloud doesn&amp;#39;t support it.&lt;/p&gt;\n\n&lt;p&gt;I need a better solution  for searchability, scheduling, dependency tracking, and testing. I&amp;#39;m willing the replace DBT or host it elsewhere. I&amp;#39;m willing to consider migrating databases as a last resort, but hoping for an easier solution. My goal is to minimize complexity and tool sprawl. What should I consider? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17688yu", "is_robot_indexable": true, "report_reasons": null, "author": "Wide_Interest_5887", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17688yu/dbt_alternative_for_mysql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17688yu/dbt_alternative_for_mysql/", "subreddit_subscribers": 133821, "created_utc": 1697120770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I read this in the book Designing Data-Intensive Applications: \"The sort merge in Unix is arguably a better sorting implementation than most programming languages have in their standard libraries (which do not spill to disk and do not use multiple threads)\".   \n\nI know Unix uses external sorting to spill to disk, but what does it mean that other libraries \"do not spill to disk\"? Like, if the dataset is large enough (like 2 TB) and can't fit into memory, how could they not spill to disk? Or am I understanding this wrong? Thanks.", "author_fullname": "t2_szomhuik", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External Sort I/O in Unix v.s. in Other Libraries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176837s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697120348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read this in the book Designing Data-Intensive Applications: &amp;quot;The sort merge in Unix is arguably a better sorting implementation than most programming languages have in their standard libraries (which do not spill to disk and do not use multiple threads)&amp;quot;.   &lt;/p&gt;\n\n&lt;p&gt;I know Unix uses external sorting to spill to disk, but what does it mean that other libraries &amp;quot;do not spill to disk&amp;quot;? Like, if the dataset is large enough (like 2 TB) and can&amp;#39;t fit into memory, how could they not spill to disk? Or am I understanding this wrong? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176837s", "is_robot_indexable": true, "report_reasons": null, "author": "TendMyOwnGarden", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176837s/external_sort_io_in_unix_vs_in_other_libraries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176837s/external_sort_io_in_unix_vs_in_other_libraries/", "subreddit_subscribers": 133821, "created_utc": 1697120348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, first post here.\n\nI've seen a few ads for Weld which piqued my interest. Has anyone actually used it in anger for commercial workloads? I'm hoping someone can share some feedback on what it's like.\n\nI searched the sub but found nothing but a lone comment...\n\nhttps://weld.app/\nhttps://www.crunchbase.com/organization/weld", "author_fullname": "t2_eclsdgax6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Weld before?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1766xhh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697117088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, first post here.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen a few ads for Weld which piqued my interest. Has anyone actually used it in anger for commercial workloads? I&amp;#39;m hoping someone can share some feedback on what it&amp;#39;s like.&lt;/p&gt;\n\n&lt;p&gt;I searched the sub but found nothing but a lone comment...&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://weld.app/\"&gt;https://weld.app/&lt;/a&gt;\n&lt;a href=\"https://www.crunchbase.com/organization/weld\"&gt;https://www.crunchbase.com/organization/weld&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1766xhh", "is_robot_indexable": true, "report_reasons": null, "author": "Silent_Ocelot3368", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1766xhh/has_anyone_used_weld_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1766xhh/has_anyone_used_weld_before/", "subreddit_subscribers": 133821, "created_utc": 1697117088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "PostgreSQL locks can cause issues in partitioned tables. Check out this blog on how TimescaleDB solves this using lock minimization strategies.  \n[https://www.timescale.com/blog/how-timescaledb-solves-common-postgresql-problems-in-database-operations-with-data-retention-management/](https://www.timescale.com/blog/how-timescaledb-solves-common-postgresql-problems-in-database-operations-with-data-retention-management/)", "author_fullname": "t2_kbw1spf0g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Problem With Locks And PostgreSQL Partitioning (And How To Actually Fix It)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176ggae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697142159.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;PostgreSQL locks can cause issues in partitioned tables. Check out this blog on how TimescaleDB solves this using lock minimization strategies.&lt;br/&gt;\n&lt;a href=\"https://www.timescale.com/blog/how-timescaledb-solves-common-postgresql-problems-in-database-operations-with-data-retention-management/\"&gt;https://www.timescale.com/blog/how-timescaledb-solves-common-postgresql-problems-in-database-operations-with-data-retention-management/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/PWwlApG-EtsRRPcByM4Q1RsbouPflZsrIxKnqFrtjaM.jpg?auto=webp&amp;s=023f5816074f4ecccf9d27a7f778b8f13b979a21", "width": 1336, "height": 718}, "resolutions": [{"url": "https://external-preview.redd.it/PWwlApG-EtsRRPcByM4Q1RsbouPflZsrIxKnqFrtjaM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=156b286e6b9190eb88175e515d24c5b4215b0f47", "width": 108, "height": 58}, {"url": "https://external-preview.redd.it/PWwlApG-EtsRRPcByM4Q1RsbouPflZsrIxKnqFrtjaM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1be892d7639c68edcefe04a383a63a705390faae", "width": 216, "height": 116}, {"url": "https://external-preview.redd.it/PWwlApG-EtsRRPcByM4Q1RsbouPflZsrIxKnqFrtjaM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ca1da345bb57ca074aca0ce9c8b959c12ff419c2", "width": 320, "height": 171}, {"url": "https://external-preview.redd.it/PWwlApG-EtsRRPcByM4Q1RsbouPflZsrIxKnqFrtjaM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=81f21d1b149e3eb45c44737e8af629ec5963bf91", "width": 640, "height": 343}, {"url": "https://external-preview.redd.it/PWwlApG-EtsRRPcByM4Q1RsbouPflZsrIxKnqFrtjaM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0e342c2c43f386292d440ca6b90731d4d7ded54e", "width": 960, "height": 515}, {"url": "https://external-preview.redd.it/PWwlApG-EtsRRPcByM4Q1RsbouPflZsrIxKnqFrtjaM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=85bb92d17610f68e2a90daa16fc1bd725163975b", "width": 1080, "height": 580}], "variants": {}, "id": "j-yRKfJXSdBpWIH10CnRfZUbQemUTLQpU0xdNN7UAx8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "176ggae", "is_robot_indexable": true, "report_reasons": null, "author": "leeshyan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176ggae/the_problem_with_locks_and_postgresql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176ggae/the_problem_with_locks_and_postgresql/", "subreddit_subscribers": 133821, "created_utc": 1697142159.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Can someone please share best data engineer resume format?", "author_fullname": "t2_ceh8gejs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer resume?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_176xs9i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697200692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone please share best data engineer resume format?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "176xs9i", "is_robot_indexable": true, "report_reasons": null, "author": "ashuhimself", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176xs9i/data_engineer_resume/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176xs9i/data_engineer_resume/", "subreddit_subscribers": 133821, "created_utc": 1697200692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_71x5sgab1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data transformation startup Prophecy.io lands $35M investment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 88, "top_awarded_type": null, "hide_score": false, "name": "t3_176js4y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OG8WSf0CVP2FGoonCrdxbPcIex1xwl4V6YnkEYzxFrA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697150539.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "techcrunch.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://techcrunch.com/2023/10/11/data-transformation-startup-prophecy-lands-35m-investment/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KY8hN4WYK-4tVe3R6o3jpFHdTBiWxRnb9GfHtUSxsbw.jpg?auto=webp&amp;s=826b21558ea31ded29be19ed310abba5481002aa", "width": 1200, "height": 755}, "resolutions": [{"url": "https://external-preview.redd.it/KY8hN4WYK-4tVe3R6o3jpFHdTBiWxRnb9GfHtUSxsbw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=80b2e2378fdb09597f156446e7aced1ae0b95f84", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/KY8hN4WYK-4tVe3R6o3jpFHdTBiWxRnb9GfHtUSxsbw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ec4a3c716eef5b365463e0a89f86efdaec996382", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/KY8hN4WYK-4tVe3R6o3jpFHdTBiWxRnb9GfHtUSxsbw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=597ca8df04000b5befddca420ab991ca04c45072", "width": 320, "height": 201}, {"url": "https://external-preview.redd.it/KY8hN4WYK-4tVe3R6o3jpFHdTBiWxRnb9GfHtUSxsbw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=526566ec4d8e85599ea9596cab3bbf7f30612191", "width": 640, "height": 402}, {"url": "https://external-preview.redd.it/KY8hN4WYK-4tVe3R6o3jpFHdTBiWxRnb9GfHtUSxsbw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f1ea12693950fe842aa09d167383dd2e42ef8063", "width": 960, "height": 604}, {"url": "https://external-preview.redd.it/KY8hN4WYK-4tVe3R6o3jpFHdTBiWxRnb9GfHtUSxsbw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0465cdcb1c8415c9d96f841ae2543016e15803eb", "width": 1080, "height": 679}], "variants": {}, "id": "vAlw9EaELcUSG2t8ds6RfsE0tSIC2nbKtTkFukwsOAE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "176js4y", "is_robot_indexable": true, "report_reasons": null, "author": "prophecyleppo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176js4y/data_transformation_startup_prophecyio_lands_35m/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://techcrunch.com/2023/10/11/data-transformation-startup-prophecy-lands-35m-investment/", "subreddit_subscribers": 133821, "created_utc": 1697150539.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}