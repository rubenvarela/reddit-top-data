{"kind": "Listing", "data": {"after": "t3_1767bi1", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " If you were presented with such an offer for a remote position, would you accept it? Is there a risk of legal consequences if you were discovered? ", "author_fullname": "t2_5fbmh3va", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How ballsy do you have to be to take on the role of Senior Data Scientist at both McDonald's and Burger King simultaneously (remote)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17666j9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697114881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you were presented with such an offer for a remote position, would you accept it? Is there a risk of legal consequences if you were discovered? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17666j9", "is_robot_indexable": true, "report_reasons": null, "author": "Excellent_Cost170", "discussion_type": null, "num_comments": 66, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17666j9/how_ballsy_do_you_have_to_be_to_take_on_the_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17666j9/how_ballsy_do_you_have_to_be_to_take_on_the_role/", "subreddit_subscribers": 1081721, "created_utc": 1697114881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let\u2019s say you get an ad hoc task that will take an hour or two. You run an sql query extract the data from the db dump into .csv spin up a quick Jupyter notebook and be done with it. But what happens after?\n\n\nHow would you store/archive this project?\nCommitting Jupyter notebooks to a repo? Now you have bunch of html in your codebase. Code that\u2019s impossible to pull request/review that also bloats the repo. If you clear the outputs of the notebook to reduce the notebook size it instantly becomes useless for later review because now you have to run it again to see what was it about. If you need to run it again you need the exact same data. Now you need to store the data snippet somewhere. Where do you store that data snipped for future reproducibility? The project is too small to spin up DVC or MLFlow so what do you do with it?\n\nWhat tool / workflow am I missing here?\n\nI keep hearning notebooks are great for experiments but I don\u2019t see what the workflow is like for these experiments\u2026\n\nEDIT: Based on the responses there is no solution to any of this chaos that covers both the code and the data... you either end up over-engineering the experiment or dumping it somewhere and hoping that a well written readme will do the job.  There has to be a better way..", "author_fullname": "t2_13hucc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you store your ad hoc experiments?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175jep1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 47, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 47, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697083575.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697044442.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s say you get an ad hoc task that will take an hour or two. You run an sql query extract the data from the db dump into .csv spin up a quick Jupyter notebook and be done with it. But what happens after?&lt;/p&gt;\n\n&lt;p&gt;How would you store/archive this project?\nCommitting Jupyter notebooks to a repo? Now you have bunch of html in your codebase. Code that\u2019s impossible to pull request/review that also bloats the repo. If you clear the outputs of the notebook to reduce the notebook size it instantly becomes useless for later review because now you have to run it again to see what was it about. If you need to run it again you need the exact same data. Now you need to store the data snippet somewhere. Where do you store that data snipped for future reproducibility? The project is too small to spin up DVC or MLFlow so what do you do with it?&lt;/p&gt;\n\n&lt;p&gt;What tool / workflow am I missing here?&lt;/p&gt;\n\n&lt;p&gt;I keep hearning notebooks are great for experiments but I don\u2019t see what the workflow is like for these experiments\u2026&lt;/p&gt;\n\n&lt;p&gt;EDIT: Based on the responses there is no solution to any of this chaos that covers both the code and the data... you either end up over-engineering the experiment or dumping it somewhere and hoping that a well written readme will do the job.  There has to be a better way..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175jep1", "is_robot_indexable": true, "report_reasons": null, "author": "every_other_freackle", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175jep1/how_do_you_store_your_ad_hoc_experiments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175jep1/how_do_you_store_your_ad_hoc_experiments/", "subreddit_subscribers": 1081721, "created_utc": 1697044442.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_b3hvfhlp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you were starting over again, How would you go about getting a Data Science job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1763k33", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697105924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1763k33", "is_robot_indexable": true, "report_reasons": null, "author": "Exotic_Avocado6164", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1763k33/if_you_were_starting_over_again_how_would_you_go/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1763k33/if_you_were_starting_over_again_how_would_you_go/", "subreddit_subscribers": 1081721, "created_utc": 1697105924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI am hired by a government based organization to work as a data scientist. I currently have 1 year of full time experience and 2 years part time before graduation. My project is ending in about 2 months and I have a budget of around \u00a35,000 that I can use for personal and professional development. I have to complete the bookings before the end of the project, although actual training/conference can take place beyond the end date. \n\nWorking in an applied research role, I can spend it on conferences, for training opportunities or certification exams. I want to ask you guys for your opinions about what would be good things to spend this budget on, considering I am at an early stage in my career. ", "author_fullname": "t2_caxt5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to spend \u00a35k budget for professional development in Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175ptfa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697060557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am hired by a government based organization to work as a data scientist. I currently have 1 year of full time experience and 2 years part time before graduation. My project is ending in about 2 months and I have a budget of around \u00a35,000 that I can use for personal and professional development. I have to complete the bookings before the end of the project, although actual training/conference can take place beyond the end date. &lt;/p&gt;\n\n&lt;p&gt;Working in an applied research role, I can spend it on conferences, for training opportunities or certification exams. I want to ask you guys for your opinions about what would be good things to spend this budget on, considering I am at an early stage in my career. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175ptfa", "is_robot_indexable": true, "report_reasons": null, "author": "greathassan", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175ptfa/where_to_spend_5k_budget_for_professional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175ptfa/where_to_spend_5k_budget_for_professional/", "subreddit_subscribers": 1081721, "created_utc": 1697060557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a PhD in biology and my next step in the pipeline is a bioinformatics post doc while studying for a DS course (IBM Data Science Professionnal Certificate) on the side.\n\nI know certificates have become insufficient to get an entry level jobs in Data Science (and tech in general) now that the market has cooled down from the pandemic craze, but I was wondering if having an advanced degree in another field and minor experience from my post doc (mostly specific data analysis tools for bioinformatics, a lot of R, and probably very minimal Python) would really be helpful or if companies don't care about non-CS scientific education ?\n\nWhat about getting an online MS in Data Science, would that be required ? How difficult would that be for someone with a weak background in statistics ?\n\nI'm interested in Data Science and I'm looking to expand my skills to give myself more options but while the certificate is short and could be useful as a biotech scientist, I wouldn't want to pursue more formal education if it doesn't really give me more options other than a false hope and wasted time applying for DS positions I can't get.", "author_fullname": "t2_pxn8nina", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any value to an unrelated advanced degree to get into DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175nbtg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697054404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a PhD in biology and my next step in the pipeline is a bioinformatics post doc while studying for a DS course (IBM Data Science Professionnal Certificate) on the side.&lt;/p&gt;\n\n&lt;p&gt;I know certificates have become insufficient to get an entry level jobs in Data Science (and tech in general) now that the market has cooled down from the pandemic craze, but I was wondering if having an advanced degree in another field and minor experience from my post doc (mostly specific data analysis tools for bioinformatics, a lot of R, and probably very minimal Python) would really be helpful or if companies don&amp;#39;t care about non-CS scientific education ?&lt;/p&gt;\n\n&lt;p&gt;What about getting an online MS in Data Science, would that be required ? How difficult would that be for someone with a weak background in statistics ?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in Data Science and I&amp;#39;m looking to expand my skills to give myself more options but while the certificate is short and could be useful as a biotech scientist, I wouldn&amp;#39;t want to pursue more formal education if it doesn&amp;#39;t really give me more options other than a false hope and wasted time applying for DS positions I can&amp;#39;t get.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175nbtg", "is_robot_indexable": true, "report_reasons": null, "author": "childofaether", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175nbtg/any_value_to_an_unrelated_advanced_degree_to_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175nbtg/any_value_to_an_unrelated_advanced_degree_to_get/", "subreddit_subscribers": 1081721, "created_utc": 1697054404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://github.com/jinyus/related\\_post\\_gen](https://github.com/jinyus/related_post_gen)\n\nhttps://preview.redd.it/ii0dm13dymtb1.png?width=849&amp;format=png&amp;auto=webp&amp;s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f", "author_fullname": "t2_6dtot6beo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Julia leads Rust, Zig, Go and Java in data processing benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ii0dm13dymtb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 111, "x": 108, "u": "https://preview.redd.it/ii0dm13dymtb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=29389ec319b46acce2f70256fb514f3b12ac60af"}, {"y": 223, "x": 216, "u": "https://preview.redd.it/ii0dm13dymtb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=edef1a8be72ea4a5076387fd93b5a248f708a697"}, {"y": 331, "x": 320, "u": "https://preview.redd.it/ii0dm13dymtb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c3945a0f9a2a5d58f5286afb0c20ee19e015e331"}, {"y": 663, "x": 640, "u": "https://preview.redd.it/ii0dm13dymtb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=04f3394bfbd28c4fab37f8d5091932b4e8a4c804"}], "s": {"y": 880, "x": 849, "u": "https://preview.redd.it/ii0dm13dymtb1.png?width=849&amp;format=png&amp;auto=webp&amp;s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f"}, "id": "ii0dm13dymtb1"}}, "name": "t3_175oh0k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/W2Naxk_8dd2GS0UHXIBaEkjm_3OxA5-KTZjS66eWAIs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697057221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/jinyus/related_post_gen\"&gt;https://github.com/jinyus/related_post_gen&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ii0dm13dymtb1.png?width=849&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f\"&gt;https://preview.redd.it/ii0dm13dymtb1.png?width=849&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175oh0k", "is_robot_indexable": true, "report_reasons": null, "author": "Fincho64", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175oh0k/julia_leads_rust_zig_go_and_java_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175oh0k/julia_leads_rust_zig_go_and_java_in_data/", "subreddit_subscribers": 1081721, "created_utc": 1697057221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been working as a \"Data Scientist\" for a little over 2 years but in my company I'm primarily tasked with developing MVPs with the company's  AI technology for potential clients. Most of the coding we do is setting up API calls, setting up environments, and connecting the different parts of the company's technology. I loathe this. Many calls people are sharing their screen showing this API call code and I absolutely cannot focus for the life of me. Mentally, I feel a huge friction/resistance to setting up a coding environment. \n\nIn school, I took Mechanical Engineering and I was a pro making code to model engineering stuff and my programming logic was solid. I was the top of the class. But this environment set up stuff and API stuff just drives me insane.\n\nI'm trying to figure out if the problem is with this role or if I just am better off in a non-coding role, like product management?", "author_fullname": "t2_8cg2z0mf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coding sometimes scares me. Is this the wrong field for me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1769ler", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697124321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working as a &amp;quot;Data Scientist&amp;quot; for a little over 2 years but in my company I&amp;#39;m primarily tasked with developing MVPs with the company&amp;#39;s  AI technology for potential clients. Most of the coding we do is setting up API calls, setting up environments, and connecting the different parts of the company&amp;#39;s technology. I loathe this. Many calls people are sharing their screen showing this API call code and I absolutely cannot focus for the life of me. Mentally, I feel a huge friction/resistance to setting up a coding environment. &lt;/p&gt;\n\n&lt;p&gt;In school, I took Mechanical Engineering and I was a pro making code to model engineering stuff and my programming logic was solid. I was the top of the class. But this environment set up stuff and API stuff just drives me insane.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out if the problem is with this role or if I just am better off in a non-coding role, like product management?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1769ler", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate_Ebb3623", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1769ler/coding_sometimes_scares_me_is_this_the_wrong/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1769ler/coding_sometimes_scares_me_is_this_the_wrong/", "subreddit_subscribers": 1081721, "created_utc": 1697124321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, I\u2019m writing this post hoping to get some advice from everyone. I\u2019m studying for a Master's degree in Data Science and conducting scientific research to publish a paper in a conference or journal. My mentors are very supportive and kind. Currently, we have selected an already published paper to build upon. I've completed all the research, read many relevant papers, and my mentors have already provided guidance on how to proceed.\n\nHowever, in addition to their suggestions, they want me to identify other weaknesses in the paper and find solutions. I'm stuck at this stage; one month has passed, and I haven't been able to discover anything new beyond what they have pointed out. I'm really worried that I might disappoint my mentors, as they've been exceptionally good and supportive to me. Am I overthinking the situation? What should I do to uncover the weaknesses of the proposed method? I'm afraid that I might be slowing down the whole team :(", "author_fullname": "t2_ctixwjk2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I feel like I\u2019m stuck with my scientific research", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1769vr7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697125064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I\u2019m writing this post hoping to get some advice from everyone. I\u2019m studying for a Master&amp;#39;s degree in Data Science and conducting scientific research to publish a paper in a conference or journal. My mentors are very supportive and kind. Currently, we have selected an already published paper to build upon. I&amp;#39;ve completed all the research, read many relevant papers, and my mentors have already provided guidance on how to proceed.&lt;/p&gt;\n\n&lt;p&gt;However, in addition to their suggestions, they want me to identify other weaknesses in the paper and find solutions. I&amp;#39;m stuck at this stage; one month has passed, and I haven&amp;#39;t been able to discover anything new beyond what they have pointed out. I&amp;#39;m really worried that I might disappoint my mentors, as they&amp;#39;ve been exceptionally good and supportive to me. Am I overthinking the situation? What should I do to uncover the weaknesses of the proposed method? I&amp;#39;m afraid that I might be slowing down the whole team :(&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1769vr7", "is_robot_indexable": true, "report_reasons": null, "author": "ma-d-ghost", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1769vr7/i_feel_like_im_stuck_with_my_scientific_research/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1769vr7/i_feel_like_im_stuck_with_my_scientific_research/", "subreddit_subscribers": 1081721, "created_utc": 1697125064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "    df.drop_duplicates()\n\n&amp;#x200B;", "author_fullname": "t2_7xuzntim", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When your clients won't provide insight or feedback on why there are 4 different rows with the same unique ID...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1769ozf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Fun/Trivia", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697124584.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;pre&gt;&lt;code&gt;df.drop_duplicates()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1769ozf", "is_robot_indexable": true, "report_reasons": null, "author": "Loose_Read_9400", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1769ozf/when_your_clients_wont_provide_insight_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1769ozf/when_your_clients_wont_provide_insight_or/", "subreddit_subscribers": 1081721, "created_utc": 1697124584.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a mathematical education and programming experience, but I have not done data science in the wild. I have a situation at work that could be an opportunity to practice model-building. \n\nI work on a team of \\~50 developers, and we have a subjective belief that some tickets stay in code review much longer than others. I can get the duration of a merge request using the Gitlab API, and I can get information about the tickets from exporting issues from Jira. \n\nI think there's a chance that some of the columns in our Jira data are good predictors of the duration, thanks to how we label issues. But it might also be the case that the title/description are natural language predictors of the duration, and so I might need to figure out how to do a text embedding or bag-of-words model as a preprocessing step.\n\nWhen you have one value (duration) that you're trying to make predictions about, but you don't have any a priori guesses about what columns are going to be predictive, what tools do you reach for? Is this a good task to learn TensorFlow for perhaps, or is there something less powerful/complex in the ML ecosystem I should look at first?", "author_fullname": "t2_c9pbqokh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predicting what features lead to long wait times", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175qvkx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697063226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a mathematical education and programming experience, but I have not done data science in the wild. I have a situation at work that could be an opportunity to practice model-building. &lt;/p&gt;\n\n&lt;p&gt;I work on a team of ~50 developers, and we have a subjective belief that some tickets stay in code review much longer than others. I can get the duration of a merge request using the Gitlab API, and I can get information about the tickets from exporting issues from Jira. &lt;/p&gt;\n\n&lt;p&gt;I think there&amp;#39;s a chance that some of the columns in our Jira data are good predictors of the duration, thanks to how we label issues. But it might also be the case that the title/description are natural language predictors of the duration, and so I might need to figure out how to do a text embedding or bag-of-words model as a preprocessing step.&lt;/p&gt;\n\n&lt;p&gt;When you have one value (duration) that you&amp;#39;re trying to make predictions about, but you don&amp;#39;t have any a priori guesses about what columns are going to be predictive, what tools do you reach for? Is this a good task to learn TensorFlow for perhaps, or is there something less powerful/complex in the ML ecosystem I should look at first?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175qvkx", "is_robot_indexable": true, "report_reasons": null, "author": "Bulky_Gap_7072", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175qvkx/predicting_what_features_lead_to_long_wait_times/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175qvkx/predicting_what_features_lead_to_long_wait_times/", "subreddit_subscribers": 1081721, "created_utc": 1697063226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for a pretty big Aerospace manufacturing company where my job title is 'Digital Engineer'. What this actually is, is a mix of data analytics and software engineering in PHP and C#. However, quite a lot of my work revolves around the transfer of Excel-based operations throughout the company to more efficient mediums. I can't disclose specifics about my current project but it involves producing a web form for our engineers to log parts into, and a big part of this project is scanning through the old Excel sheets looking for, and removing duplicate entries.\n\nI would of course like to use Python's Pandas/Polars libraries to automate a lot of my work, but due to the high-security nature of my work, I cannot pip install any packages or install most open source software.\n\nMy question is, can I automate much of my project work with a standard installation of Python or SQL Server? We also use some corporate standard software called Thingworx, but I haven't really been exposed to it yet.", "author_fullname": "t2_c4tdx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Security measures at my workplace", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175q00o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697061027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a pretty big Aerospace manufacturing company where my job title is &amp;#39;Digital Engineer&amp;#39;. What this actually is, is a mix of data analytics and software engineering in PHP and C#. However, quite a lot of my work revolves around the transfer of Excel-based operations throughout the company to more efficient mediums. I can&amp;#39;t disclose specifics about my current project but it involves producing a web form for our engineers to log parts into, and a big part of this project is scanning through the old Excel sheets looking for, and removing duplicate entries.&lt;/p&gt;\n\n&lt;p&gt;I would of course like to use Python&amp;#39;s Pandas/Polars libraries to automate a lot of my work, but due to the high-security nature of my work, I cannot pip install any packages or install most open source software.&lt;/p&gt;\n\n&lt;p&gt;My question is, can I automate much of my project work with a standard installation of Python or SQL Server? We also use some corporate standard software called Thingworx, but I haven&amp;#39;t really been exposed to it yet.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175q00o", "is_robot_indexable": true, "report_reasons": null, "author": "EncryptedMyst", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175q00o/security_measures_at_my_workplace/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175q00o/security_measures_at_my_workplace/", "subreddit_subscribers": 1081721, "created_utc": 1697061027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What's the most creative exit or pivot you have done (or seen others do) after being a DS for some time?", "author_fullname": "t2_7zmoi25a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DS exits or pivots", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1769fk8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697123889.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s the most creative exit or pivot you have done (or seen others do) after being a DS for some time?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1769fk8", "is_robot_indexable": true, "report_reasons": null, "author": "ergodym", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1769fk8/ds_exits_or_pivots/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1769fk8/ds_exits_or_pivots/", "subreddit_subscribers": 1081721, "created_utc": 1697123889.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hey guys, I  just finished my first project to my junior data analyst portfolio and would love to read some feedbacks. What do you think I can do better?\n\n&amp;#x200B;\n\nthank you so much, your feedback will help me a lot\n\nthe project is:\n\n[https://github.com/fernandococco/brazil\\_netflix](https://github.com/fernandococco/brazil_netflix)", "author_fullname": "t2_2f8t9vo1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Junior Data Analyst portfolio feedback?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1767wi3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697119844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hey guys, I  just finished my first project to my junior data analyst portfolio and would love to read some feedbacks. What do you think I can do better?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thank you so much, your feedback will help me a lot&lt;/p&gt;\n\n&lt;p&gt;the project is:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/fernandococco/brazil_netflix\"&gt;https://github.com/fernandococco/brazil_netflix&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u9oH4ENyaWBTE0-KAM0jUX3mVEQ9jkhaq8RcPQ8WrlQ.jpg?auto=webp&amp;s=c5ff10f9c6c90e2a63521b02b9004ccda3547c52", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/u9oH4ENyaWBTE0-KAM0jUX3mVEQ9jkhaq8RcPQ8WrlQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=43b0c7f8801b51cb877ef7a038e278c450962d7d", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/u9oH4ENyaWBTE0-KAM0jUX3mVEQ9jkhaq8RcPQ8WrlQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b8b9d9d90eb004f37aa96ee924a4ccb308957411", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/u9oH4ENyaWBTE0-KAM0jUX3mVEQ9jkhaq8RcPQ8WrlQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1ff03d23a57e9b51738a279c962c84691ddd925f", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/u9oH4ENyaWBTE0-KAM0jUX3mVEQ9jkhaq8RcPQ8WrlQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c49fd5c8f4982098f95c4594565b1a0bde03d99d", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/u9oH4ENyaWBTE0-KAM0jUX3mVEQ9jkhaq8RcPQ8WrlQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=99f3fc6ce4c740a0f3956314eb70e23f72ff9c73", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/u9oH4ENyaWBTE0-KAM0jUX3mVEQ9jkhaq8RcPQ8WrlQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3b47db5d875a6a229c06447ef815a63087ccf950", "width": 1080, "height": 540}], "variants": {}, "id": "fvf3VaxzPdWA5ZbPbPsp00QvyfIzUhqEYEzA0yWLZYc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1767wi3", "is_robot_indexable": true, "report_reasons": null, "author": "fefoficial", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1767wi3/junior_data_analyst_portfolio_feedback/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1767wi3/junior_data_analyst_portfolio_feedback/", "subreddit_subscribers": 1081721, "created_utc": 1697119844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it still as crushing for entry level. I have a clear shot at an entry level position so I know I will get an entry level DS job in a Fortune 100 company. But I want to know if it is typical for those of you with more experience to struggle to get a mid level to management job.", "author_fullname": "t2_8esysayj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much of an effect does this job market have on people who were Data Scientists for a solid 3-5 years?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1767l3b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697118957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it still as crushing for entry level. I have a clear shot at an entry level position so I know I will get an entry level DS job in a Fortune 100 company. But I want to know if it is typical for those of you with more experience to struggle to get a mid level to management job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1767l3b", "is_robot_indexable": true, "report_reasons": null, "author": "LossFirst2657", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1767l3b/how_much_of_an_effect_does_this_job_market_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1767l3b/how_much_of_an_effect_does_this_job_market_have/", "subreddit_subscribers": 1081721, "created_utc": 1697118957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in the very early stages of an investigatory project at my job (senior software engineer with a moderate amount of data mining and snowflake/star pattern ETL OLAP warehousing experience in SSAS from years ago, long before modern tools and platforms, who has somehow now been deemed the SME for all things \"AI\").\n\nBasically, I have a relational SQL Server database containing tens of millions of products, each with up to 20 categories of detail. I also now have usage data from our website that tracks customer interaction with these products, logging things like their account details and demographics as well as their IP, location, searches, where they clicked, how long they interacted, what they interacted with previously, what they interacted with next, etc.\n\nIf they wanted to run this in an old-school schema, I could work something up. I could probably even make some great reports in Power BI. But my bosses, of course, want to load this into a ChatGPT-type interface to ask natural language questions about the data.\n\nMy cursory research tells me I need to massage my data into a vector database first and foremost before I start worrying about Langchain, Llama, and OpenAI, and any specific platform or toolset. But I'm not sure where to start, and I'm getting hung up on that there doesn't seem to be any good examples of migrating existing data - everything is either too much hype and promise-selling language that is sparse on detail or is a very in-the-weeds, poorly documented, mostly-incoherent mess with no examples at all or uses examples that are so simplistic to be not relevant to anyone.\n\nI found some (albeit again very simplistic) examples from Milvus that show importing semi-structured JSON-formatted objects that roughly align with what I'd equate to, in my world, denormalized key/value pairs for various product properties. Cool, that makes sense. That's half of it. But I'm not sure about the other half - how much, if any, pre-aggregation do I need to do with the analytics data? Do I import essentially one object for every single piece of tracked data, or do I roll it up beforehand? I'm most interested in having this vector data be used to identify period-based trends, forecasts, and recommendations like \"Based on his individual product engagement tracking as well as the aggregate tracking of his demographically similar cohorts over the past week, what products should we surface for Bob Smith next?\"\n\nBasically, all this is a very long-winded, rambling way to get to three questions:\n\n1. Are there any examples of converting a remotely complex RDMS into a vector database?\n\n2. How much massaging beyond basic denormalization and pre-aggregation do I need to do?\n\n3. Is it sufficient to load data as lists of a buttload of key-value pairs, or would I do better to zhuzh it into wordy natural language descriptions of the data?", "author_fullname": "t2_32ls6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Existing relational database to new vector database?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1761n34", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697098022.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the very early stages of an investigatory project at my job (senior software engineer with a moderate amount of data mining and snowflake/star pattern ETL OLAP warehousing experience in SSAS from years ago, long before modern tools and platforms, who has somehow now been deemed the SME for all things &amp;quot;AI&amp;quot;).&lt;/p&gt;\n\n&lt;p&gt;Basically, I have a relational SQL Server database containing tens of millions of products, each with up to 20 categories of detail. I also now have usage data from our website that tracks customer interaction with these products, logging things like their account details and demographics as well as their IP, location, searches, where they clicked, how long they interacted, what they interacted with previously, what they interacted with next, etc.&lt;/p&gt;\n\n&lt;p&gt;If they wanted to run this in an old-school schema, I could work something up. I could probably even make some great reports in Power BI. But my bosses, of course, want to load this into a ChatGPT-type interface to ask natural language questions about the data.&lt;/p&gt;\n\n&lt;p&gt;My cursory research tells me I need to massage my data into a vector database first and foremost before I start worrying about Langchain, Llama, and OpenAI, and any specific platform or toolset. But I&amp;#39;m not sure where to start, and I&amp;#39;m getting hung up on that there doesn&amp;#39;t seem to be any good examples of migrating existing data - everything is either too much hype and promise-selling language that is sparse on detail or is a very in-the-weeds, poorly documented, mostly-incoherent mess with no examples at all or uses examples that are so simplistic to be not relevant to anyone.&lt;/p&gt;\n\n&lt;p&gt;I found some (albeit again very simplistic) examples from Milvus that show importing semi-structured JSON-formatted objects that roughly align with what I&amp;#39;d equate to, in my world, denormalized key/value pairs for various product properties. Cool, that makes sense. That&amp;#39;s half of it. But I&amp;#39;m not sure about the other half - how much, if any, pre-aggregation do I need to do with the analytics data? Do I import essentially one object for every single piece of tracked data, or do I roll it up beforehand? I&amp;#39;m most interested in having this vector data be used to identify period-based trends, forecasts, and recommendations like &amp;quot;Based on his individual product engagement tracking as well as the aggregate tracking of his demographically similar cohorts over the past week, what products should we surface for Bob Smith next?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Basically, all this is a very long-winded, rambling way to get to three questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Are there any examples of converting a remotely complex RDMS into a vector database?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How much massaging beyond basic denormalization and pre-aggregation do I need to do?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is it sufficient to load data as lists of a buttload of key-value pairs, or would I do better to zhuzh it into wordy natural language descriptions of the data?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1761n34", "is_robot_indexable": true, "report_reasons": null, "author": "ZebZ", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1761n34/existing_relational_database_to_new_vector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1761n34/existing_relational_database_to_new_vector/", "subreddit_subscribers": 1081721, "created_utc": 1697098022.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Guys,\n\nIs there a way to integrate SHAP with deep reinforcement learning agent ? I am using the FINRL library on ensemble stock trading , and trying to use SHAP with on it. But i hardly find any information or tutorial on it. \n\n&amp;#x200B;\n\nThanks. ", "author_fullname": "t2_gqmgvnn0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SHAP Deep Reinforcement Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175x92z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697081538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;Is there a way to integrate SHAP with deep reinforcement learning agent ? I am using the FINRL library on ensemble stock trading , and trying to use SHAP with on it. But i hardly find any information or tutorial on it. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175x92z", "is_robot_indexable": true, "report_reasons": null, "author": "ProductOk7316", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175x92z/shap_deep_reinforcement_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175x92z/shap_deep_reinforcement_learning/", "subreddit_subscribers": 1081721, "created_utc": 1697081538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a beginner in data science, Can someone recommend some good Data Science courses? ", "author_fullname": "t2_70rifmy3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recommend data science course", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_176bn2q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697129582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a beginner in data science, Can someone recommend some good Data Science courses? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176bn2q", "is_robot_indexable": true, "report_reasons": null, "author": "Ashfan007", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176bn2q/recommend_data_science_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176bn2q/recommend_data_science_course/", "subreddit_subscribers": 1081721, "created_utc": 1697129582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everybody!\n\nI am a Junior in college who has recently decided to major in Business Analytics with a minor in Data Science. As of right now, I am considering dropping the minor for three reasons: \n\n1. With the minor, I'll be taking 19 or more hours per semester to graduate on time\n2. I don't know if I can afford any extra semesters of school with the minor included  (I am currently on a full ride that lasts 4 years).\n3. Instead of pursuing the minor to show my interest in Data Science to recruiters I could just teach myself the technical skills and work on projects with the time freed up from not having the minor.\n\nI really wish that when I arrived at college freshman year I could've decided on this major immediately, then I wouldn't be dealing with this issue, but the past isn't gonna change anytime soon. \n\nWith that being said, how useful would you all say the minor is vs me teaching myself those in demand skills (SQL, Python, Power Bi, etc.)?\n\n&amp;#x200B;", "author_fullname": "t2_3k8a24gm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Business Analytics Major and going into Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_176b5zc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697128340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody!&lt;/p&gt;\n\n&lt;p&gt;I am a Junior in college who has recently decided to major in Business Analytics with a minor in Data Science. As of right now, I am considering dropping the minor for three reasons: &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;With the minor, I&amp;#39;ll be taking 19 or more hours per semester to graduate on time&lt;/li&gt;\n&lt;li&gt;I don&amp;#39;t know if I can afford any extra semesters of school with the minor included  (I am currently on a full ride that lasts 4 years).&lt;/li&gt;\n&lt;li&gt;Instead of pursuing the minor to show my interest in Data Science to recruiters I could just teach myself the technical skills and work on projects with the time freed up from not having the minor.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I really wish that when I arrived at college freshman year I could&amp;#39;ve decided on this major immediately, then I wouldn&amp;#39;t be dealing with this issue, but the past isn&amp;#39;t gonna change anytime soon. &lt;/p&gt;\n\n&lt;p&gt;With that being said, how useful would you all say the minor is vs me teaching myself those in demand skills (SQL, Python, Power Bi, etc.)?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176b5zc", "is_robot_indexable": true, "report_reasons": null, "author": "thekebster", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176b5zc/business_analytics_major_and_going_into_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176b5zc/business_analytics_major_and_going_into_data/", "subreddit_subscribers": 1081721, "created_utc": 1697128340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I want to make a project in which I'm thinking of combining IoT devices, PCA, LDA and SVD but I want a problem statement for which there isn't already a solution however I'm not able to think of anything so I thought I should reach out onto reddit to see if I can get something from here. If y'all have any suggestions please let me know it'll be genuinely appreciated!", "author_fullname": "t2_spw388k1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need problem statements for a project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_176aamb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697126138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to make a project in which I&amp;#39;m thinking of combining IoT devices, PCA, LDA and SVD but I want a problem statement for which there isn&amp;#39;t already a solution however I&amp;#39;m not able to think of anything so I thought I should reach out onto reddit to see if I can get something from here. If y&amp;#39;all have any suggestions please let me know it&amp;#39;ll be genuinely appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176aamb", "is_robot_indexable": true, "report_reasons": null, "author": "emotional-Limit-2000", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176aamb/need_problem_statements_for_a_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176aamb/need_problem_statements_for_a_project/", "subreddit_subscribers": 1081721, "created_utc": 1697126138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm interested in becoming a doing climate, GIS data/AI research and am intrigued by the postings at these big tech companies (Google, MSFT, IBM, etc.). I currently have a MS in Mechanical Engineering and 2 YOE as a Data Scientist in a big tech company.\n\nI wanted to know what you do as a Research Scientist. How much academic freedom do you have? Is it a lot of meetings or do you get more freedom to get into a deepwork headspace? Do you enjoy the role? Whats the work-life balance like?\n\nHow did you get the role? If I'm interested, do I need a PhD or is my MS + Professional Exp good enough? Will not having a PhD hurt me in the long run?", "author_fullname": "t2_8cg2z0mf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "can any research scientists share their experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1769z7v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697125314.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m interested in becoming a doing climate, GIS data/AI research and am intrigued by the postings at these big tech companies (Google, MSFT, IBM, etc.). I currently have a MS in Mechanical Engineering and 2 YOE as a Data Scientist in a big tech company.&lt;/p&gt;\n\n&lt;p&gt;I wanted to know what you do as a Research Scientist. How much academic freedom do you have? Is it a lot of meetings or do you get more freedom to get into a deepwork headspace? Do you enjoy the role? Whats the work-life balance like?&lt;/p&gt;\n\n&lt;p&gt;How did you get the role? If I&amp;#39;m interested, do I need a PhD or is my MS + Professional Exp good enough? Will not having a PhD hurt me in the long run?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1769z7v", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate_Ebb3623", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1769z7v/can_any_research_scientists_share_their_experience/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1769z7v/can_any_research_scientists_share_their_experience/", "subreddit_subscribers": 1081721, "created_utc": 1697125314.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, I am currently a penultimate uni student doing a double degree in business and data science (majoring in accounting). While doing uni, I balance a normal grocery store job for the past 2 years. I feel very burnt out with the workload and was wondering if its any better to take a gap year to find a full time job within my field (more so on the data science field), but I am not sure if I should just hang on another year and finish my degree. Another potential approach would be to go full time work and balance uni with 2 courses. What would be ideal and if so, what sort of IT job could I look for with no prior experience or qualifications in IT or data science?", "author_fullname": "t2_7wg5m7r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career planning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17686qn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697120602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I am currently a penultimate uni student doing a double degree in business and data science (majoring in accounting). While doing uni, I balance a normal grocery store job for the past 2 years. I feel very burnt out with the workload and was wondering if its any better to take a gap year to find a full time job within my field (more so on the data science field), but I am not sure if I should just hang on another year and finish my degree. Another potential approach would be to go full time work and balance uni with 2 courses. What would be ideal and if so, what sort of IT job could I look for with no prior experience or qualifications in IT or data science?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17686qn", "is_robot_indexable": true, "report_reasons": null, "author": "Kenny9184", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17686qn/career_planning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17686qn/career_planning/", "subreddit_subscribers": 1081721, "created_utc": 1697120602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just to know, I have many questions..", "author_fullname": "t2_e7bfii4b5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone as a DS in banking?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_176aj3m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697126727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just to know, I have many questions..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "176aj3m", "is_robot_indexable": true, "report_reasons": null, "author": "ShillerMarks", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/176aj3m/anyone_as_a_ds_in_banking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/176aj3m/anyone_as_a_ds_in_banking/", "subreddit_subscribers": 1081721, "created_utc": 1697126727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a 2Mio x 1139 dataset (huge right) and ive spent the whole day trying to load and work with in r (package data.table, function fread). It loads the data pretty quickly, in 1-2 minutes I'd say. I wanna loop over the data (or use lapply or something similar to gain efficiency). My function is fairly simple though, but the dataset is just huge. And then it runs and runs and runs, and half an hour goes by and it still runns. I AM SO AFRAID OF THE ''SESSION CRASHED''!\n\nDo you guys have any tips on dealing with such datasets and am i guaranteed if i leave the loop running over night, that it wont crash? Can I have trust in R? Are there any measures I can take to support R with its looping and looping and looping?\n\nP.S. i sadly mustn't split the dataset. \n\nThanks a lot, i wish you nothing but simple datasets. ", "author_fullname": "t2_3x05wl5n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "R-SESSION CRASHING-PHOBIA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175mipy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697052333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 2Mio x 1139 dataset (huge right) and ive spent the whole day trying to load and work with in r (package data.table, function fread). It loads the data pretty quickly, in 1-2 minutes I&amp;#39;d say. I wanna loop over the data (or use lapply or something similar to gain efficiency). My function is fairly simple though, but the dataset is just huge. And then it runs and runs and runs, and half an hour goes by and it still runns. I AM SO AFRAID OF THE &amp;#39;&amp;#39;SESSION CRASHED&amp;#39;&amp;#39;!&lt;/p&gt;\n\n&lt;p&gt;Do you guys have any tips on dealing with such datasets and am i guaranteed if i leave the loop running over night, that it wont crash? Can I have trust in R? Are there any measures I can take to support R with its looping and looping and looping?&lt;/p&gt;\n\n&lt;p&gt;P.S. i sadly mustn&amp;#39;t split the dataset. &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot, i wish you nothing but simple datasets. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175mipy", "is_robot_indexable": true, "report_reasons": null, "author": "aesthetic-mango", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175mipy/rsession_crashingphobia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175mipy/rsession_crashingphobia/", "subreddit_subscribers": 1081721, "created_utc": 1697052333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Markdown To HTML", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1760xpw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_i0179ktk", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "StreamlitOfficial", "selftext": "Markdown to HTML is a versatile tool that seamlessly transforms plain text notes into visually appealing and colourful web content. By converting markdown syntax into HTML code, enhances readability and aesthetics. Users can create stunning documents, blogs, or websites effortlessly, adding vibrancy to their content while maintaining simplicity in the editing process. \ud83c\udfa8\u2728\ud83d\udcdd Experience the convenience of uploading your Markdown files and getting instant HTML output. Try our Streamlit Markdown to HTML Converter now and elevate your document processing efficiency!\n\nIf you liked it, Donate some BTC: [https://nowpayments.io/donation?api\\_key=2166K58-CTAMFFB-P8FYBJP-ZK66TW6&amp;source=lk\\_donation&amp;medium=referral](https://nowpayments.io/donation?api_key=2166K58-CTAMFFB-P8FYBJP-ZK66TW6&amp;source=lk_donation&amp;medium=referral)", "author_fullname": "t2_i0179ktk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Markdown To HTML", "link_flair_richtext": [], "subreddit_name_prefixed": "r/StreamlitOfficial", "hidden": false, "pwls": null, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1760rc0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697094610.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697094349.0, "link_flair_type": "text", "wls": null, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.StreamlitOfficial", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Markdown to HTML is a versatile tool that seamlessly transforms plain text notes into visually appealing and colourful web content. By converting markdown syntax into HTML code, enhances readability and aesthetics. Users can create stunning documents, blogs, or websites effortlessly, adding vibrancy to their content while maintaining simplicity in the editing process. \ud83c\udfa8\u2728\ud83d\udcdd Experience the convenience of uploading your Markdown files and getting instant HTML output. Try our Streamlit Markdown to HTML Converter now and elevate your document processing efficiency!&lt;/p&gt;\n\n&lt;p&gt;If you liked it, Donate some BTC: &lt;a href=\"https://nowpayments.io/donation?api_key=2166K58-CTAMFFB-P8FYBJP-ZK66TW6&amp;amp;source=lk_donation&amp;amp;medium=referral\"&gt;https://nowpayments.io/donation?api_key=2166K58-CTAMFFB-P8FYBJP-ZK66TW6&amp;amp;source=lk_donation&amp;amp;medium=referral&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_7ispo3", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1760rc0", "is_robot_indexable": true, "report_reasons": null, "author": "RevolutionaryPen4661", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": null, "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/StreamlitOfficial/comments/1760rc0/markdown_to_html/", "parent_whitelist_status": null, "stickied": false, "url": "https://old.reddit.com/r/StreamlitOfficial/comments/1760rc0/markdown_to_html/", "subreddit_subscribers": 818, "created_utc": 1697094349.0, "num_crossposts": 4, "media": null, "is_video": false}], "created": 1697095039.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.StreamlitOfficial", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "/r/StreamlitOfficial/comments/1760rc0/markdown_to_html/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1760xpw", "is_robot_indexable": true, "report_reasons": null, "author": "RevolutionaryPen4661", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1760rc0", "author_flair_text_color": null, "permalink": "/r/datascience/comments/1760xpw/markdown_to_html/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/StreamlitOfficial/comments/1760rc0/markdown_to_html/", "subreddit_subscribers": 1081721, "created_utc": 1697095039.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "One of the departments at the hospital I work at is starting an LLM using doctors clinic notes and diagnosis as the training source. The goal is a Chat GPT like platform for predictive patient diagnosis. How much is involved in a project of this type? It's not something I'm ever being part of, I just happen to be one of the keepers of the data. ", "author_fullname": "t2_4byn8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project question: How much work is involved in creating an LLM for Healthcare.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1767bi1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697118214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One of the departments at the hospital I work at is starting an LLM using doctors clinic notes and diagnosis as the training source. The goal is a Chat GPT like platform for predictive patient diagnosis. How much is involved in a project of this type? It&amp;#39;s not something I&amp;#39;m ever being part of, I just happen to be one of the keepers of the data. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1767bi1", "is_robot_indexable": true, "report_reasons": null, "author": "oldgrumpygeek", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1767bi1/project_question_how_much_work_is_involved_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1767bi1/project_question_how_much_work_is_involved_in/", "subreddit_subscribers": 1081721, "created_utc": 1697118214.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}