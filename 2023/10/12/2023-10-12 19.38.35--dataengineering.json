{"kind": "Listing", "data": {"after": "t3_1761x4f", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This is UMortgage interview assessment. Reads to me like free work more than skills assessment.", "author_fullname": "t2_4ed4jwbg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just do a quick 30min to 1hr take home test. \ud83e\udd21 \ud83e\udd21", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_1767l40", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 227, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 227, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/L4dkpUvYTR8Wd0bbDwd9ICxvZwRdG_aH8fXf6p9O3wI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697118958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is UMortgage interview assessment. Reads to me like free work more than skills assessment.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/fvlmf8qz1stb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/fvlmf8qz1stb1.jpg?auto=webp&amp;s=e871d23f6aa715d584d73d40a5ba71442dbf5563", "width": 828, "height": 1792}, "resolutions": [{"url": "https://preview.redd.it/fvlmf8qz1stb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3422d29cda16f2aa231f250bf350abf649ca055a", "width": 108, "height": 216}, {"url": "https://preview.redd.it/fvlmf8qz1stb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a20be752c3e865249cbb3690b32b7afd9c3232a1", "width": 216, "height": 432}, {"url": "https://preview.redd.it/fvlmf8qz1stb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2934becb569e26bd164a575f84f2723c02011b5c", "width": 320, "height": 640}, {"url": "https://preview.redd.it/fvlmf8qz1stb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2906c13c5d0b2a9f81fdd656e2ede38f3c4904e2", "width": 640, "height": 1280}], "variants": {}, "id": "wiOcOa2Zlt93AaPEsfspXz9hnOBXFMX02vZ8yBFLDoA"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "1767l40", "is_robot_indexable": true, "report_reasons": null, "author": "Dull_Biscotti7205", "discussion_type": null, "num_comments": 48, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1767l40/just_do_a_quick_30min_to_1hr_take_home_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/fvlmf8qz1stb1.jpg", "subreddit_subscribers": 133589, "created_utc": 1697118958.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Please no roast. Just curious on your thoughts. I read some previous posts, and people mentioned that it's riskier to let juniors access your data, because they could be prone to mistakes. And that transitioning into DE is much more doable. But that still doesn't answer my question", "author_fullname": "t2_e58lby3h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why are there data engineering internships if there is such a lackluster amount of data engineer junior roles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175p2bq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 46, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 46, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697058691.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Please no roast. Just curious on your thoughts. I read some previous posts, and people mentioned that it&amp;#39;s riskier to let juniors access your data, because they could be prone to mistakes. And that transitioning into DE is much more doable. But that still doesn&amp;#39;t answer my question&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "175p2bq", "is_robot_indexable": true, "report_reasons": null, "author": "kid2002", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/175p2bq/why_are_there_data_engineering_internships_if/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/175p2bq/why_are_there_data_engineering_internships_if/", "subreddit_subscribers": 133589, "created_utc": 1697058691.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Yo, a recent [post](https://www.reddit.com/r/dataengineering/comments/15mhunt/is_our_dbt_project_as_bad_as_i_think/) here made me want to start a thread on dbt model explosion. Repeating my comment there, 5 engineers and a thousand models doesn't shock anybody anymore. What are your numbers, or worst numbers you've seen so far? When did you realise it's too much? Was it mostly the cost that made you realise, organisation inside the team, any impact on business? How did you go about improving it?\n\nFound into two articles on Medium, funny when you read them in order: [1](https://medium.com/@imweijian/lessons-learned-after-1-year-with-dbt-a7f0ccf85b12)  [2](https://medium.com/@imweijian/lessons-learned-when-scaling-dbt-models-quickly-c3fcd1551663). Hilarious summary in the  search, too.\n\nhttps://preview.redd.it/0xkehgr5dmtb1.png?width=1284&amp;format=png&amp;auto=webp&amp;s=439fae017967f1a4a4566ea038483e4be62345b4\n\nDisclaimer: I work for a data governance company circling around this topic. Will probably write an article about this soon, but obv won't use anything from the comments without reaching out. Genuinely curious what's the industry standard + I feel nobody really talks about this??", "author_fullname": "t2_9wfvtd4bu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many models is too many models? DBT horror stories thread?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 91, "top_awarded_type": null, "hide_score": false, "media_metadata": {"0xkehgr5dmtb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 25, "x": 108, "u": "https://preview.redd.it/0xkehgr5dmtb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=af083f822308075eb004d3827be68c5feb3d2150"}, {"y": 51, "x": 216, "u": "https://preview.redd.it/0xkehgr5dmtb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=daab666af58641e11916869fa490234d22e35367"}, {"y": 75, "x": 320, "u": "https://preview.redd.it/0xkehgr5dmtb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a031c40ad1340ab93595ea249abc12007b4b9a05"}, {"y": 151, "x": 640, "u": "https://preview.redd.it/0xkehgr5dmtb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=316657186c1fbd98a143246c04f0a45c46fe5518"}, {"y": 227, "x": 960, "u": "https://preview.redd.it/0xkehgr5dmtb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ac34c02d88cc245d074fa0cbdcab1793df866d25"}, {"y": 255, "x": 1080, "u": "https://preview.redd.it/0xkehgr5dmtb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=31c2d8176d82af828cd2021efd7690bf5a48ebb1"}], "s": {"y": 304, "x": 1284, "u": "https://preview.redd.it/0xkehgr5dmtb1.png?width=1284&amp;format=png&amp;auto=webp&amp;s=439fae017967f1a4a4566ea038483e4be62345b4"}, "id": "0xkehgr5dmtb1"}}, "name": "t3_175me07", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Ck9bMyO_eFCmURFU17rIsZERtaEhO3ueRYoqVeTH30w.jpg", "edited": 1697114592.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1697052014.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Yo, a recent &lt;a href=\"https://www.reddit.com/r/dataengineering/comments/15mhunt/is_our_dbt_project_as_bad_as_i_think/\"&gt;post&lt;/a&gt; here made me want to start a thread on dbt model explosion. Repeating my comment there, 5 engineers and a thousand models doesn&amp;#39;t shock anybody anymore. What are your numbers, or worst numbers you&amp;#39;ve seen so far? When did you realise it&amp;#39;s too much? Was it mostly the cost that made you realise, organisation inside the team, any impact on business? How did you go about improving it?&lt;/p&gt;\n\n&lt;p&gt;Found into two articles on Medium, funny when you read them in order: &lt;a href=\"https://medium.com/@imweijian/lessons-learned-after-1-year-with-dbt-a7f0ccf85b12\"&gt;1&lt;/a&gt;  &lt;a href=\"https://medium.com/@imweijian/lessons-learned-when-scaling-dbt-models-quickly-c3fcd1551663\"&gt;2&lt;/a&gt;. Hilarious summary in the  search, too.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/0xkehgr5dmtb1.png?width=1284&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=439fae017967f1a4a4566ea038483e4be62345b4\"&gt;https://preview.redd.it/0xkehgr5dmtb1.png?width=1284&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=439fae017967f1a4a4566ea038483e4be62345b4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Disclaimer: I work for a data governance company circling around this topic. Will probably write an article about this soon, but obv won&amp;#39;t use anything from the comments without reaching out. Genuinely curious what&amp;#39;s the industry standard + I feel nobody really talks about this??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nDEm8n2_3UDnhnp_h-2UxtpsdFmyKtCw9o41Bjj4q0E.jpg?auto=webp&amp;s=069b2930a996fc502f9c1a9e77cff14c02471d09", "width": 498, "height": 325}, "resolutions": [{"url": "https://external-preview.redd.it/nDEm8n2_3UDnhnp_h-2UxtpsdFmyKtCw9o41Bjj4q0E.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9d092de33c1ab0397b27185b86e91d8c8200f6b6", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/nDEm8n2_3UDnhnp_h-2UxtpsdFmyKtCw9o41Bjj4q0E.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fb711131867a14479b516a01c0854eb1330244ff", "width": 216, "height": 140}, {"url": "https://external-preview.redd.it/nDEm8n2_3UDnhnp_h-2UxtpsdFmyKtCw9o41Bjj4q0E.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a2954149f72d3ffbe86df2842454988cca1a675b", "width": 320, "height": 208}], "variants": {}, "id": "J17xFutWhTnnV7t2i9OmckmAz-6Y6l-FaLCNibXJdtU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "175me07", "is_robot_indexable": true, "report_reasons": null, "author": "prsrboi", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/175me07/how_many_models_is_too_many_models_dbt_horror/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/175me07/how_many_models_is_too_many_models_dbt_horror/", "subreddit_subscribers": 133589, "created_utc": 1697052014.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There seems to be lot of dislike in software engineering in general for consultants specially they talk about big things and complicated processes with very less actual work etc. What is your experience in general working with consultants in data engineering world?", "author_fullname": "t2_hnxu1e2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why you don't like about data engineering consultants in your company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175zng5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697090011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There seems to be lot of dislike in software engineering in general for consultants specially they talk about big things and complicated processes with very less actual work etc. What is your experience in general working with consultants in data engineering world?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "175zng5", "is_robot_indexable": true, "report_reasons": null, "author": "boogie_woogie_100", "discussion_type": null, "num_comments": 36, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/175zng5/why_you_dont_like_about_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/175zng5/why_you_dont_like_about_data_engineering/", "subreddit_subscribers": 133589, "created_utc": 1697090011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello folks, I've been working on Kenobi ([github link](https://github.com/DrDroidLab/kenobi/)) since a while now -- we made the repo open source finally (when we felt the project can have out of the box value \ud83d\ude05), so sharing about it.\n\n**What is it:** A data platform for event analytics and correlation.\n\n**Where could it be more useful:** Kenobi is a solution for companies that want to monitor operational metrics &amp; funnels with a capability to get alerts in realtime.\n\n**How is it different from:**\n\n* **Postgres/MySQL + Metabase/Superset:** Kenobi is for companies who want to move out of their OLTP for analytics due to scaling challenges.\n* **ELK:** Kenobi is optimised for aggregations on complex event joins (examples in github link); has a one-click deployment; it is easier to learn/use with no-code interface; also it has a buffer layer for data filtering and transformation on the UI.\n* **DWH:** Kenobi is designed for short-term, low-latency use-cases.\n\n**Here are some of the capabilities:**\n\n* Ingest events through multiple sources, including logs &amp; event streams (Kafka / Kinesis)\n* Create complex join queries on multiple event-types\n* Aggregate data with slicing and dicing basis the entire event payload\n* Single click deployment with horizontal scaling (tested upto 130M events/hour)\n* Near real-time alerting infrastructure baked into the platform\n\nIf you have any questions, feedback or queries about the project, please comment -- I'm happy to answer! \n\nIf you've built something like this internally, would love to hear how you did it.", "author_fullname": "t2_15bgjr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kenobi: Open Source analytics tool for funnel analysis, optimised for near real-time performance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175t57y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697069409.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks, I&amp;#39;ve been working on Kenobi (&lt;a href=\"https://github.com/DrDroidLab/kenobi/\"&gt;github link&lt;/a&gt;) since a while now -- we made the repo open source finally (when we felt the project can have out of the box value \ud83d\ude05), so sharing about it.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What is it:&lt;/strong&gt; A data platform for event analytics and correlation.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Where could it be more useful:&lt;/strong&gt; Kenobi is a solution for companies that want to monitor operational metrics &amp;amp; funnels with a capability to get alerts in realtime.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How is it different from:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Postgres/MySQL + Metabase/Superset:&lt;/strong&gt; Kenobi is for companies who want to move out of their OLTP for analytics due to scaling challenges.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;ELK:&lt;/strong&gt; Kenobi is optimised for aggregations on complex event joins (examples in github link); has a one-click deployment; it is easier to learn/use with no-code interface; also it has a buffer layer for data filtering and transformation on the UI.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;DWH:&lt;/strong&gt; Kenobi is designed for short-term, low-latency use-cases.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Here are some of the capabilities:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Ingest events through multiple sources, including logs &amp;amp; event streams (Kafka / Kinesis)&lt;/li&gt;\n&lt;li&gt;Create complex join queries on multiple event-types&lt;/li&gt;\n&lt;li&gt;Aggregate data with slicing and dicing basis the entire event payload&lt;/li&gt;\n&lt;li&gt;Single click deployment with horizontal scaling (tested upto 130M events/hour)&lt;/li&gt;\n&lt;li&gt;Near real-time alerting infrastructure baked into the platform&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;If you have any questions, feedback or queries about the project, please comment -- I&amp;#39;m happy to answer! &lt;/p&gt;\n\n&lt;p&gt;If you&amp;#39;ve built something like this internally, would love to hear how you did it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/G_Nmio5Wu0zp02x-TrS0VZtc3sbPojamX2Ld0cNsxGk.jpg?auto=webp&amp;s=ea2a9756f52902c9bc0a75eea0189097e340b1bf", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/G_Nmio5Wu0zp02x-TrS0VZtc3sbPojamX2Ld0cNsxGk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=59b13f88947c7af7ef42d6e1400a448a95d19762", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/G_Nmio5Wu0zp02x-TrS0VZtc3sbPojamX2Ld0cNsxGk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=98e023efe8b1144d6e0790166ff23c4dca49a874", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/G_Nmio5Wu0zp02x-TrS0VZtc3sbPojamX2Ld0cNsxGk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8c199595f8850ce41ce6a872200d19e7a8dd388c", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/G_Nmio5Wu0zp02x-TrS0VZtc3sbPojamX2Ld0cNsxGk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0d741f65f3d95fc7c237e23b01c63b65cd096503", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/G_Nmio5Wu0zp02x-TrS0VZtc3sbPojamX2Ld0cNsxGk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e1f36df2c7c31f0cc2569b61160917cb469f3863", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/G_Nmio5Wu0zp02x-TrS0VZtc3sbPojamX2Ld0cNsxGk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f67c922080b59c606fcdfd16a4c11d24ed30d924", "width": 1080, "height": 540}], "variants": {}, "id": "0ZCNUyfMsKpp5Vwml3FxO427XhPYYQEM4nvcBYQMIMY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "175t57y", "is_robot_indexable": true, "report_reasons": null, "author": "siddharthnibjiya", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/175t57y/kenobi_open_source_analytics_tool_for_funnel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/175t57y/kenobi_open_source_analytics_tool_for_funnel/", "subreddit_subscribers": 133589, "created_utc": 1697069409.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,   \nI'm trying to figure out what are some of the best practices for building data documentation. I came across tools like DataHub and DBT documentation. Has anyone tried using LLM's in building a data documentation? like for example \"how to find active customers\" and it provides the relevant tables that are to be used. \n\nThanks,", "author_fullname": "t2_gl7de", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for data documentation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175zjdw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697089567.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;br/&gt;\nI&amp;#39;m trying to figure out what are some of the best practices for building data documentation. I came across tools like DataHub and DBT documentation. Has anyone tried using LLM&amp;#39;s in building a data documentation? like for example &amp;quot;how to find active customers&amp;quot; and it provides the relevant tables that are to be used. &lt;/p&gt;\n\n&lt;p&gt;Thanks,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "175zjdw", "is_robot_indexable": true, "report_reasons": null, "author": "dna_o_O", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/175zjdw/best_practices_for_data_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/175zjdw/best_practices_for_data_documentation/", "subreddit_subscribers": 133589, "created_utc": 1697089567.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5paor1zb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accelerating Spark: Databricks Photon Runtime", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_175uk3s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/J3uny-MxlfRS-MJI1XvXm3vqnlH1KqaQAc7or3o4JuA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697073535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@philipdakin/accelerating-spark-databricks-photon-runtime-9a7a53824d1b", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iiNdop72CHvNr4BX_bhsAYLweJLIjntWHo5xd_fOfUo.jpg?auto=webp&amp;s=a0e4c7bd816fcbb020cb8ca369a6210bfb613e2b", "width": 482, "height": 544}, "resolutions": [{"url": "https://external-preview.redd.it/iiNdop72CHvNr4BX_bhsAYLweJLIjntWHo5xd_fOfUo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f4e6951bd885c65b233618c7569774ba568e929f", "width": 108, "height": 121}, {"url": "https://external-preview.redd.it/iiNdop72CHvNr4BX_bhsAYLweJLIjntWHo5xd_fOfUo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a281a7b9ff4b59423fea9d6c0a028fece4aab802", "width": 216, "height": 243}, {"url": "https://external-preview.redd.it/iiNdop72CHvNr4BX_bhsAYLweJLIjntWHo5xd_fOfUo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f2c932de2dbdf2a3a0724a3183a9a34e69011e4b", "width": 320, "height": 361}], "variants": {}, "id": "-0-L7CTEvHKfAYbxp9aB6JixOk_WCEouHBv-j6sJ2pc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "175uk3s", "is_robot_indexable": true, "report_reasons": null, "author": "phildakin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/175uk3s/accelerating_spark_databricks_photon_runtime/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@philipdakin/accelerating-spark-databricks-photon-runtime-9a7a53824d1b", "subreddit_subscribers": 133589, "created_utc": 1697073535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say we have a 100 source tables from an OLTP system.\n\nWhen we bring the data into Data Warehouse:\n1. Should we have a SCD2 version of the source / raw tables as a best practice? I can see how knowing what changed when can be useful.\n\n\n2. If we now want to use 30 of the source tables to build a downstream table C - which we do want to track changes on. \n\nShould we join all the raw tables (if raw is ace then read scd active row flag =1) , apply transformations,then build a wide and large table C_stg. Finally a SCD2 based on what changed with respect to current table C (active row flag=1).\n\nIs this the right way for downstream SCD tables, this seems like can get very resource intensive as source tables get bigger and bigger.", "author_fullname": "t2_tov4xq2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SCD2 - what is the right way?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175rkdy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697065085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say we have a 100 source tables from an OLTP system.&lt;/p&gt;\n\n&lt;p&gt;When we bring the data into Data Warehouse:\n1. Should we have a SCD2 version of the source / raw tables as a best practice? I can see how knowing what changed when can be useful.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;If we now want to use 30 of the source tables to build a downstream table C - which we do want to track changes on. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Should we join all the raw tables (if raw is ace then read scd active row flag =1) , apply transformations,then build a wide and large table C_stg. Finally a SCD2 based on what changed with respect to current table C (active row flag=1).&lt;/p&gt;\n\n&lt;p&gt;Is this the right way for downstream SCD tables, this seems like can get very resource intensive as source tables get bigger and bigger.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "175rkdy", "is_robot_indexable": true, "report_reasons": null, "author": "nanksk", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/175rkdy/scd2_what_is_the_right_way/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/175rkdy/scd2_what_is_the_right_way/", "subreddit_subscribers": 133589, "created_utc": 1697065085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a recent graduate and I'm working at a e-commerce startup as a data analyst for 2 months . We use Zoho for pretty much everything, CRM, accounting, marketing etc. and analytics as well. Analytics just has the option to import data directly form the other apps and store it in seperate workspaces. This becomes a pain to deal with as we cannot query data between workspaces. Even with very little data, this results in complex joins.\nI feel like a data warehouse is what we need. But I'm not sure on how to go about it as I kinda stumbled into this job and I'm still learning. \nIt would be really helpful if you guys could help me out with the general procedure and the best tools for the job.Also, I am comfortable using SQL and python.", "author_fullname": "t2_w16t5qhn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help in building a data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176a6i2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697125844.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a recent graduate and I&amp;#39;m working at a e-commerce startup as a data analyst for 2 months . We use Zoho for pretty much everything, CRM, accounting, marketing etc. and analytics as well. Analytics just has the option to import data directly form the other apps and store it in seperate workspaces. This becomes a pain to deal with as we cannot query data between workspaces. Even with very little data, this results in complex joins.\nI feel like a data warehouse is what we need. But I&amp;#39;m not sure on how to go about it as I kinda stumbled into this job and I&amp;#39;m still learning. \nIt would be really helpful if you guys could help me out with the general procedure and the best tools for the job.Also, I am comfortable using SQL and python.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176a6i2", "is_robot_indexable": true, "report_reasons": null, "author": "booberrypie_", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/176a6i2/need_help_in_building_a_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176a6i2/need_help_in_building_a_data_warehouse/", "subreddit_subscribers": 133589, "created_utc": 1697125844.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\n\nI love the engineering side of data and I'm looking to break into ml engineering or data engineering roles.  \nI have about two years of experience in backend(.net and python) plus an internship in data science. My educational background is: BS in econ, Ms in pure math, Ma in econ. Heavily self-studied ML in my bachelor's and have done a few projects already(knowledge is a little bit outdated)\n\nWhat would be your advice here? Should I apply for internships? Do I have to learn anything before applying or I can learn in my internship? \n\nMy long-term goal is becoming an ML engineer but see it as a senior role and I'm lacking DE skills", "author_fullname": "t2_45mo3pla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Breaking into the field as a backend engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1768ymf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697122679.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi&lt;/p&gt;\n\n&lt;p&gt;I love the engineering side of data and I&amp;#39;m looking to break into ml engineering or data engineering roles.&lt;br/&gt;\nI have about two years of experience in backend(.net and python) plus an internship in data science. My educational background is: BS in econ, Ms in pure math, Ma in econ. Heavily self-studied ML in my bachelor&amp;#39;s and have done a few projects already(knowledge is a little bit outdated)&lt;/p&gt;\n\n&lt;p&gt;What would be your advice here? Should I apply for internships? Do I have to learn anything before applying or I can learn in my internship? &lt;/p&gt;\n\n&lt;p&gt;My long-term goal is becoming an ML engineer but see it as a senior role and I&amp;#39;m lacking DE skills&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1768ymf", "is_robot_indexable": true, "report_reasons": null, "author": "johnprynsky", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1768ymf/breaking_into_the_field_as_a_backend_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1768ymf/breaking_into_the_field_as_a_backend_engineer/", "subreddit_subscribers": 133589, "created_utc": 1697122679.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, looking for advice on best practices on what I think is a pretty common setup, yet I couldn't find any good examples on this. \n\nI have multiple APIs as sources, each with their own script. I want to insert the data into a MySQL database. The aim is to have these tasks running separately using the k8sPodOperator. I'm using poetry as my dependency manager. GitHub Actions for CICD. \n\nMy questions are twofold:\n\n1. Is it better practice to have one large image that contains all the code for every API, and pass different commands to the image in different k8sPodOperators? Or would it be better to have multiple images, one per API pipeline? \n\n2. How should I organize my code, considering we want to keep a monorepo structure, where multiple projects within that repo will be using Airflow?\n\nCurrently the monorepo looks like:\n\n    monorepo/\n\n    --my-project/\n\n    ----dags/\n\n    ------dag_1.py\n\n    ------dag_2.py\n\n    ----api/\n\n    ------base_api_class.py\n\n    ------api1/\n\n    --------api1.py\n\n    --------api1_execute.py\n\n    ------api2/\n\n    --------api2.py\n\n    --------api2_execute.py\n\n    ----migrations/\n\n    ----pyproject.toml\n\n    ----Dockerfile (Open to change based on answer to q1)\n\n    --other_project/\n\n\nI think I'll be moving the dags/ folder to the top level in the monorepo, since other projects will be eventually using dags as well. \n\nBut I'm stuck on the others, considering that I need to take into account that we'll want the image building/pushing in CICD as well. \n\nAny examples or advice would be greatly appreciated.", "author_fullname": "t2_blmi7z1v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best practices for organizing a project using Airflow + multiple pipelines + poetry + CICD WITHIN a monorepo", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17666db", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697114866.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, looking for advice on best practices on what I think is a pretty common setup, yet I couldn&amp;#39;t find any good examples on this. &lt;/p&gt;\n\n&lt;p&gt;I have multiple APIs as sources, each with their own script. I want to insert the data into a MySQL database. The aim is to have these tasks running separately using the k8sPodOperator. I&amp;#39;m using poetry as my dependency manager. GitHub Actions for CICD. &lt;/p&gt;\n\n&lt;p&gt;My questions are twofold:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Is it better practice to have one large image that contains all the code for every API, and pass different commands to the image in different k8sPodOperators? Or would it be better to have multiple images, one per API pipeline? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How should I organize my code, considering we want to keep a monorepo structure, where multiple projects within that repo will be using Airflow?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Currently the monorepo looks like:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;monorepo/\n\n--my-project/\n\n----dags/\n\n------dag_1.py\n\n------dag_2.py\n\n----api/\n\n------base_api_class.py\n\n------api1/\n\n--------api1.py\n\n--------api1_execute.py\n\n------api2/\n\n--------api2.py\n\n--------api2_execute.py\n\n----migrations/\n\n----pyproject.toml\n\n----Dockerfile (Open to change based on answer to q1)\n\n--other_project/\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I think I&amp;#39;ll be moving the dags/ folder to the top level in the monorepo, since other projects will be eventually using dags as well. &lt;/p&gt;\n\n&lt;p&gt;But I&amp;#39;m stuck on the others, considering that I need to take into account that we&amp;#39;ll want the image building/pushing in CICD as well. &lt;/p&gt;\n\n&lt;p&gt;Any examples or advice would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17666db", "is_robot_indexable": true, "report_reasons": null, "author": "lingorioriorio", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17666db/best_practices_for_organizing_a_project_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17666db/best_practices_for_organizing_a_project_using/", "subreddit_subscribers": 133589, "created_utc": 1697114866.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you deal with using data from Mongo?  IME the data is always nested and needs to be flattened to use.  So do you flatten it in python, or in sql? or do you use something that skips the flat data requirements?  \n\n\nWe are currently playing with the idea of automatic unnesting and semantic modelling on top to enable analysing the data without writing code. This technical article describes it: [https://dlthub.com/docs/blog/MongoDB-dlt-Holistics](https://dlthub.com/docs/blog/MongoDB-dlt-Holistics)\n\n  \nWhat are your approaches to this problem?", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Easy way to model data from Mongo?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17659m7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697112029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you deal with using data from Mongo?  IME the data is always nested and needs to be flattened to use.  So do you flatten it in python, or in sql? or do you use something that skips the flat data requirements?  &lt;/p&gt;\n\n&lt;p&gt;We are currently playing with the idea of automatic unnesting and semantic modelling on top to enable analysing the data without writing code. This technical article describes it: &lt;a href=\"https://dlthub.com/docs/blog/MongoDB-dlt-Holistics\"&gt;https://dlthub.com/docs/blog/MongoDB-dlt-Holistics&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;What are your approaches to this problem?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jGEN9OFm6IxpaJTDe_7kViVHyYAO4wkq3xYbeKVqSHc.jpg?auto=webp&amp;s=f3270f1d29472d455066155750c702cd23b02a29", "width": 2693, "height": 1485}, "resolutions": [{"url": "https://external-preview.redd.it/jGEN9OFm6IxpaJTDe_7kViVHyYAO4wkq3xYbeKVqSHc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=124e5689c7e17fffd0ec326f9c69e86cf0119568", "width": 108, "height": 59}, {"url": "https://external-preview.redd.it/jGEN9OFm6IxpaJTDe_7kViVHyYAO4wkq3xYbeKVqSHc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2c115a2cf76cd8cb7008c1f7f04558f706001bfb", "width": 216, "height": 119}, {"url": "https://external-preview.redd.it/jGEN9OFm6IxpaJTDe_7kViVHyYAO4wkq3xYbeKVqSHc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=30864ec2f18c41e3d49bc38aeda7693d72f5b20b", "width": 320, "height": 176}, {"url": "https://external-preview.redd.it/jGEN9OFm6IxpaJTDe_7kViVHyYAO4wkq3xYbeKVqSHc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ccdc7ed9dc8f87d67b86e1768bde51460e98b3be", "width": 640, "height": 352}, {"url": "https://external-preview.redd.it/jGEN9OFm6IxpaJTDe_7kViVHyYAO4wkq3xYbeKVqSHc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c88cbcb9f20ad3223c021f61e0d0203cfc67337b", "width": 960, "height": 529}, {"url": "https://external-preview.redd.it/jGEN9OFm6IxpaJTDe_7kViVHyYAO4wkq3xYbeKVqSHc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5ef8cda761549d8cc64b02b1af700157b9b4dce4", "width": 1080, "height": 595}], "variants": {}, "id": "dY1Tyj6CFUjtPbkf11Mdzugrhaa5hN60x9WCS8uUcYQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17659m7", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17659m7/easy_way_to_model_data_from_mongo/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17659m7/easy_way_to_model_data_from_mongo/", "subreddit_subscribers": 133589, "created_utc": 1697112029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello there :)\n\nI would like to ask you for some career advice. Lastly, I am wondering what would be a better career path in terms of challenges in jobs, the possibility of developing skills, fun and enjoyment of work, future possibilities, and salary :)\n\nIn short, I will give you my background :)  \n\\- **1 year BI Analyst** \\- (SQL, Tableau, SSIS) - Mainly writing SQL queries and procedures, and over that building Tableau Dashboards\n\n\\- **4 years Data Engineer** \\- (Python, Airflow, MongoDB, SQL, Docker, S3, Kafka) - I worked on data pipeline, built easy APIs in FastAPI, and Flask, Designed some BI Models and fed them with Pipelines, Built some dashboards in Dash Framework, Did some small PoC on Databricks (unfortunately we needed to drop that project)\n\n\\- **10 months - Big Data Engineer** \\- Working mainly with Spark (PysPark), Hadoop, HDFS, Kafka, and HBase.\n\nAs you see I don't have too much experience with Cloud (only AWS S3).\n\n&amp;#x200B;\n\nIn my current company, we have mainly projects in Spark (mostly in Hadoop environment), and also we have a lot of projects in Snowflake.\n\nAnd I wonder what you think is a better road for data engineers? As you see I wrote a lot in Python, and tbh I enjoy it very much, and would say that I am very proficient and I write good quality code, I touched a lot of python parts, but from what I see more and more DE roles do not code to much, if yes than more like scripting, than developing high quality, well-tested frameworks, etc.  \nFor almost last year I have written in Spark - it's cool, but you know you don't need to much Python there - it's just a wrapper, so I feel like I am writing simple scripts  :D   \nSo going to the end I wanted to ask, do you think it's better go in the direction:\n\n1. Focus on spark, distributed systems, and try to get into Databricks projects (I would say Hadoop stack it's not so fun for me :D \n2. Go more into Snowflake projects and work maybe more on the side of data modeling, writing etls in python, and SQL to feed these models.\n\n&amp;#x200B;\n\nWhat's your opinion, and if I choose one of it what do you think would be great to learn, and what to seek in projects in terms of technologies etc?\n\n&amp;#x200B;\n\nBest,\n\nMartin\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_835lb23v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for DE Career advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1760tge", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697094581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there :)&lt;/p&gt;\n\n&lt;p&gt;I would like to ask you for some career advice. Lastly, I am wondering what would be a better career path in terms of challenges in jobs, the possibility of developing skills, fun and enjoyment of work, future possibilities, and salary :)&lt;/p&gt;\n\n&lt;p&gt;In short, I will give you my background :)&lt;br/&gt;\n- &lt;strong&gt;1 year BI Analyst&lt;/strong&gt; - (SQL, Tableau, SSIS) - Mainly writing SQL queries and procedures, and over that building Tableau Dashboards&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;4 years Data Engineer&lt;/strong&gt; - (Python, Airflow, MongoDB, SQL, Docker, S3, Kafka) - I worked on data pipeline, built easy APIs in FastAPI, and Flask, Designed some BI Models and fed them with Pipelines, Built some dashboards in Dash Framework, Did some small PoC on Databricks (unfortunately we needed to drop that project)&lt;/p&gt;\n\n&lt;p&gt;- &lt;strong&gt;10 months - Big Data Engineer&lt;/strong&gt; - Working mainly with Spark (PysPark), Hadoop, HDFS, Kafka, and HBase.&lt;/p&gt;\n\n&lt;p&gt;As you see I don&amp;#39;t have too much experience with Cloud (only AWS S3).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In my current company, we have mainly projects in Spark (mostly in Hadoop environment), and also we have a lot of projects in Snowflake.&lt;/p&gt;\n\n&lt;p&gt;And I wonder what you think is a better road for data engineers? As you see I wrote a lot in Python, and tbh I enjoy it very much, and would say that I am very proficient and I write good quality code, I touched a lot of python parts, but from what I see more and more DE roles do not code to much, if yes than more like scripting, than developing high quality, well-tested frameworks, etc.&lt;br/&gt;\nFor almost last year I have written in Spark - it&amp;#39;s cool, but you know you don&amp;#39;t need to much Python there - it&amp;#39;s just a wrapper, so I feel like I am writing simple scripts  :D&lt;br/&gt;\nSo going to the end I wanted to ask, do you think it&amp;#39;s better go in the direction:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Focus on spark, distributed systems, and try to get into Databricks projects (I would say Hadoop stack it&amp;#39;s not so fun for me :D &lt;/li&gt;\n&lt;li&gt;Go more into Snowflake projects and work maybe more on the side of data modeling, writing etls in python, and SQL to feed these models.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s your opinion, and if I choose one of it what do you think would be great to learn, and what to seek in projects in terms of technologies etc?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Best,&lt;/p&gt;\n\n&lt;p&gt;Martin&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1760tge", "is_robot_indexable": true, "report_reasons": null, "author": "Purple_Wrap9596", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1760tge/looking_for_de_career_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1760tge/looking_for_de_career_advice/", "subreddit_subscribers": 133589, "created_utc": 1697094581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI am trying to get an understanding from technical capabilities standpoint on what are some of the strengths and weaknesses of Azure Data Factory when compared to Informatica\u2019s Data Integration service on IDMC. Does ADF support both ETL and ELT like Informatica\u2019s Cloud Data Integration?", "author_fullname": "t2_4mdsqonb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strengths and weaknesses of ADF compared to Cloud Data Integration on Informatica Data Management Cloud (IDMC)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175svid", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697068650.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am trying to get an understanding from technical capabilities standpoint on what are some of the strengths and weaknesses of Azure Data Factory when compared to Informatica\u2019s Data Integration service on IDMC. Does ADF support both ETL and ELT like Informatica\u2019s Cloud Data Integration?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "175svid", "is_robot_indexable": true, "report_reasons": null, "author": "vrakshith28", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/175svid/strengths_and_weaknesses_of_adf_compared_to_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/175svid/strengths_and_weaknesses_of_adf_compared_to_cloud/", "subreddit_subscribers": 133589, "created_utc": 1697068650.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "No, this isn't a post about job interviews. This is related to some research I'm doing on data practitioners and their career journeys. \n\nFull disclosure: I work for a vendor (I know, ick).\n\nWe're doing some interviews of our users to feature on our community. Not about how they use our product, but about their personal story, We can talk about data stacks all day, but this isn't really about that! \n\nIf you were getting interviewed for an article or podcast, what questions would you WANT to be asked? What do you want people to know about you, your career journey, and professional accomplishments? What fun facts or personal stories would you be comfortable chatting about?\n\nAnd from the reader's perspective -- what would you want to know about your peers? What's interesting to you? \n\nI'd love to learn more. Thanks for entertaining my question. ", "author_fullname": "t2_kc8skjdm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\"Meet a Data Engineer\" interview questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176ck92", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697131927.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;No, this isn&amp;#39;t a post about job interviews. This is related to some research I&amp;#39;m doing on data practitioners and their career journeys. &lt;/p&gt;\n\n&lt;p&gt;Full disclosure: I work for a vendor (I know, ick).&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re doing some interviews of our users to feature on our community. Not about how they use our product, but about their personal story, We can talk about data stacks all day, but this isn&amp;#39;t really about that! &lt;/p&gt;\n\n&lt;p&gt;If you were getting interviewed for an article or podcast, what questions would you WANT to be asked? What do you want people to know about you, your career journey, and professional accomplishments? What fun facts or personal stories would you be comfortable chatting about?&lt;/p&gt;\n\n&lt;p&gt;And from the reader&amp;#39;s perspective -- what would you want to know about your peers? What&amp;#39;s interesting to you? &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to learn more. Thanks for entertaining my question. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "176ck92", "is_robot_indexable": true, "report_reasons": null, "author": "funkthejadeneon", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176ck92/meet_a_data_engineer_interview_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176ck92/meet_a_data_engineer_interview_questions/", "subreddit_subscribers": 133589, "created_utc": 1697131927.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I graduated in 2023 and am working an analytics engineering job at a mid sized company. My manager is the worst manager you can think of, she consistently goes on vacations, has declined our weekly 1:1\u2019s less than 5 mins before the start or does not show up to them for the past 3 months, forgets group meetings, and does not give me any work to do. I have been doing almost nothing for the past couple of months and no one has noticed.\n\nThese past weeks, my manager gave me little context on a project they were working on because they were getting pressure to complete it by their boss. They gave it to me because they have 0 technical ability and mind you, they are a new manager with analytics engineering experience before. I have 0 context on the work and now the VP is messaging me about progress and I\u2019m the SME on a project I know nothing of. I message my manager consistently for guidance and they never respond or respond with simple \u201cgreat\u201d, \u201cask xyz\u201d, \u201csounds good.\u201d\n\nThis is completely frustrating. I have learned 0 from this job and I have been working here for 7 months. I am wasting my time. What do i do?", "author_fullname": "t2_qeq05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Horrible Manager as New Grad", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176caqi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697131263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I graduated in 2023 and am working an analytics engineering job at a mid sized company. My manager is the worst manager you can think of, she consistently goes on vacations, has declined our weekly 1:1\u2019s less than 5 mins before the start or does not show up to them for the past 3 months, forgets group meetings, and does not give me any work to do. I have been doing almost nothing for the past couple of months and no one has noticed.&lt;/p&gt;\n\n&lt;p&gt;These past weeks, my manager gave me little context on a project they were working on because they were getting pressure to complete it by their boss. They gave it to me because they have 0 technical ability and mind you, they are a new manager with analytics engineering experience before. I have 0 context on the work and now the VP is messaging me about progress and I\u2019m the SME on a project I know nothing of. I message my manager consistently for guidance and they never respond or respond with simple \u201cgreat\u201d, \u201cask xyz\u201d, \u201csounds good.\u201d&lt;/p&gt;\n\n&lt;p&gt;This is completely frustrating. I have learned 0 from this job and I have been working here for 7 months. I am wasting my time. What do i do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176caqi", "is_robot_indexable": true, "report_reasons": null, "author": "therealhm2", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176caqi/horrible_manager_as_new_grad/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176caqi/horrible_manager_as_new_grad/", "subreddit_subscribers": 133589, "created_utc": 1697131263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm using MySQL as a database and data warehouse. Weird, I know, but it mostly works for our small team and use cases. We're currently scheduling our MySQL jobs with a low code tool, which has never been ideal, but has become untenable because the complexity of our data model has grown.\n\nI've been testing out DBT Core (v1.1.5 + MySQL plugin v1.1.0) and it is working well in our MySQL db but DBT Cloud doesn't support it.\n\nI need a better solution  for searchability, scheduling, dependency tracking, and testing. I'm willing the replace DBT or host it elsewhere. I'm willing to consider migrating databases as a last resort, but hoping for an easier solution. My goal is to minimize complexity and tool sprawl. What should I consider? \n\nThanks!", "author_fullname": "t2_aindslqn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT alternative for MySQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17688yu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697120770.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using MySQL as a database and data warehouse. Weird, I know, but it mostly works for our small team and use cases. We&amp;#39;re currently scheduling our MySQL jobs with a low code tool, which has never been ideal, but has become untenable because the complexity of our data model has grown.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been testing out DBT Core (v1.1.5 + MySQL plugin v1.1.0) and it is working well in our MySQL db but DBT Cloud doesn&amp;#39;t support it.&lt;/p&gt;\n\n&lt;p&gt;I need a better solution  for searchability, scheduling, dependency tracking, and testing. I&amp;#39;m willing the replace DBT or host it elsewhere. I&amp;#39;m willing to consider migrating databases as a last resort, but hoping for an easier solution. My goal is to minimize complexity and tool sprawl. What should I consider? &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17688yu", "is_robot_indexable": true, "report_reasons": null, "author": "Wide_Interest_5887", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17688yu/dbt_alternative_for_mysql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17688yu/dbt_alternative_for_mysql/", "subreddit_subscribers": 133589, "created_utc": 1697120770.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I read this in the book Designing Data-Intensive Applications: \"The sort merge in Unix is arguably a better sorting implementation than most programming languages have in their standard libraries (which do not spill to disk and do not use multiple threads)\".   \n\nI know Unix uses external sorting to spill to disk, but what does it mean that other libraries \"do not spill to disk\"? Like, if the dataset is large enough (like 2 TB) and can't fit into memory, how could they not spill to disk? Or am I understanding this wrong? Thanks.", "author_fullname": "t2_szomhuik", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "External Sort I/O in Unix v.s. in Other Libraries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176837s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697120348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read this in the book Designing Data-Intensive Applications: &amp;quot;The sort merge in Unix is arguably a better sorting implementation than most programming languages have in their standard libraries (which do not spill to disk and do not use multiple threads)&amp;quot;.   &lt;/p&gt;\n\n&lt;p&gt;I know Unix uses external sorting to spill to disk, but what does it mean that other libraries &amp;quot;do not spill to disk&amp;quot;? Like, if the dataset is large enough (like 2 TB) and can&amp;#39;t fit into memory, how could they not spill to disk? Or am I understanding this wrong? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176837s", "is_robot_indexable": true, "report_reasons": null, "author": "TendMyOwnGarden", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176837s/external_sort_io_in_unix_vs_in_other_libraries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176837s/external_sort_io_in_unix_vs_in_other_libraries/", "subreddit_subscribers": 133589, "created_utc": 1697120348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m researching theoretical part since I\u2019m a mathematician - I really appreciate your opinion", "author_fullname": "t2_6yp3m1re", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which database engineering related conference/journal is your fav &amp; why?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1767uck", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697119682.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m researching theoretical part since I\u2019m a mathematician - I really appreciate your opinion&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1767uck", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Beyond-1144", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1767uck/which_database_engineering_related/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1767uck/which_database_engineering_related/", "subreddit_subscribers": 133589, "created_utc": 1697119682.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, first post here.\n\nI've seen a few ads for Weld which piqued my interest. Has anyone actually used it in anger for commercial workloads? I'm hoping someone can share some feedback on what it's like.\n\nI searched the sub but found nothing but a lone comment...\n\nhttps://weld.app/\nhttps://www.crunchbase.com/organization/weld", "author_fullname": "t2_eclsdgax6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Weld before?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1766xhh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697117088.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, first post here.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve seen a few ads for Weld which piqued my interest. Has anyone actually used it in anger for commercial workloads? I&amp;#39;m hoping someone can share some feedback on what it&amp;#39;s like.&lt;/p&gt;\n\n&lt;p&gt;I searched the sub but found nothing but a lone comment...&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://weld.app/\"&gt;https://weld.app/&lt;/a&gt;\n&lt;a href=\"https://www.crunchbase.com/organization/weld\"&gt;https://www.crunchbase.com/organization/weld&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1766xhh", "is_robot_indexable": true, "report_reasons": null, "author": "Silent_Ocelot3368", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1766xhh/has_anyone_used_weld_before/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1766xhh/has_anyone_used_weld_before/", "subreddit_subscribers": 133589, "created_utc": 1697117088.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi !   \nI am working on data ingestion and schema comparison tool. One of initial assumption is to use S3 as a lake for incoming files. I'd like to create Kafka stream to connect it with final destination (to simplify let's assume it is PostresSql DB).  \nI'd like to perform validation of the streamed messages based on precreated schema.   \nCould you please share your thoughts on potential solution for this problem ? I've read about Custom Single Message Transformations, but without wider experience with Kafka, it is hard for me to choose the best practice way.   \nThanks ", "author_fullname": "t2_9ndqvodu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kafka best practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17605w3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697091949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi !&lt;br/&gt;\nI am working on data ingestion and schema comparison tool. One of initial assumption is to use S3 as a lake for incoming files. I&amp;#39;d like to create Kafka stream to connect it with final destination (to simplify let&amp;#39;s assume it is PostresSql DB).&lt;br/&gt;\nI&amp;#39;d like to perform validation of the streamed messages based on precreated schema.&lt;br/&gt;\nCould you please share your thoughts on potential solution for this problem ? I&amp;#39;ve read about Custom Single Message Transformations, but without wider experience with Kafka, it is hard for me to choose the best practice way.&lt;br/&gt;\nThanks &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17605w3", "is_robot_indexable": true, "report_reasons": null, "author": "ProfessionalPin7939", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17605w3/kafka_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17605w3/kafka_best_practices/", "subreddit_subscribers": 133589, "created_utc": 1697091949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have bee through many blogs, posts and videos regarding which one to choose but still confused. I am currently an ETL Developer having experience in Traditional ETL tools and SQL. I want to move to Big data and cloud related roles where I will be working on Spark, AWS Glue, S3, etc.\n\nAmong Solutions Architect Associate vs Developer Associate, studying for which cert will help me more in my journey to transition to the above mentioned roles?", "author_fullname": "t2_ht9x5dmh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Solutions Architect or Developer associate for Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175zm51", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697089864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have bee through many blogs, posts and videos regarding which one to choose but still confused. I am currently an ETL Developer having experience in Traditional ETL tools and SQL. I want to move to Big data and cloud related roles where I will be working on Spark, AWS Glue, S3, etc.&lt;/p&gt;\n\n&lt;p&gt;Among Solutions Architect Associate vs Developer Associate, studying for which cert will help me more in my journey to transition to the above mentioned roles?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "175zm51", "is_robot_indexable": true, "report_reasons": null, "author": "kaachejl", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/175zm51/aws_solutions_architect_or_developer_associate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/175zm51/aws_solutions_architect_or_developer_associate/", "subreddit_subscribers": 133589, "created_utc": 1697089864.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have several config tables that represent jobs to be run. We have a dev, test, stage and prod environment and have multiple teams working in these environments at different paces. For example, one team may start in dev before another team but may deploy to test after.\n\nTeams create entries in the config table in dev with incrementing ids and the the ids are used as foreign keys as well to connect the config tables to fully represent each job. The issue is that the INSERT statements into the config tables are added to code and then deployed to other environments but the ids may have to be different in different environments if another team has already used the same ID in another environment. This results in the foreign keys in the INSERT statement not being correct. How is this situation typically handled?", "author_fullname": "t2_la443gmcs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Consistency of surrogate key for config tables in different environments", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175xecm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697082025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have several config tables that represent jobs to be run. We have a dev, test, stage and prod environment and have multiple teams working in these environments at different paces. For example, one team may start in dev before another team but may deploy to test after.&lt;/p&gt;\n\n&lt;p&gt;Teams create entries in the config table in dev with incrementing ids and the the ids are used as foreign keys as well to connect the config tables to fully represent each job. The issue is that the INSERT statements into the config tables are added to code and then deployed to other environments but the ids may have to be different in different environments if another team has already used the same ID in another environment. This results in the foreign keys in the INSERT statement not being correct. How is this situation typically handled?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "175xecm", "is_robot_indexable": true, "report_reasons": null, "author": "No_Willingness2818", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/175xecm/consistency_of_surrogate_key_for_config_tables_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/175xecm/consistency_of_surrogate_key_for_config_tables_in/", "subreddit_subscribers": 133589, "created_utc": 1697082025.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for a book or blog or resource website to learn about Google big query \n\nSpecifically I want to learn about its data architecture. I know databricks has a lot of resources for medellion architecture in databricks , delta lake houses , etc. looking for similar resources for big query\n\nThanks!", "author_fullname": "t2_lkm6psdhm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Bigquery resource to learn data engineering/data warehouse architecture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175pp6l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697060255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a book or blog or resource website to learn about Google big query &lt;/p&gt;\n\n&lt;p&gt;Specifically I want to learn about its data architecture. I know databricks has a lot of resources for medellion architecture in databricks , delta lake houses , etc. looking for similar resources for big query&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "175pp6l", "is_robot_indexable": true, "report_reasons": null, "author": "BigFix7421", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/175pp6l/google_bigquery_resource_to_learn_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/175pp6l/google_bigquery_resource_to_learn_data/", "subreddit_subscribers": 133589, "created_utc": 1697060255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, so I have a website that was created in WordPress, and as we know, the backend or database is in PHPMyAdmin. We want to extract that data and store it in BigQuery. My website is hosted using HostPapa. I am using python code to do it. Can anyone guide me on what to do and the step to do it?", "author_fullname": "t2_dfjkwfqn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Create a pipeline to store data from phpmyadmin to BigQuery", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1761x4f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697099189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, so I have a website that was created in WordPress, and as we know, the backend or database is in PHPMyAdmin. We want to extract that data and store it in BigQuery. My website is hosted using HostPapa. I am using python code to do it. Can anyone guide me on what to do and the step to do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1761x4f", "is_robot_indexable": true, "report_reasons": null, "author": "Boss2508", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1761x4f/create_a_pipeline_to_store_data_from_phpmyadmin/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1761x4f/create_a_pipeline_to_store_data_from_phpmyadmin/", "subreddit_subscribers": 133589, "created_utc": 1697099189.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}