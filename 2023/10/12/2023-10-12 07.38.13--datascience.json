{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My team and managers are so easy to be with. Very grateful for that. The pay is okay. 150k/yr TC in Midwest. Hard for me to make a switch given how much I am appreciated. I almost feel spoiled when it comes to flexibility. I have overachiever tendency and the pace is so slow in adopting my ML models.\n\nI am the \u201clead\u201d/senior data scientist in an R&amp;D supporting scientists decision making with machine learning. Importantly, I am in a huge multinational consumer product company and I am not in the Data science organization, I bridge between the two and the data science expert on the team.\n\n  I have developed the domain expertise and I have  a PhD in  an applied computational field with 5 years experience . I am not as challenged with getting deeper into complex stats, I have been really honing the soft skills of communication, influencing etc so getting comfortable in a senior role. Also I have been growing as a ML engineer building my own pipelines and deploying my models on prem server that they bought for me.\n\nI am not sure how greener it is on the other side, how do senior folks approach deciding when to move on? Any input is much appreciated.", "author_fullname": "t2_91esrqhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is being appreciated and team fit as a factor to stay in a role with average salary given slow adoption of data science solutions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175caah", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 68, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 68, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697025555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team and managers are so easy to be with. Very grateful for that. The pay is okay. 150k/yr TC in Midwest. Hard for me to make a switch given how much I am appreciated. I almost feel spoiled when it comes to flexibility. I have overachiever tendency and the pace is so slow in adopting my ML models.&lt;/p&gt;\n\n&lt;p&gt;I am the \u201clead\u201d/senior data scientist in an R&amp;amp;D supporting scientists decision making with machine learning. Importantly, I am in a huge multinational consumer product company and I am not in the Data science organization, I bridge between the two and the data science expert on the team.&lt;/p&gt;\n\n&lt;p&gt;I have developed the domain expertise and I have  a PhD in  an applied computational field with 5 years experience . I am not as challenged with getting deeper into complex stats, I have been really honing the soft skills of communication, influencing etc so getting comfortable in a senior role. Also I have been growing as a ML engineer building my own pipelines and deploying my models on prem server that they bought for me.&lt;/p&gt;\n\n&lt;p&gt;I am not sure how greener it is on the other side, how do senior folks approach deciding when to move on? Any input is much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175caah", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent_Trust2569", "discussion_type": null, "num_comments": 72, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175caah/how_important_is_being_appreciated_and_team_fit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175caah/how_important_is_being_appreciated_and_team_fit/", "subreddit_subscribers": 1081208, "created_utc": 1697025555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Let\u2019s say you get an ad hoc task that will take an hour or two. You run an sql query extract the data from the db dump into .csv spin up a quick Jupyter notebook and be done with it. But what happens after?\n\n\nHow would you store/archive this project?\nCommitting Jupyter notebooks to a repo? Now you have bunch of html in your codebase. Code that\u2019s impossible to pull request/review that also bloats the repo. If you clear the outputs of the notebook to reduce the notebook size it instantly becomes useless for later review because now you have to run it again to see what was it about. If you need to run it again you need the exact same data. Now you need to store the data snippet somewhere. Where do you store that data snipped for future reproducibility? The project is too small to spin up DVC or MLFlow so what do you do with it?\n\nWhat tool / workflow am I missing here?\n\nI keep hearning notebooks are great for experiments but I don\u2019t see what the workflow is like for these experiments\u2026\n\nEDIT: Based on the responses there is no solution to any of this chaos that covers both the code and the data... you either end up over-engineering the experiment or dumping it somewhere and hoping that a well written readme will do the job.  There has to be a better way..", "author_fullname": "t2_13hucc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you store your ad hoc experiments?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175jep1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 38, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 38, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697083575.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697044442.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let\u2019s say you get an ad hoc task that will take an hour or two. You run an sql query extract the data from the db dump into .csv spin up a quick Jupyter notebook and be done with it. But what happens after?&lt;/p&gt;\n\n&lt;p&gt;How would you store/archive this project?\nCommitting Jupyter notebooks to a repo? Now you have bunch of html in your codebase. Code that\u2019s impossible to pull request/review that also bloats the repo. If you clear the outputs of the notebook to reduce the notebook size it instantly becomes useless for later review because now you have to run it again to see what was it about. If you need to run it again you need the exact same data. Now you need to store the data snippet somewhere. Where do you store that data snipped for future reproducibility? The project is too small to spin up DVC or MLFlow so what do you do with it?&lt;/p&gt;\n\n&lt;p&gt;What tool / workflow am I missing here?&lt;/p&gt;\n\n&lt;p&gt;I keep hearning notebooks are great for experiments but I don\u2019t see what the workflow is like for these experiments\u2026&lt;/p&gt;\n\n&lt;p&gt;EDIT: Based on the responses there is no solution to any of this chaos that covers both the code and the data... you either end up over-engineering the experiment or dumping it somewhere and hoping that a well written readme will do the job.  There has to be a better way..&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175jep1", "is_robot_indexable": true, "report_reasons": null, "author": "every_other_freackle", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175jep1/how_do_you_store_your_ad_hoc_experiments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175jep1/how_do_you_store_your_ad_hoc_experiments/", "subreddit_subscribers": 1081208, "created_utc": 1697044442.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Grid search is a basic parameter that is very slow when dealing with huge datasets. What are other tuning algorithms that are faster and perform equally as well.", "author_fullname": "t2_hf2e17ayz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are grid search alternatives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175gyx0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697038513.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Grid search is a basic parameter that is very slow when dealing with huge datasets. What are other tuning algorithms that are faster and perform equally as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175gyx0", "is_robot_indexable": true, "report_reasons": null, "author": "Pineapple_throw_105", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175gyx0/what_are_grid_search_alternatives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175gyx0/what_are_grid_search_alternatives/", "subreddit_subscribers": 1081208, "created_utc": 1697038513.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a PhD in biology and my next step in the pipeline is a bioinformatics post doc while studying for a DS course (IBM Data Science Professionnal Certificate) on the side.\n\nI know certificates have become insufficient to get an entry level jobs in Data Science (and tech in general) now that the market has cooled down from the pandemic craze, but I was wondering if having an advanced degree in another field and minor experience from my post doc (mostly specific data analysis tools for bioinformatics, a lot of R, and probably very minimal Python) would really be helpful or if companies don't care about non-CS scientific education ?\n\nWhat about getting an online MS in Data Science, would that be required ? How difficult would that be for someone with a weak background in statistics ?\n\nI'm interested in Data Science and I'm looking to expand my skills to give myself more options but while the certificate is short and could be useful as a biotech scientist, I wouldn't want to pursue more formal education if it doesn't really give me more options other than a false hope and wasted time applying for DS positions I can't get.", "author_fullname": "t2_pxn8nina", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any value to an unrelated advanced degree to get into DS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175nbtg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697054404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a PhD in biology and my next step in the pipeline is a bioinformatics post doc while studying for a DS course (IBM Data Science Professionnal Certificate) on the side.&lt;/p&gt;\n\n&lt;p&gt;I know certificates have become insufficient to get an entry level jobs in Data Science (and tech in general) now that the market has cooled down from the pandemic craze, but I was wondering if having an advanced degree in another field and minor experience from my post doc (mostly specific data analysis tools for bioinformatics, a lot of R, and probably very minimal Python) would really be helpful or if companies don&amp;#39;t care about non-CS scientific education ?&lt;/p&gt;\n\n&lt;p&gt;What about getting an online MS in Data Science, would that be required ? How difficult would that be for someone with a weak background in statistics ?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested in Data Science and I&amp;#39;m looking to expand my skills to give myself more options but while the certificate is short and could be useful as a biotech scientist, I wouldn&amp;#39;t want to pursue more formal education if it doesn&amp;#39;t really give me more options other than a false hope and wasted time applying for DS positions I can&amp;#39;t get.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175nbtg", "is_robot_indexable": true, "report_reasons": null, "author": "childofaether", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175nbtg/any_value_to_an_unrelated_advanced_degree_to_get/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175nbtg/any_value_to_an_unrelated_advanced_degree_to_get/", "subreddit_subscribers": 1081208, "created_utc": 1697054404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone,\n\nI am hired by a government based organization to work as a data scientist. I currently have 1 year of full time experience and 2 years part time before graduation. My project is ending in about 2 months and I have a budget of around \u00a35,000 that I can use for personal and professional development. I have to complete the bookings before the end of the project, although actual training/conference can take place beyond the end date. \n\nWorking in an applied research role, I can spend it on conferences, for training opportunities or certification exams. I want to ask you guys for your opinions about what would be good things to spend this budget on, considering I am at an early stage in my career. ", "author_fullname": "t2_caxt5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to spend \u00a35k budget for professional development in Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175ptfa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697060557.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am hired by a government based organization to work as a data scientist. I currently have 1 year of full time experience and 2 years part time before graduation. My project is ending in about 2 months and I have a budget of around \u00a35,000 that I can use for personal and professional development. I have to complete the bookings before the end of the project, although actual training/conference can take place beyond the end date. &lt;/p&gt;\n\n&lt;p&gt;Working in an applied research role, I can spend it on conferences, for training opportunities or certification exams. I want to ask you guys for your opinions about what would be good things to spend this budget on, considering I am at an early stage in my career. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175ptfa", "is_robot_indexable": true, "report_reasons": null, "author": "greathassan", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175ptfa/where_to_spend_5k_budget_for_professional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175ptfa/where_to_spend_5k_budget_for_professional/", "subreddit_subscribers": 1081208, "created_utc": 1697060557.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "[https://github.com/jinyus/related\\_post\\_gen](https://github.com/jinyus/related_post_gen)\n\nhttps://preview.redd.it/ii0dm13dymtb1.png?width=849&amp;format=png&amp;auto=webp&amp;s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f", "author_fullname": "t2_6dtot6beo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Julia leads Rust, Zig, Go and Java in data processing benchmark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ii0dm13dymtb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 111, "x": 108, "u": "https://preview.redd.it/ii0dm13dymtb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=29389ec319b46acce2f70256fb514f3b12ac60af"}, {"y": 223, "x": 216, "u": "https://preview.redd.it/ii0dm13dymtb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=edef1a8be72ea4a5076387fd93b5a248f708a697"}, {"y": 331, "x": 320, "u": "https://preview.redd.it/ii0dm13dymtb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c3945a0f9a2a5d58f5286afb0c20ee19e015e331"}, {"y": 663, "x": 640, "u": "https://preview.redd.it/ii0dm13dymtb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=04f3394bfbd28c4fab37f8d5091932b4e8a4c804"}], "s": {"y": 880, "x": 849, "u": "https://preview.redd.it/ii0dm13dymtb1.png?width=849&amp;format=png&amp;auto=webp&amp;s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f"}, "id": "ii0dm13dymtb1"}}, "name": "t3_175oh0k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/W2Naxk_8dd2GS0UHXIBaEkjm_3OxA5-KTZjS66eWAIs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697057221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/jinyus/related_post_gen\"&gt;https://github.com/jinyus/related_post_gen&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ii0dm13dymtb1.png?width=849&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f\"&gt;https://preview.redd.it/ii0dm13dymtb1.png?width=849&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=6cd6064d23e26958abe65cdf48e73e688f3d5f4f&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175oh0k", "is_robot_indexable": true, "report_reasons": null, "author": "Fincho64", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175oh0k/julia_leads_rust_zig_go_and_java_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175oh0k/julia_leads_rust_zig_go_and_java_in_data/", "subreddit_subscribers": 1081208, "created_utc": 1697057221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a mathematical education and programming experience, but I have not done data science in the wild. I have a situation at work that could be an opportunity to practice model-building. \n\nI work on a team of \\~50 developers, and we have a subjective belief that some tickets stay in code review much longer than others. I can get the duration of a merge request using the Gitlab API, and I can get information about the tickets from exporting issues from Jira. \n\nI think there's a chance that some of the columns in our Jira data are good predictors of the duration, thanks to how we label issues. But it might also be the case that the title/description are natural language predictors of the duration, and so I might need to figure out how to do a text embedding or bag-of-words model as a preprocessing step.\n\nWhen you have one value (duration) that you're trying to make predictions about, but you don't have any a priori guesses about what columns are going to be predictive, what tools do you reach for? Is this a good task to learn TensorFlow for perhaps, or is there something less powerful/complex in the ML ecosystem I should look at first?", "author_fullname": "t2_c9pbqokh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predicting what features lead to long wait times", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175qvkx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697063226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a mathematical education and programming experience, but I have not done data science in the wild. I have a situation at work that could be an opportunity to practice model-building. &lt;/p&gt;\n\n&lt;p&gt;I work on a team of ~50 developers, and we have a subjective belief that some tickets stay in code review much longer than others. I can get the duration of a merge request using the Gitlab API, and I can get information about the tickets from exporting issues from Jira. &lt;/p&gt;\n\n&lt;p&gt;I think there&amp;#39;s a chance that some of the columns in our Jira data are good predictors of the duration, thanks to how we label issues. But it might also be the case that the title/description are natural language predictors of the duration, and so I might need to figure out how to do a text embedding or bag-of-words model as a preprocessing step.&lt;/p&gt;\n\n&lt;p&gt;When you have one value (duration) that you&amp;#39;re trying to make predictions about, but you don&amp;#39;t have any a priori guesses about what columns are going to be predictive, what tools do you reach for? Is this a good task to learn TensorFlow for perhaps, or is there something less powerful/complex in the ML ecosystem I should look at first?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175qvkx", "is_robot_indexable": true, "report_reasons": null, "author": "Bulky_Gap_7072", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175qvkx/predicting_what_features_lead_to_long_wait_times/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175qvkx/predicting_what_features_lead_to_long_wait_times/", "subreddit_subscribers": 1081208, "created_utc": 1697063226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a classifier model. I would need the predicted probabilities for production purposes (on unseen data), as the probability score is of more concern in the project. Should I consider just the raw probabilities, as predicted, or should I make some sort of adjustment with the optimal threshold (for the trained model) and then consider the adjusted probabilities? \n\nFor example, suppose I get a probability as 0.55. Which means, in face value, that there's more likelihood of it being 1 than 0. But my model says optimal threshold is 0.6. Which means model still wants to predict it to be 0, being more conservative in predicting 1. However since I'm concerned with ONLY the probability, isnt that deceiving or wrong? \n\nAny suggestions are appreciated.", "author_fullname": "t2_28h3sgt7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predicted raw probabilities or threshold-adjusted ones?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175errf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697032992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a classifier model. I would need the predicted probabilities for production purposes (on unseen data), as the probability score is of more concern in the project. Should I consider just the raw probabilities, as predicted, or should I make some sort of adjustment with the optimal threshold (for the trained model) and then consider the adjusted probabilities? &lt;/p&gt;\n\n&lt;p&gt;For example, suppose I get a probability as 0.55. Which means, in face value, that there&amp;#39;s more likelihood of it being 1 than 0. But my model says optimal threshold is 0.6. Which means model still wants to predict it to be 0, being more conservative in predicting 1. However since I&amp;#39;m concerned with ONLY the probability, isnt that deceiving or wrong? &lt;/p&gt;\n\n&lt;p&gt;Any suggestions are appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175errf", "is_robot_indexable": true, "report_reasons": null, "author": "oblivious_horizon", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175errf/predicted_raw_probabilities_or_thresholdadjusted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175errf/predicted_raw_probabilities_or_thresholdadjusted/", "subreddit_subscribers": 1081208, "created_utc": 1697032992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hi everyone,\n\nI\u2019m thrilled to share a prototype we've been tirelessly working on.\n\nWe are developing a virtualization environment for applications, specifically tailored to engineers, designers, data scientists, and researchers.\n\nIn a nutshell, our platform enables users to run cloud-hosted desktop apps from any device, making it appear as if the applications are installed on their local machines, while they're actually operating on a remote server. The ultimate goal is to obliterate barriers between local and cloud execution, especially for compute-intensive workloads, thereby allowing seamless usage of High-Performance Computing software on the cloud with the scalability to adjust computing resources as per necessity.\n\nWe\u2019re here to solicit your invaluable feedback on our product video demo. Your insights will not only help us identify any blind spots and enhance our solution but also better understand the needs and preferences of our potential user base.\n\n\ud83d\udcfd \\[[https://youtu.be/QR8FWRnPrXM?feature=shared\\]](https://youtu.be/QR8FWRnPrXM?feature=shared])\n\nWe're eagerly awaiting your thoughts and appreciate you taking the time to help us refine our product!\n\nThank you! :)", "author_fullname": "t2_qbio8o1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[vilays] Prototype Video Demo - Any Feedback from Data Scientists?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175zeth", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697089066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m thrilled to share a prototype we&amp;#39;ve been tirelessly working on.&lt;/p&gt;\n\n&lt;p&gt;We are developing a virtualization environment for applications, specifically tailored to engineers, designers, data scientists, and researchers.&lt;/p&gt;\n\n&lt;p&gt;In a nutshell, our platform enables users to run cloud-hosted desktop apps from any device, making it appear as if the applications are installed on their local machines, while they&amp;#39;re actually operating on a remote server. The ultimate goal is to obliterate barriers between local and cloud execution, especially for compute-intensive workloads, thereby allowing seamless usage of High-Performance Computing software on the cloud with the scalability to adjust computing resources as per necessity.&lt;/p&gt;\n\n&lt;p&gt;We\u2019re here to solicit your invaluable feedback on our product video demo. Your insights will not only help us identify any blind spots and enhance our solution but also better understand the needs and preferences of our potential user base.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcfd [&lt;a href=\"https://youtu.be/QR8FWRnPrXM?feature=shared%5D\"&gt;https://youtu.be/QR8FWRnPrXM?feature=shared]&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re eagerly awaiting your thoughts and appreciate you taking the time to help us refine our product!&lt;/p&gt;\n\n&lt;p&gt;Thank you! :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/uGsE-QcM0f_EKn1Uf9rclhFwvIqT9XcSQjGyvhy6WOs.jpg?auto=webp&amp;s=dc0d2c2bb837427971f886e48c8c9a2b867be79a", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/uGsE-QcM0f_EKn1Uf9rclhFwvIqT9XcSQjGyvhy6WOs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=eed36e716881ca51576ca0cabdba292bab067ba1", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/uGsE-QcM0f_EKn1Uf9rclhFwvIqT9XcSQjGyvhy6WOs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fa590676b4dcaced3024f76f912f88b63e70a525", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/uGsE-QcM0f_EKn1Uf9rclhFwvIqT9XcSQjGyvhy6WOs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=78d732b3ea4e332e43f23a2902c2f25f63306214", "width": 320, "height": 240}], "variants": {}, "id": "MzqkoxBW4_w9DYNpY8kVtsyYUtD_tGam9rfuazJhkbg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175zeth", "is_robot_indexable": true, "report_reasons": null, "author": "aaron-cesaro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175zeth/vilays_prototype_video_demo_any_feedback_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175zeth/vilays_prototype_video_demo_any_feedback_from/", "subreddit_subscribers": 1081208, "created_utc": 1697089066.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Guys,\n\nIs there a way to integrate SHAP with deep reinforcement learning agent ? I am using the FINRL library on ensemble stock trading , and trying to use SHAP with on it. But i hardly find any information or tutorial on it. \n\n&amp;#x200B;\n\nThanks. ", "author_fullname": "t2_gqmgvnn0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SHAP Deep Reinforcement Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175x92z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697081538.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;Is there a way to integrate SHAP with deep reinforcement learning agent ? I am using the FINRL library on ensemble stock trading , and trying to use SHAP with on it. But i hardly find any information or tutorial on it. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175x92z", "is_robot_indexable": true, "report_reasons": null, "author": "ProductOk7316", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175x92z/shap_deep_reinforcement_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175x92z/shap_deep_reinforcement_learning/", "subreddit_subscribers": 1081208, "created_utc": 1697081538.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a 2Mio x 1139 dataset (huge right) and ive spent the whole day trying to load and work with in r (package data.table, function fread). It loads the data pretty quickly, in 1-2 minutes I'd say. I wanna loop over the data (or use lapply or something similar to gain efficiency). My function is fairly simple though, but the dataset is just huge. And then it runs and runs and runs, and half an hour goes by and it still runns. I AM SO AFRAID OF THE ''SESSION CRASHED''!\n\nDo you guys have any tips on dealing with such datasets and am i guaranteed if i leave the loop running over night, that it wont crash? Can I have trust in R? Are there any measures I can take to support R with its looping and looping and looping?\n\nP.S. i sadly mustn't split the dataset. \n\nThanks a lot, i wish you nothing but simple datasets. ", "author_fullname": "t2_3x05wl5n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "R-SESSION CRASHING-PHOBIA", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175mipy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697052333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 2Mio x 1139 dataset (huge right) and ive spent the whole day trying to load and work with in r (package data.table, function fread). It loads the data pretty quickly, in 1-2 minutes I&amp;#39;d say. I wanna loop over the data (or use lapply or something similar to gain efficiency). My function is fairly simple though, but the dataset is just huge. And then it runs and runs and runs, and half an hour goes by and it still runns. I AM SO AFRAID OF THE &amp;#39;&amp;#39;SESSION CRASHED&amp;#39;&amp;#39;!&lt;/p&gt;\n\n&lt;p&gt;Do you guys have any tips on dealing with such datasets and am i guaranteed if i leave the loop running over night, that it wont crash? Can I have trust in R? Are there any measures I can take to support R with its looping and looping and looping?&lt;/p&gt;\n\n&lt;p&gt;P.S. i sadly mustn&amp;#39;t split the dataset. &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot, i wish you nothing but simple datasets. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175mipy", "is_robot_indexable": true, "report_reasons": null, "author": "aesthetic-mango", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175mipy/rsession_crashingphobia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175mipy/rsession_crashingphobia/", "subreddit_subscribers": 1081208, "created_utc": 1697052333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for a pretty big Aerospace manufacturing company where my job title is 'Digital Engineer'. What this actually is, is a mix of data analytics and software engineering in PHP and C#. However, quite a lot of my work revolves around the transfer of Excel-based operations throughout the company to more efficient mediums. I can't disclose specifics about my current project but it involves producing a web form for our engineers to log parts into, and a big part of this project is scanning through the old Excel sheets looking for, and removing duplicate entries.\n\nI would of course like to use Python's Pandas/Polars libraries to automate a lot of my work, but due to the high-security nature of my work, I cannot pip install any packages or install most open source software.\n\nMy question is, can I automate much of my project work with a standard installation of Python or SQL Server? We also use some corporate standard software called Thingworx, but I haven't really been exposed to it yet.", "author_fullname": "t2_c4tdx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Security measures at my workplace", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175q00o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697061027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a pretty big Aerospace manufacturing company where my job title is &amp;#39;Digital Engineer&amp;#39;. What this actually is, is a mix of data analytics and software engineering in PHP and C#. However, quite a lot of my work revolves around the transfer of Excel-based operations throughout the company to more efficient mediums. I can&amp;#39;t disclose specifics about my current project but it involves producing a web form for our engineers to log parts into, and a big part of this project is scanning through the old Excel sheets looking for, and removing duplicate entries.&lt;/p&gt;\n\n&lt;p&gt;I would of course like to use Python&amp;#39;s Pandas/Polars libraries to automate a lot of my work, but due to the high-security nature of my work, I cannot pip install any packages or install most open source software.&lt;/p&gt;\n\n&lt;p&gt;My question is, can I automate much of my project work with a standard installation of Python or SQL Server? We also use some corporate standard software called Thingworx, but I haven&amp;#39;t really been exposed to it yet.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175q00o", "is_robot_indexable": true, "report_reasons": null, "author": "EncryptedMyst", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175q00o/security_measures_at_my_workplace/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175q00o/security_measures_at_my_workplace/", "subreddit_subscribers": 1081208, "created_utc": 1697061027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For the below Question: I have written a SQL query but that query not giving me the right answer although the second code (not mine ) is also fundamentally the same (as per my knowledge ), but that code is showing right output. Can someone please tell why  ?  \n\n\n \n\nTable: Weather\n\n\\+---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | recordDate    | date    | | temperature   | int     | +---------------+---------+ id is the column with unique values for this table. This table contains information about the temperature on a certain day. \n\nWrite a solution to find all dates' Id  \n with higher temperatures compared to its previous dates (yesterday).\n\nReturn the result table in **any order**.\n\nThe result format is in the following example.\n\n**Example 1:**\n\n**Input:**  Weather table: +----+------------+-------------+ | id | recordDate | temperature | +----+------------+-------------+ | 1  | 2015-01-01 | 10          | | 2  | 2015-01-02 | 25          | | 3  | 2015-01-03 | 20          | | 4  | 2015-01-04 | 30          | +----+------------+-------------+ **Output:**  \\+----+ | id | +----+ | 2  | | 4  | +----+ **Explanation:**  In 2015-01-02, the temperature was higher than the previous day (10 -&gt; 25). In 2015-01-04, the temperature was higher than the previous day (20 -&gt; 30). \n\n&amp;#x200B;\n\nMy Code : \n\nselect \u00a0cw1.id from Weather as cw1 inner join Weather as pw2 on cw1.id \u00a0= pw2.id  \nwhere datediff(cw1.recordDate, pw2.recordDate) = 1 and cw1.temperature &gt; pw2.temperature  \n\n\n2nd one : \n\n  \nSELECT w1.id  \nFROM Weather w1, Weather w2  \nWHERE DATEDIFF(w1.recordDate, w2.recordDate) = 1 AND w1.temperature &gt; w2.temperature; ", "author_fullname": "t2_s8y701hq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "197. Rising Temperature - LeetCode", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175l1ki", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697048550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the below Question: I have written a SQL query but that query not giving me the right answer although the second code (not mine ) is also fundamentally the same (as per my knowledge ), but that code is showing right output. Can someone please tell why  ?  &lt;/p&gt;\n\n&lt;p&gt;Table: Weather&lt;/p&gt;\n\n&lt;p&gt;+---------------+---------+ | Column Name   | Type    | +---------------+---------+ | id            | int     | | recordDate    | date    | | temperature   | int     | +---------------+---------+ id is the column with unique values for this table. This table contains information about the temperature on a certain day. &lt;/p&gt;\n\n&lt;p&gt;Write a solution to find all dates&amp;#39; Id&lt;br/&gt;\n with higher temperatures compared to its previous dates (yesterday).&lt;/p&gt;\n\n&lt;p&gt;Return the result table in &lt;strong&gt;any order&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;The result format is in the following example.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Example 1:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Input:&lt;/strong&gt;  Weather table: +----+------------+-------------+ | id | recordDate | temperature | +----+------------+-------------+ | 1  | 2015-01-01 | 10          | | 2  | 2015-01-02 | 25          | | 3  | 2015-01-03 | 20          | | 4  | 2015-01-04 | 30          | +----+------------+-------------+ &lt;strong&gt;Output:&lt;/strong&gt;  +----+ | id | +----+ | 2  | | 4  | +----+ &lt;strong&gt;Explanation:&lt;/strong&gt;  In 2015-01-02, the temperature was higher than the previous day (10 -&amp;gt; 25). In 2015-01-04, the temperature was higher than the previous day (20 -&amp;gt; 30). &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My Code : &lt;/p&gt;\n\n&lt;p&gt;select \u00a0cw1.id from Weather as cw1 inner join Weather as pw2 on cw1.id \u00a0= pw2.id&lt;br/&gt;\nwhere datediff(cw1.recordDate, pw2.recordDate) = 1 and cw1.temperature &amp;gt; pw2.temperature  &lt;/p&gt;\n\n&lt;p&gt;2nd one : &lt;/p&gt;\n\n&lt;p&gt;SELECT w1.id&lt;br/&gt;\nFROM Weather w1, Weather w2&lt;br/&gt;\nWHERE DATEDIFF(w1.recordDate, w2.recordDate) = 1 AND w1.temperature &amp;gt; w2.temperature; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175l1ki", "is_robot_indexable": true, "report_reasons": null, "author": "iamchampionno1", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175l1ki/197_rising_temperature_leetcode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175l1ki/197_rising_temperature_leetcode/", "subreddit_subscribers": 1081208, "created_utc": 1697048550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I'm on track to graduate in the summer of 2024, and I have an opportunity to pursue an internship (CPT) during the upcoming spring. Before I make a decision, I wanted to get a sense of the current job market.\n\n1. How's the job market looking for recent grads?\n2. For those who have recently graduated or are about to, what has been your experience in the current job market?", "author_fullname": "t2_1hnr82h2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Market for Upcoming Grads?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175nfei", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697054635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m on track to graduate in the summer of 2024, and I have an opportunity to pursue an internship (CPT) during the upcoming spring. Before I make a decision, I wanted to get a sense of the current job market.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;How&amp;#39;s the job market looking for recent grads?&lt;/li&gt;\n&lt;li&gt;For those who have recently graduated or are about to, what has been your experience in the current job market?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175nfei", "is_robot_indexable": true, "report_reasons": null, "author": "minato5972", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175nfei/market_for_upcoming_grads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175nfei/market_for_upcoming_grads/", "subreddit_subscribers": 1081208, "created_utc": 1697054635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;", "author_fullname": "t2_3vtdvu7m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is fitting functions to data (with chi2 and all that) data analysis or data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175qent", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.41, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697072739.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697062044.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175qent", "is_robot_indexable": true, "report_reasons": null, "author": "Silly_Valley", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175qent/is_fitting_functions_to_data_with_chi2_and_all/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175qent/is_fitting_functions_to_data_with_chi2_and_all/", "subreddit_subscribers": 1081208, "created_utc": 1697062044.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello.\n\nI have to do a project for my thesis.\nI have decided about Fraud Detection for banks. How to see if the money is like made from fraud or if it\u2019s being laundered.\n\nWhat do you say about it?\n How should I approach this topic and how to do it?\nAny ideas? Thanks.", "author_fullname": "t2_5gw1p7y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fraud Detection Thesis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175nces", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697054438.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.&lt;/p&gt;\n\n&lt;p&gt;I have to do a project for my thesis.\nI have decided about Fraud Detection for banks. How to see if the money is like made from fraud or if it\u2019s being laundered.&lt;/p&gt;\n\n&lt;p&gt;What do you say about it?\n How should I approach this topic and how to do it?\nAny ideas? Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175nces", "is_robot_indexable": true, "report_reasons": null, "author": "philemil", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175nces/fraud_detection_thesis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175nces/fraud_detection_thesis/", "subreddit_subscribers": 1081208, "created_utc": 1697054438.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I once had this crazy professor who told everyone that in the future all jobs would be automated except for AI programmer, which would be the last job requiring a person to perform.\n\nIn an ideal world, the benefits of automation would be used to benefit humanity, but I'm wondering if all the people whose jobs get replaced by AI will just end up destitute and the rich will use AI to benefit themselves and program an army of killer robots to oppress people. We will end up being the ones who get paid really well to keep the new world order. \n\nAm I ready for this job?", "author_fullname": "t2_1ns77nex", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you believe AI Programmer/Data Scientist will be the last job done by a human?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175w0gv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.36, "author_flair_background_color": "", "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "seniorflair", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697077743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I once had this crazy professor who told everyone that in the future all jobs would be automated except for AI programmer, which would be the last job requiring a person to perform.&lt;/p&gt;\n\n&lt;p&gt;In an ideal world, the benefits of automation would be used to benefit humanity, but I&amp;#39;m wondering if all the people whose jobs get replaced by AI will just end up destitute and the rich will use AI to benefit themselves and program an army of killer robots to oppress people. We will end up being the ones who get paid really well to keep the new world order. &lt;/p&gt;\n\n&lt;p&gt;Am I ready for this job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Scientist MS|MBA ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175w0gv", "is_robot_indexable": true, "report_reasons": null, "author": "DJAlaskaAndrew", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/datascience/comments/175w0gv/do_you_believe_ai_programmerdata_scientist_will/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175w0gv/do_you_believe_ai_programmerdata_scientist_will/", "subreddit_subscribers": 1081208, "created_utc": 1697077743.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}