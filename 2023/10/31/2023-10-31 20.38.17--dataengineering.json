{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The great philosophical question. I know the \"right\" answer to this question is to give users exactly what they asked for and if they asked for a dumb product, then that's on them and they should have given better requirements... but in my experience, the business doesn't know what to ask for and if you do exactly what they ask, you end up re-inventing excel.\n\nOn the other hand, Henry Ford once said \"If I asked people what they wanted, they would have told me they wanted faster horses.\"  ", "author_fullname": "t2_lp0hc3mff", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you give the business what they asked for, or what they want?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17km8af", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698762202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The great philosophical question. I know the &amp;quot;right&amp;quot; answer to this question is to give users exactly what they asked for and if they asked for a dumb product, then that&amp;#39;s on them and they should have given better requirements... but in my experience, the business doesn&amp;#39;t know what to ask for and if you do exactly what they ask, you end up re-inventing excel.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, Henry Ford once said &amp;quot;If I asked people what they wanted, they would have told me they wanted faster horses.&amp;quot;  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17km8af", "is_robot_indexable": true, "report_reasons": null, "author": "LopsidedFondant3747", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17km8af/do_you_give_the_business_what_they_asked_for_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17km8af/do_you_give_the_business_what_they_asked_for_or/", "subreddit_subscribers": 137165, "created_utc": 1698762202.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey DEs, first of all not to hate on data engineering I\u2019ve been doing this for around 7 years and really like the space and what I do (maybe not so much my current company) but have been approached by a company with a hybrid data/backend engineering role.\n\nThe data engineer title varies a lot between companies but I work a lot with python, building custom tools for everything from custom extraction, schema management, auto DAG generation, Airflow plugins, DBT plugins, etc. \n\nI like what I do but the last year or so I\u2019ve been getting pretty burnt out on the day to day data eng tasks. I actually applied to a backend Scala position internally at my company but that didn\u2019t go through. I think a lot of my frustrations stems from the data org at my current company just being incredibly non-technical and really apathetic around engineering in general.\n\nThis new role is basically someone to own their slim/simple data pipelines and DBT project, but also work on their backend APIs mostly in Golang. Just the thought of working in and learning a new language (I\u2019ve used Go a bit but not extensively) is exciting to me. Plus it seems like Go is being used a lot more on the data processing side, so not a total career flip. \n\nAgain I really enjoy the data eng space but much more so from the eng perspective. Solving \u201cbusiness problems\u201d with data just doesn\u2019t excite me anymore, I don\u2019t wanna use DBT to make your data model I wanna BUIlD DBT, I don\u2019t wanna use airflow run your ETL I wanna BUILD airflow. \n\nAny advice or warnings from engineers who\u2019ve jumped from DE would be appreciated!", "author_fullname": "t2_109762", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Switching to backend engineering from data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kcypl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698726646.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey DEs, first of all not to hate on data engineering I\u2019ve been doing this for around 7 years and really like the space and what I do (maybe not so much my current company) but have been approached by a company with a hybrid data/backend engineering role.&lt;/p&gt;\n\n&lt;p&gt;The data engineer title varies a lot between companies but I work a lot with python, building custom tools for everything from custom extraction, schema management, auto DAG generation, Airflow plugins, DBT plugins, etc. &lt;/p&gt;\n\n&lt;p&gt;I like what I do but the last year or so I\u2019ve been getting pretty burnt out on the day to day data eng tasks. I actually applied to a backend Scala position internally at my company but that didn\u2019t go through. I think a lot of my frustrations stems from the data org at my current company just being incredibly non-technical and really apathetic around engineering in general.&lt;/p&gt;\n\n&lt;p&gt;This new role is basically someone to own their slim/simple data pipelines and DBT project, but also work on their backend APIs mostly in Golang. Just the thought of working in and learning a new language (I\u2019ve used Go a bit but not extensively) is exciting to me. Plus it seems like Go is being used a lot more on the data processing side, so not a total career flip. &lt;/p&gt;\n\n&lt;p&gt;Again I really enjoy the data eng space but much more so from the eng perspective. Solving \u201cbusiness problems\u201d with data just doesn\u2019t excite me anymore, I don\u2019t wanna use DBT to make your data model I wanna BUIlD DBT, I don\u2019t wanna use airflow run your ETL I wanna BUILD airflow. &lt;/p&gt;\n\n&lt;p&gt;Any advice or warnings from engineers who\u2019ve jumped from DE would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17kcypl", "is_robot_indexable": true, "report_reasons": null, "author": "babyfacebrain666", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kcypl/switching_to_backend_engineering_from_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kcypl/switching_to_backend_engineering_from_data/", "subreddit_subscribers": 137165, "created_utc": 1698726646.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working with streaming data pipelines for a while now. We use small checks to ensure dirty data is not being written to the serving layer. The way this is done is by filtering data and send it to a layer where all the dirty data resides. We don't use any special library for this. For example, if we are working with Azure Stream Analytics we use a query to do the filters.\n\nI haven't really seen quality checks being done in streaming pipelines by any special library or framework.\n\nSo I was curious... How do other data engineers in this sub handle DQ for streaming?\n\n&amp;#x200B;", "author_fullname": "t2_66knxh65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you handle data quality in streaming pipelines?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kkerp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698757012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working with streaming data pipelines for a while now. We use small checks to ensure dirty data is not being written to the serving layer. The way this is done is by filtering data and send it to a layer where all the dirty data resides. We don&amp;#39;t use any special library for this. For example, if we are working with Azure Stream Analytics we use a query to do the filters.&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t really seen quality checks being done in streaming pipelines by any special library or framework.&lt;/p&gt;\n\n&lt;p&gt;So I was curious... How do other data engineers in this sub handle DQ for streaming?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17kkerp", "is_robot_indexable": true, "report_reasons": null, "author": "WarNeverChanges1997", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kkerp/how_do_you_handle_data_quality_in_streaming/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kkerp/how_do_you_handle_data_quality_in_streaming/", "subreddit_subscribers": 137165, "created_utc": 1698757012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys, \n\nI have started my youtube channel to post data engineering related content. Can you guys take a look at the first 2 videos and provide any comments/suggestions.   \n\n\n[https://www.youtube.com/channel/UCwJXNjW9IXa65IVBZEw1G0Q](https://www.youtube.com/channel/UCwJXNjW9IXa65IVBZEw1G0Q)  \n\n\nAlso, please let me know what kind of content will be helpful , especially for beginners. Thanks!  \n", "author_fullname": "t2_8vjbfemu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Youtube Channel", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kb5yh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698720662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys, &lt;/p&gt;\n\n&lt;p&gt;I have started my youtube channel to post data engineering related content. Can you guys take a look at the first 2 videos and provide any comments/suggestions.   &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/channel/UCwJXNjW9IXa65IVBZEw1G0Q\"&gt;https://www.youtube.com/channel/UCwJXNjW9IXa65IVBZEw1G0Q&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;Also, please let me know what kind of content will be helpful , especially for beginners. Thanks!  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/MsKu6sL1iTkkef9eWB-2vqxd4C_u3v19icWQus1WzX4.jpg?auto=webp&amp;s=445df712bc796a463f39ee9e0d9726b82f7e3e40", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/MsKu6sL1iTkkef9eWB-2vqxd4C_u3v19icWQus1WzX4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cf5b1e39d2fe2a3219a2d12fcd254389284fbb26", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/MsKu6sL1iTkkef9eWB-2vqxd4C_u3v19icWQus1WzX4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d8bc9942f642b98fd1554c11cdf72213591d2010", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/MsKu6sL1iTkkef9eWB-2vqxd4C_u3v19icWQus1WzX4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=071ef7de4178c6ff5f25aa4e0614455d2717e0f9", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/MsKu6sL1iTkkef9eWB-2vqxd4C_u3v19icWQus1WzX4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c84f62b708161649bc4d2de1a30f015912538df2", "width": 640, "height": 640}], "variants": {}, "id": "genVsnqvFyvAuimvy58zzy4flXtyy4NChxCeDiWi-0o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17kb5yh", "is_robot_indexable": true, "report_reasons": null, "author": "Curious_Guy81", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kb5yh/data_engineering_youtube_channel/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kb5yh/data_engineering_youtube_channel/", "subreddit_subscribers": 137165, "created_utc": 1698720662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "looking for ideas - anything to do with bad data/ data quality/ even regulations etc.", "author_fullname": "t2_j69fw1hz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "any funny halloween costume ideas related to data quality? \ud83c\udf83", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17k3r1v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698700067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;looking for ideas - anything to do with bad data/ data quality/ even regulations etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17k3r1v", "is_robot_indexable": true, "report_reasons": null, "author": "rdtro", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17k3r1v/any_funny_halloween_costume_ideas_related_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17k3r1v/any_funny_halloween_costume_ideas_related_to_data/", "subreddit_subscribers": 137165, "created_utc": 1698700067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serverless Is Not All You Need", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": false, "name": "t3_17k4foj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/gFqWPqOOtc9JA7odkNvCO5LKJYM73ibt4UJ-NR9S8LU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698701870.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "risingwave.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://risingwave.com/blog/serverless-is-not-all-you-need/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/BjaIuQGBUZVgoauLDw-4RCrdQepMssfz6o3ZCU2buyw.jpg?auto=webp&amp;s=04f89ab2d2a41402623fa1bb9a18187db853767b", "width": 6346, "height": 3400}, "resolutions": [{"url": "https://external-preview.redd.it/BjaIuQGBUZVgoauLDw-4RCrdQepMssfz6o3ZCU2buyw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=759280e3b45c2a812d67133823836d196855fe44", "width": 108, "height": 57}, {"url": "https://external-preview.redd.it/BjaIuQGBUZVgoauLDw-4RCrdQepMssfz6o3ZCU2buyw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d86314d7da3dd7d1b6aef7aebe3c9273fb8ef9f", "width": 216, "height": 115}, {"url": "https://external-preview.redd.it/BjaIuQGBUZVgoauLDw-4RCrdQepMssfz6o3ZCU2buyw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ad17d68c3cad267b304af6e73e4833f8f6ae8043", "width": 320, "height": 171}, {"url": "https://external-preview.redd.it/BjaIuQGBUZVgoauLDw-4RCrdQepMssfz6o3ZCU2buyw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6202570c045f26dc41c53737422a94e8cd834edf", "width": 640, "height": 342}, {"url": "https://external-preview.redd.it/BjaIuQGBUZVgoauLDw-4RCrdQepMssfz6o3ZCU2buyw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=79c2449304362e90fdc702f3dea3ed7868b75165", "width": 960, "height": 514}, {"url": "https://external-preview.redd.it/BjaIuQGBUZVgoauLDw-4RCrdQepMssfz6o3ZCU2buyw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0a584c706e637fbb76c4500d6244af4e3603ddb1", "width": 1080, "height": 578}], "variants": {}, "id": "pF39_BzUSKDtWbiEHONxLPdngWVyglfjSVUqa7wHRPU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17k4foj", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17k4foj/serverless_is_not_all_you_need/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://risingwave.com/blog/serverless-is-not-all-you-need/", "subreddit_subscribers": 137165, "created_utc": 1698701870.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for an SME in the finance industry. We are generally a pretty data immature company, using Excel as a DB in so many places(!) Albeit the data we do have is generally clean (with some funky formatting) and good quality. I want to change this and bring about some systematic ELT so ad-hoc data requests don't take 2-3x longer than they should because data is so disparate. My intention is to use something like Fivetran to build the pipelines into a cloud-based DB. The obstacle I'm running into is my vendors/data generators are wanting to charge 30/40k up front and recurring to have an API set up for us - is this to be expected?\n\nIn Finance a lot of data is transferred by SFTP, which would be an option except my IT won't let us host an FTP server... Any help or insight would be appreciated!", "author_fullname": "t2_4r5q6r38", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "API Costs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kfrye", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698738747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for an SME in the finance industry. We are generally a pretty data immature company, using Excel as a DB in so many places(!) Albeit the data we do have is generally clean (with some funky formatting) and good quality. I want to change this and bring about some systematic ELT so ad-hoc data requests don&amp;#39;t take 2-3x longer than they should because data is so disparate. My intention is to use something like Fivetran to build the pipelines into a cloud-based DB. The obstacle I&amp;#39;m running into is my vendors/data generators are wanting to charge 30/40k up front and recurring to have an API set up for us - is this to be expected?&lt;/p&gt;\n\n&lt;p&gt;In Finance a lot of data is transferred by SFTP, which would be an option except my IT won&amp;#39;t let us host an FTP server... Any help or insight would be appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17kfrye", "is_robot_indexable": true, "report_reasons": null, "author": "10formicidae", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kfrye/api_costs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kfrye/api_costs/", "subreddit_subscribers": 137165, "created_utc": 1698738747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a software engineer trying to learn more about ELT process, I have a personal project in which I am using S3 + Fivetran + Snowflake + DBT, but Fivetran doesn't have a free account, only a 15 days trial and due to life I'm never able to wrap up my project in 15 days. I already created 2 accounts, talked to Fivetran sales people, but the only thing they can do is giving me extra 15 days\ud83d\ude23. So I'm looking for a free alternative to Fivetran, pretty much to connect my S3 bucket to Snowflake. Any tips are appreciated!", "author_fullname": "t2_amvgqfyq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran substitute", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kaq90", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698720449.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698719352.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a software engineer trying to learn more about ELT process, I have a personal project in which I am using S3 + Fivetran + Snowflake + DBT, but Fivetran doesn&amp;#39;t have a free account, only a 15 days trial and due to life I&amp;#39;m never able to wrap up my project in 15 days. I already created 2 accounts, talked to Fivetran sales people, but the only thing they can do is giving me extra 15 days\ud83d\ude23. So I&amp;#39;m looking for a free alternative to Fivetran, pretty much to connect my S3 bucket to Snowflake. Any tips are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17kaq90", "is_robot_indexable": true, "report_reasons": null, "author": "julinvictus", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kaq90/fivetran_substitute/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kaq90/fivetran_substitute/", "subreddit_subscribers": 137165, "created_utc": 1698719352.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering if any data engineers here have worked for any casino companies or other gambling products. I suspect the data is interesting and I just got a job offer at one. Just curious to hear any feedback.", "author_fullname": "t2_11f1es", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Gambling/casino company", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17k80nr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698711420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if any data engineers here have worked for any casino companies or other gambling products. I suspect the data is interesting and I just got a job offer at one. Just curious to hear any feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17k80nr", "is_robot_indexable": true, "report_reasons": null, "author": "ianitic", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17k80nr/gamblingcasino_company/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17k80nr/gamblingcasino_company/", "subreddit_subscribers": 137165, "created_utc": 1698711420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "With the following commands, it prompts you which snapshot to display, and then [you have this](https://app.data-drift.io/41231518/samox/local-datadrift-repo/overview?snapshotDate=2023-10-25&amp;commitSha=105c05f0d9b418cf86e223d59cc4a686b298935f) \ud83d\ude07\n\n&amp;#x200B;\n\n    pip install driftdb==0.0.1a12\n    driftdb dbt snapshot\n\nThe lib: [https://pypi.org/project/driftdb/](https://pypi.org/project/driftdb/)\n\nAll the data stays on your host !\n\n[Example of drift](https://preview.redd.it/tfve1f4ekkxb1.png?width=2406&amp;format=png&amp;auto=webp&amp;s=7e7b1adf057dfe3ae37c49e8a86fdc9bce34e1c6)", "author_fullname": "t2_10uv2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created a tool to visualize dbt-snapshots with a git like display", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 96, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tfve1f4ekkxb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 74, "x": 108, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3381aa5d6cdc6023c7559e6cafa5f9874949c0a6"}, {"y": 149, "x": 216, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=ccde4aa990cb7d15f7af363f07e38df1b2b8113d"}, {"y": 221, "x": 320, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c024dc99c72dc3457887c326bcf3739ddf2d1ae0"}, {"y": 442, "x": 640, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=f465caf5dd2157396caad0a4073fa26341a22a41"}, {"y": 663, "x": 960, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=bc697f3963cff63421c52a7d79486fe6f7c243df"}, {"y": 746, "x": 1080, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7f0a934a13fdfcddd408c3e4b5b6f771540eb980"}], "s": {"y": 1664, "x": 2406, "u": "https://preview.redd.it/tfve1f4ekkxb1.png?width=2406&amp;format=png&amp;auto=webp&amp;s=7e7b1adf057dfe3ae37c49e8a86fdc9bce34e1c6"}, "id": "tfve1f4ekkxb1"}}, "name": "t3_17kpvp6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/M-Ib3fRg5MfaoZgm7lp_0dl2nRgC5wcT2mWawn50IP8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698771914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;With the following commands, it prompts you which snapshot to display, and then &lt;a href=\"https://app.data-drift.io/41231518/samox/local-datadrift-repo/overview?snapshotDate=2023-10-25&amp;amp;commitSha=105c05f0d9b418cf86e223d59cc4a686b298935f\"&gt;you have this&lt;/a&gt; \ud83d\ude07&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pip install driftdb==0.0.1a12\ndriftdb dbt snapshot\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;The lib: &lt;a href=\"https://pypi.org/project/driftdb/\"&gt;https://pypi.org/project/driftdb/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;All the data stays on your host !&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tfve1f4ekkxb1.png?width=2406&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=7e7b1adf057dfe3ae37c49e8a86fdc9bce34e1c6\"&gt;Example of drift&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "17kpvp6", "is_robot_indexable": true, "report_reasons": null, "author": "Srammmy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kpvp6/i_created_a_tool_to_visualize_dbtsnapshots_with_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kpvp6/i_created_a_tool_to_visualize_dbtsnapshots_with_a/", "subreddit_subscribers": 137165, "created_utc": 1698771914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There are things that we do that are very infrequent. For example, during our data ingest, sometimes we change the requirements for what exact data are ingested. This changes maybe once a year if that. We insert the requirements into a table and then our ingest service reads from that table.\n\nI've just been inserting the requirements into the table myself with an adhoc script that reads from a YAML config made by our Operations team describing the requirements. They send me the location of the YAML and I just run the script to get it into the table.\n\nBut then I get this wave of shame that this whole process should not be manual with me running the script like this. But the other part of me says this is like a once in a year thing, just run the script. Who cares.\n\nI'm not sure what my question is but do you guys have any thoughts on this? I'm still pretty new and on a small team but have a lot of freedom at my job, so I get this feeling every once in a while about when I should do something more formalized and when I shouldn't since its completely up to me. There are these moments where in a practical real life sense it works and gets the job done, but feels like I'm doing something bad. How much \"adhoc\" / one-off script type of stuff do you guys do?", "author_fullname": "t2_l2cnyx8o0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When should something be made into part of the process versus doing it manually?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17khow9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698747765.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698747382.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There are things that we do that are very infrequent. For example, during our data ingest, sometimes we change the requirements for what exact data are ingested. This changes maybe once a year if that. We insert the requirements into a table and then our ingest service reads from that table.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve just been inserting the requirements into the table myself with an adhoc script that reads from a YAML config made by our Operations team describing the requirements. They send me the location of the YAML and I just run the script to get it into the table.&lt;/p&gt;\n\n&lt;p&gt;But then I get this wave of shame that this whole process should not be manual with me running the script like this. But the other part of me says this is like a once in a year thing, just run the script. Who cares.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure what my question is but do you guys have any thoughts on this? I&amp;#39;m still pretty new and on a small team but have a lot of freedom at my job, so I get this feeling every once in a while about when I should do something more formalized and when I shouldn&amp;#39;t since its completely up to me. There are these moments where in a practical real life sense it works and gets the job done, but feels like I&amp;#39;m doing something bad. How much &amp;quot;adhoc&amp;quot; / one-off script type of stuff do you guys do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17khow9", "is_robot_indexable": true, "report_reasons": null, "author": "OctobersOwn2023", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17khow9/when_should_something_be_made_into_part_of_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17khow9/when_should_something_be_made_into_part_of_the/", "subreddit_subscribers": 137165, "created_utc": 1698747382.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello\n\nI obtained various certifications in the last few years but always with vouchers that i got at events, workshop ,etc. now i am trying to get vuochers but i can't get them anywhere, is there still a chance to get them?\n\n&amp;#x200B;", "author_fullname": "t2_d6bmxkhw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "where do you get vouchers for certifications?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17klfyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698760045.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello&lt;/p&gt;\n\n&lt;p&gt;I obtained various certifications in the last few years but always with vouchers that i got at events, workshop ,etc. now i am trying to get vuochers but i can&amp;#39;t get them anywhere, is there still a chance to get them?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17klfyq", "is_robot_indexable": true, "report_reasons": null, "author": "PinPrestigious2327", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17klfyq/where_do_you_get_vouchers_for_certifications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17klfyq/where_do_you_get_vouchers_for_certifications/", "subreddit_subscribers": 137165, "created_utc": 1698760045.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI know questions like this get asked a lot, but I was unable to find a discussion relating to my exact situation so I wanted to reach out to get you guys' opinion. \n\nI have been working as a financial analyst with a healthcare company for 3 years. During my time at this role, I have quickly learned that I have far less of an interest doing the analytics of company data to make business decisions and am far more passionate about solving efficiency and data problems with code. I really have grown to love Python and SQL and really enjoy making tools to make processes easier for our teams. Because of this, I have begun to think that a career in DE is more related to my interests. \n\nSome of the work I've done here have included: \n\n - transitioning SAS projections into Python notebooks and automating Excel read-ins to speed up the projection process saving hours weekly. \n\n- Optimizing SQL queries and improving database structure, reducing redundancies and transactions to the servers\n\n- Using Git hooks and Python to automate versioning incrementation of Excel reporting tool versions and prevent out of date versions of reports from being used\n\n- Managing data deployments to PROD servers during the insurance bid season and creating a Python tool that connects to a Git repo to execute queries and loads such data into new/existing tables, as well as copying tables from one server to another. \n\n\nI know that none of these projects have been too advanced DE type projects, but I feel like they are getting me on the right path.  I, unfortunately, have no real experience with cloud systems, formal ETL tools, data lake/warehousing, some deeper coding stuff like linux systems etc. \n\nI am looking to move soon to get closer to family, and am looking to find something that is completely remote (current role is hybrid). I have applying heavily to largely Data Engineer jobs, but have been applying to lots of other adjacent roles as well including data analyst, ETL Developer, Analytics Engineer, Business Intelligence Engineer, Database Developer, ETL Analyst, and on and on. I can't seem to get any offers. I'm not applying only to FAANG, I'm applying to hundreds of roles. I've submitted my resume to r/resumes (check my post history) and have received other online help and I believe that it shouldn't be bad *enough* to be getting no offers and hardly any interviews. I know that now is apparently a bad time for the job market, but I can not fathom how if I were to lose my job for whatever reason, that it would take months to get a single offer as even a data analyst (which is how long I've been applying for positions). \n\nWhat I'm asking is for suggestions. Should I just focus on trying to find a Data Analyst role that focuses on ETL and data pipelines before looking for strictly DE roles? I've received feedback that I could land a DE role, but I have yet to get a single interview for  DE position. Is the job market really that bad right now? \n\nDoes anyone have any suggestions on how someone with some DE-like experience could transition into a DE role? Do you have any suggestions on job titles I could look into that could be essentially a stepping stone to a DE position? Any suggestions on how/where to find job listings that I would be a decent fit in? \n\nfor context: I have a degree in Mathematics and am in the US. I work for a large insurance company doing lots of DE-like tasks using Python, SQL, Git, Excel, VBA, Power BI \n\nedit: I forgot to add, I am looking to move very soon if possible, so I really don't have time to complete a certification like one for AWS or time to learn Databricks or Snowflake unfortunately. I definitely would like to learn stuff like this, I just don't think I can get familiar with them while looking for a job/packing\n\n\ntl;dr: \nBeen working for an insurance company for 3 years doing DE type projects, but can't get a DE interview. I've received feedback saying my resume is decent. Are there any adjacent jobs that could help me transition into DE? Is the market just really bad for someone with 3 years of experience right now?", "author_fullname": "t2_gy2be", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Analyst with a focus in DE projects -&gt; DE transition/job market", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17kt7e3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698780546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I know questions like this get asked a lot, but I was unable to find a discussion relating to my exact situation so I wanted to reach out to get you guys&amp;#39; opinion. &lt;/p&gt;\n\n&lt;p&gt;I have been working as a financial analyst with a healthcare company for 3 years. During my time at this role, I have quickly learned that I have far less of an interest doing the analytics of company data to make business decisions and am far more passionate about solving efficiency and data problems with code. I really have grown to love Python and SQL and really enjoy making tools to make processes easier for our teams. Because of this, I have begun to think that a career in DE is more related to my interests. &lt;/p&gt;\n\n&lt;p&gt;Some of the work I&amp;#39;ve done here have included: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;transitioning SAS projections into Python notebooks and automating Excel read-ins to speed up the projection process saving hours weekly. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Optimizing SQL queries and improving database structure, reducing redundancies and transactions to the servers&lt;/li&gt;\n&lt;li&gt;Using Git hooks and Python to automate versioning incrementation of Excel reporting tool versions and prevent out of date versions of reports from being used&lt;/li&gt;\n&lt;li&gt;Managing data deployments to PROD servers during the insurance bid season and creating a Python tool that connects to a Git repo to execute queries and loads such data into new/existing tables, as well as copying tables from one server to another. &lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I know that none of these projects have been too advanced DE type projects, but I feel like they are getting me on the right path.  I, unfortunately, have no real experience with cloud systems, formal ETL tools, data lake/warehousing, some deeper coding stuff like linux systems etc. &lt;/p&gt;\n\n&lt;p&gt;I am looking to move soon to get closer to family, and am looking to find something that is completely remote (current role is hybrid). I have applying heavily to largely Data Engineer jobs, but have been applying to lots of other adjacent roles as well including data analyst, ETL Developer, Analytics Engineer, Business Intelligence Engineer, Database Developer, ETL Analyst, and on and on. I can&amp;#39;t seem to get any offers. I&amp;#39;m not applying only to FAANG, I&amp;#39;m applying to hundreds of roles. I&amp;#39;ve submitted my resume to &lt;a href=\"/r/resumes\"&gt;r/resumes&lt;/a&gt; (check my post history) and have received other online help and I believe that it shouldn&amp;#39;t be bad &lt;em&gt;enough&lt;/em&gt; to be getting no offers and hardly any interviews. I know that now is apparently a bad time for the job market, but I can not fathom how if I were to lose my job for whatever reason, that it would take months to get a single offer as even a data analyst (which is how long I&amp;#39;ve been applying for positions). &lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m asking is for suggestions. Should I just focus on trying to find a Data Analyst role that focuses on ETL and data pipelines before looking for strictly DE roles? I&amp;#39;ve received feedback that I could land a DE role, but I have yet to get a single interview for  DE position. Is the job market really that bad right now? &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any suggestions on how someone with some DE-like experience could transition into a DE role? Do you have any suggestions on job titles I could look into that could be essentially a stepping stone to a DE position? Any suggestions on how/where to find job listings that I would be a decent fit in? &lt;/p&gt;\n\n&lt;p&gt;for context: I have a degree in Mathematics and am in the US. I work for a large insurance company doing lots of DE-like tasks using Python, SQL, Git, Excel, VBA, Power BI &lt;/p&gt;\n\n&lt;p&gt;edit: I forgot to add, I am looking to move very soon if possible, so I really don&amp;#39;t have time to complete a certification like one for AWS or time to learn Databricks or Snowflake unfortunately. I definitely would like to learn stuff like this, I just don&amp;#39;t think I can get familiar with them while looking for a job/packing&lt;/p&gt;\n\n&lt;p&gt;tl;dr: \nBeen working for an insurance company for 3 years doing DE type projects, but can&amp;#39;t get a DE interview. I&amp;#39;ve received feedback saying my resume is decent. Are there any adjacent jobs that could help me transition into DE? Is the market just really bad for someone with 3 years of experience right now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17kt7e3", "is_robot_indexable": true, "report_reasons": null, "author": "iSeeXenuInYou", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17kt7e3/analyst_with_a_focus_in_de_projects_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kt7e3/analyst_with_a_focus_in_de_projects_de/", "subreddit_subscribers": 137165, "created_utc": 1698780546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys, so as someone w ~2 YOE as a java developer, but trying to get a DE job, what should be on my list of things to learn? \n\nHere\u2019s my list of topics so far:\n\n1. Python (Automate the Boring Stuff + Python Essentials 1 + Mode analytics) \n2. Advanced SQL (w3schools + Mode analytics + leetcode)\n3. Cloud provider (AWS)\n4. Docker\n5. Snowflake\n6. Airflow\n7. Fundamentals of Data Engineering (Reis &amp; Housley)\n\nDoes anybody recommend anything else? I\u2019m struggling with learning too much at once and learning things that i don\u2019t need to know.\n\nThanks in advance.", "author_fullname": "t2_2r5n0ce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning list advice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kq9ci", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698772912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, so as someone w ~2 YOE as a java developer, but trying to get a DE job, what should be on my list of things to learn? &lt;/p&gt;\n\n&lt;p&gt;Here\u2019s my list of topics so far:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Python (Automate the Boring Stuff + Python Essentials 1 + Mode analytics) &lt;/li&gt;\n&lt;li&gt;Advanced SQL (w3schools + Mode analytics + leetcode)&lt;/li&gt;\n&lt;li&gt;Cloud provider (AWS)&lt;/li&gt;\n&lt;li&gt;Docker&lt;/li&gt;\n&lt;li&gt;Snowflake&lt;/li&gt;\n&lt;li&gt;Airflow&lt;/li&gt;\n&lt;li&gt;Fundamentals of Data Engineering (Reis &amp;amp; Housley)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Does anybody recommend anything else? I\u2019m struggling with learning too much at once and learning things that i don\u2019t need to know.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17kq9ci", "is_robot_indexable": true, "report_reasons": null, "author": "naq98", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kq9ci/learning_list_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kq9ci/learning_list_advice/", "subreddit_subscribers": 137165, "created_utc": 1698772912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been contacted by a recruiter for a local position in a healthcare product company.\nI'm really interested in switching to a product company even through I would prefere abroad in Europe.\n\nHe stated in message that they were going for 70k-90k and then when I talked with him even if with 5 year experience he said that he was going to offer me 45k.\n\nI know, I know, so even through I was maybe interested, I told him that I wouldn't give a range and after the interviews the company would decide the right price to have my skills.\n\nI thought that I was ghosted and I contacted him with updates, he wrote two weeks ago that interviews were halted due to the company manager that had to fly home for family problems.\n\nWhat do I do ?\n\n I don't want to seem desperate but I'm starting to struggle in my role due to\n\n- manager doesn't trust my checks and when we check together, my checks are right\n- extra time for one week, I have severe back pain\n- Thinks data is normalized while is not\n- He checks every day for activities that require a huge technical time (We are loading data from anouther source and sometimes it takes 1 or 2 hours for a lot of months)\n\nManager thinks that asking every moment is gonna make us work faster but we can't haste the process since we're not in charge of that system.\n\nWhat can I write to this recruiter?\nIt would be a good company to change to since they're creating a new company in my country.", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to recontact recruiter?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17klz64", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698761531.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been contacted by a recruiter for a local position in a healthcare product company.\nI&amp;#39;m really interested in switching to a product company even through I would prefere abroad in Europe.&lt;/p&gt;\n\n&lt;p&gt;He stated in message that they were going for 70k-90k and then when I talked with him even if with 5 year experience he said that he was going to offer me 45k.&lt;/p&gt;\n\n&lt;p&gt;I know, I know, so even through I was maybe interested, I told him that I wouldn&amp;#39;t give a range and after the interviews the company would decide the right price to have my skills.&lt;/p&gt;\n\n&lt;p&gt;I thought that I was ghosted and I contacted him with updates, he wrote two weeks ago that interviews were halted due to the company manager that had to fly home for family problems.&lt;/p&gt;\n\n&lt;p&gt;What do I do ?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to seem desperate but I&amp;#39;m starting to struggle in my role due to&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;manager doesn&amp;#39;t trust my checks and when we check together, my checks are right&lt;/li&gt;\n&lt;li&gt;extra time for one week, I have severe back pain&lt;/li&gt;\n&lt;li&gt;Thinks data is normalized while is not&lt;/li&gt;\n&lt;li&gt;He checks every day for activities that require a huge technical time (We are loading data from anouther source and sometimes it takes 1 or 2 hours for a lot of months)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Manager thinks that asking every moment is gonna make us work faster but we can&amp;#39;t haste the process since we&amp;#39;re not in charge of that system.&lt;/p&gt;\n\n&lt;p&gt;What can I write to this recruiter?\nIt would be a good company to change to since they&amp;#39;re creating a new company in my country.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17klz64", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17klz64/how_to_recontact_recruiter/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17klz64/how_to_recontact_recruiter/", "subreddit_subscribers": 137165, "created_utc": 1698761531.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fwerb2uw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We\u2019ve made Data Quality an engineer\u2019s problem. It\u2019s actually a tooling issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17klp2v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3Db5jxn_0xAI4fT11AKSJ0Yo_tyzuFQwh7r0nYp6aUM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698760776.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "y42.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.y42.com/blog/how-to-improve-data-quality-with-better-data-quality-tools/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/hUevSUfoP0jELsOwSYnfPT2WJ5Tz4zjxc1h7ylbqan8.jpg?auto=webp&amp;s=c4dc5911e7fb19c1fc99366aa56379a7bb167f41", "width": 1456, "height": 816}, "resolutions": [{"url": "https://external-preview.redd.it/hUevSUfoP0jELsOwSYnfPT2WJ5Tz4zjxc1h7ylbqan8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=abcb39b0564a69a27429f79a8d6e36e918c5e20b", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/hUevSUfoP0jELsOwSYnfPT2WJ5Tz4zjxc1h7ylbqan8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ac69a8e8da768eef09b70442f5fbe09c72ed8995", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/hUevSUfoP0jELsOwSYnfPT2WJ5Tz4zjxc1h7ylbqan8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=739d5674eb2ba4e6621797c680b97a91708d9cda", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/hUevSUfoP0jELsOwSYnfPT2WJ5Tz4zjxc1h7ylbqan8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6c485808d18707b10e548a055ca5538a3b2df40c", "width": 640, "height": 358}, {"url": "https://external-preview.redd.it/hUevSUfoP0jELsOwSYnfPT2WJ5Tz4zjxc1h7ylbqan8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=abd8a022e4d9441f854ece80fb5de794dae60590", "width": 960, "height": 538}, {"url": "https://external-preview.redd.it/hUevSUfoP0jELsOwSYnfPT2WJ5Tz4zjxc1h7ylbqan8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4588bdf1ad9579ba9a7d98c5f9d008974cd60924", "width": 1080, "height": 605}], "variants": {}, "id": "Hl5mXIl8CAHTddaBRAxQHXfbdCpP9xWSNd1SmBkjGoU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17klp2v", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant-Guidance599", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17klp2v/weve_made_data_quality_an_engineers_problem_its/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.y42.com/blog/how-to-improve-data-quality-with-better-data-quality-tools/", "subreddit_subscribers": 137165, "created_utc": 1698760776.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\n\nI am working on a project for a retail company. The company has different data sources regarding transaction data, which unfortunately also have different granularity. For example, for site A we get all the details regarding the transactions made (sold items), for site B we only get the daily sales. We wanted to build the facts table according to Kimball's Retail schema, but are now wondering how best to solve this due to the different data depth.\n\nDo you have any tips on how best to approach this?", "author_fullname": "t2_3d077o4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to harmonize missing data granularity in fact dimension?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kkj2s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698757344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;I am working on a project for a retail company. The company has different data sources regarding transaction data, which unfortunately also have different granularity. For example, for site A we get all the details regarding the transactions made (sold items), for site B we only get the daily sales. We wanted to build the facts table according to Kimball&amp;#39;s Retail schema, but are now wondering how best to solve this due to the different data depth.&lt;/p&gt;\n\n&lt;p&gt;Do you have any tips on how best to approach this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17kkj2s", "is_robot_indexable": true, "report_reasons": null, "author": "axeqizec", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kkj2s/best_way_to_harmonize_missing_data_granularity_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kkj2s/best_way_to_harmonize_missing_data_granularity_in/", "subreddit_subscribers": 137165, "created_utc": 1698757344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "To preface, I am not a DE but a DA dabbling in creating data pipelines (mostly within BQ) t o support the data needs of our dept., so that we can have amalgamated figures, ease of building new reports etc.\n\nThe BQ datamart is (in my humble opinion) a big mess: there are thousands of (very wide) views and relevant information is usually scattered across many different views. As the data we have access to are views and not partitioned table, every time we query the data at the source we are querying the whole data, thus increasing costs and processing times.\n\nAs an example, just to get to the amalgamated Sales data for out dept, I need to create a SQL made up of 20 different joins, joining either transactional, dimensional or mapping (thus very few rows) views. This lengthy SQL will easily churn through 200GB worth of data.\n\nI therefore have been busy creating a staging layer, whereby I join a few related views and output the result into a partitioned table contained in our project. Each of these tables is vastly smaller than the source of data as it is made up of far fewer fields, and additionally they are partitioned.\n\nHowever, if for example I combine the 3 tables that  I created (e.g. Sales transaction, customer master, product master) in a join to get the same output of the original SQL code that queries the 20 different views, a higher number of GB will be processed, e.g. 250GB.\n\nI tried experimenting with partitioning on different fields and clustering, but it didn't affect the 250GB figure.\n\nI can imagine it perhaps can be difficult to give some specific advice not having an insight into how the views and the partitioned tables are built.However, generally speaking does anyone have any broad advice on what should I look into to make sure that the number of GB processed will be smaller than the original 200GB, as that was my expectation by using (what I believe are) optimised partitioned/clustered tables?", "author_fullname": "t2_4v8mesko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[BQ] Created a few partitioned staging tables to optimise the raw data, which is all exposed as wide views. The original SQL querying the wide views process fewer GBs than the SQL querying the optimised partitioned tables, which is contrary to expectations. Any pointers?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kk214", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698756238.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698755913.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To preface, I am not a DE but a DA dabbling in creating data pipelines (mostly within BQ) t o support the data needs of our dept., so that we can have amalgamated figures, ease of building new reports etc.&lt;/p&gt;\n\n&lt;p&gt;The BQ datamart is (in my humble opinion) a big mess: there are thousands of (very wide) views and relevant information is usually scattered across many different views. As the data we have access to are views and not partitioned table, every time we query the data at the source we are querying the whole data, thus increasing costs and processing times.&lt;/p&gt;\n\n&lt;p&gt;As an example, just to get to the amalgamated Sales data for out dept, I need to create a SQL made up of 20 different joins, joining either transactional, dimensional or mapping (thus very few rows) views. This lengthy SQL will easily churn through 200GB worth of data.&lt;/p&gt;\n\n&lt;p&gt;I therefore have been busy creating a staging layer, whereby I join a few related views and output the result into a partitioned table contained in our project. Each of these tables is vastly smaller than the source of data as it is made up of far fewer fields, and additionally they are partitioned.&lt;/p&gt;\n\n&lt;p&gt;However, if for example I combine the 3 tables that  I created (e.g. Sales transaction, customer master, product master) in a join to get the same output of the original SQL code that queries the 20 different views, a higher number of GB will be processed, e.g. 250GB.&lt;/p&gt;\n\n&lt;p&gt;I tried experimenting with partitioning on different fields and clustering, but it didn&amp;#39;t affect the 250GB figure.&lt;/p&gt;\n\n&lt;p&gt;I can imagine it perhaps can be difficult to give some specific advice not having an insight into how the views and the partitioned tables are built.However, generally speaking does anyone have any broad advice on what should I look into to make sure that the number of GB processed will be smaller than the original 200GB, as that was my expectation by using (what I believe are) optimised partitioned/clustered tables?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17kk214", "is_robot_indexable": true, "report_reasons": null, "author": "_thetrue_SpaceTofu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kk214/bq_created_a_few_partitioned_staging_tables_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kk214/bq_created_a_few_partitioned_staging_tables_to/", "subreddit_subscribers": 137165, "created_utc": 1698755913.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone been successful using the meltano target-oracle with an oracle wallet as the login credential? If so, how did you set up your config?  I know it can be done with cx_oracle, but I'm not sure how to set up the tns params in the meltano config.", "author_fullname": "t2_1hb8tav0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meltano target-oracle with wallet", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kjy7e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698755559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone been successful using the meltano target-oracle with an oracle wallet as the login credential? If so, how did you set up your config?  I know it can be done with cx_oracle, but I&amp;#39;m not sure how to set up the tns params in the meltano config.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17kjy7e", "is_robot_indexable": true, "report_reasons": null, "author": "FrebTheRat", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kjy7e/meltano_targetoracle_with_wallet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kjy7e/meltano_targetoracle_with_wallet/", "subreddit_subscribers": 137165, "created_utc": 1698755559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey community,\n\nCurrently I\u2019m in the process of building a new data infra at my company, and I always opted using custom DAGs for extracting data from source system, and orchestrating it with Airflow.\n\nCan you please give me some pros and cons of using a tool for this? My line of thinking currently is that a tool would decrease the initial setup time needed, and it is easier to onboard probably, however a custom DAG is not a blackbox, it\u2019s highly customizable for our needs, and allows us to have full ownership.", "author_fullname": "t2_16ts9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advantage kf using Airbyte/Meltano over custom DAG", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kjl8u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698754424.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey community,&lt;/p&gt;\n\n&lt;p&gt;Currently I\u2019m in the process of building a new data infra at my company, and I always opted using custom DAGs for extracting data from source system, and orchestrating it with Airflow.&lt;/p&gt;\n\n&lt;p&gt;Can you please give me some pros and cons of using a tool for this? My line of thinking currently is that a tool would decrease the initial setup time needed, and it is easier to onboard probably, however a custom DAG is not a blackbox, it\u2019s highly customizable for our needs, and allows us to have full ownership.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17kjl8u", "is_robot_indexable": true, "report_reasons": null, "author": "pimadd_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kjl8u/advantage_kf_using_airbytemeltano_over_custom_dag/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kjl8u/advantage_kf_using_airbytemeltano_over_custom_dag/", "subreddit_subscribers": 137165, "created_utc": 1698754424.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently tasked with creating a data model to track the flow of customers through our sales funnel, from salesforce all the way to product usage within DBT.\n\nThe general structure is:\nLead -&gt; opportunity -&gt; signup -&gt; risk approved signup -&gt; use product \n\nThe issue I am having here is that a customer may progress to the next stage within 1 day or 6 months, and often there is no clear event which tells us when a customer has dropped out of the funnel.\n\nFor example, even if the sales guys close an opportunity or a lead, there is still a possibility that 2 months later that supplier signs up anyway, and so the funnel falls apart as we presumed they dropped out previously. Similarly, a customer may sign up, but not use the product for 3 or even 6 months after signup, but then use it after this point.\n\nI have considered using an accumulating snapshot fact table, but I'm not sure how it might be implemented. \nPlease help \ud83d\ude4f", "author_fullname": "t2_2tntx2vs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Customer Funnel Data Model Design", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kiy9f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698752225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently tasked with creating a data model to track the flow of customers through our sales funnel, from salesforce all the way to product usage within DBT.&lt;/p&gt;\n\n&lt;p&gt;The general structure is:\nLead -&amp;gt; opportunity -&amp;gt; signup -&amp;gt; risk approved signup -&amp;gt; use product &lt;/p&gt;\n\n&lt;p&gt;The issue I am having here is that a customer may progress to the next stage within 1 day or 6 months, and often there is no clear event which tells us when a customer has dropped out of the funnel.&lt;/p&gt;\n\n&lt;p&gt;For example, even if the sales guys close an opportunity or a lead, there is still a possibility that 2 months later that supplier signs up anyway, and so the funnel falls apart as we presumed they dropped out previously. Similarly, a customer may sign up, but not use the product for 3 or even 6 months after signup, but then use it after this point.&lt;/p&gt;\n\n&lt;p&gt;I have considered using an accumulating snapshot fact table, but I&amp;#39;m not sure how it might be implemented. \nPlease help \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17kiy9f", "is_robot_indexable": true, "report_reasons": null, "author": "casematta", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kiy9f/customer_funnel_data_model_design/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kiy9f/customer_funnel_data_model_design/", "subreddit_subscribers": 137165, "created_utc": 1698752225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As a data warehouse solution, is what I mean. Currently looking at user friendly and cost effective options. Ones I like so far are Astera Data Stack, Knime, and Yellowbrick has recently caught my attention. How does it compare to the more popular data warehouse solutions such as Amazon Redshift or Snowflake?", "author_fullname": "t2_5hpq24rk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone here have any experience with Yellowbrick?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kc01w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698723262.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a data warehouse solution, is what I mean. Currently looking at user friendly and cost effective options. Ones I like so far are Astera Data Stack, Knime, and Yellowbrick has recently caught my attention. How does it compare to the more popular data warehouse solutions such as Amazon Redshift or Snowflake?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17kc01w", "is_robot_indexable": true, "report_reasons": null, "author": "letsgopablo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17kc01w/does_anyone_here_have_any_experience_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17kc01w/does_anyone_here_have_any_experience_with/", "subreddit_subscribers": 137165, "created_utc": 1698723262.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Blog - [https://blog.peerdb.io/real-time-change-data-capture-for-postgres-partitioned-tables](https://blog.peerdb.io/real-time-change-data-capture-for-postgres-partitioned-tables)  \nThis is one of my favorite features that we shipped recently. Building Change Data Capture (CDC) for Postgres Partitioned Tables involves handling various scenarios that need care and emphasis.\n\nWe at [PeerDB](https://peerdb.io) are building a specialized data-movement tool for Postgres. So supporting this feature was a given and a self expectation. This feature was one of the top asks from customers. We will keep adding more such native features as we evolve. \ud83d\udc18 \ud83d\ude0a\n\nAlso, don't forget to see the demo - it was a very candid one. \ud83d\ude0a I enjoyed covering different scenarios incl. adding new partitions, adding new columns, dropping partitions etc and showing how PeerDB handles replication for each of these cases.", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Real-time Change Data Capture for Postgres Partitioned Tables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17k6nqz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698707657.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Blog - &lt;a href=\"https://blog.peerdb.io/real-time-change-data-capture-for-postgres-partitioned-tables\"&gt;https://blog.peerdb.io/real-time-change-data-capture-for-postgres-partitioned-tables&lt;/a&gt;&lt;br/&gt;\nThis is one of my favorite features that we shipped recently. Building Change Data Capture (CDC) for Postgres Partitioned Tables involves handling various scenarios that need care and emphasis.&lt;/p&gt;\n\n&lt;p&gt;We at &lt;a href=\"https://peerdb.io\"&gt;PeerDB&lt;/a&gt; are building a specialized data-movement tool for Postgres. So supporting this feature was a given and a self expectation. This feature was one of the top asks from customers. We will keep adding more such native features as we evolve. \ud83d\udc18 \ud83d\ude0a&lt;/p&gt;\n\n&lt;p&gt;Also, don&amp;#39;t forget to see the demo - it was a very candid one. \ud83d\ude0a I enjoyed covering different scenarios incl. adding new partitions, adding new columns, dropping partitions etc and showing how PeerDB handles replication for each of these cases.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/2W-69-HMB1Kln5rBlUsBq7hRSavCiF-sO3S2GWUFvVs.jpg?auto=webp&amp;s=f15558a233cb041e7cbb936e6d28481da5c669a9", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/2W-69-HMB1Kln5rBlUsBq7hRSavCiF-sO3S2GWUFvVs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d42d389c2eaf50f0d59909e9e8c4d27f35090cae", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/2W-69-HMB1Kln5rBlUsBq7hRSavCiF-sO3S2GWUFvVs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9c12d95bfb8dc5752d80f2e1e8efa12c412fda35", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/2W-69-HMB1Kln5rBlUsBq7hRSavCiF-sO3S2GWUFvVs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0f8a35b92ef215a27916e04e37db5214df581a13", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/2W-69-HMB1Kln5rBlUsBq7hRSavCiF-sO3S2GWUFvVs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8f17a26ccc3c95f27b9b04a213b6b847ac48a368", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/2W-69-HMB1Kln5rBlUsBq7hRSavCiF-sO3S2GWUFvVs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8d468c005cb1e5297dee15f1136930fb2a6bff9c", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/2W-69-HMB1Kln5rBlUsBq7hRSavCiF-sO3S2GWUFvVs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a833b762cb64708495e11e40c4ef4747b2cde979", "width": 1080, "height": 720}], "variants": {}, "id": "cBb2hhJuA-FHaSqfR3Lbm-5Henzo5jLdmsOWfRINUFs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17k6nqz", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17k6nqz/realtime_change_data_capture_for_postgres/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17k6nqz/realtime_change_data_capture_for_postgres/", "subreddit_subscribers": 137165, "created_utc": 1698707657.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}