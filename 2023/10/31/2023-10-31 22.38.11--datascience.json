{"kind": "Listing", "data": {"after": null, "dist": 11, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Got assigned some TS projects at work and now have kind of carved out this niche at my company. It\u2019s great career-wise but I feel like I\u2019d enjoy working with other ML approaches more. \n\nTime series at the scale I\u2019m doing it is basically just lightweight software development; at the end of the day all we do is train a bunch of transformers and models and see which is best for each time series, then use that to make a forecast. \n\nIt also seems that the simplest models (ETS, Theta) perform at least on par with fancy unexplainable models, so there is not much reason to use or even learn about them in depth. \n\nAnyone else find time series somewhat uninteresting? What can I do to get more interested it in?", "author_fullname": "t2_g7jmnu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone else find time series work a little dull?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17koo01", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 39, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 39, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698768668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got assigned some TS projects at work and now have kind of carved out this niche at my company. It\u2019s great career-wise but I feel like I\u2019d enjoy working with other ML approaches more. &lt;/p&gt;\n\n&lt;p&gt;Time series at the scale I\u2019m doing it is basically just lightweight software development; at the end of the day all we do is train a bunch of transformers and models and see which is best for each time series, then use that to make a forecast. &lt;/p&gt;\n\n&lt;p&gt;It also seems that the simplest models (ETS, Theta) perform at least on par with fancy unexplainable models, so there is not much reason to use or even learn about them in depth. &lt;/p&gt;\n\n&lt;p&gt;Anyone else find time series somewhat uninteresting? What can I do to get more interested it in?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17koo01", "is_robot_indexable": true, "report_reasons": null, "author": "_hairyberry_", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/", "subreddit_subscribers": 1107503, "created_utc": 1698768668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "prompt: female data scientist as a sealed action figure\n\n(needs couple retries)", "author_fullname": "t2_wvbdt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data scientist action figure - female version (dalle3)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_17kv7uh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/B03fsktbJmiqO3p1jdLqQ5ELK-f6t7Ml9t_g5b_UVZs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698785941.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;prompt: female data scientist as a sealed action figure&lt;/p&gt;\n\n&lt;p&gt;(needs couple retries)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/qmho6x9sqlxb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/qmho6x9sqlxb1.jpg?auto=webp&amp;s=0152303468b4064c84a1650396c3097a83f73f6e", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://preview.redd.it/qmho6x9sqlxb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=70e392f9ea54917571b1403beb8096452415953f", "width": 108, "height": 108}, {"url": "https://preview.redd.it/qmho6x9sqlxb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0bd867b98789056c3e74c010a8e3ea7524f30ffb", "width": 216, "height": 216}, {"url": "https://preview.redd.it/qmho6x9sqlxb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4cea46f7a378e0355d908bf8bf9503d3e537b4c4", "width": 320, "height": 320}, {"url": "https://preview.redd.it/qmho6x9sqlxb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f44fd8c7e310db455b5bfdc1d8d77317e86e5c9e", "width": 640, "height": 640}, {"url": "https://preview.redd.it/qmho6x9sqlxb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a01eb06e23c7ac72221c5e02d9c7617601f71dd3", "width": 960, "height": 960}], "variants": {}, "id": "gHQ7rlkKVXBm79IVVcygIVjhOMfJagdWjJn5em1UmPg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17kv7uh", "is_robot_indexable": true, "report_reasons": null, "author": "fulowa", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kv7uh/data_scientist_action_figure_female_version_dalle3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/qmho6x9sqlxb1.jpg", "subreddit_subscribers": 1107503, "created_utc": 1698785941.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry if this is a dumb question. But how are you all analyzing your models after fitting it with the training? Or in general? \n\nMy coworkers only use GLR for binomial type data. And that allows you to print out a full statistical summary from there. They use the pvalues from this summary to pick the features that are most significant to go into the final model and then test the data. I like this method for GLR but other algorithms aren\u2019t able to print summaries like this and I don\u2019t think we should limit ourselves to GLR only for future projects. \n\nSo how are you all analyzing the data to get insight on what features to use into these types of models? Most of my courses in school taught us to use the correlation matrix against the target. So I am a bit lost on this. I\u2019m not even sure how I would suggest using other algorithms for future business projects if they don\u2019t agree with using a correlation matrix or features of importance to pick the features.", "author_fullname": "t2_5akq1mi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you analyze your models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kp0nu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698769598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this is a dumb question. But how are you all analyzing your models after fitting it with the training? Or in general? &lt;/p&gt;\n\n&lt;p&gt;My coworkers only use GLR for binomial type data. And that allows you to print out a full statistical summary from there. They use the pvalues from this summary to pick the features that are most significant to go into the final model and then test the data. I like this method for GLR but other algorithms aren\u2019t able to print summaries like this and I don\u2019t think we should limit ourselves to GLR only for future projects. &lt;/p&gt;\n\n&lt;p&gt;So how are you all analyzing the data to get insight on what features to use into these types of models? Most of my courses in school taught us to use the correlation matrix against the target. So I am a bit lost on this. I\u2019m not even sure how I would suggest using other algorithms for future business projects if they don\u2019t agree with using a correlation matrix or features of importance to pick the features.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17kp0nu", "is_robot_indexable": true, "report_reasons": null, "author": "Dapper-Economy", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/", "subreddit_subscribers": 1107503, "created_utc": 1698769598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " So I have been reading up on SHAP values. I get that it works on the principle of game theory . Basically, just like we would want to allocate a payoff among the participants fairly, the same could be done to a statistical model.\n\nFor e.g. if we have a Linear regression model and we have ice cream sales as dependent variable. The independent variables are weather, location of the ice cream store, cost of the ice creams, some marketing efforts (pamphlets, bill boards, sales person etc.) . The SHAP value would ideally attribute the sales to the IVs cited above in varying order of importance.\n\nNow we already get a coefficient associated with each IV through linear regression. Thus giving us the importance of that particular variable.\n\nMy question is : Would a SHAP value applied on top of the Linear regression model discover the same 'truth'. That is, would the SHAP value identify the magnitude of importance of variables exactly like the regression coefficients?\n\nWhat has been your experience? Has SHAP worked for you in case LM or GLM models?\n\nWhat are the pitfalls of using SHAP?", "author_fullname": "t2_1umdosna", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any utility in using SHAP values for feature attribution in cases of Linear models and GLMs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kfjr0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698737668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have been reading up on SHAP values. I get that it works on the principle of game theory . Basically, just like we would want to allocate a payoff among the participants fairly, the same could be done to a statistical model.&lt;/p&gt;\n\n&lt;p&gt;For e.g. if we have a Linear regression model and we have ice cream sales as dependent variable. The independent variables are weather, location of the ice cream store, cost of the ice creams, some marketing efforts (pamphlets, bill boards, sales person etc.) . The SHAP value would ideally attribute the sales to the IVs cited above in varying order of importance.&lt;/p&gt;\n\n&lt;p&gt;Now we already get a coefficient associated with each IV through linear regression. Thus giving us the importance of that particular variable.&lt;/p&gt;\n\n&lt;p&gt;My question is : Would a SHAP value applied on top of the Linear regression model discover the same &amp;#39;truth&amp;#39;. That is, would the SHAP value identify the magnitude of importance of variables exactly like the regression coefficients?&lt;/p&gt;\n\n&lt;p&gt;What has been your experience? Has SHAP worked for you in case LM or GLM models?&lt;/p&gt;\n\n&lt;p&gt;What are the pitfalls of using SHAP?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17kfjr0", "is_robot_indexable": true, "report_reasons": null, "author": "venkarafa", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kfjr0/is_there_any_utility_in_using_shap_values_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kfjr0/is_there_any_utility_in_using_shap_values_for/", "subreddit_subscribers": 1107503, "created_utc": 1698737668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know a number of people express annoyance at interviews on this sub. I was raked over the coals a few months ago for apparently bad interview questions but my latest experience blows that out the water. I thought I'd give my experience from the other side of the desk which may go some way to showing why it can be so bad.\n\nI received a message last week saying that an online assessor for a Graduate Data Scientist role had dropped out and they needed volunteers to stand in. I volunteered to help.\n\nSomeone from HR sent me an email with a link to a training video and the interview platform. I watched the 30 min video at 1.5 speed which was mostly stuff like which buttons to press.\n\nThe day before I logged onto the assessment portal I reviewed the questions. I noticed that the questions were very generic but thought there might be some 'calibration' briefing before the interviews; it was too late to speak to HR.\n\nBefore the assessment day there was a HR call 30 mins before. It turned out to be just to check if anyone had technical issues. There was no 'calibration' brief. The call ended after 10 mins as the HR rep had to leave to chase no shows.\n\nI was dropped straight into a 'technical' interview 1 on 1 with the candidate. Although it was apparently technical most of the questions were very generic. E.g. Walk me through a project where you had to solve a problem.\n\nThere were criteria associated with the questions but there was no way you would answer them as the interviewee unless prompted. E.g in the above question a criterion might be 'The candidate readily accepts new ideas'. Given the short time (5 mins per question) it was not really possible to prompt for every criterion but I did try to enable the candidate to score highly but it meant the questioning was very disjointed.\n\nAfter a few of these there was the 'technical' section. These questions seemed to be totally left-field. E.g. you have two identical-size metal cubes how could you differentiate the material they are made of? Obviously this question is useless for the role and the CS-background interviewee needed lots of coaching to answer this.\n\nNext I had a soft skills interview with a different candidate. The questions again were vague and sensible answers would not meet the criteria.\n\nFinally there was a group activity and we were supposed to observe the 'teamwork' but the team just split the tasks and got on with them individually so there was hardly anything to observe.\n\nAfter this the HR bod asked us to complete all the assessments and submit them. Then we'd have a 'wash up'. The wash up was basically the place where scoring could be calibrated by discussing with the other assessors. Of course, the scores had already been submitted by then so this was entirely pointless.\n\nI also asked about the inappropriate technical questions and they said they didn't get the DS questions in time so had just used other technical questions (we were hiring other engineers/scientists at the same time).\n\nSo, as you can see, HR ruin everything they touch and hiring is a HR process so it's terrible. Sorry if you had to go through this.", "author_fullname": "t2_7q2ap", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why some data science interviews suck, as an interviewer...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17kvjmp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698786767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know a number of people express annoyance at interviews on this sub. I was raked over the coals a few months ago for apparently bad interview questions but my latest experience blows that out the water. I thought I&amp;#39;d give my experience from the other side of the desk which may go some way to showing why it can be so bad.&lt;/p&gt;\n\n&lt;p&gt;I received a message last week saying that an online assessor for a Graduate Data Scientist role had dropped out and they needed volunteers to stand in. I volunteered to help.&lt;/p&gt;\n\n&lt;p&gt;Someone from HR sent me an email with a link to a training video and the interview platform. I watched the 30 min video at 1.5 speed which was mostly stuff like which buttons to press.&lt;/p&gt;\n\n&lt;p&gt;The day before I logged onto the assessment portal I reviewed the questions. I noticed that the questions were very generic but thought there might be some &amp;#39;calibration&amp;#39; briefing before the interviews; it was too late to speak to HR.&lt;/p&gt;\n\n&lt;p&gt;Before the assessment day there was a HR call 30 mins before. It turned out to be just to check if anyone had technical issues. There was no &amp;#39;calibration&amp;#39; brief. The call ended after 10 mins as the HR rep had to leave to chase no shows.&lt;/p&gt;\n\n&lt;p&gt;I was dropped straight into a &amp;#39;technical&amp;#39; interview 1 on 1 with the candidate. Although it was apparently technical most of the questions were very generic. E.g. Walk me through a project where you had to solve a problem.&lt;/p&gt;\n\n&lt;p&gt;There were criteria associated with the questions but there was no way you would answer them as the interviewee unless prompted. E.g in the above question a criterion might be &amp;#39;The candidate readily accepts new ideas&amp;#39;. Given the short time (5 mins per question) it was not really possible to prompt for every criterion but I did try to enable the candidate to score highly but it meant the questioning was very disjointed.&lt;/p&gt;\n\n&lt;p&gt;After a few of these there was the &amp;#39;technical&amp;#39; section. These questions seemed to be totally left-field. E.g. you have two identical-size metal cubes how could you differentiate the material they are made of? Obviously this question is useless for the role and the CS-background interviewee needed lots of coaching to answer this.&lt;/p&gt;\n\n&lt;p&gt;Next I had a soft skills interview with a different candidate. The questions again were vague and sensible answers would not meet the criteria.&lt;/p&gt;\n\n&lt;p&gt;Finally there was a group activity and we were supposed to observe the &amp;#39;teamwork&amp;#39; but the team just split the tasks and got on with them individually so there was hardly anything to observe.&lt;/p&gt;\n\n&lt;p&gt;After this the HR bod asked us to complete all the assessments and submit them. Then we&amp;#39;d have a &amp;#39;wash up&amp;#39;. The wash up was basically the place where scoring could be calibrated by discussing with the other assessors. Of course, the scores had already been submitted by then so this was entirely pointless.&lt;/p&gt;\n\n&lt;p&gt;I also asked about the inappropriate technical questions and they said they didn&amp;#39;t get the DS questions in time so had just used other technical questions (we were hiring other engineers/scientists at the same time).&lt;/p&gt;\n\n&lt;p&gt;So, as you can see, HR ruin everything they touch and hiring is a HR process so it&amp;#39;s terrible. Sorry if you had to go through this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17kvjmp", "is_robot_indexable": true, "report_reasons": null, "author": "nth_citizen", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kvjmp/why_some_data_science_interviews_suck_as_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kvjmp/why_some_data_science_interviews_suck_as_an/", "subreddit_subscribers": 1107503, "created_utc": 1698786767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey y'all, I made a [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) here last month about my team spending too much time on ad-hoc SQL requests.\n\nSo I partnered up with a friend created an AI data assistant to automate ad-hoc SQL requests. It's basically a text to SQL interface for your users. We're looking for a design partner to use our product for free in exchange for feedback.\n\nIn the original [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) there were concerns with trusting an LLM to produce accurate queries. We think there are too, it's not perfect yet. That's why we'd love to partner up with you guys to figure out a way to design a system that can be trusted and reliable, and at the very least, automates the 80% of ad-hoc questions that should be self-served\n\nDM or comment if you're interested and we'll set something up! Would love to hear some feedback, positive or negative, from y'all", "author_fullname": "t2_l386p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "automating ad-hoc SQL requests from stakeholders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kpxml", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698772053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all, I made a &lt;a href=\"https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/\"&gt;post&lt;/a&gt; here last month about my team spending too much time on ad-hoc SQL requests.&lt;/p&gt;\n\n&lt;p&gt;So I partnered up with a friend created an AI data assistant to automate ad-hoc SQL requests. It&amp;#39;s basically a text to SQL interface for your users. We&amp;#39;re looking for a design partner to use our product for free in exchange for feedback.&lt;/p&gt;\n\n&lt;p&gt;In the original &lt;a href=\"https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/\"&gt;post&lt;/a&gt; there were concerns with trusting an LLM to produce accurate queries. We think there are too, it&amp;#39;s not perfect yet. That&amp;#39;s why we&amp;#39;d love to partner up with you guys to figure out a way to design a system that can be trusted and reliable, and at the very least, automates the 80% of ad-hoc questions that should be self-served&lt;/p&gt;\n\n&lt;p&gt;DM or comment if you&amp;#39;re interested and we&amp;#39;ll set something up! Would love to hear some feedback, positive or negative, from y&amp;#39;all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17kpxml", "is_robot_indexable": true, "report_reasons": null, "author": "ruckrawjers", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/", "subreddit_subscribers": 1107503, "created_utc": 1698772053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Would appreciate other website suggestions too.", "author_fullname": "t2_bmxqugb8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Upwork a good place to find data science freelance gigs in the UK ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kmu0e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698763882.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would appreciate other website suggestions too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17kmu0e", "is_robot_indexable": true, "report_reasons": null, "author": "FreakedoutNeurotic98", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kmu0e/is_upwork_a_good_place_to_find_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kmu0e/is_upwork_a_good_place_to_find_data_science/", "subreddit_subscribers": 1107503, "created_utc": 1698763882.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a technical interview coming up. The focus will be cleaning unstructured data with Pandas. Are there specific resources for this type of interviews other than just practicing with Kaggle?", "author_fullname": "t2_dc8euqz6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Resources for technical interviews with focus on cleaning unstructured data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17kvm37", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698786949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a technical interview coming up. The focus will be cleaning unstructured data with Pandas. Are there specific resources for this type of interviews other than just practicing with Kaggle?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17kvm37", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Bed5587", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kvm37/resources_for_technical_interviews_with_focus_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kvm37/resources_for_technical_interviews_with_focus_on/", "subreddit_subscribers": 1107503, "created_utc": 1698786949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My company offers tuition assistance and I'm thinking about going back for a formal degree, but it'd need to be online in a way I can do while working. I have a Bsc in statistics and an MSc in an unrelated field that I lucked out in being able to take quant-ier courses and leverage an internship into a job, but I feel like there's gaps in my math and experience with some of the newer ML methods &amp; neural networks in particular. \n\nI'm thinking of the Georgia Tech one but would be curious to hear about others.", "author_fullname": "t2_89ar1fajx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "If you did an online MSc in Stats and/or DS or something in that area &amp; liked it, what program was it and what did you like about it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ktlc5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698781586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company offers tuition assistance and I&amp;#39;m thinking about going back for a formal degree, but it&amp;#39;d need to be online in a way I can do while working. I have a Bsc in statistics and an MSc in an unrelated field that I lucked out in being able to take quant-ier courses and leverage an internship into a job, but I feel like there&amp;#39;s gaps in my math and experience with some of the newer ML methods &amp;amp; neural networks in particular. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking of the Georgia Tech one but would be curious to hear about others.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "17ktlc5", "is_robot_indexable": true, "report_reasons": null, "author": "AnxiousEgg6284", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ktlc5/if_you_did_an_online_msc_in_stats_andor_ds_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ktlc5/if_you_did_an_online_msc_in_stats_andor_ds_or/", "subreddit_subscribers": 1107503, "created_utc": 1698781586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it right to assume that the reason, the validation loss (inside the purple box) is fluctuating so much is due to small batch size? What are other reasons due to which loss validation could be fluctuating so much? All hyperparameter values are given in the bottom left of the image.\n\nI'm using BinaryCrossentropy loss function. The problem I'm trying to  solve is from the kaggle's titanic competition. Basically, it's tabular  structured data that has features 'TicketClass', 'Name', 'Sex', 'Age',  'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is  'Survived'(1/0). Let me know if you need more info.\n\nhttps://preview.redd.it/gerrkzyzxjxb1.png?width=1087&amp;format=png&amp;auto=webp&amp;s=b20530593f527d138a190a33740e752692d984aa", "author_fullname": "t2_hcgjj0xo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the possible reasons for validation loss to fluctuate so much?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"gerrkzyzxjxb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e2a5627af7b1c267249de3a3e7f0ff925f0b3aa"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a6b403d79031bd86f826c73bfa42c859981b8306"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bd5e667d6c545449021465ebfd60cd8bf51b2ee9"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8330db62adf83621f9466ea9aec74bc7c388347c"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=911c8213651e7ab675c2811cc1cf28983a6ae038"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1ec96c1e6f9b25fc17e998f016ac3ffafd21c19b"}], "s": {"y": 816, "x": 1087, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&amp;format=png&amp;auto=webp&amp;s=b20530593f527d138a190a33740e752692d984aa"}, "id": "gerrkzyzxjxb1"}}, "name": "t3_17kmxnc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fpweJb1vOAfmPPotR_URI75nCKNS8GeENhE2Rtp6YPU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698764164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it right to assume that the reason, the validation loss (inside the purple box) is fluctuating so much is due to small batch size? What are other reasons due to which loss validation could be fluctuating so much? All hyperparameter values are given in the bottom left of the image.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using BinaryCrossentropy loss function. The problem I&amp;#39;m trying to  solve is from the kaggle&amp;#39;s titanic competition. Basically, it&amp;#39;s tabular  structured data that has features &amp;#39;TicketClass&amp;#39;, &amp;#39;Name&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Age&amp;#39;,  &amp;#39;SiblingsBoarded&amp;#39;, &amp;#39;ParentsBoarded&amp;#39;, &amp;#39;Fare&amp;#39;, &amp;#39;Embarked&amp;#39; and target is  &amp;#39;Survived&amp;#39;(1/0). Let me know if you need more info.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b20530593f527d138a190a33740e752692d984aa\"&gt;https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b20530593f527d138a190a33740e752692d984aa&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "17kmxnc", "is_robot_indexable": true, "report_reasons": null, "author": "Total-Opposite-8396", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kmxnc/what_are_the_possible_reasons_for_validation_loss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kmxnc/what_are_the_possible_reasons_for_validation_loss/", "subreddit_subscribers": 1107503, "created_utc": 1698764164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019ll compile answers and write an article with the summary", "author_fullname": "t2_dif6b393", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Describe the analytics tool of your dreams\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17kvn2f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698787019.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ll compile answers and write an article with the summary&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17kvn2f", "is_robot_indexable": true, "report_reasons": null, "author": "ExpressOcelot8977", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kvn2f/describe_the_analytics_tool_of_your_dreams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kvn2f/describe_the_analytics_tool_of_your_dreams/", "subreddit_subscribers": 1107503, "created_utc": 1698787019.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}