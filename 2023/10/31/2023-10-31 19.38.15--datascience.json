{"kind": "Listing", "data": {"after": null, "dist": 8, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "prompt: data scientist as a sealed action figure", "author_fullname": "t2_wvbdt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Scientist action figure (dalle3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_17kl7ve", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "ups": 298, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 298, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/hxu_foI1v9hrRrNxv9L0SAP59gXHZ1wwCXnT31fhFao.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698759398.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;prompt: data scientist as a sealed action figure&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/cfd8yawujjxb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/cfd8yawujjxb1.jpg?auto=webp&amp;s=86aa0dcacc83e325b5b10718ad58f9747534a9a8", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://preview.redd.it/cfd8yawujjxb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=d5ce918c9d33901aada13f25db0620bc81d219f6", "width": 108, "height": 108}, {"url": "https://preview.redd.it/cfd8yawujjxb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c7884e8af7d17a81401c1c295d8d755fe34d8f68", "width": 216, "height": 216}, {"url": "https://preview.redd.it/cfd8yawujjxb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=89c705f05b3ffb8f07b38f7eed89ea7f8d6a8f34", "width": 320, "height": 320}, {"url": "https://preview.redd.it/cfd8yawujjxb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=938c0b14e64569f807aa97e696bdd5cadb9e0188", "width": 640, "height": 640}, {"url": "https://preview.redd.it/cfd8yawujjxb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=66ad68a82985ace087fa883654bb0abbf3d9e8fc", "width": 960, "height": 960}], "variants": {}, "id": "VEM1x17cP7YXZQWwBF-d0hgoxFkqlbr-80aIwiDwyIE"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17kl7ve", "is_robot_indexable": true, "report_reasons": null, "author": "fulowa", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kl7ve/data_scientist_action_figure_dalle3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/cfd8yawujjxb1.jpg", "subreddit_subscribers": 1107328, "created_utc": 1698759398.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Got assigned some TS projects at work and now have kind of carved out this niche at my company. It\u2019s great career-wise but I feel like I\u2019d enjoy working with other ML approaches more. \n\nTime series at the scale I\u2019m doing it is basically just lightweight software development; at the end of the day all we do is train a bunch of transformers and models and see which is best for each time series, then use that to make a forecast. \n\nIt also seems that the simplest models (ETS, Theta) perform at least on par with fancy unexplainable models, so there is not much reason to use or even learn about them in depth. \n\nAnyone else find time series somewhat uninteresting? What can I do to get more interested it in?", "author_fullname": "t2_g7jmnu5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone else find time series work a little dull?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17koo01", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698768668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got assigned some TS projects at work and now have kind of carved out this niche at my company. It\u2019s great career-wise but I feel like I\u2019d enjoy working with other ML approaches more. &lt;/p&gt;\n\n&lt;p&gt;Time series at the scale I\u2019m doing it is basically just lightweight software development; at the end of the day all we do is train a bunch of transformers and models and see which is best for each time series, then use that to make a forecast. &lt;/p&gt;\n\n&lt;p&gt;It also seems that the simplest models (ETS, Theta) perform at least on par with fancy unexplainable models, so there is not much reason to use or even learn about them in depth. &lt;/p&gt;\n\n&lt;p&gt;Anyone else find time series somewhat uninteresting? What can I do to get more interested it in?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17koo01", "is_robot_indexable": true, "report_reasons": null, "author": "_hairyberry_", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17koo01/anyone_else_find_time_series_work_a_little_dull/", "subreddit_subscribers": 1107328, "created_utc": 1698768668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " So I have been reading up on SHAP values. I get that it works on the principle of game theory . Basically, just like we would want to allocate a payoff among the participants fairly, the same could be done to a statistical model.\n\nFor e.g. if we have a Linear regression model and we have ice cream sales as dependent variable. The independent variables are weather, location of the ice cream store, cost of the ice creams, some marketing efforts (pamphlets, bill boards, sales person etc.) . The SHAP value would ideally attribute the sales to the IVs cited above in varying order of importance.\n\nNow we already get a coefficient associated with each IV through linear regression. Thus giving us the importance of that particular variable.\n\nMy question is : Would a SHAP value applied on top of the Linear regression model discover the same 'truth'. That is, would the SHAP value identify the magnitude of importance of variables exactly like the regression coefficients?\n\nWhat has been your experience? Has SHAP worked for you in case LM or GLM models?\n\nWhat are the pitfalls of using SHAP?", "author_fullname": "t2_1umdosna", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any utility in using SHAP values for feature attribution in cases of Linear models and GLMs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kfjr0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698737668.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have been reading up on SHAP values. I get that it works on the principle of game theory . Basically, just like we would want to allocate a payoff among the participants fairly, the same could be done to a statistical model.&lt;/p&gt;\n\n&lt;p&gt;For e.g. if we have a Linear regression model and we have ice cream sales as dependent variable. The independent variables are weather, location of the ice cream store, cost of the ice creams, some marketing efforts (pamphlets, bill boards, sales person etc.) . The SHAP value would ideally attribute the sales to the IVs cited above in varying order of importance.&lt;/p&gt;\n\n&lt;p&gt;Now we already get a coefficient associated with each IV through linear regression. Thus giving us the importance of that particular variable.&lt;/p&gt;\n\n&lt;p&gt;My question is : Would a SHAP value applied on top of the Linear regression model discover the same &amp;#39;truth&amp;#39;. That is, would the SHAP value identify the magnitude of importance of variables exactly like the regression coefficients?&lt;/p&gt;\n\n&lt;p&gt;What has been your experience? Has SHAP worked for you in case LM or GLM models?&lt;/p&gt;\n\n&lt;p&gt;What are the pitfalls of using SHAP?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17kfjr0", "is_robot_indexable": true, "report_reasons": null, "author": "venkarafa", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kfjr0/is_there_any_utility_in_using_shap_values_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kfjr0/is_there_any_utility_in_using_shap_values_for/", "subreddit_subscribers": 1107328, "created_utc": 1698737668.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Would appreciate other website suggestions too.", "author_fullname": "t2_bmxqugb8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Upwork a good place to find data science freelance gigs in the UK ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kmu0e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698763882.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would appreciate other website suggestions too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17kmu0e", "is_robot_indexable": true, "report_reasons": null, "author": "FreakedoutNeurotic98", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kmu0e/is_upwork_a_good_place_to_find_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kmu0e/is_upwork_a_good_place_to_find_data_science/", "subreddit_subscribers": 1107328, "created_utc": 1698763882.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey y'all, I made a [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) here last month about my team spending too much time on ad-hoc SQL requests.\n\nSo I partnered up with a friend created an AI data assistant to automate ad-hoc SQL requests. It's basically a text to SQL interface for your users. We're looking for a design partner to use our product for free in exchange for feedback.\n\nIn the original [post](https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/) there were concerns with trusting an LLM to produce accurate queries. We think there are too, it's not perfect yet. That's why we'd love to partner up with you guys to figure out a way to design a system that can be trusted and reliable, and at the very least, automates the 80% of ad-hoc questions that should be self-served\n\nDM or comment if you're interested and we'll set something up! Would love to hear some feedback, positive or negative, from y'all", "author_fullname": "t2_l386p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "automating ad-hoc SQL requests from stakeholders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kpxml", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698772053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey y&amp;#39;all, I made a &lt;a href=\"https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/\"&gt;post&lt;/a&gt; here last month about my team spending too much time on ad-hoc SQL requests.&lt;/p&gt;\n\n&lt;p&gt;So I partnered up with a friend created an AI data assistant to automate ad-hoc SQL requests. It&amp;#39;s basically a text to SQL interface for your users. We&amp;#39;re looking for a design partner to use our product for free in exchange for feedback.&lt;/p&gt;\n\n&lt;p&gt;In the original &lt;a href=\"https://www.reddit.com/r/datascience/comments/16rvrrx/anyone_else_here_bogged_down_with_adhoc_sql/\"&gt;post&lt;/a&gt; there were concerns with trusting an LLM to produce accurate queries. We think there are too, it&amp;#39;s not perfect yet. That&amp;#39;s why we&amp;#39;d love to partner up with you guys to figure out a way to design a system that can be trusted and reliable, and at the very least, automates the 80% of ad-hoc questions that should be self-served&lt;/p&gt;\n\n&lt;p&gt;DM or comment if you&amp;#39;re interested and we&amp;#39;ll set something up! Would love to hear some feedback, positive or negative, from y&amp;#39;all&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17kpxml", "is_robot_indexable": true, "report_reasons": null, "author": "ruckrawjers", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kpxml/automating_adhoc_sql_requests_from_stakeholders/", "subreddit_subscribers": 1107328, "created_utc": 1698772053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Sorry if this is a dumb question. But how are you all analyzing your models after fitting it with the training? Or in general? \n\nMy coworkers only use GLR for binomial type data. And that allows you to print out a full statistical summary from there. They use the pvalues from this summary to pick the features that are most significant to go into the final model and then test the data. I like this method for GLR but other algorithms aren\u2019t able to print summaries like this and I don\u2019t think we should limit ourselves to GLR only for future projects. \n\nSo how are you all analyzing the data to get insight on what features to use into these types of models? Most of my courses in school taught us to use the correlation matrix against the target. So I am a bit lost on this. I\u2019m not even sure how I would suggest using other algorithms for future business projects if they don\u2019t agree with using a correlation matrix or features of importance to pick the features.", "author_fullname": "t2_5akq1mi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you analyze your models?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17kp0nu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698769598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sorry if this is a dumb question. But how are you all analyzing your models after fitting it with the training? Or in general? &lt;/p&gt;\n\n&lt;p&gt;My coworkers only use GLR for binomial type data. And that allows you to print out a full statistical summary from there. They use the pvalues from this summary to pick the features that are most significant to go into the final model and then test the data. I like this method for GLR but other algorithms aren\u2019t able to print summaries like this and I don\u2019t think we should limit ourselves to GLR only for future projects. &lt;/p&gt;\n\n&lt;p&gt;So how are you all analyzing the data to get insight on what features to use into these types of models? Most of my courses in school taught us to use the correlation matrix against the target. So I am a bit lost on this. I\u2019m not even sure how I would suggest using other algorithms for future business projects if they don\u2019t agree with using a correlation matrix or features of importance to pick the features.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17kp0nu", "is_robot_indexable": true, "report_reasons": null, "author": "Dapper-Economy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kp0nu/how_do_you_analyze_your_models/", "subreddit_subscribers": 1107328, "created_utc": 1698769598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Is it right to assume that the reason, the validation loss (inside the purple box) is fluctuating so much is due to small batch size? What are other reasons due to which loss validation could be fluctuating so much? All hyperparameter values are given in the bottom left of the image.\n\nI'm using BinaryCrossentropy loss function. The problem I'm trying to  solve is from the kaggle's titanic competition. Basically, it's tabular  structured data that has features 'TicketClass', 'Name', 'Sex', 'Age',  'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is  'Survived'(1/0). Let me know if you need more info.\n\nhttps://preview.redd.it/gerrkzyzxjxb1.png?width=1087&amp;format=png&amp;auto=webp&amp;s=b20530593f527d138a190a33740e752692d984aa", "author_fullname": "t2_hcgjj0xo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the possible reasons for validation loss to fluctuate so much?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "media_metadata": {"gerrkzyzxjxb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=8e2a5627af7b1c267249de3a3e7f0ff925f0b3aa"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a6b403d79031bd86f826c73bfa42c859981b8306"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=bd5e667d6c545449021465ebfd60cd8bf51b2ee9"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=8330db62adf83621f9466ea9aec74bc7c388347c"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=911c8213651e7ab675c2811cc1cf28983a6ae038"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1ec96c1e6f9b25fc17e998f016ac3ffafd21c19b"}], "s": {"y": 816, "x": 1087, "u": "https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&amp;format=png&amp;auto=webp&amp;s=b20530593f527d138a190a33740e752692d984aa"}, "id": "gerrkzyzxjxb1"}}, "name": "t3_17kmxnc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fpweJb1vOAfmPPotR_URI75nCKNS8GeENhE2Rtp6YPU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698764164.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it right to assume that the reason, the validation loss (inside the purple box) is fluctuating so much is due to small batch size? What are other reasons due to which loss validation could be fluctuating so much? All hyperparameter values are given in the bottom left of the image.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using BinaryCrossentropy loss function. The problem I&amp;#39;m trying to  solve is from the kaggle&amp;#39;s titanic competition. Basically, it&amp;#39;s tabular  structured data that has features &amp;#39;TicketClass&amp;#39;, &amp;#39;Name&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Age&amp;#39;,  &amp;#39;SiblingsBoarded&amp;#39;, &amp;#39;ParentsBoarded&amp;#39;, &amp;#39;Fare&amp;#39;, &amp;#39;Embarked&amp;#39; and target is  &amp;#39;Survived&amp;#39;(1/0). Let me know if you need more info.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b20530593f527d138a190a33740e752692d984aa\"&gt;https://preview.redd.it/gerrkzyzxjxb1.png?width=1087&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=b20530593f527d138a190a33740e752692d984aa&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "17kmxnc", "is_robot_indexable": true, "report_reasons": null, "author": "Total-Opposite-8396", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17kmxnc/what_are_the_possible_reasons_for_validation_loss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17kmxnc/what_are_the_possible_reasons_for_validation_loss/", "subreddit_subscribers": 1107328, "created_utc": 1698764164.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I've seen a few people talk cursor [https://cursor.sh/](https://cursor.sh/) for software saying that it was good. Has anyone tried it for data science?  ", "author_fullname": "t2_c2he9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone tried Cursor.sh AI editor for data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17k3svb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "AI", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698700202.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen a few people talk cursor &lt;a href=\"https://cursor.sh/\"&gt;https://cursor.sh/&lt;/a&gt; for software saying that it was good. Has anyone tried it for data science?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?auto=webp&amp;s=ddd8534bccd1e9ba238ef21b5d0fc7c4c457fb97", "width": 1280, "height": 768}, "resolutions": [{"url": "https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7185039b9858f428266b2f6416be37e60f4e6f23", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c09e7c93e2dddf120954de9f757c970ff207dcce", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=df9fb53b9d7a724ddb7e217e326075f7decdcecc", "width": 320, "height": 192}, {"url": "https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1aeb9824b09f337e027493de1389cc5ec0f4c42a", "width": 640, "height": 384}, {"url": "https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=279b74c69dbc47d261554d71fca84f23354f789f", "width": 960, "height": 576}, {"url": "https://external-preview.redd.it/rR6D6u0s1YlkkcDirob8pWwxSQgeIBu5ttGqeLtbVgc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2ae3a7c8bd64d82a6d257c2b53f158916fa969af", "width": 1080, "height": 648}], "variants": {}, "id": "I0Ul3MOzbyiZw9IRp9XDSogkzkh7d8CGD6U_MgNb1SA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2f731e52-70eb-11ee-bec5-5a5142e6a4d2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#46d160", "id": "17k3svb", "is_robot_indexable": true, "report_reasons": null, "author": "soggypocket", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17k3svb/has_anyone_tried_cursorsh_ai_editor_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17k3svb/has_anyone_tried_cursorsh_ai_editor_for_data/", "subreddit_subscribers": 1107328, "created_utc": 1698700202.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}