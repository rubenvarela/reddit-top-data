{"kind": "Listing", "data": {"after": null, "dist": 21, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "how did it begin?", "author_fullname": "t2_hlypar61", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any &lt;20 year olds here? How did you get into this hobby?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17hbvcc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698369047.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;how did it begin?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "34TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17hbvcc", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic_Cup_8436", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17hbvcc/any_20_year_olds_here_how_did_you_get_into_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17hbvcc/any_20_year_olds_here_how_did_you_get_into_this/", "subreddit_subscribers": 708916, "created_utc": 1698369047.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI am about to undergo a major change in my home NAS configuration moving from a RAID ext4 config to a ZFS filesystem with TrueNAS.\n\nI need temporary storage for my data (\\~45TB) -&gt; excluding upload &amp; download time, I estimate this to be 1-2 days. Is there a solution out there I can use?", "author_fullname": "t2_cxhmpy2s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Temporary Capacity for 45TB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17grsf4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698308956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am about to undergo a major change in my home NAS configuration moving from a RAID ext4 config to a ZFS filesystem with TrueNAS.&lt;/p&gt;\n\n&lt;p&gt;I need temporary storage for my data (~45TB) -&amp;gt; excluding upload &amp;amp; download time, I estimate this to be 1-2 days. Is there a solution out there I can use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "30TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17grsf4", "is_robot_indexable": true, "report_reasons": null, "author": "seriouslyfun95", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17grsf4/temporary_capacity_for_45tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17grsf4/temporary_capacity_for_45tb/", "subreddit_subscribers": 708916, "created_utc": 1698308956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_7i5d3bi3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Accidently got an sas hdd, is this what I need to connect it? I have a spare pcie3 slot and wouldn't mind spending 30 more bucks to have an extra sas slot for future instead of returning the drive and getting sata.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_17he7zq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5583R1MGFeox92STZx3sirrzFn40njWBd4HYeZKhBFY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698376476.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/2btipyj8xnwb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/2btipyj8xnwb1.png?auto=webp&amp;s=f3933a43153177ed08efcbd2591a298b7aa33ee8", "width": 720, "height": 777}, "resolutions": [{"url": "https://preview.redd.it/2btipyj8xnwb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=dcb2a70b92ddd6bb735ca2f4622637dbf19a5de0", "width": 108, "height": 116}, {"url": "https://preview.redd.it/2btipyj8xnwb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=adc1cd2655f80c1def61872ae1789bfed6953643", "width": 216, "height": 233}, {"url": "https://preview.redd.it/2btipyj8xnwb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=76725b0222ccefdf866d35fed193001a62e31832", "width": 320, "height": 345}, {"url": "https://preview.redd.it/2btipyj8xnwb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=90101b30b1e3dd96da20403ba697aa85f6f43220", "width": 640, "height": 690}], "variants": {}, "id": "Qlc737F8_OSaU7uuVmhrJIqNDBPRxjehvvTjx2eTxI0"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17he7zq", "is_robot_indexable": true, "report_reasons": null, "author": "Accomplished_Fan_880", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17he7zq/accidently_got_an_sas_hdd_is_this_what_i_need_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/2btipyj8xnwb1.png", "subreddit_subscribers": 708916, "created_utc": 1698376476.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been working on archiving media for my family, photos that I save as jpegs and films, haven't gotten will get there.\n\nThis got me thinking about the risk of file types getting extinct and unreadable \u2013 how should one approach that if the goal is (as long term as possible) archival of data? \n\nI suppose film formats are more vulnerable since algorithms are more complex \u2013 but it also feel to me like the common formats are so widly spread that there will always be a way. What are your thoughts?", "author_fullname": "t2_61hn66ao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Risk of file types dying", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gs1nx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698310158.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working on archiving media for my family, photos that I save as jpegs and films, haven&amp;#39;t gotten will get there.&lt;/p&gt;\n\n&lt;p&gt;This got me thinking about the risk of file types getting extinct and unreadable \u2013 how should one approach that if the goal is (as long term as possible) archival of data? &lt;/p&gt;\n\n&lt;p&gt;I suppose film formats are more vulnerable since algorithms are more complex \u2013 but it also feel to me like the common formats are so widly spread that there will always be a way. What are your thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17gs1nx", "is_robot_indexable": true, "report_reasons": null, "author": "Primary_Season7533", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17gs1nx/risk_of_file_types_dying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17gs1nx/risk_of_file_types_dying/", "subreddit_subscribers": 708916, "created_utc": 1698310158.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Although my Drobo still works, my computer does not, so if I am updating my computer to a new mac, might as well update my Drobo, to another DAS that is reliable.\n\nAs a photographer, I am not needing a NAS, as I only have one computer and do not share information to other devices. Its use is to hold the RAW photo file, edit the image and the finished ones and the whole Drobo is backed up to Backblaze. Simple enough setup.\n\nAre there any RAID DAS systems available like the Drobo 5D3? \n\nDo any of them allow hot swapping of drives like the Drobo did?\n\nI am looking at the OWC Thunder-bay Raid, but a would love other DAS suggestions.\n\nI realize the OWC does not allow hot swapping and what you setup at the beginning is what you get.\n\nAppreciate it.", "author_fullname": "t2_ly2vfl65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Coming from Drobo 5d3. Any recommended DAS systems?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17h4caj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698348243.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Although my Drobo still works, my computer does not, so if I am updating my computer to a new mac, might as well update my Drobo, to another DAS that is reliable.&lt;/p&gt;\n\n&lt;p&gt;As a photographer, I am not needing a NAS, as I only have one computer and do not share information to other devices. Its use is to hold the RAW photo file, edit the image and the finished ones and the whole Drobo is backed up to Backblaze. Simple enough setup.&lt;/p&gt;\n\n&lt;p&gt;Are there any RAID DAS systems available like the Drobo 5D3? &lt;/p&gt;\n\n&lt;p&gt;Do any of them allow hot swapping of drives like the Drobo did?&lt;/p&gt;\n\n&lt;p&gt;I am looking at the OWC Thunder-bay Raid, but a would love other DAS suggestions.&lt;/p&gt;\n\n&lt;p&gt;I realize the OWC does not allow hot swapping and what you setup at the beginning is what you get.&lt;/p&gt;\n\n&lt;p&gt;Appreciate it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17h4caj", "is_robot_indexable": true, "report_reasons": null, "author": "ilzphotos", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17h4caj/coming_from_drobo_5d3_any_recommended_das_systems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17h4caj/coming_from_drobo_5d3_any_recommended_das_systems/", "subreddit_subscribers": 708916, "created_utc": 1698348243.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know this is Data *Hoarder* and I'm asking for advice on how to do the opposite and make sure something is *deleted,* but honestly I don't really know where else a post like this could go and the people on this sub seem to be pretty knowledgeable on these topics. Plus, someone could probably learn a thing or two from this post on how they may be able to better hoard or recover supposedly lost data if they didn't know about the MFT.    \n\nA little backstory, I was recently cleaning up my devices (I'm the type of person who usually never cleans up their downloads folder then gets surprised when I realize it's accumulated to taking up like half of my disk space) and doing a little bit more learning about how computers work in general while doing so. Younger me was incredibly stupid and stored some pretty sensitive info (as sensitive as my passport number, my country's equivalent to a SSN, and some passwords to pretty important accounts) in text files in a folder. I completely forgot about these and being older and now smart enough to know not to do that even though I don't expect to download any viruses or have anyone else use my computer, I just deleted these .txt files and figured that my SSD's garbage collection would take care of them whenever it next occurs.   \n\nBut after doing a little more learning about this whole thing and learned some more about how computers work, I found out that NTFS, the main format used for Windows computers, has this thing called a \"Master File Table\", and that any files under 1kb are stored *inside* of it. It's practically inaccessible to regular users without complex software but the jist of it is that even if you delete a file, if it's under 1kb, it will never truly be deleted as it's stored as a \"resident\" of the MFT. And you can't access or edit it like a regular file/folder, so you can't just go in, find the small file, and delete it individually. This means that technically a dedicated attacker or malware could pull any small files from the MFT, even if you deleted them long ago and thought they were overwritten.   \n\nNow I'm kind of worried because this means that all those passwords, my SSN, passport number and other sensitive information that stupid younger me decided to write down in text files are now stuck in the darkest depths of my computer unable to be deleted by any conventional means, but also readily accessible to a dedicated enough intruder, unless I reformat my entire boot drive where these text files were deleted from and reinstall Windows. Now I would obviously really like to not do that - reinstalling the years' worth of software I have installed and setting everything back up to my liking is not really something I want (or have the time) to do.  \n\nSo to all the much more tech-savvy folks on this sub, is there any other way I can go about this? Is there a software that can safely and reliably delete these text files, and any other &lt;1kb stuff from the MFT, without me having to do a full reformat? In the limited research I did, I saw a few people mention various programs, but most of those recommendations were followed by someone saying *not* to use it for one of various reasons, most commonly that it would screw with core Windows functions and cause instability, or that it was unreliable for one reason or another. I also saw a lot of people mentioning that something that may work for an HDD wouldn't work on an SSD or vice versa. If someone who knows more about this stuff than I do could explain it to me, I would hugely appreciate it!", "author_fullname": "t2_m5c2xzrq8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to safely and securely delete \"resident\" files from the MFT on an NTFS-formatted drive without having to reformat the entire thing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17h1n44", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698341040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this is Data &lt;em&gt;Hoarder&lt;/em&gt; and I&amp;#39;m asking for advice on how to do the opposite and make sure something is &lt;em&gt;deleted,&lt;/em&gt; but honestly I don&amp;#39;t really know where else a post like this could go and the people on this sub seem to be pretty knowledgeable on these topics. Plus, someone could probably learn a thing or two from this post on how they may be able to better hoard or recover supposedly lost data if they didn&amp;#39;t know about the MFT.    &lt;/p&gt;\n\n&lt;p&gt;A little backstory, I was recently cleaning up my devices (I&amp;#39;m the type of person who usually never cleans up their downloads folder then gets surprised when I realize it&amp;#39;s accumulated to taking up like half of my disk space) and doing a little bit more learning about how computers work in general while doing so. Younger me was incredibly stupid and stored some pretty sensitive info (as sensitive as my passport number, my country&amp;#39;s equivalent to a SSN, and some passwords to pretty important accounts) in text files in a folder. I completely forgot about these and being older and now smart enough to know not to do that even though I don&amp;#39;t expect to download any viruses or have anyone else use my computer, I just deleted these .txt files and figured that my SSD&amp;#39;s garbage collection would take care of them whenever it next occurs.   &lt;/p&gt;\n\n&lt;p&gt;But after doing a little more learning about this whole thing and learned some more about how computers work, I found out that NTFS, the main format used for Windows computers, has this thing called a &amp;quot;Master File Table&amp;quot;, and that any files under 1kb are stored &lt;em&gt;inside&lt;/em&gt; of it. It&amp;#39;s practically inaccessible to regular users without complex software but the jist of it is that even if you delete a file, if it&amp;#39;s under 1kb, it will never truly be deleted as it&amp;#39;s stored as a &amp;quot;resident&amp;quot; of the MFT. And you can&amp;#39;t access or edit it like a regular file/folder, so you can&amp;#39;t just go in, find the small file, and delete it individually. This means that technically a dedicated attacker or malware could pull any small files from the MFT, even if you deleted them long ago and thought they were overwritten.   &lt;/p&gt;\n\n&lt;p&gt;Now I&amp;#39;m kind of worried because this means that all those passwords, my SSN, passport number and other sensitive information that stupid younger me decided to write down in text files are now stuck in the darkest depths of my computer unable to be deleted by any conventional means, but also readily accessible to a dedicated enough intruder, unless I reformat my entire boot drive where these text files were deleted from and reinstall Windows. Now I would obviously really like to not do that - reinstalling the years&amp;#39; worth of software I have installed and setting everything back up to my liking is not really something I want (or have the time) to do.  &lt;/p&gt;\n\n&lt;p&gt;So to all the much more tech-savvy folks on this sub, is there any other way I can go about this? Is there a software that can safely and reliably delete these text files, and any other &amp;lt;1kb stuff from the MFT, without me having to do a full reformat? In the limited research I did, I saw a few people mention various programs, but most of those recommendations were followed by someone saying &lt;em&gt;not&lt;/em&gt; to use it for one of various reasons, most commonly that it would screw with core Windows functions and cause instability, or that it was unreliable for one reason or another. I also saw a lot of people mentioning that something that may work for an HDD wouldn&amp;#39;t work on an SSD or vice versa. If someone who knows more about this stuff than I do could explain it to me, I would hugely appreciate it!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17h1n44", "is_robot_indexable": true, "report_reasons": null, "author": "barrendeser7", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17h1n44/is_there_a_way_to_safely_and_securely_delete/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17h1n44/is_there_a_way_to_safely_and_securely_delete/", "subreddit_subscribers": 708916, "created_utc": 1698341040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Can someone explain the difference between the Long Drive Test vs Long Generic Test in SeaTools?\n\nSeagate's manual only caused more confusion. It lists all of the tests in a table:\n\n|Short Self Test|Tests all aspects of the drive. Does not test the flash media. Completes in 60 seconds or less.|\n|:-|:-|\n|Short Generic Test|Performs random read tests on random blocks of the media.|\n|Long Drive Self Test|Tests all aspects of the drive. Performs limited testing of the drive media blocks. Completes in several minutes depending on drive.|\n|Long Generic Test|Performs read and write test on all blocks of the flash media.|\n|2-minute Generic Test|Performs read and write tests on random blocks of the media. Completes in two minutes.|\n|Fix All Short|Back up your data. Fix All reads data blocks; repairs and replaces bad blocks. Recovery results can vary.  Fix All short is a fast test, completing in minutes.|\n|Fix All Long|Back up your data. Defrags the full disk. Reads and writes all data blocks; finds and replaces bad blocks.  Recovery results can vary. This test can take as long at 1 hour per TB, and cannot be interrupted.|\n\nWhy does the language keep switching between \"media\" and \"flash media\"? Are some of these tests only for SSDs? Trying to test 10TB IronWolf Pro.\n\nLater, in the Extended Tests section, it repeats the bit about the Long Self Test:\n\n&gt;The Long Self Test tests all aspects of the drive. Performs limited testing of the drive media blocks. Completes in several minutes depending on the drive.\n\n...but doesn't say a word about Long Generic Test.\n\nThe table says that the LDST tests \"all aspects\" of the drive but provides only limited testing of \"drive media blocks\" (which seems a little self-contradictory), while the LGT tests all media blocks. This vague language makes it uncertain whether LGT includes everything in LDST. i.e., if you do an LGT, is there still any reason to do an LDST? Can the LGT be considered to be a more thorough version of the LDST, or are they testing different things with just some overlap?\n\nAre any of these tests the same thing as what people are calling \"extended SMART tests\" on this forum?", "author_fullname": "t2_72fm42nb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SeaTools Long Drive Test vs Long Generic Test", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17hfazb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698386141.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698380294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Can someone explain the difference between the Long Drive Test vs Long Generic Test in SeaTools?&lt;/p&gt;\n\n&lt;p&gt;Seagate&amp;#39;s manual only caused more confusion. It lists all of the tests in a table:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;Short Self Test&lt;/th&gt;\n&lt;th align=\"left\"&gt;Tests all aspects of the drive. Does not test the flash media. Completes in 60 seconds or less.&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Short Generic Test&lt;/td&gt;\n&lt;td align=\"left\"&gt;Performs random read tests on random blocks of the media.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Long Drive Self Test&lt;/td&gt;\n&lt;td align=\"left\"&gt;Tests all aspects of the drive. Performs limited testing of the drive media blocks. Completes in several minutes depending on drive.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Long Generic Test&lt;/td&gt;\n&lt;td align=\"left\"&gt;Performs read and write test on all blocks of the flash media.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;2-minute Generic Test&lt;/td&gt;\n&lt;td align=\"left\"&gt;Performs read and write tests on random blocks of the media. Completes in two minutes.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Fix All Short&lt;/td&gt;\n&lt;td align=\"left\"&gt;Back up your data. Fix All reads data blocks; repairs and replaces bad blocks. Recovery results can vary.  Fix All short is a fast test, completing in minutes.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;Fix All Long&lt;/td&gt;\n&lt;td align=\"left\"&gt;Back up your data. Defrags the full disk. Reads and writes all data blocks; finds and replaces bad blocks.  Recovery results can vary. This test can take as long at 1 hour per TB, and cannot be interrupted.&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;Why does the language keep switching between &amp;quot;media&amp;quot; and &amp;quot;flash media&amp;quot;? Are some of these tests only for SSDs? Trying to test 10TB IronWolf Pro.&lt;/p&gt;\n\n&lt;p&gt;Later, in the Extended Tests section, it repeats the bit about the Long Self Test:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The Long Self Test tests all aspects of the drive. Performs limited testing of the drive media blocks. Completes in several minutes depending on the drive.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;...but doesn&amp;#39;t say a word about Long Generic Test.&lt;/p&gt;\n\n&lt;p&gt;The table says that the LDST tests &amp;quot;all aspects&amp;quot; of the drive but provides only limited testing of &amp;quot;drive media blocks&amp;quot; (which seems a little self-contradictory), while the LGT tests all media blocks. This vague language makes it uncertain whether LGT includes everything in LDST. i.e., if you do an LGT, is there still any reason to do an LDST? Can the LGT be considered to be a more thorough version of the LDST, or are they testing different things with just some overlap?&lt;/p&gt;\n\n&lt;p&gt;Are any of these tests the same thing as what people are calling &amp;quot;extended SMART tests&amp;quot; on this forum?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17hfazb", "is_robot_indexable": true, "report_reasons": null, "author": "ScrioteMyRewquards", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17hfazb/seatools_long_drive_test_vs_long_generic_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17hfazb/seatools_long_drive_test_vs_long_generic_test/", "subreddit_subscribers": 708916, "created_utc": 1698380294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Spare Terastation 1200DS collecting dust at the office, currenly has 2 4tb drives. Can i just order any NAS capable 8tb drives and use them? The Buffalo site makes it seem like you have to get the drive from them.\n\nTIA!\n\n&amp;#x200B;", "author_fullname": "t2_tdl81", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Buffalo TeraStation...can I use any drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17h3y5x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698347238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Spare Terastation 1200DS collecting dust at the office, currenly has 2 4tb drives. Can i just order any NAS capable 8tb drives and use them? The Buffalo site makes it seem like you have to get the drive from them.&lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17h3y5x", "is_robot_indexable": true, "report_reasons": null, "author": "monsterzro_nyc", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17h3y5x/buffalo_terastationcan_i_use_any_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17h3y5x/buffalo_terastationcan_i_use_any_drive/", "subreddit_subscribers": 708916, "created_utc": 1698347238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "hi, in the past i used an ELOAM document scanner for fast digital archiving of standard sized documents. It came with a handy desktop pad that had the A5 A4 A3 markings.  \nIs there any such type of thin and rollable pad, quite large if possible, that could suit as a support for the documents ?  \n", "author_fullname": "t2_24umd93p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "(black) desktop pad with paper size markings for document digitalization ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gzbo7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698334807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi, in the past i used an ELOAM document scanner for fast digital archiving of standard sized documents. It came with a handy desktop pad that had the A5 A4 A3 markings.&lt;br/&gt;\nIs there any such type of thin and rollable pad, quite large if possible, that could suit as a support for the documents ?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17gzbo7", "is_robot_indexable": true, "report_reasons": null, "author": "greenreddits", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17gzbo7/black_desktop_pad_with_paper_size_markings_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17gzbo7/black_desktop_pad_with_paper_size_markings_for/", "subreddit_subscribers": 708916, "created_utc": 1698334807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I tried to archive 6 YouTube videos on Ghostarchive.org , but I'm having difficulties since they are stuck in a loading screen for more than 2 weeks, and they are still not archived. Can someone tell me why is this happening? I also included six links for you to see what I'm talking about.\n\nhttps://ghostarchive.org/varchive/mMPd05WcQ9k\n\nhttps://ghostarchive.org/varchive/vwTquP7J7Kw\n\nhttps://ghostarchive.org/varchive/LuIQtKvLXWU\n\nhttps://ghostarchive.org/varchive/z6e3OOM3zR0\n\nhttps://ghostarchive.org/varchive/IBQ2TrrbY_k\n\nhttps://ghostarchive.org/varchive/eEiEn8j3z8M\n\nEdit: Why is this downvoted?", "author_fullname": "t2_l4dd2xezu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Some YouTube videos are not being archived to Ghostarchive.org?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17h8mp7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698365408.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698359497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I tried to archive 6 YouTube videos on Ghostarchive.org , but I&amp;#39;m having difficulties since they are stuck in a loading screen for more than 2 weeks, and they are still not archived. Can someone tell me why is this happening? I also included six links for you to see what I&amp;#39;m talking about.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ghostarchive.org/varchive/mMPd05WcQ9k\"&gt;https://ghostarchive.org/varchive/mMPd05WcQ9k&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ghostarchive.org/varchive/vwTquP7J7Kw\"&gt;https://ghostarchive.org/varchive/vwTquP7J7Kw&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ghostarchive.org/varchive/LuIQtKvLXWU\"&gt;https://ghostarchive.org/varchive/LuIQtKvLXWU&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ghostarchive.org/varchive/z6e3OOM3zR0\"&gt;https://ghostarchive.org/varchive/z6e3OOM3zR0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ghostarchive.org/varchive/IBQ2TrrbY_k\"&gt;https://ghostarchive.org/varchive/IBQ2TrrbY_k&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ghostarchive.org/varchive/eEiEn8j3z8M\"&gt;https://ghostarchive.org/varchive/eEiEn8j3z8M&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Edit: Why is this downvoted?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17h8mp7", "is_robot_indexable": true, "report_reasons": null, "author": "Veggiemitter", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17h8mp7/some_youtube_videos_are_not_being_archived_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17h8mp7/some_youtube_videos_are_not_being_archived_to/", "subreddit_subscribers": 708916, "created_utc": 1698359497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_x75wr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sold out now but the is the pre-black Friday sale at Best Buy so it may become available again soon so keep an eye out. 18TB WD EasyStore for $119", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_17hhmqz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/i_JzK1i8BppI1dxWj86yKvnk1_yG3gIDwmiuMG7JkKo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698389693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/bg56robj0pwb1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/bg56robj0pwb1.jpg?auto=webp&amp;s=ddd4a751229e2b094db7abfa5f843224196a591d", "width": 945, "height": 2048}, "resolutions": [{"url": "https://preview.redd.it/bg56robj0pwb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=173055ac8a968e223a09c6067bbf5edf2be030d3", "width": 108, "height": 216}, {"url": "https://preview.redd.it/bg56robj0pwb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=490114b9a26c62191f64d09e12583d1f42345cef", "width": 216, "height": 432}, {"url": "https://preview.redd.it/bg56robj0pwb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=78bf406c0b88c19052642266fa3534486d86dacd", "width": 320, "height": 640}, {"url": "https://preview.redd.it/bg56robj0pwb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f91a2a1fff17afbe8cdf3022207b8f8da8827d9d", "width": 640, "height": 1280}], "variants": {}, "id": "0F9d63UO2oBXc_ltNnW2CGCT0zc1HytcZb_d4hUDM5Y"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "17hhmqz", "is_robot_indexable": true, "report_reasons": null, "author": "shelms488", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17hhmqz/sold_out_now_but_the_is_the_preblack_friday_sale/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/bg56robj0pwb1.jpg", "subreddit_subscribers": 708916, "created_utc": 1698389693.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "If you're not a member of Best Buy Plus / Total, you can add a Plus membership to the cart at the same time for $49.99 and the discount will apply. \n\nhttps://www.bestbuy.com/site/wd-easystore-18tb-external-usb-3-0-hard-drive-black/6427995.p?skuId=6427995\n\nLimit 5 for each order\n\nMembership activates instantly so, if you need more, you can go back and order more at $119.99 right away.", "author_fullname": "t2_q1vgy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD Easystore 18tb External for $119.99 with Best Buy Plus / Total ($49.99 yr)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "sale", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17hgwo0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Sale", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698387379.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698386558.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you&amp;#39;re not a member of Best Buy Plus / Total, you can add a Plus membership to the cart at the same time for $49.99 and the discount will apply. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.bestbuy.com/site/wd-easystore-18tb-external-usb-3-0-hard-drive-black/6427995.p?skuId=6427995\"&gt;https://www.bestbuy.com/site/wd-easystore-18tb-external-usb-3-0-hard-drive-black/6427995.p?skuId=6427995&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Limit 5 for each order&lt;/p&gt;\n\n&lt;p&gt;Membership activates instantly so, if you need more, you can go back and order more at $119.99 right away.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j-fYkjsUoqb2Y_HEaJTt0O6SFu84iERf5p6Knb4VXrM.jpg?auto=webp&amp;s=d671ea6a9ef0fcea27b3eb26b7d23a482e599c37", "width": 1459, "height": 5014}, "resolutions": [{"url": "https://external-preview.redd.it/j-fYkjsUoqb2Y_HEaJTt0O6SFu84iERf5p6Knb4VXrM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1e1c73e6849b7ce0ef03c674ccdc76c97f89b0de", "width": 108, "height": 216}, {"url": "https://external-preview.redd.it/j-fYkjsUoqb2Y_HEaJTt0O6SFu84iERf5p6Knb4VXrM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0b769c39787a3f29ab4d63170d30bddbad894113", "width": 216, "height": 432}, {"url": "https://external-preview.redd.it/j-fYkjsUoqb2Y_HEaJTt0O6SFu84iERf5p6Knb4VXrM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fae2e0d1244ecdc2bcc7b52ea4cc65af04f57ad4", "width": 320, "height": 640}, {"url": "https://external-preview.redd.it/j-fYkjsUoqb2Y_HEaJTt0O6SFu84iERf5p6Knb4VXrM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6284575a2f234215c3ba4b1acee0f5aa20a32663", "width": 640, "height": 1280}, {"url": "https://external-preview.redd.it/j-fYkjsUoqb2Y_HEaJTt0O6SFu84iERf5p6Knb4VXrM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0b76a8836c0b5f72da5932efd7d330af109ea391", "width": 960, "height": 1920}, {"url": "https://external-preview.redd.it/j-fYkjsUoqb2Y_HEaJTt0O6SFu84iERf5p6Knb4VXrM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=aba4f139864126b43b498d312e2f488388df78ac", "width": 1080, "height": 2160}], "variants": {}, "id": "SrN0HZ9v3jOj__KqsCfpPNQGMVguAxONYQuuyn3T2vI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ef8232de-b94e-11eb-ba29-0ed106a6f983", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17hgwo0", "is_robot_indexable": true, "report_reasons": null, "author": "keloms15", "discussion_type": null, "num_comments": 3, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17hgwo0/wd_easystore_18tb_external_for_11999_with_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17hgwo0/wd_easystore_18tb_external_for_11999_with_best/", "subreddit_subscribers": 708916, "created_utc": 1698386558.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019m coming up on another space limit and I\u2019m taking this time to reevaluate my setup. \nCurrent setup:\n\nPlex server: windows 10 pro \n12700k 32gb ram 10 gig Nic \n500gb gen 4 boot \n2TB P3 plus seed drive\n2Tb 980 pro seed drive\nRunning plex, arr stack, Qbittorrent, ups software \n\n\nStorage server: windows server 2019\n13100k 16gb ram 10 gig Nic\n500gb gen 4 boot \n1tb 980 pro cache\n4x12 TB refurbished seagate exos driver\nRunning stable bit drivepool/scanner\n\nOffsite backup:\nSynology ds220+\n3.7TB usable \n\nMy 44 TB of usable storage is almost full, I have personal documents/video x3 duplicated and all of my Linux ISO\u2019s have no redundancy.\nI am adding 2x20tb soon but before I do I want to see if it would be smart to move to Unraid in the process.\n\nI will keep my plex server on windows for now, but I have been learning Unraid during my 2 trials I\u2019ve done. Should I change my NAS to Unraid? Will I still get 10gig with nvme read/write cache? \n\nI will not be getting new hardware for Unraid as I\u2019ll be reusing my current server. Is the best course of migration putting the 2x20 tb drives in my plex server, move data to that then repopulate the drives on Unraid? \n\nAny other advice is appreciated.", "author_fullname": "t2_a0gpg32f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for NAS OS advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17heydz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698379035.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m coming up on another space limit and I\u2019m taking this time to reevaluate my setup. \nCurrent setup:&lt;/p&gt;\n\n&lt;p&gt;Plex server: windows 10 pro \n12700k 32gb ram 10 gig Nic \n500gb gen 4 boot \n2TB P3 plus seed drive\n2Tb 980 pro seed drive\nRunning plex, arr stack, Qbittorrent, ups software &lt;/p&gt;\n\n&lt;p&gt;Storage server: windows server 2019\n13100k 16gb ram 10 gig Nic\n500gb gen 4 boot \n1tb 980 pro cache\n4x12 TB refurbished seagate exos driver\nRunning stable bit drivepool/scanner&lt;/p&gt;\n\n&lt;p&gt;Offsite backup:\nSynology ds220+\n3.7TB usable &lt;/p&gt;\n\n&lt;p&gt;My 44 TB of usable storage is almost full, I have personal documents/video x3 duplicated and all of my Linux ISO\u2019s have no redundancy.\nI am adding 2x20tb soon but before I do I want to see if it would be smart to move to Unraid in the process.&lt;/p&gt;\n\n&lt;p&gt;I will keep my plex server on windows for now, but I have been learning Unraid during my 2 trials I\u2019ve done. Should I change my NAS to Unraid? Will I still get 10gig with nvme read/write cache? &lt;/p&gt;\n\n&lt;p&gt;I will not be getting new hardware for Unraid as I\u2019ll be reusing my current server. Is the best course of migration putting the 2x20 tb drives in my plex server, move data to that then repopulate the drives on Unraid? &lt;/p&gt;\n\n&lt;p&gt;Any other advice is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17heydz", "is_robot_indexable": true, "report_reasons": null, "author": "SSavage260", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17heydz/looking_for_nas_os_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17heydz/looking_for_nas_os_advice/", "subreddit_subscribers": 708916, "created_utc": 1698379035.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello friends! Relatively new data hoarder here! My data stash of choice is an archive of all of my Twitch streams over the last 6 years. \n\nHistorically, I\u2019d buy 4TB spinners and make a parent folder respective to the year, and title all of the video files with the format: MM-DD_HHMMSS_&lt;game list&gt;_#.mkv where the pound is optional if I had to pause the recording.\n\nEssentially, the metadata essential to me was the date of recording, and the game (or games) that were played. \n\nI\u2019ve reached the point where I\u2019m at some 7TB of video footage, as well as another 2TB of miscellaneous resources I\u2019d use for the purposes of editing said footage. I\u2019ve just built a server which I hope to use as my storage server. Right now I\u2019m looking at mergerFS paired with snapraid for parity if I lose a drive at some point. \n\nI love the concept of mergerFS, though archiving via nested folders sounds less ideal if my goal is to be able to add drives arbitrarily. I\u2019d rather keep all the files at the root of every mergerFS drive and then use some solution to index all of the files, so I can easily retrieve them via a query to the date, and/or game that was streamed. \n\nI was originally considering building a program which would maintain a .metadata file of sorts, and changing it the naming scheme to something more consistent, such that every video \u201cID\u201d could be associated with its tags. \n\nIt then occurred to me that this sounds very similar to just a standard database. Perhaps hosting one locally is a better solution still? \n\nI\u2019m curious if any of you guys have used or heard of similar projects! I struggle to imagine that something like this doesn\u2019t already exist, though my search has only lead me to dead ends. \n\nThanks for any insights!!", "author_fullname": "t2_nqfrv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a solution for tag-based indexing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ha8b7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698364018.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello friends! Relatively new data hoarder here! My data stash of choice is an archive of all of my Twitch streams over the last 6 years. &lt;/p&gt;\n\n&lt;p&gt;Historically, I\u2019d buy 4TB spinners and make a parent folder respective to the year, and title all of the video files with the format: MM-DD&lt;em&gt;HHMMSS&lt;/em&gt;&amp;lt;game list&amp;gt;_#.mkv where the pound is optional if I had to pause the recording.&lt;/p&gt;\n\n&lt;p&gt;Essentially, the metadata essential to me was the date of recording, and the game (or games) that were played. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve reached the point where I\u2019m at some 7TB of video footage, as well as another 2TB of miscellaneous resources I\u2019d use for the purposes of editing said footage. I\u2019ve just built a server which I hope to use as my storage server. Right now I\u2019m looking at mergerFS paired with snapraid for parity if I lose a drive at some point. &lt;/p&gt;\n\n&lt;p&gt;I love the concept of mergerFS, though archiving via nested folders sounds less ideal if my goal is to be able to add drives arbitrarily. I\u2019d rather keep all the files at the root of every mergerFS drive and then use some solution to index all of the files, so I can easily retrieve them via a query to the date, and/or game that was streamed. &lt;/p&gt;\n\n&lt;p&gt;I was originally considering building a program which would maintain a .metadata file of sorts, and changing it the naming scheme to something more consistent, such that every video \u201cID\u201d could be associated with its tags. &lt;/p&gt;\n\n&lt;p&gt;It then occurred to me that this sounds very similar to just a standard database. Perhaps hosting one locally is a better solution still? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m curious if any of you guys have used or heard of similar projects! I struggle to imagine that something like this doesn\u2019t already exist, though my search has only lead me to dead ends. &lt;/p&gt;\n\n&lt;p&gt;Thanks for any insights!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ha8b7", "is_robot_indexable": true, "report_reasons": null, "author": "Drayux", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ha8b7/creating_a_solution_for_tagbased_indexing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ha8b7/creating_a_solution_for_tagbased_indexing/", "subreddit_subscribers": 708916, "created_utc": 1698364018.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nI would like to create a (relatively) high capacity encrypted RAID for backing up my files after a recent hard drive failure and have been looking at the 870 QVO 8TB pending any other better alternatives. Does anyone have experience with the 870 QVO? Is the performance as advertised, is it reliable etc.?\n\nI plan to set the drives up in either RAID1, 5 or 6 and it will only be used for monthly backups.", "author_fullname": "t2_4yw51px8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "870 QVO for Redundant RAID?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17h77en", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698355757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I would like to create a (relatively) high capacity encrypted RAID for backing up my files after a recent hard drive failure and have been looking at the 870 QVO 8TB pending any other better alternatives. Does anyone have experience with the 870 QVO? Is the performance as advertised, is it reliable etc.?&lt;/p&gt;\n\n&lt;p&gt;I plan to set the drives up in either RAID1, 5 or 6 and it will only be used for monthly backups.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17h77en", "is_robot_indexable": true, "report_reasons": null, "author": "safelyvulnerable", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17h77en/870_qvo_for_redundant_raid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17h77en/870_qvo_for_redundant_raid/", "subreddit_subscribers": 708916, "created_utc": 1698355757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, a long time I acquired a cheap Dell powervault md1000 with two amp01-sim inside. Each amp has an In and Out SFF-8470. I wish to have all 15 drives in a single raid, as far as I gathered I only need to use one amp. I had an ICT-1606 lying around and was wondering if I could connect the amp directly to it using SFF-8470 to SFF-8087 cables.\n\nThe end goal is to connect the vault to a dell optiplex 745 desktop running alpine linux, and I am not sure if the ict can handle the vault, nor if I need one or two cables (I have seen a video where someone had only the In plugged in). In some video someone said one needs SFF-8470 to SFF-8088 cables, but my controller has SFF-8087 (do I have to get a perc??).\n\nAny hints are welcome, I have never dealt much with hardware, but thought I might start hoarding on a budget.", "author_fullname": "t2_jwyg02rla", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Powervault md1000 to optiplex 745", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17h645l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698352885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, a long time I acquired a cheap Dell powervault md1000 with two amp01-sim inside. Each amp has an In and Out SFF-8470. I wish to have all 15 drives in a single raid, as far as I gathered I only need to use one amp. I had an ICT-1606 lying around and was wondering if I could connect the amp directly to it using SFF-8470 to SFF-8087 cables.&lt;/p&gt;\n\n&lt;p&gt;The end goal is to connect the vault to a dell optiplex 745 desktop running alpine linux, and I am not sure if the ict can handle the vault, nor if I need one or two cables (I have seen a video where someone had only the In plugged in). In some video someone said one needs SFF-8470 to SFF-8088 cables, but my controller has SFF-8087 (do I have to get a perc??).&lt;/p&gt;\n\n&lt;p&gt;Any hints are welcome, I have never dealt much with hardware, but thought I might start hoarding on a budget.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17h645l", "is_robot_indexable": true, "report_reasons": null, "author": "jeanlekhey", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17h645l/powervault_md1000_to_optiplex_745/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17h645l/powervault_md1000_to_optiplex_745/", "subreddit_subscribers": 708916, "created_utc": 1698352885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "no raid, just drives. Can I just pop them out of the old and put into the new? Safe?", "author_fullname": "t2_5i4om", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Just checking before transferring drives from old probox enclosure to new Sabrant", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17h0pjj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698338497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;no raid, just drives. Can I just pop them out of the old and put into the new? Safe?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17h0pjj", "is_robot_indexable": true, "report_reasons": null, "author": "nicknacc", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17h0pjj/just_checking_before_transferring_drives_from_old/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17h0pjj/just_checking_before_transferring_drives_from_old/", "subreddit_subscribers": 708916, "created_utc": 1698338497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As a followup to [my post about backup solutions](https://www.reddit.com/r/DataHoarder/comments/17ec8s3/comment/k62rq2t/), I have rsnapshot specific questions.\n\nI have set up rsnapshot to backup to a separate internal drive. As expected, this creates multiple snapshots, and uses hardlinks as much as possible to minimize space usage and deduplicate.\n\nHowever, I am unsure what to do about external disks. In addition to the internal backup disk, I also have an external backup disk that I keep off-site most of the time. The straightforward way would be to just backup data from the primary disk to the external disk. But, I want to reduce the load on the primary disk, so ideally, I'd copy the contents of the backup disk instead. Using rsnapshot for *that* is not a good idea I think, since it would then create \"snapshots of snapshots\" etc.\n\nSo, I am considering to use plain rsync for that, passing the `--hard-links` argument to it to replicate the hardlinks rsnapshot created on the internal backup drive. This would essentially clone the backup drive's contents, including all of its snapshots.\n\nOne advantage of that is that this not only prevents extra load on the primary drive, it also saves the previous snapshots' contents, which may sometimes be useful. However, the `--hard-links` argument may not be able to preserve all hardlinks, and problems that arise from combinations with `--link-dest` are probably difficult to debug.\n\nAnother option would be to let rsnapshot backup the `daily.0` snapshot of the internal backup disk. That one contains a full backup, and no hardlinks, and the external disk could then have its own snapshots based on that. However, the path rsnapshot creates would be different, and probably very confusing. It would be something like `/mnt/external-hdd/daily.0/localhost/mnt/internal-backup-hdd/daily.0/localhost/mnt/primary-hdd`. I haven't found a way to influence how rsnapshot creates these paths, so I am not a fan of that option.\n\nThoughts?", "author_fullname": "t2_v3szwqll", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Combining rsnapshot and internal and external backups - how to \"backup a backup\"?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gtukv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698317930.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a followup to &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/17ec8s3/comment/k62rq2t/\"&gt;my post about backup solutions&lt;/a&gt;, I have rsnapshot specific questions.&lt;/p&gt;\n\n&lt;p&gt;I have set up rsnapshot to backup to a separate internal drive. As expected, this creates multiple snapshots, and uses hardlinks as much as possible to minimize space usage and deduplicate.&lt;/p&gt;\n\n&lt;p&gt;However, I am unsure what to do about external disks. In addition to the internal backup disk, I also have an external backup disk that I keep off-site most of the time. The straightforward way would be to just backup data from the primary disk to the external disk. But, I want to reduce the load on the primary disk, so ideally, I&amp;#39;d copy the contents of the backup disk instead. Using rsnapshot for &lt;em&gt;that&lt;/em&gt; is not a good idea I think, since it would then create &amp;quot;snapshots of snapshots&amp;quot; etc.&lt;/p&gt;\n\n&lt;p&gt;So, I am considering to use plain rsync for that, passing the &lt;code&gt;--hard-links&lt;/code&gt; argument to it to replicate the hardlinks rsnapshot created on the internal backup drive. This would essentially clone the backup drive&amp;#39;s contents, including all of its snapshots.&lt;/p&gt;\n\n&lt;p&gt;One advantage of that is that this not only prevents extra load on the primary drive, it also saves the previous snapshots&amp;#39; contents, which may sometimes be useful. However, the &lt;code&gt;--hard-links&lt;/code&gt; argument may not be able to preserve all hardlinks, and problems that arise from combinations with &lt;code&gt;--link-dest&lt;/code&gt; are probably difficult to debug.&lt;/p&gt;\n\n&lt;p&gt;Another option would be to let rsnapshot backup the &lt;code&gt;daily.0&lt;/code&gt; snapshot of the internal backup disk. That one contains a full backup, and no hardlinks, and the external disk could then have its own snapshots based on that. However, the path rsnapshot creates would be different, and probably very confusing. It would be something like &lt;code&gt;/mnt/external-hdd/daily.0/localhost/mnt/internal-backup-hdd/daily.0/localhost/mnt/primary-hdd&lt;/code&gt;. I haven&amp;#39;t found a way to influence how rsnapshot creates these paths, so I am not a fan of that option.&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17gtukv", "is_robot_indexable": true, "report_reasons": null, "author": "FourDimensionalTaco", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17gtukv/combining_rsnapshot_and_internal_and_external/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17gtukv/combining_rsnapshot_and_internal_and_external/", "subreddit_subscribers": 708916, "created_utc": 1698317930.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Some people are saying I shouldn't buy a Slim External BD Burner if I want to burn good quality discs, because they are crap and the discs will die sooner. Is that true?\n\nIs it a better option to buy an internal drive and use some kind of sata to usb external adapter?\n\nI'd prefer the SLIM USB one, but if the burn quality is really worse, I will consider an internal as external...", "author_fullname": "t2_2xftem1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are SLIM BD Drives considerably worse than normal Internal drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17hgh4b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698384803.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some people are saying I shouldn&amp;#39;t buy a Slim External BD Burner if I want to burn good quality discs, because they are crap and the discs will die sooner. Is that true?&lt;/p&gt;\n\n&lt;p&gt;Is it a better option to buy an internal drive and use some kind of sata to usb external adapter?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d prefer the SLIM USB one, but if the burn quality is really worse, I will consider an internal as external...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17hgh4b", "is_robot_indexable": true, "report_reasons": null, "author": "Leonhardt90", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17hgh4b/are_slim_bd_drives_considerably_worse_than_normal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17hgh4b/are_slim_bd_drives_considerably_worse_than_normal/", "subreddit_subscribers": 708916, "created_utc": 1698384803.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for the best 3.5 HDD cases and enclosures around. Water, shock and fire protection are all pluses.", "author_fullname": "t2_btog27yk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "3.5 cases and enclosures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17hbln5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698368220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for the best 3.5 HDD cases and enclosures around. Water, shock and fire protection are all pluses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17hbln5", "is_robot_indexable": true, "report_reasons": null, "author": "zeetree137", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17hbln5/35_cases_and_enclosures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17hbln5/35_cases_and_enclosures/", "subreddit_subscribers": 708916, "created_utc": 1698368220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been running into issues with my SSD, mainly being unable to make a shadow copy of it (using Veeam Agent).  \n  \nJust noticed that when Veeam fails, I get a bunch of errors in Windows event log saying : \\Device\\Harddisk4\\DR4 has a bad block  \n  \nBut earlier, I figured bad blocks might be the issue and already ran a full chkdsk /f /r /x on the disk, but it didn't find any bad block.  \n  \nIs there another way to find these bad blocks?", "author_fullname": "t2_5srl8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bad sectors on SSD causing issues, but chkdsk find nothing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17h9ex4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698361675.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been running into issues with my SSD, mainly being unable to make a shadow copy of it (using Veeam Agent).  &lt;/p&gt;\n\n&lt;p&gt;Just noticed that when Veeam fails, I get a bunch of errors in Windows event log saying : \\Device\\Harddisk4\\DR4 has a bad block  &lt;/p&gt;\n\n&lt;p&gt;But earlier, I figured bad blocks might be the issue and already ran a full chkdsk /f /r /x on the disk, but it didn&amp;#39;t find any bad block.  &lt;/p&gt;\n\n&lt;p&gt;Is there another way to find these bad blocks?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17h9ex4", "is_robot_indexable": true, "report_reasons": null, "author": "DiNoMC", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17h9ex4/bad_sectors_on_ssd_causing_issues_but_chkdsk_find/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17h9ex4/bad_sectors_on_ssd_causing_issues_but_chkdsk_find/", "subreddit_subscribers": 708916, "created_utc": 1698361675.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}