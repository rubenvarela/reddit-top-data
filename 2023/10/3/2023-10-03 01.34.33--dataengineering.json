{"kind": "Listing", "data": {"after": "t3_16ycoj4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For me: I was pushed to use FiveTran and from there the pain started, our simple infra became complicated. Took me almost 8 months to convince my boss to replace that with ELT approach where sink to S3 -&gt; dbt-&gt;Redshift", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tool, you regret buying or deploying in the data infrastructure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xxu15", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696256235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For me: I was pushed to use FiveTran and from there the pain started, our simple infra became complicated. Took me almost 8 months to convince my boss to replace that with ELT approach where sink to S3 -&amp;gt; dbt-&amp;gt;Redshift&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xxu15", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 75, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xxu15/any_tool_you_regret_buying_or_deploying_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xxu15/any_tool_you_regret_buying_or_deploying_in_the/", "subreddit_subscribers": 131717, "created_utc": 1696256235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working at a company that is trying to make a push for I4.0. Whether or not you think thats a buzzword, there are tons of companies making the push towards smart manufacturing. My question, is it worth it?\n\nMaybe it is only because we are new to it and I'm not seeing the full benefits but cost of collection (sensors, PLCs, etc) is often expensive. If you want production data to be captured constantly (good counts, scrap counts, etc.) you need redundant networking/power.\n\nMoving data to the cloud is unbelievably expensive at this volume and SCADAs/Historians are equally expensive. The hardware requires highly skilled employees to set up and maintain the system.\n\nAll this for managerial metrics and the ability to root cause faster? Maybe if you're good enough get some predictive maintenance?\n\nTo the others in the industry, is this all worth it? Have you seen the value add at your own job?", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To those that work in manufacturing, do you believe IoT (and heavy collection of manufacturing data) is a fad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xyt26", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696258506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working at a company that is trying to make a push for I4.0. Whether or not you think thats a buzzword, there are tons of companies making the push towards smart manufacturing. My question, is it worth it?&lt;/p&gt;\n\n&lt;p&gt;Maybe it is only because we are new to it and I&amp;#39;m not seeing the full benefits but cost of collection (sensors, PLCs, etc) is often expensive. If you want production data to be captured constantly (good counts, scrap counts, etc.) you need redundant networking/power.&lt;/p&gt;\n\n&lt;p&gt;Moving data to the cloud is unbelievably expensive at this volume and SCADAs/Historians are equally expensive. The hardware requires highly skilled employees to set up and maintain the system.&lt;/p&gt;\n\n&lt;p&gt;All this for managerial metrics and the ability to root cause faster? Maybe if you&amp;#39;re good enough get some predictive maintenance?&lt;/p&gt;\n\n&lt;p&gt;To the others in the industry, is this all worth it? Have you seen the value add at your own job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xyt26", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xyt26/to_those_that_work_in_manufacturing_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xyt26/to_those_that_work_in_manufacturing_do_you/", "subreddit_subscribers": 131717, "created_utc": 1696258506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just looking for a bit of feedback on this matter. \n\nI just started in a new company, and 2 weeks in I was assigned to a new project. The project consists of fetching data from a known CRM Rest API, which have a good amount of documentation. Based on a  list of abstracts, my task was to find a proper endpoint for each table, and develop the code to fetch everything needed and save raw files in S3, while validating against a schema. \n\nI was given 1 month to develop everything alone, except the Terraform script for the infrastructure. Basic documentation, CI CD, docker image generation and upload to registry, Python coding with logging and memory leak safeguards. \n\nI thought it was hard but achievable. But when the scope changed everything derailed. The change was with additional level of detail of some datasets. \n\nThe project is being delivered 2 weeks late, and I'm getting a negative feedback because of the delay. \n\nI feel that I worked a lot to get that done on time, and I can't see where I could have done better. Specially being so new to the company and getting used to the processes and people. \n\nIs 6 weeks too much time for a project this big? Is the company asking too much of me?", "author_fullname": "t2_hcybngxl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rant about my new job. I need a bit of insight from other DEs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y2nwa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696285739.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696267625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just looking for a bit of feedback on this matter. &lt;/p&gt;\n\n&lt;p&gt;I just started in a new company, and 2 weeks in I was assigned to a new project. The project consists of fetching data from a known CRM Rest API, which have a good amount of documentation. Based on a  list of abstracts, my task was to find a proper endpoint for each table, and develop the code to fetch everything needed and save raw files in S3, while validating against a schema. &lt;/p&gt;\n\n&lt;p&gt;I was given 1 month to develop everything alone, except the Terraform script for the infrastructure. Basic documentation, CI CD, docker image generation and upload to registry, Python coding with logging and memory leak safeguards. &lt;/p&gt;\n\n&lt;p&gt;I thought it was hard but achievable. But when the scope changed everything derailed. The change was with additional level of detail of some datasets. &lt;/p&gt;\n\n&lt;p&gt;The project is being delivered 2 weeks late, and I&amp;#39;m getting a negative feedback because of the delay. &lt;/p&gt;\n\n&lt;p&gt;I feel that I worked a lot to get that done on time, and I can&amp;#39;t see where I could have done better. Specially being so new to the company and getting used to the processes and people. &lt;/p&gt;\n\n&lt;p&gt;Is 6 weeks too much time for a project this big? Is the company asking too much of me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16y2nwa", "is_robot_indexable": true, "report_reasons": null, "author": "Gh0sthy1", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y2nwa/rant_about_my_new_job_i_need_a_bit_of_insight/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y2nwa/rant_about_my_new_job_i_need_a_bit_of_insight/", "subreddit_subscribers": 131717, "created_utc": 1696267625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am dealing with small to medium sized customers looking for a basic data warehouse solution for Power BI reports. They generally have several GB up to a maximum of a 100 GB of data to store, and several dozens of users.\n\nFor these small scale solutions, is it really better to use OLAP databases like Synapse, Snowflake, Redshift? It seems like a simple Azure database or PostgreSQL as a service is much cheaper and would offer sufficient performance? Am I missing something?\n\nI have been involved with Snowflake solutions twice before, but in both cases the client had a negative perception of the costs. Or could I configure Snowflake in such a way that it runs cheaply?", "author_fullname": "t2_u2p974i5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I really need an OLAP database for a data warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xzlm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696260420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am dealing with small to medium sized customers looking for a basic data warehouse solution for Power BI reports. They generally have several GB up to a maximum of a 100 GB of data to store, and several dozens of users.&lt;/p&gt;\n\n&lt;p&gt;For these small scale solutions, is it really better to use OLAP databases like Synapse, Snowflake, Redshift? It seems like a simple Azure database or PostgreSQL as a service is much cheaper and would offer sufficient performance? Am I missing something?&lt;/p&gt;\n\n&lt;p&gt;I have been involved with Snowflake solutions twice before, but in both cases the client had a negative perception of the costs. Or could I configure Snowflake in such a way that it runs cheaply?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xzlm4", "is_robot_indexable": true, "report_reasons": null, "author": "MarcScripts", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xzlm4/do_i_really_need_an_olap_database_for_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xzlm4/do_i_really_need_an_olap_database_for_a_data/", "subreddit_subscribers": 131717, "created_utc": 1696260420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thanks to the community for being so helpful and supportive!\n\nI am considering to start a data engineering consulting. My niche is e-commerce business.\n\nWhat to hear what the community thinks about this? \n\nIs this a bad decision to focus on building a company around DE consulting? \nWhat are the key challenges I need to prepare for?\nWhat industries to target?\nHow to grow my business? \n\nThanks again!", "author_fullname": "t2_hlf7js20w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering consulting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xob54", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696224918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thanks to the community for being so helpful and supportive!&lt;/p&gt;\n\n&lt;p&gt;I am considering to start a data engineering consulting. My niche is e-commerce business.&lt;/p&gt;\n\n&lt;p&gt;What to hear what the community thinks about this? &lt;/p&gt;\n\n&lt;p&gt;Is this a bad decision to focus on building a company around DE consulting? \nWhat are the key challenges I need to prepare for?\nWhat industries to target?\nHow to grow my business? &lt;/p&gt;\n\n&lt;p&gt;Thanks again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16xob54", "is_robot_indexable": true, "report_reasons": null, "author": "No-Dream-420", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xob54/data_engineering_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xob54/data_engineering_consulting/", "subreddit_subscribers": 131717, "created_utc": 1696224918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Goodbye Spark. Hello Polars + Delta Lake.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16xzcqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uoju8UTP0tZAIdqZc3iW3ef3oNtUOsvWrwPRLKKEcso.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696259823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/goodbye-spark-hello-polars-delta", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?auto=webp&amp;s=e585ee336c489e1e9d450ed5159b115f114faf2a", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e5c6d53daaae3bdf1918e25f3f0270fc6dc7f597", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aa672a15ff78edbc9baca55c9808ad1f74530570", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=754d2c0745079122b89f58f096f81dd3529333b2", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=233e82aa2321f7d05735593d9a37da1064b50bc0", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=91e26d7ce3a240db9569e53c0674a9b3db878065", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=69f818883fada4b287989c118a7cd66802bf6540", "width": 1080, "height": 540}], "variants": {}, "id": "PURvM--d-7MgOYB6-qnYgEtr-OWAeVREK0gXETFQvXQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xzcqx", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xzcqx/goodbye_spark_hello_polars_delta_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/goodbye-spark-hello-polars-delta", "subreddit_subscribers": 131717, "created_utc": 1696259823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my latest blog post, I've summarized the key takeaways from Snowflake Summit 2023 in Bangalore, so that those who couldn't attend can benefit from the latest updates on data governance and cost management.  \n\n\nData Governance Highlights:  \n1) Data Quality Monitoring  \n2) Query Constraint Policies  \n3) Data Access Policies  \n4) Data Governance UI  \n5) Classification UI  \n6) Global PII Classification  \n\n\nCost Control Highlights:  \n1) Budget  \n2) Warehouse Utilization  \n3) SnowLens  \n\n\nBlog Link - [Unlocking the Power of Data Governance and Cost Control: Insights from Snowflake Summit 2023](https://medium.com/bi3-technologies/unlocking-the-power-of-data-governance-and-privacy-insights-from-snowflake-summit-2023-7ffcb697e005)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/z371joftmqrb1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=7aa178f639e8751472f63f1d63fcc22805cd9d90\n\nI want to thank the event organizers and the insightful speakers:  \n\n\n1) [Hemant Raorane](https://www.linkedin.com/in/ACoAABMXMIIB6tUTKUjbYz1CqBz2jS3NCnSpM7I), Sales Engineer, [Snowflake](https://www.linkedin.com/company/snowflake-computing/) India  \n2) [Sachin Gangwar](https://www.linkedin.com/in/ACoAAAZGouMBkudPlBY9PD76sXVTAdnwWQNQm9w), Senior Sales Engineer, [Snowflake](https://www.linkedin.com/company/snowflake-computing/) India  \n3) [Wasim El-Omari](https://www.linkedin.com/in/ACoAAC-O1KYBhH78QJa92-7ggpODUPFVS3jvgAc), Principal Architect, Security, Field CTO Office, [Snowflake](https://www.linkedin.com/company/snowflake-computing/)  \n4) [Pawan Mall](https://www.linkedin.com/in/ACoAAAEq2hkBAI8EwgK_ROKoaULMSB-72GQrnS0), Senior Sales Engineer, [Snowflake](https://www.linkedin.com/company/snowflake-computing/) India  \n5) [Vikash K.](https://www.linkedin.com/in/ACoAACea-JUBwLCCA2Iqcbrpm_F6rHUrEKHpHA4), Senior Data Cloud Architect | GSI Partners, [Snowflake](https://www.linkedin.com/company/snowflake-computing/) India  \n\n\nYour expertise will shape how we handle data in our projects.  \n\n\n[\\#SnowflakeSummit2023](https://www.linkedin.com/feed/hashtag/?keywords=snowflakesummit2023&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#DataGovernance](https://www.linkedin.com/feed/hashtag/?keywords=datagovernance&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#CostControl](https://www.linkedin.com/feed/hashtag/?keywords=costcontrol&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#DataManagement](https://www.linkedin.com/feed/hashtag/?keywords=datamanagement&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#TechTrends](https://www.linkedin.com/feed/hashtag/?keywords=techtrends&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#DataAnalytics](https://www.linkedin.com/feed/hashtag/?keywords=dataanalytics&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#DataSecurity](https://www.linkedin.com/feed/hashtag/?keywords=datasecurity&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#Snowflake](https://www.linkedin.com/feed/hashtag/?keywords=snowflake&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#SnowflakeDevelopers](https://www.linkedin.com/feed/hashtag/?keywords=snowflakedevelopers&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) ", "author_fullname": "t2_hhlcq19gr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Key takeaways from Snowflake Summit 2023 in Bangalore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"z371joftmqrb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=632d25e3e54af280ce7616d3debab386c63f0568"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9bfbd5f8788550e35d5658dcefb105c1c63d6b0d"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f77fa2d109d22fad0d51dbf0bcd975b9114bd1d5"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f028485b825f179d5aed019f12d7568ebb1adaf2"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b201bb9b074bf1f4348fa10aa0d65cd0ada5e4c4"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0e153a28fa2528f892f5df29d19402d8c80efb2c"}], "s": {"y": 1200, "x": 1600, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=7aa178f639e8751472f63f1d63fcc22805cd9d90"}, "id": "z371joftmqrb1"}}, "name": "t3_16xprjr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GTriMGw7dhnIVYinyVqUBxw7GM_RpAGKtQqnNof47ck.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1696230074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my latest blog post, I&amp;#39;ve summarized the key takeaways from Snowflake Summit 2023 in Bangalore, so that those who couldn&amp;#39;t attend can benefit from the latest updates on data governance and cost management.  &lt;/p&gt;\n\n&lt;p&gt;Data Governance Highlights:&lt;br/&gt;\n1) Data Quality Monitoring&lt;br/&gt;\n2) Query Constraint Policies&lt;br/&gt;\n3) Data Access Policies&lt;br/&gt;\n4) Data Governance UI&lt;br/&gt;\n5) Classification UI&lt;br/&gt;\n6) Global PII Classification  &lt;/p&gt;\n\n&lt;p&gt;Cost Control Highlights:&lt;br/&gt;\n1) Budget&lt;br/&gt;\n2) Warehouse Utilization&lt;br/&gt;\n3) SnowLens  &lt;/p&gt;\n\n&lt;p&gt;Blog Link - &lt;a href=\"https://medium.com/bi3-technologies/unlocking-the-power-of-data-governance-and-privacy-insights-from-snowflake-summit-2023-7ffcb697e005\"&gt;Unlocking the Power of Data Governance and Cost Control: Insights from Snowflake Summit 2023&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/z371joftmqrb1.jpg?width=1600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7aa178f639e8751472f63f1d63fcc22805cd9d90\"&gt;https://preview.redd.it/z371joftmqrb1.jpg?width=1600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7aa178f639e8751472f63f1d63fcc22805cd9d90&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I want to thank the event organizers and the insightful speakers:  &lt;/p&gt;\n\n&lt;p&gt;1) &lt;a href=\"https://www.linkedin.com/in/ACoAABMXMIIB6tUTKUjbYz1CqBz2jS3NCnSpM7I\"&gt;Hemant Raorane&lt;/a&gt;, Sales Engineer, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt; India&lt;br/&gt;\n2) &lt;a href=\"https://www.linkedin.com/in/ACoAAAZGouMBkudPlBY9PD76sXVTAdnwWQNQm9w\"&gt;Sachin Gangwar&lt;/a&gt;, Senior Sales Engineer, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt; India&lt;br/&gt;\n3) &lt;a href=\"https://www.linkedin.com/in/ACoAAC-O1KYBhH78QJa92-7ggpODUPFVS3jvgAc\"&gt;Wasim El-Omari&lt;/a&gt;, Principal Architect, Security, Field CTO Office, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt;&lt;br/&gt;\n4) &lt;a href=\"https://www.linkedin.com/in/ACoAAAEq2hkBAI8EwgK_ROKoaULMSB-72GQrnS0\"&gt;Pawan Mall&lt;/a&gt;, Senior Sales Engineer, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt; India&lt;br/&gt;\n5) &lt;a href=\"https://www.linkedin.com/in/ACoAACea-JUBwLCCA2Iqcbrpm_F6rHUrEKHpHA4\"&gt;Vikash K.&lt;/a&gt;, Senior Data Cloud Architect | GSI Partners, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt; India  &lt;/p&gt;\n\n&lt;p&gt;Your expertise will shape how we handle data in our projects.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=snowflakesummit2023&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#SnowflakeSummit2023&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=datagovernance&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#DataGovernance&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=costcontrol&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#CostControl&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=datamanagement&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#DataManagement&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=techtrends&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#TechTrends&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=dataanalytics&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#DataAnalytics&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=datasecurity&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#DataSecurity&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=snowflake&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#Snowflake&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=snowflakedevelopers&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#SnowflakeDevelopers&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?auto=webp&amp;s=87203ce307f9b72fb094e85035ea3a41a5c8c384", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9637f60474d774efa820fda8f5974253eaefa50", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=83868552d3590e90338962cb8d1672ccbaa73828", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4b715c2453ce59b28c1dcce84f0153ab57bd1f0", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9699bdf7ecc3f6608279ad7cb3f1411d89fc0424", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7c95fed484686b328184f7151ca8e51384b94448", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=20407829974bcc45a6f50e4809fca58564a96763", "width": 1080, "height": 565}], "variants": {}, "id": "4x9_UIUovtScdP6OlrszrrtgeXaSEDyQR_m-Sv_lbvk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xprjr", "is_robot_indexable": true, "report_reasons": null, "author": "ijiv_s", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xprjr/key_takeaways_from_snowflake_summit_2023_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xprjr/key_takeaways_from_snowflake_summit_2023_in/", "subreddit_subscribers": 131717, "created_utc": 1696230074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting Started with Airflow for Beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16xw41s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Getting Started with Airflow for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xUKIL7zsjos/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16xw41s", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IfZ7wJhL9utiPsC-TD-zD8lu-CTQx4ysaSk8Sv6M6fA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696251805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/xUKIL7zsjos", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?auto=webp&amp;s=57532a9798dd0f63f82f98e6bdad2b089b1be608", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa7e8c5e146fd23eb95bfc63815b710a803be4e6", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=15475b8c73de173bfc254994ecfb17fcdb78c882", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=40b1b167450b074097af8c9efc000061a07aed17", "width": 320, "height": 240}], "variants": {}, "id": "LmI8hdoYDnBSx0i5v80cfgwiuAE39fOk0kw_zg9f3lw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xw41s", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xw41s/getting_started_with_airflow_for_beginners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/xUKIL7zsjos", "subreddit_subscribers": 131717, "created_utc": 1696251805.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Getting Started with Airflow for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xUKIL7zsjos/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello Everyone,\n\nI'm an Industrial Engineer that has been working on data for the last couple of years. 1 year as a Data Analyst and almost 2 years as an Analytics Specialist. I ended up on this area by learning on my own and getting some certifications (also there wasn't as much analysts as there are now).\n\nAnyways, as it happens to a lot, my position is kind of ambiguous and I personally would define it as an ETL and dashboard developer. I create initial queries using SQL and then transform the data using Alteryx and feed it to a tableau or power BI dashboard that I create.  \nA regular workflow could have 10 different EDW sources and a couple of excel files. The initial data is generally around 400M records and ends of being 100K - 4M record. So I have to prepare the data for myself to use later.\n\nI want to get deeper into the Data engineering part of it and eventually look for data engineer jobs, I started my research today to determine the next logical steps but depending on the source, the suggestions are very different. I would like to study a masters eventually but I can\u00b4t do it right now.\n\nSo, my question is: In your opinion and taking into account your personal experience and preferences and **without saying \"it depends\"**, given my described background. which tool/software/process do you think would be the most valuable to learn to be competitive?\n\nAlso, if you know of a good youtube video that explains what it actually is to be a data engineer, it would be appreciated, most of the content I saw seemed like it was made by a 20 yr old influencer trying to get likes.", "author_fullname": "t2_38po62bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from Analytics Specialist to Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y5790", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696273467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m an Industrial Engineer that has been working on data for the last couple of years. 1 year as a Data Analyst and almost 2 years as an Analytics Specialist. I ended up on this area by learning on my own and getting some certifications (also there wasn&amp;#39;t as much analysts as there are now).&lt;/p&gt;\n\n&lt;p&gt;Anyways, as it happens to a lot, my position is kind of ambiguous and I personally would define it as an ETL and dashboard developer. I create initial queries using SQL and then transform the data using Alteryx and feed it to a tableau or power BI dashboard that I create.&lt;br/&gt;\nA regular workflow could have 10 different EDW sources and a couple of excel files. The initial data is generally around 400M records and ends of being 100K - 4M record. So I have to prepare the data for myself to use later.&lt;/p&gt;\n\n&lt;p&gt;I want to get deeper into the Data engineering part of it and eventually look for data engineer jobs, I started my research today to determine the next logical steps but depending on the source, the suggestions are very different. I would like to study a masters eventually but I can\u00b4t do it right now.&lt;/p&gt;\n\n&lt;p&gt;So, my question is: In your opinion and taking into account your personal experience and preferences and &lt;strong&gt;without saying &amp;quot;it depends&amp;quot;&lt;/strong&gt;, given my described background. which tool/software/process do you think would be the most valuable to learn to be competitive?&lt;/p&gt;\n\n&lt;p&gt;Also, if you know of a good youtube video that explains what it actually is to be a data engineer, it would be appreciated, most of the content I saw seemed like it was made by a 20 yr old influencer trying to get likes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16y5790", "is_robot_indexable": true, "report_reasons": null, "author": "Esteban_Rdz", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y5790/transitioning_from_analytics_specialist_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y5790/transitioning_from_analytics_specialist_to_data/", "subreddit_subscribers": 131717, "created_utc": 1696273467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I am comfortable with setting up a pipeline, it runs more or less as I expect but I am not really confident when it comes to configure it, automate to the fullest, parametrize, orchestrate maybe, so all the MS docs and most of youtube/udemy tackles the topic vaguely, just letting you dip the toes and while it'll make you know the tool, it doesnt make you being independent. Now I landed on client site, created some pipelines and need to make them config driven, so there is no further development at UAT's, it should be prone to any changes, additions etc. Are there any prototypes/projects with descriptions, where those things have been discussed in depth, ETL configs etc? Or some blog posts? Thank you in advance", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get good at config driven pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xuvb6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696248221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I am comfortable with setting up a pipeline, it runs more or less as I expect but I am not really confident when it comes to configure it, automate to the fullest, parametrize, orchestrate maybe, so all the MS docs and most of youtube/udemy tackles the topic vaguely, just letting you dip the toes and while it&amp;#39;ll make you know the tool, it doesnt make you being independent. Now I landed on client site, created some pipelines and need to make them config driven, so there is no further development at UAT&amp;#39;s, it should be prone to any changes, additions etc. Are there any prototypes/projects with descriptions, where those things have been discussed in depth, ETL configs etc? Or some blog posts? Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xuvb6", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xuvb6/how_to_get_good_at_config_driven_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xuvb6/how_to_get_good_at_config_driven_pipelines/", "subreddit_subscribers": 131717, "created_utc": 1696248221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an s3 bucket with about 5+ million JSON files loaded per day (across our different client folders).\n\n* clientA - 9/25 - 120k files\n* clientB - 9/25 - 1.2M files  (1 file per userid)\n\neach JSON is small &lt; 10kb each.\n\nI have to retrieve a couple key-value pairs from the json and export it back to a new s3 bucket (combined). so from 1.2M files, the output should maybe be &lt;50 files in parquet/csv format.\n\n* example: extract these fields from JSON\n   * \"activated\": true and \"userid\": 123\n* expected results: tabular parquet/csv file\n   * activated, userid\n\n|activated|userid|\n|:-|:-|\n|true|123|\n|false|456|\n\nthis only needs to run once per day (batch).\n\n**current environment:**\n\nHybrid - SQL Server on-prem and Airflow (on-prem) and Redshift, primarily. we actually need to load this to SQL Server but we can use Redshift as a  processing middle-man if we need to.\n\nwe have the option of using Glue/Spark.\n\n**rough plan**\n\n1. glue job using pyspark to read the files for the previous day\n2. parse the json to get what we need\n3. export it back out to another s3 bucket  in gzipped csv\n   1. each brand will get its own folder of exported files\n\nAny ideas on this approach?\n\n* is there a way to trigger the glue job for a specific day (if we wanted to rerun a day?)\n* it'd be nice if there's an error that it can alert but continue with the other clients (non-blocking)\n\nWe don't have an EMR cluster (don't really have a need). I realize we can use EMR Serverless as well. Perhaps we can use that with our on-prem Airflow instance instead\n\n**Another option -**\n\n1. use Redshift's COPY command and [JSONPaths filters](https://docs.aws.amazon.com/redshift/latest/dg/copy-usage_notes-copy-from-json.html) to load the s3 files to a staging table on Redshift\n2. Then UNLOAD the entire table (all the records) to csv so it can be imported into SQL Server\n   1. this has the benefit of being \"free\" since our cluster is always running.\n\nOption 3:\n\n* use aws athena\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nedit: updated post with some more details.\n\n&amp;#x200B;", "author_fullname": "t2_3yozg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about using Glue/Spark to process millions of JSON files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y7wpn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696284082.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696279632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an s3 bucket with about 5+ million JSON files loaded per day (across our different client folders).&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;clientA - 9/25 - 120k files&lt;/li&gt;\n&lt;li&gt;clientB - 9/25 - 1.2M files  (1 file per userid)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;each JSON is small &amp;lt; 10kb each.&lt;/p&gt;\n\n&lt;p&gt;I have to retrieve a couple key-value pairs from the json and export it back to a new s3 bucket (combined). so from 1.2M files, the output should maybe be &amp;lt;50 files in parquet/csv format.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;example: extract these fields from JSON\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;activated&amp;quot;: true and &amp;quot;userid&amp;quot;: 123&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;expected results: tabular parquet/csv file\n\n&lt;ul&gt;\n&lt;li&gt;activated, userid&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;activated&lt;/th&gt;\n&lt;th align=\"left\"&gt;userid&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;true&lt;/td&gt;\n&lt;td align=\"left\"&gt;123&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;false&lt;/td&gt;\n&lt;td align=\"left\"&gt;456&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;this only needs to run once per day (batch).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;current environment:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Hybrid - SQL Server on-prem and Airflow (on-prem) and Redshift, primarily. we actually need to load this to SQL Server but we can use Redshift as a  processing middle-man if we need to.&lt;/p&gt;\n\n&lt;p&gt;we have the option of using Glue/Spark.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;rough plan&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;glue job using pyspark to read the files for the previous day&lt;/li&gt;\n&lt;li&gt;parse the json to get what we need&lt;/li&gt;\n&lt;li&gt;export it back out to another s3 bucket  in gzipped csv\n\n&lt;ol&gt;\n&lt;li&gt;each brand will get its own folder of exported files&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any ideas on this approach?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;is there a way to trigger the glue job for a specific day (if we wanted to rerun a day?)&lt;/li&gt;\n&lt;li&gt;it&amp;#39;d be nice if there&amp;#39;s an error that it can alert but continue with the other clients (non-blocking)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We don&amp;#39;t have an EMR cluster (don&amp;#39;t really have a need). I realize we can use EMR Serverless as well. Perhaps we can use that with our on-prem Airflow instance instead&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Another option -&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;use Redshift&amp;#39;s COPY command and &lt;a href=\"https://docs.aws.amazon.com/redshift/latest/dg/copy-usage_notes-copy-from-json.html\"&gt;JSONPaths filters&lt;/a&gt; to load the s3 files to a staging table on Redshift&lt;/li&gt;\n&lt;li&gt;Then UNLOAD the entire table (all the records) to csv so it can be imported into SQL Server\n\n&lt;ol&gt;\n&lt;li&gt;this has the benefit of being &amp;quot;free&amp;quot; since our cluster is always running.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Option 3:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;use aws athena&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;edit: updated post with some more details.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16y7wpn", "is_robot_indexable": true, "report_reasons": null, "author": "gman1023", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y7wpn/question_about_using_gluespark_to_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y7wpn/question_about_using_gluespark_to_process/", "subreddit_subscribers": 131717, "created_utc": 1696279632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI am running pyspark code on my local machine and trying to understand how to get rid of pyspark warning- 23/10/02 11:31:14 WARN TaskSetManager: Stage 36 contains a task of very large size (2886 KiB). The maximum recommended task size is 1000 KiB.\n\nI read multiple posts suggesting using repartition or parallelize functions. But when I try the repartition function the large size value does not change at all. And I haven't tried parallelize because I do not want the dataframe to convert into RDD.\n\nSo I did a comparing test: \n\nCASE I: Code:\n\n    scada = spark.read.csv('../processed/scada_data.csv') \n    scada.count() \n\nOutput: \n\n    337776 \n\nCASE II: Code:\n\n    test = pd.read_csv('../processed/scada_data.csv') \n    spark_scada = spark.createDataFrame(test) \n    spark_scada.count() \n\nOutput:\n\n    23/10/02 11:31:14 WARN TaskSetManager: Stage 36 contains a task of very large size (2886 KiB). The maximum recommended task size is 1000 KiB. \n    337776 \n\nInterestingly, I do not get the warning when directly reading the csv using pyspark. But if I read it using pandas and then convert it to a spark dataframe, I get the warning. So, just to understand better - If I was to read csv using pandas then convert to spark dataframe (I know I dont have to but just to understand) what can I do to get rid of the warning, like the same way there is no warning when reading directly through pyspark?", "author_fullname": "t2_hywcxnb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyspark question about warning - Stage contains a task of very large size.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y537v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696273221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am running pyspark code on my local machine and trying to understand how to get rid of pyspark warning- 23/10/02 11:31:14 WARN TaskSetManager: Stage 36 contains a task of very large size (2886 KiB). The maximum recommended task size is 1000 KiB.&lt;/p&gt;\n\n&lt;p&gt;I read multiple posts suggesting using repartition or parallelize functions. But when I try the repartition function the large size value does not change at all. And I haven&amp;#39;t tried parallelize because I do not want the dataframe to convert into RDD.&lt;/p&gt;\n\n&lt;p&gt;So I did a comparing test: &lt;/p&gt;\n\n&lt;p&gt;CASE I: Code:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;scada = spark.read.csv(&amp;#39;../processed/scada_data.csv&amp;#39;) \nscada.count() \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Output: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;337776 \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;CASE II: Code:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;test = pd.read_csv(&amp;#39;../processed/scada_data.csv&amp;#39;) \nspark_scada = spark.createDataFrame(test) \nspark_scada.count() \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Output:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;23/10/02 11:31:14 WARN TaskSetManager: Stage 36 contains a task of very large size (2886 KiB). The maximum recommended task size is 1000 KiB. \n337776 \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Interestingly, I do not get the warning when directly reading the csv using pyspark. But if I read it using pandas and then convert it to a spark dataframe, I get the warning. So, just to understand better - If I was to read csv using pandas then convert to spark dataframe (I know I dont have to but just to understand) what can I do to get rid of the warning, like the same way there is no warning when reading directly through pyspark?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16y537v", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Role_8051", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y537v/pyspark_question_about_warning_stage_contains_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y537v/pyspark_question_about_warning_stage_contains_a/", "subreddit_subscribers": 131717, "created_utc": 1696273221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say we have a column called previous_order_id that gives the order_id of the previous customer for a given order. It is defined as (using snowflake):\n\n    lag(order_id, 1, 0) over (partition by customer_id order by created_at asc) as previous_email_id\n\nHow would we test the values are correct? \n\nI guess in general, if we generate a SQL based report, how do we know the report has generated the correct values? Aside from testing nulls, accepted values etc.", "author_fullname": "t2_ske3s9us", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing complex logic of SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y0fcs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696262318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say we have a column called previous_order_id that gives the order_id of the previous customer for a given order. It is defined as (using snowflake):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;lag(order_id, 1, 0) over (partition by customer_id order by created_at asc) as previous_email_id\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;How would we test the values are correct? &lt;/p&gt;\n\n&lt;p&gt;I guess in general, if we generate a SQL based report, how do we know the report has generated the correct values? Aside from testing nulls, accepted values etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16y0fcs", "is_robot_indexable": true, "report_reasons": null, "author": "iamanoob38", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y0fcs/testing_complex_logic_of_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y0fcs/testing_complex_logic_of_sql/", "subreddit_subscribers": 131717, "created_utc": 1696262318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I try to understand what are the benefits to convert DICOM images to PNG's.  \nContext:  \nI have DICOM images which I already extracted the useful meta-data I want to use.  \nThose images are for a task, classification-detection pipeline of some disease.\n\nSo  as I already asked, what are the benefits of converting those DICOM  files to PNG's rather then just using pydicom and the dicom pixel\\_array?\n\nReason I ask this is because I saw many top 5 users on kaggle do this when dealing with DICOM images.\n\nIf  I understand how networks actually works, they get as input an array of  pixels as floating point numbers no? So what's the differences between  DICOM pixel\\_array to PNG's pixel array and numpy array or tensor? both  are eventually will be fed to the network as a tensor of floating  numbers.\n\nIs the reason is because PNG's are usually faster to train?\n\nIs the reason is because PNG's have more libraries support for preprocessing / augmentation / etc. ?\n\nIs  the reason is because PNG's are the format many pre-trained models  expect to? (I write this knowing it's 99% not true, as mentioned the  tensor thing)\n\nThanks in Advance, and Please, forgive my English (I could use AI tools to fix it but I feel addicted already)", "author_fullname": "t2_5vngcus6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benefits of converting DICOM images to PNG's", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y6r61", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696277029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I try to understand what are the benefits to convert DICOM images to PNG&amp;#39;s.&lt;br/&gt;\nContext:&lt;br/&gt;\nI have DICOM images which I already extracted the useful meta-data I want to use.&lt;br/&gt;\nThose images are for a task, classification-detection pipeline of some disease.&lt;/p&gt;\n\n&lt;p&gt;So  as I already asked, what are the benefits of converting those DICOM  files to PNG&amp;#39;s rather then just using pydicom and the dicom pixel_array?&lt;/p&gt;\n\n&lt;p&gt;Reason I ask this is because I saw many top 5 users on kaggle do this when dealing with DICOM images.&lt;/p&gt;\n\n&lt;p&gt;If  I understand how networks actually works, they get as input an array of  pixels as floating point numbers no? So what&amp;#39;s the differences between  DICOM pixel_array to PNG&amp;#39;s pixel array and numpy array or tensor? both  are eventually will be fed to the network as a tensor of floating  numbers.&lt;/p&gt;\n\n&lt;p&gt;Is the reason is because PNG&amp;#39;s are usually faster to train?&lt;/p&gt;\n\n&lt;p&gt;Is the reason is because PNG&amp;#39;s have more libraries support for preprocessing / augmentation / etc. ?&lt;/p&gt;\n\n&lt;p&gt;Is  the reason is because PNG&amp;#39;s are the format many pre-trained models  expect to? (I write this knowing it&amp;#39;s 99% not true, as mentioned the  tensor thing)&lt;/p&gt;\n\n&lt;p&gt;Thanks in Advance, and Please, forgive my English (I could use AI tools to fix it but I feel addicted already)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16y6r61", "is_robot_indexable": true, "report_reasons": null, "author": "01jasper", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y6r61/benefits_of_converting_dicom_images_to_pngs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y6r61/benefits_of_converting_dicom_images_to_pngs/", "subreddit_subscribers": 131717, "created_utc": 1696277029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I started my career in 2017 working as Backend Developer, however, two years ago I decided to move to a Data Engineer role in my previous company. I requested the switch to the company because I wanted to try something new and I'm passionate about the data world and everything its involved. \n\nHowever, two years later I was layoff with some other team members. Now, we just two years of experience as Data Engineer it's getting difficult to find a new job remotely or even in my country (I'm from Latin America, I worked for US based companies though staff company). \n\nThese days I've been study and getting certified in some tools like Apache Kafka, dbt and Azure, maybe this would help me to find something. I got the Databricks Apache Spark recently, but I worked with Spark for two years. \n\nAnyway, I've been thinking to switch back to backend. \n\nWhat would you recommend me, what your thoughts? \n\nJust want to read some comments or maybe similar experiences. ", "author_fullname": "t2_7hlpzyga", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't find a job (switched from Backend to Data)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y6c83", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696276083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started my career in 2017 working as Backend Developer, however, two years ago I decided to move to a Data Engineer role in my previous company. I requested the switch to the company because I wanted to try something new and I&amp;#39;m passionate about the data world and everything its involved. &lt;/p&gt;\n\n&lt;p&gt;However, two years later I was layoff with some other team members. Now, we just two years of experience as Data Engineer it&amp;#39;s getting difficult to find a new job remotely or even in my country (I&amp;#39;m from Latin America, I worked for US based companies though staff company). &lt;/p&gt;\n\n&lt;p&gt;These days I&amp;#39;ve been study and getting certified in some tools like Apache Kafka, dbt and Azure, maybe this would help me to find something. I got the Databricks Apache Spark recently, but I worked with Spark for two years. &lt;/p&gt;\n\n&lt;p&gt;Anyway, I&amp;#39;ve been thinking to switch back to backend. &lt;/p&gt;\n\n&lt;p&gt;What would you recommend me, what your thoughts? &lt;/p&gt;\n\n&lt;p&gt;Just want to read some comments or maybe similar experiences. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16y6c83", "is_robot_indexable": true, "report_reasons": null, "author": "Still_Young8611", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y6c83/cant_find_a_job_switched_from_backend_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y6c83/cant_find_a_job_switched_from_backend_to_data/", "subreddit_subscribers": 131717, "created_utc": 1696276083.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I started a job as a Data Entry/ Integration clerk for a manufacturing company, I had an internship as Solution Architect, where I briefly touched upon data pipeline and did a Data analytics bootcamp, but don't have much experience in this regard.\nThe company I'm working is quite small and atm is trying to migrate from a bespoke, old software toward the Microsoft ecosystem. They are bringing in a business analyst and some other people and I have been given charge of the data mapping/ migration, CRM side of things (with support of the BA). I was wondering if any of you have any resource I should consult, and could make this easier.\nSo far I read up some introductiory content\nThank you", "author_fullname": "t2_8v5n5r3my", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any resource useful for data mapping and data migration effort?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y5mcn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696274441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I started a job as a Data Entry/ Integration clerk for a manufacturing company, I had an internship as Solution Architect, where I briefly touched upon data pipeline and did a Data analytics bootcamp, but don&amp;#39;t have much experience in this regard.\nThe company I&amp;#39;m working is quite small and atm is trying to migrate from a bespoke, old software toward the Microsoft ecosystem. They are bringing in a business analyst and some other people and I have been given charge of the data mapping/ migration, CRM side of things (with support of the BA). I was wondering if any of you have any resource I should consult, and could make this easier.\nSo far I read up some introductiory content\nThank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16y5mcn", "is_robot_indexable": true, "report_reasons": null, "author": "Zabadabadoodles", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y5mcn/any_resource_useful_for_data_mapping_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y5mcn/any_resource_useful_for_data_mapping_and_data/", "subreddit_subscribers": 131717, "created_utc": 1696274441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our organisation is looking to migrate spark +EMR stack to alternative stack due to horrible implementation that has caused a lot of downtime. One of the solution that we are discussing is Nifi + dbt + Redshift. I have looked into Nifi but on first glance documentation seems very limited and I don\u2019t find extensive implementation tutorials. \n\nHave anyone used this tool in n production and how was your experience? \n\nAny guidelines would help us in decision making.\n\nApologies I\u2019m not a native english speaker", "author_fullname": "t2_nfqnja68", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using Apache Nifi for production workflows ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y4eml", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696271603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our organisation is looking to migrate spark +EMR stack to alternative stack due to horrible implementation that has caused a lot of downtime. One of the solution that we are discussing is Nifi + dbt + Redshift. I have looked into Nifi but on first glance documentation seems very limited and I don\u2019t find extensive implementation tutorials. &lt;/p&gt;\n\n&lt;p&gt;Have anyone used this tool in n production and how was your experience? &lt;/p&gt;\n\n&lt;p&gt;Any guidelines would help us in decision making.&lt;/p&gt;\n\n&lt;p&gt;Apologies I\u2019m not a native english speaker&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16y4eml", "is_robot_indexable": true, "report_reasons": null, "author": "pudding0ridden0a", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y4eml/anyone_using_apache_nifi_for_production_workflows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y4eml/anyone_using_apache_nifi_for_production_workflows/", "subreddit_subscribers": 131717, "created_utc": 1696271603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Economics of a Data Mesh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16xylzj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/asYHsIY2kWUJFwtiE2r846XwB1kMey6DWhbL0qhH6RU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696258006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/hubertdulay/p/the-economics-of-a-data-mesh?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?auto=webp&amp;s=7c34009cf87a9174cefcac1ea03e4e8915ebe8ec", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f32b9a9cd7b57620422d8eda54ea146ef1886234", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=44dd3db79dcc5c718e4c70adedbd3fd157d6c9ed", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=977ed1c2fd28853d7d2cd2955ad926ae1c141923", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c04e0b8d6ca89d0628ba471d9e580492926f8957", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ddb0864bca29658a528df99596a5cf9a251a1efd", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8ff2c7a04498f0549c3bf53b29cc99e9078e8295", "width": 1080, "height": 540}], "variants": {}, "id": "NcNSsLXEhXs6fOgmhbwaZYHPgD_-CjFwtLmWBLgasOU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xylzj", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xylzj/the_economics_of_a_data_mesh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/hubertdulay/p/the-economics-of-a-data-mesh?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 131717, "created_utc": 1696258006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there! I'm reading some documentation about Databricks and how to optimize the table sizes. I've found that the default (and sometimes recommended) value of individual files when using OPTIMIZE is 1 GB (and I understand the rationale for this file size) but then found out that there is another feature called AUTO OPTIMIZE that will set the file size at 128 MB in order to *accelerate write-intensive operations (as mentioned in* [here](https://docs.databricks.com/en/delta/tune-file-size.html#autotune-workload)). \n\nI'm a little bit confused about why having smaller files would be good for write operations (I'm guessing it may have something to do with parallelization, but not sure), and also confirm that (if I understood correctly) we want large files for improving reads on tables but small files for improving writes.\n\nCould anyone shed some light on this questions?\n\n ", "author_fullname": "t2_zn4k7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 GB (OPTIMIZE) vs 128 MB (AUTO OPTIMIZE) file size in Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xyl6t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696257954.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there! I&amp;#39;m reading some documentation about Databricks and how to optimize the table sizes. I&amp;#39;ve found that the default (and sometimes recommended) value of individual files when using OPTIMIZE is 1 GB (and I understand the rationale for this file size) but then found out that there is another feature called AUTO OPTIMIZE that will set the file size at 128 MB in order to &lt;em&gt;accelerate write-intensive operations (as mentioned in&lt;/em&gt; &lt;a href=\"https://docs.databricks.com/en/delta/tune-file-size.html#autotune-workload\"&gt;here&lt;/a&gt;). &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a little bit confused about why having smaller files would be good for write operations (I&amp;#39;m guessing it may have something to do with parallelization, but not sure), and also confirm that (if I understood correctly) we want large files for improving reads on tables but small files for improving writes.&lt;/p&gt;\n\n&lt;p&gt;Could anyone shed some light on this questions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?auto=webp&amp;s=9dd59568b8579947f05ce66ee028655ef14e64d6", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99613d282007d0bcc41947bc7f0846da94adca04", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=400ef45c57444e53fb95c1358e9a0b6419c3112e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ed83d9a6c1afb35b8be4de3f85b722298d1c3d6", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=768e111879e31b88e5a61b81d8d367edaa5e5351", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2a359111feb6e4d3ffa529f6614614a63914c4e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f6e5d40f18830851f93eb2158f465da573a5df80", "width": 1080, "height": 567}], "variants": {}, "id": "RDPFo3n-9ZSpTUT0k9sCNnHc7tSD0wBu2TyDFfITIDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xyl6t", "is_robot_indexable": true, "report_reasons": null, "author": "DUM00", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xyl6t/1_gb_optimize_vs_128_mb_auto_optimize_file_size/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xyl6t/1_gb_optimize_vs_128_mb_auto_optimize_file_size/", "subreddit_subscribers": 131717, "created_utc": 1696257954.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just trying to do some calculations on data pipelines via Synapse, mainly the costings for activity runs.\n\nForEach &amp; Switches (iterations &amp; conditionals), do they have to be included in the cost as a activity run cost? They don't fall under Azure Integration Runtime or Self Hosted so I assume not?\n\nThanks!", "author_fullname": "t2_2ybq8ird", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Synapse Analytics - Data Pipeline - Costings on Activity Runs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xt4op", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696242822.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just trying to do some calculations on data pipelines via Synapse, mainly the costings for activity runs.&lt;/p&gt;\n\n&lt;p&gt;ForEach &amp;amp; Switches (iterations &amp;amp; conditionals), do they have to be included in the cost as a activity run cost? They don&amp;#39;t fall under Azure Integration Runtime or Self Hosted so I assume not?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16xt4op", "is_robot_indexable": true, "report_reasons": null, "author": "downsy2019", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xt4op/azure_synapse_analytics_data_pipeline_costings_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xt4op/azure_synapse_analytics_data_pipeline_costings_on/", "subreddit_subscribers": 131717, "created_utc": 1696242822.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m an expert in python, SQL and Bash. Do data engineers still used Java? Since MapReduce is kinda phased out by Spark/PySpark.", "author_fullname": "t2_muzoa5tk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Java still a requirement in DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xqihp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696232898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m an expert in python, SQL and Bash. Do data engineers still used Java? Since MapReduce is kinda phased out by Spark/PySpark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16xqihp", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Box-7", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xqihp/java_still_a_requirement_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xqihp/java_still_a_requirement_in_de/", "subreddit_subscribers": 131717, "created_utc": 1696232898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,  \nWe make use of the Debezium PostgreSQL connector but we don't appreciate that it cannot deliver DDL operations. (citation [https://debezium.io/documentation/reference/stable/connectors/postgresql.html](https://debezium.io/documentation/reference/stable/connectors/postgresql.html))\n\nOur expectation was that we could simply hook up Debezium and our PostgreSQL instance and get near-real-time \"mirroring\" to Kafka. We eventually need this mirroring to end up in Redshift, but that's out of scope of this question.\n\nQuestion: are there any alternatives to Debezium's PostgreSQL connector that do capture DDL operations? Some constraints:\n\n\\- cannot send data to a third party. Everything must take place on prem.", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative to Debezium PostgreSQL connector?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xoddt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696225138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nWe make use of the Debezium PostgreSQL connector but we don&amp;#39;t appreciate that it cannot deliver DDL operations. (citation &lt;a href=\"https://debezium.io/documentation/reference/stable/connectors/postgresql.html\"&gt;https://debezium.io/documentation/reference/stable/connectors/postgresql.html&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Our expectation was that we could simply hook up Debezium and our PostgreSQL instance and get near-real-time &amp;quot;mirroring&amp;quot; to Kafka. We eventually need this mirroring to end up in Redshift, but that&amp;#39;s out of scope of this question.&lt;/p&gt;\n\n&lt;p&gt;Question: are there any alternatives to Debezium&amp;#39;s PostgreSQL connector that do capture DDL operations? Some constraints:&lt;/p&gt;\n\n&lt;p&gt;- cannot send data to a third party. Everything must take place on prem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xoddt", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xoddt/alternative_to_debezium_postgresql_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xoddt/alternative_to_debezium_postgresql_connector/", "subreddit_subscribers": 131717, "created_utc": 1696225138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working in Data for 5 years, the last 2 as DE. During that time I have worked for same number of companies (around 1 year per company)\n\nThe problem for me is that all companies did not really understood what DE is about. Finding this subreddit has been an eye-opener for me also because I am reading all about this cool tools and ideas but I haven't really worked with anything regarding proper DE.\n\nI just recently snatched an opportunity as a Sr DE but to my surprise, the team is more BI that anything else. One person even holds the same title as me but doesn't even know SQL. Plus the company work with external dbs (some systems have their own dbs and we have reader access only). During this time I have only made some queries and helped with some dashboards and that's it. This is almost the same thing that I did on my past company as DE.\n\nI feel that I have a very good SQL, a decent Python and useful knowledge of BI Tools (mostly Tableau and PowerBI) and have a certification on AWS. I also sell myself very good on interviews which I feel has given me a better job opportunity each year. \n\nI often read about tools like dbt, terraform, airflow etc. I kind of know how they work but the reality is that I have not touched any of that.\n\nI really want to give value and to this point in my carreer I really feel that I need to be updating myself but I don't really know how to that without proper exposure. \n\n&amp;#x200B;\n\nAny thoughts on this??", "author_fullname": "t2_gbmtpmgy2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling a bit down regarding my DE career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ye2hm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696294489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working in Data for 5 years, the last 2 as DE. During that time I have worked for same number of companies (around 1 year per company)&lt;/p&gt;\n\n&lt;p&gt;The problem for me is that all companies did not really understood what DE is about. Finding this subreddit has been an eye-opener for me also because I am reading all about this cool tools and ideas but I haven&amp;#39;t really worked with anything regarding proper DE.&lt;/p&gt;\n\n&lt;p&gt;I just recently snatched an opportunity as a Sr DE but to my surprise, the team is more BI that anything else. One person even holds the same title as me but doesn&amp;#39;t even know SQL. Plus the company work with external dbs (some systems have their own dbs and we have reader access only). During this time I have only made some queries and helped with some dashboards and that&amp;#39;s it. This is almost the same thing that I did on my past company as DE.&lt;/p&gt;\n\n&lt;p&gt;I feel that I have a very good SQL, a decent Python and useful knowledge of BI Tools (mostly Tableau and PowerBI) and have a certification on AWS. I also sell myself very good on interviews which I feel has given me a better job opportunity each year. &lt;/p&gt;\n\n&lt;p&gt;I often read about tools like dbt, terraform, airflow etc. I kind of know how they work but the reality is that I have not touched any of that.&lt;/p&gt;\n\n&lt;p&gt;I really want to give value and to this point in my carreer I really feel that I need to be updating myself but I don&amp;#39;t really know how to that without proper exposure. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any thoughts on this??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ye2hm", "is_robot_indexable": true, "report_reasons": null, "author": "hot-bulbasur", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ye2hm/feeling_a_bit_down_regarding_my_de_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ye2hm/feeling_a_bit_down_regarding_my_de_career/", "subreddit_subscribers": 131717, "created_utc": 1696294489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for a new role. I am interested in the SWE side &amp; not interested in the analytics engineer roles. After working for a year in the DE space I have realized that ~80-90% DE roles in the market are mostly analytics engineer roles and only 10-15% or even less are SWE oriented roles. I would like to know from the community which companies offer these roles", "author_fullname": "t2_dpc2z7ubu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Companies having SWE oriented data roles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ydysg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696294200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a new role. I am interested in the SWE side &amp;amp; not interested in the analytics engineer roles. After working for a year in the DE space I have realized that ~80-90% DE roles in the market are mostly analytics engineer roles and only 10-15% or even less are SWE oriented roles. I would like to know from the community which companies offer these roles&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ydysg", "is_robot_indexable": true, "report_reasons": null, "author": "cyamnihc", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ydysg/companies_having_swe_oriented_data_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ydysg/companies_having_swe_oriented_data_roles/", "subreddit_subscribers": 131717, "created_utc": 1696294200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So like the title says I started a new job today. Figure out why this report written in R broke 2 months ago. I open up a single file with 6952 lines in it. All that's left of me is a 2 page word dock explaining it the main file that call 3 other files, each with 2-3k lines of R code, to create a single 7 page PDF report from a single data source.\n\nWHAT THE ABSOLUTE HELL AM I LOOKING AT LOL. I don't know R, but it's similar enough to python that I can follow along to get the gist of what it's doing. BUT STILL! WHO NEED 10K+ LINES OF CODE FOR THIS?\n\nShould I tell them it's all bunk and make my case to start from scratch, or just buckle down and learn myself some R to make it work?", "author_fullname": "t2_3wxhxt1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New job. Minor shit show rant, and advice needed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ycoj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696290766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So like the title says I started a new job today. Figure out why this report written in R broke 2 months ago. I open up a single file with 6952 lines in it. All that&amp;#39;s left of me is a 2 page word dock explaining it the main file that call 3 other files, each with 2-3k lines of R code, to create a single 7 page PDF report from a single data source.&lt;/p&gt;\n\n&lt;p&gt;WHAT THE ABSOLUTE HELL AM I LOOKING AT LOL. I don&amp;#39;t know R, but it&amp;#39;s similar enough to python that I can follow along to get the gist of what it&amp;#39;s doing. BUT STILL! WHO NEED 10K+ LINES OF CODE FOR THIS?&lt;/p&gt;\n\n&lt;p&gt;Should I tell them it&amp;#39;s all bunk and make my case to start from scratch, or just buckle down and learn myself some R to make it work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ycoj4", "is_robot_indexable": true, "report_reasons": null, "author": "TrainquilOasis1423", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ycoj4/new_job_minor_shit_show_rant_and_advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ycoj4/new_job_minor_shit_show_rant_and_advice_needed/", "subreddit_subscribers": 131717, "created_utc": 1696290766.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}