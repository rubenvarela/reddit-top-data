{"kind": "Listing", "data": {"after": "t3_16y3bo4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My wife finally caved and is letting me start looking for storage options for the server and nas and was impressed with this and asked me what this was and I have no clue and so here we are and thanks for the help in advance ", "author_fullname": "t2_zeet3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is this setup?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_16yfa9k", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 182, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 1200, "fallback_url": "https://v.redd.it/0jax06eg8wrb1/DASH_480.mp4?source=fallback", "height": 854, "width": 480, "scrubber_media_url": "https://v.redd.it/0jax06eg8wrb1/DASH_96.mp4", "dash_url": "https://v.redd.it/0jax06eg8wrb1/DASHPlaylist.mpd?a=1698921505%2CMGVjOWNiYTk0MDBjNTczMGI5MGFiZTBmMmE0NWYwODZmNjBkNzI4YzQ1YWJkYmQ3MzE0MTY2NWRhYzNkYzg4Zg%3D%3D&amp;v=1&amp;f=sd", "duration": 21, "hls_url": "https://v.redd.it/0jax06eg8wrb1/HLSPlaylist.m3u8?a=1698921505%2CZGZjNmQyMmY2ZWJhOGIyM2U2ZjJiNGY1OGY4MzM5ZDBkNmVmNWFlMjFmYmNjOTRjZjI5MWNkMjZiYzAxZjlhZQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 182, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/cGNnMnltYWc4d3JiMZ_YBANuCpDJb6djZXiylbI-75d6mgit1OJTy-aZQJ7U.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=f44093be4fe19e76f39e140e9311f588be6407fc", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696297864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My wife finally caved and is letting me start looking for storage options for the server and nas and was impressed with this and asked me what this was and I have no clue and so here we are and thanks for the help in advance &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/0jax06eg8wrb1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/cGNnMnltYWc4d3JiMZ_YBANuCpDJb6djZXiylbI-75d6mgit1OJTy-aZQJ7U.png?format=pjpg&amp;auto=webp&amp;s=f71b1996b6beaa69796d824e691037a136c11827", "width": 982, "height": 1746}, "resolutions": [{"url": "https://external-preview.redd.it/cGNnMnltYWc4d3JiMZ_YBANuCpDJb6djZXiylbI-75d6mgit1OJTy-aZQJ7U.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=f7d690b43e76a7a217dec0a3da05c7c6add44c13", "width": 108, "height": 192}, {"url": "https://external-preview.redd.it/cGNnMnltYWc4d3JiMZ_YBANuCpDJb6djZXiylbI-75d6mgit1OJTy-aZQJ7U.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9658a823dffd14785a8bda8f080311733618cabc", "width": 216, "height": 384}, {"url": "https://external-preview.redd.it/cGNnMnltYWc4d3JiMZ_YBANuCpDJb6djZXiylbI-75d6mgit1OJTy-aZQJ7U.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=64ded4f3e40a38152103abb0d2913a49f7d22bee", "width": 320, "height": 568}, {"url": "https://external-preview.redd.it/cGNnMnltYWc4d3JiMZ_YBANuCpDJb6djZXiylbI-75d6mgit1OJTy-aZQJ7U.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=7968c9711dd8cc39045e50537c4bed29203d31fb", "width": 640, "height": 1137}, {"url": "https://external-preview.redd.it/cGNnMnltYWc4d3JiMZ_YBANuCpDJb6djZXiylbI-75d6mgit1OJTy-aZQJ7U.png?width=960&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=5135e2abb22e8e3b9c76e2bc0668134f36626be3", "width": 960, "height": 1706}], "variants": {}, "id": "cGNnMnltYWc4d3JiMZ_YBANuCpDJb6djZXiylbI-75d6mgit1OJTy-aZQJ7U"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16yfa9k", "is_robot_indexable": true, "report_reasons": null, "author": "drake53545", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16yfa9k/what_is_this_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/0jax06eg8wrb1", "subreddit_subscribers": 704513, "created_utc": 1696297864.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 1200, "fallback_url": "https://v.redd.it/0jax06eg8wrb1/DASH_480.mp4?source=fallback", "height": 854, "width": 480, "scrubber_media_url": "https://v.redd.it/0jax06eg8wrb1/DASH_96.mp4", "dash_url": "https://v.redd.it/0jax06eg8wrb1/DASHPlaylist.mpd?a=1698921505%2CMGVjOWNiYTk0MDBjNTczMGI5MGFiZTBmMmE0NWYwODZmNjBkNzI4YzQ1YWJkYmQ3MzE0MTY2NWRhYzNkYzg4Zg%3D%3D&amp;v=1&amp;f=sd", "duration": 21, "hls_url": "https://v.redd.it/0jax06eg8wrb1/HLSPlaylist.m3u8?a=1698921505%2CZGZjNmQyMmY2ZWJhOGIyM2U2ZjJiNGY1OGY4MzM5ZDBkNmVmNWFlMjFmYmNjOTRjZjI5MWNkMjZiYzAxZjlhZQ%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So... in 2019 or something like so I decided to watch 1 movie for every year since 1895 till $current\\_year but sad true is most fun for me is looking for movies, downloading them (so far I have only one screen recording case) and adding into Kodi. \n\n&amp;#x200B;\n\nAny tips how keep it low as downloading and catologing movies took quite a time", "author_fullname": "t2_11am0r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Movie downloading addiction?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xzy69", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 73, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 73, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696261217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So... in 2019 or something like so I decided to watch 1 movie for every year since 1895 till $current_year but sad true is most fun for me is looking for movies, downloading them (so far I have only one screen recording case) and adding into Kodi. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any tips how keep it low as downloading and catologing movies took quite a time&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16xzy69", "is_robot_indexable": true, "report_reasons": null, "author": "wytrzeszcz", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16xzy69/movie_downloading_addiction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16xzy69/movie_downloading_addiction/", "subreddit_subscribers": 704513, "created_utc": 1696261217.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/collateral/white-paper/white-paper-ssd-endurance-and-hdd-workloads.pdf\n\n(EDIT: Published January 2023 so fairly recent)\n\nIt addresses SSD endurance (long term unpowered storage) and generally how SSD's operate.\n\nBut regarding HDD's, particularly interesting is addressing the Hard Drive Workload Rating and why it's the same regardless of capacity (cherry picked specific entries below):\n\n&gt; Why Doesn\u2019t Workload Increase with Capacity?\n&gt; \n&gt; There is also no ability to wear-level the amount of data that is transferred through any specific head. While populating a greater number of heads and platters in a higher-capacity drive will mean that on average each head will transfer less data, the higher number of components provides more potential points of failure. \n&gt; \n&gt; The failure of a single head is typically deemed a failure condition for the entire drive. For example, if a large drive containing 20 heads experiences a failure of only 1 head the drive must be taken out of service and replaced.\n&gt; \n&gt; Across a spectrum where a drive has 6 heads and 3 platters up through a drive which has 20 heads and 10 platters, the failure rates for a given host workload are close to identical.\n&gt; \n&gt; In a single-drive scenario, an HDD that is operated beyond its workload rating does not mean that there is any specific concern about its ability to perform its duty. A drive that is beyond its workload rating that is still operating properly\u2014and for which SMART or SAS log data do not show any red flags\u2014is not expected to individually fail simply by being beyond the rating. HDD workload ratings are best understood as a population-level prediction of failure rates.", "author_fullname": "t2_fzwj4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interesting White Paper about SSD Endurance and HDD Workload Ratings.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y013y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "White Paper", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": 1696261669.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696261395.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/collateral/white-paper/white-paper-ssd-endurance-and-hdd-workloads.pdf\"&gt;https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/collateral/white-paper/white-paper-ssd-endurance-and-hdd-workloads.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;(EDIT: Published January 2023 so fairly recent)&lt;/p&gt;\n\n&lt;p&gt;It addresses SSD endurance (long term unpowered storage) and generally how SSD&amp;#39;s operate.&lt;/p&gt;\n\n&lt;p&gt;But regarding HDD&amp;#39;s, particularly interesting is addressing the Hard Drive Workload Rating and why it&amp;#39;s the same regardless of capacity (cherry picked specific entries below):&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Why Doesn\u2019t Workload Increase with Capacity?&lt;/p&gt;\n\n&lt;p&gt;There is also no ability to wear-level the amount of data that is transferred through any specific head. While populating a greater number of heads and platters in a higher-capacity drive will mean that on average each head will transfer less data, the higher number of components provides more potential points of failure. &lt;/p&gt;\n\n&lt;p&gt;The failure of a single head is typically deemed a failure condition for the entire drive. For example, if a large drive containing 20 heads experiences a failure of only 1 head the drive must be taken out of service and replaced.&lt;/p&gt;\n\n&lt;p&gt;Across a spectrum where a drive has 6 heads and 3 platters up through a drive which has 20 heads and 10 platters, the failure rates for a given host workload are close to identical.&lt;/p&gt;\n\n&lt;p&gt;In a single-drive scenario, an HDD that is operated beyond its workload rating does not mean that there is any specific concern about its ability to perform its duty. A drive that is beyond its workload rating that is still operating properly\u2014and for which SMART or SAS log data do not show any red flags\u2014is not expected to individually fail simply by being beyond the rating. HDD workload ratings are best understood as a population-level prediction of failure rates.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "1TB = 0.909495TiB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16y013y", "is_robot_indexable": true, "report_reasons": null, "author": "HTWingNut", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/16y013y/interesting_white_paper_about_ssd_endurance_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16y013y/interesting_white_paper_about_ssd_endurance_and/", "subreddit_subscribers": 704513, "created_utc": 1696261395.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all! I'm trying to build my first NAS, and wanted to make sure I wasn't missing anything before pulling the trigger!\n\n&amp;#x200B;\n\n[https://ca.pcpartpicker.com/list/WWvqmD](https://ca.pcpartpicker.com/list/WWvqmD)\n\n* i3-10100 (for Plex QuickSync, although I was hoping for something cheaper)\n* 16Gb DDR4-3200 ram. It's RGB, so you know it's fast /s (had it lying around)\n* Asus prime H570M-Plus\n* 2.5/10 Gb/s ethernet adapter (Later buy, had trouble finding a cheaper mobo with 2.5)\n* Cooler master N400\n* eVGA 500w 80+ Gold\n\n&amp;#x200B;\n\nI want to throw unraid on it, and use it to host some docker services, plex, and a perforce server. Is there anything on here I should worry will come back to bite me, or anything that seems over/under spec?\n\nAlso for storage, is there any way for me to buy a single 12TB drive, and upgrade to RAID5 in the future with 2 additional drives?  From what I understand, you can't go from RAID0/RAID1 to RAID5 without just transferring data over to a new set of drives.", "author_fullname": "t2_ndu0t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First-time NAS builder - Will this suffice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y5a5i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696273656.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all! I&amp;#39;m trying to build my first NAS, and wanted to make sure I wasn&amp;#39;t missing anything before pulling the trigger!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://ca.pcpartpicker.com/list/WWvqmD\"&gt;https://ca.pcpartpicker.com/list/WWvqmD&lt;/a&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;i3-10100 (for Plex QuickSync, although I was hoping for something cheaper)&lt;/li&gt;\n&lt;li&gt;16Gb DDR4-3200 ram. It&amp;#39;s RGB, so you know it&amp;#39;s fast /s (had it lying around)&lt;/li&gt;\n&lt;li&gt;Asus prime H570M-Plus&lt;/li&gt;\n&lt;li&gt;2.5/10 Gb/s ethernet adapter (Later buy, had trouble finding a cheaper mobo with 2.5)&lt;/li&gt;\n&lt;li&gt;Cooler master N400&lt;/li&gt;\n&lt;li&gt;eVGA 500w 80+ Gold&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I want to throw unraid on it, and use it to host some docker services, plex, and a perforce server. Is there anything on here I should worry will come back to bite me, or anything that seems over/under spec?&lt;/p&gt;\n\n&lt;p&gt;Also for storage, is there any way for me to buy a single 12TB drive, and upgrade to RAID5 in the future with 2 additional drives?  From what I understand, you can&amp;#39;t go from RAID0/RAID1 to RAID5 without just transferring data over to a new set of drives.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16y5a5i", "is_robot_indexable": true, "report_reasons": null, "author": "GriMw0lf69", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16y5a5i/firsttime_nas_builder_will_this_suffice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16y5a5i/firsttime_nas_builder_will_this_suffice/", "subreddit_subscribers": 704513, "created_utc": 1696273656.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "https://serverpartdeals.com/collections/manufacturer-recertified-drives/products/western-digital-ultrastar-dc-hc530-wuh721414aln6l4-0f31278-14tb-7-2k-rpm-sata-6gb-s-4kn-3-5-recertified-hard-drive", "author_fullname": "t2_2oq4ldty", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is thuds recertified drive good and worth buying WD ultra star", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y80xb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.59, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696279901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://serverpartdeals.com/collections/manufacturer-recertified-drives/products/western-digital-ultrastar-dc-hc530-wuh721414aln6l4-0f31278-14tb-7-2k-rpm-sata-6gb-s-4kn-3-5-recertified-hard-drive\"&gt;https://serverpartdeals.com/collections/manufacturer-recertified-drives/products/western-digital-ultrastar-dc-hc530-wuh721414aln6l4-0f31278-14tb-7-2k-rpm-sata-6gb-s-4kn-3-5-recertified-hard-drive&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TkyP760JhMl_BfXj6JTEvhRPNZYm3ShFR99adLJ00pE.jpg?auto=webp&amp;s=bef394b7ca298f17a9073e324ff90d7bf4585db9", "width": 1200, "height": 1200}, "resolutions": [{"url": "https://external-preview.redd.it/TkyP760JhMl_BfXj6JTEvhRPNZYm3ShFR99adLJ00pE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3812e62d0e4310f92b0be8b4740ff8d06db61b95", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/TkyP760JhMl_BfXj6JTEvhRPNZYm3ShFR99adLJ00pE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7e2046089b3278a19626493460c1feb009bee5c8", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/TkyP760JhMl_BfXj6JTEvhRPNZYm3ShFR99adLJ00pE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=704d5e935c6454567d01db7d7ede39d754c869f4", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/TkyP760JhMl_BfXj6JTEvhRPNZYm3ShFR99adLJ00pE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b58b89993ff1e99925ba300f5776049227babe7c", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/TkyP760JhMl_BfXj6JTEvhRPNZYm3ShFR99adLJ00pE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5ca9c4e56ccd6af73afb71c82d6e27dd88eb2cb2", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/TkyP760JhMl_BfXj6JTEvhRPNZYm3ShFR99adLJ00pE.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=de4c30037a0a6759fa4f133bceefb6bd1b9b0e6d", "width": 1080, "height": 1080}], "variants": {}, "id": "QQdeUyNg_ZOcYoIdgxZ9d5zzvrSlp0F5d13aCQ__si8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16y80xb", "is_robot_indexable": true, "report_reasons": null, "author": "thephillman", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16y80xb/is_thuds_recertified_drive_good_and_worth_buying/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16y80xb/is_thuds_recertified_drive_good_and_worth_buying/", "subreddit_subscribers": 704513, "created_utc": 1696279901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am in the process of upgrading some drives to larger sizes. I figure I can use the old drives as an extra extra layer of backup, just because I have them. Are there any good tools out there for populating the drives, setting up redundancy or parity data, and keeping track of what files are stored on them?\n\nThis whole premise might be a dumb idea vs bitrot, but if they are not sipping electrons and I have the shelf space to store them I felt like I might as well. The alternative would be putting them on the shelf without anything on them.", "author_fullname": "t2_qngs2dbp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good Tools For Cold Storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y8jjv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696281049.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in the process of upgrading some drives to larger sizes. I figure I can use the old drives as an extra extra layer of backup, just because I have them. Are there any good tools out there for populating the drives, setting up redundancy or parity data, and keeping track of what files are stored on them?&lt;/p&gt;\n\n&lt;p&gt;This whole premise might be a dumb idea vs bitrot, but if they are not sipping electrons and I have the shelf space to store them I felt like I might as well. The alternative would be putting them on the shelf without anything on them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16y8jjv", "is_robot_indexable": true, "report_reasons": null, "author": "ByteArchivist", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16y8jjv/good_tools_for_cold_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16y8jjv/good_tools_for_cold_storage/", "subreddit_subscribers": 704513, "created_utc": 1696281049.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been running openmediaserver for many years. I have a 4 drive configuration using snapraid (3 data drives + one parity drive) with mergerfs.  I use the NAS for storing photos, music and a few movies/videos/torrents.  I sometimes use bitorrent on the NAS and I have a plex server on the nas. Updating OMS and Plex is a pain though. It always has some complications. I'm at the point that I need to do a major update and will likely just start from scratch and do a fresh install.  I currently store about 1TB of data on the NAS and I have a separate 3TB drive for backups.\n\nI need to downsize to a smaller place and I can go three ways. 1) Update and keep my OMS NAS (it's in a typical desktop case), 2) get something like a synology NAS, or 3) just get a 3TB drive and put it in my desktop.\n\nI'm really leaning towards option 3, I'm testing running plex media server on my desktop and it works well. Updates can be done very easily.  Option 2 is somewhat appealing because it's a bit more plug n play than my OMS and it is smaller in size.  OMS is becoming less appealing because of the technical side of running it and the space it takes up. As well, file transfers are pretty slow on it.\n\nDowntime isn't important so I don't think I really need redundancy from raid, but maybe I misunderstand what a mirrored drive might give me. Like if I don't have a mirrored drive and my drive slowly starts crapping out, maybe I won't notice it and I'll even start making backups with missing data.\n\nGiven my main use (storage and serving media files via plex or UPNP), option 3 seems good. Is there any other thoughts that maybe I'm missing? \n\n&amp;#x200B;", "author_fullname": "t2_haxjv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Move from NAS to a single drive in my Desktop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y7jmu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696278789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been running openmediaserver for many years. I have a 4 drive configuration using snapraid (3 data drives + one parity drive) with mergerfs.  I use the NAS for storing photos, music and a few movies/videos/torrents.  I sometimes use bitorrent on the NAS and I have a plex server on the nas. Updating OMS and Plex is a pain though. It always has some complications. I&amp;#39;m at the point that I need to do a major update and will likely just start from scratch and do a fresh install.  I currently store about 1TB of data on the NAS and I have a separate 3TB drive for backups.&lt;/p&gt;\n\n&lt;p&gt;I need to downsize to a smaller place and I can go three ways. 1) Update and keep my OMS NAS (it&amp;#39;s in a typical desktop case), 2) get something like a synology NAS, or 3) just get a 3TB drive and put it in my desktop.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m really leaning towards option 3, I&amp;#39;m testing running plex media server on my desktop and it works well. Updates can be done very easily.  Option 2 is somewhat appealing because it&amp;#39;s a bit more plug n play than my OMS and it is smaller in size.  OMS is becoming less appealing because of the technical side of running it and the space it takes up. As well, file transfers are pretty slow on it.&lt;/p&gt;\n\n&lt;p&gt;Downtime isn&amp;#39;t important so I don&amp;#39;t think I really need redundancy from raid, but maybe I misunderstand what a mirrored drive might give me. Like if I don&amp;#39;t have a mirrored drive and my drive slowly starts crapping out, maybe I won&amp;#39;t notice it and I&amp;#39;ll even start making backups with missing data.&lt;/p&gt;\n\n&lt;p&gt;Given my main use (storage and serving media files via plex or UPNP), option 3 seems good. Is there any other thoughts that maybe I&amp;#39;m missing? &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16y7jmu", "is_robot_indexable": true, "report_reasons": null, "author": "dougshmish", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16y7jmu/move_from_nas_to_a_single_drive_in_my_desktop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16y7jmu/move_from_nas_to_a_single_drive_in_my_desktop/", "subreddit_subscribers": 704513, "created_utc": 1696278789.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "As the title states, I need some ideas for storing around 50TB of video streams which grow by 8TB per month. \n\nI can\u2019t upload the streams to a public site. Although there may be some interest in them, I would violate copyright. So this is not an option. \n\nOVH\u2018s cold archive is the cheapest option I have found so far. The only drawback is, I can\u2019t use the material whenever I want to. \n\nSo now I\u2019m wondering: How to store and keep them accessible at the lowest cost? \n\nI\u2019m mostly using my Jellyfin server to access the files. They are all MP4. \n\nAny cloud storage would be capable too. \n\nAppreciate any idea!", "author_fullname": "t2_b7a8w160", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to store video streams?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xz61o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696259373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title states, I need some ideas for storing around 50TB of video streams which grow by 8TB per month. &lt;/p&gt;\n\n&lt;p&gt;I can\u2019t upload the streams to a public site. Although there may be some interest in them, I would violate copyright. So this is not an option. &lt;/p&gt;\n\n&lt;p&gt;OVH\u2018s cold archive is the cheapest option I have found so far. The only drawback is, I can\u2019t use the material whenever I want to. &lt;/p&gt;\n\n&lt;p&gt;So now I\u2019m wondering: How to store and keep them accessible at the lowest cost? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m mostly using my Jellyfin server to access the files. They are all MP4. &lt;/p&gt;\n\n&lt;p&gt;Any cloud storage would be capable too. &lt;/p&gt;\n\n&lt;p&gt;Appreciate any idea!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16xz61o", "is_robot_indexable": true, "report_reasons": null, "author": "_c0der", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16xz61o/where_to_store_video_streams/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16xz61o/where_to_store_video_streams/", "subreddit_subscribers": 704513, "created_utc": 1696259373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am using a LSI 9201-16e 6Gbps HBA with 12x Exos 20TB drives in a NetApp DS4246 enclosure. The DS4246 is connected via a QSFP (SFF-8436) to MiniSAS HD SFF-8088 DDR Hybrid cable.\n\n&amp;#x200B;\n\n Every now and then when I'm copying a 10GB+ file over from a RAM drive, I can get 140MB-190MB/s, but 95% of the time, it's averaging 50-55MB/s.  \n\n&amp;#x200B;\n\nI just don't know what I'm doing wrong. The drives are supposed to be able to sustain a 260MB/s write speed, but I've never even come close.\n\n&amp;#x200B;\n\nWindows 10 Pro x64\n\n128GB Ram DDR3 1333MHz (100GB as a RAM drive)\n\nDual Xeon E5-2697 v2\n\nASUS Z9PE-D8 WS\n\nPrimary OS drive is a Samsung 980 Pro 1TB\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nI can't think of anything else relevant. ", "author_fullname": "t2_rcnc114", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Think I messed up my setup, could use help with my DS4246 being slow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ygnwi", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696301768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am using a LSI 9201-16e 6Gbps HBA with 12x Exos 20TB drives in a NetApp DS4246 enclosure. The DS4246 is connected via a QSFP (SFF-8436) to MiniSAS HD SFF-8088 DDR Hybrid cable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Every now and then when I&amp;#39;m copying a 10GB+ file over from a RAM drive, I can get 140MB-190MB/s, but 95% of the time, it&amp;#39;s averaging 50-55MB/s.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I just don&amp;#39;t know what I&amp;#39;m doing wrong. The drives are supposed to be able to sustain a 260MB/s write speed, but I&amp;#39;ve never even come close.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Windows 10 Pro x64&lt;/p&gt;\n\n&lt;p&gt;128GB Ram DDR3 1333MHz (100GB as a RAM drive)&lt;/p&gt;\n\n&lt;p&gt;Dual Xeon E5-2697 v2&lt;/p&gt;\n\n&lt;p&gt;ASUS Z9PE-D8 WS&lt;/p&gt;\n\n&lt;p&gt;Primary OS drive is a Samsung 980 Pro 1TB&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t think of anything else relevant. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16ygnwi", "is_robot_indexable": true, "report_reasons": null, "author": "Sabertoothplex", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ygnwi/think_i_messed_up_my_setup_could_use_help_with_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16ygnwi/think_i_messed_up_my_setup_could_use_help_with_my/", "subreddit_subscribers": 704513, "created_utc": 1696301768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI need advice on a major project. I have to scan 200 articles (approximately 10 pages each) so around 2000 pages. I then need to convert the scanned articles into a word document or some other digital text format. The reason for this is that I want to upload the text from scanned articles on a website. So three steps:\n\n1) Scan a hard copy of an article\n2) Convert the scan to a digital text file of some sort\n3) Upload the digital text to a website\n\nA few questions:\n\nA) What is the most efficient way to accomplish this? \nB) Is there a program that will do both steps and 1 and 2 simultaneously?\nC) Is there a way to do all of this on my phone with an app?\n\nThanks you!!", "author_fullname": "t2_b1on3h09", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice needed for archive - scanning articles for website p", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y87v0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696280348.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I need advice on a major project. I have to scan 200 articles (approximately 10 pages each) so around 2000 pages. I then need to convert the scanned articles into a word document or some other digital text format. The reason for this is that I want to upload the text from scanned articles on a website. So three steps:&lt;/p&gt;\n\n&lt;p&gt;1) Scan a hard copy of an article\n2) Convert the scan to a digital text file of some sort\n3) Upload the digital text to a website&lt;/p&gt;\n\n&lt;p&gt;A few questions:&lt;/p&gt;\n\n&lt;p&gt;A) What is the most efficient way to accomplish this? \nB) Is there a program that will do both steps and 1 and 2 simultaneously?\nC) Is there a way to do all of this on my phone with an app?&lt;/p&gt;\n\n&lt;p&gt;Thanks you!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16y87v0", "is_robot_indexable": true, "report_reasons": null, "author": "Fragrant-Cap-4462", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16y87v0/advice_needed_for_archive_scanning_articles_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16y87v0/advice_needed_for_archive_scanning_articles_for/", "subreddit_subscribers": 704513, "created_utc": 1696280348.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "About 6 months ago, I purchased an Orico 3559RU3 [Orico 80TB Enterprise Raid Enclosure](https://www.newegg.com/orico-3559rus3-bk/p/0VN-0003-00023?Item=9SIA1DS0CD0629), and filled it with 3 [Seagate 16TB HDD Enterprise Edition](https://www.amazon.com/gp/product/B07SPFPKF4/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1), and set it up as a RAID 5 with Orico HW RAID Manager.\n\nI pretty much just used it to dump everything from multiple externals, so it's all in once place for storage.  As my computer is running off a 2 TB SSD and watching things off that was easier.  But I'm now going back and trying to organize things, and watch some movies from it, and I can't.  The movies and TV shows buffer every minute or so.  Also, as I'm trying to move files from my C: to the RAID, it's incredibly slow, often getting locked up on a file for minutes at a time (sometimes it's a small file, sometimes it's a big file).  \n\nThis data solution is causing more trouble than benefit, since if I want to watch a movie from the drive, I need to copy it to my C drive, which takes several minutes to watch it.  \n\nMy two questions are:\n\n1) If there maybe something I did wrong that's causing this to run so slowly? I know other people run Plex servers off their RAIDs, and that was the plan, but I definitely can't.\n\n2) If this solution is not going to be able to work for my needs (being able to watch files off of it, whether locally or via Plex), is there a safe and easy way to dismantle 21TB of data on a RAID without having to buy new drives?\n\nThank you in advance.  I used to know a lot about computers, but I've forgotten so much and so much has changed since my last build that I don't have any idea what I'm doing anymore. ", "author_fullname": "t2_7pokn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Slow read and write speeds on my RAID 5. Can't watch videos off of it without lagging", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y4qyy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696272404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;About 6 months ago, I purchased an Orico 3559RU3 &lt;a href=\"https://www.newegg.com/orico-3559rus3-bk/p/0VN-0003-00023?Item=9SIA1DS0CD0629\"&gt;Orico 80TB Enterprise Raid Enclosure&lt;/a&gt;, and filled it with 3 &lt;a href=\"https://www.amazon.com/gp/product/B07SPFPKF4/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;amp;psc=1\"&gt;Seagate 16TB HDD Enterprise Edition&lt;/a&gt;, and set it up as a RAID 5 with Orico HW RAID Manager.&lt;/p&gt;\n\n&lt;p&gt;I pretty much just used it to dump everything from multiple externals, so it&amp;#39;s all in once place for storage.  As my computer is running off a 2 TB SSD and watching things off that was easier.  But I&amp;#39;m now going back and trying to organize things, and watch some movies from it, and I can&amp;#39;t.  The movies and TV shows buffer every minute or so.  Also, as I&amp;#39;m trying to move files from my C: to the RAID, it&amp;#39;s incredibly slow, often getting locked up on a file for minutes at a time (sometimes it&amp;#39;s a small file, sometimes it&amp;#39;s a big file).  &lt;/p&gt;\n\n&lt;p&gt;This data solution is causing more trouble than benefit, since if I want to watch a movie from the drive, I need to copy it to my C drive, which takes several minutes to watch it.  &lt;/p&gt;\n\n&lt;p&gt;My two questions are:&lt;/p&gt;\n\n&lt;p&gt;1) If there maybe something I did wrong that&amp;#39;s causing this to run so slowly? I know other people run Plex servers off their RAIDs, and that was the plan, but I definitely can&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;2) If this solution is not going to be able to work for my needs (being able to watch files off of it, whether locally or via Plex), is there a safe and easy way to dismantle 21TB of data on a RAID without having to buy new drives?&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.  I used to know a lot about computers, but I&amp;#39;ve forgotten so much and so much has changed since my last build that I don&amp;#39;t have any idea what I&amp;#39;m doing anymore. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16y4qyy", "is_robot_indexable": true, "report_reasons": null, "author": "ojuditho", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16y4qyy/slow_read_and_write_speeds_on_my_raid_5_cant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16y4qyy/slow_read_and_write_speeds_on_my_raid_5_cant/", "subreddit_subscribers": 704513, "created_utc": 1696272404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Got 3TBytes worth of movie and music files which I would like to have a copy backed up off site.\n\nNot going to retrieve them unless my local copy totally craps out. Heard of AWS Glaciers but can't for the hell of me figure out what I would be paying with that kind of data. I also cannot figure out using the Amazon calculator. \n\nFor example, let's say I upload 3TB within the period of 1 month. Then I store it for 12 months and eventually I have to restore 1TB in the 13th month. How much would I be paying? \n\nAnyone familiar with this? Or can point me to somewhere easy for a dumbass like me?\n\nThank you.", "author_fullname": "t2_3sz6u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cold Storage - AWS Glacier?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xy70s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696257067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got 3TBytes worth of movie and music files which I would like to have a copy backed up off site.&lt;/p&gt;\n\n&lt;p&gt;Not going to retrieve them unless my local copy totally craps out. Heard of AWS Glaciers but can&amp;#39;t for the hell of me figure out what I would be paying with that kind of data. I also cannot figure out using the Amazon calculator. &lt;/p&gt;\n\n&lt;p&gt;For example, let&amp;#39;s say I upload 3TB within the period of 1 month. Then I store it for 12 months and eventually I have to restore 1TB in the 13th month. How much would I be paying? &lt;/p&gt;\n\n&lt;p&gt;Anyone familiar with this? Or can point me to somewhere easy for a dumbass like me?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16xy70s", "is_robot_indexable": true, "report_reasons": null, "author": "butterninja", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16xy70s/cold_storage_aws_glacier/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16xy70s/cold_storage_aws_glacier/", "subreddit_subscribers": 704513, "created_utc": 1696257067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 1TB Sandisk Ultra 3D SSD (SDSSDH3) connected by SATA to my desktop rig, which I use in addition to my WD SN850 boot drive. It's used for storage (games/media) and is typically around 90% filled. \nIt seems to work normally when writing files to it, but If I try to transfer files off the Sandisk to another drive, it fluctuates between 1-5mb/sec the whole way through. Running CrystalDiskMark seems to show a similar problem albeit not as severe, I was getting around ~100mb/sec read and 550mb/sec write in there. Sometimes accessing files on the drive and navigating though folders would be really slow and other times perfectly fine.\n\nAfter backing up and removing it from my system I tried the drive  in a USB 3.0 enclosure, initially had the exact same problem, but after quick formatting (**which takes 5-10 mins, whereas normally it's 10-15 seconds)** the read performance is back to where it should be. Even after transferring the same files back it and doing the same backup procedure as previously, performance is normal\n\nSo I don't really know what's up with it, I thought maybe it's a TRIM problem but I verified that it's enabled\n\nIt's still currently in the USB enclosure, but here's SMART data and health in Crystaldiskinfo \n\nhttps://imgur.com/a/Q76LDJk", "author_fullname": "t2_gjbb3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Strange behaviour from Sandisk SSD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16ymtbu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696324109.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696323910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 1TB Sandisk Ultra 3D SSD (SDSSDH3) connected by SATA to my desktop rig, which I use in addition to my WD SN850 boot drive. It&amp;#39;s used for storage (games/media) and is typically around 90% filled. \nIt seems to work normally when writing files to it, but If I try to transfer files off the Sandisk to another drive, it fluctuates between 1-5mb/sec the whole way through. Running CrystalDiskMark seems to show a similar problem albeit not as severe, I was getting around ~100mb/sec read and 550mb/sec write in there. Sometimes accessing files on the drive and navigating though folders would be really slow and other times perfectly fine.&lt;/p&gt;\n\n&lt;p&gt;After backing up and removing it from my system I tried the drive  in a USB 3.0 enclosure, initially had the exact same problem, but after quick formatting (&lt;strong&gt;which takes 5-10 mins, whereas normally it&amp;#39;s 10-15 seconds)&lt;/strong&gt; the read performance is back to where it should be. Even after transferring the same files back it and doing the same backup procedure as previously, performance is normal&lt;/p&gt;\n\n&lt;p&gt;So I don&amp;#39;t really know what&amp;#39;s up with it, I thought maybe it&amp;#39;s a TRIM problem but I verified that it&amp;#39;s enabled&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s still currently in the USB enclosure, but here&amp;#39;s SMART data and health in Crystaldiskinfo &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/a/Q76LDJk\"&gt;https://imgur.com/a/Q76LDJk&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fE8Ur5GFqw7fFKpjvUt30Cd_kTWdqW_BeCTvdOgTdr0.jpg?auto=webp&amp;s=175e1f727a36a7828b3f8b7af317307f152f21d4", "width": 1010, "height": 1019}, "resolutions": [{"url": "https://external-preview.redd.it/fE8Ur5GFqw7fFKpjvUt30Cd_kTWdqW_BeCTvdOgTdr0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce81026c729f61bec92bf8d57ca954736c27723f", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/fE8Ur5GFqw7fFKpjvUt30Cd_kTWdqW_BeCTvdOgTdr0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=86095a71ea0525de91e430219a086ed9030ed811", "width": 216, "height": 217}, {"url": "https://external-preview.redd.it/fE8Ur5GFqw7fFKpjvUt30Cd_kTWdqW_BeCTvdOgTdr0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6aa2367b76740fa17b89fce98b8b7cafe411c29a", "width": 320, "height": 322}, {"url": "https://external-preview.redd.it/fE8Ur5GFqw7fFKpjvUt30Cd_kTWdqW_BeCTvdOgTdr0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4a4c2678f9f6dbf6c3511bf1a5272f25bb9c1512", "width": 640, "height": 645}, {"url": "https://external-preview.redd.it/fE8Ur5GFqw7fFKpjvUt30Cd_kTWdqW_BeCTvdOgTdr0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=efa9fc576fe721fdaec68ccf00c02eb0f3871869", "width": 960, "height": 968}], "variants": {}, "id": "J_gkl9DGBR5XOq9cDJ2RjQ7rabKW-4Hj9Uv7440dQfc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16ymtbu", "is_robot_indexable": true, "report_reasons": null, "author": "x3nics", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ymtbu/strange_behaviour_from_sandisk_ssd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16ymtbu/strange_behaviour_from_sandisk_ssd/", "subreddit_subscribers": 704513, "created_utc": 1696323910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A few years back SI opened what they called \"[SI VAULT](https://vault.si.com/vault/archives)\", pretty much a database of the magazine issues from way back in the day that includes bot the original scans and a text-based transcription of all of the articles.\n\nI have always felt this anxiety of building an offline archive by crawling/downloading all of the content (which is available for free on the web) to keep it safe in my HDD, but never really got the time to do it somehow automatically (it'd just be impossible to do it manually, tons of content out there).\n\nHas anyone here explored that possibility? Maybe coded something to fetch the texts/scans in an easy way? I'd love to discuss this with you!", "author_fullname": "t2_g6pn4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help to get the full Sports Illustrated Vault archive? Texts and images available online, want to download it!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yjw3w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696312320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A few years back SI opened what they called &amp;quot;&lt;a href=\"https://vault.si.com/vault/archives\"&gt;SI VAULT&lt;/a&gt;&amp;quot;, pretty much a database of the magazine issues from way back in the day that includes bot the original scans and a text-based transcription of all of the articles.&lt;/p&gt;\n\n&lt;p&gt;I have always felt this anxiety of building an offline archive by crawling/downloading all of the content (which is available for free on the web) to keep it safe in my HDD, but never really got the time to do it somehow automatically (it&amp;#39;d just be impossible to do it manually, tons of content out there).&lt;/p&gt;\n\n&lt;p&gt;Has anyone here explored that possibility? Maybe coded something to fetch the texts/scans in an easy way? I&amp;#39;d love to discuss this with you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16yjw3w", "is_robot_indexable": true, "report_reasons": null, "author": "Chapulana", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16yjw3w/help_to_get_the_full_sports_illustrated_vault/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16yjw3w/help_to_get_the_full_sports_illustrated_vault/", "subreddit_subscribers": 704513, "created_utc": 1696312320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have some .mkv videos and want to reduce the space they occupy, so i want to convert it to MP4, but don\u00b4t want to lose any audio quality. Is there a way to do it?", "author_fullname": "t2_1xrwfw4m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I convert MKV to MP4 without losing audio quality?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y7czw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696278385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some .mkv videos and want to reduce the space they occupy, so i want to convert it to MP4, but don\u00b4t want to lose any audio quality. Is there a way to do it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16y7czw", "is_robot_indexable": true, "report_reasons": null, "author": "SushiVoador", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16y7czw/can_i_convert_mkv_to_mp4_without_losing_audio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16y7czw/can_i_convert_mkv_to_mp4_without_losing_audio/", "subreddit_subscribers": 704513, "created_utc": 1696278385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How do you lot archive site like this? \n\n[https://segaretro.org/Sega\\_Power#Back\\_issues](https://segaretro.org/Sega_Power#Back_issues)\n\nI'm trying to get all the issues instead of having to click each one individually.\n\nSeem to be here but always in different location\n\n[https://retrocdn.net/images/b/b8/SegaPower\\_UK\\_15.pdf](https://retrocdn.net/images/b/b8/SegaPower_UK_15.pdf)\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_3xqpnc72", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archive a site", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xx8ra", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696254814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you lot archive site like this? &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://segaretro.org/Sega_Power#Back_issues\"&gt;https://segaretro.org/Sega_Power#Back_issues&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to get all the issues instead of having to click each one individually.&lt;/p&gt;\n\n&lt;p&gt;Seem to be here but always in different location&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://retrocdn.net/images/b/b8/SegaPower_UK_15.pdf\"&gt;https://retrocdn.net/images/b/b8/SegaPower_UK_15.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rGUfvT12rAA6iIndmcybq0S6vfRvTg2bkGyJLFi5CpE.jpg?auto=webp&amp;s=9ce538e01d2fc9574c2bc79c2027049730772c96", "width": 271, "height": 60}, "resolutions": [{"url": "https://external-preview.redd.it/rGUfvT12rAA6iIndmcybq0S6vfRvTg2bkGyJLFi5CpE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=44006b33cb1dc9dc31eea5602262715643313a55", "width": 108, "height": 23}, {"url": "https://external-preview.redd.it/rGUfvT12rAA6iIndmcybq0S6vfRvTg2bkGyJLFi5CpE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3d286536a405b00010e62e055f10ff207a2da6cc", "width": 216, "height": 47}], "variants": {}, "id": "CAODis5qgT7a7F-oJJ-_28iL3rHdYUiWOL2UosmYgOA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16xx8ra", "is_robot_indexable": true, "report_reasons": null, "author": "steviefaux", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16xx8ra/archive_a_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16xx8ra/archive_a_site/", "subreddit_subscribers": 704513, "created_utc": 1696254814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know the easy answer... a phone. but my mom has 70 GB of photos and video on her phone and I'm helping her put it on a USB. thing is I know she going want to go through them all again and better organize it but she not tech savvy\n\nI'm hoping there a device that the sole purpose is to hold and view photos so it's easier for her. I also just think it would be a nice gift but I can't really find anything like that.", "author_fullname": "t2_10qqu2nl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a device that can store, view and organize photos/video", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yc0lx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696289071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know the easy answer... a phone. but my mom has 70 GB of photos and video on her phone and I&amp;#39;m helping her put it on a USB. thing is I know she going want to go through them all again and better organize it but she not tech savvy&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m hoping there a device that the sole purpose is to hold and view photos so it&amp;#39;s easier for her. I also just think it would be a nice gift but I can&amp;#39;t really find anything like that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16yc0lx", "is_robot_indexable": true, "report_reasons": null, "author": "OTHREDARIS", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16yc0lx/is_there_a_device_that_can_store_view_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16yc0lx/is_there_a_device_that_can_store_view_and/", "subreddit_subscribers": 704513, "created_utc": 1696289071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hope the mods are ok with this, as it should be of interest to a sub-set of data hoarders..\n\nAnnoucing the Beta 2.0.0 release of the Black DVD Archiver - [https://github.com/David-Worboys/Black-DVD-Archiver](https://github.com/David-Worboys/Black-DVD-Archiver)\n\n&amp;#x200B;\n\nI guess it is good enough now for others to kick the tyres and give it a go... but it will have bugs at this early stage\n\n&amp;#x200B;\n\n**What is the Black DVD Archiver?**\n\n&amp;#x200B;\n\nThe Black DVD Archiver is an open source Linux application that will place user selected video files on a DVD and the source files in an archive location specified by the user.\n\nThe intended use case is for those that are interested in getting Video 8, VHS, Betamax, DV and Digital 8 sourced video files onto DVD and archiving the source video files \n\nRefer to [README.md](https://README.md) for archiving discussion (including disk longevity), current feature set and usage ( [https://github.com/David-Worboys/Black-DVD-Archiver/blob/main/README.md](https://github.com/David-Worboys/Black-DVD-Archiver/blob/main/README.md) )\n\n&amp;#x200B;\n\n**Features**\n\n\\- Selection Of Input Files In A Variety Of Container Formats \u2014 As Long As They Conform To PAL/NTSC standards\n\n\\- A Simple Video Editor\n\n\\- Limited Video Filters With Fixed Settings\n\n\\- DVDs Have A Simplified Menu Structure\n\n\\- Saves The Input/Output Files Into A User-Selected Archive Folder Structure.\n\n\\- This Can Be Placed On A NAS And Accessed By A Media Player.\n\n\\- An ISO image of the DVD is produced so that DVD burning software can produce the physical DVD.\n\n\\- The archived video files are stored in their original format and are split to fit into 25 GB or 4 GB folders, so that they can be burnt off to optical disk for backup.\n\n\\- Check sums are calculated for source video files and are stored with them to verify the integrity of the source video files at a later date\n\n&amp;#x200B;\n\nThe Black DVD Archiver - \u03b2eta 2.0 Release Notes\n\n&amp;#x200B;\n\nThis is the \u03b22.0.0 Release developed on Linux Mint and tested on a minimal Mx Linux install\n\n&amp;#x200B;\n\n**New Features**\n\n&amp;#x200B;\n\nThe process of making the DVD iso image and associated files is now performed as a background task. This allows the user to continue working whilst \"Make DVD\" tasks are running.\n\nVideo source files are now cut as simultaneous background tasks to speed cuts on large files although the user still needs to wait for the cuts to finish.\n\nVideo source files are now archived in Disk\\_xx sub-folders and the user can select 4 GB DVD or 25 GB Blu-ray folder sizes. If a video source file will not fit in a Disk\\_xx sub-folder it will be split into parts that will fit. Note at this time these sub-folders are not optimally packed.\n\nVideo source files are now archived with a corresponding sha245 checksum file to allow for future validation of video source file data integrity\n\nDVD menu page change icons can now be user selected.\n\nBasic language translation functionality has been added. This allows a user to select a country language and enter translated application phrases. These translations can be imported and exported for sharing with other users.\n\nStability enhancements\n\nBug fixes\n\n&amp;#x200B;\n\n**Notes**\n\n&amp;#x200B;\n\nIt is expected to have bugs at this point, some could even be serious and crash the app!\n\nIt is expected to do the basic job it is designed and tested to do\n\nWhen reporting bugs, state Linux version, distro and then clearly state the problem and how to reproduce\n\nAll feedback and bug reports are welcome. These will be addressed as quickly as my time allows\n\nTesting has not covered NTSC recordings as mine are only PAL\n\nTesting has not covered 16:9 aspect ratios as my test set is 4:3\n\nI will stress again that test coverage has been light but it works with my test files - avi wrapped DV compressed.\n\n&amp;#x200B;", "author_fullname": "t2_by89ccv1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Announcing the Beta 2.0.0 release of the Black DVD Archiver", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ybhvg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696287755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hope the mods are ok with this, as it should be of interest to a sub-set of data hoarders..&lt;/p&gt;\n\n&lt;p&gt;Annoucing the Beta 2.0.0 release of the Black DVD Archiver - &lt;a href=\"https://github.com/David-Worboys/Black-DVD-Archiver\"&gt;https://github.com/David-Worboys/Black-DVD-Archiver&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I guess it is good enough now for others to kick the tyres and give it a go... but it will have bugs at this early stage&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What is the Black DVD Archiver?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The Black DVD Archiver is an open source Linux application that will place user selected video files on a DVD and the source files in an archive location specified by the user.&lt;/p&gt;\n\n&lt;p&gt;The intended use case is for those that are interested in getting Video 8, VHS, Betamax, DV and Digital 8 sourced video files onto DVD and archiving the source video files &lt;/p&gt;\n\n&lt;p&gt;Refer to &lt;a href=\"https://README.md\"&gt;README.md&lt;/a&gt; for archiving discussion (including disk longevity), current feature set and usage ( &lt;a href=\"https://github.com/David-Worboys/Black-DVD-Archiver/blob/main/README.md\"&gt;https://github.com/David-Worboys/Black-DVD-Archiver/blob/main/README.md&lt;/a&gt; )&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Features&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- Selection Of Input Files In A Variety Of Container Formats \u2014 As Long As They Conform To PAL/NTSC standards&lt;/p&gt;\n\n&lt;p&gt;- A Simple Video Editor&lt;/p&gt;\n\n&lt;p&gt;- Limited Video Filters With Fixed Settings&lt;/p&gt;\n\n&lt;p&gt;- DVDs Have A Simplified Menu Structure&lt;/p&gt;\n\n&lt;p&gt;- Saves The Input/Output Files Into A User-Selected Archive Folder Structure.&lt;/p&gt;\n\n&lt;p&gt;- This Can Be Placed On A NAS And Accessed By A Media Player.&lt;/p&gt;\n\n&lt;p&gt;- An ISO image of the DVD is produced so that DVD burning software can produce the physical DVD.&lt;/p&gt;\n\n&lt;p&gt;- The archived video files are stored in their original format and are split to fit into 25 GB or 4 GB folders, so that they can be burnt off to optical disk for backup.&lt;/p&gt;\n\n&lt;p&gt;- Check sums are calculated for source video files and are stored with them to verify the integrity of the source video files at a later date&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The Black DVD Archiver - \u03b2eta 2.0 Release Notes&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This is the \u03b22.0.0 Release developed on Linux Mint and tested on a minimal Mx Linux install&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;New Features&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;The process of making the DVD iso image and associated files is now performed as a background task. This allows the user to continue working whilst &amp;quot;Make DVD&amp;quot; tasks are running.&lt;/p&gt;\n\n&lt;p&gt;Video source files are now cut as simultaneous background tasks to speed cuts on large files although the user still needs to wait for the cuts to finish.&lt;/p&gt;\n\n&lt;p&gt;Video source files are now archived in Disk_xx sub-folders and the user can select 4 GB DVD or 25 GB Blu-ray folder sizes. If a video source file will not fit in a Disk_xx sub-folder it will be split into parts that will fit. Note at this time these sub-folders are not optimally packed.&lt;/p&gt;\n\n&lt;p&gt;Video source files are now archived with a corresponding sha245 checksum file to allow for future validation of video source file data integrity&lt;/p&gt;\n\n&lt;p&gt;DVD menu page change icons can now be user selected.&lt;/p&gt;\n\n&lt;p&gt;Basic language translation functionality has been added. This allows a user to select a country language and enter translated application phrases. These translations can be imported and exported for sharing with other users.&lt;/p&gt;\n\n&lt;p&gt;Stability enhancements&lt;/p&gt;\n\n&lt;p&gt;Bug fixes&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It is expected to have bugs at this point, some could even be serious and crash the app!&lt;/p&gt;\n\n&lt;p&gt;It is expected to do the basic job it is designed and tested to do&lt;/p&gt;\n\n&lt;p&gt;When reporting bugs, state Linux version, distro and then clearly state the problem and how to reproduce&lt;/p&gt;\n\n&lt;p&gt;All feedback and bug reports are welcome. These will be addressed as quickly as my time allows&lt;/p&gt;\n\n&lt;p&gt;Testing has not covered NTSC recordings as mine are only PAL&lt;/p&gt;\n\n&lt;p&gt;Testing has not covered 16:9 aspect ratios as my test set is 4:3&lt;/p&gt;\n\n&lt;p&gt;I will stress again that test coverage has been light but it works with my test files - avi wrapped DV compressed.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GPGOZyDHdoAAJMmtY3ZK3_ofqtkIfpVB5xAudAQBh9I.jpg?auto=webp&amp;s=4ed18dc60f652b56ced727f4dd3a69823cbc9c1b", "width": 1024, "height": 620}, "resolutions": [{"url": "https://external-preview.redd.it/GPGOZyDHdoAAJMmtY3ZK3_ofqtkIfpVB5xAudAQBh9I.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9f5e6369bc3af0da2ed52d61c31a76eac9effe05", "width": 108, "height": 65}, {"url": "https://external-preview.redd.it/GPGOZyDHdoAAJMmtY3ZK3_ofqtkIfpVB5xAudAQBh9I.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0bf5b11bb80709472dea25d96d04561922498392", "width": 216, "height": 130}, {"url": "https://external-preview.redd.it/GPGOZyDHdoAAJMmtY3ZK3_ofqtkIfpVB5xAudAQBh9I.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e686b2eb404dd536d0a3e09f0c517f9e402f6f05", "width": 320, "height": 193}, {"url": "https://external-preview.redd.it/GPGOZyDHdoAAJMmtY3ZK3_ofqtkIfpVB5xAudAQBh9I.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=36c75c8671bec7f468a8edf471af67467c8d4004", "width": 640, "height": 387}, {"url": "https://external-preview.redd.it/GPGOZyDHdoAAJMmtY3ZK3_ofqtkIfpVB5xAudAQBh9I.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=fbca6f614de61e8122d3f9cbf9a2ee1d9790a2c1", "width": 960, "height": 581}], "variants": {}, "id": "1abO3eZAc0tkKBIEPWYK7LbshfABTfKICcVgmZjfiJk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16ybhvg", "is_robot_indexable": true, "report_reasons": null, "author": "Black-DVD-Archiver", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ybhvg/announcing_the_beta_200_release_of_the_black_dvd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16ybhvg/announcing_the_beta_200_release_of_the_black_dvd/", "subreddit_subscribers": 704513, "created_utc": 1696287755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone\n\nI have a relatively powerful mini PC, an intel Nuc 12 pro i7, and want to set up a NAS server. When I looked online nas servers seem to be expensive ranging from 400 to 500 which is kind of out of my budget. I also saw you could build an inexpensive PC but I don't really want to be new parts when I already have a mini PC and a desktop PC. So is there any good thunderbolt 3/4 4 expansion bays?\n\nthx", "author_fullname": "t2_5wfo3a3oy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Expansion bay that supports Thunderbolt 4", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y9kwq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696283298.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone&lt;/p&gt;\n\n&lt;p&gt;I have a relatively powerful mini PC, an intel Nuc 12 pro i7, and want to set up a NAS server. When I looked online nas servers seem to be expensive ranging from 400 to 500 which is kind of out of my budget. I also saw you could build an inexpensive PC but I don&amp;#39;t really want to be new parts when I already have a mini PC and a desktop PC. So is there any good thunderbolt 3/4 4 expansion bays?&lt;/p&gt;\n\n&lt;p&gt;thx&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16y9kwq", "is_robot_indexable": true, "report_reasons": null, "author": "NoobMaster2787", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16y9kwq/best_expansion_bay_that_supports_thunderbolt_4/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16y9kwq/best_expansion_bay_that_supports_thunderbolt_4/", "subreddit_subscribers": 704513, "created_utc": 1696283298.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a way to make it have a better more clean UI like DVDFab and others? \n\nHow can I have it so the episodes I rip are titled as the episode number or anything except for title_1 or whatever it is?\n\nHow can I remux it to MP4? I'm on a Mac if that makes any difference.\n\nThank you so much!", "author_fullname": "t2_k457l2o98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MakeMKV questions.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y2qpq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.46, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696267814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a way to make it have a better more clean UI like DVDFab and others? &lt;/p&gt;\n\n&lt;p&gt;How can I have it so the episodes I rip are titled as the episode number or anything except for title_1 or whatever it is?&lt;/p&gt;\n\n&lt;p&gt;How can I remux it to MP4? I&amp;#39;m on a Mac if that makes any difference.&lt;/p&gt;\n\n&lt;p&gt;Thank you so much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16y2qpq", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyMyOpinions", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16y2qpq/makemkv_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16y2qpq/makemkv_questions/", "subreddit_subscribers": 704513, "created_utc": 1696267814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was looking into options for a secondary backup since I currently have all my stuff split into several SSDs/HDDs and it's a fucking mess -- also very far from following safe backup practices such as the 3-2-1 rule.\n\nSo I did some research on cloud storage and none seemed to offer a reliable source to retrieve my data if needed, which is something I would like to do since I would rather keep all my data together on the cloud (for accessibility) rather than on a huge SSD which I'm going to have to carry around (with all my stuff on it), plug in and every few years transfer onto a new one.\n\nThis sucks. Not as much as Amazon S3 though. First of all I can't find an official source that clearly lists all the fees involved. I just have to do research outside Amazon docs and rely on some dude's blog 'cause on their pricing page I only see storage fees, which is not the biggest problem as I understand. Basically this would be okay if I only needed my files back at the end of the world.\n\nThis would not let me sleep until I stumbled into this almost forgotten memory lying in my browser's tabs. It was [Storj](https://storj.io).\n\nStorj not only solves the lock-in issue which is a problem whenever you want your files back with **every** other cloud hosting provider I've found, but it's also transparent **clear**. This instantly seemed like a service I'd trust with actually using to host my data even if I needed to **access** it, at times. (Also, you only pay for what you use so you don't need a 16TB plan if you have like 8TB + 1 byte of data).\n\nSo I wanted to know if anyone here has had any experience with it or other services which provide something like that, or if anyone could perhaps help me change my mind about S3 or similar, 'cause that would actually be cheaper for very long-term (as in I hope I never need it again) storage: **$0.99/TB** (S3 Deep Archive) vs **$4/TB** (Storj). I just really feel like I won't like it, but I'd love to be corrected.\n\nThank you.", "author_fullname": "t2_l80muynz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Very long-term remote storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xtxbc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696245447.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was looking into options for a secondary backup since I currently have all my stuff split into several SSDs/HDDs and it&amp;#39;s a fucking mess -- also very far from following safe backup practices such as the 3-2-1 rule.&lt;/p&gt;\n\n&lt;p&gt;So I did some research on cloud storage and none seemed to offer a reliable source to retrieve my data if needed, which is something I would like to do since I would rather keep all my data together on the cloud (for accessibility) rather than on a huge SSD which I&amp;#39;m going to have to carry around (with all my stuff on it), plug in and every few years transfer onto a new one.&lt;/p&gt;\n\n&lt;p&gt;This sucks. Not as much as Amazon S3 though. First of all I can&amp;#39;t find an official source that clearly lists all the fees involved. I just have to do research outside Amazon docs and rely on some dude&amp;#39;s blog &amp;#39;cause on their pricing page I only see storage fees, which is not the biggest problem as I understand. Basically this would be okay if I only needed my files back at the end of the world.&lt;/p&gt;\n\n&lt;p&gt;This would not let me sleep until I stumbled into this almost forgotten memory lying in my browser&amp;#39;s tabs. It was &lt;a href=\"https://storj.io\"&gt;Storj&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Storj not only solves the lock-in issue which is a problem whenever you want your files back with &lt;strong&gt;every&lt;/strong&gt; other cloud hosting provider I&amp;#39;ve found, but it&amp;#39;s also transparent &lt;strong&gt;clear&lt;/strong&gt;. This instantly seemed like a service I&amp;#39;d trust with actually using to host my data even if I needed to &lt;strong&gt;access&lt;/strong&gt; it, at times. (Also, you only pay for what you use so you don&amp;#39;t need a 16TB plan if you have like 8TB + 1 byte of data).&lt;/p&gt;\n\n&lt;p&gt;So I wanted to know if anyone here has had any experience with it or other services which provide something like that, or if anyone could perhaps help me change my mind about S3 or similar, &amp;#39;cause that would actually be cheaper for very long-term (as in I hope I never need it again) storage: &lt;strong&gt;$0.99/TB&lt;/strong&gt; (S3 Deep Archive) vs &lt;strong&gt;$4/TB&lt;/strong&gt; (Storj). I just really feel like I won&amp;#39;t like it, but I&amp;#39;d love to be corrected.&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/YFfSEB0H8kk7fQlEPJiav-8Iqpccpv8qIpIawFjwUBw.jpg?auto=webp&amp;s=2f5e4eb20565ed624ec4ae5c7323bae03d28254b", "width": 900, "height": 506}, "resolutions": [{"url": "https://external-preview.redd.it/YFfSEB0H8kk7fQlEPJiav-8Iqpccpv8qIpIawFjwUBw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=df85547a4e4103ba9052e37d416051e09c38f711", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/YFfSEB0H8kk7fQlEPJiav-8Iqpccpv8qIpIawFjwUBw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=844025b5349e04865313b12503ef419c1ac17a48", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/YFfSEB0H8kk7fQlEPJiav-8Iqpccpv8qIpIawFjwUBw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8bff46910910c038019a3bb6fb4f16aac70cb47c", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/YFfSEB0H8kk7fQlEPJiav-8Iqpccpv8qIpIawFjwUBw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=573b6c52228089a0c8f990b017984d23df93d835", "width": 640, "height": 359}], "variants": {}, "id": "jguIFMc2oFBjJ25TW4_LymL5ERdzGEeqAC79GFfIURM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16xtxbc", "is_robot_indexable": true, "report_reasons": null, "author": "cherrynoize", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16xtxbc/very_longterm_remote_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16xtxbc/very_longterm_remote_storage/", "subreddit_subscribers": 704513, "created_utc": 1696245447.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently opened a huge csv file and put it through an app to have the data in a chart table and was wondering if there is a way I can search it? like put certain keywords to slim down results so I can find what I'm looking for?", "author_fullname": "t2_voj1eunx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way for me to slim down results in a csv data table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yjdgn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696310391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently opened a huge csv file and put it through an app to have the data in a chart table and was wondering if there is a way I can search it? like put certain keywords to slim down results so I can find what I&amp;#39;m looking for?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16yjdgn", "is_robot_indexable": true, "report_reasons": null, "author": "tellmewhy24", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16yjdgn/is_there_a_way_for_me_to_slim_down_results_in_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16yjdgn/is_there_a_way_for_me_to_slim_down_results_in_a/", "subreddit_subscribers": 704513, "created_utc": 1696310391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Not sure where I'd even ask this but this subreddit seems appropriate enough.\n\nDoes anyone else have issues with Mega video being incredible painful to load and download? I've always chalked this down as being an ISP issue but it's bugging me enough that I want to know for sure so I can know if I have any chance of fixing it.\n\nWhen I try to load a video, it'll sit there for a few seconds up to a couple minutes before starting. After that initial load, it's more or less fine. When I scrub it'll sometimes need me to pause and resume it, or shift the playback head somewhere else , but other than that, it loads fine. \n\nSimilarly, when I download a file it'll have errors throughout the entire download. Between the errors it'll download for a bit before stalling again.\n\nMy intuition tells me that it's either an ISP issue or just a lack of bandwidth between me (Australia) and wherever the files are being hosted, but I'd love to be wrong. It's been an ongoing issue for me for years", "author_fullname": "t2_gfntt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mega.co.nz being slow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yc18i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696289114.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure where I&amp;#39;d even ask this but this subreddit seems appropriate enough.&lt;/p&gt;\n\n&lt;p&gt;Does anyone else have issues with Mega video being incredible painful to load and download? I&amp;#39;ve always chalked this down as being an ISP issue but it&amp;#39;s bugging me enough that I want to know for sure so I can know if I have any chance of fixing it.&lt;/p&gt;\n\n&lt;p&gt;When I try to load a video, it&amp;#39;ll sit there for a few seconds up to a couple minutes before starting. After that initial load, it&amp;#39;s more or less fine. When I scrub it&amp;#39;ll sometimes need me to pause and resume it, or shift the playback head somewhere else , but other than that, it loads fine. &lt;/p&gt;\n\n&lt;p&gt;Similarly, when I download a file it&amp;#39;ll have errors throughout the entire download. Between the errors it&amp;#39;ll download for a bit before stalling again.&lt;/p&gt;\n\n&lt;p&gt;My intuition tells me that it&amp;#39;s either an ISP issue or just a lack of bandwidth between me (Australia) and wherever the files are being hosted, but I&amp;#39;d love to be wrong. It&amp;#39;s been an ongoing issue for me for years&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16yc18i", "is_robot_indexable": true, "report_reasons": null, "author": "BreadBreadington", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16yc18i/megaconz_being_slow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16yc18i/megaconz_being_slow/", "subreddit_subscribers": 704513, "created_utc": 1696289114.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "&amp;#x200B;\n\n[in case you don't know, its a full badblocks pass \\(on an HDD\\)](https://preview.redd.it/2g2r8hlnvurb1.png?width=1591&amp;format=png&amp;auto=webp&amp;s=4412bc1e92d055778d4b55a2fa99e990a54c5fe1)\n\nEvery time i get new HDDs for my backup TrueNas system i find it interesting to see what it means to read/write data on a physical platter where the read/write head distance isn't equal for every sector.\n\nAdditionally i use it as a form of stresstest, bc some time ago (IDE era) a new replacement disk died on a resync.\n\nSo i hope some one else does like this chart, as i can't explain much else... \n\nWYSIWYG  ;)\n\n\\---\n\nI won't argue why i do a badblocks even if it takes \\~4 days for a 18 TB SATA drive!   \nIt is just my believe in better safe than sorry while my life can handle 4 days of storage stagnation.   \n(Additional i believe in one should not argue a believe. Debate or discuss ofc, but not argue. It's called believe for a reason!)\n\n\\---\n\nI don't know if this belongs on a free post friday, if so i'm sorry and please delete this one (kind sir mrs/mr. mod)\n\n\\---\n\n\\#english second language  \ncould't find a fool prove hashtag, so \\[ASCII\\] 70 85   X(Twitter) hashtags with a space are a thing (now)!  \n(brainfart: the function call X(Twitter) will throw an error \ud83e\udd14)", "author_fullname": "t2_nlv70", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "IYKYK - If You Know You Know - (hard disk drive speeds)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 16, "top_awarded_type": null, "hide_score": false, "media_metadata": {"2g2r8hlnvurb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 12, "x": 108, "u": "https://preview.redd.it/2g2r8hlnvurb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=3377e5ac44461514f6c02548c00f423c7d841fad"}, {"y": 25, "x": 216, "u": "https://preview.redd.it/2g2r8hlnvurb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6476787e27a89cbf735e6ad678b3acf3b9f2a649"}, {"y": 37, "x": 320, "u": "https://preview.redd.it/2g2r8hlnvurb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9869ea1d1c36f3290d43c16e8c3d884571d36e8f"}, {"y": 75, "x": 640, "u": "https://preview.redd.it/2g2r8hlnvurb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=28130087b2ea5f28176518827b758a3f0e61cb09"}, {"y": 112, "x": 960, "u": "https://preview.redd.it/2g2r8hlnvurb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ae76f6eb08085fea546ff362bb5e833bc0e9a655"}, {"y": 126, "x": 1080, "u": "https://preview.redd.it/2g2r8hlnvurb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=faca28a6b943f4dfa584c3992fc8b0d335ae4e77"}], "s": {"y": 187, "x": 1591, "u": "https://preview.redd.it/2g2r8hlnvurb1.png?width=1591&amp;format=png&amp;auto=webp&amp;s=4412bc1e92d055778d4b55a2fa99e990a54c5fe1"}, "id": "2g2r8hlnvurb1"}}, "name": "t3_16ya62r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "mildlyinteresting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/H3E0RmnFPwB_GgMb7CtQwFS76wLKuN9aFyxKI6g0u3E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696284686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/2g2r8hlnvurb1.png?width=1591&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4412bc1e92d055778d4b55a2fa99e990a54c5fe1\"&gt;in case you don&amp;#39;t know, its a full badblocks pass (on an HDD)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Every time i get new HDDs for my backup TrueNas system i find it interesting to see what it means to read/write data on a physical platter where the read/write head distance isn&amp;#39;t equal for every sector.&lt;/p&gt;\n\n&lt;p&gt;Additionally i use it as a form of stresstest, bc some time ago (IDE era) a new replacement disk died on a resync.&lt;/p&gt;\n\n&lt;p&gt;So i hope some one else does like this chart, as i can&amp;#39;t explain much else... &lt;/p&gt;\n\n&lt;p&gt;WYSIWYG  ;)&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;I won&amp;#39;t argue why i do a badblocks even if it takes ~4 days for a 18 TB SATA drive!&lt;br/&gt;\nIt is just my believe in better safe than sorry while my life can handle 4 days of storage stagnation.&lt;br/&gt;\n(Additional i believe in one should not argue a believe. Debate or discuss ofc, but not argue. It&amp;#39;s called believe for a reason!)&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know if this belongs on a free post friday, if so i&amp;#39;m sorry and please delete this one (kind sir mrs/mr. mod)&lt;/p&gt;\n\n&lt;p&gt;---&lt;/p&gt;\n\n&lt;p&gt;#english second language&lt;br/&gt;\ncould&amp;#39;t find a fool prove hashtag, so [ASCII] 70 85   X(Twitter) hashtags with a space are a thing (now)!&lt;br/&gt;\n(brainfart: the function call X(Twitter) will throw an error \ud83e\udd14)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "a9b81a26-bb69-11eb-8bca-0ea4446fb5bf", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "16ya62r", "is_robot_indexable": true, "report_reasons": null, "author": "Koobey", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16ya62r/iykyk_if_you_know_you_know_hard_disk_drive_speeds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16ya62r/iykyk_if_you_know_you_know_hard_disk_drive_speeds/", "subreddit_subscribers": 704513, "created_utc": 1696284686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Question  \nthis mega link contains many folders which are crucial as oxygen to me, im afraid one day the link gets corrupted or so, so i want to make a back up of it, but as far as i know that mega has a 5gb download limit per day, so whats your say?", "author_fullname": "t2_5l3isyb1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how can i make a back up of a 1TB mega link to an external hard drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y3bo4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696269156.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Question&lt;br/&gt;\nthis mega link contains many folders which are crucial as oxygen to me, im afraid one day the link gets corrupted or so, so i want to make a back up of it, but as far as i know that mega has a 5gb download limit per day, so whats your say?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "16y3bo4", "is_robot_indexable": true, "report_reasons": null, "author": "doepual", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/16y3bo4/how_can_i_make_a_back_up_of_a_1tb_mega_link_to_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/16y3bo4/how_can_i_make_a_back_up_of_a_1tb_mega_link_to_an/", "subreddit_subscribers": 704513, "created_utc": 1696269156.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}