{"kind": "Listing", "data": {"after": "t3_16y5mcn", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So like the title says I started a new job today. Figure out why this report written in R broke 2 months ago. I open up a single file with 6952 lines in it. All that's left of me is a 2 page word dock explaining it the main file that call 3 other files, each with 2-3k lines of R code, to create a single 7 page PDF report from a single data source.\n\nWHAT THE ABSOLUTE HELL AM I LOOKING AT LOL. I don't know R, but it's similar enough to python that I can follow along to get the gist of what it's doing. BUT STILL! WHO NEED 10K+ LINES OF CODE FOR THIS?\n\nShould I tell them it's all bunk and make my case to start from scratch, or just buckle down and learn myself some R to make it work?\n\nEdit:\nSo after further investigation there are 3 major issues.\n\n1: He would comment out old code and leave it in the file. Shout out @Strider_A for the git joke. After deleting all the obvious old code I have taken it down to a total of 5,679 lines of code among 4 files.\n\n1.5: he has multiple SQL queries as strings in file. I could probably just copy paste those to a different file and figure out how R opens and reads files pretty easy.\n\n2: He seems to be allergic to loops or reusable functions. 300 lines of calling the exact same function with the same inputs, but typing out every column name rather than looping through the columns. Or 1000+ lines of the same function copy/pasted with a different name for each column name.\n\n3: assigning variables with hard coded paths to dozens of files rather than walking through the directory.\n\nBonus round: I don't know enough about R to know if this is bad, but like 400 lines of creating 3 tables. Running a few data validation scripts on each column matching regex. Idk this part is probably fineISH.\n\nI might have overreacted to the 10k+ lines. This probably won't be too difficult to figure out. Thanks for all the advice and for joining me in this day 1 freak out.", "author_fullname": "t2_3wxhxt1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New job. Minor shit show rant, and advice needed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ycoj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696308368.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696290766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So like the title says I started a new job today. Figure out why this report written in R broke 2 months ago. I open up a single file with 6952 lines in it. All that&amp;#39;s left of me is a 2 page word dock explaining it the main file that call 3 other files, each with 2-3k lines of R code, to create a single 7 page PDF report from a single data source.&lt;/p&gt;\n\n&lt;p&gt;WHAT THE ABSOLUTE HELL AM I LOOKING AT LOL. I don&amp;#39;t know R, but it&amp;#39;s similar enough to python that I can follow along to get the gist of what it&amp;#39;s doing. BUT STILL! WHO NEED 10K+ LINES OF CODE FOR THIS?&lt;/p&gt;\n\n&lt;p&gt;Should I tell them it&amp;#39;s all bunk and make my case to start from scratch, or just buckle down and learn myself some R to make it work?&lt;/p&gt;\n\n&lt;p&gt;Edit:\nSo after further investigation there are 3 major issues.&lt;/p&gt;\n\n&lt;p&gt;1: He would comment out old code and leave it in the file. Shout out @Strider_A for the git joke. After deleting all the obvious old code I have taken it down to a total of 5,679 lines of code among 4 files.&lt;/p&gt;\n\n&lt;p&gt;1.5: he has multiple SQL queries as strings in file. I could probably just copy paste those to a different file and figure out how R opens and reads files pretty easy.&lt;/p&gt;\n\n&lt;p&gt;2: He seems to be allergic to loops or reusable functions. 300 lines of calling the exact same function with the same inputs, but typing out every column name rather than looping through the columns. Or 1000+ lines of the same function copy/pasted with a different name for each column name.&lt;/p&gt;\n\n&lt;p&gt;3: assigning variables with hard coded paths to dozens of files rather than walking through the directory.&lt;/p&gt;\n\n&lt;p&gt;Bonus round: I don&amp;#39;t know enough about R to know if this is bad, but like 400 lines of creating 3 tables. Running a few data validation scripts on each column matching regex. Idk this part is probably fineISH.&lt;/p&gt;\n\n&lt;p&gt;I might have overreacted to the 10k+ lines. This probably won&amp;#39;t be too difficult to figure out. Thanks for all the advice and for joining me in this day 1 freak out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ycoj4", "is_robot_indexable": true, "report_reasons": null, "author": "TrainquilOasis1423", "discussion_type": null, "num_comments": 47, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ycoj4/new_job_minor_shit_show_rant_and_advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ycoj4/new_job_minor_shit_show_rant_and_advice_needed/", "subreddit_subscribers": 131870, "created_utc": 1696290766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Iv been a DE for around 5 years now. I love working with data, building pipelines, ML platforms, supporting BI/DA/DS teams, etc. But I HATE dev ops.\n\nI work for a company with a pretty complex cloud environment setup. Handling permissions and networking between microservices takes up about 80% of my daily energy.\n\nIt seems like a lot of DE jobs require quite a bit of devops work. Is this true?\n\nHow do I transition to a role that focuses less on devops and more on software design/performance? Iv been thinking of Skilling up and trying to transition into an ML. Engineer role. Would a role like that theoretically have less devops responsibility?", "author_fullname": "t2_hc5pt3hd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I get away from devops", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ysjx8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696341226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Iv been a DE for around 5 years now. I love working with data, building pipelines, ML platforms, supporting BI/DA/DS teams, etc. But I HATE dev ops.&lt;/p&gt;\n\n&lt;p&gt;I work for a company with a pretty complex cloud environment setup. Handling permissions and networking between microservices takes up about 80% of my daily energy.&lt;/p&gt;\n\n&lt;p&gt;It seems like a lot of DE jobs require quite a bit of devops work. Is this true?&lt;/p&gt;\n\n&lt;p&gt;How do I transition to a role that focuses less on devops and more on software design/performance? Iv been thinking of Skilling up and trying to transition into an ML. Engineer role. Would a role like that theoretically have less devops responsibility?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ysjx8", "is_robot_indexable": true, "report_reasons": null, "author": "burns_after_reading", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ysjx8/how_do_i_get_away_from_devops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ysjx8/how_do_i_get_away_from_devops/", "subreddit_subscribers": 131870, "created_utc": 1696341226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I\u2019ve been working as a DE for 1.5 years. I\u2019ve touched on some cloud, some ci/cd, lots of ETL and some database design. I enjoy the work but it seems to me that each DE job is sort of like this. Is this it? Do I just make pipelines until I hit senior or manager or am I missing something? Like there\u2019s always work to be done and although we implement interesting solutions, no one really cares instead they ask for delivery dates or why the data is wrong. I\u2019ve seen this across 2 teams, does DE not get recognition? \n\nLike I enjoy the work day to day but when I look at what I do or am creating, it just doesn\u2019t seem impactful compared to other SWE roles like cloud/security/infra. \n\nI\u2019m looking to switch jobs and next job will be more analytics focused (tableau/ETL). After working though I don\u2019t know what my progression will be, like what does a senior / engineer manager in data do? How do I get there? Is it fulfilling?\n\nIt\u2019s a loaded question I\u2019m mainly just concerned about the culture &amp; future of DE work and if I made the right choice doing this after graduating with a CS degree.\n\nI\u2019m based in Toronto if that helps", "author_fullname": "t2_7okz25a22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Failing to see impact and progression in DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yhc5t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696303743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019ve been working as a DE for 1.5 years. I\u2019ve touched on some cloud, some ci/cd, lots of ETL and some database design. I enjoy the work but it seems to me that each DE job is sort of like this. Is this it? Do I just make pipelines until I hit senior or manager or am I missing something? Like there\u2019s always work to be done and although we implement interesting solutions, no one really cares instead they ask for delivery dates or why the data is wrong. I\u2019ve seen this across 2 teams, does DE not get recognition? &lt;/p&gt;\n\n&lt;p&gt;Like I enjoy the work day to day but when I look at what I do or am creating, it just doesn\u2019t seem impactful compared to other SWE roles like cloud/security/infra. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking to switch jobs and next job will be more analytics focused (tableau/ETL). After working though I don\u2019t know what my progression will be, like what does a senior / engineer manager in data do? How do I get there? Is it fulfilling?&lt;/p&gt;\n\n&lt;p&gt;It\u2019s a loaded question I\u2019m mainly just concerned about the culture &amp;amp; future of DE work and if I made the right choice doing this after graduating with a CS degree.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m based in Toronto if that helps&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16yhc5t", "is_robot_indexable": true, "report_reasons": null, "author": "Big-Comparison321", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yhc5t/failing_to_see_impact_and_progression_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yhc5t/failing_to_see_impact_and_progression_in_de/", "subreddit_subscribers": 131870, "created_utc": 1696303743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working in Data for 5 years, the last 2 as DE. During that time I have worked for same number of companies (around 1 year per company)\n\nThe problem for me is that all companies did not really understood what DE is about. Finding this subreddit has been an eye-opener for me also because I am reading all about this cool tools and ideas but I haven't really worked with anything regarding proper DE.\n\nI just recently snatched an opportunity as a Sr DE but to my surprise, the team is more BI that anything else. One person even holds the same title as me but doesn't even know SQL. Plus the company work with external dbs (some systems have their own dbs and we have reader access only). During this time I have only made some queries and helped with some dashboards and that's it. This is almost the same thing that I did on my past company as DE.\n\nI feel that I have a very good SQL, a decent Python and useful knowledge of BI Tools (mostly Tableau and PowerBI) and have a certification on AWS. I also sell myself very good on interviews which I feel has given me a better job opportunity each year. \n\nI often read about tools like dbt, terraform, airflow etc. I kind of know how they work but the reality is that I have not touched any of that.\n\nI really want to give value and to this point in my carreer I really feel that I need to be updating myself but I don't really know how to that without proper exposure. \n\n&amp;#x200B;\n\nAny thoughts on this??", "author_fullname": "t2_gbmtpmgy2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling a bit down regarding my DE career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ye2hm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696294489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working in Data for 5 years, the last 2 as DE. During that time I have worked for same number of companies (around 1 year per company)&lt;/p&gt;\n\n&lt;p&gt;The problem for me is that all companies did not really understood what DE is about. Finding this subreddit has been an eye-opener for me also because I am reading all about this cool tools and ideas but I haven&amp;#39;t really worked with anything regarding proper DE.&lt;/p&gt;\n\n&lt;p&gt;I just recently snatched an opportunity as a Sr DE but to my surprise, the team is more BI that anything else. One person even holds the same title as me but doesn&amp;#39;t even know SQL. Plus the company work with external dbs (some systems have their own dbs and we have reader access only). During this time I have only made some queries and helped with some dashboards and that&amp;#39;s it. This is almost the same thing that I did on my past company as DE.&lt;/p&gt;\n\n&lt;p&gt;I feel that I have a very good SQL, a decent Python and useful knowledge of BI Tools (mostly Tableau and PowerBI) and have a certification on AWS. I also sell myself very good on interviews which I feel has given me a better job opportunity each year. &lt;/p&gt;\n\n&lt;p&gt;I often read about tools like dbt, terraform, airflow etc. I kind of know how they work but the reality is that I have not touched any of that.&lt;/p&gt;\n\n&lt;p&gt;I really want to give value and to this point in my carreer I really feel that I need to be updating myself but I don&amp;#39;t really know how to that without proper exposure. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any thoughts on this??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ye2hm", "is_robot_indexable": true, "report_reasons": null, "author": "hot-bulbasur", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ye2hm/feeling_a_bit_down_regarding_my_de_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ye2hm/feeling_a_bit_down_regarding_my_de_career/", "subreddit_subscribers": 131870, "created_utc": 1696294489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI've built a data pipeline using an orchestrated azure function that has 5 or so steps (python scripts) that load data from a storage blob, perform a bunch of transformations on the data then load into an azure SQL database. I'm running into problems as I'm hitting the 10minute limit.\n\nOn top of this I'd also like to host and schedule a whole bunch of web scrapers (which would also probably hit the 10minute limit)\n\nI'm looking at alternatives whilst staying within the Azure ecosystem. Currently I'm thinking of getting an Azure VM and installing airflow/prefect to run and manage this pipeline. The VM would also host and run the web scrapers.\n\nAre there any other solutions you can recommend or anything I'm missing?", "author_fullname": "t2_9pvwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on Azure Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yo0lc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696328271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve built a data pipeline using an orchestrated azure function that has 5 or so steps (python scripts) that load data from a storage blob, perform a bunch of transformations on the data then load into an azure SQL database. I&amp;#39;m running into problems as I&amp;#39;m hitting the 10minute limit.&lt;/p&gt;\n\n&lt;p&gt;On top of this I&amp;#39;d also like to host and schedule a whole bunch of web scrapers (which would also probably hit the 10minute limit)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking at alternatives whilst staying within the Azure ecosystem. Currently I&amp;#39;m thinking of getting an Azure VM and installing airflow/prefect to run and manage this pipeline. The VM would also host and run the web scrapers.&lt;/p&gt;\n\n&lt;p&gt;Are there any other solutions you can recommend or anything I&amp;#39;m missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16yo0lc", "is_robot_indexable": true, "report_reasons": null, "author": "lieutenant_lowercase", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yo0lc/advice_on_azure_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yo0lc/advice_on_azure_data_engineering/", "subreddit_subscribers": 131870, "created_utc": 1696328271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello Everyone,\n\nI'm an Industrial Engineer that has been working on data for the last couple of years. 1 year as a Data Analyst and almost 2 years as an Analytics Specialist. I ended up on this area by learning on my own and getting some certifications (also there wasn't as much analysts as there are now).\n\nAnyways, as it happens to a lot, my position is kind of ambiguous and I personally would define it as an ETL and dashboard developer. I create initial queries using SQL and then transform the data using Alteryx and feed it to a tableau or power BI dashboard that I create.  \nA regular workflow could have 10 different EDW sources and a couple of excel files. The initial data is generally around 400M records and ends of being 100K - 4M record. So I have to prepare the data for myself to use later.\n\nI want to get deeper into the Data engineering part of it and eventually look for data engineer jobs, I started my research today to determine the next logical steps but depending on the source, the suggestions are very different. I would like to study a masters eventually but I can\u00b4t do it right now.\n\nSo, my question is: In your opinion and taking into account your personal experience and preferences and **without saying \"it depends\"**, given my described background. which tool/software/process do you think would be the most valuable to learn to be competitive?\n\nAlso, if you know of a good youtube video that explains what it actually is to be a data engineer, it would be appreciated, most of the content I saw seemed like it was made by a 20 yr old influencer trying to get likes.", "author_fullname": "t2_38po62bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from Analytics Specialist to Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y5790", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696273467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m an Industrial Engineer that has been working on data for the last couple of years. 1 year as a Data Analyst and almost 2 years as an Analytics Specialist. I ended up on this area by learning on my own and getting some certifications (also there wasn&amp;#39;t as much analysts as there are now).&lt;/p&gt;\n\n&lt;p&gt;Anyways, as it happens to a lot, my position is kind of ambiguous and I personally would define it as an ETL and dashboard developer. I create initial queries using SQL and then transform the data using Alteryx and feed it to a tableau or power BI dashboard that I create.&lt;br/&gt;\nA regular workflow could have 10 different EDW sources and a couple of excel files. The initial data is generally around 400M records and ends of being 100K - 4M record. So I have to prepare the data for myself to use later.&lt;/p&gt;\n\n&lt;p&gt;I want to get deeper into the Data engineering part of it and eventually look for data engineer jobs, I started my research today to determine the next logical steps but depending on the source, the suggestions are very different. I would like to study a masters eventually but I can\u00b4t do it right now.&lt;/p&gt;\n\n&lt;p&gt;So, my question is: In your opinion and taking into account your personal experience and preferences and &lt;strong&gt;without saying &amp;quot;it depends&amp;quot;&lt;/strong&gt;, given my described background. which tool/software/process do you think would be the most valuable to learn to be competitive?&lt;/p&gt;\n\n&lt;p&gt;Also, if you know of a good youtube video that explains what it actually is to be a data engineer, it would be appreciated, most of the content I saw seemed like it was made by a 20 yr old influencer trying to get likes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16y5790", "is_robot_indexable": true, "report_reasons": null, "author": "Esteban_Rdz", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y5790/transitioning_from_analytics_specialist_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y5790/transitioning_from_analytics_specialist_to_data/", "subreddit_subscribers": 131870, "created_utc": 1696273467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been tasked with centrally documenting a BI product and I am wondering how professionals approach this problem as I am relatively new to this field of work.\n\nThis product in short boils down to: get data from source system --&gt; select and transform data in SQL --&gt; store created tables in data warehouse --&gt; load in Power BI.\n\nOf course there is a number of standard approaches in place such as commenting the SQL queries etc. but I am trying to find the best way to centrally store all underlying relationships in this data product. Such that for every Power BI measure, I store the used data warehouse column(s) and the source column(s) used to generate said data warehouse column(s).\n\nI attached a visual example of the relationships I am trying to centrally document, quickly written up in MS Excel style. In the example *my\\_powerbi\\_measure\\_1* is created using *my\\_datawarehouse\\_column1*/*2*/*3* and *my\\_datawarehouse\\_column1* is created using *my\\_sourcedata\\_column1*.\n\n&amp;#x200B;\n\nWhat are tools or documentation approaches you guys use, or would use, to get to this central documentation of data flows? All ideas and tips are appreciated!\n\n&amp;#x200B;\n\n[Visual example](https://preview.redd.it/gkr7g6cs80sb1.png?width=1023&amp;format=png&amp;auto=webp&amp;s=2d61ee6c27f787bd23ec9074fdff6a4a1488fdc3)", "author_fullname": "t2_3tjzfxzi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Centrally documenting data flows of a BI product", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 37, "top_awarded_type": null, "hide_score": false, "media_metadata": {"gkr7g6cs80sb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 28, "x": 108, "u": "https://preview.redd.it/gkr7g6cs80sb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ddacf8e0df5a525fd12de3e7faff4cee91e28338"}, {"y": 57, "x": 216, "u": "https://preview.redd.it/gkr7g6cs80sb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e90d278173bca8eef273915d4ec22c16f55f7e15"}, {"y": 85, "x": 320, "u": "https://preview.redd.it/gkr7g6cs80sb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0b6d7fac4d1bdb877c7b34afab7627f52e9a6a4d"}, {"y": 171, "x": 640, "u": "https://preview.redd.it/gkr7g6cs80sb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=587548bb83d6e2ab9a4ff7031ad7b27e5c7720a2"}, {"y": 257, "x": 960, "u": "https://preview.redd.it/gkr7g6cs80sb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7857a6bc212c9ce6086927a4113ecaac6ade0622"}], "s": {"y": 274, "x": 1023, "u": "https://preview.redd.it/gkr7g6cs80sb1.png?width=1023&amp;format=png&amp;auto=webp&amp;s=2d61ee6c27f787bd23ec9074fdff6a4a1488fdc3"}, "id": "gkr7g6cs80sb1"}}, "name": "t3_16yuq2k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nAeYY4IgGMBgUxkb7oPsBq8oEFo3Uy6L8SJPVkWvKic.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696346440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been tasked with centrally documenting a BI product and I am wondering how professionals approach this problem as I am relatively new to this field of work.&lt;/p&gt;\n\n&lt;p&gt;This product in short boils down to: get data from source system --&amp;gt; select and transform data in SQL --&amp;gt; store created tables in data warehouse --&amp;gt; load in Power BI.&lt;/p&gt;\n\n&lt;p&gt;Of course there is a number of standard approaches in place such as commenting the SQL queries etc. but I am trying to find the best way to centrally store all underlying relationships in this data product. Such that for every Power BI measure, I store the used data warehouse column(s) and the source column(s) used to generate said data warehouse column(s).&lt;/p&gt;\n\n&lt;p&gt;I attached a visual example of the relationships I am trying to centrally document, quickly written up in MS Excel style. In the example &lt;em&gt;my_powerbi_measure_1&lt;/em&gt; is created using &lt;em&gt;my_datawarehouse_column1&lt;/em&gt;/&lt;em&gt;2&lt;/em&gt;/&lt;em&gt;3&lt;/em&gt; and &lt;em&gt;my_datawarehouse_column1&lt;/em&gt; is created using &lt;em&gt;my_sourcedata_column1&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What are tools or documentation approaches you guys use, or would use, to get to this central documentation of data flows? All ideas and tips are appreciated!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gkr7g6cs80sb1.png?width=1023&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2d61ee6c27f787bd23ec9074fdff6a4a1488fdc3\"&gt;Visual example&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16yuq2k", "is_robot_indexable": true, "report_reasons": null, "author": "basr98", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yuq2k/centrally_documenting_data_flows_of_a_bi_product/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yuq2k/centrally_documenting_data_flows_of_a_bi_product/", "subreddit_subscribers": 131870, "created_utc": 1696346440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineers - Backbone of MDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16yf8wu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/4zNY8SJjG0uF5uSb-XaNvehId38x1Rawzto3oaYlnx0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696297757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/tygyfvt28wrb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/tygyfvt28wrb1.jpg?auto=webp&amp;s=e8af4c5dbbe32d1730afe9e93356407e8d287e80", "width": 832, "height": 418}, "resolutions": [{"url": "https://preview.redd.it/tygyfvt28wrb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a0524687244a4c5a47f25e20ec06d54ad6d9249e", "width": 108, "height": 54}, {"url": "https://preview.redd.it/tygyfvt28wrb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8fbcccdd0c92d285a19469b36df9e842316153b1", "width": 216, "height": 108}, {"url": "https://preview.redd.it/tygyfvt28wrb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=946ddaed54f027f76cd85ef2c0254c1f4251e92b", "width": 320, "height": 160}, {"url": "https://preview.redd.it/tygyfvt28wrb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5700636714e2788765207720260f1cfcd276cd93", "width": 640, "height": 321}], "variants": {}, "id": "jViKEmiyM67RCQbJtmI7F5AOIWKL15ioGaTkD-Zmc4c"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "16yf8wu", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yf8wu/data_engineers_backbone_of_mds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/tygyfvt28wrb1.jpg", "subreddit_subscribers": 131870, "created_utc": 1696297757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an s3 bucket with about 5+ million JSON files loaded per day (across our different client folders).\n\n* clientA - 9/25 - 120k files\n* clientB - 9/25 - 1.2M files  (1 file per userid)\n\neach JSON is small &lt; 10kb each.\n\nI have to retrieve a couple key-value pairs from the json and export it back to a new s3 bucket (combined). so from 1.2M files, the output should maybe be &lt;50 files in parquet/csv format.\n\n* example: extract these fields from JSON\n   * \"activated\": true and \"userid\": 123\n* expected results: tabular parquet/csv file\n   * activated, userid\n\n|activated|userid|\n|:-|:-|\n|true|123|\n|false|456|\n\nthis only needs to run once per day (batch).\n\n**current environment:**\n\nHybrid - SQL Server on-prem and Airflow (on-prem) and Redshift, primarily. we actually need to load this to SQL Server but we can use Redshift as a  processing middle-man if we need to.\n\nwe have the option of using Glue/Spark.\n\n**rough plan**\n\n1. glue job using pyspark to read the files for the previous day\n2. parse the json to get what we need\n3. export it back out to another s3 bucket  in gzipped csv\n   1. each brand will get its own folder of exported files\n\nAny ideas on this approach?\n\n* is there a way to trigger the glue job for a specific day (if we wanted to rerun a day?)\n* it'd be nice if there's an error that it can alert but continue with the other clients (non-blocking)\n\nWe don't have an EMR cluster (don't really have a need). I realize we can use EMR Serverless as well. Perhaps we can use that with our on-prem Airflow instance instead\n\n**Another option -**\n\n1. use Redshift's COPY command and [JSONPaths filters](https://docs.aws.amazon.com/redshift/latest/dg/copy-usage_notes-copy-from-json.html) to load the s3 files to a staging table on Redshift\n2. Then UNLOAD the entire table (all the records) to csv so it can be imported into SQL Server\n   1. this has the benefit of being \"free\" since our cluster is always running.\n\nOption 3:\n\n* use aws athena\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nedit: updated post with some more details.\n\n&amp;#x200B;", "author_fullname": "t2_3yozg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about using Glue/Spark to process millions of JSON files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y7wpn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696284082.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696279632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an s3 bucket with about 5+ million JSON files loaded per day (across our different client folders).&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;clientA - 9/25 - 120k files&lt;/li&gt;\n&lt;li&gt;clientB - 9/25 - 1.2M files  (1 file per userid)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;each JSON is small &amp;lt; 10kb each.&lt;/p&gt;\n\n&lt;p&gt;I have to retrieve a couple key-value pairs from the json and export it back to a new s3 bucket (combined). so from 1.2M files, the output should maybe be &amp;lt;50 files in parquet/csv format.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;example: extract these fields from JSON\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;activated&amp;quot;: true and &amp;quot;userid&amp;quot;: 123&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;expected results: tabular parquet/csv file\n\n&lt;ul&gt;\n&lt;li&gt;activated, userid&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;activated&lt;/th&gt;\n&lt;th align=\"left\"&gt;userid&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;true&lt;/td&gt;\n&lt;td align=\"left\"&gt;123&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;false&lt;/td&gt;\n&lt;td align=\"left\"&gt;456&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;this only needs to run once per day (batch).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;current environment:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Hybrid - SQL Server on-prem and Airflow (on-prem) and Redshift, primarily. we actually need to load this to SQL Server but we can use Redshift as a  processing middle-man if we need to.&lt;/p&gt;\n\n&lt;p&gt;we have the option of using Glue/Spark.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;rough plan&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;glue job using pyspark to read the files for the previous day&lt;/li&gt;\n&lt;li&gt;parse the json to get what we need&lt;/li&gt;\n&lt;li&gt;export it back out to another s3 bucket  in gzipped csv\n\n&lt;ol&gt;\n&lt;li&gt;each brand will get its own folder of exported files&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any ideas on this approach?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;is there a way to trigger the glue job for a specific day (if we wanted to rerun a day?)&lt;/li&gt;\n&lt;li&gt;it&amp;#39;d be nice if there&amp;#39;s an error that it can alert but continue with the other clients (non-blocking)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We don&amp;#39;t have an EMR cluster (don&amp;#39;t really have a need). I realize we can use EMR Serverless as well. Perhaps we can use that with our on-prem Airflow instance instead&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Another option -&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;use Redshift&amp;#39;s COPY command and &lt;a href=\"https://docs.aws.amazon.com/redshift/latest/dg/copy-usage_notes-copy-from-json.html\"&gt;JSONPaths filters&lt;/a&gt; to load the s3 files to a staging table on Redshift&lt;/li&gt;\n&lt;li&gt;Then UNLOAD the entire table (all the records) to csv so it can be imported into SQL Server\n\n&lt;ol&gt;\n&lt;li&gt;this has the benefit of being &amp;quot;free&amp;quot; since our cluster is always running.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Option 3:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;use aws athena&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;edit: updated post with some more details.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16y7wpn", "is_robot_indexable": true, "report_reasons": null, "author": "gman1023", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y7wpn/question_about_using_gluespark_to_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y7wpn/question_about_using_gluespark_to_process/", "subreddit_subscribers": 131870, "created_utc": 1696279632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there, so ive been on the internship hunt for quite a long time now and 2 of the 3 interviews I've managed to get thus far I've wound up getting surprised with a surprising amount of DS questions (stats, ML modeling experience, prior work with DS/ML tools) along with typical SQL + Data Modeling, Python, Data Integration/Orchestration tooling questions.\n\nThe thing is this hasn't always been very explicit in the job posting and I've only really taken intro-level coursework in stats and ML (almost entirely intro-level supervised learning concepts and models, lightly touched unsupervised learning at the end) so I'm very weak footed when answering DS questions that go much further beyond basic regression in complexity. Im now wondering if I need to sit down and spend time improving that side of my skillset?\n\nIts also extra stressful because doing an internship is a mandatory part of my undergrad program to graduate and with how brutally slim job postings are on average I cant afford to keep slipping on these interviews", "author_fullname": "t2_pfwkw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it typical to see Data Engineer and Data Science duties intertwined on Internship roles with smaller companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yx85g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696352967.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696352268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, so ive been on the internship hunt for quite a long time now and 2 of the 3 interviews I&amp;#39;ve managed to get thus far I&amp;#39;ve wound up getting surprised with a surprising amount of DS questions (stats, ML modeling experience, prior work with DS/ML tools) along with typical SQL + Data Modeling, Python, Data Integration/Orchestration tooling questions.&lt;/p&gt;\n\n&lt;p&gt;The thing is this hasn&amp;#39;t always been very explicit in the job posting and I&amp;#39;ve only really taken intro-level coursework in stats and ML (almost entirely intro-level supervised learning concepts and models, lightly touched unsupervised learning at the end) so I&amp;#39;m very weak footed when answering DS questions that go much further beyond basic regression in complexity. Im now wondering if I need to sit down and spend time improving that side of my skillset?&lt;/p&gt;\n\n&lt;p&gt;Its also extra stressful because doing an internship is a mandatory part of my undergrad program to graduate and with how brutally slim job postings are on average I cant afford to keep slipping on these interviews&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16yx85g", "is_robot_indexable": true, "report_reasons": null, "author": "Anic135", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yx85g/is_it_typical_to_see_data_engineer_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yx85g/is_it_typical_to_see_data_engineer_and_data/", "subreddit_subscribers": 131870, "created_utc": 1696352268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been reading a lot about polaris but one thing about the industry I\u2019ve seen is that new technologies come and have a a lot of hype but do not cause any real change to the current accepted stack. \n\nI\u2019m wondering if this subreddit feels the same way about it as me. Obviously it\u2019s good to keep learning but between getting better at pyspark vs Polaris I\u2019m wondering which should be the focus", "author_fullname": "t2_xzn0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Polaris worth learning over pyspark? Or is it just hype while the industry has no intention of moving away from a Apache/Cloud framework", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yx6f1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696352149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been reading a lot about polaris but one thing about the industry I\u2019ve seen is that new technologies come and have a a lot of hype but do not cause any real change to the current accepted stack. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m wondering if this subreddit feels the same way about it as me. Obviously it\u2019s good to keep learning but between getting better at pyspark vs Polaris I\u2019m wondering which should be the focus&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16yx6f1", "is_robot_indexable": true, "report_reasons": null, "author": "richhoods", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yx6f1/is_polaris_worth_learning_over_pyspark_or_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yx6f1/is_polaris_worth_learning_over_pyspark_or_is_it/", "subreddit_subscribers": 131870, "created_utc": 1696352149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Apologies in advance for any grammatical errors, english is not my first languange.\n\nQuick background.\n\nI work in a large EDW project at a bank where our main goal is to replace their old enterprise data warehouse and build it more future proof with more modern technology. For regulatory reasons we're not allowed to store any data in a cloud platform unfortunately.\n\nDescription of our technology stack:\n\n* Getting source systems into a data lake, streaming data through kafka and Oracle Golden Gate.\n* Data lake, integration layer and data marts are in an Oracle database.\n* We use DBT to model and code everything and use airflow for scheduling and deployment.\n* On top of that we have SSAS cubes and Power BI as the self-service and reporting layer.\n\nNow to my question. We have received a demand from upper management that we need to implement \"Separation of duties\" in all of our deployments, meaning the person who wrote the code can't deploy it.\n\nSince we use DBT and airflow. There's no people that actually deploy stuff to our production environment. When a PR has been checked and approved by two people (not the same as the developer), it's usually the person who wrote the code who presses the \"complete\" button. Which then gets put into DBT which then gets picked up by airflow and makes whatever change was implemented.\n\nIn our mind this is enough \"separation of duties\". The code is checked by two people and there's automation tools that runs everything. But now after a meeting with upper management they are saying that the person who wrote the code can't be the one that presses \"complete\". This to me seems like a super unnecessary step which just creates more administration and now we need to dedicate a person within the team who will complete all the approved pull requests....\n\nDo anyone here have any experience with implementing SoD in EDW projects? How did you go about doing it? Where did you draw the line of \"this is compliant enough\"?\n\n&amp;#x200B;", "author_fullname": "t2_hafid", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you work with \"Separation of Duties\" in enterprise data warehouse projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yr1ae", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696337310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies in advance for any grammatical errors, english is not my first languange.&lt;/p&gt;\n\n&lt;p&gt;Quick background.&lt;/p&gt;\n\n&lt;p&gt;I work in a large EDW project at a bank where our main goal is to replace their old enterprise data warehouse and build it more future proof with more modern technology. For regulatory reasons we&amp;#39;re not allowed to store any data in a cloud platform unfortunately.&lt;/p&gt;\n\n&lt;p&gt;Description of our technology stack:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Getting source systems into a data lake, streaming data through kafka and Oracle Golden Gate.&lt;/li&gt;\n&lt;li&gt;Data lake, integration layer and data marts are in an Oracle database.&lt;/li&gt;\n&lt;li&gt;We use DBT to model and code everything and use airflow for scheduling and deployment.&lt;/li&gt;\n&lt;li&gt;On top of that we have SSAS cubes and Power BI as the self-service and reporting layer.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Now to my question. We have received a demand from upper management that we need to implement &amp;quot;Separation of duties&amp;quot; in all of our deployments, meaning the person who wrote the code can&amp;#39;t deploy it.&lt;/p&gt;\n\n&lt;p&gt;Since we use DBT and airflow. There&amp;#39;s no people that actually deploy stuff to our production environment. When a PR has been checked and approved by two people (not the same as the developer), it&amp;#39;s usually the person who wrote the code who presses the &amp;quot;complete&amp;quot; button. Which then gets put into DBT which then gets picked up by airflow and makes whatever change was implemented.&lt;/p&gt;\n\n&lt;p&gt;In our mind this is enough &amp;quot;separation of duties&amp;quot;. The code is checked by two people and there&amp;#39;s automation tools that runs everything. But now after a meeting with upper management they are saying that the person who wrote the code can&amp;#39;t be the one that presses &amp;quot;complete&amp;quot;. This to me seems like a super unnecessary step which just creates more administration and now we need to dedicate a person within the team who will complete all the approved pull requests....&lt;/p&gt;\n\n&lt;p&gt;Do anyone here have any experience with implementing SoD in EDW projects? How did you go about doing it? Where did you draw the line of &amp;quot;this is compliant enough&amp;quot;?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16yr1ae", "is_robot_indexable": true, "report_reasons": null, "author": "Pimdaz", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yr1ae/how_do_you_work_with_separation_of_duties_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yr1ae/how_do_you_work_with_separation_of_duties_in/", "subreddit_subscribers": 131870, "created_utc": 1696337310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking for a new role. I am interested in the SWE side &amp; not interested in the analytics engineer roles. After working for a year in the DE space I have realized that ~80-90% DE roles in the market are mostly analytics engineer roles and only 10-15% or even less are SWE oriented roles. I would like to know from the community which companies offer these roles", "author_fullname": "t2_dpc2z7ubu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Companies having SWE oriented data roles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ydysg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696294200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for a new role. I am interested in the SWE side &amp;amp; not interested in the analytics engineer roles. After working for a year in the DE space I have realized that ~80-90% DE roles in the market are mostly analytics engineer roles and only 10-15% or even less are SWE oriented roles. I would like to know from the community which companies offer these roles&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ydysg", "is_robot_indexable": true, "report_reasons": null, "author": "cyamnihc", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ydysg/companies_having_swe_oriented_data_roles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ydysg/companies_having_swe_oriented_data_roles/", "subreddit_subscribers": 131870, "created_utc": 1696294200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI just started up in a non-DE position at what is essentially a boutique consulting firm that has grown a good bit recently. The company is small enough and the industry is new enough that it is doing well without any sort of data-driven processes or dedicated data team. I\u2019ve relayed my interest in automation and DE, and while I\u2019ve already done some one-off convenience types of things (automating emails, checking calendars in order to create agendas with the Outlook API, etc), I\u2019d love to implement and practice some DE work with this company. Unfortunately, because all of our clients are prospective businesses, there\u2019s no real easy data to collect that I can think of. \n\nLuckily, my boss is all for anything that makes the company better or the work easier, so cost is only a minor issue and I\u2019m encouraged to use my time here as a sort of playground to test things out. Without getting into too many details about the company itself, would anyone have any ideas on general projects to take on while working here? Would love to boost my resume until I can land a more tech-centric gig!", "author_fullname": "t2_2ivpdou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to practice and implement DE in a non-tech aware company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ya38i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696284512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I just started up in a non-DE position at what is essentially a boutique consulting firm that has grown a good bit recently. The company is small enough and the industry is new enough that it is doing well without any sort of data-driven processes or dedicated data team. I\u2019ve relayed my interest in automation and DE, and while I\u2019ve already done some one-off convenience types of things (automating emails, checking calendars in order to create agendas with the Outlook API, etc), I\u2019d love to implement and practice some DE work with this company. Unfortunately, because all of our clients are prospective businesses, there\u2019s no real easy data to collect that I can think of. &lt;/p&gt;\n\n&lt;p&gt;Luckily, my boss is all for anything that makes the company better or the work easier, so cost is only a minor issue and I\u2019m encouraged to use my time here as a sort of playground to test things out. Without getting into too many details about the company itself, would anyone have any ideas on general projects to take on while working here? Would love to boost my resume until I can land a more tech-centric gig!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ya38i", "is_robot_indexable": true, "report_reasons": null, "author": "Butterhero_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ya38i/how_to_practice_and_implement_de_in_a_nontech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ya38i/how_to_practice_and_implement_de_in_a_nontech/", "subreddit_subscribers": 131870, "created_utc": 1696284512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team really likes Sigma and would love to integrate it in our stack but their price is not public which makes me think they just say prices based on their perception of how much a company needs it. So my question is: is Sigma in your stack and how much do you pay for it?", "author_fullname": "t2_axgif", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sigma pricing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y59mv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696273625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team really likes Sigma and would love to integrate it in our stack but their price is not public which makes me think they just say prices based on their perception of how much a company needs it. So my question is: is Sigma in your stack and how much do you pay for it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16y59mv", "is_robot_indexable": true, "report_reasons": null, "author": "Batto1300", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y59mv/sigma_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y59mv/sigma_pricing/", "subreddit_subscribers": 131870, "created_utc": 1696273625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_14v3ms", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Completeness: To Stream or Not to Stream", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ywpin", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1696351027.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "tobikodata.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://tobikodata.com/data-completeness.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16ywpin", "is_robot_indexable": true, "report_reasons": null, "author": "s0ck_r4w", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ywpin/data_completeness_to_stream_or_not_to_stream/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://tobikodata.com/data-completeness.html", "subreddit_subscribers": 131870, "created_utc": 1696351027.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Could one senior data engineer with solid experience setup Apache Beam and real-time streaming from scratch for a startup organisation within a reasonable timeframe? Eg., 8-12 weeks, with earlier prototypes?\nJust getting a handle on the complexity compared to a non-streaming data warehouse like dbt, which I would have said definitely yes.\n\nAny thoughts or advice on complexities jumping to streaming and Apache Beam is much appreciated.\n\nThanks!!", "author_fullname": "t2_jkvzr8r3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Beam Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ysa9g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696340547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could one senior data engineer with solid experience setup Apache Beam and real-time streaming from scratch for a startup organisation within a reasonable timeframe? Eg., 8-12 weeks, with earlier prototypes?\nJust getting a handle on the complexity compared to a non-streaming data warehouse like dbt, which I would have said definitely yes.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts or advice on complexities jumping to streaming and Apache Beam is much appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ysa9g", "is_robot_indexable": true, "report_reasons": null, "author": "pbower2049", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ysa9g/apache_beam_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ysa9g/apache_beam_question/", "subreddit_subscribers": 131870, "created_utc": 1696340547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All. I have a requirement to read data from on-prem MySQL database to Azure Event Hub. This data will be later used in Power BI. \n\nWhat is the best way to get MySQL data to Event Hub in streaming fashion? I read that we can use bin logs of MySQL, which means I need to run a python process on on-prem system that can push data to Event Hub. Is there any other ways which are better? ", "author_fullname": "t2_2xxs9nne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming data from MySQL to Azure Event Hub", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yqrwy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696336598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All. I have a requirement to read data from on-prem MySQL database to Azure Event Hub. This data will be later used in Power BI. &lt;/p&gt;\n\n&lt;p&gt;What is the best way to get MySQL data to Event Hub in streaming fashion? I read that we can use bin logs of MySQL, which means I need to run a python process on on-prem system that can push data to Event Hub. Is there any other ways which are better? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16yqrwy", "is_robot_indexable": true, "report_reasons": null, "author": "inglocines", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yqrwy/streaming_data_from_mysql_to_azure_event_hub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yqrwy/streaming_data_from_mysql_to_azure_event_hub/", "subreddit_subscribers": 131870, "created_utc": 1696336598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nDo you have some beginner resources (blog posts, books, videos) to start learning ML terminology and connection points with data engineering ?", "author_fullname": "t2_8ejk5itu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introductive ML lectures as DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ypyoo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696334294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nDo you have some beginner resources (blog posts, books, videos) to start learning ML terminology and connection points with data engineering ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ypyoo", "is_robot_indexable": true, "report_reasons": null, "author": "ultimaRati0", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ypyoo/introductive_ml_lectures_as_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ypyoo/introductive_ml_lectures_as_de/", "subreddit_subscribers": 131870, "created_utc": 1696334294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What exactly is involved in data engineering?\n\nAre data engineers supposed to design data collection instruments?", "author_fullname": "t2_ebi9k4t3e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Acticities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ykk2c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696314950.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What exactly is involved in data engineering?&lt;/p&gt;\n\n&lt;p&gt;Are data engineers supposed to design data collection instruments?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16ykk2c", "is_robot_indexable": true, "report_reasons": null, "author": "Educational-Rise6486", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ykk2c/data_engineering_acticities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ykk2c/data_engineering_acticities/", "subreddit_subscribers": 131870, "created_utc": 1696314950.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I currently know how to do basic batch-processing ETL (have tried extracting data from APIs and gsheets using python, used GCS / AWS S3 buckets to store raw and transformed data if needed, and ingest to bigquery (I find that redshift is too expensive for personal projects so I just stick to bigquery), using airflow for orchestration, docker compose to setup airflow, all inside a headless VM, port passthrough so I can access airflow web UI in my browser).\n\nNow i want to learn streaming ETL using kafka and pyspark. I find it difficult to setup a self-managed kafka cluster as you have to learn so many new things at once, at the same time I don't think it's gonna be cheap to rely on GCP / AWS for kafka (this is my understanding, please correct me if I'm wrong). There's not much \"updated\" guides on the internet when I tried to search. For example I learned that the newer versions of kafka can avoid using zookeeper (and some users find zookeeper a pain in the ass so that's good, right?) but there's basically zero guides to setting up kafka without using zookeeper. Yes, there's the official docs and I tried it but it only teaches the super basic setup (no connections to anything).\n\nI know this sounds so whiny but it's not like I'm looking to be spoon-fed. I just want to know how you guys learned streaming and would be glad to know your tips on this. Thank you!", "author_fullname": "t2_96yckejj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "having a hard time self-studying kafka", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yi48n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696306120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I currently know how to do basic batch-processing ETL (have tried extracting data from APIs and gsheets using python, used GCS / AWS S3 buckets to store raw and transformed data if needed, and ingest to bigquery (I find that redshift is too expensive for personal projects so I just stick to bigquery), using airflow for orchestration, docker compose to setup airflow, all inside a headless VM, port passthrough so I can access airflow web UI in my browser).&lt;/p&gt;\n\n&lt;p&gt;Now i want to learn streaming ETL using kafka and pyspark. I find it difficult to setup a self-managed kafka cluster as you have to learn so many new things at once, at the same time I don&amp;#39;t think it&amp;#39;s gonna be cheap to rely on GCP / AWS for kafka (this is my understanding, please correct me if I&amp;#39;m wrong). There&amp;#39;s not much &amp;quot;updated&amp;quot; guides on the internet when I tried to search. For example I learned that the newer versions of kafka can avoid using zookeeper (and some users find zookeeper a pain in the ass so that&amp;#39;s good, right?) but there&amp;#39;s basically zero guides to setting up kafka without using zookeeper. Yes, there&amp;#39;s the official docs and I tried it but it only teaches the super basic setup (no connections to anything).&lt;/p&gt;\n\n&lt;p&gt;I know this sounds so whiny but it&amp;#39;s not like I&amp;#39;m looking to be spoon-fed. I just want to know how you guys learned streaming and would be glad to know your tips on this. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16yi48n", "is_robot_indexable": true, "report_reasons": null, "author": "march-2020", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16yi48n/having_a_hard_time_selfstudying_kafka/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yi48n/having_a_hard_time_selfstudying_kafka/", "subreddit_subscribers": 131870, "created_utc": 1696306120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a personal project so that I can try data flows from an iot device to the data platform. My project looks like this:\n\n\\- esp32 dht11 sensor creates temperature and humidity data and sends them to aws iot core\n\n\\- aws iot core routes the received data to the aws sqs\n\n\\- confluent kafka consumes data from aws sqs using the sqs source connector\n\n\\- reads data from confluent kafka from a databricks cluster using structured spark streaming and sinks into a raw table\n\n\\- use a spark streaming to read from the raw table and merge into the curated table real-time\n\nI will have all the processed documented so that I can use it for my portfolio but wanted to get some feedback whether this architecture sounds about the right track.\n\nThanks in advance!", "author_fullname": "t2_86pd6cgg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are services used in my personal project for my portfolio look okay?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y9a7i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696282576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a personal project so that I can try data flows from an iot device to the data platform. My project looks like this:&lt;/p&gt;\n\n&lt;p&gt;- esp32 dht11 sensor creates temperature and humidity data and sends them to aws iot core&lt;/p&gt;\n\n&lt;p&gt;- aws iot core routes the received data to the aws sqs&lt;/p&gt;\n\n&lt;p&gt;- confluent kafka consumes data from aws sqs using the sqs source connector&lt;/p&gt;\n\n&lt;p&gt;- reads data from confluent kafka from a databricks cluster using structured spark streaming and sinks into a raw table&lt;/p&gt;\n\n&lt;p&gt;- use a spark streaming to read from the raw table and merge into the curated table real-time&lt;/p&gt;\n\n&lt;p&gt;I will have all the processed documented so that I can use it for my portfolio but wanted to get some feedback whether this architecture sounds about the right track.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16y9a7i", "is_robot_indexable": true, "report_reasons": null, "author": "EmploymentMammoth659", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y9a7i/are_services_used_in_my_personal_project_for_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y9a7i/are_services_used_in_my_personal_project_for_my/", "subreddit_subscribers": 131870, "created_utc": 1696282576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I try to understand what are the benefits to convert DICOM images to PNG's.  \nContext:  \nI have DICOM images which I already extracted the useful meta-data I want to use.  \nThose images are for a task, classification-detection pipeline of some disease.\n\nSo  as I already asked, what are the benefits of converting those DICOM  files to PNG's rather then just using pydicom and the dicom pixel\\_array?\n\nReason I ask this is because I saw many top 5 users on kaggle do this when dealing with DICOM images.\n\nIf  I understand how networks actually works, they get as input an array of  pixels as floating point numbers no? So what's the differences between  DICOM pixel\\_array to PNG's pixel array and numpy array or tensor? both  are eventually will be fed to the network as a tensor of floating  numbers.\n\nIs the reason is because PNG's are usually faster to train?\n\nIs the reason is because PNG's have more libraries support for preprocessing / augmentation / etc. ?\n\nIs  the reason is because PNG's are the format many pre-trained models  expect to? (I write this knowing it's 99% not true, as mentioned the  tensor thing)\n\nThanks in Advance, and Please, forgive my English (I could use AI tools to fix it but I feel addicted already)", "author_fullname": "t2_5vngcus6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benefits of converting DICOM images to PNG's", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y6r61", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696277029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I try to understand what are the benefits to convert DICOM images to PNG&amp;#39;s.&lt;br/&gt;\nContext:&lt;br/&gt;\nI have DICOM images which I already extracted the useful meta-data I want to use.&lt;br/&gt;\nThose images are for a task, classification-detection pipeline of some disease.&lt;/p&gt;\n\n&lt;p&gt;So  as I already asked, what are the benefits of converting those DICOM  files to PNG&amp;#39;s rather then just using pydicom and the dicom pixel_array?&lt;/p&gt;\n\n&lt;p&gt;Reason I ask this is because I saw many top 5 users on kaggle do this when dealing with DICOM images.&lt;/p&gt;\n\n&lt;p&gt;If  I understand how networks actually works, they get as input an array of  pixels as floating point numbers no? So what&amp;#39;s the differences between  DICOM pixel_array to PNG&amp;#39;s pixel array and numpy array or tensor? both  are eventually will be fed to the network as a tensor of floating  numbers.&lt;/p&gt;\n\n&lt;p&gt;Is the reason is because PNG&amp;#39;s are usually faster to train?&lt;/p&gt;\n\n&lt;p&gt;Is the reason is because PNG&amp;#39;s have more libraries support for preprocessing / augmentation / etc. ?&lt;/p&gt;\n\n&lt;p&gt;Is  the reason is because PNG&amp;#39;s are the format many pre-trained models  expect to? (I write this knowing it&amp;#39;s 99% not true, as mentioned the  tensor thing)&lt;/p&gt;\n\n&lt;p&gt;Thanks in Advance, and Please, forgive my English (I could use AI tools to fix it but I feel addicted already)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16y6r61", "is_robot_indexable": true, "report_reasons": null, "author": "01jasper", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y6r61/benefits_of_converting_dicom_images_to_pngs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y6r61/benefits_of_converting_dicom_images_to_pngs/", "subreddit_subscribers": 131870, "created_utc": 1696277029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\n\nI was looking for some advice whether to pursue AWS data analytics cert. I have been in BI field for a while and i have already completed the GCP data engineer cert. At work i don't have enough opportunities to work on GCP . I have done some small pet projects on gcp but not consistently motivated to do these on my own. \n\nWhat is the best way to move ? I always appreciate your advise. \n\n&amp;#x200B;\n\nthanks", "author_fullname": "t2_a1u8biz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS data analytics cert - advise needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y63xd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696275552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;I was looking for some advice whether to pursue AWS data analytics cert. I have been in BI field for a while and i have already completed the GCP data engineer cert. At work i don&amp;#39;t have enough opportunities to work on GCP . I have done some small pet projects on gcp but not consistently motivated to do these on my own. &lt;/p&gt;\n\n&lt;p&gt;What is the best way to move ? I always appreciate your advise. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16y63xd", "is_robot_indexable": true, "report_reasons": null, "author": "Iffy-diffy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y63xd/aws_data_analytics_cert_advise_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y63xd/aws_data_analytics_cert_advise_needed/", "subreddit_subscribers": 131870, "created_utc": 1696275552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I started a job as a Data Entry/ Integration clerk for a manufacturing company, I had an internship as Solution Architect, where I briefly touched upon data pipeline and did a Data analytics bootcamp, but don't have much experience in this regard.\nThe company I'm working is quite small and atm is trying to migrate from a bespoke, old software toward the Microsoft ecosystem. They are bringing in a business analyst and some other people and I have been given charge of the data mapping/ migration, CRM side of things (with support of the BA). I was wondering if any of you have any resource I should consult, and could make this easier.\nSo far I read up some introductiory content\nThank you", "author_fullname": "t2_8v5n5r3my", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any resource useful for data mapping and data migration effort?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y5mcn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696274441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I started a job as a Data Entry/ Integration clerk for a manufacturing company, I had an internship as Solution Architect, where I briefly touched upon data pipeline and did a Data analytics bootcamp, but don&amp;#39;t have much experience in this regard.\nThe company I&amp;#39;m working is quite small and atm is trying to migrate from a bespoke, old software toward the Microsoft ecosystem. They are bringing in a business analyst and some other people and I have been given charge of the data mapping/ migration, CRM side of things (with support of the BA). I was wondering if any of you have any resource I should consult, and could make this easier.\nSo far I read up some introductiory content\nThank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16y5mcn", "is_robot_indexable": true, "report_reasons": null, "author": "Zabadabadoodles", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y5mcn/any_resource_useful_for_data_mapping_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y5mcn/any_resource_useful_for_data_mapping_and_data/", "subreddit_subscribers": 131870, "created_utc": 1696274441.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}