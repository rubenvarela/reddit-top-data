{"kind": "Listing", "data": {"after": "t3_16xylzj", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For me: I was pushed to use FiveTran and from there the pain started, our simple infra became complicated. Took me almost 8 months to convince my boss to replace that with ELT approach where sink to S3 -&gt; dbt-&gt;Redshift", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tool, you regret buying or deploying in the data infrastructure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xxu15", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 55, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 55, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696256235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For me: I was pushed to use FiveTran and from there the pain started, our simple infra became complicated. Took me almost 8 months to convince my boss to replace that with ELT approach where sink to S3 -&amp;gt; dbt-&amp;gt;Redshift&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xxu15", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 84, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xxu15/any_tool_you_regret_buying_or_deploying_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xxu15/any_tool_you_regret_buying_or_deploying_in_the/", "subreddit_subscribers": 131778, "created_utc": 1696256235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working at a company that is trying to make a push for I4.0. Whether or not you think thats a buzzword, there are tons of companies making the push towards smart manufacturing. My question, is it worth it?\n\nMaybe it is only because we are new to it and I'm not seeing the full benefits but cost of collection (sensors, PLCs, etc) is often expensive. If you want production data to be captured constantly (good counts, scrap counts, etc.) you need redundant networking/power.\n\nMoving data to the cloud is unbelievably expensive at this volume and SCADAs/Historians are equally expensive. The hardware requires highly skilled employees to set up and maintain the system.\n\nAll this for managerial metrics and the ability to root cause faster? Maybe if you're good enough get some predictive maintenance?\n\nTo the others in the industry, is this all worth it? Have you seen the value add at your own job?", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To those that work in manufacturing, do you believe IoT (and heavy collection of manufacturing data) is a fad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xyt26", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696258506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working at a company that is trying to make a push for I4.0. Whether or not you think thats a buzzword, there are tons of companies making the push towards smart manufacturing. My question, is it worth it?&lt;/p&gt;\n\n&lt;p&gt;Maybe it is only because we are new to it and I&amp;#39;m not seeing the full benefits but cost of collection (sensors, PLCs, etc) is often expensive. If you want production data to be captured constantly (good counts, scrap counts, etc.) you need redundant networking/power.&lt;/p&gt;\n\n&lt;p&gt;Moving data to the cloud is unbelievably expensive at this volume and SCADAs/Historians are equally expensive. The hardware requires highly skilled employees to set up and maintain the system.&lt;/p&gt;\n\n&lt;p&gt;All this for managerial metrics and the ability to root cause faster? Maybe if you&amp;#39;re good enough get some predictive maintenance?&lt;/p&gt;\n\n&lt;p&gt;To the others in the industry, is this all worth it? Have you seen the value add at your own job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xyt26", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xyt26/to_those_that_work_in_manufacturing_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xyt26/to_those_that_work_in_manufacturing_do_you/", "subreddit_subscribers": 131778, "created_utc": 1696258506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So like the title says I started a new job today. Figure out why this report written in R broke 2 months ago. I open up a single file with 6952 lines in it. All that's left of me is a 2 page word dock explaining it the main file that call 3 other files, each with 2-3k lines of R code, to create a single 7 page PDF report from a single data source.\n\nWHAT THE ABSOLUTE HELL AM I LOOKING AT LOL. I don't know R, but it's similar enough to python that I can follow along to get the gist of what it's doing. BUT STILL! WHO NEED 10K+ LINES OF CODE FOR THIS?\n\nShould I tell them it's all bunk and make my case to start from scratch, or just buckle down and learn myself some R to make it work?\n\nEdit:\nSo after further investigation there are 3 major issues.\n\n1: He would comment out old code and leave it in the file. Shout out @Strider_A for the git joke. After deleting all the obvious old code I have taken it down to a total of 5,679 lines of code among 4 files.\n\n1.5: he has multiple SQL queries as strings in file. I could probably just copy paste those to a different file and figure out how R opens and reads files pretty easy.\n\n2: He seems to be allergic to loops or reusable functions. 300 lines of calling the exact same function with the same inputs, but typing out every column name rather than looping through the columns. Or 1000+ lines of the same function copy/pasted with a different name for each column name.\n\n3: assigning variables with hard coded paths to dozens of files rather than walking through the directory.\n\nBonus round: I don't know enough about R to know if this is bad, but like 400 lines of creating 3 tables. Running a few data validation scripts on each column matching regex. Idk this part is probably fineISH.\n\nI might have overreacted to the 10k+ lines. This probably won't be too difficult to figure out. Thanks for all the advice and for joining me in this day 1 freak out.", "author_fullname": "t2_3wxhxt1i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New job. Minor shit show rant, and advice needed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ycoj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696308368.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696290766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So like the title says I started a new job today. Figure out why this report written in R broke 2 months ago. I open up a single file with 6952 lines in it. All that&amp;#39;s left of me is a 2 page word dock explaining it the main file that call 3 other files, each with 2-3k lines of R code, to create a single 7 page PDF report from a single data source.&lt;/p&gt;\n\n&lt;p&gt;WHAT THE ABSOLUTE HELL AM I LOOKING AT LOL. I don&amp;#39;t know R, but it&amp;#39;s similar enough to python that I can follow along to get the gist of what it&amp;#39;s doing. BUT STILL! WHO NEED 10K+ LINES OF CODE FOR THIS?&lt;/p&gt;\n\n&lt;p&gt;Should I tell them it&amp;#39;s all bunk and make my case to start from scratch, or just buckle down and learn myself some R to make it work?&lt;/p&gt;\n\n&lt;p&gt;Edit:\nSo after further investigation there are 3 major issues.&lt;/p&gt;\n\n&lt;p&gt;1: He would comment out old code and leave it in the file. Shout out @Strider_A for the git joke. After deleting all the obvious old code I have taken it down to a total of 5,679 lines of code among 4 files.&lt;/p&gt;\n\n&lt;p&gt;1.5: he has multiple SQL queries as strings in file. I could probably just copy paste those to a different file and figure out how R opens and reads files pretty easy.&lt;/p&gt;\n\n&lt;p&gt;2: He seems to be allergic to loops or reusable functions. 300 lines of calling the exact same function with the same inputs, but typing out every column name rather than looping through the columns. Or 1000+ lines of the same function copy/pasted with a different name for each column name.&lt;/p&gt;\n\n&lt;p&gt;3: assigning variables with hard coded paths to dozens of files rather than walking through the directory.&lt;/p&gt;\n\n&lt;p&gt;Bonus round: I don&amp;#39;t know enough about R to know if this is bad, but like 400 lines of creating 3 tables. Running a few data validation scripts on each column matching regex. Idk this part is probably fineISH.&lt;/p&gt;\n\n&lt;p&gt;I might have overreacted to the 10k+ lines. This probably won&amp;#39;t be too difficult to figure out. Thanks for all the advice and for joining me in this day 1 freak out.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ycoj4", "is_robot_indexable": true, "report_reasons": null, "author": "TrainquilOasis1423", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ycoj4/new_job_minor_shit_show_rant_and_advice_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ycoj4/new_job_minor_shit_show_rant_and_advice_needed/", "subreddit_subscribers": 131778, "created_utc": 1696290766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Goodbye Spark. Hello Polars + Delta Lake.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16xzcqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uoju8UTP0tZAIdqZc3iW3ef3oNtUOsvWrwPRLKKEcso.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696259823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/goodbye-spark-hello-polars-delta", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?auto=webp&amp;s=e585ee336c489e1e9d450ed5159b115f114faf2a", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e5c6d53daaae3bdf1918e25f3f0270fc6dc7f597", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aa672a15ff78edbc9baca55c9808ad1f74530570", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=754d2c0745079122b89f58f096f81dd3529333b2", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=233e82aa2321f7d05735593d9a37da1064b50bc0", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=91e26d7ce3a240db9569e53c0674a9b3db878065", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=69f818883fada4b287989c118a7cd66802bf6540", "width": 1080, "height": 540}], "variants": {}, "id": "PURvM--d-7MgOYB6-qnYgEtr-OWAeVREK0gXETFQvXQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xzcqx", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xzcqx/goodbye_spark_hello_polars_delta_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/goodbye-spark-hello-polars-delta", "subreddit_subscribers": 131778, "created_utc": 1696259823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just looking for a bit of feedback on this matter. \n\nI just started in a new company, and 2 weeks in I was assigned to a new project. The project consists of fetching data from a known CRM Rest API, which have a good amount of documentation. Based on a  list of abstracts, my task was to find a proper endpoint for each table, and develop the code to fetch everything needed and save raw files in S3, while validating against a schema. \n\nI was given 1 month to develop everything alone, except the Terraform script for the infrastructure. Basic documentation, CI CD, docker image generation and upload to registry, Python coding with logging and memory leak safeguards. \n\nI thought it was hard but achievable. But when the scope changed everything derailed. The change was with additional level of detail of some datasets. \n\nThe project is being delivered 2 weeks late, and I'm getting a negative feedback because of the delay. \n\nI feel that I worked a lot to get that done on time, and I can't see where I could have done better. Specially being so new to the company and getting used to the processes and people. \n\nIs 6 weeks too much time for a project this big? Is the company asking too much of me?", "author_fullname": "t2_hcybngxl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Rant about my new job. I need a bit of insight from other DEs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y2nwa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696285739.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696267625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just looking for a bit of feedback on this matter. &lt;/p&gt;\n\n&lt;p&gt;I just started in a new company, and 2 weeks in I was assigned to a new project. The project consists of fetching data from a known CRM Rest API, which have a good amount of documentation. Based on a  list of abstracts, my task was to find a proper endpoint for each table, and develop the code to fetch everything needed and save raw files in S3, while validating against a schema. &lt;/p&gt;\n\n&lt;p&gt;I was given 1 month to develop everything alone, except the Terraform script for the infrastructure. Basic documentation, CI CD, docker image generation and upload to registry, Python coding with logging and memory leak safeguards. &lt;/p&gt;\n\n&lt;p&gt;I thought it was hard but achievable. But when the scope changed everything derailed. The change was with additional level of detail of some datasets. &lt;/p&gt;\n\n&lt;p&gt;The project is being delivered 2 weeks late, and I&amp;#39;m getting a negative feedback because of the delay. &lt;/p&gt;\n\n&lt;p&gt;I feel that I worked a lot to get that done on time, and I can&amp;#39;t see where I could have done better. Specially being so new to the company and getting used to the processes and people. &lt;/p&gt;\n\n&lt;p&gt;Is 6 weeks too much time for a project this big? Is the company asking too much of me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16y2nwa", "is_robot_indexable": true, "report_reasons": null, "author": "Gh0sthy1", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y2nwa/rant_about_my_new_job_i_need_a_bit_of_insight/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y2nwa/rant_about_my_new_job_i_need_a_bit_of_insight/", "subreddit_subscribers": 131778, "created_utc": 1696267625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am dealing with small to medium sized customers looking for a basic data warehouse solution for Power BI reports. They generally have several GB up to a maximum of a 100 GB of data to store, and several dozens of users.\n\nFor these small scale solutions, is it really better to use OLAP databases like Synapse, Snowflake, Redshift? It seems like a simple Azure database or PostgreSQL as a service is much cheaper and would offer sufficient performance? Am I missing something?\n\nI have been involved with Snowflake solutions twice before, but in both cases the client had a negative perception of the costs. Or could I configure Snowflake in such a way that it runs cheaply?", "author_fullname": "t2_u2p974i5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I really need an OLAP database for a data warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xzlm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696260420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am dealing with small to medium sized customers looking for a basic data warehouse solution for Power BI reports. They generally have several GB up to a maximum of a 100 GB of data to store, and several dozens of users.&lt;/p&gt;\n\n&lt;p&gt;For these small scale solutions, is it really better to use OLAP databases like Synapse, Snowflake, Redshift? It seems like a simple Azure database or PostgreSQL as a service is much cheaper and would offer sufficient performance? Am I missing something?&lt;/p&gt;\n\n&lt;p&gt;I have been involved with Snowflake solutions twice before, but in both cases the client had a negative perception of the costs. Or could I configure Snowflake in such a way that it runs cheaply?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xzlm4", "is_robot_indexable": true, "report_reasons": null, "author": "MarcScripts", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xzlm4/do_i_really_need_an_olap_database_for_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xzlm4/do_i_really_need_an_olap_database_for_a_data/", "subreddit_subscribers": 131778, "created_utc": 1696260420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting Started with Airflow for Beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16xw41s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Getting Started with Airflow for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xUKIL7zsjos/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16xw41s", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IfZ7wJhL9utiPsC-TD-zD8lu-CTQx4ysaSk8Sv6M6fA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696251805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/xUKIL7zsjos", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?auto=webp&amp;s=57532a9798dd0f63f82f98e6bdad2b089b1be608", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa7e8c5e146fd23eb95bfc63815b710a803be4e6", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=15475b8c73de173bfc254994ecfb17fcdb78c882", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=40b1b167450b074097af8c9efc000061a07aed17", "width": 320, "height": 240}], "variants": {}, "id": "LmI8hdoYDnBSx0i5v80cfgwiuAE39fOk0kw_zg9f3lw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xw41s", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xw41s/getting_started_with_airflow_for_beginners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/xUKIL7zsjos", "subreddit_subscribers": 131778, "created_utc": 1696251805.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Getting Started with Airflow for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xUKIL7zsjos/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello Everyone,\n\nI'm an Industrial Engineer that has been working on data for the last couple of years. 1 year as a Data Analyst and almost 2 years as an Analytics Specialist. I ended up on this area by learning on my own and getting some certifications (also there wasn't as much analysts as there are now).\n\nAnyways, as it happens to a lot, my position is kind of ambiguous and I personally would define it as an ETL and dashboard developer. I create initial queries using SQL and then transform the data using Alteryx and feed it to a tableau or power BI dashboard that I create.  \nA regular workflow could have 10 different EDW sources and a couple of excel files. The initial data is generally around 400M records and ends of being 100K - 4M record. So I have to prepare the data for myself to use later.\n\nI want to get deeper into the Data engineering part of it and eventually look for data engineer jobs, I started my research today to determine the next logical steps but depending on the source, the suggestions are very different. I would like to study a masters eventually but I can\u00b4t do it right now.\n\nSo, my question is: In your opinion and taking into account your personal experience and preferences and **without saying \"it depends\"**, given my described background. which tool/software/process do you think would be the most valuable to learn to be competitive?\n\nAlso, if you know of a good youtube video that explains what it actually is to be a data engineer, it would be appreciated, most of the content I saw seemed like it was made by a 20 yr old influencer trying to get likes.", "author_fullname": "t2_38po62bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Transitioning from Analytics Specialist to Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y5790", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696273467.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m an Industrial Engineer that has been working on data for the last couple of years. 1 year as a Data Analyst and almost 2 years as an Analytics Specialist. I ended up on this area by learning on my own and getting some certifications (also there wasn&amp;#39;t as much analysts as there are now).&lt;/p&gt;\n\n&lt;p&gt;Anyways, as it happens to a lot, my position is kind of ambiguous and I personally would define it as an ETL and dashboard developer. I create initial queries using SQL and then transform the data using Alteryx and feed it to a tableau or power BI dashboard that I create.&lt;br/&gt;\nA regular workflow could have 10 different EDW sources and a couple of excel files. The initial data is generally around 400M records and ends of being 100K - 4M record. So I have to prepare the data for myself to use later.&lt;/p&gt;\n\n&lt;p&gt;I want to get deeper into the Data engineering part of it and eventually look for data engineer jobs, I started my research today to determine the next logical steps but depending on the source, the suggestions are very different. I would like to study a masters eventually but I can\u00b4t do it right now.&lt;/p&gt;\n\n&lt;p&gt;So, my question is: In your opinion and taking into account your personal experience and preferences and &lt;strong&gt;without saying &amp;quot;it depends&amp;quot;&lt;/strong&gt;, given my described background. which tool/software/process do you think would be the most valuable to learn to be competitive?&lt;/p&gt;\n\n&lt;p&gt;Also, if you know of a good youtube video that explains what it actually is to be a data engineer, it would be appreciated, most of the content I saw seemed like it was made by a 20 yr old influencer trying to get likes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16y5790", "is_robot_indexable": true, "report_reasons": null, "author": "Esteban_Rdz", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y5790/transitioning_from_analytics_specialist_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y5790/transitioning_from_analytics_specialist_to_data/", "subreddit_subscribers": 131778, "created_utc": 1696273467.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey, Any data engineers working remotely from Asia in US/EU based companies? I had some doubts \n\n\\-How did you get the remote job? It'd be helpful if you guys can share method you followed, websites on which you applied etc \n\n\\-What is the tech stack you are working?\n\n\\-What is the YOE and salary range?  \n\n\\-What was the interview process like?\n\n&amp;#x200B;\n\nI have create my profile in Turing, cleared the test as well and now I'm waiting to be matched. \n\nMy tech stack\n\n\\-Strong skillset in Python, SQL and PL/SQL\n\n\\-Good understanding in Spark, GCP, Hive and HDFS, Informatica (ETL tool)\n\n\\-I have also basic understanding of Airflow.\n\n&amp;#x200B;", "author_fullname": "t2_knqp3qus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to land remote Data Engineering jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yjnuf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696311460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, Any data engineers working remotely from Asia in US/EU based companies? I had some doubts &lt;/p&gt;\n\n&lt;p&gt;-How did you get the remote job? It&amp;#39;d be helpful if you guys can share method you followed, websites on which you applied etc &lt;/p&gt;\n\n&lt;p&gt;-What is the tech stack you are working?&lt;/p&gt;\n\n&lt;p&gt;-What is the YOE and salary range?  &lt;/p&gt;\n\n&lt;p&gt;-What was the interview process like?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have create my profile in Turing, cleared the test as well and now I&amp;#39;m waiting to be matched. &lt;/p&gt;\n\n&lt;p&gt;My tech stack&lt;/p&gt;\n\n&lt;p&gt;-Strong skillset in Python, SQL and PL/SQL&lt;/p&gt;\n\n&lt;p&gt;-Good understanding in Spark, GCP, Hive and HDFS, Informatica (ETL tool)&lt;/p&gt;\n\n&lt;p&gt;-I have also basic understanding of Airflow.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16yjnuf", "is_robot_indexable": true, "report_reasons": null, "author": "Mad-Sweeneyy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yjnuf/how_to_land_remote_data_engineering_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yjnuf/how_to_land_remote_data_engineering_jobs/", "subreddit_subscribers": 131778, "created_utc": 1696311460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say we have a column called previous_order_id that gives the order_id of the previous customer for a given order. It is defined as (using snowflake):\n\n    lag(order_id, 1, 0) over (partition by customer_id order by created_at asc) as previous_email_id\n\nHow would we test the values are correct? \n\nI guess in general, if we generate a SQL based report, how do we know the report has generated the correct values? Aside from testing nulls, accepted values etc.", "author_fullname": "t2_ske3s9us", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing complex logic of SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y0fcs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696262318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say we have a column called previous_order_id that gives the order_id of the previous customer for a given order. It is defined as (using snowflake):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;lag(order_id, 1, 0) over (partition by customer_id order by created_at asc) as previous_email_id\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;How would we test the values are correct? &lt;/p&gt;\n\n&lt;p&gt;I guess in general, if we generate a SQL based report, how do we know the report has generated the correct values? Aside from testing nulls, accepted values etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16y0fcs", "is_robot_indexable": true, "report_reasons": null, "author": "iamanoob38", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y0fcs/testing_complex_logic_of_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y0fcs/testing_complex_logic_of_sql/", "subreddit_subscribers": 131778, "created_utc": 1696262318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an s3 bucket with about 5+ million JSON files loaded per day (across our different client folders).\n\n* clientA - 9/25 - 120k files\n* clientB - 9/25 - 1.2M files  (1 file per userid)\n\neach JSON is small &lt; 10kb each.\n\nI have to retrieve a couple key-value pairs from the json and export it back to a new s3 bucket (combined). so from 1.2M files, the output should maybe be &lt;50 files in parquet/csv format.\n\n* example: extract these fields from JSON\n   * \"activated\": true and \"userid\": 123\n* expected results: tabular parquet/csv file\n   * activated, userid\n\n|activated|userid|\n|:-|:-|\n|true|123|\n|false|456|\n\nthis only needs to run once per day (batch).\n\n**current environment:**\n\nHybrid - SQL Server on-prem and Airflow (on-prem) and Redshift, primarily. we actually need to load this to SQL Server but we can use Redshift as a  processing middle-man if we need to.\n\nwe have the option of using Glue/Spark.\n\n**rough plan**\n\n1. glue job using pyspark to read the files for the previous day\n2. parse the json to get what we need\n3. export it back out to another s3 bucket  in gzipped csv\n   1. each brand will get its own folder of exported files\n\nAny ideas on this approach?\n\n* is there a way to trigger the glue job for a specific day (if we wanted to rerun a day?)\n* it'd be nice if there's an error that it can alert but continue with the other clients (non-blocking)\n\nWe don't have an EMR cluster (don't really have a need). I realize we can use EMR Serverless as well. Perhaps we can use that with our on-prem Airflow instance instead\n\n**Another option -**\n\n1. use Redshift's COPY command and [JSONPaths filters](https://docs.aws.amazon.com/redshift/latest/dg/copy-usage_notes-copy-from-json.html) to load the s3 files to a staging table on Redshift\n2. Then UNLOAD the entire table (all the records) to csv so it can be imported into SQL Server\n   1. this has the benefit of being \"free\" since our cluster is always running.\n\nOption 3:\n\n* use aws athena\n\n&amp;#x200B;\n\n&amp;#x200B;\n\nedit: updated post with some more details.\n\n&amp;#x200B;", "author_fullname": "t2_3yozg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question about using Glue/Spark to process millions of JSON files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y7wpn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696284082.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696279632.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an s3 bucket with about 5+ million JSON files loaded per day (across our different client folders).&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;clientA - 9/25 - 120k files&lt;/li&gt;\n&lt;li&gt;clientB - 9/25 - 1.2M files  (1 file per userid)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;each JSON is small &amp;lt; 10kb each.&lt;/p&gt;\n\n&lt;p&gt;I have to retrieve a couple key-value pairs from the json and export it back to a new s3 bucket (combined). so from 1.2M files, the output should maybe be &amp;lt;50 files in parquet/csv format.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;example: extract these fields from JSON\n\n&lt;ul&gt;\n&lt;li&gt;&amp;quot;activated&amp;quot;: true and &amp;quot;userid&amp;quot;: 123&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;expected results: tabular parquet/csv file\n\n&lt;ul&gt;\n&lt;li&gt;activated, userid&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"left\"&gt;activated&lt;/th&gt;\n&lt;th align=\"left\"&gt;userid&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;true&lt;/td&gt;\n&lt;td align=\"left\"&gt;123&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"left\"&gt;false&lt;/td&gt;\n&lt;td align=\"left\"&gt;456&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;this only needs to run once per day (batch).&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;current environment:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Hybrid - SQL Server on-prem and Airflow (on-prem) and Redshift, primarily. we actually need to load this to SQL Server but we can use Redshift as a  processing middle-man if we need to.&lt;/p&gt;\n\n&lt;p&gt;we have the option of using Glue/Spark.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;rough plan&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;glue job using pyspark to read the files for the previous day&lt;/li&gt;\n&lt;li&gt;parse the json to get what we need&lt;/li&gt;\n&lt;li&gt;export it back out to another s3 bucket  in gzipped csv\n\n&lt;ol&gt;\n&lt;li&gt;each brand will get its own folder of exported files&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any ideas on this approach?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;is there a way to trigger the glue job for a specific day (if we wanted to rerun a day?)&lt;/li&gt;\n&lt;li&gt;it&amp;#39;d be nice if there&amp;#39;s an error that it can alert but continue with the other clients (non-blocking)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;We don&amp;#39;t have an EMR cluster (don&amp;#39;t really have a need). I realize we can use EMR Serverless as well. Perhaps we can use that with our on-prem Airflow instance instead&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Another option -&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;use Redshift&amp;#39;s COPY command and &lt;a href=\"https://docs.aws.amazon.com/redshift/latest/dg/copy-usage_notes-copy-from-json.html\"&gt;JSONPaths filters&lt;/a&gt; to load the s3 files to a staging table on Redshift&lt;/li&gt;\n&lt;li&gt;Then UNLOAD the entire table (all the records) to csv so it can be imported into SQL Server\n\n&lt;ol&gt;\n&lt;li&gt;this has the benefit of being &amp;quot;free&amp;quot; since our cluster is always running.&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Option 3:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;use aws athena&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;edit: updated post with some more details.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16y7wpn", "is_robot_indexable": true, "report_reasons": null, "author": "gman1023", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y7wpn/question_about_using_gluespark_to_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y7wpn/question_about_using_gluespark_to_process/", "subreddit_subscribers": 131778, "created_utc": 1696279632.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I am comfortable with setting up a pipeline, it runs more or less as I expect but I am not really confident when it comes to configure it, automate to the fullest, parametrize, orchestrate maybe, so all the MS docs and most of youtube/udemy tackles the topic vaguely, just letting you dip the toes and while it'll make you know the tool, it doesnt make you being independent. Now I landed on client site, created some pipelines and need to make them config driven, so there is no further development at UAT's, it should be prone to any changes, additions etc. Are there any prototypes/projects with descriptions, where those things have been discussed in depth, ETL configs etc? Or some blog posts? Thank you in advance", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get good at config driven pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xuvb6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696248221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I am comfortable with setting up a pipeline, it runs more or less as I expect but I am not really confident when it comes to configure it, automate to the fullest, parametrize, orchestrate maybe, so all the MS docs and most of youtube/udemy tackles the topic vaguely, just letting you dip the toes and while it&amp;#39;ll make you know the tool, it doesnt make you being independent. Now I landed on client site, created some pipelines and need to make them config driven, so there is no further development at UAT&amp;#39;s, it should be prone to any changes, additions etc. Are there any prototypes/projects with descriptions, where those things have been discussed in depth, ETL configs etc? Or some blog posts? Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xuvb6", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xuvb6/how_to_get_good_at_config_driven_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xuvb6/how_to_get_good_at_config_driven_pipelines/", "subreddit_subscribers": 131778, "created_utc": 1696248221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I\u2019ve been working as a DE for 1.5 years. I\u2019ve touched on some cloud, some ci/cd, lots of ETL and some database design. I enjoy the work but it seems to me that each DE job is sort of like this. Is this it? Do I just make pipelines until I hit senior or manager or am I missing something? Like there\u2019s always work to be done and although we implement interesting solutions, no one really cares instead they ask for delivery dates or why the data is wrong. I\u2019ve seen this across 2 teams, does DE not get recognition? \n\nLike I enjoy the work day to day but when I look at what I do or am creating, it just doesn\u2019t seem impactful compared to other SWE roles like cloud/security/infra. \n\nI\u2019m looking to switch jobs and next job will be more analytics focused (tableau/ETL). After working though I don\u2019t know what my progression will be, like what does a senior / engineer manager in data do? How do I get there? Is it fulfilling?\n\nIt\u2019s a loaded question I\u2019m mainly just concerned about the culture &amp; future of DE work and if I made the right choice doing this after graduating with a CS degree.\n\nI\u2019m based in Toronto if that helps", "author_fullname": "t2_7okz25a22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Failing to see impact and progression in DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yhc5t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696303743.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019ve been working as a DE for 1.5 years. I\u2019ve touched on some cloud, some ci/cd, lots of ETL and some database design. I enjoy the work but it seems to me that each DE job is sort of like this. Is this it? Do I just make pipelines until I hit senior or manager or am I missing something? Like there\u2019s always work to be done and although we implement interesting solutions, no one really cares instead they ask for delivery dates or why the data is wrong. I\u2019ve seen this across 2 teams, does DE not get recognition? &lt;/p&gt;\n\n&lt;p&gt;Like I enjoy the work day to day but when I look at what I do or am creating, it just doesn\u2019t seem impactful compared to other SWE roles like cloud/security/infra. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m looking to switch jobs and next job will be more analytics focused (tableau/ETL). After working though I don\u2019t know what my progression will be, like what does a senior / engineer manager in data do? How do I get there? Is it fulfilling?&lt;/p&gt;\n\n&lt;p&gt;It\u2019s a loaded question I\u2019m mainly just concerned about the culture &amp;amp; future of DE work and if I made the right choice doing this after graduating with a CS degree.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m based in Toronto if that helps&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16yhc5t", "is_robot_indexable": true, "report_reasons": null, "author": "Big-Comparison321", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yhc5t/failing_to_see_impact_and_progression_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yhc5t/failing_to_see_impact_and_progression_in_de/", "subreddit_subscribers": 131778, "created_utc": 1696303743.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working in Data for 5 years, the last 2 as DE. During that time I have worked for same number of companies (around 1 year per company)\n\nThe problem for me is that all companies did not really understood what DE is about. Finding this subreddit has been an eye-opener for me also because I am reading all about this cool tools and ideas but I haven't really worked with anything regarding proper DE.\n\nI just recently snatched an opportunity as a Sr DE but to my surprise, the team is more BI that anything else. One person even holds the same title as me but doesn't even know SQL. Plus the company work with external dbs (some systems have their own dbs and we have reader access only). During this time I have only made some queries and helped with some dashboards and that's it. This is almost the same thing that I did on my past company as DE.\n\nI feel that I have a very good SQL, a decent Python and useful knowledge of BI Tools (mostly Tableau and PowerBI) and have a certification on AWS. I also sell myself very good on interviews which I feel has given me a better job opportunity each year. \n\nI often read about tools like dbt, terraform, airflow etc. I kind of know how they work but the reality is that I have not touched any of that.\n\nI really want to give value and to this point in my carreer I really feel that I need to be updating myself but I don't really know how to that without proper exposure. \n\n&amp;#x200B;\n\nAny thoughts on this??", "author_fullname": "t2_gbmtpmgy2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feeling a bit down regarding my DE career", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ye2hm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696294489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working in Data for 5 years, the last 2 as DE. During that time I have worked for same number of companies (around 1 year per company)&lt;/p&gt;\n\n&lt;p&gt;The problem for me is that all companies did not really understood what DE is about. Finding this subreddit has been an eye-opener for me also because I am reading all about this cool tools and ideas but I haven&amp;#39;t really worked with anything regarding proper DE.&lt;/p&gt;\n\n&lt;p&gt;I just recently snatched an opportunity as a Sr DE but to my surprise, the team is more BI that anything else. One person even holds the same title as me but doesn&amp;#39;t even know SQL. Plus the company work with external dbs (some systems have their own dbs and we have reader access only). During this time I have only made some queries and helped with some dashboards and that&amp;#39;s it. This is almost the same thing that I did on my past company as DE.&lt;/p&gt;\n\n&lt;p&gt;I feel that I have a very good SQL, a decent Python and useful knowledge of BI Tools (mostly Tableau and PowerBI) and have a certification on AWS. I also sell myself very good on interviews which I feel has given me a better job opportunity each year. &lt;/p&gt;\n\n&lt;p&gt;I often read about tools like dbt, terraform, airflow etc. I kind of know how they work but the reality is that I have not touched any of that.&lt;/p&gt;\n\n&lt;p&gt;I really want to give value and to this point in my carreer I really feel that I need to be updating myself but I don&amp;#39;t really know how to that without proper exposure. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any thoughts on this??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ye2hm", "is_robot_indexable": true, "report_reasons": null, "author": "hot-bulbasur", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ye2hm/feeling_a_bit_down_regarding_my_de_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ye2hm/feeling_a_bit_down_regarding_my_de_career/", "subreddit_subscribers": 131778, "created_utc": 1696294489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI just started up in a non-DE position at what is essentially a boutique consulting firm that has grown a good bit recently. The company is small enough and the industry is new enough that it is doing well without any sort of data-driven processes or dedicated data team. I\u2019ve relayed my interest in automation and DE, and while I\u2019ve already done some one-off convenience types of things (automating emails, checking calendars in order to create agendas with the Outlook API, etc), I\u2019d love to implement and practice some DE work with this company. Unfortunately, because all of our clients are prospective businesses, there\u2019s no real easy data to collect that I can think of. \n\nLuckily, my boss is all for anything that makes the company better or the work easier, so cost is only a minor issue and I\u2019m encouraged to use my time here as a sort of playground to test things out. Without getting into too many details about the company itself, would anyone have any ideas on general projects to take on while working here? Would love to boost my resume until I can land a more tech-centric gig!", "author_fullname": "t2_2ivpdou", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to practice and implement DE in a non-tech aware company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ya38i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696284512.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I just started up in a non-DE position at what is essentially a boutique consulting firm that has grown a good bit recently. The company is small enough and the industry is new enough that it is doing well without any sort of data-driven processes or dedicated data team. I\u2019ve relayed my interest in automation and DE, and while I\u2019ve already done some one-off convenience types of things (automating emails, checking calendars in order to create agendas with the Outlook API, etc), I\u2019d love to implement and practice some DE work with this company. Unfortunately, because all of our clients are prospective businesses, there\u2019s no real easy data to collect that I can think of. &lt;/p&gt;\n\n&lt;p&gt;Luckily, my boss is all for anything that makes the company better or the work easier, so cost is only a minor issue and I\u2019m encouraged to use my time here as a sort of playground to test things out. Without getting into too many details about the company itself, would anyone have any ideas on general projects to take on while working here? Would love to boost my resume until I can land a more tech-centric gig!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ya38i", "is_robot_indexable": true, "report_reasons": null, "author": "Butterhero_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ya38i/how_to_practice_and_implement_de_in_a_nontech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ya38i/how_to_practice_and_implement_de_in_a_nontech/", "subreddit_subscribers": 131778, "created_utc": 1696284512.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team really likes Sigma and would love to integrate it in our stack but their price is not public which makes me think they just say prices based on their perception of how much a company needs it. So my question is: is Sigma in your stack and how much do you pay for it?", "author_fullname": "t2_axgif", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sigma pricing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y59mv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696273625.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team really likes Sigma and would love to integrate it in our stack but their price is not public which makes me think they just say prices based on their perception of how much a company needs it. So my question is: is Sigma in your stack and how much do you pay for it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16y59mv", "is_robot_indexable": true, "report_reasons": null, "author": "Batto1300", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y59mv/sigma_pricing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y59mv/sigma_pricing/", "subreddit_subscribers": 131778, "created_utc": 1696273625.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nI am running pyspark code on my local machine and trying to understand how to get rid of pyspark warning- 23/10/02 11:31:14 WARN TaskSetManager: Stage 36 contains a task of very large size (2886 KiB). The maximum recommended task size is 1000 KiB.\n\nI read multiple posts suggesting using repartition or parallelize functions. But when I try the repartition function the large size value does not change at all. And I haven't tried parallelize because I do not want the dataframe to convert into RDD.\n\nSo I did a comparing test: \n\nCASE I: Code:\n\n    scada = spark.read.csv('../processed/scada_data.csv') \n    scada.count() \n\nOutput: \n\n    337776 \n\nCASE II: Code:\n\n    test = pd.read_csv('../processed/scada_data.csv') \n    spark_scada = spark.createDataFrame(test) \n    spark_scada.count() \n\nOutput:\n\n    23/10/02 11:31:14 WARN TaskSetManager: Stage 36 contains a task of very large size (2886 KiB). The maximum recommended task size is 1000 KiB. \n    337776 \n\nInterestingly, I do not get the warning when directly reading the csv using pyspark. But if I read it using pandas and then convert it to a spark dataframe, I get the warning. So, just to understand better - If I was to read csv using pandas then convert to spark dataframe (I know I dont have to but just to understand) what can I do to get rid of the warning, like the same way there is no warning when reading directly through pyspark?", "author_fullname": "t2_hywcxnb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyspark question about warning - Stage contains a task of very large size.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y537v", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696273221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am running pyspark code on my local machine and trying to understand how to get rid of pyspark warning- 23/10/02 11:31:14 WARN TaskSetManager: Stage 36 contains a task of very large size (2886 KiB). The maximum recommended task size is 1000 KiB.&lt;/p&gt;\n\n&lt;p&gt;I read multiple posts suggesting using repartition or parallelize functions. But when I try the repartition function the large size value does not change at all. And I haven&amp;#39;t tried parallelize because I do not want the dataframe to convert into RDD.&lt;/p&gt;\n\n&lt;p&gt;So I did a comparing test: &lt;/p&gt;\n\n&lt;p&gt;CASE I: Code:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;scada = spark.read.csv(&amp;#39;../processed/scada_data.csv&amp;#39;) \nscada.count() \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Output: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;337776 \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;CASE II: Code:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;test = pd.read_csv(&amp;#39;../processed/scada_data.csv&amp;#39;) \nspark_scada = spark.createDataFrame(test) \nspark_scada.count() \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Output:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;23/10/02 11:31:14 WARN TaskSetManager: Stage 36 contains a task of very large size (2886 KiB). The maximum recommended task size is 1000 KiB. \n337776 \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Interestingly, I do not get the warning when directly reading the csv using pyspark. But if I read it using pandas and then convert it to a spark dataframe, I get the warning. So, just to understand better - If I was to read csv using pandas then convert to spark dataframe (I know I dont have to but just to understand) what can I do to get rid of the warning, like the same way there is no warning when reading directly through pyspark?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16y537v", "is_robot_indexable": true, "report_reasons": null, "author": "Glittering_Role_8051", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y537v/pyspark_question_about_warning_stage_contains_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y537v/pyspark_question_about_warning_stage_contains_a/", "subreddit_subscribers": 131778, "created_utc": 1696273221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineers - Backbone of MDS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16yf8wu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/4zNY8SJjG0uF5uSb-XaNvehId38x1Rawzto3oaYlnx0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696297757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/tygyfvt28wrb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/tygyfvt28wrb1.jpg?auto=webp&amp;s=e8af4c5dbbe32d1730afe9e93356407e8d287e80", "width": 832, "height": 418}, "resolutions": [{"url": "https://preview.redd.it/tygyfvt28wrb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a0524687244a4c5a47f25e20ec06d54ad6d9249e", "width": 108, "height": 54}, {"url": "https://preview.redd.it/tygyfvt28wrb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8fbcccdd0c92d285a19469b36df9e842316153b1", "width": 216, "height": 108}, {"url": "https://preview.redd.it/tygyfvt28wrb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=946ddaed54f027f76cd85ef2c0254c1f4251e92b", "width": 320, "height": 160}, {"url": "https://preview.redd.it/tygyfvt28wrb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5700636714e2788765207720260f1cfcd276cd93", "width": 640, "height": 321}], "variants": {}, "id": "jViKEmiyM67RCQbJtmI7F5AOIWKL15ioGaTkD-Zmc4c"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "16yf8wu", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yf8wu/data_engineers_backbone_of_mds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/tygyfvt28wrb1.jpg", "subreddit_subscribers": 131778, "created_utc": 1696297757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working on a personal project so that I can try data flows from an iot device to the data platform. My project looks like this:\n\n\\- esp32 dht11 sensor creates temperature and humidity data and sends them to aws iot core\n\n\\- aws iot core routes the received data to the aws sqs\n\n\\- confluent kafka consumes data from aws sqs using the sqs source connector\n\n\\- reads data from confluent kafka from a databricks cluster using structured spark streaming and sinks into a raw table\n\n\\- use a spark streaming to read from the raw table and merge into the curated table real-time\n\nI will have all the processed documented so that I can use it for my portfolio but wanted to get some feedback whether this architecture sounds about the right track.\n\nThanks in advance!", "author_fullname": "t2_86pd6cgg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are services used in my personal project for my portfolio look okay?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y9a7i", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696282576.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a personal project so that I can try data flows from an iot device to the data platform. My project looks like this:&lt;/p&gt;\n\n&lt;p&gt;- esp32 dht11 sensor creates temperature and humidity data and sends them to aws iot core&lt;/p&gt;\n\n&lt;p&gt;- aws iot core routes the received data to the aws sqs&lt;/p&gt;\n\n&lt;p&gt;- confluent kafka consumes data from aws sqs using the sqs source connector&lt;/p&gt;\n\n&lt;p&gt;- reads data from confluent kafka from a databricks cluster using structured spark streaming and sinks into a raw table&lt;/p&gt;\n\n&lt;p&gt;- use a spark streaming to read from the raw table and merge into the curated table real-time&lt;/p&gt;\n\n&lt;p&gt;I will have all the processed documented so that I can use it for my portfolio but wanted to get some feedback whether this architecture sounds about the right track.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16y9a7i", "is_robot_indexable": true, "report_reasons": null, "author": "EmploymentMammoth659", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y9a7i/are_services_used_in_my_personal_project_for_my/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y9a7i/are_services_used_in_my_personal_project_for_my/", "subreddit_subscribers": 131778, "created_utc": 1696282576.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_b4zj70tb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Key Takeaways from the Airflow Summit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_16y7wc0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/LR4EfZH-sc9Wz8IojsO1My9nxqpzX3ybBTFmpkf6Xlo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696279609.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "astronomer.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.astronomer.io/blog/3-key-takeaways-from-airflow-summit-2023/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/j3000RlQ5ObpU0PjMLmcjoq2LuJ7RVZS8Px-bWyb5Pw.jpg?auto=webp&amp;s=9bef9c36a4e1b1ee27fecaac8baaa6e008912a81", "width": 2560, "height": 1440}, "resolutions": [{"url": "https://external-preview.redd.it/j3000RlQ5ObpU0PjMLmcjoq2LuJ7RVZS8Px-bWyb5Pw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=40d045a1f2d1a49d70e385c40de0489f0380c7a5", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/j3000RlQ5ObpU0PjMLmcjoq2LuJ7RVZS8Px-bWyb5Pw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8953bdaa4d2c41eb5e1c97dcfbf98bfd99447168", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/j3000RlQ5ObpU0PjMLmcjoq2LuJ7RVZS8Px-bWyb5Pw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=14ca71627375bedb10316da0c4478692391b5837", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/j3000RlQ5ObpU0PjMLmcjoq2LuJ7RVZS8Px-bWyb5Pw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=10b5467271821ad9ad46f4f61201df82128a46bf", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/j3000RlQ5ObpU0PjMLmcjoq2LuJ7RVZS8Px-bWyb5Pw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8bd6686b27d6ebacaba582d645c06f758ceb3e01", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/j3000RlQ5ObpU0PjMLmcjoq2LuJ7RVZS8Px-bWyb5Pw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=a0792607b118b06943a1f3dc0a327ed1b63f94cd", "width": 1080, "height": 607}], "variants": {}, "id": "UXbJzLPxY6sjkwyfRExYOUI1Dx5zKMnjyJnEPiCTdwA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16y7wc0", "is_robot_indexable": true, "report_reasons": null, "author": "fritz-astronomer", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y7wc0/key_takeaways_from_the_airflow_summit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.astronomer.io/blog/3-key-takeaways-from-airflow-summit-2023/", "subreddit_subscribers": 131778, "created_utc": 1696279609.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " I try to understand what are the benefits to convert DICOM images to PNG's.  \nContext:  \nI have DICOM images which I already extracted the useful meta-data I want to use.  \nThose images are for a task, classification-detection pipeline of some disease.\n\nSo  as I already asked, what are the benefits of converting those DICOM  files to PNG's rather then just using pydicom and the dicom pixel\\_array?\n\nReason I ask this is because I saw many top 5 users on kaggle do this when dealing with DICOM images.\n\nIf  I understand how networks actually works, they get as input an array of  pixels as floating point numbers no? So what's the differences between  DICOM pixel\\_array to PNG's pixel array and numpy array or tensor? both  are eventually will be fed to the network as a tensor of floating  numbers.\n\nIs the reason is because PNG's are usually faster to train?\n\nIs the reason is because PNG's have more libraries support for preprocessing / augmentation / etc. ?\n\nIs  the reason is because PNG's are the format many pre-trained models  expect to? (I write this knowing it's 99% not true, as mentioned the  tensor thing)\n\nThanks in Advance, and Please, forgive my English (I could use AI tools to fix it but I feel addicted already)", "author_fullname": "t2_5vngcus6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benefits of converting DICOM images to PNG's", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y6r61", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696277029.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I try to understand what are the benefits to convert DICOM images to PNG&amp;#39;s.&lt;br/&gt;\nContext:&lt;br/&gt;\nI have DICOM images which I already extracted the useful meta-data I want to use.&lt;br/&gt;\nThose images are for a task, classification-detection pipeline of some disease.&lt;/p&gt;\n\n&lt;p&gt;So  as I already asked, what are the benefits of converting those DICOM  files to PNG&amp;#39;s rather then just using pydicom and the dicom pixel_array?&lt;/p&gt;\n\n&lt;p&gt;Reason I ask this is because I saw many top 5 users on kaggle do this when dealing with DICOM images.&lt;/p&gt;\n\n&lt;p&gt;If  I understand how networks actually works, they get as input an array of  pixels as floating point numbers no? So what&amp;#39;s the differences between  DICOM pixel_array to PNG&amp;#39;s pixel array and numpy array or tensor? both  are eventually will be fed to the network as a tensor of floating  numbers.&lt;/p&gt;\n\n&lt;p&gt;Is the reason is because PNG&amp;#39;s are usually faster to train?&lt;/p&gt;\n\n&lt;p&gt;Is the reason is because PNG&amp;#39;s have more libraries support for preprocessing / augmentation / etc. ?&lt;/p&gt;\n\n&lt;p&gt;Is  the reason is because PNG&amp;#39;s are the format many pre-trained models  expect to? (I write this knowing it&amp;#39;s 99% not true, as mentioned the  tensor thing)&lt;/p&gt;\n\n&lt;p&gt;Thanks in Advance, and Please, forgive my English (I could use AI tools to fix it but I feel addicted already)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16y6r61", "is_robot_indexable": true, "report_reasons": null, "author": "01jasper", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y6r61/benefits_of_converting_dicom_images_to_pngs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y6r61/benefits_of_converting_dicom_images_to_pngs/", "subreddit_subscribers": 131778, "created_utc": 1696277029.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\n\nI was looking for some advice whether to pursue AWS data analytics cert. I have been in BI field for a while and i have already completed the GCP data engineer cert. At work i don't have enough opportunities to work on GCP . I have done some small pet projects on gcp but not consistently motivated to do these on my own. \n\nWhat is the best way to move ? I always appreciate your advise. \n\n&amp;#x200B;\n\nthanks", "author_fullname": "t2_a1u8biz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS data analytics cert - advise needed", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y63xd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696275552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;I was looking for some advice whether to pursue AWS data analytics cert. I have been in BI field for a while and i have already completed the GCP data engineer cert. At work i don&amp;#39;t have enough opportunities to work on GCP . I have done some small pet projects on gcp but not consistently motivated to do these on my own. &lt;/p&gt;\n\n&lt;p&gt;What is the best way to move ? I always appreciate your advise. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16y63xd", "is_robot_indexable": true, "report_reasons": null, "author": "Iffy-diffy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y63xd/aws_data_analytics_cert_advise_needed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y63xd/aws_data_analytics_cert_advise_needed/", "subreddit_subscribers": 131778, "created_utc": 1696275552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I started a job as a Data Entry/ Integration clerk for a manufacturing company, I had an internship as Solution Architect, where I briefly touched upon data pipeline and did a Data analytics bootcamp, but don't have much experience in this regard.\nThe company I'm working is quite small and atm is trying to migrate from a bespoke, old software toward the Microsoft ecosystem. They are bringing in a business analyst and some other people and I have been given charge of the data mapping/ migration, CRM side of things (with support of the BA). I was wondering if any of you have any resource I should consult, and could make this easier.\nSo far I read up some introductiory content\nThank you", "author_fullname": "t2_8v5n5r3my", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any resource useful for data mapping and data migration effort?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y5mcn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696274441.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I started a job as a Data Entry/ Integration clerk for a manufacturing company, I had an internship as Solution Architect, where I briefly touched upon data pipeline and did a Data analytics bootcamp, but don&amp;#39;t have much experience in this regard.\nThe company I&amp;#39;m working is quite small and atm is trying to migrate from a bespoke, old software toward the Microsoft ecosystem. They are bringing in a business analyst and some other people and I have been given charge of the data mapping/ migration, CRM side of things (with support of the BA). I was wondering if any of you have any resource I should consult, and could make this easier.\nSo far I read up some introductiory content\nThank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16y5mcn", "is_robot_indexable": true, "report_reasons": null, "author": "Zabadabadoodles", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y5mcn/any_resource_useful_for_data_mapping_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y5mcn/any_resource_useful_for_data_mapping_and_data/", "subreddit_subscribers": 131778, "created_utc": 1696274441.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our organisation is looking to migrate spark +EMR stack to alternative stack due to horrible implementation that has caused a lot of downtime. One of the solution that we are discussing is Nifi + dbt + Redshift. I have looked into Nifi but on first glance documentation seems very limited and I don\u2019t find extensive implementation tutorials. \n\nHave anyone used this tool in n production and how was your experience? \n\nAny guidelines would help us in decision making.\n\nApologies I\u2019m not a native english speaker", "author_fullname": "t2_nfqnja68", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone using Apache Nifi for production workflows ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16y4eml", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696271603.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our organisation is looking to migrate spark +EMR stack to alternative stack due to horrible implementation that has caused a lot of downtime. One of the solution that we are discussing is Nifi + dbt + Redshift. I have looked into Nifi but on first glance documentation seems very limited and I don\u2019t find extensive implementation tutorials. &lt;/p&gt;\n\n&lt;p&gt;Have anyone used this tool in n production and how was your experience? &lt;/p&gt;\n\n&lt;p&gt;Any guidelines would help us in decision making.&lt;/p&gt;\n\n&lt;p&gt;Apologies I\u2019m not a native english speaker&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16y4eml", "is_robot_indexable": true, "report_reasons": null, "author": "pudding0ridden0a", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y4eml/anyone_using_apache_nifi_for_production_workflows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y4eml/anyone_using_apache_nifi_for_production_workflows/", "subreddit_subscribers": 131778, "created_utc": 1696271603.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Economics of a Data Mesh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16xylzj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/asYHsIY2kWUJFwtiE2r846XwB1kMey6DWhbL0qhH6RU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696258006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/hubertdulay/p/the-economics-of-a-data-mesh?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?auto=webp&amp;s=7c34009cf87a9174cefcac1ea03e4e8915ebe8ec", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f32b9a9cd7b57620422d8eda54ea146ef1886234", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=44dd3db79dcc5c718e4c70adedbd3fd157d6c9ed", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=977ed1c2fd28853d7d2cd2955ad926ae1c141923", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c04e0b8d6ca89d0628ba471d9e580492926f8957", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ddb0864bca29658a528df99596a5cf9a251a1efd", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8ff2c7a04498f0549c3bf53b29cc99e9078e8295", "width": 1080, "height": 540}], "variants": {}, "id": "NcNSsLXEhXs6fOgmhbwaZYHPgD_-CjFwtLmWBLgasOU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xylzj", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xylzj/the_economics_of_a_data_mesh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/hubertdulay/p/the-economics-of-a-data-mesh?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 131778, "created_utc": 1696258006.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}