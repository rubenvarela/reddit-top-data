{"kind": "Listing", "data": {"after": "t3_17gmbgv", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In contrast to my previous post, i wanted to ask you guys about the downsides of data engineering. So many people hype it up because of the salary, but whats the reality of being a data engineer? Thanks", "author_fullname": "t2_2r5n0ce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To my data engineers: what do you *not* like about being a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gduz6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698264708.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In contrast to my previous post, i wanted to ask you guys about the downsides of data engineering. So many people hype it up because of the salary, but whats the reality of being a data engineer? Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17gduz6", "is_robot_indexable": true, "report_reasons": null, "author": "naq98", "discussion_type": null, "num_comments": 154, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gduz6/to_my_data_engineers_what_do_you_not_like_about/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gduz6/to_my_data_engineers_what_do_you_not_like_about/", "subreddit_subscribers": 136136, "created_utc": 1698264708.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I thought this project by Anvaka was pretty cool:  \n[https://anvaka.github.io/sayit/?query=dataengineering](https://anvaka.github.io/sayit/?query=dataengineering)\n\nhttps://preview.redd.it/hpl8c4wxzdwb1.png?width=926&amp;format=png&amp;auto=webp&amp;s=32eba2842d196c68915490492913e6df3b787cea", "author_fullname": "t2_pl4q8ng7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where data engineers hang out on Reddit", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 118, "top_awarded_type": null, "hide_score": false, "media_metadata": {"hpl8c4wxzdwb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 70, "x": 108, "u": "https://preview.redd.it/hpl8c4wxzdwb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f18cf4237cfdf2ed84e4fb0c632737fd5b61dd76"}, {"y": 141, "x": 216, "u": "https://preview.redd.it/hpl8c4wxzdwb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b64ef83417e1e45915551b92a974b1a6d0882789"}, {"y": 210, "x": 320, "u": "https://preview.redd.it/hpl8c4wxzdwb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=698a1acb8b64f14eecca00b49d0e562bd3506cda"}, {"y": 420, "x": 640, "u": "https://preview.redd.it/hpl8c4wxzdwb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=a0a9282f093b2efbe976feb00ad900cb603f267a"}], "s": {"y": 608, "x": 926, "u": "https://preview.redd.it/hpl8c4wxzdwb1.png?width=926&amp;format=png&amp;auto=webp&amp;s=32eba2842d196c68915490492913e6df3b787cea"}, "id": "hpl8c4wxzdwb1"}}, "name": "t3_17gaqpq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/_84AkyxMEfq9dPQmbQAtgc-Wi8iv-dKGdGMIPyhmWWQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1698256380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I thought this project by Anvaka was pretty cool:&lt;br/&gt;\n&lt;a href=\"https://anvaka.github.io/sayit/?query=dataengineering\"&gt;https://anvaka.github.io/sayit/?query=dataengineering&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/hpl8c4wxzdwb1.png?width=926&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=32eba2842d196c68915490492913e6df3b787cea\"&gt;https://preview.redd.it/hpl8c4wxzdwb1.png?width=926&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=32eba2842d196c68915490492913e6df3b787cea&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/iU-gZF9Q6oLDAAgE2M6tYRKKbV2U92ci6JWGsXTkxv0.jpg?auto=webp&amp;s=a23b0412b77111bb6ea939abefb35a1def2e131e", "width": 1712, "height": 1448}, "resolutions": [{"url": "https://external-preview.redd.it/iU-gZF9Q6oLDAAgE2M6tYRKKbV2U92ci6JWGsXTkxv0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6f7eaf1d30026c5d4f194d43601de927a6f8e98b", "width": 108, "height": 91}, {"url": "https://external-preview.redd.it/iU-gZF9Q6oLDAAgE2M6tYRKKbV2U92ci6JWGsXTkxv0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7e00dc8eecdc4693de2804f9521e4cc9e8c3db16", "width": 216, "height": 182}, {"url": "https://external-preview.redd.it/iU-gZF9Q6oLDAAgE2M6tYRKKbV2U92ci6JWGsXTkxv0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2a8e20e84dcb6e502e1cbf6008531c0ba66ed47e", "width": 320, "height": 270}, {"url": "https://external-preview.redd.it/iU-gZF9Q6oLDAAgE2M6tYRKKbV2U92ci6JWGsXTkxv0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=192cca37d0e6ae1e22d8f29c33dbf6b81cc20764", "width": 640, "height": 541}, {"url": "https://external-preview.redd.it/iU-gZF9Q6oLDAAgE2M6tYRKKbV2U92ci6JWGsXTkxv0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ae6040375adb17a76d29a88ac103a1029066b0c0", "width": 960, "height": 811}, {"url": "https://external-preview.redd.it/iU-gZF9Q6oLDAAgE2M6tYRKKbV2U92ci6JWGsXTkxv0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c72fc98a00190b007fc770739d3e205711561e77", "width": 1080, "height": 913}], "variants": {}, "id": "sKZVCz4_R-jSodtclLt-OBW_BuUObldDB1sSMcBLAF0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17gaqpq", "is_robot_indexable": true, "report_reasons": null, "author": "droppedorphan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gaqpq/where_data_engineers_hang_out_on_reddit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gaqpq/where_data_engineers_hang_out_on_reddit/", "subreddit_subscribers": 136136, "created_utc": 1698256380.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello fellow DEs, thank you for taking the time to read my message, and I truly value any response you may provide.\n\nI'll keep my message concise. I work as a DE, and our team comprises three DEs and one Architect. We conduct weekly data tech meetings to discuss our ongoing tasks and address any technical queries.\n\nRecently, one of the DEs made direct changes to the main branch, disrupting the git automation I had established. To prevent future issues, I addressed this matter during our data tech meeting, emphasizing the importance of vigilance in our work practices. I undertook the responsibility to resolve the issue, which was a repetition of a previous incident caused by the same DE. I had approached him privately via Teams to discuss this matter before.\n\nFollowing my address, there was a noticeable silence for about 20-30 seconds, creating an awkward atmosphere.This has led me to question whether I should have brought up the issue during the meeting. Did I make a mistake, or was discussing it in the meeting the correct course of action?", "author_fullname": "t2_2lpjnuf3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please help me know if I did the right thing.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17geey5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698266186.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello fellow DEs, thank you for taking the time to read my message, and I truly value any response you may provide.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ll keep my message concise. I work as a DE, and our team comprises three DEs and one Architect. We conduct weekly data tech meetings to discuss our ongoing tasks and address any technical queries.&lt;/p&gt;\n\n&lt;p&gt;Recently, one of the DEs made direct changes to the main branch, disrupting the git automation I had established. To prevent future issues, I addressed this matter during our data tech meeting, emphasizing the importance of vigilance in our work practices. I undertook the responsibility to resolve the issue, which was a repetition of a previous incident caused by the same DE. I had approached him privately via Teams to discuss this matter before.&lt;/p&gt;\n\n&lt;p&gt;Following my address, there was a noticeable silence for about 20-30 seconds, creating an awkward atmosphere.This has led me to question whether I should have brought up the issue during the meeting. Did I make a mistake, or was discussing it in the meeting the correct course of action?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17geey5", "is_robot_indexable": true, "report_reasons": null, "author": "asdhjhjf", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17geey5/please_help_me_know_if_i_did_the_right_thing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17geey5/please_help_me_know_if_i_did_the_right_thing/", "subreddit_subscribers": 136136, "created_utc": 1698266186.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone transitioned from DE to Product Management? Or vice versa? How has your experience been?", "author_fullname": "t2_1reibdu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE to Product Management", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gbczz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698258048.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone transitioned from DE to Product Management? Or vice versa? How has your experience been?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17gbczz", "is_robot_indexable": true, "report_reasons": null, "author": "luckykanwar", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gbczz/de_to_product_management/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gbczz/de_to_product_management/", "subreddit_subscribers": 136136, "created_utc": 1698258048.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Essentially, I fumbled into a DE job at a large commodities company. The department always hired external consultants. But it wasn\u2019t successful. Their solution was converting civil/materials engineers to manage their Data. It was easier to have a Civil engineer learn how to data engineer than vice versa. \n\nI was an external hire. I don\u2019t have coding experience. There is no data team, so essentially, I and another guy with a similar background. From what we have, it is a vendor database and gets transcribed into an internal database, mainly using SQL views. Then, the data gets connected to powerbi using a gateway. \n\nMy coworker set up a Linux server to run automated scripts to update the internal database. \n\nMost of the work is building Power BI reports and ensuring the scripts run. \n\nI\u2019m getting the hunch that my work isn\u2019t natural DE, and I\u2019m worried I won\u2019t be able to move forward.  I also don\u2019t have a team to learn from. \n\nWhat\u2019s the best way to get the most out of this role? \n\nIs it realistic to teach myself and use that to move forward, or would I be teaching myself bad habits?", "author_fullname": "t2_pcaci", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stumbled into DE job. Not sure if the work I do is developing actually competencies.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gavez", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698256731.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Essentially, I fumbled into a DE job at a large commodities company. The department always hired external consultants. But it wasn\u2019t successful. Their solution was converting civil/materials engineers to manage their Data. It was easier to have a Civil engineer learn how to data engineer than vice versa. &lt;/p&gt;\n\n&lt;p&gt;I was an external hire. I don\u2019t have coding experience. There is no data team, so essentially, I and another guy with a similar background. From what we have, it is a vendor database and gets transcribed into an internal database, mainly using SQL views. Then, the data gets connected to powerbi using a gateway. &lt;/p&gt;\n\n&lt;p&gt;My coworker set up a Linux server to run automated scripts to update the internal database. &lt;/p&gt;\n\n&lt;p&gt;Most of the work is building Power BI reports and ensuring the scripts run. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m getting the hunch that my work isn\u2019t natural DE, and I\u2019m worried I won\u2019t be able to move forward.  I also don\u2019t have a team to learn from. &lt;/p&gt;\n\n&lt;p&gt;What\u2019s the best way to get the most out of this role? &lt;/p&gt;\n\n&lt;p&gt;Is it realistic to teach myself and use that to move forward, or would I be teaching myself bad habits?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17gavez", "is_robot_indexable": true, "report_reasons": null, "author": "I-was_thinking", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gavez/stumbled_into_de_job_not_sure_if_the_work_i_do_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gavez/stumbled_into_de_job_not_sure_if_the_work_i_do_is/", "subreddit_subscribers": 136136, "created_utc": 1698256731.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a website like leetcode to practice pyspark ? Or is there any website with good amount of question and solutions related to pyspark ?", "author_fullname": "t2_6jeofkw8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a Leetcode for Pyspark to practice coding tests ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gqx0w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698305008.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a website like leetcode to practice pyspark ? Or is there any website with good amount of question and solutions related to pyspark ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17gqx0w", "is_robot_indexable": true, "report_reasons": null, "author": "itsPranil", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gqx0w/is_there_a_leetcode_for_pyspark_to_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gqx0w/is_there_a_leetcode_for_pyspark_to_practice/", "subreddit_subscribers": 136136, "created_utc": 1698305008.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What role is it if I have to make sure that data is ingested from erp systems to data lake (using ADF) and then load that data in databricks as a row data into bronze layer.And curate to silver and gold by building sql views and finishing up with pbi reports. Is not it a mix of DE and BI?", "author_fullname": "t2_56g5f4cg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What role is it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gpevp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698298586.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What role is it if I have to make sure that data is ingested from erp systems to data lake (using ADF) and then load that data in databricks as a row data into bronze layer.And curate to silver and gold by building sql views and finishing up with pbi reports. Is not it a mix of DE and BI?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17gpevp", "is_robot_indexable": true, "report_reasons": null, "author": "9gg6", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gpevp/what_role_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gpevp/what_role_is_it/", "subreddit_subscribers": 136136, "created_utc": 1698298586.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "First time post.\n\nAsk: I need help with understanding my orgs tech stack requirements for a datalake. \n\nContext: I am not an engineer but have a strong analytics background. My org is trying to build our datalake. We're rather 'simple' in that we have \\~10 TB of data coming from 15 sources which 13 have native integrations with BigQuery. We're trying to run this all on Google products due to some finance decision.  We do not have any DE on the team as of now. I am the sole engineer, scientist, analyst, and owner of this.  \n\nWe've received bids from various dev shops charging anywhere from $30k - $360k to build the datalake. I've done some leg work trying to understand what tools/products we even need. No one has helped us build a clean list. \n\nFrom my research (which I can use your help with). \n\n1. Google Fusion as the no-code ETL (est. $20k / year) \n2. Google BigQuery ($10k / year)\n3. Google Looker Pro ($75k / year)\n4. 3 tools = $105k year. Hopefully I am way over estimating here\n\nAm I tripping that it could be this short list? ", "author_fullname": "t2_a6u3e8u6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "GCP Datalake Tech Stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gdcvu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698263370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First time post.&lt;/p&gt;\n\n&lt;p&gt;Ask: I need help with understanding my orgs tech stack requirements for a datalake. &lt;/p&gt;\n\n&lt;p&gt;Context: I am not an engineer but have a strong analytics background. My org is trying to build our datalake. We&amp;#39;re rather &amp;#39;simple&amp;#39; in that we have ~10 TB of data coming from 15 sources which 13 have native integrations with BigQuery. We&amp;#39;re trying to run this all on Google products due to some finance decision.  We do not have any DE on the team as of now. I am the sole engineer, scientist, analyst, and owner of this.  &lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve received bids from various dev shops charging anywhere from $30k - $360k to build the datalake. I&amp;#39;ve done some leg work trying to understand what tools/products we even need. No one has helped us build a clean list. &lt;/p&gt;\n\n&lt;p&gt;From my research (which I can use your help with). &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Google Fusion as the no-code ETL (est. $20k / year) &lt;/li&gt;\n&lt;li&gt;Google BigQuery ($10k / year)&lt;/li&gt;\n&lt;li&gt;Google Looker Pro ($75k / year)&lt;/li&gt;\n&lt;li&gt;3 tools = $105k year. Hopefully I am way over estimating here&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Am I tripping that it could be this short list? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17gdcvu", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Brain-3524", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gdcvu/gcp_datalake_tech_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gdcvu/gcp_datalake_tech_stack/", "subreddit_subscribers": 136136, "created_utc": 1698263370.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I created a video covering 5 Azure Data Factory best practices. I am planning to create a part two and would like to hear your thoughts on Azure Data Factory best practices.\n\nIn my video I cover these 5 topics:\n\n1. Naming conventions\n2. Activity retry\n3. Activity timeout\n4. Pipeline concurrency\n5. Iterative pipelines\n\n&amp;#x200B;\n\nHere is link to my video if you would like to check it out:\n\n[https://youtu.be/Mf\\_W6ENjnAY](https://youtu.be/Mf_W6ENjnAY)", "author_fullname": "t2_u9bnox3q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Your Azure Data Factory Best Practices?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gdbe1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698263513.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698263255.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I created a video covering 5 Azure Data Factory best practices. I am planning to create a part two and would like to hear your thoughts on Azure Data Factory best practices.&lt;/p&gt;\n\n&lt;p&gt;In my video I cover these 5 topics:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Naming conventions&lt;/li&gt;\n&lt;li&gt;Activity retry&lt;/li&gt;\n&lt;li&gt;Activity timeout&lt;/li&gt;\n&lt;li&gt;Pipeline concurrency&lt;/li&gt;\n&lt;li&gt;Iterative pipelines&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here is link to my video if you would like to check it out:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/Mf_W6ENjnAY\"&gt;https://youtu.be/Mf_W6ENjnAY&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7UCV8k-RcUHi9T8SBk_CvkF5VaHHYPv2VOluztEK7AE.jpg?auto=webp&amp;s=601be843a526384a3f6d345fc47cb702777f15c3", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/7UCV8k-RcUHi9T8SBk_CvkF5VaHHYPv2VOluztEK7AE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ee90fcd7b041908387bfc4dafcbb72c64c81ce33", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/7UCV8k-RcUHi9T8SBk_CvkF5VaHHYPv2VOluztEK7AE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=07ca5f3d949b97e2bfbc1eb5bcccf636345d848a", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/7UCV8k-RcUHi9T8SBk_CvkF5VaHHYPv2VOluztEK7AE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=78825852515fff53dae553eee74e8950e02938f7", "width": 320, "height": 240}], "variants": {}, "id": "MmnxL7bsBm84lyXbHkRv8e7HVaGNs3zeCBS4aiOyjJ4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17gdbe1", "is_robot_indexable": true, "report_reasons": null, "author": "aleks1ck", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gdbe1/your_azure_data_factory_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gdbe1/your_azure_data_factory_best_practices/", "subreddit_subscribers": 136136, "created_utc": 1698263255.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently exploring the concept of a data lake house, and I'm eager to embark on the journey of constructing a modest data lake house to gain a comprehensive understanding of the process. My intention is to create one from the ground up, without using platforms like AWS, Azure, or GCS. I would greatly appreciate any guidance or recommendations on how to get started with building a small-scale data lake house.  \n\n\nI hope to use opensource applications.\n\n&amp;#x200B;", "author_fullname": "t2_mkmebnbcd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help create a datalake house.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gumky", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698320847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently exploring the concept of a data lake house, and I&amp;#39;m eager to embark on the journey of constructing a modest data lake house to gain a comprehensive understanding of the process. My intention is to create one from the ground up, without using platforms like AWS, Azure, or GCS. I would greatly appreciate any guidance or recommendations on how to get started with building a small-scale data lake house.  &lt;/p&gt;\n\n&lt;p&gt;I hope to use opensource applications.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17gumky", "is_robot_indexable": true, "report_reasons": null, "author": "WideIllustrator3260", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gumky/help_create_a_datalake_house/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gumky/help_create_a_datalake_house/", "subreddit_subscribers": 136136, "created_utc": 1698320847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I\u2019m going a little back and fourth in my head for deciding a good base structure for our datalake. Reading the documentation they mention \u201c/in, /out /bad\u201d, also \u201c/sensitive , /general\u201d. These where welcome additions to my thinking. But the documentation also mentionen to look at the \u201corganizational structure\u201d and the \u201csubject matter\u201c. \n\nI worry that the organizational structure will be shooting a bird with a canon and overkill. The subject matter makes more sense to me. But where in the order would it be wise to put it? \nCan someone guide my thoughts on what works and why? \n\nAs an example would a \u201craw/in/general/&lt;subject-matter&gt;/&lt;sub table&gt;/year/month/day\u201d be a good idea?", "author_fullname": "t2_jvtay3bqi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Datalake folder structure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gsxdn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698314161.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I\u2019m going a little back and fourth in my head for deciding a good base structure for our datalake. Reading the documentation they mention \u201c/in, /out /bad\u201d, also \u201c/sensitive , /general\u201d. These where welcome additions to my thinking. But the documentation also mentionen to look at the \u201corganizational structure\u201d and the \u201csubject matter\u201c. &lt;/p&gt;\n\n&lt;p&gt;I worry that the organizational structure will be shooting a bird with a canon and overkill. The subject matter makes more sense to me. But where in the order would it be wise to put it? \nCan someone guide my thoughts on what works and why? &lt;/p&gt;\n\n&lt;p&gt;As an example would a \u201craw/in/general/&amp;lt;subject-matter&amp;gt;/&amp;lt;sub table&amp;gt;/year/month/day\u201d be a good idea?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17gsxdn", "is_robot_indexable": true, "report_reasons": null, "author": "Southern_Version2681", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gsxdn/datalake_folder_structure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gsxdn/datalake_folder_structure/", "subreddit_subscribers": 136136, "created_utc": 1698314161.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_21nis1o2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bytebase v2.10.0 released, Database DevOps &amp; CI/CD tool for engineering teams", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17gstni", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/vTnNnm6b1f_P3_MLHb2H8M_yBcUWC90g0qawPCSwKC4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698313716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bytebase.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.bytebase.com/changelog/bytebase-2-10-0/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/5t4dbm_faxK-wJVMLYG36ULo2cy6M-KRkVEpPhSIzko.jpg?auto=webp&amp;s=7b82d96c9cb424614183cfb5e4866b13183b55d7", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/5t4dbm_faxK-wJVMLYG36ULo2cy6M-KRkVEpPhSIzko.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=96068c473054aa33baafc17e4a7354167a202021", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/5t4dbm_faxK-wJVMLYG36ULo2cy6M-KRkVEpPhSIzko.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1b8d4140819dfe4987119eec4bee5ece524f1422", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/5t4dbm_faxK-wJVMLYG36ULo2cy6M-KRkVEpPhSIzko.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=65c741d1460e348c737c9da4d8089f218283ab15", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/5t4dbm_faxK-wJVMLYG36ULo2cy6M-KRkVEpPhSIzko.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c78299e251d81ff419ce643a7c60be6d9de8c0f8", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/5t4dbm_faxK-wJVMLYG36ULo2cy6M-KRkVEpPhSIzko.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=101bf04f11ad18e24ebfb95719e04c02e2ebd71c", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/5t4dbm_faxK-wJVMLYG36ULo2cy6M-KRkVEpPhSIzko.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5a16561ee9ba4e7361b958525bd211c447e2698c", "width": 1080, "height": 607}], "variants": {}, "id": "wdLfEGz49etGB86umdaBfv9Y_-P5_Z1mFUta_Jk9hMM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17gstni", "is_robot_indexable": true, "report_reasons": null, "author": "placestamphere_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gstni/bytebase_v2100_released_database_devops_cicd_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.bytebase.com/changelog/bytebase-2-10-0/", "subreddit_subscribers": 136136, "created_utc": 1698313716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am a 4th grade cs student. I have backend knowledge. .net and php are popular in the city I live in. I learned PHP. But backend with PHP does not seem like a very impressive career to me. Data engineering seems like a better career. But I'm not sure if it's right for me. I know the best way to understand this is to do a project in that field. It looked interesting in Frontend, but after learning React and doing a few projects, I realized that it was not me. Is there a project or a course that I can do quickly? How can I understand if it is a suitable field for me?  By the way, I have knowledge of Python and SQL.  ", "author_fullname": "t2_kvtdypych", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I know if data engineering is right for me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gsgy8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698312135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a 4th grade cs student. I have backend knowledge. .net and php are popular in the city I live in. I learned PHP. But backend with PHP does not seem like a very impressive career to me. Data engineering seems like a better career. But I&amp;#39;m not sure if it&amp;#39;s right for me. I know the best way to understand this is to do a project in that field. It looked interesting in Frontend, but after learning React and doing a few projects, I realized that it was not me. Is there a project or a course that I can do quickly? How can I understand if it is a suitable field for me?  By the way, I have knowledge of Python and SQL.  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17gsgy8", "is_robot_indexable": true, "report_reasons": null, "author": "Fit-Metal4876", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gsgy8/how_do_i_know_if_data_engineering_is_right_for_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gsgy8/how_do_i_know_if_data_engineering_is_right_for_me/", "subreddit_subscribers": 136136, "created_utc": 1698312135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I find it amusing when banks, insurance providers, asset managers etc. say \u201ctrust us\u201d with your money, when their own employees don\u2019t even trust their own databases!\n\nI\u2019ve seen employees struggling to even tell me which clients are still \u201cactive clients\u201d, finance teams not knowing how much money belongs to our clients and other shenanigans. \n\nThese incidents can be avoided if there were proper controls in place to prevent and detect them - read more about them in the link attached!\n\nFeedback always welcome and let me know if I missed anything!", "author_fullname": "t2_em7bm1wg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10 Controls for Trustworthy Databases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17gs6w3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HVzKJs3QIGlJS552NhT9EzDD4XINmT0EuhS-pcFtl5Y.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698310852.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "fintechnomad.medium.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I find it amusing when banks, insurance providers, asset managers etc. say \u201ctrust us\u201d with your money, when their own employees don\u2019t even trust their own databases!&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve seen employees struggling to even tell me which clients are still \u201cactive clients\u201d, finance teams not knowing how much money belongs to our clients and other shenanigans. &lt;/p&gt;\n\n&lt;p&gt;These incidents can be avoided if there were proper controls in place to prevent and detect them - read more about them in the link attached!&lt;/p&gt;\n\n&lt;p&gt;Feedback always welcome and let me know if I missed anything!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://fintechnomad.medium.com/trust-your-data-with-these-10-controls-71d756c86430", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/aNdXNgtlrGJPP862ki3sTjUN6CATwWZgeZ17amGIN8o.jpg?auto=webp&amp;s=67f82dc39d9490a3081cd68011093750869489a5", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/aNdXNgtlrGJPP862ki3sTjUN6CATwWZgeZ17amGIN8o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9410adb9bad9b66ab4247e7b34dfd48132b7466", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/aNdXNgtlrGJPP862ki3sTjUN6CATwWZgeZ17amGIN8o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=625617a27b54c4aead78d51d24fee3928066103f", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/aNdXNgtlrGJPP862ki3sTjUN6CATwWZgeZ17amGIN8o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ceaab0270085b0cd4a1563cdafefa595d651107", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/aNdXNgtlrGJPP862ki3sTjUN6CATwWZgeZ17amGIN8o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d16ea480122b294f0014c62797250c759faed358", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/aNdXNgtlrGJPP862ki3sTjUN6CATwWZgeZ17amGIN8o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=22232b1c9f1e6466c5995d4793998cb73f2cb5e6", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/aNdXNgtlrGJPP862ki3sTjUN6CATwWZgeZ17amGIN8o.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3d42e26af7efb3575cdc39658a35bec7076ef16d", "width": 1080, "height": 607}], "variants": {}, "id": "o7teyJsV078BaCMe8uqYPc2-Gs1Yr6OiCyNuF0gYc7c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17gs6w3", "is_robot_indexable": true, "report_reasons": null, "author": "FinTechNomad1", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gs6w3/10_controls_for_trustworthy_databases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://fintechnomad.medium.com/trust-your-data-with-these-10-controls-71d756c86430", "subreddit_subscribers": 136136, "created_utc": 1698310852.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The most common architectures I see are\n\n1. raw\n2. stage\n3. edw\n4. datamart\n\nand \n\n1. raw\n2. bronze\n3. silver\n4. gold\n\nRaw data is obviously always organized by source. Ie a model in your database roughly corresponds to a model from the source.\n\nStage, in my experience is just a cleaned up version of the raw data, but no real joining or rearchitecting of objects has happened yet.\n\nBetween stage and EDW, often data flips from being organized by source model to being organized by 'business object', so the models essentially 'invert' via lots of joins from being organized by what source they came from, to what downstream systems they will support.\n\nAt the datamart layer, the models are essentially 1-1 with an outbound query/dashboard/ML-model etc.\n\nI've only described the architectures I've seen - and I don't have a lot of experience with the \"medals\" model. So I'm curious what your experience has been, and how you go about doing the \"inversion\" from source-&gt;target.", "author_fullname": "t2_ofoc42j9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At what level does your data go from being organized by source - to organized by target?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gx3nn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698329704.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698328537.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The most common architectures I see are&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;raw&lt;/li&gt;\n&lt;li&gt;stage&lt;/li&gt;\n&lt;li&gt;edw&lt;/li&gt;\n&lt;li&gt;datamart&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;and &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;raw&lt;/li&gt;\n&lt;li&gt;bronze&lt;/li&gt;\n&lt;li&gt;silver&lt;/li&gt;\n&lt;li&gt;gold&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Raw data is obviously always organized by source. Ie a model in your database roughly corresponds to a model from the source.&lt;/p&gt;\n\n&lt;p&gt;Stage, in my experience is just a cleaned up version of the raw data, but no real joining or rearchitecting of objects has happened yet.&lt;/p&gt;\n\n&lt;p&gt;Between stage and EDW, often data flips from being organized by source model to being organized by &amp;#39;business object&amp;#39;, so the models essentially &amp;#39;invert&amp;#39; via lots of joins from being organized by what source they came from, to what downstream systems they will support.&lt;/p&gt;\n\n&lt;p&gt;At the datamart layer, the models are essentially 1-1 with an outbound query/dashboard/ML-model etc.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve only described the architectures I&amp;#39;ve seen - and I don&amp;#39;t have a lot of experience with the &amp;quot;medals&amp;quot; model. So I&amp;#39;m curious what your experience has been, and how you go about doing the &amp;quot;inversion&amp;quot; from source-&amp;gt;target.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17gx3nn", "is_robot_indexable": true, "report_reasons": null, "author": "PangeanPrawn", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gx3nn/at_what_level_does_your_data_go_from_being/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gx3nn/at_what_level_does_your_data_go_from_being/", "subreddit_subscribers": 136136, "created_utc": 1698328537.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m building Underhive, a collaboration platform for ML Teams. I\u2019ve just put out the first product up which helps you use your own storage backend for Git-LFS.\n\nPlease email me at: support@underhive.in.\nIf you want to help and be one of the first beta clients.\nWe\u2019re also giving free usage for upto 200GBs for the next 6 months to beta clients.\r  \nTry out: https://underhive.in (please use on Desktop, the mobile version is broken right now)", "author_fullname": "t2_6qimiaok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Git Version Controlled Datasets using your own S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "name": "t3_17gweke", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/-bf7Vg5yvQzftXwwfVn-Ex6DpD3CtgCRhdNeTlqQPlo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698326505.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m building Underhive, a collaboration platform for ML Teams. I\u2019ve just put out the first product up which helps you use your own storage backend for Git-LFS.&lt;/p&gt;\n\n&lt;p&gt;Please email me at: &lt;a href=\"mailto:support@underhive.in\"&gt;support@underhive.in&lt;/a&gt;.\nIf you want to help and be one of the first beta clients.\nWe\u2019re also giving free usage for upto 200GBs for the next 6 months to beta clients.&lt;/p&gt;\n\n&lt;p&gt;Try out: &lt;a href=\"https://underhive.in\"&gt;https://underhive.in&lt;/a&gt; (please use on Desktop, the mobile version is broken right now)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/yvqqpo2msjwb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/yvqqpo2msjwb1.jpg?auto=webp&amp;s=9a5ec14280fb1969f9fb7bfe469e0b7371440c40", "width": 1919, "height": 910}, "resolutions": [{"url": "https://preview.redd.it/yvqqpo2msjwb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=328a5d6bf9b8cf4312528a0b7022cd623549f807", "width": 108, "height": 51}, {"url": "https://preview.redd.it/yvqqpo2msjwb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3a0d1efe44bd77f05ab1b75393f74e5f5f044a73", "width": 216, "height": 102}, {"url": "https://preview.redd.it/yvqqpo2msjwb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d91f81f4ae1b97f11ee5327afffb02cac87b10d3", "width": 320, "height": 151}, {"url": "https://preview.redd.it/yvqqpo2msjwb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=72b304f00afa4bfb3c1c3fbe3076ddb857e19509", "width": 640, "height": 303}, {"url": "https://preview.redd.it/yvqqpo2msjwb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=81bbfd2c439bf38ce18caa5e28f9cb74988037f4", "width": 960, "height": 455}, {"url": "https://preview.redd.it/yvqqpo2msjwb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2712591302b668051c2f0195bc0d2e9935ff6b63", "width": 1080, "height": 512}], "variants": {}, "id": "7APKsVCb7Onan7ymmnzRQ0Bc2xYR0fB7gQsZiYVHlJ4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17gweke", "is_robot_indexable": true, "report_reasons": null, "author": "kaisoma", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gweke/git_version_controlled_datasets_using_your_own_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/yvqqpo2msjwb1.jpg", "subreddit_subscribers": 136136, "created_utc": 1698326505.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We\u2019re in the middle of implementing Workday at our org and the consultants in charge are trying to sell us on the idea of using Workday Prism as a replacement for our data lakehouse. Basically move all of our external data into the platform so it can be blended to the HR and Finance stuff stored in Workday.\n\nI have a general distrust for all-in-one platforms that claim point-and-click ETL so easy any business user can do it. Anyone have any experience with Prism they\u2019d care to share?", "author_fullname": "t2_17k8yb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Workday prism experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gj4vr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698278245.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We\u2019re in the middle of implementing Workday at our org and the consultants in charge are trying to sell us on the idea of using Workday Prism as a replacement for our data lakehouse. Basically move all of our external data into the platform so it can be blended to the HR and Finance stuff stored in Workday.&lt;/p&gt;\n\n&lt;p&gt;I have a general distrust for all-in-one platforms that claim point-and-click ETL so easy any business user can do it. Anyone have any experience with Prism they\u2019d care to share?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17gj4vr", "is_robot_indexable": true, "report_reasons": null, "author": "demost11", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gj4vr/workday_prism_experiences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gj4vr/workday_prism_experiences/", "subreddit_subscribers": 136136, "created_utc": 1698278245.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the best practices for storing raw data in an ETL pipeline?", "author_fullname": "t2_ldf4a4fn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Storing raw data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gf79r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698268241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best practices for storing raw data in an ETL pipeline?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17gf79r", "is_robot_indexable": true, "report_reasons": null, "author": "Unhappy-Feedback1851", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gf79r/storing_raw_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gf79r/storing_raw_data/", "subreddit_subscribers": 136136, "created_utc": 1698268241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Vector DB offerings today are structured in such a way that the user is expected to have all files/file embeddings in the same place, and every time a search is effected, the entirety of that pool is queried through.\n\nIf so prepared, a user can do some filtering through metadata tags. However, this feels like a limited and clunky way to reduce the scope of what's queried.\n\nAm I missing something here? Do most use cases call for all files/vectors being kept in the same bucket, as opposed to some other arrangement? What use cases work best with a \"big bucket\" structure in which everything is kept in the same place?", "author_fullname": "t2_9pje88yp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vector DB directory structuring - ideal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gef20", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698266193.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Vector DB offerings today are structured in such a way that the user is expected to have all files/file embeddings in the same place, and every time a search is effected, the entirety of that pool is queried through.&lt;/p&gt;\n\n&lt;p&gt;If so prepared, a user can do some filtering through metadata tags. However, this feels like a limited and clunky way to reduce the scope of what&amp;#39;s queried.&lt;/p&gt;\n\n&lt;p&gt;Am I missing something here? Do most use cases call for all files/vectors being kept in the same bucket, as opposed to some other arrangement? What use cases work best with a &amp;quot;big bucket&amp;quot; structure in which everything is kept in the same place?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17gef20", "is_robot_indexable": true, "report_reasons": null, "author": "LucasSaysHello", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gef20/vector_db_directory_structuring_ideal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gef20/vector_db_directory_structuring_ideal/", "subreddit_subscribers": 136136, "created_utc": 1698266193.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I had 2 yoe as QA analyst, and it pays well but I do have a lot of interest in the Data related fields such as Data Analyst, Data Engineer\n\nI wanted to know if skills and experiences learned during QA are transferable to such Data related fields. And also which is better for me to switch to : Data analyst or Data Engineer?\n\nWould be nice if someone has done a similar transition and can share their story.\n\nAppreciate your help!", "author_fullname": "t2_bpk9d5w9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data analyst or Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gb1ki", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698257172.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had 2 yoe as QA analyst, and it pays well but I do have a lot of interest in the Data related fields such as Data Analyst, Data Engineer&lt;/p&gt;\n\n&lt;p&gt;I wanted to know if skills and experiences learned during QA are transferable to such Data related fields. And also which is better for me to switch to : Data analyst or Data Engineer?&lt;/p&gt;\n\n&lt;p&gt;Would be nice if someone has done a similar transition and can share their story.&lt;/p&gt;\n\n&lt;p&gt;Appreciate your help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17gb1ki", "is_robot_indexable": true, "report_reasons": null, "author": "Zestyclose_Web_6331", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gb1ki/data_analyst_or_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gb1ki/data_analyst_or_data_engineer/", "subreddit_subscribers": 136136, "created_utc": 1698257172.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This may or may not be a little different from the normal career advise posts. I've been a systems engineer and DBA for the last 20+ years in a large org. I supported both backend and frontend Dev-Ops. Everything I done has been on the job. I just learned how to do thing by doing them. I have a bachelors' in cyber security and recently earned a masters' in data science. I still fell like a noob because I can't always explain what I know in interviews. Since getting the MSDS I've felt like I should start over but now I'm think I just need to work on the explanation part of the process and maybe build some projects to show case what I know. I know I can do the work, I just need to prove it. Does this approach sound right? ", "author_fullname": "t2_4byn8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career Advise: Am I thinking this all wrong?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17gzo4q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698335760.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This may or may not be a little different from the normal career advise posts. I&amp;#39;ve been a systems engineer and DBA for the last 20+ years in a large org. I supported both backend and frontend Dev-Ops. Everything I done has been on the job. I just learned how to do thing by doing them. I have a bachelors&amp;#39; in cyber security and recently earned a masters&amp;#39; in data science. I still fell like a noob because I can&amp;#39;t always explain what I know in interviews. Since getting the MSDS I&amp;#39;ve felt like I should start over but now I&amp;#39;m think I just need to work on the explanation part of the process and maybe build some projects to show case what I know. I know I can do the work, I just need to prove it. Does this approach sound right? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17gzo4q", "is_robot_indexable": true, "report_reasons": null, "author": "oldgrumpygeek", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gzo4q/career_advise_am_i_thinking_this_all_wrong/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gzo4q/career_advise_am_i_thinking_this_all_wrong/", "subreddit_subscribers": 136136, "created_utc": 1698335760.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am using spark on databricks and have a delta file in my bronze layer that is ingesting json data using the autoloader, which works great on a schedule. However for my Silver layer I only want to read those new rows in the delta file, but I'm not sure what the best method is. \n\nCurrently I am just using a clunky anti join from the unique identifier which works. I'm not sure what the best practice would be for this and documentation just points to delta live tables which I'm not too keen on. \n\nIs there a way to use the autoloader on delta to delta files to only pick up only new rows? \n\nOr can I pull in as a parameter the last time my task ran and use that to pull all the new rows from that point?", "author_fullname": "t2_4e7vcqz8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incremental Batch Processing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gsih8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698312326.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am using spark on databricks and have a delta file in my bronze layer that is ingesting json data using the autoloader, which works great on a schedule. However for my Silver layer I only want to read those new rows in the delta file, but I&amp;#39;m not sure what the best method is. &lt;/p&gt;\n\n&lt;p&gt;Currently I am just using a clunky anti join from the unique identifier which works. I&amp;#39;m not sure what the best practice would be for this and documentation just points to delta live tables which I&amp;#39;m not too keen on. &lt;/p&gt;\n\n&lt;p&gt;Is there a way to use the autoloader on delta to delta files to only pick up only new rows? &lt;/p&gt;\n\n&lt;p&gt;Or can I pull in as a parameter the last time my task ran and use that to pull all the new rows from that point?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17gsih8", "is_robot_indexable": true, "report_reasons": null, "author": "noodlehead13", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gsih8/incremental_batch_processing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gsih8/incremental_batch_processing/", "subreddit_subscribers": 136136, "created_utc": 1698312326.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I m learning dbt on Snowflake. But I m unable to get a hold of it. Can anyone suggest any video learning series apart from official documentation ?", "author_fullname": "t2_602lxjl2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dbt learning videos with hands on practice?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gsago", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698311295.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I m learning dbt on Snowflake. But I m unable to get a hold of it. Can anyone suggest any video learning series apart from official documentation ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17gsago", "is_robot_indexable": true, "report_reasons": null, "author": "ankititachi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gsago/dbt_learning_videos_with_hands_on_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gsago/dbt_learning_videos_with_hands_on_practice/", "subreddit_subscribers": 136136, "created_utc": 1698311295.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "As the title suggests, I'm just getting started with a basic dbt project locally with Postgres on Docker, and dbt.\n\nWhat struck me when starting doing transformations was that I really miss the IntelliSense that's provided in tools like SSMS. I keep forgetting the syntax for some basic functions (you know, CASE(), CONCAT() etc) and I'd like to get some hints as I write my statements. I know that column autocomplete is not available but have you any tips or tricks with regards to writing jinja-sql in vscode and the syntax highlighting? I've searched for extensions and the only thing that comes close is the mssql one, but since my .sql-files are associated as jinja-sql, this extension doesn't activate.\n\n&amp;#x200B;\n\nAny help much appreciated!", "author_fullname": "t2_2iwhn32y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "VSCode and dbt development with IntelliSense?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gr9mq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698306547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As the title suggests, I&amp;#39;m just getting started with a basic dbt project locally with Postgres on Docker, and dbt.&lt;/p&gt;\n\n&lt;p&gt;What struck me when starting doing transformations was that I really miss the IntelliSense that&amp;#39;s provided in tools like SSMS. I keep forgetting the syntax for some basic functions (you know, CASE(), CONCAT() etc) and I&amp;#39;d like to get some hints as I write my statements. I know that column autocomplete is not available but have you any tips or tricks with regards to writing jinja-sql in vscode and the syntax highlighting? I&amp;#39;ve searched for extensions and the only thing that comes close is the mssql one, but since my .sql-files are associated as jinja-sql, this extension doesn&amp;#39;t activate.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any help much appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17gr9mq", "is_robot_indexable": true, "report_reasons": null, "author": "yeykawb", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gr9mq/vscode_and_dbt_development_with_intellisense/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gr9mq/vscode_and_dbt_development_with_intellisense/", "subreddit_subscribers": 136136, "created_utc": 1698306547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks, I'm currently doing some elt that should feed a dashboard. However i transform my data in Google Big query + dbt at the end of the procesos i have a final table that contains around 1.5 million rows (600 MB).\n\nWhen I try to sync my Big query table into on-premise server with airbyte the Docker compose stucks and a few moments later kill all process.\n\nI have a 16GB ram + r5 3400g. Should i ask to my company for a server with More capacity or I'm doing wrong with the connection in airbyte?\n\nThanks for your support.", "author_fullname": "t2_bvpnqeta", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airbyte troubleshooting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gmbgv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698287762.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, I&amp;#39;m currently doing some elt that should feed a dashboard. However i transform my data in Google Big query + dbt at the end of the procesos i have a final table that contains around 1.5 million rows (600 MB).&lt;/p&gt;\n\n&lt;p&gt;When I try to sync my Big query table into on-premise server with airbyte the Docker compose stucks and a few moments later kill all process.&lt;/p&gt;\n\n&lt;p&gt;I have a 16GB ram + r5 3400g. Should i ask to my company for a server with More capacity or I&amp;#39;m doing wrong with the connection in airbyte?&lt;/p&gt;\n\n&lt;p&gt;Thanks for your support.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17gmbgv", "is_robot_indexable": true, "report_reasons": null, "author": "aaaasd12", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17gmbgv/airbyte_troubleshooting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17gmbgv/airbyte_troubleshooting/", "subreddit_subscribers": 136136, "created_utc": 1698287762.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}