{"kind": "Listing", "data": {"after": "t3_17fzyic", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I see more and more companies requiring drag and drop solutions such as Power BI, Tableau, Alteryx, etc. rather than Python/R/SQL. I don\u2019t know it makes me a bit sad because I feel like drag and drop takes all of the joy out of programming, but I just can\u2019t help but thinking this is the future of many data jobs. Of course companies like OpenAI will be using Python and R and such, but I feel like the majority of data jobs it will be standard to use these drag and drop enterprise solutions. What is everyone\u2019s thoughts?", "author_fullname": "t2_d97itlol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the future of data science drag and drop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g7kqf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 85, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 85, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698248160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see more and more companies requiring drag and drop solutions such as Power BI, Tableau, Alteryx, etc. rather than Python/R/SQL. I don\u2019t know it makes me a bit sad because I feel like drag and drop takes all of the joy out of programming, but I just can\u2019t help but thinking this is the future of many data jobs. Of course companies like OpenAI will be using Python and R and such, but I feel like the majority of data jobs it will be standard to use these drag and drop enterprise solutions. What is everyone\u2019s thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17g7kqf", "is_robot_indexable": true, "report_reasons": null, "author": "cptsanderzz", "discussion_type": null, "num_comments": 115, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g7kqf/is_the_future_of_data_science_drag_and_drop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g7kqf/is_the_future_of_data_science_drag_and_drop/", "subreddit_subscribers": 1099696, "created_utc": 1698248160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I used to work in R markdown. My new job require me to switch to Tableau. I feel like i am downgrade myself from Mercedes Benz to Trabant.  I know because i am intern i should do whatever my company tells me. Just give me reasons why Tableau is good to ease my anxiety", "author_fullname": "t2_3cw1ph2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am intern and i hate Tableau. Can u give some copium?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fzssg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 83, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 83, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698221359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to work in R markdown. My new job require me to switch to Tableau. I feel like i am downgrade myself from Mercedes Benz to Trabant.  I know because i am intern i should do whatever my company tells me. Just give me reasons why Tableau is good to ease my anxiety&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17fzssg", "is_robot_indexable": true, "report_reasons": null, "author": "One_Ad_3499", "discussion_type": null, "num_comments": 74, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17fzssg/i_am_intern_and_i_hate_tableau_can_u_give_some/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17fzssg/i_am_intern_and_i_hate_tableau_can_u_give_some/", "subreddit_subscribers": 1099696, "created_utc": 1698221359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was laid off from my startup in January so I took a job as a principal data scientist at a huge corporation. They exhibit every major red flag I can think of and I'm slowly losing my mind - any tips on how to survive long enough that it looks ok on my resume to leave?\n\nRed flags include:\n\n* No data / inaccessible data / data flying around in Excel\n* Management is not \"ML literate\"\n* More work dealing with red tape than actual work\n* 2x more managers than workers driving projects\n* Business consumers of our ML output do not trust it, and do not want it. They only like linear regression because they understand it\n* No version control. We run everything manually in prod. There is no dev/qa/prod separation. There is no deployment. There is no automation.\n* Because we work directly in prod, we don't have permission to save our processed data to tables or csv's - it must be done in memory every single day\n* No access to basic tools of the trade. We had to beg for basic file storage (s3) for 9 weeks. We can't download unapproved libraries or pre-trained models without security review (even just for exploration)\n\nMy career is jumpy recently - my first few roles were 3-4 years, but my last 2 roles were 1 year-ish, so trying to make it to Feb 2025", "author_fullname": "t2_am698", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to survive at nightmare employer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gfqqp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 67, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 67, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698270328.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698269551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was laid off from my startup in January so I took a job as a principal data scientist at a huge corporation. They exhibit every major red flag I can think of and I&amp;#39;m slowly losing my mind - any tips on how to survive long enough that it looks ok on my resume to leave?&lt;/p&gt;\n\n&lt;p&gt;Red flags include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;No data / inaccessible data / data flying around in Excel&lt;/li&gt;\n&lt;li&gt;Management is not &amp;quot;ML literate&amp;quot;&lt;/li&gt;\n&lt;li&gt;More work dealing with red tape than actual work&lt;/li&gt;\n&lt;li&gt;2x more managers than workers driving projects&lt;/li&gt;\n&lt;li&gt;Business consumers of our ML output do not trust it, and do not want it. They only like linear regression because they understand it&lt;/li&gt;\n&lt;li&gt;No version control. We run everything manually in prod. There is no dev/qa/prod separation. There is no deployment. There is no automation.&lt;/li&gt;\n&lt;li&gt;Because we work directly in prod, we don&amp;#39;t have permission to save our processed data to tables or csv&amp;#39;s - it must be done in memory every single day&lt;/li&gt;\n&lt;li&gt;No access to basic tools of the trade. We had to beg for basic file storage (s3) for 9 weeks. We can&amp;#39;t download unapproved libraries or pre-trained models without security review (even just for exploration)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My career is jumpy recently - my first few roles were 3-4 years, but my last 2 roles were 1 year-ish, so trying to make it to Feb 2025&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17gfqqp", "is_robot_indexable": true, "report_reasons": null, "author": "Mackelday", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gfqqp/how_to_survive_at_nightmare_employer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gfqqp/how_to_survive_at_nightmare_employer/", "subreddit_subscribers": 1099696, "created_utc": 1698269551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Beyond salary which almost everyone requires to survive, how do you maintain motivation in a data role? Specifically when your function is repeatedly called into question and educating the business seems to be an uphill battle? How do you keep going when you have to constantly perform in the corporate popularity contest?\n\nAdditionally, how do you maintain motivation when you're working with a domain that you don't like? Not tolerate, generally don't like. ", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you maintain motivation in your data role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g6gbt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698245141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Beyond salary which almost everyone requires to survive, how do you maintain motivation in a data role? Specifically when your function is repeatedly called into question and educating the business seems to be an uphill battle? How do you keep going when you have to constantly perform in the corporate popularity contest?&lt;/p&gt;\n\n&lt;p&gt;Additionally, how do you maintain motivation when you&amp;#39;re working with a domain that you don&amp;#39;t like? Not tolerate, generally don&amp;#39;t like. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17g6gbt", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g6gbt/how_do_you_maintain_motivation_in_your_data_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g6gbt/how_do_you_maintain_motivation_in_your_data_role/", "subreddit_subscribers": 1099696, "created_utc": 1698245141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " For context, I am a Master's student in CS and lurking in sub has made me realize that CS guys need more statistical background regarding DS positions. Hence, the motivation. However, I am already taking a course called Foundations course which feels like a quick Statistics walkthrough. I am also taking an Automated Learning course which basically follows the ISL contents. This course would be the third one? or the fourth one if I plan to audit this one.\n\nThis is what the course page says : \n\nStudent Learning Outcomes: \n\nMaster the essential tools of convex analysis, ability to characterize solutions to convex optimization problems, ability to formulate standard data science problems as convex optimization problems, and understanding the structure and implementation of the main classes of algorithms for solving optimization problems in data science.\n\nDetailed Content: \n\nIteration principles, fixed-point algorithms, convex sets and convex cones, best approximation paradigms, projection methods in convex feasibility problems \u2013 applications to data fusion and image recovery, convex functions, conjugation of convex functions, duality in convex optimization, subdifferential calculus, subgradient algorithms for convex feasibility and best approximation \u2013 applications in inverse problems, proximity operators, proximal calculus, forward-backward splitting and variants (Dykstra-like methods, Chambolle-Pock algorithm, dual ascent method, etc.), Douglas-Rachford splitting and variants (parallel proximal algorithm, alternating direction method of multipliers, composite primal-dual method, etc.), the monotone + skew decomposition principle \u2013 primal-dual algorithms, proximal modeling of statistical information, proximal information extraction, proximal sparsity enforcement, proximal data classification, proximal principal component analysis, proximal image reconstruction, proximal learning, proximal methods for matrix-based learning, scalability: proximal methods in big data problems, special topics.  \n\n\n  \nI was wondering if this would be something that could help with the day-to-day computations as a DS. I feel like real-world DS is more about optimization and less about using high-end ML/DL techniques. Any thoughts or suggestions?", "author_fullname": "t2_k6fzzm72", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a Convex Optimization class good for Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gc0b4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698259755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I am a Master&amp;#39;s student in CS and lurking in sub has made me realize that CS guys need more statistical background regarding DS positions. Hence, the motivation. However, I am already taking a course called Foundations course which feels like a quick Statistics walkthrough. I am also taking an Automated Learning course which basically follows the ISL contents. This course would be the third one? or the fourth one if I plan to audit this one.&lt;/p&gt;\n\n&lt;p&gt;This is what the course page says : &lt;/p&gt;\n\n&lt;p&gt;Student Learning Outcomes: &lt;/p&gt;\n\n&lt;p&gt;Master the essential tools of convex analysis, ability to characterize solutions to convex optimization problems, ability to formulate standard data science problems as convex optimization problems, and understanding the structure and implementation of the main classes of algorithms for solving optimization problems in data science.&lt;/p&gt;\n\n&lt;p&gt;Detailed Content: &lt;/p&gt;\n\n&lt;p&gt;Iteration principles, fixed-point algorithms, convex sets and convex cones, best approximation paradigms, projection methods in convex feasibility problems \u2013 applications to data fusion and image recovery, convex functions, conjugation of convex functions, duality in convex optimization, subdifferential calculus, subgradient algorithms for convex feasibility and best approximation \u2013 applications in inverse problems, proximity operators, proximal calculus, forward-backward splitting and variants (Dykstra-like methods, Chambolle-Pock algorithm, dual ascent method, etc.), Douglas-Rachford splitting and variants (parallel proximal algorithm, alternating direction method of multipliers, composite primal-dual method, etc.), the monotone + skew decomposition principle \u2013 primal-dual algorithms, proximal modeling of statistical information, proximal information extraction, proximal sparsity enforcement, proximal data classification, proximal principal component analysis, proximal image reconstruction, proximal learning, proximal methods for matrix-based learning, scalability: proximal methods in big data problems, special topics.  &lt;/p&gt;\n\n&lt;p&gt;I was wondering if this would be something that could help with the day-to-day computations as a DS. I feel like real-world DS is more about optimization and less about using high-end ML/DL techniques. Any thoughts or suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "17gc0b4", "is_robot_indexable": true, "report_reasons": null, "author": "VastDragonfruit847", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gc0b4/is_a_convex_optimization_class_good_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gc0b4/is_a_convex_optimization_class_good_for_data/", "subreddit_subscribers": 1099696, "created_utc": 1698259755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know you would have heard so many people asking this question, but please bear with me.\n\nI had worked on a college project where we just implemented 6 different machine learning models (RF, XGB, GLM, DT, Naive Bayes &amp; GBM) on a health care fraud detection dataset to predict fraud. While interacting with an experienced working professional, he told that this is the stupiedest way to go about a problem. He said we have to choose a model which suits our data the most. But I don't know how to go about selelcting a model that suits the data the most because I don't have enough experience to just select any model based on experience and I didn't find any \"algorithm\" which tells me how to do it. I would like to hear from you about how to go on about this silly problem of mine.", "author_fullname": "t2_9llh8x8t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the most suitable model for my problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g8cbj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698250152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know you would have heard so many people asking this question, but please bear with me.&lt;/p&gt;\n\n&lt;p&gt;I had worked on a college project where we just implemented 6 different machine learning models (RF, XGB, GLM, DT, Naive Bayes &amp;amp; GBM) on a health care fraud detection dataset to predict fraud. While interacting with an experienced working professional, he told that this is the stupiedest way to go about a problem. He said we have to choose a model which suits our data the most. But I don&amp;#39;t know how to go about selelcting a model that suits the data the most because I don&amp;#39;t have enough experience to just select any model based on experience and I didn&amp;#39;t find any &amp;quot;algorithm&amp;quot; which tells me how to do it. I would like to hear from you about how to go on about this silly problem of mine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17g8cbj", "is_robot_indexable": true, "report_reasons": null, "author": "jakeblack06", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g8cbj/what_is_the_most_suitable_model_for_my_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g8cbj/what_is_the_most_suitable_model_for_my_problem/", "subreddit_subscribers": 1099696, "created_utc": 1698250152.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently doing some side work for a client that requires creating custom apis and having them run on a server. I am doing it in Google Console. But I noticed that there are so many different features within google console, I was curious if this is essentially a data engineer's life. Learning the  the ins and outs of AWS/Azure/GCS. I feel like it's so different from data science where we focus on concepts vs tools. \n\nOne reason Im curious is if you're the head of an analytics department how do you manage all of this? How would you know how much work something is?", "author_fullname": "t2_3kdgnq0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Cloud Platforms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g8iu2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698250622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently doing some side work for a client that requires creating custom apis and having them run on a server. I am doing it in Google Console. But I noticed that there are so many different features within google console, I was curious if this is essentially a data engineer&amp;#39;s life. Learning the  the ins and outs of AWS/Azure/GCS. I feel like it&amp;#39;s so different from data science where we focus on concepts vs tools. &lt;/p&gt;\n\n&lt;p&gt;One reason Im curious is if you&amp;#39;re the head of an analytics department how do you manage all of this? How would you know how much work something is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17g8iu2", "is_robot_indexable": true, "report_reasons": null, "author": "Jbor941197", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g8iu2/learning_cloud_platforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g8iu2/learning_cloud_platforms/", "subreddit_subscribers": 1099696, "created_utc": 1698250622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\n[ ](https://preview.redd.it/4cikjimrrcwb1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=8aac443256e5e5f18497718aa7d928d143a41b9b)\n\nI've been training this model and what I'm seeing is that after around 100 epochs, the loss of training data goes down, whereas the loss of validation data goes up, which indicates overfitting. However, the accuracy metric for both training and validation data keeps on increasing after around 100 epochs, which indicates that the model is not overfitting.  I've never encountered this before. I assumed that the loss and accuracy metric behaved in somewhat similar manner, but they are not behaving like that in this case. Can anyone explain why this is happening. Is the model overfitting or not?\n\nEdit: I'm using BinaryCrossentropy loss function. The problem I'm trying to solve is from the kaggle's titanic competition. Basically, it's tabular structured data that has features 'TicketClass', 'Name', 'Sex', 'Age', 'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is 'Survived'(1/0). Let me know if you need more info.", "author_fullname": "t2_hcgjj0xo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help understanding if the model here is overfitting or not.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": 48, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4cikjimrrcwb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 37, "x": 108, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7771c425ef8e85b6d0257d24ff7eb2dd6c3f633b"}, {"y": 74, "x": 216, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8a0d072e224adc11e96db3e8c55a7c923bdd4f12"}, {"y": 110, "x": 320, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=306b25854215a1dcd4f8d1e734e8cb762e9fb9b0"}, {"y": 221, "x": 640, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=31b3bdc29a5930780065a694881c62cacf1ddc2f"}, {"y": 331, "x": 960, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d90194b0c01dfa4582192355dc0653ea409462a"}, {"y": 373, "x": 1080, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d31555d54e47b347278ab81e74b9305b216e588f"}], "s": {"y": 534, "x": 1546, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=8aac443256e5e5f18497718aa7d928d143a41b9b"}, "id": "4cikjimrrcwb1"}}, "name": "t3_17g55zm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xtw4EAc8CYsFFqHXS6MxDctZLMU8Ncxdd7yk5ULOV_c.jpg", "edited": 1698242330.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698241481.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4cikjimrrcwb1.png?width=1546&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8aac443256e5e5f18497718aa7d928d143a41b9b\"&gt; &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been training this model and what I&amp;#39;m seeing is that after around 100 epochs, the loss of training data goes down, whereas the loss of validation data goes up, which indicates overfitting. However, the accuracy metric for both training and validation data keeps on increasing after around 100 epochs, which indicates that the model is not overfitting.  I&amp;#39;ve never encountered this before. I assumed that the loss and accuracy metric behaved in somewhat similar manner, but they are not behaving like that in this case. Can anyone explain why this is happening. Is the model overfitting or not?&lt;/p&gt;\n\n&lt;p&gt;Edit: I&amp;#39;m using BinaryCrossentropy loss function. The problem I&amp;#39;m trying to solve is from the kaggle&amp;#39;s titanic competition. Basically, it&amp;#39;s tabular structured data that has features &amp;#39;TicketClass&amp;#39;, &amp;#39;Name&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Age&amp;#39;, &amp;#39;SiblingsBoarded&amp;#39;, &amp;#39;ParentsBoarded&amp;#39;, &amp;#39;Fare&amp;#39;, &amp;#39;Embarked&amp;#39; and target is &amp;#39;Survived&amp;#39;(1/0). Let me know if you need more info.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17g55zm", "is_robot_indexable": true, "report_reasons": null, "author": "Total-Opposite-8396", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g55zm/need_help_understanding_if_the_model_here_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g55zm/need_help_understanding_if_the_model_here_is/", "subreddit_subscribers": 1099696, "created_utc": 1698241481.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Any company size (please include in response if possible).", "author_fullname": "t2_coz8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data scientists reporting to CTO/equivalent (1 step below CEO), what's your job title?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g41qs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698238322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any company size (please include in response if possible).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17g41qs", "is_robot_indexable": true, "report_reasons": null, "author": "honeyplease", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g41qs/data_scientists_reporting_to_ctoequivalent_1_step/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g41qs/data_scientists_reporting_to_ctoequivalent_1_step/", "subreddit_subscribers": 1099696, "created_utc": 1698238322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello folks, I'm working on a medical image dataset using EM loss and asymmetric pseudo labelling for single positive multi-label learning (only training using 1 positive label). I'm using a densenet121 and on a chest x-ray dataset.\n\n1. I see a difference of 10% in my validation vs test score (score = mAP: mean average precision). The score seems okay and was expected but the difference is bothering me. I understand that it's obvious but any visual insights from your side? (Attaching plot below)\n2. The validation set consist less than half of test set samples. (It is the official split; I have nothing to do with it). I feel it is the reason, as ofcourse more the randomness in a set, poorer the convergence.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/nseqy1mw5bwb1.png?width=577&amp;format=png&amp;auto=webp&amp;s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58\n\nDo share any experiences or suggestions!", "author_fullname": "t2_c2ajt49e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[P][R] Test-Val scores, how much difference isn't problematic.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "media_metadata": {"nseqy1mw5bwb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 79, "x": 108, "u": "https://preview.redd.it/nseqy1mw5bwb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=092bc7878e652493ab2260ccf9d6ab2c9bbea107"}, {"y": 159, "x": 216, "u": "https://preview.redd.it/nseqy1mw5bwb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=886f635604373da0bf03a3e7abaf511f21e3ba0c"}, {"y": 236, "x": 320, "u": "https://preview.redd.it/nseqy1mw5bwb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=74d0e6889b44444b1be07e30de9d108a927e935d"}], "s": {"y": 427, "x": 577, "u": "https://preview.redd.it/nseqy1mw5bwb1.png?width=577&amp;format=png&amp;auto=webp&amp;s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58"}, "id": "nseqy1mw5bwb1"}}, "name": "t3_17g01rn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698222484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello folks, I&amp;#39;m working on a medical image dataset using EM loss and asymmetric pseudo labelling for single positive multi-label learning (only training using 1 positive label). I&amp;#39;m using a densenet121 and on a chest x-ray dataset.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;I see a difference of 10% in my validation vs test score (score = mAP: mean average precision). The score seems okay and was expected but the difference is bothering me. I understand that it&amp;#39;s obvious but any visual insights from your side? (Attaching plot below)&lt;/li&gt;\n&lt;li&gt;The validation set consist less than half of test set samples. (It is the official split; I have nothing to do with it). I feel it is the reason, as ofcourse more the randomness in a set, poorer the convergence.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nseqy1mw5bwb1.png?width=577&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58\"&gt;https://preview.redd.it/nseqy1mw5bwb1.png?width=577&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=fbd63e8a5f4920a8109b6a75aeb039a3965bba58&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Do share any experiences or suggestions!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "17g01rn", "is_robot_indexable": true, "report_reasons": null, "author": "ade17_in", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g01rn/pr_testval_scores_how_much_difference_isnt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g01rn/pr_testval_scores_how_much_difference_isnt/", "subreddit_subscribers": 1099696, "created_utc": 1698222484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I currently work for a government contractor. I have an opportunity to take a job with a technology consulting company as a consultant. I am on W2 at the first job and would be on a 1099 for the second. Could the first job still be able to find out about the second?  If I'm doing 20 hrs/wk at the second job, would that still be a problem for employers since I would be able to do it after hours?", "author_fullname": "t2_jnnvdz39c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "having a second job on 1099", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17goc84", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698294457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work for a government contractor. I have an opportunity to take a job with a technology consulting company as a consultant. I am on W2 at the first job and would be on a 1099 for the second. Could the first job still be able to find out about the second?  If I&amp;#39;m doing 20 hrs/wk at the second job, would that still be a problem for employers since I would be able to do it after hours?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17goc84", "is_robot_indexable": true, "report_reasons": null, "author": "daufoi21", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17goc84/having_a_second_job_on_1099/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17goc84/having_a_second_job_on_1099/", "subreddit_subscribers": 1099696, "created_utc": 1698294457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\nI made this little doodle below as a good-faith effort at trying to lay out a reasonable decision tree for choosing an appropriate model evaluation metric for the sort of basic cases of predictive analytics. I'm ignoring numerous more complex cases of like like NLP, Computer Vision, and even arguably some simpler cases like forecasting, but trying to still cover the bulk of the entry gauntlet. There's obviously innumerable choices one could make for metrics, so the bias here is picking ones that are \"less wrong\" (avoid as many pitfalls as possible), fairly interpretable (e.g. a value of 1 or 0 \"means something\"), and have some popular acceptance. Sharing here in case it's helpful, and also I'm interested in others poking holes in the choices I made (if something seems egregious enough)!\n\nMy motivation here was mostly out of internal frustration of often seeing folks (online, friends, colleagues) fall into fairly rough pitfalls in their eval choices, and just seeing whether something like this could be reasonably written out. Not for anything else in a sense than the jollies.\n\nhttps://preview.redd.it/7nplhw2npgwb1.png?width=7162&amp;format=png&amp;auto=webp&amp;s=9bf42afad02bccdb791e88016a78862c7d7faa32", "author_fullname": "t2_9yzncc2e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Evaluation Metric Flowchart (possibly handy, interested in feedback!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7nplhw2npgwb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=030c67234c4f1eab22019470c0c1ca689e587b78"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4778be88b74770c29cfba8eb985952477d7e668d"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2575007f8ef0e519f6657b3807e6a8eef7520277"}, {"y": 356, "x": 640, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6807bc711553c64a5d8a096d501ce856e4c4cb53"}, {"y": 534, "x": 960, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3b91e51da19d7ecac8dd06a18ef275289f9ba9fa"}, {"y": 601, "x": 1080, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3c8caebe3c3b31aa7899791907ab558296754139"}], "s": {"y": 3990, "x": 7162, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=7162&amp;format=png&amp;auto=webp&amp;s=9bf42afad02bccdb791e88016a78862c7d7faa32"}, "id": "7nplhw2npgwb1"}}, "name": "t3_17gn08a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/C6FsdcbioThGINeCCFjlbVQ1pb184byUS-UeLLkTbLs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698289874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I made this little doodle below as a good-faith effort at trying to lay out a reasonable decision tree for choosing an appropriate model evaluation metric for the sort of basic cases of predictive analytics. I&amp;#39;m ignoring numerous more complex cases of like like NLP, Computer Vision, and even arguably some simpler cases like forecasting, but trying to still cover the bulk of the entry gauntlet. There&amp;#39;s obviously innumerable choices one could make for metrics, so the bias here is picking ones that are &amp;quot;less wrong&amp;quot; (avoid as many pitfalls as possible), fairly interpretable (e.g. a value of 1 or 0 &amp;quot;means something&amp;quot;), and have some popular acceptance. Sharing here in case it&amp;#39;s helpful, and also I&amp;#39;m interested in others poking holes in the choices I made (if something seems egregious enough)!&lt;/p&gt;\n\n&lt;p&gt;My motivation here was mostly out of internal frustration of often seeing folks (online, friends, colleagues) fall into fairly rough pitfalls in their eval choices, and just seeing whether something like this could be reasonably written out. Not for anything else in a sense than the jollies.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7nplhw2npgwb1.png?width=7162&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9bf42afad02bccdb791e88016a78862c7d7faa32\"&gt;https://preview.redd.it/7nplhw2npgwb1.png?width=7162&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9bf42afad02bccdb791e88016a78862c7d7faa32&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17gn08a", "is_robot_indexable": true, "report_reasons": null, "author": "jshkk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gn08a/evaluation_metric_flowchart_possibly_handy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gn08a/evaluation_metric_flowchart_possibly_handy/", "subreddit_subscribers": 1099696, "created_utc": 1698289874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m right now coming to the end of my post graduation in data science and how can I proceed from now in order to get a job or an internship? What can be the different methods I can apply. My institute where I\u2019m pursuing right now also promised placement opportunities but I do not want to wait till the end\u2026", "author_fullname": "t2_o9iya5e7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to proceed\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gn7d8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698290490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m right now coming to the end of my post graduation in data science and how can I proceed from now in order to get a job or an internship? What can be the different methods I can apply. My institute where I\u2019m pursuing right now also promised placement opportunities but I do not want to wait till the end\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17gn7d8", "is_robot_indexable": true, "report_reasons": null, "author": "LegitimateAd4716", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gn7d8/how_to_proceed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gn7d8/how_to_proceed/", "subreddit_subscribers": 1099696, "created_utc": 1698290490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have film consumption data and although the natural trend is of a decayed nature certain assets have latent growth and I\u2019m trying to find the best way to read through the noise of the consumption data and generate a forecast. Ideally the algorithm works so that it can be transferred to any new data, rather than just training an ARIMA or fitting a regression for any new film.\n\nLooking for any really good tutorials on models that may help.\n\nThanks", "author_fullname": "t2_ds90qagip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "YouTube or Tutorials on Advanced Time Series?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gmvhs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698289454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have film consumption data and although the natural trend is of a decayed nature certain assets have latent growth and I\u2019m trying to find the best way to read through the noise of the consumption data and generate a forecast. Ideally the algorithm works so that it can be transferred to any new data, rather than just training an ARIMA or fitting a regression for any new film.&lt;/p&gt;\n\n&lt;p&gt;Looking for any really good tutorials on models that may help.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "17gmvhs", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable-Farmer186", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gmvhs/youtube_or_tutorials_on_advanced_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gmvhs/youtube_or_tutorials_on_advanced_time_series/", "subreddit_subscribers": 1099696, "created_utc": 1698289454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have few questions regarding ML batch model and hope someone clarifies them. \n\nI have developed a text classification model.  While testing the model, I used the train_test_split to create test data which was used  to determine the performance of model and then also did hyperparameter tuning to select the best estimator. This helped me determine my best model.\n\nMy questions are- \n\n- Once I have finalized the model, can I train my model on the whole dataset?  And then use this model to predict the new data.\n\n- It\u2019s a batch model and I have to use this model for classification for every 3 months. So, do I have to repeat the whole process(from train_test_split to hyperparameter tuning) to make sure there\u2019s no degradation in model performance?\n\n- How does this works in production? Once I deploy my model trained on the whole dataset, how do we deal with new instances which were not in the historical data? Since this is a batch model, we have to train the model on the recent data if I need to account any new instances( which I currently deal by retraining the model) but I\u2019m not sure how do I do this when the model is in production?\n\nCan anyone please clarify? \nThanks!", "author_fullname": "t2_p657jjww", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ML batch model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gejiw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698266521.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have few questions regarding ML batch model and hope someone clarifies them. &lt;/p&gt;\n\n&lt;p&gt;I have developed a text classification model.  While testing the model, I used the train_test_split to create test data which was used  to determine the performance of model and then also did hyperparameter tuning to select the best estimator. This helped me determine my best model.&lt;/p&gt;\n\n&lt;p&gt;My questions are- &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Once I have finalized the model, can I train my model on the whole dataset?  And then use this model to predict the new data.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;It\u2019s a batch model and I have to use this model for classification for every 3 months. So, do I have to repeat the whole process(from train_test_split to hyperparameter tuning) to make sure there\u2019s no degradation in model performance?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How does this works in production? Once I deploy my model trained on the whole dataset, how do we deal with new instances which were not in the historical data? Since this is a batch model, we have to train the model on the recent data if I need to account any new instances( which I currently deal by retraining the model) but I\u2019m not sure how do I do this when the model is in production?&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Can anyone please clarify? \nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17gejiw", "is_robot_indexable": true, "report_reasons": null, "author": "tinkerpal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gejiw/ml_batch_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gejiw/ml_batch_model/", "subreddit_subscribers": 1099696, "created_utc": 1698266521.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Vector DB offerings today are structured in such a way that the user is expected to have all files/file embeddings in the same place, and every time a search is effected, the entirety of that pool is queried through.\n\nIf so prepared, a user can do some filtering through metadata tags. However, this feels like a limited and clunky way to reduce the scope of what's queried.\n\nAm I missing something here? Do most use cases call for all files/vectors being kept in the same bucket, as opposed to some other arrangement? What use cases work best with a \"big bucket\" structure in which everything is kept in the same place?", "author_fullname": "t2_9pje88yp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vector DB directory structuring - ideal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gej5o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698266491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Vector DB offerings today are structured in such a way that the user is expected to have all files/file embeddings in the same place, and every time a search is effected, the entirety of that pool is queried through.&lt;/p&gt;\n\n&lt;p&gt;If so prepared, a user can do some filtering through metadata tags. However, this feels like a limited and clunky way to reduce the scope of what&amp;#39;s queried.&lt;/p&gt;\n\n&lt;p&gt;Am I missing something here? Do most use cases call for all files/vectors being kept in the same bucket, as opposed to some other arrangement? What use cases work best with a &amp;quot;big bucket&amp;quot; structure in which everything is kept in the same place?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17gej5o", "is_robot_indexable": true, "report_reasons": null, "author": "LucasSaysHello", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gej5o/vector_db_directory_structuring_ideal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gej5o/vector_db_directory_structuring_ideal/", "subreddit_subscribers": 1099696, "created_utc": 1698266491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_v8n3a1nm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vertex AI and the ML Workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_17gdj5r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/QuvPUscW6_M?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Vertex AI and the ML Workflow\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Vertex AI and the ML Workflow", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/QuvPUscW6_M?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Vertex AI and the ML Workflow\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/QuvPUscW6_M/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/QuvPUscW6_M?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Vertex AI and the ML Workflow\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/17gdj5r", "height": 200}, "link_flair_text": "ML", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UglbwEzmGoH6x6X1fj7UmxY8eCEBS723SF_rRVQ0Gho.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698263836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/QuvPUscW6_M?si=ztT87cclfME_8155", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/x_4RfHp_-YzK3n2GnJNhNrbE-x60dX8LdPK2BC42SPQ.jpg?auto=webp&amp;s=893332251d48a32055d059bfa35684dc07de2950", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/x_4RfHp_-YzK3n2GnJNhNrbE-x60dX8LdPK2BC42SPQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b14eb59dba0794e9198fdad37e5f507c9d028c83", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/x_4RfHp_-YzK3n2GnJNhNrbE-x60dX8LdPK2BC42SPQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f0761a384f6a80654c846dd5de759ced87765332", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/x_4RfHp_-YzK3n2GnJNhNrbE-x60dX8LdPK2BC42SPQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25557a0bd982c3a1d7eb1ebf1028916e7df98f36", "width": 320, "height": 240}], "variants": {}, "id": "mtzGT5vBpn8t8bEIjErreC4c4LdRcc_7IfAM3NGHsmQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "17gdj5r", "is_robot_indexable": true, "report_reasons": null, "author": "fancypigollo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gdj5r/vertex_ai_and_the_ml_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/QuvPUscW6_M?si=ztT87cclfME_8155", "subreddit_subscribers": 1099696, "created_utc": 1698263836.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Vertex AI and the ML Workflow", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/QuvPUscW6_M?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Vertex AI and the ML Workflow\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/QuvPUscW6_M/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hey there, fellow data science people,\n\nI'm reaching out for a little help and some advice in my quest to jump into the data science world. I come from a biotech background and have been devouring data science content for the past year, but I'm having a bit of a struggle finding my first gig.\n\nHere's where I need advice. I'm curious about which cloud computing system is currently the talk of the town in the data science universe. With tech evolving fast, I want to make sure I'm learning a cloud platform that'll give me some edge in the job market. I guess the battle is between Azure and AWS, but between those two I dont know what would best to learn if you dont know any.\n\nAnd last but not least, I'm all eyes for recommendations on these cloud computing systems certifications that could beef up my skillset and make me more hireable. \n\nThank you a lot in advance", "author_fullname": "t2_ec0fi5ob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud computing trends in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g9mzj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698253498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, fellow data science people,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out for a little help and some advice in my quest to jump into the data science world. I come from a biotech background and have been devouring data science content for the past year, but I&amp;#39;m having a bit of a struggle finding my first gig.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s where I need advice. I&amp;#39;m curious about which cloud computing system is currently the talk of the town in the data science universe. With tech evolving fast, I want to make sure I&amp;#39;m learning a cloud platform that&amp;#39;ll give me some edge in the job market. I guess the battle is between Azure and AWS, but between those two I dont know what would best to learn if you dont know any.&lt;/p&gt;\n\n&lt;p&gt;And last but not least, I&amp;#39;m all eyes for recommendations on these cloud computing systems certifications that could beef up my skillset and make me more hireable. &lt;/p&gt;\n\n&lt;p&gt;Thank you a lot in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "17g9mzj", "is_robot_indexable": true, "report_reasons": null, "author": "lucasso13", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g9mzj/cloud_computing_trends_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g9mzj/cloud_computing_trends_in_data_science/", "subreddit_subscribers": 1099696, "created_utc": 1698253498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey there. \nWe are going to start working with Google sheets and podio.\nWe wanted to know which tool would be easier to learn and start working with. \nWe are still beginners and we don't have access to paid versions and I got confused searching online.\n\nWhat would be the pros and cons of using each tool. \n\nThanks in advance.", "author_fullname": "t2_e9y297r4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Choosing between google data studio (Looker studio now I guess) and Tableau.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g1rz7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698230230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there. \nWe are going to start working with Google sheets and podio.\nWe wanted to know which tool would be easier to learn and start working with. \nWe are still beginners and we don&amp;#39;t have access to paid versions and I got confused searching online.&lt;/p&gt;\n\n&lt;p&gt;What would be the pros and cons of using each tool. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17g1rz7", "is_robot_indexable": true, "report_reasons": null, "author": "sigma_chungus", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g1rz7/choosing_between_google_data_studio_looker_studio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g1rz7/choosing_between_google_data_studio_looker_studio/", "subreddit_subscribers": 1099696, "created_utc": 1698230230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My employer ran a rather expensive A/B test in its operations. The issue is that they failed to check for SRM and also didn't conduct A/A test beforehand. Now I inherited a test result that is poised with SRM. Due to their test setup, I could run a back A/A test, the result showed no significant difference between control and treatment. We tried to debug the SRM for a few weeks with no luck. I suppose with such SRM, the test results are not reliable. \n\nNow I am stuck between a rock and a hard place. Should we spend more time debugging the SRM or should we accept the cost and redesign and rerun the experiment. Is there a middle ground here?", "author_fullname": "t2_4oockqg5s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A/B test in real life", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17go3pk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698293599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My employer ran a rather expensive A/B test in its operations. The issue is that they failed to check for SRM and also didn&amp;#39;t conduct A/A test beforehand. Now I inherited a test result that is poised with SRM. Due to their test setup, I could run a back A/A test, the result showed no significant difference between control and treatment. We tried to debug the SRM for a few weeks with no luck. I suppose with such SRM, the test results are not reliable. &lt;/p&gt;\n\n&lt;p&gt;Now I am stuck between a rock and a hard place. Should we spend more time debugging the SRM or should we accept the cost and redesign and rerun the experiment. Is there a middle ground here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17go3pk", "is_robot_indexable": true, "report_reasons": null, "author": "furioncruz", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17go3pk/ab_test_in_real_life/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17go3pk/ab_test_in_real_life/", "subreddit_subscribers": 1099696, "created_utc": 1698293599.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2hf1v3a2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get into data science entry level position with an engineering degree?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gnj7i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698291562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17gnj7i", "is_robot_indexable": true, "report_reasons": null, "author": "Nickaroo321", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gnj7i/how_to_get_into_data_science_entry_level_position/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gnj7i/how_to_get_into_data_science_entry_level_position/", "subreddit_subscribers": 1099696, "created_utc": 1698291562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a company page and branding package set up on LinkedIn \u2013 is it in bad taste to list actual personal and pro-bono projects as experience in order to not have a huge employment gap?\n\nSome details: I'm a Data Analyst with CRM consulting experience but currently unemployed since June (layoffs). I have professional work I've created but not yet published (ie. dashboards, architecture frameworks, wireframes, etc.) that I would be publishing under my profile and tagging my company. Some of this work involves working with real-world businesses for free.", "author_fullname": "t2_883ga", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Worthwhile to post personal and pro-bono projects under my company page in order to list experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g7vsr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698248991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a company page and branding package set up on LinkedIn \u2013 is it in bad taste to list actual personal and pro-bono projects as experience in order to not have a huge employment gap?&lt;/p&gt;\n\n&lt;p&gt;Some details: I&amp;#39;m a Data Analyst with CRM consulting experience but currently unemployed since June (layoffs). I have professional work I&amp;#39;ve created but not yet published (ie. dashboards, architecture frameworks, wireframes, etc.) that I would be publishing under my profile and tagging my company. Some of this work involves working with real-world businesses for free.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17g7vsr", "is_robot_indexable": true, "report_reasons": null, "author": "CarbonHero", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g7vsr/worthwhile_to_post_personal_and_probono_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g7vsr/worthwhile_to_post_personal_and_probono_projects/", "subreddit_subscribers": 1099696, "created_utc": 1698248991.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We work in an items per hr setting with 100's of various goals used to get a performance rate per worker. Some items can be worked at 4 per hr while some can be worked at 30 per hr.  The different goals are scattered between 2 to 60 per hr.  We want to reduce these hundreds down to maybe 5 to 10 goals with the workers still being able to reach the goals.  Any ideas how that can be accomplished with data?  Is there some sort of percentage difference that would help categorize them?  Any ideas would be appreciated.", "author_fullname": "t2_m4d1tjfvl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reducing Goals Using Dats", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gkbw1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698281777.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We work in an items per hr setting with 100&amp;#39;s of various goals used to get a performance rate per worker. Some items can be worked at 4 per hr while some can be worked at 30 per hr.  The different goals are scattered between 2 to 60 per hr.  We want to reduce these hundreds down to maybe 5 to 10 goals with the workers still being able to reach the goals.  Any ideas how that can be accomplished with data?  Is there some sort of percentage difference that would help categorize them?  Any ideas would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "17gkbw1", "is_robot_indexable": true, "report_reasons": null, "author": "Time_Law_2659", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gkbw1/reducing_goals_using_dats/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gkbw1/reducing_goals_using_dats/", "subreddit_subscribers": 1099696, "created_utc": 1698281777.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As data scientists some of us used to do a lot of work wrangling masses of unstructured text data (like tweets for example) into insights through various NLP, topic modelling, sentiment analysis, clustering approaches etc. However, ChatGPT seems to perform miles better than any of those older methods with just a UI. So my question is, what is the role of data scientists in insight-driven NLP projects these days if it's not \"advanced prompt engineering\"?", "author_fullname": "t2_4n4wgk9f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The role of data scientists in NLP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fytrb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698216935.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As data scientists some of us used to do a lot of work wrangling masses of unstructured text data (like tweets for example) into insights through various NLP, topic modelling, sentiment analysis, clustering approaches etc. However, ChatGPT seems to perform miles better than any of those older methods with just a UI. So my question is, what is the role of data scientists in insight-driven NLP projects these days if it&amp;#39;s not &amp;quot;advanced prompt engineering&amp;quot;?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17fytrb", "is_robot_indexable": true, "report_reasons": null, "author": "mint_warios", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17fytrb/the_role_of_data_scientists_in_nlp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17fytrb/the_role_of_data_scientists_in_nlp/", "subreddit_subscribers": 1099696, "created_utc": 1698216935.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_x3vk1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Human behaviour is more complex than too much shallow analysis (why you need to dig deeper)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_17fzyic", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.3, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/eqT0iddSDmTb0YUVYZw_vvJa0U1t5EpCaoP_aRwhDgs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698222067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "customerinsightleader.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.customerinsightleader.com/opinion/human-behaviour-is-more-complex-than-too-much-shallow-analysis/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AWMI_sO_jK8FZ0Nd0HWZqICUOKX08ZSZn1cbvj7TT04.jpg?auto=webp&amp;s=339196116cb266c7ee301d9080178623299b7ea4", "width": 2121, "height": 1414}, "resolutions": [{"url": "https://external-preview.redd.it/AWMI_sO_jK8FZ0Nd0HWZqICUOKX08ZSZn1cbvj7TT04.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9172c8e21761c2b6312904e14f10987f4f68d0d3", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/AWMI_sO_jK8FZ0Nd0HWZqICUOKX08ZSZn1cbvj7TT04.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e44ecb3b3fa4d1ca9512264d9760eef5df7210a9", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/AWMI_sO_jK8FZ0Nd0HWZqICUOKX08ZSZn1cbvj7TT04.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=822374d012de4b097b3d426a61fc75eea4ffe6f9", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/AWMI_sO_jK8FZ0Nd0HWZqICUOKX08ZSZn1cbvj7TT04.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d6f75408f4f92460202d5ec4123b67fa7a988df6", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/AWMI_sO_jK8FZ0Nd0HWZqICUOKX08ZSZn1cbvj7TT04.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7ead4f78d131e7771275c973bd1aa2bbac3de989", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/AWMI_sO_jK8FZ0Nd0HWZqICUOKX08ZSZn1cbvj7TT04.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=de5ef91ce59b678b0239ebb173ed738a0c895f38", "width": 1080, "height": 720}], "variants": {}, "id": "AthHClAt7IuKM1OwJ5aZiSDIW-rIZX2eFdPzZigRFAE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17fzyic", "is_robot_indexable": true, "report_reasons": null, "author": "PaulLaughlin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17fzyic/human_behaviour_is_more_complex_than_too_much/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.customerinsightleader.com/opinion/human-behaviour-is-more-complex-than-too-much-shallow-analysis/", "subreddit_subscribers": 1099696, "created_utc": 1698222067.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}