{"kind": "Listing", "data": {"after": "t3_17g7vsr", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I see more and more companies requiring drag and drop solutions such as Power BI, Tableau, Alteryx, etc. rather than Python/R/SQL. I don\u2019t know it makes me a bit sad because I feel like drag and drop takes all of the joy out of programming, but I just can\u2019t help but thinking this is the future of many data jobs. Of course companies like OpenAI will be using Python and R and such, but I feel like the majority of data jobs it will be standard to use these drag and drop enterprise solutions. What is everyone\u2019s thoughts?", "author_fullname": "t2_d97itlol", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the future of data science drag and drop?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g7kqf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 98, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 98, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698248160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I see more and more companies requiring drag and drop solutions such as Power BI, Tableau, Alteryx, etc. rather than Python/R/SQL. I don\u2019t know it makes me a bit sad because I feel like drag and drop takes all of the joy out of programming, but I just can\u2019t help but thinking this is the future of many data jobs. Of course companies like OpenAI will be using Python and R and such, but I feel like the majority of data jobs it will be standard to use these drag and drop enterprise solutions. What is everyone\u2019s thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17g7kqf", "is_robot_indexable": true, "report_reasons": null, "author": "cptsanderzz", "discussion_type": null, "num_comments": 130, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g7kqf/is_the_future_of_data_science_drag_and_drop/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g7kqf/is_the_future_of_data_science_drag_and_drop/", "subreddit_subscribers": 1099939, "created_utc": 1698248160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was laid off from my startup in January so I took a job as a principal data scientist at a huge corporation. They exhibit every major red flag I can think of and I'm slowly losing my mind - any tips on how to survive long enough that it looks ok on my resume to leave?\n\nRed flags include:\n\n* No data / inaccessible data / data flying around in Excel\n* Management is not \"ML literate\"\n* More work dealing with red tape than actual work\n* 2x more managers than workers driving projects\n* Business consumers of our ML output do not trust it, and do not want it. They only like linear regression because they understand it\n* No version control. We run everything manually in prod. There is no dev/qa/prod separation. There is no deployment. There is no automation.\n* Because we work directly in prod, we don't have permission to save our processed data to tables or csv's - it must be done in memory every single day\n* No access to basic tools of the trade. We had to beg for basic file storage (s3) for 9 weeks. We can't download unapproved libraries or pre-trained models without security review (even just for exploration)\n\nMy career is jumpy recently - my first few roles were 3-4 years, but my last 2 roles were 1 year-ish, so trying to make it to Feb 2025", "author_fullname": "t2_am698", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to survive at nightmare employer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gfqqp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 89, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 89, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698270328.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698269551.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was laid off from my startup in January so I took a job as a principal data scientist at a huge corporation. They exhibit every major red flag I can think of and I&amp;#39;m slowly losing my mind - any tips on how to survive long enough that it looks ok on my resume to leave?&lt;/p&gt;\n\n&lt;p&gt;Red flags include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;No data / inaccessible data / data flying around in Excel&lt;/li&gt;\n&lt;li&gt;Management is not &amp;quot;ML literate&amp;quot;&lt;/li&gt;\n&lt;li&gt;More work dealing with red tape than actual work&lt;/li&gt;\n&lt;li&gt;2x more managers than workers driving projects&lt;/li&gt;\n&lt;li&gt;Business consumers of our ML output do not trust it, and do not want it. They only like linear regression because they understand it&lt;/li&gt;\n&lt;li&gt;No version control. We run everything manually in prod. There is no dev/qa/prod separation. There is no deployment. There is no automation.&lt;/li&gt;\n&lt;li&gt;Because we work directly in prod, we don&amp;#39;t have permission to save our processed data to tables or csv&amp;#39;s - it must be done in memory every single day&lt;/li&gt;\n&lt;li&gt;No access to basic tools of the trade. We had to beg for basic file storage (s3) for 9 weeks. We can&amp;#39;t download unapproved libraries or pre-trained models without security review (even just for exploration)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;My career is jumpy recently - my first few roles were 3-4 years, but my last 2 roles were 1 year-ish, so trying to make it to Feb 2025&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17gfqqp", "is_robot_indexable": true, "report_reasons": null, "author": "Mackelday", "discussion_type": null, "num_comments": 40, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gfqqp/how_to_survive_at_nightmare_employer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gfqqp/how_to_survive_at_nightmare_employer/", "subreddit_subscribers": 1099939, "created_utc": 1698269551.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " For context, I am a Master's student in CS and lurking in sub has made me realize that CS guys need more statistical background regarding DS positions. Hence, the motivation. However, I am already taking a course called Foundations course which feels like a quick Statistics walkthrough. I am also taking an Automated Learning course which basically follows the ISL contents. This course would be the third one? or the fourth one if I plan to audit this one.\n\nThis is what the course page says : \n\nStudent Learning Outcomes: \n\nMaster the essential tools of convex analysis, ability to characterize solutions to convex optimization problems, ability to formulate standard data science problems as convex optimization problems, and understanding the structure and implementation of the main classes of algorithms for solving optimization problems in data science.\n\nDetailed Content: \n\nIteration principles, fixed-point algorithms, convex sets and convex cones, best approximation paradigms, projection methods in convex feasibility problems \u2013 applications to data fusion and image recovery, convex functions, conjugation of convex functions, duality in convex optimization, subdifferential calculus, subgradient algorithms for convex feasibility and best approximation \u2013 applications in inverse problems, proximity operators, proximal calculus, forward-backward splitting and variants (Dykstra-like methods, Chambolle-Pock algorithm, dual ascent method, etc.), Douglas-Rachford splitting and variants (parallel proximal algorithm, alternating direction method of multipliers, composite primal-dual method, etc.), the monotone + skew decomposition principle \u2013 primal-dual algorithms, proximal modeling of statistical information, proximal information extraction, proximal sparsity enforcement, proximal data classification, proximal principal component analysis, proximal image reconstruction, proximal learning, proximal methods for matrix-based learning, scalability: proximal methods in big data problems, special topics.  \n\n\n  \nI was wondering if this would be something that could help with the day-to-day computations as a DS. I feel like real-world DS is more about optimization and less about using high-end ML/DL techniques. Any thoughts or suggestions?", "author_fullname": "t2_k6fzzm72", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is a Convex Optimization class good for Data Science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gc0b4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698259755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I am a Master&amp;#39;s student in CS and lurking in sub has made me realize that CS guys need more statistical background regarding DS positions. Hence, the motivation. However, I am already taking a course called Foundations course which feels like a quick Statistics walkthrough. I am also taking an Automated Learning course which basically follows the ISL contents. This course would be the third one? or the fourth one if I plan to audit this one.&lt;/p&gt;\n\n&lt;p&gt;This is what the course page says : &lt;/p&gt;\n\n&lt;p&gt;Student Learning Outcomes: &lt;/p&gt;\n\n&lt;p&gt;Master the essential tools of convex analysis, ability to characterize solutions to convex optimization problems, ability to formulate standard data science problems as convex optimization problems, and understanding the structure and implementation of the main classes of algorithms for solving optimization problems in data science.&lt;/p&gt;\n\n&lt;p&gt;Detailed Content: &lt;/p&gt;\n\n&lt;p&gt;Iteration principles, fixed-point algorithms, convex sets and convex cones, best approximation paradigms, projection methods in convex feasibility problems \u2013 applications to data fusion and image recovery, convex functions, conjugation of convex functions, duality in convex optimization, subdifferential calculus, subgradient algorithms for convex feasibility and best approximation \u2013 applications in inverse problems, proximity operators, proximal calculus, forward-backward splitting and variants (Dykstra-like methods, Chambolle-Pock algorithm, dual ascent method, etc.), Douglas-Rachford splitting and variants (parallel proximal algorithm, alternating direction method of multipliers, composite primal-dual method, etc.), the monotone + skew decomposition principle \u2013 primal-dual algorithms, proximal modeling of statistical information, proximal information extraction, proximal sparsity enforcement, proximal data classification, proximal principal component analysis, proximal image reconstruction, proximal learning, proximal methods for matrix-based learning, scalability: proximal methods in big data problems, special topics.  &lt;/p&gt;\n\n&lt;p&gt;I was wondering if this would be something that could help with the day-to-day computations as a DS. I feel like real-world DS is more about optimization and less about using high-end ML/DL techniques. Any thoughts or suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "17gc0b4", "is_robot_indexable": true, "report_reasons": null, "author": "VastDragonfruit847", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gc0b4/is_a_convex_optimization_class_good_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gc0b4/is_a_convex_optimization_class_good_for_data/", "subreddit_subscribers": 1099939, "created_utc": 1698259755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Beyond salary which almost everyone requires to survive, how do you maintain motivation in a data role? Specifically when your function is repeatedly called into question and educating the business seems to be an uphill battle? How do you keep going when you have to constantly perform in the corporate popularity contest?\n\nAdditionally, how do you maintain motivation when you're working with a domain that you don't like? Not tolerate, generally don't like. ", "author_fullname": "t2_3uoce3bn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you maintain motivation in your data role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g6gbt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698245141.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Beyond salary which almost everyone requires to survive, how do you maintain motivation in a data role? Specifically when your function is repeatedly called into question and educating the business seems to be an uphill battle? How do you keep going when you have to constantly perform in the corporate popularity contest?&lt;/p&gt;\n\n&lt;p&gt;Additionally, how do you maintain motivation when you&amp;#39;re working with a domain that you don&amp;#39;t like? Not tolerate, generally don&amp;#39;t like. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17g6gbt", "is_robot_indexable": true, "report_reasons": null, "author": "Tender_Figs", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g6gbt/how_do_you_maintain_motivation_in_your_data_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g6gbt/how_do_you_maintain_motivation_in_your_data_role/", "subreddit_subscribers": 1099939, "created_utc": 1698245141.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I know you would have heard so many people asking this question, but please bear with me.\n\nI had worked on a college project where we just implemented 6 different machine learning models (RF, XGB, GLM, DT, Naive Bayes &amp; GBM) on a health care fraud detection dataset to predict fraud. While interacting with an experienced working professional, he told that this is the stupiedest way to go about a problem. He said we have to choose a model which suits our data the most. But I don't know how to go about selelcting a model that suits the data the most because I don't have enough experience to just select any model based on experience and I didn't find any \"algorithm\" which tells me how to do it. I would like to hear from you about how to go on about this silly problem of mine.", "author_fullname": "t2_9llh8x8t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the most suitable model for my problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g8cbj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698250152.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know you would have heard so many people asking this question, but please bear with me.&lt;/p&gt;\n\n&lt;p&gt;I had worked on a college project where we just implemented 6 different machine learning models (RF, XGB, GLM, DT, Naive Bayes &amp;amp; GBM) on a health care fraud detection dataset to predict fraud. While interacting with an experienced working professional, he told that this is the stupiedest way to go about a problem. He said we have to choose a model which suits our data the most. But I don&amp;#39;t know how to go about selelcting a model that suits the data the most because I don&amp;#39;t have enough experience to just select any model based on experience and I didn&amp;#39;t find any &amp;quot;algorithm&amp;quot; which tells me how to do it. I would like to hear from you about how to go on about this silly problem of mine.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17g8cbj", "is_robot_indexable": true, "report_reasons": null, "author": "jakeblack06", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g8cbj/what_is_the_most_suitable_model_for_my_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g8cbj/what_is_the_most_suitable_model_for_my_problem/", "subreddit_subscribers": 1099939, "created_utc": 1698250152.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently doing some side work for a client that requires creating custom apis and having them run on a server. I am doing it in Google Console. But I noticed that there are so many different features within google console, I was curious if this is essentially a data engineer's life. Learning the  the ins and outs of AWS/Azure/GCS. I feel like it's so different from data science where we focus on concepts vs tools. \n\nOne reason Im curious is if you're the head of an analytics department how do you manage all of this? How would you know how much work something is?", "author_fullname": "t2_3kdgnq0f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Learning Cloud Platforms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g8iu2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698250622.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently doing some side work for a client that requires creating custom apis and having them run on a server. I am doing it in Google Console. But I noticed that there are so many different features within google console, I was curious if this is essentially a data engineer&amp;#39;s life. Learning the  the ins and outs of AWS/Azure/GCS. I feel like it&amp;#39;s so different from data science where we focus on concepts vs tools. &lt;/p&gt;\n\n&lt;p&gt;One reason Im curious is if you&amp;#39;re the head of an analytics department how do you manage all of this? How would you know how much work something is?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17g8iu2", "is_robot_indexable": true, "report_reasons": null, "author": "Jbor941197", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g8iu2/learning_cloud_platforms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g8iu2/learning_cloud_platforms/", "subreddit_subscribers": 1099939, "created_utc": 1698250622.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\n[ ](https://preview.redd.it/4cikjimrrcwb1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=8aac443256e5e5f18497718aa7d928d143a41b9b)\n\nI've been training this model and what I'm seeing is that after around 100 epochs, the loss of training data goes down, whereas the loss of validation data goes up, which indicates overfitting. However, the accuracy metric for both training and validation data keeps on increasing after around 100 epochs, which indicates that the model is not overfitting.  I've never encountered this before. I assumed that the loss and accuracy metric behaved in somewhat similar manner, but they are not behaving like that in this case. Can anyone explain why this is happening. Is the model overfitting or not?\n\nEdit: I'm using BinaryCrossentropy loss function. The problem I'm trying to solve is from the kaggle's titanic competition. Basically, it's tabular structured data that has features 'TicketClass', 'Name', 'Sex', 'Age', 'SiblingsBoarded', 'ParentsBoarded', 'Fare', 'Embarked' and target is 'Survived'(1/0). Let me know if you need more info.", "author_fullname": "t2_hcgjj0xo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help understanding if the model here is overfitting or not.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": 48, "top_awarded_type": null, "hide_score": false, "media_metadata": {"4cikjimrrcwb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 37, "x": 108, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=7771c425ef8e85b6d0257d24ff7eb2dd6c3f633b"}, {"y": 74, "x": 216, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=8a0d072e224adc11e96db3e8c55a7c923bdd4f12"}, {"y": 110, "x": 320, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=306b25854215a1dcd4f8d1e734e8cb762e9fb9b0"}, {"y": 221, "x": 640, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=31b3bdc29a5930780065a694881c62cacf1ddc2f"}, {"y": 331, "x": 960, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9d90194b0c01dfa4582192355dc0653ea409462a"}, {"y": 373, "x": 1080, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d31555d54e47b347278ab81e74b9305b216e588f"}], "s": {"y": 534, "x": 1546, "u": "https://preview.redd.it/4cikjimrrcwb1.png?width=1546&amp;format=png&amp;auto=webp&amp;s=8aac443256e5e5f18497718aa7d928d143a41b9b"}, "id": "4cikjimrrcwb1"}}, "name": "t3_17g55zm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/xtw4EAc8CYsFFqHXS6MxDctZLMU8Ncxdd7yk5ULOV_c.jpg", "edited": 1698242330.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698241481.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/4cikjimrrcwb1.png?width=1546&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=8aac443256e5e5f18497718aa7d928d143a41b9b\"&gt; &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been training this model and what I&amp;#39;m seeing is that after around 100 epochs, the loss of training data goes down, whereas the loss of validation data goes up, which indicates overfitting. However, the accuracy metric for both training and validation data keeps on increasing after around 100 epochs, which indicates that the model is not overfitting.  I&amp;#39;ve never encountered this before. I assumed that the loss and accuracy metric behaved in somewhat similar manner, but they are not behaving like that in this case. Can anyone explain why this is happening. Is the model overfitting or not?&lt;/p&gt;\n\n&lt;p&gt;Edit: I&amp;#39;m using BinaryCrossentropy loss function. The problem I&amp;#39;m trying to solve is from the kaggle&amp;#39;s titanic competition. Basically, it&amp;#39;s tabular structured data that has features &amp;#39;TicketClass&amp;#39;, &amp;#39;Name&amp;#39;, &amp;#39;Sex&amp;#39;, &amp;#39;Age&amp;#39;, &amp;#39;SiblingsBoarded&amp;#39;, &amp;#39;ParentsBoarded&amp;#39;, &amp;#39;Fare&amp;#39;, &amp;#39;Embarked&amp;#39; and target is &amp;#39;Survived&amp;#39;(1/0). Let me know if you need more info.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17g55zm", "is_robot_indexable": true, "report_reasons": null, "author": "Total-Opposite-8396", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g55zm/need_help_understanding_if_the_model_here_is/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g55zm/need_help_understanding_if_the_model_here_is/", "subreddit_subscribers": 1099939, "created_utc": 1698241481.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Any company size (please include in response if possible).", "author_fullname": "t2_coz8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data scientists reporting to CTO/equivalent (1 step below CEO), what's your job title?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g41qs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698238322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any company size (please include in response if possible).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17g41qs", "is_robot_indexable": true, "report_reasons": null, "author": "honeyplease", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g41qs/data_scientists_reporting_to_ctoequivalent_1_step/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g41qs/data_scientists_reporting_to_ctoequivalent_1_step/", "subreddit_subscribers": 1099939, "created_utc": 1698238322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My employer ran a rather expensive A/B test in its operations. The issue is that they failed to check for SRM and also didn't conduct A/A test beforehand. Now I inherited a test result that is poised with SRM. Due to their test setup, I could run a back A/A test, the result showed no significant difference between control and treatment. We tried to debug the SRM for a few weeks with no luck. I suppose with such SRM, the test results are not reliable. \n\nNow I am stuck between a rock and a hard place. Should we spend more time debugging the SRM or should we accept the cost and redesign and rerun the experiment. Is there a middle ground here?", "author_fullname": "t2_4oockqg5s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A/B test in real life", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17go3pk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698293599.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My employer ran a rather expensive A/B test in its operations. The issue is that they failed to check for SRM and also didn&amp;#39;t conduct A/A test beforehand. Now I inherited a test result that is poised with SRM. Due to their test setup, I could run a back A/A test, the result showed no significant difference between control and treatment. We tried to debug the SRM for a few weeks with no luck. I suppose with such SRM, the test results are not reliable. &lt;/p&gt;\n\n&lt;p&gt;Now I am stuck between a rock and a hard place. Should we spend more time debugging the SRM or should we accept the cost and redesign and rerun the experiment. Is there a middle ground here?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17go3pk", "is_robot_indexable": true, "report_reasons": null, "author": "furioncruz", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17go3pk/ab_test_in_real_life/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17go3pk/ab_test_in_real_life/", "subreddit_subscribers": 1099939, "created_utc": 1698293599.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I currently work for a government contractor. I have an opportunity to take a job with a technology consulting company as a consultant. I am on W2 at the first job and would be on a 1099 for the second. Could the first job still be able to find out about the second?  If I'm doing 20 hrs/wk at the second job, would that still be a problem for employers since I would be able to do it after hours?", "author_fullname": "t2_jnnvdz39c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "having a second job on 1099", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17goc84", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698294457.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently work for a government contractor. I have an opportunity to take a job with a technology consulting company as a consultant. I am on W2 at the first job and would be on a 1099 for the second. Could the first job still be able to find out about the second?  If I&amp;#39;m doing 20 hrs/wk at the second job, would that still be a problem for employers since I would be able to do it after hours?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17goc84", "is_robot_indexable": true, "report_reasons": null, "author": "daufoi21", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17goc84/having_a_second_job_on_1099/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17goc84/having_a_second_job_on_1099/", "subreddit_subscribers": 1099939, "created_utc": 1698294457.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\nI made this little doodle below as a good-faith effort at trying to lay out a reasonable decision tree for choosing an appropriate model evaluation metric for the sort of basic cases of predictive analytics. I'm ignoring numerous more complex cases of like like NLP, Computer Vision, and even arguably some simpler cases like forecasting, but trying to still cover the bulk of the entry gauntlet. There's obviously innumerable choices one could make for metrics, so the bias here is picking ones that are \"less wrong\" (avoid as many pitfalls as possible), fairly interpretable (e.g. a value of 1 or 0 \"means something\"), and have some popular acceptance. Sharing here in case it's helpful, and also I'm interested in others poking holes in the choices I made (if something seems egregious enough)!\n\nMy motivation here was mostly out of internal frustration of often seeing folks (online, friends, colleagues) fall into fairly rough pitfalls in their eval choices, and just seeing whether something like this could be reasonably written out. Not for anything else in a sense than the jollies.\n\nhttps://preview.redd.it/7nplhw2npgwb1.png?width=7162&amp;format=png&amp;auto=webp&amp;s=9bf42afad02bccdb791e88016a78862c7d7faa32", "author_fullname": "t2_9yzncc2e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Evaluation Metric Flowchart (possibly handy, interested in feedback!)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 77, "top_awarded_type": null, "hide_score": false, "media_metadata": {"7nplhw2npgwb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 60, "x": 108, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=030c67234c4f1eab22019470c0c1ca689e587b78"}, {"y": 120, "x": 216, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=4778be88b74770c29cfba8eb985952477d7e668d"}, {"y": 178, "x": 320, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=2575007f8ef0e519f6657b3807e6a8eef7520277"}, {"y": 356, "x": 640, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6807bc711553c64a5d8a096d501ce856e4c4cb53"}, {"y": 534, "x": 960, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=3b91e51da19d7ecac8dd06a18ef275289f9ba9fa"}, {"y": 601, "x": 1080, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3c8caebe3c3b31aa7899791907ab558296754139"}], "s": {"y": 3990, "x": 7162, "u": "https://preview.redd.it/7nplhw2npgwb1.png?width=7162&amp;format=png&amp;auto=webp&amp;s=9bf42afad02bccdb791e88016a78862c7d7faa32"}, "id": "7nplhw2npgwb1"}}, "name": "t3_17gn08a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/C6FsdcbioThGINeCCFjlbVQ1pb184byUS-UeLLkTbLs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698289874.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I made this little doodle below as a good-faith effort at trying to lay out a reasonable decision tree for choosing an appropriate model evaluation metric for the sort of basic cases of predictive analytics. I&amp;#39;m ignoring numerous more complex cases of like like NLP, Computer Vision, and even arguably some simpler cases like forecasting, but trying to still cover the bulk of the entry gauntlet. There&amp;#39;s obviously innumerable choices one could make for metrics, so the bias here is picking ones that are &amp;quot;less wrong&amp;quot; (avoid as many pitfalls as possible), fairly interpretable (e.g. a value of 1 or 0 &amp;quot;means something&amp;quot;), and have some popular acceptance. Sharing here in case it&amp;#39;s helpful, and also I&amp;#39;m interested in others poking holes in the choices I made (if something seems egregious enough)!&lt;/p&gt;\n\n&lt;p&gt;My motivation here was mostly out of internal frustration of often seeing folks (online, friends, colleagues) fall into fairly rough pitfalls in their eval choices, and just seeing whether something like this could be reasonably written out. Not for anything else in a sense than the jollies.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/7nplhw2npgwb1.png?width=7162&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9bf42afad02bccdb791e88016a78862c7d7faa32\"&gt;https://preview.redd.it/7nplhw2npgwb1.png?width=7162&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9bf42afad02bccdb791e88016a78862c7d7faa32&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17gn08a", "is_robot_indexable": true, "report_reasons": null, "author": "jshkk", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gn08a/evaluation_metric_flowchart_possibly_handy/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gn08a/evaluation_metric_flowchart_possibly_handy/", "subreddit_subscribers": 1099939, "created_utc": 1698289874.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Context: I have been looking at learning resources for data science interview preparations. Most are targeted at entry level and contains SQL/Coding questions as preparation guide. But then often interviews are asking questions like:  **Say you work at a major credit card company and are given a dataset of 600,000 credit card transactions. Use this dataset to build a fraud detection model.**   \n\n\nI have seen and found this framework for answering such questions:  \n\n\nStep1: Ask clarifying questions on problems and constraints \n\nStep 2: Establish Metrics \n\nStep 3: Understand your data sources \n\nStep 4: Explore your data \n\nStep 5: Data Cleanup \n\nStep 6: Feature Engineering \n\nStep 7: Model Selection and training \n\nStep 8: Deployment \n\nStep 9: Iterate \n\nI would love to get inputs on need and usefulness of such frameworks?\n\n&amp;#x200B;", "author_fullname": "t2_mjdr3ppgq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are data science answering frameworks helpful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17gtvwl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698318064.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I have been looking at learning resources for data science interview preparations. Most are targeted at entry level and contains SQL/Coding questions as preparation guide. But then often interviews are asking questions like:  &lt;strong&gt;Say you work at a major credit card company and are given a dataset of 600,000 credit card transactions. Use this dataset to build a fraud detection model.&lt;/strong&gt;   &lt;/p&gt;\n\n&lt;p&gt;I have seen and found this framework for answering such questions:  &lt;/p&gt;\n\n&lt;p&gt;Step1: Ask clarifying questions on problems and constraints &lt;/p&gt;\n\n&lt;p&gt;Step 2: Establish Metrics &lt;/p&gt;\n\n&lt;p&gt;Step 3: Understand your data sources &lt;/p&gt;\n\n&lt;p&gt;Step 4: Explore your data &lt;/p&gt;\n\n&lt;p&gt;Step 5: Data Cleanup &lt;/p&gt;\n\n&lt;p&gt;Step 6: Feature Engineering &lt;/p&gt;\n\n&lt;p&gt;Step 7: Model Selection and training &lt;/p&gt;\n\n&lt;p&gt;Step 8: Deployment &lt;/p&gt;\n\n&lt;p&gt;Step 9: Iterate &lt;/p&gt;\n\n&lt;p&gt;I would love to get inputs on need and usefulness of such frameworks?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "17gtvwl", "is_robot_indexable": true, "report_reasons": null, "author": "First_Beginning6365", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gtvwl/are_data_science_answering_frameworks_helpful/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gtvwl/are_data_science_answering_frameworks_helpful/", "subreddit_subscribers": 1099939, "created_utc": 1698318064.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all, I encountered this data analytics / data science challenge at work, and I was quite perplexed about how to approach it. I'm curious to hear from those with more experience (if this is more of a stack overflow question, I apologize).\n\nIn order to not reveal confidential information, I have changed the details, but the problem statement remains the same.\n\n**Background:**\n\nI was working for an online platform that showcased products from various vendors, and our objective was to pinpoint which features contribute to user engagement (likes, shares, purchases, etc.) with a product listing.\n\nGiven that we weren't producing the product descriptions ourselves, our focus was on **features we could influence**. This meant we **did not include** aspects such as:\n\n* product origin / vendor, \n* brand reputation, \n* type of product, \n* price \n\n, even if they were vital factors driving user engagement. --&gt; Naturally, a product from a renowned brand priced competitively will receive much more attention than a niche article from an unknown maker priced higher than market average.\n\nOur attention was instead directed at a few controllable features:\n\n* whether or not the descriptions and product names exceeded a certain length (we could provide feedback on these to vendors)\n* whether or not our in-house ML model could categorize the product (affecting its searchability)\n* the presence of vendor ratings,\n* etc.\n\nTo clarify, every feature we identified was binary. That is, the listing either met the criteria or it didn't. So, my dataset consisted of rows representing all product listings from a 6 month period, around 10 feature columns with binary values, and an engagement metric.\n\n**Approach:**\n\nMy next steps? I initiated numerous student t-tests. \n\nFor instance, how do product listings with names shorter than 80 characters fare against those longer than 80 characters? What's the engagement disparity between products that were categorized versus those that weren't? \n\nGiven the presence of three distinct engagement metrics and three different product listing styles, each significance test focused on a single feature, metric, and style. I conducted over 100 tests, applying the Bonferroni correction to address the multiple comparisons problem. \n\nNote: while A/B testing was on my mind, I did not see an easy possibility of performing A/B testing on short vs. long product descriptions and titles, since every additional word also influences the content and meaning (adding certain words could have a beneficial effect, others a detrimental one). Some features (like presence of vendor ratings) likely could have been A/B tested, but weren't for UX / political reasons.\n\n**Results:**\n\nWith extensive data at hand, I observed significant differences in engagement for nearly all features for the primary engagement metric, which was encouraging (I of course also had a few false negatives due to the Bonferroni correction).\n\nYet, the findings weren't consistent. While some features demonstrated consistent engagement patterns across all listing styles, most varied. Without the structure of an A/B testing framework, it became evident that multiple confounding variables were in action. For instance, certain products and vendors were more prevalent in specific listing styles than others.\n\nMy next idea was to devise a regression model to predict engagement based on these diverse features. However, I was unsure what type of model to use considering that the features were binary, and I was also aware that multi-collinearity would impact the coefficients for a linear regression model. Also, my ultimate goal was not to develop a predictive model, but rather to have a solid understanding of the extent to which each feature influenced engagement.\n\nI never was able to fully explore this avenue because the project was called off -  the achievable bottom-line impact seemed less than that which could be achieved through other means.\n\n**What could I have done differently?**\n\nIn retrospect, I wonder what I could have done differently / better. Given the lack of an A/B testing environment, was it even possible to draw any conclusions? If yes, what kind of methods or approaches could have been better? Were the significance tests the correct way to go? Should I have tried a certain predictive model type? How and at what point do I determine that this is an avenue worth / not worth exploring further?\n\nI would love to hear your thoughts!", "author_fullname": "t2_ap3spmczk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dealing with features of questionable predictive power and confounding variables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17gtslo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698318586.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698317713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I encountered this data analytics / data science challenge at work, and I was quite perplexed about how to approach it. I&amp;#39;m curious to hear from those with more experience (if this is more of a stack overflow question, I apologize).&lt;/p&gt;\n\n&lt;p&gt;In order to not reveal confidential information, I have changed the details, but the problem statement remains the same.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I was working for an online platform that showcased products from various vendors, and our objective was to pinpoint which features contribute to user engagement (likes, shares, purchases, etc.) with a product listing.&lt;/p&gt;\n\n&lt;p&gt;Given that we weren&amp;#39;t producing the product descriptions ourselves, our focus was on &lt;strong&gt;features we could influence&lt;/strong&gt;. This meant we &lt;strong&gt;did not include&lt;/strong&gt; aspects such as:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;product origin / vendor, &lt;/li&gt;\n&lt;li&gt;brand reputation, &lt;/li&gt;\n&lt;li&gt;type of product, &lt;/li&gt;\n&lt;li&gt;price &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;, even if they were vital factors driving user engagement. --&amp;gt; Naturally, a product from a renowned brand priced competitively will receive much more attention than a niche article from an unknown maker priced higher than market average.&lt;/p&gt;\n\n&lt;p&gt;Our attention was instead directed at a few controllable features:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;whether or not the descriptions and product names exceeded a certain length (we could provide feedback on these to vendors)&lt;/li&gt;\n&lt;li&gt;whether or not our in-house ML model could categorize the product (affecting its searchability)&lt;/li&gt;\n&lt;li&gt;the presence of vendor ratings,&lt;/li&gt;\n&lt;li&gt;etc.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;To clarify, every feature we identified was binary. That is, the listing either met the criteria or it didn&amp;#39;t. So, my dataset consisted of rows representing all product listings from a 6 month period, around 10 feature columns with binary values, and an engagement metric.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Approach:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;My next steps? I initiated numerous student t-tests. &lt;/p&gt;\n\n&lt;p&gt;For instance, how do product listings with names shorter than 80 characters fare against those longer than 80 characters? What&amp;#39;s the engagement disparity between products that were categorized versus those that weren&amp;#39;t? &lt;/p&gt;\n\n&lt;p&gt;Given the presence of three distinct engagement metrics and three different product listing styles, each significance test focused on a single feature, metric, and style. I conducted over 100 tests, applying the Bonferroni correction to address the multiple comparisons problem. &lt;/p&gt;\n\n&lt;p&gt;Note: while A/B testing was on my mind, I did not see an easy possibility of performing A/B testing on short vs. long product descriptions and titles, since every additional word also influences the content and meaning (adding certain words could have a beneficial effect, others a detrimental one). Some features (like presence of vendor ratings) likely could have been A/B tested, but weren&amp;#39;t for UX / political reasons.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Results:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;With extensive data at hand, I observed significant differences in engagement for nearly all features for the primary engagement metric, which was encouraging (I of course also had a few false negatives due to the Bonferroni correction).&lt;/p&gt;\n\n&lt;p&gt;Yet, the findings weren&amp;#39;t consistent. While some features demonstrated consistent engagement patterns across all listing styles, most varied. Without the structure of an A/B testing framework, it became evident that multiple confounding variables were in action. For instance, certain products and vendors were more prevalent in specific listing styles than others.&lt;/p&gt;\n\n&lt;p&gt;My next idea was to devise a regression model to predict engagement based on these diverse features. However, I was unsure what type of model to use considering that the features were binary, and I was also aware that multi-collinearity would impact the coefficients for a linear regression model. Also, my ultimate goal was not to develop a predictive model, but rather to have a solid understanding of the extent to which each feature influenced engagement.&lt;/p&gt;\n\n&lt;p&gt;I never was able to fully explore this avenue because the project was called off -  the achievable bottom-line impact seemed less than that which could be achieved through other means.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What could I have done differently?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;In retrospect, I wonder what I could have done differently / better. Given the lack of an A/B testing environment, was it even possible to draw any conclusions? If yes, what kind of methods or approaches could have been better? Were the significance tests the correct way to go? Should I have tried a certain predictive model type? How and at what point do I determine that this is an avenue worth / not worth exploring further?&lt;/p&gt;\n\n&lt;p&gt;I would love to hear your thoughts!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17gtslo", "is_robot_indexable": true, "report_reasons": null, "author": "Glum-Bat8771", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gtslo/dealing_with_features_of_questionable_predictive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gtslo/dealing_with_features_of_questionable_predictive/", "subreddit_subscribers": 1099939, "created_utc": 1698317713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_mjdr3ppgq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are data science interviews for entry level different from senior level (L5-L6). How is the interview preparation different?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17gtqqz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698317497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17gtqqz", "is_robot_indexable": true, "report_reasons": null, "author": "First_Beginning6365", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gtqqz/how_are_data_science_interviews_for_entry_level/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gtqqz/how_are_data_science_interviews_for_entry_level/", "subreddit_subscribers": 1099939, "created_utc": 1698317497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently working as a Research Specialist at a private company where I conduct trials and experimental data analysis. I have a biological science background with experience in R and JMP and thinking of jumping careers in Data Science. \n\nAny additional skills I need to learn?", "author_fullname": "t2_m26htnjnl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to qualify for a job in Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17gtgb0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698316319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently working as a Research Specialist at a private company where I conduct trials and experimental data analysis. I have a biological science background with experience in R and JMP and thinking of jumping careers in Data Science. &lt;/p&gt;\n\n&lt;p&gt;Any additional skills I need to learn?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17gtgb0", "is_robot_indexable": true, "report_reasons": null, "author": "cinderbl0ckgardener", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gtgb0/how_to_qualify_for_a_job_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gtgb0/how_to_qualify_for_a_job_in_data_science/", "subreddit_subscribers": 1099939, "created_utc": 1698316319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What's a DL project that could be worked on for 4 weeks with roughly 3 part time resources \n\nLooking for novel ideas and things you wanted to do and haven't done yet or done it and want to suggest cos it's fun \n\nI'm not married to any industry or sub space but I'm open to ideas that use modern DL paradigms\n\nIt could be models that generate new sets like prompts or images or something that analyzes vast amounts of data to make accurate classifications or predictions \n\n\nPersonally , I have the usual run of the mill ideas like nba , soccer analysis. But these have been so overdone at this point\n\n\nTwitter and reddit killed their api and I don't just want a random historic kaggle dataset .", "author_fullname": "t2_mloui", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A very open ended question- suggestion for 4 week long DL projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gs022", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "ML", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698309944.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s a DL project that could be worked on for 4 weeks with roughly 3 part time resources &lt;/p&gt;\n\n&lt;p&gt;Looking for novel ideas and things you wanted to do and haven&amp;#39;t done yet or done it and want to suggest cos it&amp;#39;s fun &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not married to any industry or sub space but I&amp;#39;m open to ideas that use modern DL paradigms&lt;/p&gt;\n\n&lt;p&gt;It could be models that generate new sets like prompts or images or something that analyzes vast amounts of data to make accurate classifications or predictions &lt;/p&gt;\n\n&lt;p&gt;Personally , I have the usual run of the mill ideas like nba , soccer analysis. But these have been so overdone at this point&lt;/p&gt;\n\n&lt;p&gt;Twitter and reddit killed their api and I don&amp;#39;t just want a random historic kaggle dataset .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "17gs022", "is_robot_indexable": true, "report_reasons": null, "author": "Asshaisin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gs022/a_very_open_ended_question_suggestion_for_4_week/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gs022/a_very_open_ended_question_suggestion_for_4_week/", "subreddit_subscribers": 1099939, "created_utc": 1698309944.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a dataset of values for a set of variables that are all complete and I want to build a model to impute any missing values in future observations. A typical use case might be healthcare records where I have weight, height, blood pressure, cholesterol levels, etc. for a set of patients.\n\nThe tricky part is that there will be different combinations of missing values for each of the future observations, e.g. one patient misssing weight and height, another patient missing cholesterol and blood pressure. In my dataset I have about 2000 variables for each observation, and in future observations, 90% or more values could be missing, but the data is homogenous so it should be predictable.\n\nI'm looking to compile possible models that can fill in a set of missing values, and have ideally been implemented in Python. So far I have been looking at using GANS ([Missing Data Imputation using Generative Adversarial Nets](https://arxiv.org/abs/1806.02920)) and [MissForest](https://academic.oup.com/bioinformatics/article/28/1/112/219101). Does anybody have any other suggestions of imputers that might work?", "author_fullname": "t2_qgew7u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imputation of multiple missing values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gqxzh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1698305124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a dataset of values for a set of variables that are all complete and I want to build a model to impute any missing values in future observations. A typical use case might be healthcare records where I have weight, height, blood pressure, cholesterol levels, etc. for a set of patients.&lt;/p&gt;\n\n&lt;p&gt;The tricky part is that there will be different combinations of missing values for each of the future observations, e.g. one patient misssing weight and height, another patient missing cholesterol and blood pressure. In my dataset I have about 2000 variables for each observation, and in future observations, 90% or more values could be missing, but the data is homogenous so it should be predictable.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking to compile possible models that can fill in a set of missing values, and have ideally been implemented in Python. So far I have been looking at using GANS (&lt;a href=\"https://arxiv.org/abs/1806.02920\"&gt;Missing Data Imputation using Generative Adversarial Nets&lt;/a&gt;) and &lt;a href=\"https://academic.oup.com/bioinformatics/article/28/1/112/219101\"&gt;MissForest&lt;/a&gt;. Does anybody have any other suggestions of imputers that might work?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?auto=webp&amp;s=8efe489c05609f1626bbb44354c77840623707de", "width": 1200, "height": 700}, "resolutions": [{"url": "https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bc9575b410002edc2df3c5b5b0355fefedc7baa8", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=dbce7f303173724d23fb33cd3fc636c04c72b290", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c1043d604105157f56a615cc59bb14d7ae64653f", "width": 320, "height": 186}, {"url": "https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ce8b9192ed7ca476d2844aaa405c5014a7a1ab45", "width": 640, "height": 373}, {"url": "https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=76aed6fd51086798b2d415a7d57562c967db4111", "width": 960, "height": 560}, {"url": "https://external-preview.redd.it/izh8gZHY4FqZ1nwtU1N_TjtohUCNuvTyMn90toXda80.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=46129c06d8fad9a58fff9740c079e13d4e829213", "width": 1080, "height": 630}], "variants": {}, "id": "q3evP6JeDpAC2MdSQHWYxnCYTqbJkElIQsLFqVSdkss"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17gqxzh", "is_robot_indexable": true, "report_reasons": null, "author": "ChrisReynolds83", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gqxzh/imputation_of_multiple_missing_values/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gqxzh/imputation_of_multiple_missing_values/", "subreddit_subscribers": 1099939, "created_utc": 1698305124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "PFW MSCS:\nPros: MSCS, regional campus of Purdue, less expensive\nCons: Not Weft Lafayette Campus, less jobs fairs compared to WL, Ranking\n\nGWU MSDS:\nPros: Scholarship, Good ranking compared to PFW\nCons: Not CS, expensive compared to PFW\n\nAt first, I applied for MSDS, but I started thinking about CS as a safer choice. I was unsure if there would be enough demand for entry level DS/DE roles by the end of 2025 when I graduate, given the current market situation.\n\nMy Profile:\nBachelor's: CS\n4 YoE as a software Engineer in India\nCgpa: 7.52\nIELTS: 7.5\nGRE: didn't submit for both universities\n\nThanks in advance!", "author_fullname": "t2_32a80xb2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me decide: PFW vs GWU for Spring 2024", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gq6hs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698301816.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;PFW MSCS:\nPros: MSCS, regional campus of Purdue, less expensive\nCons: Not Weft Lafayette Campus, less jobs fairs compared to WL, Ranking&lt;/p&gt;\n\n&lt;p&gt;GWU MSDS:\nPros: Scholarship, Good ranking compared to PFW\nCons: Not CS, expensive compared to PFW&lt;/p&gt;\n\n&lt;p&gt;At first, I applied for MSDS, but I started thinking about CS as a safer choice. I was unsure if there would be enough demand for entry level DS/DE roles by the end of 2025 when I graduate, given the current market situation.&lt;/p&gt;\n\n&lt;p&gt;My Profile:\nBachelor&amp;#39;s: CS\n4 YoE as a software Engineer in India\nCgpa: 7.52\nIELTS: 7.5\nGRE: didn&amp;#39;t submit for both universities&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "17gq6hs", "is_robot_indexable": true, "report_reasons": null, "author": "MylarSome", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gq6hs/help_me_decide_pfw_vs_gwu_for_spring_2024/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gq6hs/help_me_decide_pfw_vs_gwu_for_spring_2024/", "subreddit_subscribers": 1099939, "created_utc": 1698301816.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have film consumption data and although the natural trend is of a decayed nature certain assets have latent growth and I\u2019m trying to find the best way to read through the noise of the consumption data and generate a forecast. Ideally the algorithm works so that it can be transferred to any new data, rather than just training an ARIMA or fitting a regression for any new film.\n\nLooking for any really good tutorials on models that may help.\n\nThanks", "author_fullname": "t2_ds90qagip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "YouTube or Tutorials on Advanced Time Series?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gmvhs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698289454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have film consumption data and although the natural trend is of a decayed nature certain assets have latent growth and I\u2019m trying to find the best way to read through the noise of the consumption data and generate a forecast. Ideally the algorithm works so that it can be transferred to any new data, rather than just training an ARIMA or fitting a regression for any new film.&lt;/p&gt;\n\n&lt;p&gt;Looking for any really good tutorials on models that may help.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "17gmvhs", "is_robot_indexable": true, "report_reasons": null, "author": "Reasonable-Farmer186", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gmvhs/youtube_or_tutorials_on_advanced_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gmvhs/youtube_or_tutorials_on_advanced_time_series/", "subreddit_subscribers": 1099939, "created_utc": 1698289454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Vector DB offerings today are structured in such a way that the user is expected to have all files/file embeddings in the same place, and every time a search is effected, the entirety of that pool is queried through.\n\nIf so prepared, a user can do some filtering through metadata tags. However, this feels like a limited and clunky way to reduce the scope of what's queried.\n\nAm I missing something here? Do most use cases call for all files/vectors being kept in the same bucket, as opposed to some other arrangement? What use cases work best with a \"big bucket\" structure in which everything is kept in the same place?", "author_fullname": "t2_9pje88yp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vector DB directory structuring - ideal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gej5o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698266491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Vector DB offerings today are structured in such a way that the user is expected to have all files/file embeddings in the same place, and every time a search is effected, the entirety of that pool is queried through.&lt;/p&gt;\n\n&lt;p&gt;If so prepared, a user can do some filtering through metadata tags. However, this feels like a limited and clunky way to reduce the scope of what&amp;#39;s queried.&lt;/p&gt;\n\n&lt;p&gt;Am I missing something here? Do most use cases call for all files/vectors being kept in the same bucket, as opposed to some other arrangement? What use cases work best with a &amp;quot;big bucket&amp;quot; structure in which everything is kept in the same place?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17gej5o", "is_robot_indexable": true, "report_reasons": null, "author": "LucasSaysHello", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gej5o/vector_db_directory_structuring_ideal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gej5o/vector_db_directory_structuring_ideal/", "subreddit_subscribers": 1099939, "created_utc": 1698266491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_v8n3a1nm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Vertex AI and the ML Workflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_17gdj5r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/QuvPUscW6_M?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Vertex AI and the ML Workflow\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Vertex AI and the ML Workflow", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/QuvPUscW6_M?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Vertex AI and the ML Workflow\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/QuvPUscW6_M/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/QuvPUscW6_M?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Vertex AI and the ML Workflow\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/17gdj5r", "height": 200}, "link_flair_text": "ML", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/UglbwEzmGoH6x6X1fj7UmxY8eCEBS723SF_rRVQ0Gho.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698263836.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/QuvPUscW6_M?si=ztT87cclfME_8155", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/x_4RfHp_-YzK3n2GnJNhNrbE-x60dX8LdPK2BC42SPQ.jpg?auto=webp&amp;s=893332251d48a32055d059bfa35684dc07de2950", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/x_4RfHp_-YzK3n2GnJNhNrbE-x60dX8LdPK2BC42SPQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b14eb59dba0794e9198fdad37e5f507c9d028c83", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/x_4RfHp_-YzK3n2GnJNhNrbE-x60dX8LdPK2BC42SPQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f0761a384f6a80654c846dd5de759ced87765332", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/x_4RfHp_-YzK3n2GnJNhNrbE-x60dX8LdPK2BC42SPQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=25557a0bd982c3a1d7eb1ebf1028916e7df98f36", "width": 320, "height": 240}], "variants": {}, "id": "mtzGT5vBpn8t8bEIjErreC4c4LdRcc_7IfAM3NGHsmQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#878a8c", "id": "17gdj5r", "is_robot_indexable": true, "report_reasons": null, "author": "fancypigollo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gdj5r/vertex_ai_and_the_ml_workflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/QuvPUscW6_M?si=ztT87cclfME_8155", "subreddit_subscribers": 1099939, "created_utc": 1698263836.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Vertex AI and the ML Workflow", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/QuvPUscW6_M?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Vertex AI and the ML Workflow\"&gt;&lt;/iframe&gt;", "author_name": "The Data Science Channel", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/QuvPUscW6_M/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@TheDataScienceChannel"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hey there, fellow data science people,\n\nI'm reaching out for a little help and some advice in my quest to jump into the data science world. I come from a biotech background and have been devouring data science content for the past year, but I'm having a bit of a struggle finding my first gig.\n\nHere's where I need advice. I'm curious about which cloud computing system is currently the talk of the town in the data science universe. With tech evolving fast, I want to make sure I'm learning a cloud platform that'll give me some edge in the job market. I guess the battle is between Azure and AWS, but between those two I dont know what would best to learn if you dont know any.\n\nAnd last but not least, I'm all eyes for recommendations on these cloud computing systems certifications that could beef up my skillset and make me more hireable. \n\nThank you a lot in advance", "author_fullname": "t2_ec0fi5ob", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud computing trends in data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g9mzj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698253498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, fellow data science people,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m reaching out for a little help and some advice in my quest to jump into the data science world. I come from a biotech background and have been devouring data science content for the past year, but I&amp;#39;m having a bit of a struggle finding my first gig.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s where I need advice. I&amp;#39;m curious about which cloud computing system is currently the talk of the town in the data science universe. With tech evolving fast, I want to make sure I&amp;#39;m learning a cloud platform that&amp;#39;ll give me some edge in the job market. I guess the battle is between Azure and AWS, but between those two I dont know what would best to learn if you dont know any.&lt;/p&gt;\n\n&lt;p&gt;And last but not least, I&amp;#39;m all eyes for recommendations on these cloud computing systems certifications that could beef up my skillset and make me more hireable. &lt;/p&gt;\n\n&lt;p&gt;Thank you a lot in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "17g9mzj", "is_robot_indexable": true, "report_reasons": null, "author": "lucasso13", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g9mzj/cloud_computing_trends_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g9mzj/cloud_computing_trends_in_data_science/", "subreddit_subscribers": 1099939, "created_utc": 1698253498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I already know enough technical stuff I believe. But how one can learn to find insights or trends from the data. And then suggest product improvements?", "author_fullname": "t2_ii3qs0uq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can you learn to find the insights", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gpxlq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698300755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I already know enough technical stuff I believe. But how one can learn to find insights or trends from the data. And then suggest product improvements?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17gpxlq", "is_robot_indexable": true, "report_reasons": null, "author": "SaiyWolf", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gpxlq/how_can_you_learn_to_find_the_insights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gpxlq/how_can_you_learn_to_find_the_insights/", "subreddit_subscribers": 1099939, "created_utc": 1698300755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m right now coming to the end of my post graduation in data science and how can I proceed from now in order to get a job or an internship? What can be the different methods I can apply. My institute where I\u2019m pursuing right now also promised placement opportunities but I do not want to wait till the end\u2026", "author_fullname": "t2_o9iya5e7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to proceed\u2026", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gn7d8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698290490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m right now coming to the end of my post graduation in data science and how can I proceed from now in order to get a job or an internship? What can be the different methods I can apply. My institute where I\u2019m pursuing right now also promised placement opportunities but I do not want to wait till the end\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17gn7d8", "is_robot_indexable": true, "report_reasons": null, "author": "LegitimateAd4716", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17gn7d8/how_to_proceed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17gn7d8/how_to_proceed/", "subreddit_subscribers": 1099939, "created_utc": 1698290490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a company page and branding package set up on LinkedIn \u2013 is it in bad taste to list actual personal and pro-bono projects as experience in order to not have a huge employment gap?\n\nSome details: I'm a Data Analyst with CRM consulting experience but currently unemployed since June (layoffs). I have professional work I've created but not yet published (ie. dashboards, architecture frameworks, wireframes, etc.) that I would be publishing under my profile and tagging my company. Some of this work involves working with real-world businesses for free.", "author_fullname": "t2_883ga", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Worthwhile to post personal and pro-bono projects under my company page in order to list experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g7vsr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698248991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a company page and branding package set up on LinkedIn \u2013 is it in bad taste to list actual personal and pro-bono projects as experience in order to not have a huge employment gap?&lt;/p&gt;\n\n&lt;p&gt;Some details: I&amp;#39;m a Data Analyst with CRM consulting experience but currently unemployed since June (layoffs). I have professional work I&amp;#39;ve created but not yet published (ie. dashboards, architecture frameworks, wireframes, etc.) that I would be publishing under my profile and tagging my company. Some of this work involves working with real-world businesses for free.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17g7vsr", "is_robot_indexable": true, "report_reasons": null, "author": "CarbonHero", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17g7vsr/worthwhile_to_post_personal_and_probono_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17g7vsr/worthwhile_to_post_personal_and_probono_projects/", "subreddit_subscribers": 1099939, "created_utc": 1698248991.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}