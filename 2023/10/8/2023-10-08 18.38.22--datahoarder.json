{"kind": "Listing", "data": {"after": "t3_172qrn5", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_btjq8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New optical disc tech could make $5 per TB possible (September, 2022)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_172gyc6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 265, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 265, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ZkuTXq3Yky-zj_-cqnStPwvqwktVf8q90dPwfFi-iMg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696712940.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "techspot.com", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.techspot.com/news/95846-new-optical-disc-tech-could-makes-5-tb.html", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mmRKp8pJzeoCqMzm_x-N9mwmj-HOzbKkibriH79YnUY.jpg?auto=webp&amp;s=187432ba5a27b59f5996cee579e78dd72676a3c2", "width": 1500, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/mmRKp8pJzeoCqMzm_x-N9mwmj-HOzbKkibriH79YnUY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e6e92a1fcdf968127c20481585ebbf86919c8551", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/mmRKp8pJzeoCqMzm_x-N9mwmj-HOzbKkibriH79YnUY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c664194f7bf792a55074e4f119d7a01c412bebb", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/mmRKp8pJzeoCqMzm_x-N9mwmj-HOzbKkibriH79YnUY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b70e6476b802049ac86a867fc891b22151ae9337", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/mmRKp8pJzeoCqMzm_x-N9mwmj-HOzbKkibriH79YnUY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=79c36d2b7006f3e35ad2e1711e56660aceae6df4", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/mmRKp8pJzeoCqMzm_x-N9mwmj-HOzbKkibriH79YnUY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7467fdc78f3f95d0b71496cacb7c6151bb4212d3", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/mmRKp8pJzeoCqMzm_x-N9mwmj-HOzbKkibriH79YnUY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6b146eb6848c217de027a5e86561e0593267cc0f", "width": 1080, "height": 720}], "variants": {}, "id": "Dw6pSkMItumEzVG1es5hHCPMxowzl1QoUK02BRAq70k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "172gyc6", "is_robot_indexable": true, "report_reasons": null, "author": "five_inch_penis", "discussion_type": null, "num_comments": 62, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172gyc6/new_optical_disc_tech_could_make_5_per_tb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.techspot.com/news/95846-new-optical-disc-tech-could-makes-5-tb.html", "subreddit_subscribers": 705638, "created_utc": 1696712940.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've found the following deal: [Seagate IronWolf Pro 16TB](https://www.jb-computer.de/komponenten-zubehoer/speicher/hdd/9078/seagate-ironwolf-pro-16tb-hdd-3.5-zoll-nas-festplatte-sata-6gb/s-7200rpm-recertified-new-st16000ne0?number=MJB991970)\n\nThey're \"Recertified new\", so they should be as good as new, but I'm still wondering about the price, since it's about 100\u20ac cheaper than everywhere else I could find.\n\nIs there anything that I should worry about / that I'm missing?", "author_fullname": "t2_clqfxwwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this deal too good to be true? [IronWolf Pro 16TB for 240\u20ac]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172w1r5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696761516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve found the following deal: &lt;a href=\"https://www.jb-computer.de/komponenten-zubehoer/speicher/hdd/9078/seagate-ironwolf-pro-16tb-hdd-3.5-zoll-nas-festplatte-sata-6gb/s-7200rpm-recertified-new-st16000ne0?number=MJB991970\"&gt;Seagate IronWolf Pro 16TB&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;re &amp;quot;Recertified new&amp;quot;, so they should be as good as new, but I&amp;#39;m still wondering about the price, since it&amp;#39;s about 100\u20ac cheaper than everywhere else I could find.&lt;/p&gt;\n\n&lt;p&gt;Is there anything that I should worry about / that I&amp;#39;m missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?auto=webp&amp;s=56b69a3282cb2b793518b93e5713fc05ca97b3a3", "width": 1021, "height": 1500}, "resolutions": [{"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6898dba29c225dfd92ade0f094b1bbc543b719a3", "width": 108, "height": 158}, {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a4b1c16bc0482411036a8bc1a55652efc557a52f", "width": 216, "height": 317}, {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3024895cf2dfea54a338522a6bc78b40b887c476", "width": 320, "height": 470}, {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6cdd1ca290de37f8d622429d54dceef9789eb559", "width": 640, "height": 940}, {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=eb5eac25e419fcfd5b6110cb0299daba31487979", "width": 960, "height": 1410}], "variants": {}, "id": "_I8KRd5bw-DkkX0QsAwG4hMeOwGXhPN3hpap37_8jGY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172w1r5", "is_robot_indexable": true, "report_reasons": null, "author": "SeltsamerMagnet", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172w1r5/is_this_deal_too_good_to_be_true_ironwolf_pro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172w1r5/is_this_deal_too_good_to_be_true_ironwolf_pro/", "subreddit_subscribers": 705638, "created_utc": 1696761516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://sketchfab.com/ffishAsia-and-floraZia/models](https://sketchfab.com/ffishAsia-and-floraZia/models)\n\nI'm posting this here for anyone interested in preserving this.", "author_fullname": "t2_vg1a74d0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kyushu University released 2180 models of animals and plants.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172q0vr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696738978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://sketchfab.com/ffishAsia-and-floraZia/models\"&gt;https://sketchfab.com/ffishAsia-and-floraZia/models&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m posting this here for anyone interested in preserving this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172q0vr", "is_robot_indexable": true, "report_reasons": null, "author": "Not_Espion", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172q0vr/kyushu_university_released_2180_models_of_animals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172q0vr/kyushu_university_released_2180_models_of_animals/", "subreddit_subscribers": 705638, "created_utc": 1696738978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi I\u2019m on windows 10 and I\u2019ve started using Macrium Reflect to clone my files stored on an external hard drives and have cloned them to two other external hard drives for extra copies of my backups. But when I go to check the used space in disk properties they are a tiny bit off. \n\nI checked all folder sizes and modified date and they all matched up, but I\u2019ve also read that this is not a reliable method to verify copied files. \n\nOriginal Ext HDD 1,971,778,027,520 bytes\n\nClone of Ext HDD 1,971,716.644,864 bytes\n\nSecond Clone HDD 1,971,717,033,984 bytes\n\nIs this normal or should they be exactly the same?\n\nAny recommendations on how to verify that the filters on all three disks are exactly the same. \n\nI\u2019ve see terracopy mentioned but I think that\u2019s for files that have yet to be copied. \n\nThanks.", "author_fullname": "t2_5195n8p0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows software to verify copied files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172s5a4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696746556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I\u2019m on windows 10 and I\u2019ve started using Macrium Reflect to clone my files stored on an external hard drives and have cloned them to two other external hard drives for extra copies of my backups. But when I go to check the used space in disk properties they are a tiny bit off. &lt;/p&gt;\n\n&lt;p&gt;I checked all folder sizes and modified date and they all matched up, but I\u2019ve also read that this is not a reliable method to verify copied files. &lt;/p&gt;\n\n&lt;p&gt;Original Ext HDD 1,971,778,027,520 bytes&lt;/p&gt;\n\n&lt;p&gt;Clone of Ext HDD 1,971,716.644,864 bytes&lt;/p&gt;\n\n&lt;p&gt;Second Clone HDD 1,971,717,033,984 bytes&lt;/p&gt;\n\n&lt;p&gt;Is this normal or should they be exactly the same?&lt;/p&gt;\n\n&lt;p&gt;Any recommendations on how to verify that the filters on all three disks are exactly the same. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve see terracopy mentioned but I think that\u2019s for files that have yet to be copied. &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172s5a4", "is_robot_indexable": true, "report_reasons": null, "author": "jumpyHR", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172s5a4/windows_software_to_verify_copied_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172s5a4/windows_software_to_verify_copied_files/", "subreddit_subscribers": 705638, "created_utc": 1696746556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone hoarding videos from Israel-Palestine, and Russia-Ukraine wars. How do you chronicle? How do you vet the correctness? What sources do you use? I guess sources are too many to list but I would appreciate some discussion.", "author_fullname": "t2_2lugimc5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone doing war footage archiving?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172q3im", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696739246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone hoarding videos from Israel-Palestine, and Russia-Ukraine wars. How do you chronicle? How do you vet the correctness? What sources do you use? I guess sources are too many to list but I would appreciate some discussion.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "50TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172q3im", "is_robot_indexable": true, "report_reasons": null, "author": "logicalcliff", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/172q3im/anyone_doing_war_footage_archiving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172q3im/anyone_doing_war_footage_archiving/", "subreddit_subscribers": 705638, "created_utc": 1696739246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 60+TB TrueNAS box. It's maybe half full, 20-30TB. Half of that is irreplaceable photos/video I've shot, the other half is movies/tv shows. I'd like to back up some or all of this to tape. Two copies, one offsite. Rotated monthly. \n\nI bought a LTO6 drive off ebay (External SAS) but haven't yet setup a server to handle the backups. I'm looking for recommendations for software and strategies to backup this data. \n\n1. What software would you use to backup zfs data sets to LTO-6 tape? \n   1. Each pool is lets say 10TB currently but could grow. \n   2. I'd really like to not pay yearly license fees but would pay for software if Free is not an option\n   3. I need two copies of each dataset\n   4. I've looked into Uranium and Veeam but I know almost nothing about them\n2. How should this be setup physically? I have a TrueNAS server and a Proxmox 8 server that have available slots that could talk to this drive. Do I make a windows VM and passthrough the drive? Do I setup a separate backup box?\n   1. I have a proxmox backup server but I dont think it can backup NFS shares to tape in the same way that LTO software can\n3. Any other considerations? LTFS or not? Something else I'm missing? How to transport tapes?", "author_fullname": "t2_a223n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LTO tape backup of NAS, what software to use", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172q92w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696739780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 60+TB TrueNAS box. It&amp;#39;s maybe half full, 20-30TB. Half of that is irreplaceable photos/video I&amp;#39;ve shot, the other half is movies/tv shows. I&amp;#39;d like to back up some or all of this to tape. Two copies, one offsite. Rotated monthly. &lt;/p&gt;\n\n&lt;p&gt;I bought a LTO6 drive off ebay (External SAS) but haven&amp;#39;t yet setup a server to handle the backups. I&amp;#39;m looking for recommendations for software and strategies to backup this data. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What software would you use to backup zfs data sets to LTO-6 tape? \n\n&lt;ol&gt;\n&lt;li&gt;Each pool is lets say 10TB currently but could grow. &lt;/li&gt;\n&lt;li&gt;I&amp;#39;d really like to not pay yearly license fees but would pay for software if Free is not an option&lt;/li&gt;\n&lt;li&gt;I need two copies of each dataset&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve looked into Uranium and Veeam but I know almost nothing about them&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;How should this be setup physically? I have a TrueNAS server and a Proxmox 8 server that have available slots that could talk to this drive. Do I make a windows VM and passthrough the drive? Do I setup a separate backup box?\n\n&lt;ol&gt;\n&lt;li&gt;I have a proxmox backup server but I dont think it can backup NFS shares to tape in the same way that LTO software can&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Any other considerations? LTFS or not? Something else I&amp;#39;m missing? How to transport tapes?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172q92w", "is_robot_indexable": true, "report_reasons": null, "author": "pcmofo", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172q92w/lto_tape_backup_of_nas_what_software_to_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172q92w/lto_tape_backup_of_nas_what_software_to_use/", "subreddit_subscribers": 705638, "created_utc": 1696739780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I saved a 6 hours music livestream from the 20th anniversary of Ed Banger Records and I don't really know where to publish it.\n\nSince I don't have the rights I can't publish it to youtube, but at the same time I want to share it to others because it's a piece of the label's history.\n\nDo you have any ideas? I'm already uploading it to archive.org but I don't know if it will thay there for a long time.\n\nThank you!", "author_fullname": "t2_8if3bv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where can I host/share a saved livestream without having the rights?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172xepr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696766346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I saved a 6 hours music livestream from the 20th anniversary of Ed Banger Records and I don&amp;#39;t really know where to publish it.&lt;/p&gt;\n\n&lt;p&gt;Since I don&amp;#39;t have the rights I can&amp;#39;t publish it to youtube, but at the same time I want to share it to others because it&amp;#39;s a piece of the label&amp;#39;s history.&lt;/p&gt;\n\n&lt;p&gt;Do you have any ideas? I&amp;#39;m already uploading it to archive.org but I don&amp;#39;t know if it will thay there for a long time.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172xepr", "is_robot_indexable": true, "report_reasons": null, "author": "ibrokemywatch", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172xepr/where_can_i_hostshare_a_saved_livestream_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172xepr/where_can_i_hostshare_a_saved_livestream_without/", "subreddit_subscribers": 705638, "created_utc": 1696766346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I picked up the WD MyBook 8TB a while back because I\u2019m a videographer and I need to store all my raw footage and other things in it. I\u2019ve been video editing on my desktop through windows and I\u2019m fully switching to my MacBook Pro. I was just wondering how I should switch the hard drive from my PC to my MacBook without anything corrupting or deleting. I\u2019m only asking because I was looking up videos of the setup on Mac and everyone was erasing everything off of it at first to set it up and I cant do that as I have almost a TB already on it. Please let me know what to do so I can safely transfer this hard drive to my mac.", "author_fullname": "t2_5gezuxf6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "WD MyBook 8TB Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172f0a7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696707835.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I picked up the WD MyBook 8TB a while back because I\u2019m a videographer and I need to store all my raw footage and other things in it. I\u2019ve been video editing on my desktop through windows and I\u2019m fully switching to my MacBook Pro. I was just wondering how I should switch the hard drive from my PC to my MacBook without anything corrupting or deleting. I\u2019m only asking because I was looking up videos of the setup on Mac and everyone was erasing everything off of it at first to set it up and I cant do that as I have almost a TB already on it. Please let me know what to do so I can safely transfer this hard drive to my mac.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172f0a7", "is_robot_indexable": true, "report_reasons": null, "author": "accastelao", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172f0a7/wd_mybook_8tb_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172f0a7/wd_mybook_8tb_question/", "subreddit_subscribers": 705638, "created_utc": 1696707835.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I ran a SMART test in TrueNAS for an old 6TB Western Digital Green drive (model WD60EZRX), and although TureNAS is telling me that the drive has failed the test, `smartctl` gives a status of \"SMART overall-health self-assessment test result: PASSED\" and all of my actual values look okay.  I'm trying to figure out what's going on.\n\nFrom what I can tell, the issue is that the test isn't completing.  I'm seeing this in the `General SMART Values:` section:\n\n    \tSelf-test execution status:      (  57) A fatal error or unknown test error\n    \t                                        occurred while the device was executing\n    \t                                        its self-test routine and the device \n    \t                                        was unable to complete the self-test \n    \t                                        routine.\n\nAnd under `SMART Self-test log structure` I'm seeing this:\n\n    \tSMART Self-test log structure revision number 1\n    \tNum  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error\n    \t# 1  Short offline       Fatal or unknown error        90%     43903         -\n    \t# 2  Extended offline    Fatal or unknown error        90%     43881         -\n    \t# 3  Short offline       Fatal or unknown error        90%     43879         -\n\n\n\n#**HOWEVER**! \nIt does look like it's updating the disk values in the `Vendor Specific SMART Attributes with Thresholds` section.  Here's the output of the first and second SMART tests for comparison:\n\n    \tSMART Attributes Data Structure revision number: 16\n    \tVendor Specific SMART Attributes with Thresholds:\n    \tID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n    \t  1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n    \t  3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n    \t  4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n    \t  5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n    \t  7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n    \t  9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43890\n    \t 10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n    \t 11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n    \t 12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    \t192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    \t193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123623\n    \t194 Temperature_Celsius     0x0022   123   103   000    Old_age   Always       -       29\n    \t196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    \t197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    \t198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    \t199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    \t200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n    \t\n    \tSMART Error Log Version: 1\n    \tNo Errors Logged\n\nAnd the second test:\n\n    SMART Attributes Data Structure revision number: 16\n    \tVendor Specific SMART Attributes with Thresholds:\n    \tID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n    \t  1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n    \t  3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n    \t  4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n    \t  5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n    \t  7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n    \t  9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43903\n    \t 10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n    \t 11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n    \t 12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    \t192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    \t193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123650\n    \t194 Temperature_Celsius     0x0022   119   103   000    Old_age   Always       -       33\n    \t196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    \t197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    \t198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    \t199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    \t200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n    \t\n    \tSMART Error Log Version: 1\n    \tNo Errors Logged\n\nBetween the first and second test, I filled the drive with random data overnight, but it didn't seem to make any difference.\n\nI have no clue what to make of this.  Everything tests well within tolerances, but the testing isn't completing properly?  No idea what to do with this.\n\nAny suggestions for next steps?  I have a Windows box I can plug this drive into for further testing, but is there any reason to think I'd get a different result?  I'm pretty stumped on this one.  Full logs in the comments in case it's helpful.", "author_fullname": "t2_vqak2uq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TrueNAS Scale shows that my drive's SMART test failed, but `smartctl` says it passed. Do I really have a problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1732na8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696781061.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696780669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ran a SMART test in TrueNAS for an old 6TB Western Digital Green drive (model WD60EZRX), and although TureNAS is telling me that the drive has failed the test, &lt;code&gt;smartctl&lt;/code&gt; gives a status of &amp;quot;SMART overall-health self-assessment test result: PASSED&amp;quot; and all of my actual values look okay.  I&amp;#39;m trying to figure out what&amp;#39;s going on.&lt;/p&gt;\n\n&lt;p&gt;From what I can tell, the issue is that the test isn&amp;#39;t completing.  I&amp;#39;m seeing this in the &lt;code&gt;General SMART Values:&lt;/code&gt; section:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    Self-test execution status:      (  57) A fatal error or unknown test error\n                                            occurred while the device was executing\n                                            its self-test routine and the device \n                                            was unable to complete the self-test \n                                            routine.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And under &lt;code&gt;SMART Self-test log structure&lt;/code&gt; I&amp;#39;m seeing this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    SMART Self-test log structure revision number 1\n    Num  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error\n    # 1  Short offline       Fatal or unknown error        90%     43903         -\n    # 2  Extended offline    Fatal or unknown error        90%     43881         -\n    # 3  Short offline       Fatal or unknown error        90%     43879         -\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h1&gt;&lt;strong&gt;HOWEVER&lt;/strong&gt;!&lt;/h1&gt;\n\n&lt;p&gt;It does look like it&amp;#39;s updating the disk values in the &lt;code&gt;Vendor Specific SMART Attributes with Thresholds&lt;/code&gt; section.  Here&amp;#39;s the output of the first and second SMART tests for comparison:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    SMART Attributes Data Structure revision number: 16\n    Vendor Specific SMART Attributes with Thresholds:\n    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n      1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n      3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n      4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n      5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n      7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n      9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43890\n     10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n     11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n     12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123623\n    194 Temperature_Celsius     0x0022   123   103   000    Old_age   Always       -       29\n    196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n\n    SMART Error Log Version: 1\n    No Errors Logged\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And the second test:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SMART Attributes Data Structure revision number: 16\n    Vendor Specific SMART Attributes with Thresholds:\n    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n      1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n      3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n      4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n      5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n      7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n      9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43903\n     10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n     11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n     12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123650\n    194 Temperature_Celsius     0x0022   119   103   000    Old_age   Always       -       33\n    196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n\n    SMART Error Log Version: 1\n    No Errors Logged\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Between the first and second test, I filled the drive with random data overnight, but it didn&amp;#39;t seem to make any difference.&lt;/p&gt;\n\n&lt;p&gt;I have no clue what to make of this.  Everything tests well within tolerances, but the testing isn&amp;#39;t completing properly?  No idea what to do with this.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for next steps?  I have a Windows box I can plug this drive into for further testing, but is there any reason to think I&amp;#39;d get a different result?  I&amp;#39;m pretty stumped on this one.  Full logs in the comments in case it&amp;#39;s helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1732na8", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyForSomeThings", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1732na8/truenas_scale_shows_that_my_drives_smart_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1732na8/truenas_scale_shows_that_my_drives_smart_test/", "subreddit_subscribers": 705638, "created_utc": 1696780669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What can archive downloaders are safe to use, I was about to use camsweb but I\u2019m unsure of its safety, other places charge payment are there any other free sites that are confirmed safe to use?", "author_fullname": "t2_81aol1r9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archive safety", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172x5xg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696765516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What can archive downloaders are safe to use, I was about to use camsweb but I\u2019m unsure of its safety, other places charge payment are there any other free sites that are confirmed safe to use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172x5xg", "is_robot_indexable": true, "report_reasons": null, "author": "Revolutionary-Group7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172x5xg/archive_safety/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172x5xg/archive_safety/", "subreddit_subscribers": 705638, "created_utc": 1696765516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, almost all of my files are stored on my computer, and phone in the same manner and many of them are 320kbs, some even higher, however my phone is running low on space can't run the powerful good headphones and doesn't need as high of bitrate, so I want to convert a copy on my phone at 192 or 128 kbs as aac files (just to be consistent with ky other non-flac files) \n\nDo you know any good tools for this? All of the ones I tried either are online with a limit, or crash even I put over a bou 150 songs In the queue (total of about 2200 to convert iirc)", "author_fullname": "t2_3re8ly8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk Audio conversion for use on phone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172rkx6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696744518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, almost all of my files are stored on my computer, and phone in the same manner and many of them are 320kbs, some even higher, however my phone is running low on space can&amp;#39;t run the powerful good headphones and doesn&amp;#39;t need as high of bitrate, so I want to convert a copy on my phone at 192 or 128 kbs as aac files (just to be consistent with ky other non-flac files) &lt;/p&gt;\n\n&lt;p&gt;Do you know any good tools for this? All of the ones I tried either are online with a limit, or crash even I put over a bou 150 songs In the queue (total of about 2200 to convert iirc)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172rkx6", "is_robot_indexable": true, "report_reasons": null, "author": "WHOTOOKMEEP", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172rkx6/bulk_audio_conversion_for_use_on_phone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172rkx6/bulk_audio_conversion_for_use_on_phone/", "subreddit_subscribers": 705638, "created_utc": 1696744518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just wondering if anyone uses a company to backup their NAS servers and what would be recommended, I\u2019m currently sitting at just under 8tb and looking to continue to increase as time goes on.\n\nCouple of features I would like would be to stream from this cloud or download media from it to watch and at the same time it\u2019ll act as a backup for my home NAS.\n\n\nAny help here would be great thanks!", "author_fullname": "t2_o6pjtof", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Large cloud storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1735etr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696787765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering if anyone uses a company to backup their NAS servers and what would be recommended, I\u2019m currently sitting at just under 8tb and looking to continue to increase as time goes on.&lt;/p&gt;\n\n&lt;p&gt;Couple of features I would like would be to stream from this cloud or download media from it to watch and at the same time it\u2019ll act as a backup for my home NAS.&lt;/p&gt;\n\n&lt;p&gt;Any help here would be great thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1735etr", "is_robot_indexable": true, "report_reasons": null, "author": "Aswe14", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1735etr/large_cloud_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1735etr/large_cloud_storage/", "subreddit_subscribers": 705638, "created_utc": 1696787765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I'm currently new to this topic so I would like some clarification between cloning and imaging. I've done some research, but most of the articles aren't doing a very good job of clarifying the differences between the two and which is most effective for what.  \n\n\nSo here are some of the scenarios that I will create a backup for:\n\n1. Restoring windows and my data in case of a software issue (bad update or malware, but hardware is fine)\n2. Replacing a failing hard drive. If my hard drive stops working the very next day, I would like to use my backup to restore all my files to a new drive\n3. Transferring all of my data from an old computer to a new computer.\n\nIn which of these scenarios would imaging or cloning make the most sense? \n\nThank you in advance.  \n\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_25235vtr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use imaging or cloning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_1733ztz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696784110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I&amp;#39;m currently new to this topic so I would like some clarification between cloning and imaging. I&amp;#39;ve done some research, but most of the articles aren&amp;#39;t doing a very good job of clarifying the differences between the two and which is most effective for what.  &lt;/p&gt;\n\n&lt;p&gt;So here are some of the scenarios that I will create a backup for:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Restoring windows and my data in case of a software issue (bad update or malware, but hardware is fine)&lt;/li&gt;\n&lt;li&gt;Replacing a failing hard drive. If my hard drive stops working the very next day, I would like to use my backup to restore all my files to a new drive&lt;/li&gt;\n&lt;li&gt;Transferring all of my data from an old computer to a new computer.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;In which of these scenarios would imaging or cloning make the most sense? &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1733ztz", "is_robot_indexable": true, "report_reasons": null, "author": "iSpazm", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1733ztz/should_i_use_imaging_or_cloning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1733ztz/should_i_use_imaging_or_cloning/", "subreddit_subscribers": 705638, "created_utc": 1696784110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been writing BD-REs with CDBurnerXP, and every single time I used \"verify data after burning\".\n\nI am using an external Blu-ray recorder. The ASUS SBW-06D5H-U. Connected with a 2 meter USB-C cable (+ 3.2 Micro-B for the device).\n\nIt came with a 0.5 m cable, not enough for me, so I got this other one.\n\n\\+++++++\n\nI noticed that on my i5 11400 (now 32 GB of DDR-4 RAM, MB is Z590-A Pro, from MSI), using two SSDs, one for C: is a 2 TB NVME from Western Digital, the other 870 EVO 4 TB from Samsung (regular):\n\n\\- It takes 40-45 minutes to burn a rewritable 25 GB disc; I tried in 2x, Ritek media;\n\n\\- I always use CDBurnerXP, and \"verify data after burning\".\n\nIn the past I used an old internal drive, the GGW-H20L from LG;\n\nI once bought 50 discs and noticed all 49 were recorded OK;\n\nIt takes additional 40-45 minutes to verify data after burning. I always let this enabled, to check if there isn't any data corruption. Is this a good idea?\n\nThe 50th disc which was not OK, I think I only spotted a problem with the \"verify after burning\". Most of the contents were fine; some were not, and could not be played (all my discs are backups, data only).\n\nThen I inspected the disc and noticed a very small scratch in the surface. Which accounts for the errors, that blank disc was already flawed.\n\n\\+++++\n\nA few more things I want to point out:\n\n\\- If I simply copy (control + C and control + V) the entire 25 GB disc (or 23 = real size) to my NVME SSD, it will take 25 minutes. But if I do the same for the Samsung regular SSD, it will take 35-40 minutes. I didn't know it was going to be slower depending on the SSD, I thought this was limited by the reader/disc speeds, regardless of the SSD used.\n\n\\++++  \nSome users on this sub and on the internet suggested IMGBURN instead, There's just one problem - CDBURNERXP is updated, while IMGBURN is no longer developed, the last version is [2.5.8.0](https://2.5.8.0), from 10 years ago. Even if you say it doesn't matter how old it is (for the purpose of burning and checking), are there any reasons to use IMGBURN instead, or it doesn't matter which one we choose?", "author_fullname": "t2_1utoiwm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Verifying a disc after burning, copying files back, and ImgBurn vs. CDBurnerXP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1733bf0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696782383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been writing BD-REs with CDBurnerXP, and every single time I used &amp;quot;verify data after burning&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I am using an external Blu-ray recorder. The ASUS SBW-06D5H-U. Connected with a 2 meter USB-C cable (+ 3.2 Micro-B for the device).&lt;/p&gt;\n\n&lt;p&gt;It came with a 0.5 m cable, not enough for me, so I got this other one.&lt;/p&gt;\n\n&lt;p&gt;+++++++&lt;/p&gt;\n\n&lt;p&gt;I noticed that on my i5 11400 (now 32 GB of DDR-4 RAM, MB is Z590-A Pro, from MSI), using two SSDs, one for C: is a 2 TB NVME from Western Digital, the other 870 EVO 4 TB from Samsung (regular):&lt;/p&gt;\n\n&lt;p&gt;- It takes 40-45 minutes to burn a rewritable 25 GB disc; I tried in 2x, Ritek media;&lt;/p&gt;\n\n&lt;p&gt;- I always use CDBurnerXP, and &amp;quot;verify data after burning&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;In the past I used an old internal drive, the GGW-H20L from LG;&lt;/p&gt;\n\n&lt;p&gt;I once bought 50 discs and noticed all 49 were recorded OK;&lt;/p&gt;\n\n&lt;p&gt;It takes additional 40-45 minutes to verify data after burning. I always let this enabled, to check if there isn&amp;#39;t any data corruption. Is this a good idea?&lt;/p&gt;\n\n&lt;p&gt;The 50th disc which was not OK, I think I only spotted a problem with the &amp;quot;verify after burning&amp;quot;. Most of the contents were fine; some were not, and could not be played (all my discs are backups, data only).&lt;/p&gt;\n\n&lt;p&gt;Then I inspected the disc and noticed a very small scratch in the surface. Which accounts for the errors, that blank disc was already flawed.&lt;/p&gt;\n\n&lt;p&gt;+++++&lt;/p&gt;\n\n&lt;p&gt;A few more things I want to point out:&lt;/p&gt;\n\n&lt;p&gt;- If I simply copy (control + C and control + V) the entire 25 GB disc (or 23 = real size) to my NVME SSD, it will take 25 minutes. But if I do the same for the Samsung regular SSD, it will take 35-40 minutes. I didn&amp;#39;t know it was going to be slower depending on the SSD, I thought this was limited by the reader/disc speeds, regardless of the SSD used.&lt;/p&gt;\n\n&lt;p&gt;++++&lt;br/&gt;\nSome users on this sub and on the internet suggested IMGBURN instead, There&amp;#39;s just one problem - CDBURNERXP is updated, while IMGBURN is no longer developed, the last version is &lt;a href=\"https://2.5.8.0\"&gt;2.5.8.0&lt;/a&gt;, from 10 years ago. Even if you say it doesn&amp;#39;t matter how old it is (for the purpose of burning and checking), are there any reasons to use IMGBURN instead, or it doesn&amp;#39;t matter which one we choose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1733bf0", "is_robot_indexable": true, "report_reasons": null, "author": "Maratocarde", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1733bf0/verifying_a_disc_after_burning_copying_files_back/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1733bf0/verifying_a_disc_after_burning_copying_files_back/", "subreddit_subscribers": 705638, "created_utc": 1696782383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there datahoarders, I was searching for a lot of time for solutions for bulk download from zlib. Sadly I wasn't able to find any real solutions. There was a post about this topic 3 years ago but there was no real solution.   \n\n\nDoes any one of you know about a solution for this? I am a bit skeptical and would love to have a database of books for personal use and would love to download non fiction books. ", "author_fullname": "t2_jvrt4662", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zlibrary Book Download", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17302gj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696774191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there datahoarders, I was searching for a lot of time for solutions for bulk download from zlib. Sadly I wasn&amp;#39;t able to find any real solutions. There was a post about this topic 3 years ago but there was no real solution.   &lt;/p&gt;\n\n&lt;p&gt;Does any one of you know about a solution for this? I am a bit skeptical and would love to have a database of books for personal use and would love to download non fiction books. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17302gj", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic-Patient56", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17302gj/zlibrary_book_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17302gj/zlibrary_book_download/", "subreddit_subscribers": 705638, "created_utc": 1696774191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is a short-depth 2.5\" 12GB SAS 24 drive JBOD enclosure that would fit well in my closet. The problem seems they are impossible to find. \n\nAnyone here who knows a good Chenbro reseller/shop in either Europe or USA? ", "author_fullname": "t2_7zshev0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Chenbro DS25224", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172wthk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696764303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a short-depth 2.5&amp;quot; 12GB SAS 24 drive JBOD enclosure that would fit well in my closet. The problem seems they are impossible to find. &lt;/p&gt;\n\n&lt;p&gt;Anyone here who knows a good Chenbro reseller/shop in either Europe or USA? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172wthk", "is_robot_indexable": true, "report_reasons": null, "author": "kY2iB3yH0mN8wI2h", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172wthk/looking_for_chenbro_ds25224/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172wthk/looking_for_chenbro_ds25224/", "subreddit_subscribers": 705638, "created_utc": 1696764303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The account in question is set to private but I'm a subscriber.\n\nWould be great if I could also archive comments to that account's posts.\nThank you.", "author_fullname": "t2_114rdj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I mass-archive caption text from an Instagram account's posts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172w4pu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696761826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The account in question is set to private but I&amp;#39;m a subscriber.&lt;/p&gt;\n\n&lt;p&gt;Would be great if I could also archive comments to that account&amp;#39;s posts.\nThank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "16TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172w4pu", "is_robot_indexable": true, "report_reasons": null, "author": "KitezhGrad", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/172w4pu/how_do_i_massarchive_caption_text_from_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172w4pu/how_do_i_massarchive_caption_text_from_an/", "subreddit_subscribers": 705638, "created_utc": 1696761826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have several LT0 5 FC drives and sleds, I have an LTO 6 drive and SAS sled, can they be swapped so I can continue using FC?", "author_fullname": "t2_kcl1hk9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you swap an LTO5 Sled on an LTO6 Sled", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172rzkm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696745961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have several LT0 5 FC drives and sleds, I have an LTO 6 drive and SAS sled, can they be swapped so I can continue using FC?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172rzkm", "is_robot_indexable": true, "report_reasons": null, "author": "metalabs", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172rzkm/can_you_swap_an_lto5_sled_on_an_lto6_sled/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172rzkm/can_you_swap_an_lto5_sled_on_an_lto6_sled/", "subreddit_subscribers": 705638, "created_utc": 1696745961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I keep seeing posts saying that a lot of SD cards and flash drives bought online are fake especially from Amazon. Where should I buy flash media to make sure it is legit and is there a way to test it to make sure it's authentic after I receive it? Follow up, do you get faster transfer speeds with a 3.1 flash drive or a modern micro SD with an SD to USB adapter?", "author_fullname": "t2_3latcv5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to buy flash media", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172r62z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696743021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I keep seeing posts saying that a lot of SD cards and flash drives bought online are fake especially from Amazon. Where should I buy flash media to make sure it is legit and is there a way to test it to make sure it&amp;#39;s authentic after I receive it? Follow up, do you get faster transfer speeds with a 3.1 flash drive or a modern micro SD with an SD to USB adapter?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172r62z", "is_robot_indexable": true, "report_reasons": null, "author": "reeper150", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172r62z/where_to_buy_flash_media/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172r62z/where_to_buy_flash_media/", "subreddit_subscribers": 705638, "created_utc": 1696743021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a functioning tool to download the saved posts / upvotes that you do on reddit? This tool: [https://github.com/shadowmoose/RedditDownloader](https://github.com/shadowmoose/RedditDownloader) was perfect, but it got rekt by the API changes and has been discontinued.", "author_fullname": "t2_16hsu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit downloader that works after API upgrade", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17304ho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696774341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a functioning tool to download the saved posts / upvotes that you do on reddit? This tool: &lt;a href=\"https://github.com/shadowmoose/RedditDownloader\"&gt;https://github.com/shadowmoose/RedditDownloader&lt;/a&gt; was perfect, but it got rekt by the API changes and has been discontinued.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17304ho", "is_robot_indexable": true, "report_reasons": null, "author": "TheSaltyJ", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17304ho/reddit_downloader_that_works_after_api_upgrade/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17304ho/reddit_downloader_that_works_after_api_upgrade/", "subreddit_subscribers": 705638, "created_utc": 1696774341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i have a few thousand videos that i need to crop and can't find any good software for pc, any suggestions? (would be better if it allows for custom crop ratio and not just 1:1 or 16:9 ect...)", "author_fullname": "t2_dfdoc6ab", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A good free video cropping software for lots of video?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172y71e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696768842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have a few thousand videos that i need to crop and can&amp;#39;t find any good software for pc, any suggestions? (would be better if it allows for custom crop ratio and not just 1:1 or 16:9 ect...)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "5,5TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172y71e", "is_robot_indexable": true, "report_reasons": null, "author": "Key-Wait-3098", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/172y71e/a_good_free_video_cropping_software_for_lots_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172y71e/a_good_free_video_cropping_software_for_lots_of/", "subreddit_subscribers": 705638, "created_utc": 1696768842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I ripped an entire show on my hard drive in iso to preserve the dvd menus, I would like to rip the episodes in different files instead of one big mkv with 6 or 7 episodes and I know how to do that for a singke dvd with MakeMkv manuak mode, is it possible to do iylt in batch?", "author_fullname": "t2_8gbb02ie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I need help with extracting episodes of a show", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172vhf0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696759404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ripped an entire show on my hard drive in iso to preserve the dvd menus, I would like to rip the episodes in different files instead of one big mkv with 6 or 7 episodes and I know how to do that for a singke dvd with MakeMkv manuak mode, is it possible to do iylt in batch?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172vhf0", "is_robot_indexable": true, "report_reasons": null, "author": "NoIdentityV0-1", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172vhf0/i_need_help_with_extracting_episodes_of_a_show/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172vhf0/i_need_help_with_extracting_episodes_of_a_show/", "subreddit_subscribers": 705638, "created_utc": 1696759404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a WD Elements 8 TB. This one: [https://www.amazon.com/dp/B07FNK6QMT](https://www.amazon.com/dp/B07FNK6QMT)\n\nSo everything seems to be OK, like SMART. I did an 13 hour long extended smart test. Other than accidently fucking up once (rotating it while it is running from horizontal to vertical which made a scary noise and probably reduced the hard drive lifetime by a decade) I don't see any issues OTHER THAN THE TEMPERATURE.\n\nMust note, it likes to click periodically and when plugged in. It also likes to make noises during SMART which I never heard before.\n\nYeah so, this drive is supposed to handle its own temperature, it literally asks for external power from plug so I assume it is for cooling? Yet it is literally **idling at 54-55C (crystaldiskinfo says that. It is red)** and during SMART it even maxed out to 57C or something. Touching the enclosure doesn't feel like it but I don't want to extract the drive from the enclosure when I can just refund right now (I don't plan to unless I hear some very bad things in the comments such as a chronic failure of this exact product)\n\n**Can I use it horizontally? It is intended to be vertical but I don't want to imagine it falling to one side... Not sure if the HDDs have a preferred rotation (vertical/horizontal).**\n\n**Did I really fuck up the interiors by rotating and hearing that ear screeching noise once? Is it official, final and permanent? How can I measure the damage?**\n\nEven though SMART tests didn't report failure, I will put this guy on 3 badblocks tests and measure SMART. **I hope it fails right there if it is faulty because I don't know what else I can do.**", "author_fullname": "t2_yj6p9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I bought a HDD, I have questions about its idling temperature + I may have done something really bad to it (I rotated it...)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172uqwj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696756595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a WD Elements 8 TB. This one: &lt;a href=\"https://www.amazon.com/dp/B07FNK6QMT\"&gt;https://www.amazon.com/dp/B07FNK6QMT&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So everything seems to be OK, like SMART. I did an 13 hour long extended smart test. Other than accidently fucking up once (rotating it while it is running from horizontal to vertical which made a scary noise and probably reduced the hard drive lifetime by a decade) I don&amp;#39;t see any issues OTHER THAN THE TEMPERATURE.&lt;/p&gt;\n\n&lt;p&gt;Must note, it likes to click periodically and when plugged in. It also likes to make noises during SMART which I never heard before.&lt;/p&gt;\n\n&lt;p&gt;Yeah so, this drive is supposed to handle its own temperature, it literally asks for external power from plug so I assume it is for cooling? Yet it is literally &lt;strong&gt;idling at 54-55C (crystaldiskinfo says that. It is red)&lt;/strong&gt; and during SMART it even maxed out to 57C or something. Touching the enclosure doesn&amp;#39;t feel like it but I don&amp;#39;t want to extract the drive from the enclosure when I can just refund right now (I don&amp;#39;t plan to unless I hear some very bad things in the comments such as a chronic failure of this exact product)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Can I use it horizontally? It is intended to be vertical but I don&amp;#39;t want to imagine it falling to one side... Not sure if the HDDs have a preferred rotation (vertical/horizontal).&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Did I really fuck up the interiors by rotating and hearing that ear screeching noise once? Is it official, final and permanent? How can I measure the damage?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Even though SMART tests didn&amp;#39;t report failure, I will put this guy on 3 badblocks tests and measure SMART. &lt;strong&gt;I hope it fails right there if it is faulty because I don&amp;#39;t know what else I can do.&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172uqwj", "is_robot_indexable": true, "report_reasons": null, "author": "LAMGE2", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172uqwj/i_bought_a_hdd_i_have_questions_about_its_idling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172uqwj/i_bought_a_hdd_i_have_questions_about_its_idling/", "subreddit_subscribers": 705638, "created_utc": 1696756595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to download videos from a website which only allows me to watch for a certain amount of time before locking, and the videos are private - can't just use inspect element to download. \n\nTried using video downloadhelper which came the closest, but it's only able to download 1-2 videos properly. The rest only come with audio, and are stuck at the first frame of the video the entire time.\n\nI tried using jdownloader2 but when I use the links, too many things would be there, but not the mp4.\n\nAny other good ways which will let me download video with audio?", "author_fullname": "t2_6ge26gbj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to download videos from website which has timer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172xumh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696768678.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696767725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to download videos from a website which only allows me to watch for a certain amount of time before locking, and the videos are private - can&amp;#39;t just use inspect element to download. &lt;/p&gt;\n\n&lt;p&gt;Tried using video downloadhelper which came the closest, but it&amp;#39;s only able to download 1-2 videos properly. The rest only come with audio, and are stuck at the first frame of the video the entire time.&lt;/p&gt;\n\n&lt;p&gt;I tried using jdownloader2 but when I use the links, too many things would be there, but not the mp4.&lt;/p&gt;\n\n&lt;p&gt;Any other good ways which will let me download video with audio?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172xumh", "is_robot_indexable": true, "report_reasons": null, "author": "AvxrageX", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172xumh/trying_to_download_videos_from_website_which_has/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172xumh/trying_to_download_videos_from_website_which_has/", "subreddit_subscribers": 705638, "created_utc": 1696767725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi! I'm new here so please cut me slack if I broke rules.. let me know and Ill do my best to fix the post or remove. \n\nOver recent years I have been attempting to \"collapse\" proof my (small(.5Tb)) personal stash of favorite media from deletion or loss due to some kind of EMP event. \n\nSure, there's fire, media degradation, water etc, but those are all solved problems. I.E. Insulation, robust media, multiple copies, seals, etc.\n\nBut an EMP event seems unsolved for a regular backup type situation.\n\nSo, I am wondering if anyone here is familiar with full digital SSD or HDD protection from lightning, solar EMP, nuclear EMP, or EMP device.\n\nTheoretical problems I have so far encountered are the data/power lines.\n\nOk cool, you've got a fully grounded 1/2' copper plate box to negate electromagnetic radiation.  How do you power it? How do you send/receive data?\n\nIf one were using standard ethernet, those conductors feed straight into your drive, same goes with power, via supply or USB.\n\nThe only option I could think of was to have two separate backup drives that opened a physical connection at different times in the day, to do their thing, before being mechanically sealed away inside a solid EMP proof casing.\n\nAm I missing anything? Figures I might be, so worth an ask right?\n\nNote: This is all for fun, nuke goes off and we're all most likely dead right? Still, might be fun to have my favorite meme videos in the post apocalypse. I enjoy the technological challenge though. ", "author_fullname": "t2_b3cvauh4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Failure proofing digital storage media for EMP scenario.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172qrn5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696741573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! I&amp;#39;m new here so please cut me slack if I broke rules.. let me know and Ill do my best to fix the post or remove. &lt;/p&gt;\n\n&lt;p&gt;Over recent years I have been attempting to &amp;quot;collapse&amp;quot; proof my (small(.5Tb)) personal stash of favorite media from deletion or loss due to some kind of EMP event. &lt;/p&gt;\n\n&lt;p&gt;Sure, there&amp;#39;s fire, media degradation, water etc, but those are all solved problems. I.E. Insulation, robust media, multiple copies, seals, etc.&lt;/p&gt;\n\n&lt;p&gt;But an EMP event seems unsolved for a regular backup type situation.&lt;/p&gt;\n\n&lt;p&gt;So, I am wondering if anyone here is familiar with full digital SSD or HDD protection from lightning, solar EMP, nuclear EMP, or EMP device.&lt;/p&gt;\n\n&lt;p&gt;Theoretical problems I have so far encountered are the data/power lines.&lt;/p&gt;\n\n&lt;p&gt;Ok cool, you&amp;#39;ve got a fully grounded 1/2&amp;#39; copper plate box to negate electromagnetic radiation.  How do you power it? How do you send/receive data?&lt;/p&gt;\n\n&lt;p&gt;If one were using standard ethernet, those conductors feed straight into your drive, same goes with power, via supply or USB.&lt;/p&gt;\n\n&lt;p&gt;The only option I could think of was to have two separate backup drives that opened a physical connection at different times in the day, to do their thing, before being mechanically sealed away inside a solid EMP proof casing.&lt;/p&gt;\n\n&lt;p&gt;Am I missing anything? Figures I might be, so worth an ask right?&lt;/p&gt;\n\n&lt;p&gt;Note: This is all for fun, nuke goes off and we&amp;#39;re all most likely dead right? Still, might be fun to have my favorite meme videos in the post apocalypse. I enjoy the technological challenge though. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "172qrn5", "is_robot_indexable": true, "report_reasons": null, "author": "PseudoEmpthy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172qrn5/failure_proofing_digital_storage_media_for_emp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172qrn5/failure_proofing_digital_storage_media_for_emp/", "subreddit_subscribers": 705638, "created_utc": 1696741573.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}