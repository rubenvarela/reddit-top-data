{"kind": "Listing", "data": {"after": "t3_172wthk", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I ran a SMART test in TrueNAS for an old 6TB Western Digital Green drive (model WD60EZRX), and although TureNAS is telling me that the drive has failed the test, `smartctl` gives a status of \"SMART overall-health self-assessment test result: PASSED\" and all of my actual values look okay.  I'm trying to figure out what's going on.\n\nFrom what I can tell, the issue is that the test isn't completing.  I'm seeing this in the `General SMART Values:` section:\n\n    \tSelf-test execution status:      (  57) A fatal error or unknown test error\n    \t                                        occurred while the device was executing\n    \t                                        its self-test routine and the device \n    \t                                        was unable to complete the self-test \n    \t                                        routine.\n\nAnd under `SMART Self-test log structure` I'm seeing this:\n\n    \tSMART Self-test log structure revision number 1\n    \tNum  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error\n    \t# 1  Short offline       Fatal or unknown error        90%     43903         -\n    \t# 2  Extended offline    Fatal or unknown error        90%     43881         -\n    \t# 3  Short offline       Fatal or unknown error        90%     43879         -\n\n\n\n#**HOWEVER**! \nIt does look like it's updating the disk values in the `Vendor Specific SMART Attributes with Thresholds` section.  Here's the output of the first and second SMART tests for comparison:\n\n    \tSMART Attributes Data Structure revision number: 16\n    \tVendor Specific SMART Attributes with Thresholds:\n    \tID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n    \t  1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n    \t  3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n    \t  4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n    \t  5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n    \t  7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n    \t  9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43890\n    \t 10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n    \t 11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n    \t 12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    \t192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    \t193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123623\n    \t194 Temperature_Celsius     0x0022   123   103   000    Old_age   Always       -       29\n    \t196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    \t197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    \t198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    \t199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    \t200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n    \t\n    \tSMART Error Log Version: 1\n    \tNo Errors Logged\n\nAnd the second test:\n\n    SMART Attributes Data Structure revision number: 16\n    \tVendor Specific SMART Attributes with Thresholds:\n    \tID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n    \t  1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n    \t  3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n    \t  4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n    \t  5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n    \t  7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n    \t  9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43903\n    \t 10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n    \t 11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n    \t 12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    \t192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    \t193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123650\n    \t194 Temperature_Celsius     0x0022   119   103   000    Old_age   Always       -       33\n    \t196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    \t197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    \t198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    \t199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    \t200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n    \t\n    \tSMART Error Log Version: 1\n    \tNo Errors Logged\n\nBetween the first and second test, I filled the drive with random data overnight, but it didn't seem to make any difference.\n\nI have no clue what to make of this.  Everything tests well within tolerances, but the testing isn't completing properly?  No idea what to do with this.\n\nAny suggestions for next steps?  I have a Windows box I can plug this drive into for further testing, but is there any reason to think I'd get a different result?  I'm pretty stumped on this one.  Full logs in the comments in case it's helpful.", "author_fullname": "t2_vqak2uq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TrueNAS Scale shows that my drive's SMART test failed, but `smartctl` says it passed. Do I really have a problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1732na8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 23, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 23, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696781061.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696780669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ran a SMART test in TrueNAS for an old 6TB Western Digital Green drive (model WD60EZRX), and although TureNAS is telling me that the drive has failed the test, &lt;code&gt;smartctl&lt;/code&gt; gives a status of &amp;quot;SMART overall-health self-assessment test result: PASSED&amp;quot; and all of my actual values look okay.  I&amp;#39;m trying to figure out what&amp;#39;s going on.&lt;/p&gt;\n\n&lt;p&gt;From what I can tell, the issue is that the test isn&amp;#39;t completing.  I&amp;#39;m seeing this in the &lt;code&gt;General SMART Values:&lt;/code&gt; section:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    Self-test execution status:      (  57) A fatal error or unknown test error\n                                            occurred while the device was executing\n                                            its self-test routine and the device \n                                            was unable to complete the self-test \n                                            routine.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And under &lt;code&gt;SMART Self-test log structure&lt;/code&gt; I&amp;#39;m seeing this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    SMART Self-test log structure revision number 1\n    Num  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error\n    # 1  Short offline       Fatal or unknown error        90%     43903         -\n    # 2  Extended offline    Fatal or unknown error        90%     43881         -\n    # 3  Short offline       Fatal or unknown error        90%     43879         -\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h1&gt;&lt;strong&gt;HOWEVER&lt;/strong&gt;!&lt;/h1&gt;\n\n&lt;p&gt;It does look like it&amp;#39;s updating the disk values in the &lt;code&gt;Vendor Specific SMART Attributes with Thresholds&lt;/code&gt; section.  Here&amp;#39;s the output of the first and second SMART tests for comparison:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    SMART Attributes Data Structure revision number: 16\n    Vendor Specific SMART Attributes with Thresholds:\n    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n      1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n      3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n      4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n      5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n      7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n      9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43890\n     10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n     11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n     12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123623\n    194 Temperature_Celsius     0x0022   123   103   000    Old_age   Always       -       29\n    196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n\n    SMART Error Log Version: 1\n    No Errors Logged\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And the second test:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SMART Attributes Data Structure revision number: 16\n    Vendor Specific SMART Attributes with Thresholds:\n    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n      1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n      3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n      4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n      5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n      7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n      9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43903\n     10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n     11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n     12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123650\n    194 Temperature_Celsius     0x0022   119   103   000    Old_age   Always       -       33\n    196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n\n    SMART Error Log Version: 1\n    No Errors Logged\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Between the first and second test, I filled the drive with random data overnight, but it didn&amp;#39;t seem to make any difference.&lt;/p&gt;\n\n&lt;p&gt;I have no clue what to make of this.  Everything tests well within tolerances, but the testing isn&amp;#39;t completing properly?  No idea what to do with this.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for next steps?  I have a Windows box I can plug this drive into for further testing, but is there any reason to think I&amp;#39;d get a different result?  I&amp;#39;m pretty stumped on this one.  Full logs in the comments in case it&amp;#39;s helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1732na8", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyForSomeThings", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1732na8/truenas_scale_shows_that_my_drives_smart_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1732na8/truenas_scale_shows_that_my_drives_smart_test/", "subreddit_subscribers": 705671, "created_utc": 1696780669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've found the following deal: [Seagate IronWolf Pro 16TB](https://www.jb-computer.de/komponenten-zubehoer/speicher/hdd/9078/seagate-ironwolf-pro-16tb-hdd-3.5-zoll-nas-festplatte-sata-6gb/s-7200rpm-recertified-new-st16000ne0?number=MJB991970)\n\nThey're \"Recertified new\", so they should be as good as new, but I'm still wondering about the price, since it's about 100\u20ac cheaper than everywhere else I could find.\n\nIs there anything that I should worry about / that I'm missing?", "author_fullname": "t2_clqfxwwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this deal too good to be true? [IronWolf Pro 16TB for 240\u20ac]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172w1r5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696761516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve found the following deal: &lt;a href=\"https://www.jb-computer.de/komponenten-zubehoer/speicher/hdd/9078/seagate-ironwolf-pro-16tb-hdd-3.5-zoll-nas-festplatte-sata-6gb/s-7200rpm-recertified-new-st16000ne0?number=MJB991970\"&gt;Seagate IronWolf Pro 16TB&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;re &amp;quot;Recertified new&amp;quot;, so they should be as good as new, but I&amp;#39;m still wondering about the price, since it&amp;#39;s about 100\u20ac cheaper than everywhere else I could find.&lt;/p&gt;\n\n&lt;p&gt;Is there anything that I should worry about / that I&amp;#39;m missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?auto=webp&amp;s=56b69a3282cb2b793518b93e5713fc05ca97b3a3", "width": 1021, "height": 1500}, "resolutions": [{"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6898dba29c225dfd92ade0f094b1bbc543b719a3", "width": 108, "height": 158}, {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a4b1c16bc0482411036a8bc1a55652efc557a52f", "width": 216, "height": 317}, {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3024895cf2dfea54a338522a6bc78b40b887c476", "width": 320, "height": 470}, {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6cdd1ca290de37f8d622429d54dceef9789eb559", "width": 640, "height": 940}, {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=eb5eac25e419fcfd5b6110cb0299daba31487979", "width": 960, "height": 1410}], "variants": {}, "id": "_I8KRd5bw-DkkX0QsAwG4hMeOwGXhPN3hpap37_8jGY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172w1r5", "is_robot_indexable": true, "report_reasons": null, "author": "SeltsamerMagnet", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172w1r5/is_this_deal_too_good_to_be_true_ironwolf_pro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172w1r5/is_this_deal_too_good_to_be_true_ironwolf_pro/", "subreddit_subscribers": 705671, "created_utc": 1696761516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://sketchfab.com/ffishAsia-and-floraZia/models](https://sketchfab.com/ffishAsia-and-floraZia/models)\n\nI'm posting this here for anyone interested in preserving this.", "author_fullname": "t2_vg1a74d0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kyushu University released 2180 models of animals and plants.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172q0vr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696738978.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://sketchfab.com/ffishAsia-and-floraZia/models\"&gt;https://sketchfab.com/ffishAsia-and-floraZia/models&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m posting this here for anyone interested in preserving this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172q0vr", "is_robot_indexable": true, "report_reasons": null, "author": "Not_Espion", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172q0vr/kyushu_university_released_2180_models_of_animals/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172q0vr/kyushu_university_released_2180_models_of_animals/", "subreddit_subscribers": 705671, "created_utc": 1696738978.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi I\u2019m on windows 10 and I\u2019ve started using Macrium Reflect to clone my files stored on an external hard drives and have cloned them to two other external hard drives for extra copies of my backups. But when I go to check the used space in disk properties they are a tiny bit off. \n\nI checked all folder sizes and modified date and they all matched up, but I\u2019ve also read that this is not a reliable method to verify copied files. \n\nOriginal Ext HDD 1,971,778,027,520 bytes\n\nClone of Ext HDD 1,971,716.644,864 bytes\n\nSecond Clone HDD 1,971,717,033,984 bytes\n\nIs this normal or should they be exactly the same?\n\nAny recommendations on how to verify that the filters on all three disks are exactly the same. \n\nI\u2019ve see terracopy mentioned but I think that\u2019s for files that have yet to be copied. \n\nThanks.", "author_fullname": "t2_5195n8p0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows software to verify copied files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172s5a4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696746556.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I\u2019m on windows 10 and I\u2019ve started using Macrium Reflect to clone my files stored on an external hard drives and have cloned them to two other external hard drives for extra copies of my backups. But when I go to check the used space in disk properties they are a tiny bit off. &lt;/p&gt;\n\n&lt;p&gt;I checked all folder sizes and modified date and they all matched up, but I\u2019ve also read that this is not a reliable method to verify copied files. &lt;/p&gt;\n\n&lt;p&gt;Original Ext HDD 1,971,778,027,520 bytes&lt;/p&gt;\n\n&lt;p&gt;Clone of Ext HDD 1,971,716.644,864 bytes&lt;/p&gt;\n\n&lt;p&gt;Second Clone HDD 1,971,717,033,984 bytes&lt;/p&gt;\n\n&lt;p&gt;Is this normal or should they be exactly the same?&lt;/p&gt;\n\n&lt;p&gt;Any recommendations on how to verify that the filters on all three disks are exactly the same. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve see terracopy mentioned but I think that\u2019s for files that have yet to be copied. &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172s5a4", "is_robot_indexable": true, "report_reasons": null, "author": "jumpyHR", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172s5a4/windows_software_to_verify_copied_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172s5a4/windows_software_to_verify_copied_files/", "subreddit_subscribers": 705671, "created_utc": 1696746556.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a 60+TB TrueNAS box. It's maybe half full, 20-30TB. Half of that is irreplaceable photos/video I've shot, the other half is movies/tv shows. I'd like to back up some or all of this to tape. Two copies, one offsite. Rotated monthly. \n\nI bought a LTO6 drive off ebay (External SAS) but haven't yet setup a server to handle the backups. I'm looking for recommendations for software and strategies to backup this data. \n\n1. What software would you use to backup zfs data sets to LTO-6 tape? \n   1. Each pool is lets say 10TB currently but could grow. \n   2. I'd really like to not pay yearly license fees but would pay for software if Free is not an option\n   3. I need two copies of each dataset\n   4. I've looked into Uranium and Veeam but I know almost nothing about them\n2. How should this be setup physically? I have a TrueNAS server and a Proxmox 8 server that have available slots that could talk to this drive. Do I make a windows VM and passthrough the drive? Do I setup a separate backup box?\n   1. I have a proxmox backup server but I dont think it can backup NFS shares to tape in the same way that LTO software can\n3. Any other considerations? LTFS or not? Something else I'm missing? How to transport tapes?", "author_fullname": "t2_a223n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LTO tape backup of NAS, what software to use", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172q92w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696739780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a 60+TB TrueNAS box. It&amp;#39;s maybe half full, 20-30TB. Half of that is irreplaceable photos/video I&amp;#39;ve shot, the other half is movies/tv shows. I&amp;#39;d like to back up some or all of this to tape. Two copies, one offsite. Rotated monthly. &lt;/p&gt;\n\n&lt;p&gt;I bought a LTO6 drive off ebay (External SAS) but haven&amp;#39;t yet setup a server to handle the backups. I&amp;#39;m looking for recommendations for software and strategies to backup this data. &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;What software would you use to backup zfs data sets to LTO-6 tape? \n\n&lt;ol&gt;\n&lt;li&gt;Each pool is lets say 10TB currently but could grow. &lt;/li&gt;\n&lt;li&gt;I&amp;#39;d really like to not pay yearly license fees but would pay for software if Free is not an option&lt;/li&gt;\n&lt;li&gt;I need two copies of each dataset&lt;/li&gt;\n&lt;li&gt;I&amp;#39;ve looked into Uranium and Veeam but I know almost nothing about them&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;How should this be setup physically? I have a TrueNAS server and a Proxmox 8 server that have available slots that could talk to this drive. Do I make a windows VM and passthrough the drive? Do I setup a separate backup box?\n\n&lt;ol&gt;\n&lt;li&gt;I have a proxmox backup server but I dont think it can backup NFS shares to tape in the same way that LTO software can&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;li&gt;Any other considerations? LTFS or not? Something else I&amp;#39;m missing? How to transport tapes?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172q92w", "is_robot_indexable": true, "report_reasons": null, "author": "pcmofo", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172q92w/lto_tape_backup_of_nas_what_software_to_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172q92w/lto_tape_backup_of_nas_what_software_to_use/", "subreddit_subscribers": 705671, "created_utc": 1696739780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Anyone hoarding videos from Israel-Palestine, and Russia-Ukraine wars. How do you chronicle? How do you vet the correctness? What sources do you use? I guess sources are too many to list but I would appreciate some discussion.", "author_fullname": "t2_2lugimc5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone doing war footage archiving?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172q3im", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696739246.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone hoarding videos from Israel-Palestine, and Russia-Ukraine wars. How do you chronicle? How do you vet the correctness? What sources do you use? I guess sources are too many to list but I would appreciate some discussion.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "50TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172q3im", "is_robot_indexable": true, "report_reasons": null, "author": "logicalcliff", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/172q3im/anyone_doing_war_footage_archiving/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172q3im/anyone_doing_war_footage_archiving/", "subreddit_subscribers": 705671, "created_utc": 1696739246.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been writing BD-REs with CDBurnerXP, and every single time I used \"verify data after burning\".\n\nI am using an external Blu-ray recorder. The ASUS SBW-06D5H-U. Connected with a 2 meter USB-C cable (+ 3.2 Micro-B for the device).\n\nIt came with a 0.5 m cable, not enough for me, so I got this other one.\n\n\\+++++++\n\nI noticed that on my i5 11400 (now 32 GB of DDR-4 RAM, MB is Z590-A Pro, from MSI), using two SSDs, one for C: is a 2 TB NVME from Western Digital, the other 870 EVO 4 TB from Samsung (regular):\n\n\\- It takes 40-45 minutes to burn a rewritable 25 GB disc; I tried in 2x, Ritek media;\n\n\\- I always use CDBurnerXP, and \"verify data after burning\".\n\nIn the past I used an old internal drive, the GGW-H20L from LG;\n\nI once bought 50 discs and noticed all 49 were recorded OK;\n\nIt takes additional 40-45 minutes to verify data after burning. I always let this enabled, to check if there isn't any data corruption. Is this a good idea?\n\nThe 50th disc which was not OK, I think I only spotted a problem with the \"verify after burning\". Most of the contents were fine; some were not, and could not be played (all my discs are backups, data only).\n\nThen I inspected the disc and noticed a very small scratch in the surface. Which accounts for the errors, that blank disc was already flawed.\n\n\\+++++\n\nA few more things I want to point out:\n\n\\- If I simply copy (control + C and control + V) the entire 25 GB disc (or 23 = real size) to my NVME SSD, it will take 25 minutes. But if I do the same for the Samsung regular SSD, it will take 35-40 minutes. I didn't know it was going to be slower depending on the SSD, I thought this was limited by the reader/disc speeds, regardless of the SSD used.\n\n\\++++  \nSome users on this sub and on the internet suggested IMGBURN instead, There's just one problem - CDBURNERXP is updated, while IMGBURN is no longer developed, the last version is [2.5.8.0](https://2.5.8.0), from 10 years ago. Even if you say it doesn't matter how old it is (for the purpose of burning and checking), are there any reasons to use IMGBURN instead, or it doesn't matter which one we choose?", "author_fullname": "t2_1utoiwm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Verifying a disc after burning, copying files back, and ImgBurn vs. CDBurnerXP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1733bf0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696782383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been writing BD-REs with CDBurnerXP, and every single time I used &amp;quot;verify data after burning&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I am using an external Blu-ray recorder. The ASUS SBW-06D5H-U. Connected with a 2 meter USB-C cable (+ 3.2 Micro-B for the device).&lt;/p&gt;\n\n&lt;p&gt;It came with a 0.5 m cable, not enough for me, so I got this other one.&lt;/p&gt;\n\n&lt;p&gt;+++++++&lt;/p&gt;\n\n&lt;p&gt;I noticed that on my i5 11400 (now 32 GB of DDR-4 RAM, MB is Z590-A Pro, from MSI), using two SSDs, one for C: is a 2 TB NVME from Western Digital, the other 870 EVO 4 TB from Samsung (regular):&lt;/p&gt;\n\n&lt;p&gt;- It takes 40-45 minutes to burn a rewritable 25 GB disc; I tried in 2x, Ritek media;&lt;/p&gt;\n\n&lt;p&gt;- I always use CDBurnerXP, and &amp;quot;verify data after burning&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;In the past I used an old internal drive, the GGW-H20L from LG;&lt;/p&gt;\n\n&lt;p&gt;I once bought 50 discs and noticed all 49 were recorded OK;&lt;/p&gt;\n\n&lt;p&gt;It takes additional 40-45 minutes to verify data after burning. I always let this enabled, to check if there isn&amp;#39;t any data corruption. Is this a good idea?&lt;/p&gt;\n\n&lt;p&gt;The 50th disc which was not OK, I think I only spotted a problem with the &amp;quot;verify after burning&amp;quot;. Most of the contents were fine; some were not, and could not be played (all my discs are backups, data only).&lt;/p&gt;\n\n&lt;p&gt;Then I inspected the disc and noticed a very small scratch in the surface. Which accounts for the errors, that blank disc was already flawed.&lt;/p&gt;\n\n&lt;p&gt;+++++&lt;/p&gt;\n\n&lt;p&gt;A few more things I want to point out:&lt;/p&gt;\n\n&lt;p&gt;- If I simply copy (control + C and control + V) the entire 25 GB disc (or 23 = real size) to my NVME SSD, it will take 25 minutes. But if I do the same for the Samsung regular SSD, it will take 35-40 minutes. I didn&amp;#39;t know it was going to be slower depending on the SSD, I thought this was limited by the reader/disc speeds, regardless of the SSD used.&lt;/p&gt;\n\n&lt;p&gt;++++&lt;br/&gt;\nSome users on this sub and on the internet suggested IMGBURN instead, There&amp;#39;s just one problem - CDBURNERXP is updated, while IMGBURN is no longer developed, the last version is &lt;a href=\"https://2.5.8.0\"&gt;2.5.8.0&lt;/a&gt;, from 10 years ago. Even if you say it doesn&amp;#39;t matter how old it is (for the purpose of burning and checking), are there any reasons to use IMGBURN instead, or it doesn&amp;#39;t matter which one we choose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1733bf0", "is_robot_indexable": true, "report_reasons": null, "author": "Maratocarde", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1733bf0/verifying_a_disc_after_burning_copying_files_back/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1733bf0/verifying_a_disc_after_burning_copying_files_back/", "subreddit_subscribers": 705671, "created_utc": 1696782383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there datahoarders, I was searching for a lot of time for solutions for bulk download from zlib. Sadly I wasn't able to find any real solutions. There was a post about this topic 3 years ago but there was no real solution.   \n\n\nDoes any one of you know about a solution for this? I am a bit skeptical and would love to have a database of books for personal use and would love to download non fiction books. ", "author_fullname": "t2_jvrt4662", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zlibrary Book Download", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17302gj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696774191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there datahoarders, I was searching for a lot of time for solutions for bulk download from zlib. Sadly I wasn&amp;#39;t able to find any real solutions. There was a post about this topic 3 years ago but there was no real solution.   &lt;/p&gt;\n\n&lt;p&gt;Does any one of you know about a solution for this? I am a bit skeptical and would love to have a database of books for personal use and would love to download non fiction books. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17302gj", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic-Patient56", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17302gj/zlibrary_book_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17302gj/zlibrary_book_download/", "subreddit_subscribers": 705671, "created_utc": 1696774191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a 2 TB SanDisk SSD on Amazon, and let it sit around for couple weeks before I got around to trying it out on my iMac. I struggled to get the thing recognized by the Mac, and then when it did show up, I couldn't format the drive to anything but MAC OS (attempts at APFS failed every time). Once it was formatted, file transfers were slow, and then the files I copied on there as a test just disappeared. Now the thing doesn't function at all, either on the Mac or on a Win 11 laptop. The thing is dead.\n\n&amp;#x200B;\n\nAm I just out the money I spent on it? I waited too long and I can't return it to Amazon, and SanDisk won't take it either. Also, what is a decent 2-4 TB SSD I could trust? The SanDisk looked really cool, but I certainly don't trust it to buy another one.", "author_fullname": "t2_4vnjyete", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SanDisk Extreme SSD bricked. What now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173a11c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696799368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a 2 TB SanDisk SSD on Amazon, and let it sit around for couple weeks before I got around to trying it out on my iMac. I struggled to get the thing recognized by the Mac, and then when it did show up, I couldn&amp;#39;t format the drive to anything but MAC OS (attempts at APFS failed every time). Once it was formatted, file transfers were slow, and then the files I copied on there as a test just disappeared. Now the thing doesn&amp;#39;t function at all, either on the Mac or on a Win 11 laptop. The thing is dead.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Am I just out the money I spent on it? I waited too long and I can&amp;#39;t return it to Amazon, and SanDisk won&amp;#39;t take it either. Also, what is a decent 2-4 TB SSD I could trust? The SanDisk looked really cool, but I certainly don&amp;#39;t trust it to buy another one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173a11c", "is_robot_indexable": true, "report_reasons": null, "author": "tedlyri", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173a11c/sandisk_extreme_ssd_bricked_what_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173a11c/sandisk_extreme_ssd_bricked_what_now/", "subreddit_subscribers": 705671, "created_utc": 1696799368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, almost all of my files are stored on my computer, and phone in the same manner and many of them are 320kbs, some even higher, however my phone is running low on space can't run the powerful good headphones and doesn't need as high of bitrate, so I want to convert a copy on my phone at 192 or 128 kbs as aac files (just to be consistent with ky other non-flac files) \n\nDo you know any good tools for this? All of the ones I tried either are online with a limit, or crash even I put over a bou 150 songs In the queue (total of about 2200 to convert iirc)", "author_fullname": "t2_3re8ly8f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk Audio conversion for use on phone?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172rkx6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696744518.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, almost all of my files are stored on my computer, and phone in the same manner and many of them are 320kbs, some even higher, however my phone is running low on space can&amp;#39;t run the powerful good headphones and doesn&amp;#39;t need as high of bitrate, so I want to convert a copy on my phone at 192 or 128 kbs as aac files (just to be consistent with ky other non-flac files) &lt;/p&gt;\n\n&lt;p&gt;Do you know any good tools for this? All of the ones I tried either are online with a limit, or crash even I put over a bou 150 songs In the queue (total of about 2200 to convert iirc)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172rkx6", "is_robot_indexable": true, "report_reasons": null, "author": "WHOTOOKMEEP", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172rkx6/bulk_audio_conversion_for_use_on_phone/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172rkx6/bulk_audio_conversion_for_use_on_phone/", "subreddit_subscribers": 705671, "created_utc": 1696744518.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi \n\nI currently have a LSI 9305-24i in my server with 24 drives connected up. This card has the AVAGO bios on the card.\n\nMy question, if i purchase another card for example a LSI 9300-8i would I be able to see that AVAGO bios also during the post?\n\nSorry if this question is pretty dumb but I am pretty new to this.\n\nReason being I want to test if my current card is playing up as one the drives is negotiating at 3Gbps instead of 6Gbps.\n\nThe server is a Truenas build.\n\nOnce again sorry if this is stupid", "author_fullname": "t2_4kl3s1e1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I use 2 different SAS cards in my server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1739mhx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696798344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;/p&gt;\n\n&lt;p&gt;I currently have a LSI 9305-24i in my server with 24 drives connected up. This card has the AVAGO bios on the card.&lt;/p&gt;\n\n&lt;p&gt;My question, if i purchase another card for example a LSI 9300-8i would I be able to see that AVAGO bios also during the post?&lt;/p&gt;\n\n&lt;p&gt;Sorry if this question is pretty dumb but I am pretty new to this.&lt;/p&gt;\n\n&lt;p&gt;Reason being I want to test if my current card is playing up as one the drives is negotiating at 3Gbps instead of 6Gbps.&lt;/p&gt;\n\n&lt;p&gt;The server is a Truenas build.&lt;/p&gt;\n\n&lt;p&gt;Once again sorry if this is stupid&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1739mhx", "is_robot_indexable": true, "report_reasons": null, "author": "AJBOJACK", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1739mhx/can_i_use_2_different_sas_cards_in_my_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1739mhx/can_i_use_2_different_sas_cards_in_my_server/", "subreddit_subscribers": 705671, "created_utc": 1696798344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I'm currently new to this topic so I would like some clarification between cloning and imaging. I've done some research, but most of the articles aren't doing a very good job of clarifying the differences between the two and which is most effective for what.  \n\n\nSo here are some of the scenarios that I will create a backup for:\n\n1. Restoring windows and my data in case of a software issue (bad update or malware, but hardware is fine)\n2. Replacing a failing hard drive. If my hard drive stops working the very next day, I would like to use my backup to restore all my files to a new drive\n3. Transferring all of my data from an old computer to a new computer.\n\nIn which of these scenarios would imaging or cloning make the most sense? \n\nThank you in advance.  \n\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_25235vtr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use imaging or cloning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1733ztz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696784110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I&amp;#39;m currently new to this topic so I would like some clarification between cloning and imaging. I&amp;#39;ve done some research, but most of the articles aren&amp;#39;t doing a very good job of clarifying the differences between the two and which is most effective for what.  &lt;/p&gt;\n\n&lt;p&gt;So here are some of the scenarios that I will create a backup for:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Restoring windows and my data in case of a software issue (bad update or malware, but hardware is fine)&lt;/li&gt;\n&lt;li&gt;Replacing a failing hard drive. If my hard drive stops working the very next day, I would like to use my backup to restore all my files to a new drive&lt;/li&gt;\n&lt;li&gt;Transferring all of my data from an old computer to a new computer.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;In which of these scenarios would imaging or cloning make the most sense? &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1733ztz", "is_robot_indexable": true, "report_reasons": null, "author": "iSpazm", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1733ztz/should_i_use_imaging_or_cloning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1733ztz/should_i_use_imaging_or_cloning/", "subreddit_subscribers": 705671, "created_utc": 1696784110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a functioning tool to download the saved posts / upvotes that you do on reddit? This tool: [https://github.com/shadowmoose/RedditDownloader](https://github.com/shadowmoose/RedditDownloader) was perfect, but it got rekt by the API changes and has been discontinued.", "author_fullname": "t2_16hsu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit downloader that works after API upgrade", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17304ho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696774341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a functioning tool to download the saved posts / upvotes that you do on reddit? This tool: &lt;a href=\"https://github.com/shadowmoose/RedditDownloader\"&gt;https://github.com/shadowmoose/RedditDownloader&lt;/a&gt; was perfect, but it got rekt by the API changes and has been discontinued.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17304ho", "is_robot_indexable": true, "report_reasons": null, "author": "TheSaltyJ", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17304ho/reddit_downloader_that_works_after_api_upgrade/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17304ho/reddit_downloader_that_works_after_api_upgrade/", "subreddit_subscribers": 705671, "created_utc": 1696774341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What is the best way to upgrade RAID1 pool with 2 WD 500gb drives? I bought 2x4 TB drives but my truenas server only has 3 sata ports. What should i do?", "author_fullname": "t2_adfbrmlw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expanding NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172zvdn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696773671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the best way to upgrade RAID1 pool with 2 WD 500gb drives? I bought 2x4 TB drives but my truenas server only has 3 sata ports. What should i do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172zvdn", "is_robot_indexable": true, "report_reasons": null, "author": "picua_", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172zvdn/expanding_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172zvdn/expanding_nas/", "subreddit_subscribers": 705671, "created_utc": 1696773671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What can archive downloaders are safe to use, I was about to use camsweb but I\u2019m unsure of its safety, other places charge payment are there any other free sites that are confirmed safe to use?", "author_fullname": "t2_81aol1r9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archive safety", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172x5xg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696765516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What can archive downloaders are safe to use, I was about to use camsweb but I\u2019m unsure of its safety, other places charge payment are there any other free sites that are confirmed safe to use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172x5xg", "is_robot_indexable": true, "report_reasons": null, "author": "Revolutionary-Group7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172x5xg/archive_safety/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172x5xg/archive_safety/", "subreddit_subscribers": 705671, "created_utc": 1696765516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The account in question is set to private but I'm a subscriber.\n\nWould be great if I could also archive comments to that account's posts.\nThank you.", "author_fullname": "t2_114rdj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I mass-archive caption text from an Instagram account's posts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172w4pu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696761826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The account in question is set to private but I&amp;#39;m a subscriber.&lt;/p&gt;\n\n&lt;p&gt;Would be great if I could also archive comments to that account&amp;#39;s posts.\nThank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "16TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172w4pu", "is_robot_indexable": true, "report_reasons": null, "author": "KitezhGrad", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/172w4pu/how_do_i_massarchive_caption_text_from_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172w4pu/how_do_i_massarchive_caption_text_from_an/", "subreddit_subscribers": 705671, "created_utc": 1696761826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a WD Elements 8 TB. This one: [https://www.amazon.com/dp/B07FNK6QMT](https://www.amazon.com/dp/B07FNK6QMT)\n\nSo everything seems to be OK, like SMART. I did an 13 hour long extended smart test. Other than accidently fucking up once (rotating it while it is running from horizontal to vertical which made a scary noise and probably reduced the hard drive lifetime by a decade) I don't see any issues OTHER THAN THE TEMPERATURE.\n\nMust note, it likes to click periodically and when plugged in. It also likes to make noises during SMART which I never heard before.\n\nYeah so, this drive is supposed to handle its own temperature, it literally asks for external power from plug so I assume it is for cooling? Yet it is literally **idling at 54-55C (crystaldiskinfo says that. It is red)** and during SMART it even maxed out to 57C or something. Touching the enclosure doesn't feel like it but I don't want to extract the drive from the enclosure when I can just refund right now (I don't plan to unless I hear some very bad things in the comments such as a chronic failure of this exact product)\n\n**Can I use it horizontally? It is intended to be vertical but I don't want to imagine it falling to one side... Not sure if the HDDs have a preferred rotation (vertical/horizontal).**\n\n**Did I really fuck up the interiors by rotating and hearing that ear screeching noise once? Is it official, final and permanent? How can I measure the damage?**\n\nEven though SMART tests didn't report failure, I will put this guy on 3 badblocks tests and measure SMART. **I hope it fails right there if it is faulty because I don't know what else I can do.**", "author_fullname": "t2_yj6p9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I bought a HDD, I have questions about its idling temperature + I may have done something really bad to it (I rotated it...)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172uqwj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696756595.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a WD Elements 8 TB. This one: &lt;a href=\"https://www.amazon.com/dp/B07FNK6QMT\"&gt;https://www.amazon.com/dp/B07FNK6QMT&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;So everything seems to be OK, like SMART. I did an 13 hour long extended smart test. Other than accidently fucking up once (rotating it while it is running from horizontal to vertical which made a scary noise and probably reduced the hard drive lifetime by a decade) I don&amp;#39;t see any issues OTHER THAN THE TEMPERATURE.&lt;/p&gt;\n\n&lt;p&gt;Must note, it likes to click periodically and when plugged in. It also likes to make noises during SMART which I never heard before.&lt;/p&gt;\n\n&lt;p&gt;Yeah so, this drive is supposed to handle its own temperature, it literally asks for external power from plug so I assume it is for cooling? Yet it is literally &lt;strong&gt;idling at 54-55C (crystaldiskinfo says that. It is red)&lt;/strong&gt; and during SMART it even maxed out to 57C or something. Touching the enclosure doesn&amp;#39;t feel like it but I don&amp;#39;t want to extract the drive from the enclosure when I can just refund right now (I don&amp;#39;t plan to unless I hear some very bad things in the comments such as a chronic failure of this exact product)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Can I use it horizontally? It is intended to be vertical but I don&amp;#39;t want to imagine it falling to one side... Not sure if the HDDs have a preferred rotation (vertical/horizontal).&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Did I really fuck up the interiors by rotating and hearing that ear screeching noise once? Is it official, final and permanent? How can I measure the damage?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Even though SMART tests didn&amp;#39;t report failure, I will put this guy on 3 badblocks tests and measure SMART. &lt;strong&gt;I hope it fails right there if it is faulty because I don&amp;#39;t know what else I can do.&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172uqwj", "is_robot_indexable": true, "report_reasons": null, "author": "LAMGE2", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172uqwj/i_bought_a_hdd_i_have_questions_about_its_idling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172uqwj/i_bought_a_hdd_i_have_questions_about_its_idling/", "subreddit_subscribers": 705671, "created_utc": 1696756595.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have several LT0 5 FC drives and sleds, I have an LTO 6 drive and SAS sled, can they be swapped so I can continue using FC?", "author_fullname": "t2_kcl1hk9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you swap an LTO5 Sled on an LTO6 Sled", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172rzkm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696745961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have several LT0 5 FC drives and sleds, I have an LTO 6 drive and SAS sled, can they be swapped so I can continue using FC?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172rzkm", "is_robot_indexable": true, "report_reasons": null, "author": "metalabs", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172rzkm/can_you_swap_an_lto5_sled_on_an_lto6_sled/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172rzkm/can_you_swap_an_lto5_sled_on_an_lto6_sled/", "subreddit_subscribers": 705671, "created_utc": 1696745961.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I keep seeing posts saying that a lot of SD cards and flash drives bought online are fake especially from Amazon. Where should I buy flash media to make sure it is legit and is there a way to test it to make sure it's authentic after I receive it? Follow up, do you get faster transfer speeds with a 3.1 flash drive or a modern micro SD with an SD to USB adapter?", "author_fullname": "t2_3latcv5q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to buy flash media", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172r62z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696743021.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I keep seeing posts saying that a lot of SD cards and flash drives bought online are fake especially from Amazon. Where should I buy flash media to make sure it is legit and is there a way to test it to make sure it&amp;#39;s authentic after I receive it? Follow up, do you get faster transfer speeds with a 3.1 flash drive or a modern micro SD with an SD to USB adapter?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172r62z", "is_robot_indexable": true, "report_reasons": null, "author": "reeper150", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172r62z/where_to_buy_flash_media/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172r62z/where_to_buy_flash_media/", "subreddit_subscribers": 705671, "created_utc": 1696743021.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi everyone, I've created a script that utilizes the Whisper model to generate subtitles. I'm aware that there's an option in Bazarr to use Whisper as a source, but it only employs a selected docker image for the Whisper model. Unfortunately, in my case, this doesn't allow the use of m2 Neural Engine.\n\nAdditionally, I'd like to be able to identify the generated subtitles in my web player (Emby / Plex / Jellyfin). However, Bazarr's naming conventions currently don't accommodate this.\n\nWould this be helpful for everyone? I'm considering making it open source.\n\nCurrent features:\n\n1. Set up folders to scan.\n2. Choose interval time to rescan folder.\n3. This script will start generating subtitles for videos with the fewest available subtitles (it sorts all videos by subtitle count, including embedded subtitles).\n4. Option to choose Whisper model (tiny / small / medium, etc.).\n5. Progress bar with ETA (Estimated Time of Arrival) showing subtitle generation progress.\n6. Subtitles are named like \"AI - English\" for easy identification.\n7. Support for Core ML is included to fully leverage the Neural Engine of the M series chips.\n\nMissing features:\n\n1. No web UI.\n2. Converting video to audio using ffmpeg isn't utilizing hardware acceleration. (The Whisper model requires audio to generate subtitles).\n3. No option to manually generate subtitles.\n4. Songs are not supported yet. I'm considering generating an LRC file for live lyrics.\n5. Option to distribute the workload across multiple servers.\n6. No docker image available (although I may be mistaken, as it may not be possible with Neural Engine support).\n7. No GPU support for Whisper model yet on Nvidia / AMD / Intel systems. \n\nLet me know what you think! \ud83c\udf89", "author_fullname": "t2_77pdgip9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created a script for subtitles", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172pb2e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696736563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I&amp;#39;ve created a script that utilizes the Whisper model to generate subtitles. I&amp;#39;m aware that there&amp;#39;s an option in Bazarr to use Whisper as a source, but it only employs a selected docker image for the Whisper model. Unfortunately, in my case, this doesn&amp;#39;t allow the use of m2 Neural Engine.&lt;/p&gt;\n\n&lt;p&gt;Additionally, I&amp;#39;d like to be able to identify the generated subtitles in my web player (Emby / Plex / Jellyfin). However, Bazarr&amp;#39;s naming conventions currently don&amp;#39;t accommodate this.&lt;/p&gt;\n\n&lt;p&gt;Would this be helpful for everyone? I&amp;#39;m considering making it open source.&lt;/p&gt;\n\n&lt;p&gt;Current features:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Set up folders to scan.&lt;/li&gt;\n&lt;li&gt;Choose interval time to rescan folder.&lt;/li&gt;\n&lt;li&gt;This script will start generating subtitles for videos with the fewest available subtitles (it sorts all videos by subtitle count, including embedded subtitles).&lt;/li&gt;\n&lt;li&gt;Option to choose Whisper model (tiny / small / medium, etc.).&lt;/li&gt;\n&lt;li&gt;Progress bar with ETA (Estimated Time of Arrival) showing subtitle generation progress.&lt;/li&gt;\n&lt;li&gt;Subtitles are named like &amp;quot;AI - English&amp;quot; for easy identification.&lt;/li&gt;\n&lt;li&gt;Support for Core ML is included to fully leverage the Neural Engine of the M series chips.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Missing features:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;No web UI.&lt;/li&gt;\n&lt;li&gt;Converting video to audio using ffmpeg isn&amp;#39;t utilizing hardware acceleration. (The Whisper model requires audio to generate subtitles).&lt;/li&gt;\n&lt;li&gt;No option to manually generate subtitles.&lt;/li&gt;\n&lt;li&gt;Songs are not supported yet. I&amp;#39;m considering generating an LRC file for live lyrics.&lt;/li&gt;\n&lt;li&gt;Option to distribute the workload across multiple servers.&lt;/li&gt;\n&lt;li&gt;No docker image available (although I may be mistaken, as it may not be possible with Neural Engine support).&lt;/li&gt;\n&lt;li&gt;No GPU support for Whisper model yet on Nvidia / AMD / Intel systems. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Let me know what you think! \ud83c\udf89&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172pb2e", "is_robot_indexable": true, "report_reasons": null, "author": "Jamsy100", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172pb2e/i_created_a_script_for_subtitles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172pb2e/i_created_a_script_for_subtitles/", "subreddit_subscribers": 705671, "created_utc": 1696736563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There were tons of downloader scripts that would download saved posts for reddit. But what about lemmy... do you know of any such scripts. I searched but couldn't find any...\n\n Or do you know of a way of downloading saved posts (pictures, videos) on Lemmy?", "author_fullname": "t2_caaja", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a lemmy downloader?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173bzu0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696804324.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There were tons of downloader scripts that would download saved posts for reddit. But what about lemmy... do you know of any such scripts. I searched but couldn&amp;#39;t find any...&lt;/p&gt;\n\n&lt;p&gt;Or do you know of a way of downloading saved posts (pictures, videos) on Lemmy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173bzu0", "is_robot_indexable": true, "report_reasons": null, "author": "ideas_r_bulletproof", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173bzu0/is_there_a_lemmy_downloader/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173bzu0/is_there_a_lemmy_downloader/", "subreddit_subscribers": 705671, "created_utc": 1696804324.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've bought plenty of \"normal\" HDDs and SSDs for my desktop PC, highest size being a WD Blue 6TB. Well, it's maxed out on space, and instead of wasting SATA space with another 6TB, I want to turn to NAS drives. I know literally next to nothing about them and what to look for if I intend to use one for simple image/file storage in my desktop (so not in a dedicated NAS setup). I really just want a high capacity with a decent value. Speed would be nice, too, but since the use case will probably include upwards of accessing images or simple files, speed isn't a priority, just a luxury.\n\nI've found a couple on Amazon, but again, I have no idea what I'm looking at to compare them to each other with their relative prices:\n\nLike this Seagate Exos X18 18TB @ $279 USD, or Seagate Ironwolf Pro 16TB @ $285 USD\n\nI figure the Ironwolf Pro just adds some markup for features I don't need, so I suppose I should disqualify that one. But what about other choices similar to the Exos at a similar price range? Most of these seem to be CRM 7200rpm in this class. And is that even a good price? \n\nNote, my max budget ideally is less than $250, but there seems to be only a $20 difference in price in the 14-18TB options.\n\nAlso, I haven't stalked these before - do these products ever take part in Prime Day deals? There's some deal days coming up this week, if I recall correctly.", "author_fullname": "t2_7damr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good bang-for-your-buck NAS drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173bp11", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696803552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve bought plenty of &amp;quot;normal&amp;quot; HDDs and SSDs for my desktop PC, highest size being a WD Blue 6TB. Well, it&amp;#39;s maxed out on space, and instead of wasting SATA space with another 6TB, I want to turn to NAS drives. I know literally next to nothing about them and what to look for if I intend to use one for simple image/file storage in my desktop (so not in a dedicated NAS setup). I really just want a high capacity with a decent value. Speed would be nice, too, but since the use case will probably include upwards of accessing images or simple files, speed isn&amp;#39;t a priority, just a luxury.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve found a couple on Amazon, but again, I have no idea what I&amp;#39;m looking at to compare them to each other with their relative prices:&lt;/p&gt;\n\n&lt;p&gt;Like this Seagate Exos X18 18TB @ $279 USD, or Seagate Ironwolf Pro 16TB @ $285 USD&lt;/p&gt;\n\n&lt;p&gt;I figure the Ironwolf Pro just adds some markup for features I don&amp;#39;t need, so I suppose I should disqualify that one. But what about other choices similar to the Exos at a similar price range? Most of these seem to be CRM 7200rpm in this class. And is that even a good price? &lt;/p&gt;\n\n&lt;p&gt;Note, my max budget ideally is less than $250, but there seems to be only a $20 difference in price in the 14-18TB options.&lt;/p&gt;\n\n&lt;p&gt;Also, I haven&amp;#39;t stalked these before - do these products ever take part in Prime Day deals? There&amp;#39;s some deal days coming up this week, if I recall correctly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173bp11", "is_robot_indexable": true, "report_reasons": null, "author": "PhotonWolfsky", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173bp11/good_bangforyourbuck_nas_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173bp11/good_bangforyourbuck_nas_drive/", "subreddit_subscribers": 705671, "created_utc": 1696803552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a LSI SAS3041E pci card to add more sata ports on my computer, I'm running truenas scale, I was expecting to have to flash it but thought let me try it as it's a used part. It recognized the drive. Has this card already been flashed to IT mode? How can I tell?", "author_fullname": "t2_31uwvm4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flashing SAS card to IT mode.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1739adk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696797490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a LSI SAS3041E pci card to add more sata ports on my computer, I&amp;#39;m running truenas scale, I was expecting to have to flash it but thought let me try it as it&amp;#39;s a used part. It recognized the drive. Has this card already been flashed to IT mode? How can I tell?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1739adk", "is_robot_indexable": true, "report_reasons": null, "author": "arun2118", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1739adk/flashing_sas_card_to_it_mode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1739adk/flashing_sas_card_to_it_mode/", "subreddit_subscribers": 705671, "created_utc": 1696797490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i have a few thousand videos that i need to crop and can't find any good software for pc, any suggestions? (would be better if it allows for custom crop ratio and not just 1:1 or 16:9 ect...)", "author_fullname": "t2_dfdoc6ab", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A good free video cropping software for lots of video?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172y71e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696768842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have a few thousand videos that i need to crop and can&amp;#39;t find any good software for pc, any suggestions? (would be better if it allows for custom crop ratio and not just 1:1 or 16:9 ect...)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "5,5TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172y71e", "is_robot_indexable": true, "report_reasons": null, "author": "Key-Wait-3098", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/172y71e/a_good_free_video_cropping_software_for_lots_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172y71e/a_good_free_video_cropping_software_for_lots_of/", "subreddit_subscribers": 705671, "created_utc": 1696768842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This is a short-depth 2.5\" 12GB SAS 24 drive JBOD enclosure that would fit well in my closet. The problem seems they are impossible to find. \n\nAnyone here who knows a good Chenbro reseller/shop in either Europe or USA? ", "author_fullname": "t2_7zshev0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for Chenbro DS25224", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172wthk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696764303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is a short-depth 2.5&amp;quot; 12GB SAS 24 drive JBOD enclosure that would fit well in my closet. The problem seems they are impossible to find. &lt;/p&gt;\n\n&lt;p&gt;Anyone here who knows a good Chenbro reseller/shop in either Europe or USA? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172wthk", "is_robot_indexable": true, "report_reasons": null, "author": "kY2iB3yH0mN8wI2h", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172wthk/looking_for_chenbro_ds25224/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172wthk/looking_for_chenbro_ds25224/", "subreddit_subscribers": 705671, "created_utc": 1696764303.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}