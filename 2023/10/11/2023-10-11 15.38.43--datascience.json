{"kind": "Listing", "data": {"after": null, "dist": 15, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Got into my first job about 10 months ago. I study a master\u2019s on data science and I\u2019m about to finish school in 2-3 months. I\u2019m doing okay, my lowest score is B+ and I\u2019m working on a churn project. \n\nI got my job through a friend, the company knew I was recently starting my master\u2019s and that I had no experience in this field. However, they were really interested in what I was (supposedly) going to learn, and were excited that I\u2019d bring a new perspective to the team. \n\nThings started ok and I\u2019m doing pretty good on every day tasks, but whenever I\u2019m handed an analysis task/data science project, it always ends up taking more time than allowed, and the more experienced people in my team usually end up coming in and having to re-do everything, sometimes even work overtime to meet deadlines. \n\nIt\u2019s not that I\u2019m not working on it, like for example I have about 8 hours on this one project I had to do, and all I have is a few tables and metrics. Yet, the customer meeting is tomorrow and I have nothing to show for the time I have put in.\n\nI\u2019m starting to feel like I\u2019m wasting company\u2019s time and resources and more importantly, I feel bad about not having learned anything and not being able to apply anything.", "author_fullname": "t2_m826ekr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sucking at my job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174wmnk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 101, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 101, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696973097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Got into my first job about 10 months ago. I study a master\u2019s on data science and I\u2019m about to finish school in 2-3 months. I\u2019m doing okay, my lowest score is B+ and I\u2019m working on a churn project. &lt;/p&gt;\n\n&lt;p&gt;I got my job through a friend, the company knew I was recently starting my master\u2019s and that I had no experience in this field. However, they were really interested in what I was (supposedly) going to learn, and were excited that I\u2019d bring a new perspective to the team. &lt;/p&gt;\n\n&lt;p&gt;Things started ok and I\u2019m doing pretty good on every day tasks, but whenever I\u2019m handed an analysis task/data science project, it always ends up taking more time than allowed, and the more experienced people in my team usually end up coming in and having to re-do everything, sometimes even work overtime to meet deadlines. &lt;/p&gt;\n\n&lt;p&gt;It\u2019s not that I\u2019m not working on it, like for example I have about 8 hours on this one project I had to do, and all I have is a few tables and metrics. Yet, the customer meeting is tomorrow and I have nothing to show for the time I have put in.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m starting to feel like I\u2019m wasting company\u2019s time and resources and more importantly, I feel bad about not having learned anything and not being able to apply anything.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "174wmnk", "is_robot_indexable": true, "report_reasons": null, "author": "Utterizi", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/174wmnk/sucking_at_my_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/174wmnk/sucking_at_my_job/", "subreddit_subscribers": 1080386, "created_utc": 1696973097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "One area of data science I think that people struggle to wrap their head around is thinking of problems and frameworks, tools, technologies in simple real world terms. Very hard to understand something You're just writing lines of code and programming into a machine, without really understanding in the real world that you live in what they could possibly be related to...\n\n\nAnd recently I've been learning tensorflow, and apparently tensor is an actual word, like this is a real thing. But what I don't understand is what a real world example of a tensor could possibly be, like an analogy, or metaphor for how to explain them to someone else. For example, tree, box, power plant, etc. I'm not saying those are related to tensor, but those are often things that people use to explain complex concepts in the real world. \n\n\nSo how would you explain what a tensor is in real world terms?", "author_fullname": "t2_hdeet8zsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can anyone provide an easy to understand real world example of tensors, and how they are used?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174pvw9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 57, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 57, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696956432.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;One area of data science I think that people struggle to wrap their head around is thinking of problems and frameworks, tools, technologies in simple real world terms. Very hard to understand something You&amp;#39;re just writing lines of code and programming into a machine, without really understanding in the real world that you live in what they could possibly be related to...&lt;/p&gt;\n\n&lt;p&gt;And recently I&amp;#39;ve been learning tensorflow, and apparently tensor is an actual word, like this is a real thing. But what I don&amp;#39;t understand is what a real world example of a tensor could possibly be, like an analogy, or metaphor for how to explain them to someone else. For example, tree, box, power plant, etc. I&amp;#39;m not saying those are related to tensor, but those are often things that people use to explain complex concepts in the real world. &lt;/p&gt;\n\n&lt;p&gt;So how would you explain what a tensor is in real world terms?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "174pvw9", "is_robot_indexable": true, "report_reasons": null, "author": "databro92", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/174pvw9/can_anyone_provide_an_easy_to_understand_real/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/174pvw9/can_anyone_provide_an_easy_to_understand_real/", "subreddit_subscribers": 1080386, "created_utc": 1696956432.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My team and managers are so easy to be with. Very grateful for that. The pay is okay. 150k/yr TC in Midwest. Hard for me to make a switch given how much I am appreciated. I almost feel spoiled when it comes to flexibility. I have overachiever tendency and the pace is so slow in adopting my ML models.\n\nI am the \u201clead\u201d/senior data scientist in an R&amp;D supporting scientists decision making with machine learning. Importantly, I am in a huge multinational consumer product company and I am not in the Data science organization, I bridge between the two and the data science expert on the team.\n\n  I have developed the domain expertise and I have  a PhD in  an applied computational field with 5 years experience . I am not as challenged with getting deeper into complex stats, I have been really honing the soft skills of communication, influencing etc so getting comfortable in a senior role. Also I have been growing as a ML engineer building my own pipelines and deploying my models on prem server that they bought for me.\n\nI am not sure how greener it is on the other side, how do senior folks approach deciding when to move on? Any input is much appreciated.", "author_fullname": "t2_91esrqhf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How important is being appreciated and team fit as a factor to stay in a role with average salary given slow adoption of data science solutions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_175caah", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697025555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team and managers are so easy to be with. Very grateful for that. The pay is okay. 150k/yr TC in Midwest. Hard for me to make a switch given how much I am appreciated. I almost feel spoiled when it comes to flexibility. I have overachiever tendency and the pace is so slow in adopting my ML models.&lt;/p&gt;\n\n&lt;p&gt;I am the \u201clead\u201d/senior data scientist in an R&amp;amp;D supporting scientists decision making with machine learning. Importantly, I am in a huge multinational consumer product company and I am not in the Data science organization, I bridge between the two and the data science expert on the team.&lt;/p&gt;\n\n&lt;p&gt;I have developed the domain expertise and I have  a PhD in  an applied computational field with 5 years experience . I am not as challenged with getting deeper into complex stats, I have been really honing the soft skills of communication, influencing etc so getting comfortable in a senior role. Also I have been growing as a ML engineer building my own pipelines and deploying my models on prem server that they bought for me.&lt;/p&gt;\n\n&lt;p&gt;I am not sure how greener it is on the other side, how do senior folks approach deciding when to move on? Any input is much appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175caah", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent_Trust2569", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175caah/how_important_is_being_appreciated_and_team_fit/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175caah/how_important_is_being_appreciated_and_team_fit/", "subreddit_subscribers": 1080386, "created_utc": 1697025555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I started a new job ~3 months ago as the sole person on the data science team and have been working alone on my project in that time.\n\nThe first project I'm on involves making a predictive model, and my manager had expectations from the start on what sort of accuracy he was looking to achieve. \n\nThe first thing I did when joining was try to better understand the context - what is the model for, who will be using it, are there existing solutions we'd be competing with, etc.\n\nIn the first couple weeks I spent time looking into any remotely similar products and their advertised accuracy. My conclusion was that it would be unlikely to achieve what my manager was hoping, and I put that conclusion into a presentation, which included some strategies we may want to consider for choosing a target that makes sense for the business.\n\nWell fast forward 3 months, my concerns were ignored, we've seemingly settled on the original number that my manager pulled out of their ass, and all of my updates are judged against that highly improbable goal. Meeting that goal would make us  - no, *me*, far and away the market leader in accuracy, and I just don't think at this point that we have the data / are willing to pay for the data that would get us there.\n\nWhat do I do? Maybe I didn't push back hard enough the first time, but... what now? Pretty sure that goal will simply not be met.\n\nAnyone been in a similar position?", "author_fullname": "t2_jy1ivbmzy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to manage expectations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1756sze", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697003261.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I started a new job ~3 months ago as the sole person on the data science team and have been working alone on my project in that time.&lt;/p&gt;\n\n&lt;p&gt;The first project I&amp;#39;m on involves making a predictive model, and my manager had expectations from the start on what sort of accuracy he was looking to achieve. &lt;/p&gt;\n\n&lt;p&gt;The first thing I did when joining was try to better understand the context - what is the model for, who will be using it, are there existing solutions we&amp;#39;d be competing with, etc.&lt;/p&gt;\n\n&lt;p&gt;In the first couple weeks I spent time looking into any remotely similar products and their advertised accuracy. My conclusion was that it would be unlikely to achieve what my manager was hoping, and I put that conclusion into a presentation, which included some strategies we may want to consider for choosing a target that makes sense for the business.&lt;/p&gt;\n\n&lt;p&gt;Well fast forward 3 months, my concerns were ignored, we&amp;#39;ve seemingly settled on the original number that my manager pulled out of their ass, and all of my updates are judged against that highly improbable goal. Meeting that goal would make us  - no, &lt;em&gt;me&lt;/em&gt;, far and away the market leader in accuracy, and I just don&amp;#39;t think at this point that we have the data / are willing to pay for the data that would get us there.&lt;/p&gt;\n\n&lt;p&gt;What do I do? Maybe I didn&amp;#39;t push back hard enough the first time, but... what now? Pretty sure that goal will simply not be met.&lt;/p&gt;\n\n&lt;p&gt;Anyone been in a similar position?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1756sze", "is_robot_indexable": true, "report_reasons": null, "author": "youngslaphappy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1756sze/how_to_manage_expectations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1756sze/how_to_manage_expectations/", "subreddit_subscribers": 1080386, "created_utc": 1697003261.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work as a Sales Engineer for a SaaS company where my work mainly revolves around working with Excel Spreadsheets and PowerPoint decks, which I am very tired of and want to make a switch. I\u2019m very passionate about data science and have some skillset through side learning- intermediate Python and SQL with basic grasp of machine learning. For xyz reasons I can not make an official role switch so the best I can do is make my job more interesting. Any suggestions on how I could use data science to add value to the sales/ sales engineering process? For context, I have access to my company\u2019s CRM data and my company\u2019s product offering is price benchmarking.", "author_fullname": "t2_8felv1zi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science for Sales", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1754v9n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696996136.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work as a Sales Engineer for a SaaS company where my work mainly revolves around working with Excel Spreadsheets and PowerPoint decks, which I am very tired of and want to make a switch. I\u2019m very passionate about data science and have some skillset through side learning- intermediate Python and SQL with basic grasp of machine learning. For xyz reasons I can not make an official role switch so the best I can do is make my job more interesting. Any suggestions on how I could use data science to add value to the sales/ sales engineering process? For context, I have access to my company\u2019s CRM data and my company\u2019s product offering is price benchmarking.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1754v9n", "is_robot_indexable": true, "report_reasons": null, "author": "DapperAd8264", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1754v9n/data_science_for_sales/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1754v9n/data_science_for_sales/", "subreddit_subscribers": 1080386, "created_utc": 1696996136.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone!\n\nIs there a simple and robust method for extracting highly tabular data from a PDF without resorting to rule based regex parsing?  I'm currently using PDFminer, PDFplumber and regex to build templates to extract PDFs based on the type of PDF but it's very time-consuming and tedious.  Is there a better way?\n\nI've used Langchain and OpenAI to build \"Chat with your document\" apps which works great for uploading a PDF of a whitepaper and asking it to summarize the paper, but when it comes to extracting table data - I don't think this solution will work.\n\n&amp;#x200B;\n\nThank you for your input,\n\nData Scallion", "author_fullname": "t2_dffy2296", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advancements in extracting tabular data from PDFs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174pkt1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696955619.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;/p&gt;\n\n&lt;p&gt;Is there a simple and robust method for extracting highly tabular data from a PDF without resorting to rule based regex parsing?  I&amp;#39;m currently using PDFminer, PDFplumber and regex to build templates to extract PDFs based on the type of PDF but it&amp;#39;s very time-consuming and tedious.  Is there a better way?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve used Langchain and OpenAI to build &amp;quot;Chat with your document&amp;quot; apps which works great for uploading a PDF of a whitepaper and asking it to summarize the paper, but when it comes to extracting table data - I don&amp;#39;t think this solution will work.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thank you for your input,&lt;/p&gt;\n\n&lt;p&gt;Data Scallion&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "174pkt1", "is_robot_indexable": true, "report_reasons": null, "author": "data_scallion", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/174pkt1/advancements_in_extracting_tabular_data_from_pdfs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/174pkt1/advancements_in_extracting_tabular_data_from_pdfs/", "subreddit_subscribers": 1080386, "created_utc": 1696955619.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Has anyone been to an event hosted by this group? They reached out and asked if I want to be part of the group to discuss cultural change, align stakeholders, and increase adoption, and they mentioned some big names like Coca Cola as part of the panel. \nNot sure if this is a waste of time", "author_fullname": "t2_16kgog", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The data storytellers community?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_175fc3f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697034530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone been to an event hosted by this group? They reached out and asked if I want to be part of the group to discuss cultural change, align stakeholders, and increase adoption, and they mentioned some big names like Coca Cola as part of the panel. \nNot sure if this is a waste of time&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175fc3f", "is_robot_indexable": true, "report_reasons": null, "author": "balpby1989", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175fc3f/the_data_storytellers_community/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175fc3f/the_data_storytellers_community/", "subreddit_subscribers": 1080386, "created_utc": 1697034530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work for a company that sells unique items online (think collectibles or artwork in an eBay style auction). We have a data model that can tell if the item is \u2018attractive\u2019, meaning the seller has a reasonable reserve and users can potentially get it for a good deal.\n\nIf I want to do A/B test on this to see if this \u2018attractive\u2019 indication makes those items sell at a higher rate, how would you design the test? Would you:\n1. Identify those items (say they are 500) and split them randomly into test/control groups (can be 250 items each) and provide all users the same experience for those items then measure how well they sell by group?\n2. Identify those items and only show the \u2018attractive\u2019 indicator to half of the users. Meaning that half the users will see the existing experience (no \u2018attractive\u2019 indicator at all) and half will see the \u2018attractive\u2019 indicator on all 500 items, then compare how they sell by user group?\n\nIntuitively #1 makes more sense to me, but I\u2019m not finding a lot of literature to support this methodology. How would you design such a test and what\u2019s your rationale?\n\nPlease note that engagement, clicks, time on site are not our main drivers for this test, I am mainly focused on testing if this will lead to more sales.\n\nThanks", "author_fullname": "t2_82f9k6td", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A/B Testing Product or User Split", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1756hae", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697002012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for a company that sells unique items online (think collectibles or artwork in an eBay style auction). We have a data model that can tell if the item is \u2018attractive\u2019, meaning the seller has a reasonable reserve and users can potentially get it for a good deal.&lt;/p&gt;\n\n&lt;p&gt;If I want to do A/B test on this to see if this \u2018attractive\u2019 indication makes those items sell at a higher rate, how would you design the test? Would you:\n1. Identify those items (say they are 500) and split them randomly into test/control groups (can be 250 items each) and provide all users the same experience for those items then measure how well they sell by group?\n2. Identify those items and only show the \u2018attractive\u2019 indicator to half of the users. Meaning that half the users will see the existing experience (no \u2018attractive\u2019 indicator at all) and half will see the \u2018attractive\u2019 indicator on all 500 items, then compare how they sell by user group?&lt;/p&gt;\n\n&lt;p&gt;Intuitively #1 makes more sense to me, but I\u2019m not finding a lot of literature to support this methodology. How would you design such a test and what\u2019s your rationale?&lt;/p&gt;\n\n&lt;p&gt;Please note that engagement, clicks, time on site are not our main drivers for this test, I am mainly focused on testing if this will lead to more sales.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1756hae", "is_robot_indexable": true, "report_reasons": null, "author": "DboS3dan", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1756hae/ab_testing_product_or_user_split/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1756hae/ab_testing_product_or_user_split/", "subreddit_subscribers": 1080386, "created_utc": 1697002012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm trying to build something similar where websites can be crawled and refresh daily", "author_fullname": "t2_8es0n3vl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How does SEMRUSH, and other big analytic crawler works?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1752wat", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696990173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to build something similar where websites can be crawled and refresh daily&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1752wat", "is_robot_indexable": true, "report_reasons": null, "author": "Breadskinjinhojiak", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1752wat/how_does_semrush_and_other_big_analytic_crawler/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1752wat/how_does_semrush_and_other_big_analytic_crawler/", "subreddit_subscribers": 1080386, "created_utc": 1696990173.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I mean cities where a data scientist with a few years of experience who lives there would have a hard time NOT finding a new job.\n\nWhat are the top 5 or 10 DS hubs in the US, and then what's 1 or 2 cities near the great lakes that punch well above its weight (besides the obvious answer which I'm assuming is Chicago)?", "author_fullname": "t2_4ckw169q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[US] What are some hubs for data science or data analytics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174sfb2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696962814.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mean cities where a data scientist with a few years of experience who lives there would have a hard time NOT finding a new job.&lt;/p&gt;\n\n&lt;p&gt;What are the top 5 or 10 DS hubs in the US, and then what&amp;#39;s 1 or 2 cities near the great lakes that punch well above its weight (besides the obvious answer which I&amp;#39;m assuming is Chicago)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "174sfb2", "is_robot_indexable": true, "report_reasons": null, "author": "valkaress", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/174sfb2/us_what_are_some_hubs_for_data_science_or_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/174sfb2/us_what_are_some_hubs_for_data_science_or_data/", "subreddit_subscribers": 1080386, "created_utc": 1696962814.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a classifier model. I would need the predicted probabilities for production purposes (on unseen data), as the probability score is of more concern in the project. Should I consider just the raw probabilities, as predicted, or should I make some sort of adjustment with the optimal threshold (for the trained model) and then consider the adjusted probabilities? \n\nFor example, suppose I get a probability as 0.55. Which means, in face value, that there's more likelihood of it being 1 than 0. But my model says optimal threshold is 0.6. Which means model still wants to predict it to be 0, being more conservative in predicting 1. However since I'm concerned with ONLY the probability, isnt that deceiving or wrong? \n\nAny suggestions are appreciated.", "author_fullname": "t2_28h3sgt7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predicted raw probabilities or threshold-adjusted ones?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_175errf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697032992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a classifier model. I would need the predicted probabilities for production purposes (on unseen data), as the probability score is of more concern in the project. Should I consider just the raw probabilities, as predicted, or should I make some sort of adjustment with the optimal threshold (for the trained model) and then consider the adjusted probabilities? &lt;/p&gt;\n\n&lt;p&gt;For example, suppose I get a probability as 0.55. Which means, in face value, that there&amp;#39;s more likelihood of it being 1 than 0. But my model says optimal threshold is 0.6. Which means model still wants to predict it to be 0, being more conservative in predicting 1. However since I&amp;#39;m concerned with ONLY the probability, isnt that deceiving or wrong? &lt;/p&gt;\n\n&lt;p&gt;Any suggestions are appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175errf", "is_robot_indexable": true, "report_reasons": null, "author": "oblivious_horizon", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175errf/predicted_raw_probabilities_or_thresholdadjusted/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175errf/predicted_raw_probabilities_or_thresholdadjusted/", "subreddit_subscribers": 1080386, "created_utc": 1697032992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all! I created a CLI Python package to allow anyone to run any code (a function, a script, or a Jupyter notebook) on an EC2 instance. Still in the early stages, so would love any feedback y'all have!\n\n* Github: [https://github.com/runprism/nomad](https://github.com/runprism/nomad)\n* Docs: [https://docs.trynomad.dev](https://docs.trynomad.dev/)\n\nAlso, please visit our Github to show support, raise bugs, or request features!", "author_fullname": "t2_g2ejflv7v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Nomad: CLI tool to run any Python code on an EC2 instance", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_175eli7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697032522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all! I created a CLI Python package to allow anyone to run any code (a function, a script, or a Jupyter notebook) on an EC2 instance. Still in the early stages, so would love any feedback y&amp;#39;all have!&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Github: &lt;a href=\"https://github.com/runprism/nomad\"&gt;https://github.com/runprism/nomad&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;Docs: &lt;a href=\"https://docs.trynomad.dev/\"&gt;https://docs.trynomad.dev&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Also, please visit our Github to show support, raise bugs, or request features!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/VCOhd8wyGmTn1og6s3NA8n0kAMGM4BeFwFHqYLpiR_Y.jpg?auto=webp&amp;s=38181289f36b39a24210c07827bfbf44dfa0cc2a", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/VCOhd8wyGmTn1og6s3NA8n0kAMGM4BeFwFHqYLpiR_Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b40a9a45c6aa345fa7434cc16f0e13d75d7005a5", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/VCOhd8wyGmTn1og6s3NA8n0kAMGM4BeFwFHqYLpiR_Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=232d218b0623b343a7427094efdccb49d8b4a4a5", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/VCOhd8wyGmTn1og6s3NA8n0kAMGM4BeFwFHqYLpiR_Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=081bb6fd475a59001ddd0d37f759154a5337b9ff", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/VCOhd8wyGmTn1og6s3NA8n0kAMGM4BeFwFHqYLpiR_Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7395c77ab8d6bc446636a7fcfe625e4da3489e34", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/VCOhd8wyGmTn1og6s3NA8n0kAMGM4BeFwFHqYLpiR_Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=280ffeb8837b17f02cf9ac7dc76331eb278e95d3", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/VCOhd8wyGmTn1og6s3NA8n0kAMGM4BeFwFHqYLpiR_Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2c43d0dfbc5e5a5f55999510fb07b7d18560bc1d", "width": 1080, "height": 540}], "variants": {}, "id": "LwMTTl9nStupJJIcnymO4em4IW9sYITgpOEoB6Nh5xQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "175eli7", "is_robot_indexable": true, "report_reasons": null, "author": "runprism", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/175eli7/nomad_cli_tool_to_run_any_python_code_on_an_ec2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/175eli7/nomad_cli_tool_to_run_any_python_code_on_an_ec2/", "subreddit_subscribers": 1080386, "created_utc": 1697032522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey! Has anyone used Comet (https://www.comet.com) for their experiment tracking? I\u2019m looking into the product and am curious if anyone here has enjoyed using it", "author_fullname": "t2_nm4npbzv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has anyone used Comet for experiment tracking?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1755h3b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696998190.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey! Has anyone used Comet (&lt;a href=\"https://www.comet.com\"&gt;https://www.comet.com&lt;/a&gt;) for their experiment tracking? I\u2019m looking into the product and am curious if anyone here has enjoyed using it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1755h3b", "is_robot_indexable": true, "report_reasons": null, "author": "jacobwlyman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1755h3b/has_anyone_used_comet_for_experiment_tracking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1755h3b/has_anyone_used_comet_for_experiment_tracking/", "subreddit_subscribers": 1080386, "created_utc": 1696998190.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm working on a project that is looking at the interaction between gps tracked pelicans and oil rigs in the gulf of mexico. The big thing with tracking data analyses such as hidden markov model and step selection functions is to have consistently recorded locations to analyze, looking at the data I realized that there is a gap from 9:30pm to 5am everyday, this is because it was assumed they were sleeping at these times and the rows removed. Should I put back those missing rows if possible or just have the coordinates record at 9:30pm repeated every 90 minutes until the 5am ping for each pelican?", "author_fullname": "t2_mzobbzq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question animal tracking data and filling in periods of sleep?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174wama", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696972280.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working on a project that is looking at the interaction between gps tracked pelicans and oil rigs in the gulf of mexico. The big thing with tracking data analyses such as hidden markov model and step selection functions is to have consistently recorded locations to analyze, looking at the data I realized that there is a gap from 9:30pm to 5am everyday, this is because it was assumed they were sleeping at these times and the rows removed. Should I put back those missing rows if possible or just have the coordinates record at 9:30pm repeated every 90 minutes until the 5am ping for each pelican?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "174wama", "is_robot_indexable": true, "report_reasons": null, "author": "HyenaJack94", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/174wama/question_animal_tracking_data_and_filling_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/174wama/question_animal_tracking_data_and_filling_in/", "subreddit_subscribers": 1080386, "created_utc": 1696972280.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Everyone\n\nI am a new data analyst in an insurance company that uses DOMO as its BI tool, there have been many previous contractors doing similar work and this has led to many visuals being duplicated and many dashboards having redundant and repetitive information. \n\nI am in the process of having only one source of truth for a specific graph, however, different departments have been using different graphs (i.e. monthly premiums but unconnected cards in different dashboards). \n\nMy question is beyond a refresher training I wanted to make a map for the ~~lazy~~ some staff to easily locate specific graphs, has anyone done something similar and have any advice on how to go about it.", "author_fullname": "t2_8o2bbpliq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Creating a Visualizations Map", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17578q8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697004961.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone&lt;/p&gt;\n\n&lt;p&gt;I am a new data analyst in an insurance company that uses DOMO as its BI tool, there have been many previous contractors doing similar work and this has led to many visuals being duplicated and many dashboards having redundant and repetitive information. &lt;/p&gt;\n\n&lt;p&gt;I am in the process of having only one source of truth for a specific graph, however, different departments have been using different graphs (i.e. monthly premiums but unconnected cards in different dashboards). &lt;/p&gt;\n\n&lt;p&gt;My question is beyond a refresher training I wanted to make a map for the &lt;del&gt;lazy&lt;/del&gt; some staff to easily locate specific graphs, has anyone done something similar and have any advice on how to go about it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17578q8", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious_Virus_33", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17578q8/creating_a_visualizations_map/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17578q8/creating_a_visualizations_map/", "subreddit_subscribers": 1080386, "created_utc": 1697004961.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}