{"kind": "Listing", "data": {"after": "t3_174vubc", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there any of you who love data engineering but feels frustrated to be literally forced to use Python for everything while you'd prefer to use a proper statistically typed language like Scala, Java or Go?\n\nI currently do most of the services in Java. I did some Scala before. \nWe also use a bit of Go and Python mainly for Airflow DAGs. \n\nPython is nice dynamic language. I have nothing against it. \nI see people adding types hints, static checkers like MyPy, etc... \nWe're turning Python into Typescript basically. And why not? That's one way to go to achieve a better type safety. \nBut ...can we do ourselves a favor and use a proper statically typed language? \ud83d\ude02\n\nPerhaps we should develop better data ecosystems in other languages as well. \nJust like backend people have been doing. \n\nI know this post will get some hate. \n\nIs there any of you who wish to have more variety in the data engineering job market or you're all fully satisfied working with Python for everything?\n\nHave a good day :)", "author_fullname": "t2_3wj092gm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Python our fate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1750zdx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696984654.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there any of you who love data engineering but feels frustrated to be literally forced to use Python for everything while you&amp;#39;d prefer to use a proper statistically typed language like Scala, Java or Go?&lt;/p&gt;\n\n&lt;p&gt;I currently do most of the services in Java. I did some Scala before. \nWe also use a bit of Go and Python mainly for Airflow DAGs. &lt;/p&gt;\n\n&lt;p&gt;Python is nice dynamic language. I have nothing against it. \nI see people adding types hints, static checkers like MyPy, etc... \nWe&amp;#39;re turning Python into Typescript basically. And why not? That&amp;#39;s one way to go to achieve a better type safety. \nBut ...can we do ourselves a favor and use a proper statically typed language? \ud83d\ude02&lt;/p&gt;\n\n&lt;p&gt;Perhaps we should develop better data ecosystems in other languages as well. \nJust like backend people have been doing. &lt;/p&gt;\n\n&lt;p&gt;I know this post will get some hate. &lt;/p&gt;\n\n&lt;p&gt;Is there any of you who wish to have more variety in the data engineering job market or you&amp;#39;re all fully satisfied working with Python for everything?&lt;/p&gt;\n\n&lt;p&gt;Have a good day :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1750zdx", "is_robot_indexable": true, "report_reasons": null, "author": "yinshangyi", "discussion_type": null, "num_comments": 93, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1750zdx/is_python_our_fate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1750zdx/is_python_our_fate/", "subreddit_subscribers": 133138, "created_utc": 1696984654.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you'd start a career in data engineering  in 2023 ,\n\n&amp; you've exp in python sql  , \n\nwould you pursue learning ssis or choose cloud technology ? \n\nThank you ", "author_fullname": "t2_t3nz93za", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On Premises Vs Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174jezy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696939266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you&amp;#39;d start a career in data engineering  in 2023 ,&lt;/p&gt;\n\n&lt;p&gt;&amp;amp; you&amp;#39;ve exp in python sql  , &lt;/p&gt;\n\n&lt;p&gt;would you pursue learning ssis or choose cloud technology ? &lt;/p&gt;\n\n&lt;p&gt;Thank you &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174jezy", "is_robot_indexable": true, "report_reasons": null, "author": "Repulsive-Ad7769", "discussion_type": null, "num_comments": 46, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174jezy/on_premises_vs_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174jezy/on_premises_vs_cloud/", "subreddit_subscribers": 133138, "created_utc": 1696939266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6vz2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Help] Tried highlighting what Databricks does \"in-house\" for a project. Is this accurate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_174j9ov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/q3Q6PeLx4nf2CkBUckenFrp8x3M87-n6tWdw4vsV20M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696938786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dqmlofum5dtb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dqmlofum5dtb1.png?auto=webp&amp;s=934d980ca188a1b4bf1a6c5a211557f9b454fc6e", "width": 2264, "height": 2323}, "resolutions": [{"url": "https://preview.redd.it/dqmlofum5dtb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f3435cde6ec91dfa9ca9f535eaf0a228bc0b461b", "width": 108, "height": 110}, {"url": "https://preview.redd.it/dqmlofum5dtb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0cd06c19a55477daca085fa59cd60b8ce2189463", "width": 216, "height": 221}, {"url": "https://preview.redd.it/dqmlofum5dtb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a7cf468576834af1e6abfe22f983baf6c0683803", "width": 320, "height": 328}, {"url": "https://preview.redd.it/dqmlofum5dtb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f780866b1d8438d2d36ea255b01eef82974c2e6", "width": 640, "height": 656}, {"url": "https://preview.redd.it/dqmlofum5dtb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=816f4f3aee433d66db633a010df2efe0a00a3ba1", "width": 960, "height": 985}, {"url": "https://preview.redd.it/dqmlofum5dtb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=16fa3fcde7e1fddbff3687503e7403c027f6a376", "width": 1080, "height": 1108}], "variants": {}, "id": "1XiupRIo73tDBkiQdN0J0Hw0qRuljcK-TfvELTnl8Bo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174j9ov", "is_robot_indexable": true, "report_reasons": null, "author": "boulking", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174j9ov/help_tried_highlighting_what_databricks_does/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dqmlofum5dtb1.png", "subreddit_subscribers": 133138, "created_utc": 1696938786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a consultancy but I've been thinking recently that a lot of SME requirements can really be handled by a solo developer and don't need a whole team or business behind them. \n\nThe biggest obstacles I see are client acquisition and also that a client may not be comfortable hiring a one man team. \n\nDoes anyone have any experience striking out as a solo? I'd love to hear any stories. Or if anyone knows of anything online where someone has documented their own journey.\n\nEven if you haven't done it yourself it'd be interesting to hear your general thoughts on the prospect.", "author_fullname": "t2_6o5du", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody here started a solo consultancy (or can share a good resource for it)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174irny", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696937086.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a consultancy but I&amp;#39;ve been thinking recently that a lot of SME requirements can really be handled by a solo developer and don&amp;#39;t need a whole team or business behind them. &lt;/p&gt;\n\n&lt;p&gt;The biggest obstacles I see are client acquisition and also that a client may not be comfortable hiring a one man team. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any experience striking out as a solo? I&amp;#39;d love to hear any stories. Or if anyone knows of anything online where someone has documented their own journey.&lt;/p&gt;\n\n&lt;p&gt;Even if you haven&amp;#39;t done it yourself it&amp;#39;d be interesting to hear your general thoughts on the prospect.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "174irny", "is_robot_indexable": true, "report_reasons": null, "author": "Cypher211", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174irny/anybody_here_started_a_solo_consultancy_or_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174irny/anybody_here_started_a_solo_consultancy_or_can/", "subreddit_subscribers": 133138, "created_utc": 1696937086.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a data stored in a bronze delta that I need to further process. It is only about 2 billion rows and is 20gb of data read from storage. The problem, I think, in short is that the data is highly compressed and while unserialized, my cluster / its settings is not prepared for it and breakdown ensues.\n\nMy first DAG step, mapping partition blocks to RDD, takes an enormously long time (hours). The data is split on my executors in a fairly balanced form, where each gets roughly 1.1 gb of data while my shuffle write is tiny ranging from bytes to kb.\n\nThe only knob I know to turn to alter the input stage is this: spark.sql.files.maxPartitionBytes but it does not help. With a small value, Spark will blow through the first n-thousands but will grind on the last 50-ish blocks of data.\n\nRepartitioning or coalescing is only an option after my first DAG step. Running OPTIMIZE fails; I get OOM on my executors and I have tried these operations on many configs / cluster sizes.", "author_fullname": "t2_u4zm4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark - How to break up extremely compressed data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174c1zs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696910635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a data stored in a bronze delta that I need to further process. It is only about 2 billion rows and is 20gb of data read from storage. The problem, I think, in short is that the data is highly compressed and while unserialized, my cluster / its settings is not prepared for it and breakdown ensues.&lt;/p&gt;\n\n&lt;p&gt;My first DAG step, mapping partition blocks to RDD, takes an enormously long time (hours). The data is split on my executors in a fairly balanced form, where each gets roughly 1.1 gb of data while my shuffle write is tiny ranging from bytes to kb.&lt;/p&gt;\n\n&lt;p&gt;The only knob I know to turn to alter the input stage is this: spark.sql.files.maxPartitionBytes but it does not help. With a small value, Spark will blow through the first n-thousands but will grind on the last 50-ish blocks of data.&lt;/p&gt;\n\n&lt;p&gt;Repartitioning or coalescing is only an option after my first DAG step. Running OPTIMIZE fails; I get OOM on my executors and I have tried these operations on many configs / cluster sizes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174c1zs", "is_robot_indexable": true, "report_reasons": null, "author": "JohnStud85", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174c1zs/pyspark_how_to_break_up_extremely_compressed_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174c1zs/pyspark_how_to_break_up_extremely_compressed_data/", "subreddit_subscribers": 133138, "created_utc": 1696910635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I work in a two man team for a government organization as an all purpose data engineer. Meaning we set up and maintain all data pipelines, the databases, the data reports and do machine learning projects when we have time. The methodology for the last three years, (yes the organization just started to think about data three years ago), has been a low hanging fruit methodology, meaning we start a project, create some value from it, publish it and move on. \n\nNeedless to say that has left a lot of quality control neglected. Name giving is inconsistent, data owners and users are often unknown and some quick fix sh\\*t solutions are still being used like windows scheduler to run some codes. There is hardly any documentation about our data infrastructure to add. \n\nNow I don't think any one is to blame for this as this is a government organization on a budget and the two of us are head over heels in projects but the time has come to tighten loose ends. My question is, has anyone experienced a similar scenario and solved it? How did you solve it? Is there any good literature on the subject or other resources? \n\nFYI we are using Microsoft solutions like Azure and power platform for 90% of what we do. We are also a REIT and construction management type of organization if that is relevant.\n\nThanks a lot in advance for all responses.", "author_fullname": "t2_6j5e93w9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organizational documentation for data infrastructure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174hlpp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696932690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I work in a two man team for a government organization as an all purpose data engineer. Meaning we set up and maintain all data pipelines, the databases, the data reports and do machine learning projects when we have time. The methodology for the last three years, (yes the organization just started to think about data three years ago), has been a low hanging fruit methodology, meaning we start a project, create some value from it, publish it and move on. &lt;/p&gt;\n\n&lt;p&gt;Needless to say that has left a lot of quality control neglected. Name giving is inconsistent, data owners and users are often unknown and some quick fix sh*t solutions are still being used like windows scheduler to run some codes. There is hardly any documentation about our data infrastructure to add. &lt;/p&gt;\n\n&lt;p&gt;Now I don&amp;#39;t think any one is to blame for this as this is a government organization on a budget and the two of us are head over heels in projects but the time has come to tighten loose ends. My question is, has anyone experienced a similar scenario and solved it? How did you solve it? Is there any good literature on the subject or other resources? &lt;/p&gt;\n\n&lt;p&gt;FYI we are using Microsoft solutions like Azure and power platform for 90% of what we do. We are also a REIT and construction management type of organization if that is relevant.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot in advance for all responses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "174hlpp", "is_robot_indexable": true, "report_reasons": null, "author": "arachnarus96", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174hlpp/organizational_documentation_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174hlpp/organizational_documentation_for_data/", "subreddit_subscribers": 133138, "created_utc": 1696932690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. I\u2019m a data analyst based in UK with 4 years experience. I saw an ad for a \u201cData Analyst / Data Engineering\u201d position for a huge company (with 1 day a week university training), and I decided to apply.\nTurned out after the interview and briefing, the position was \u201cAnalytics Engineering\u201d\u2026 I had to Google that\u2026\n\nThe thing is I\u2019ve passed the second round interview and assignment using ChatGPT and previous knowledge to connect dots, however I\u2019m way more skilled as a Data Analyst than an Engineer. I\u2019d honestly struggle to describe what I built for the assignment without notes.\n\nSo naturally, I\u2019m still not 100% sure if Analytics Engineering is right for me although the company and programme looks great. I get the feeling every Analytics Engineering job mightn\u2019t be an equal split.\n\nIs this a role that\u2019s more suited to someone with solely Data Engineer or Data Analytics experience?\n\nTLDR: ended up interviewing as an Analytics engineering. Is my data analyst experience good enough?", "author_fullname": "t2_shaidtoo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is an Analytics Engineering position possible to pivot from Data Analyst?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174g2q6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "author_cakeday": true, "edited": 1696926815.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696926514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I\u2019m a data analyst based in UK with 4 years experience. I saw an ad for a \u201cData Analyst / Data Engineering\u201d position for a huge company (with 1 day a week university training), and I decided to apply.\nTurned out after the interview and briefing, the position was \u201cAnalytics Engineering\u201d\u2026 I had to Google that\u2026&lt;/p&gt;\n\n&lt;p&gt;The thing is I\u2019ve passed the second round interview and assignment using ChatGPT and previous knowledge to connect dots, however I\u2019m way more skilled as a Data Analyst than an Engineer. I\u2019d honestly struggle to describe what I built for the assignment without notes.&lt;/p&gt;\n\n&lt;p&gt;So naturally, I\u2019m still not 100% sure if Analytics Engineering is right for me although the company and programme looks great. I get the feeling every Analytics Engineering job mightn\u2019t be an equal split.&lt;/p&gt;\n\n&lt;p&gt;Is this a role that\u2019s more suited to someone with solely Data Engineer or Data Analytics experience?&lt;/p&gt;\n\n&lt;p&gt;TLDR: ended up interviewing as an Analytics engineering. Is my data analyst experience good enough?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "174g2q6", "is_robot_indexable": true, "report_reasons": null, "author": "Noot-Noot-456", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174g2q6/is_an_analytics_engineering_position_possible_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174g2q6/is_an_analytics_engineering_position_possible_to/", "subreddit_subscribers": 133138, "created_utc": 1696926514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, and TIA! I'm a data engineer in a somewhat restrictive environment- we're all baremetal at my shop, and the *only* pipelines we've run are using boutique code I've had to create, manage, and supervise. It's an extremely nonstandard environment- we're 100% locked down to our intranet- no pip/apt/yum install etc. We have a single RDBMS for a warehouse and my single server to process on.\n\nI see this as a huge detriment to my career long term. I'm still working on a degree, as is my wife- so I don't have enough time to play around on my own time and stay up to speed on the modern data stack. I therefore have absolutely 0 professional cloud experience.\n\nHowever, an internal transfer position has opened as a cloud engineer. This would give me a broader skillset. Is there any reason I shouldn't jump on it? I do intend, in the long run, to move back to data engineering with the broader experience gained. I'm also 1 year from finishing my degree and my wife is 1.5 from finishing her doctorate, so I'll have more time to play with things on my own time. Is there any angle I'm not considering here? Would this be a bad move for any reason? For argument's sake, assume no salary or working condition changes.", "author_fullname": "t2_sa00zipn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benefit to holding adjacent positions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174p2q9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696954376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, and TIA! I&amp;#39;m a data engineer in a somewhat restrictive environment- we&amp;#39;re all baremetal at my shop, and the &lt;em&gt;only&lt;/em&gt; pipelines we&amp;#39;ve run are using boutique code I&amp;#39;ve had to create, manage, and supervise. It&amp;#39;s an extremely nonstandard environment- we&amp;#39;re 100% locked down to our intranet- no pip/apt/yum install etc. We have a single RDBMS for a warehouse and my single server to process on.&lt;/p&gt;\n\n&lt;p&gt;I see this as a huge detriment to my career long term. I&amp;#39;m still working on a degree, as is my wife- so I don&amp;#39;t have enough time to play around on my own time and stay up to speed on the modern data stack. I therefore have absolutely 0 professional cloud experience.&lt;/p&gt;\n\n&lt;p&gt;However, an internal transfer position has opened as a cloud engineer. This would give me a broader skillset. Is there any reason I shouldn&amp;#39;t jump on it? I do intend, in the long run, to move back to data engineering with the broader experience gained. I&amp;#39;m also 1 year from finishing my degree and my wife is 1.5 from finishing her doctorate, so I&amp;#39;ll have more time to play with things on my own time. Is there any angle I&amp;#39;m not considering here? Would this be a bad move for any reason? For argument&amp;#39;s sake, assume no salary or working condition changes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "174p2q9", "is_robot_indexable": true, "report_reasons": null, "author": "dillan_pickle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174p2q9/benefit_to_holding_adjacent_positions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174p2q9/benefit_to_holding_adjacent_positions/", "subreddit_subscribers": 133138, "created_utc": 1696954376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the difference between Databricks\u2019s Overwatch and System Tables tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_174j9fg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7H7guNkrLzYUixs3AR3Psyd23HlFvAUyaDvJr6r1KQs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696938761.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.det.life", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.det.life/whats-the-difference-between-databricks-s-overwatch-and-system-tables-tools-f9d0cd75a2f2", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?auto=webp&amp;s=cdf604b54fe85e5e161f564bad80873c3b0b2d73", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=495021a9846e755e37ba06d7fb7b00bdd919d5af", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=74fc4c3c060466a5374a28a66f96c5e3a1efaa3e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f2f1a08b5cf74574326b34e55fcaa8a7192d42f2", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=60ae1eaf20860d2e12e3860d79789872c68c554f", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8619f09a42879ea79dc90050268fbd11970bf2a0", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dfe55cdcb6fd4feaba16b6a4a3591f9e94b9c621", "width": 1080, "height": 720}], "variants": {}, "id": "XTYuj6I-Q2v_xqeIXOzOgfp785bB9G0Zkdojd7TtV_w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "174j9fg", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174j9fg/whats_the_difference_between_databrickss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.det.life/whats-the-difference-between-databricks-s-overwatch-and-system-tables-tools-f9d0cd75a2f2", "subreddit_subscribers": 133138, "created_utc": 1696938761.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I recently started a job as a Junior Data Engineer. I have learned a lot so far working with DBT, Snowflake, Looker, Jira workflow, and Git using SQL and Python.\n\nI plan to stay at this company for 2 years. My boss has assured me that if I work hard I will progress from a Junior to full Data Engineer.\n\nMy question is: what other paths could I take after working as a Data Engineer for 2-3 years? What other skills should I learn to enable me to increase my salary?\n\nFrom basic research: Data Management, Senior Data Engineer, Data Scientist, Backend Engineer, Machine Learning Engineer are some potential paths. (I personally am interested in Machine Learning)\n\nJust looking for some advice/suggestions. Thanks!", "author_fullname": "t2_138zju", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Potential Career path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174xegg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696975079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I recently started a job as a Junior Data Engineer. I have learned a lot so far working with DBT, Snowflake, Looker, Jira workflow, and Git using SQL and Python.&lt;/p&gt;\n\n&lt;p&gt;I plan to stay at this company for 2 years. My boss has assured me that if I work hard I will progress from a Junior to full Data Engineer.&lt;/p&gt;\n\n&lt;p&gt;My question is: what other paths could I take after working as a Data Engineer for 2-3 years? What other skills should I learn to enable me to increase my salary?&lt;/p&gt;\n\n&lt;p&gt;From basic research: Data Management, Senior Data Engineer, Data Scientist, Backend Engineer, Machine Learning Engineer are some potential paths. (I personally am interested in Machine Learning)&lt;/p&gt;\n\n&lt;p&gt;Just looking for some advice/suggestions. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "174xegg", "is_robot_indexable": true, "report_reasons": null, "author": "SydeFxs", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174xegg/potential_career_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174xegg/potential_career_path/", "subreddit_subscribers": 133138, "created_utc": 1696975079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[PeerDB's](https://peerdb.io/) founding engineer Kevin provides a detailed analysis on benchmarks comparing PeerDB with AirByte. The benchmark involves syncing a large table (\\~1.5TB) from Postgres to Snowflake. Results show that PeerDB can be\u00a02x-16x faster\u00a0than AirByte. He digs deep into\u00a0how\u00a0PeerDB is able to achieve this performance.  \n[https://blog.peerdb.io/benchmarking-postgres-replication-peerdb-vs-airbyte](https://blog.peerdb.io/benchmarking-postgres-replication-peerdb-vs-airbyte)", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benchmarking Postgres Replication: PeerDB vs Airbyte", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174t7j8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696964716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://peerdb.io/\"&gt;PeerDB&amp;#39;s&lt;/a&gt; founding engineer Kevin provides a detailed analysis on benchmarks comparing PeerDB with AirByte. The benchmark involves syncing a large table (~1.5TB) from Postgres to Snowflake. Results show that PeerDB can be\u00a02x-16x faster\u00a0than AirByte. He digs deep into\u00a0how\u00a0PeerDB is able to achieve this performance.&lt;br/&gt;\n&lt;a href=\"https://blog.peerdb.io/benchmarking-postgres-replication-peerdb-vs-airbyte\"&gt;https://blog.peerdb.io/benchmarking-postgres-replication-peerdb-vs-airbyte&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "174t7j8", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174t7j8/benchmarking_postgres_replication_peerdb_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174t7j8/benchmarking_postgres_replication_peerdb_vs/", "subreddit_subscribers": 133138, "created_utc": 1696964716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "lkml2cube \u2014 Python tool for Looker to Cube migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_174p08y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GozUw7rjDqDnEWxOLuOQx3_1TmMF9JnqnGL1gTr-ILM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696954215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/introducing-a-tool-for-looker-to-cube-migration", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?auto=webp&amp;s=b8eba6ffc77a44754baf05f96de17f030efb060f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=383c436589031515ff8397aedca4f5b01a0d4975", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fde98a1c0b9bf8b65edbe8060349c707a4d9668f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a68b94465cfab03d609b94d4be932d2595c1d586", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d436ec35787d4ce31655cee673aa0977ac88b71e", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87c6b8d6eee163118e7d71a3167d88c56761da52", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6cdb3d80b9ba7698ee60180bedda92b27ab1db7a", "width": 1080, "height": 567}], "variants": {}, "id": "YN4ONYvMYrtjTMi361aNDScXaUCDC4BoWTi_F_Fd1wE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "174p08y", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174p08y/lkml2cube_python_tool_for_looker_to_cube_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/introducing-a-tool-for-looker-to-cube-migration", "subreddit_subscribers": 133138, "created_utc": 1696954215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you are interested in massive data processing, [this case](https://doris.apache.org/zh-CN/blog/Log-Analysis-How-to-Digest-15-Billion-Logs-Per-Day-and-Keep-Big-Queries-Within-1-Second) might help.\n\nhttps://preview.redd.it/cbo62wez7dtb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=bfddfc33093973663168acaa2faec12eacf0f460", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Log Analysis: How to Digest 15 Billion Logs Per Day and Keep Big Queries Within 1 Second", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "media_metadata": {"cbo62wez7dtb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0a5caa4edbd79f9685695161cdef806fde66dcf1"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=57bd4f7571a2e26560df0d73593faadb8719ce72"}, {"y": 152, "x": 320, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=39755c160045c001c5e73a094aa359423c6b977b"}, {"y": 304, "x": 640, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=afe1f4773ac6e4a30eef23670a47ba7aa01ccf1a"}, {"y": 456, "x": 960, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0bb433e300b8c0ca107dfdc6c5950f37b3b1d24b"}, {"y": 513, "x": 1080, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c5d59d668997a10e02f0d0e92ce0fb0abbbb75de"}], "s": {"y": 609, "x": 1280, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=bfddfc33093973663168acaa2faec12eacf0f460"}, "id": "cbo62wez7dtb1"}}, "name": "t3_174jidr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Kie1SniWpE6PDH5ujmco-oEtxQ7mTnSn37C3nGuPrIk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696939550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you are interested in massive data processing, &lt;a href=\"https://doris.apache.org/zh-CN/blog/Log-Analysis-How-to-Digest-15-Billion-Logs-Per-Day-and-Keep-Big-Queries-Within-1-Second\"&gt;this case&lt;/a&gt; might help.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/cbo62wez7dtb1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bfddfc33093973663168acaa2faec12eacf0f460\"&gt;https://preview.redd.it/cbo62wez7dtb1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bfddfc33093973663168acaa2faec12eacf0f460&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "174jidr", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174jidr/log_analysis_how_to_digest_15_billion_logs_per/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174jidr/log_analysis_how_to_digest_15_billion_logs_per/", "subreddit_subscribers": 133138, "created_utc": 1696939550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mxj2oz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Postgres Partitioning Really That Hard? An Introduction To Hypertables", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 84, "top_awarded_type": null, "hide_score": false, "name": "t3_1750it8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nH8_CLzBzX0ff9WWmlejtIGwpKa7RZhoqEzoLbWGbdc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696983359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "timescale.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.timescale.com/blog/is-postgres-partitioning-really-that-hard-introducing-hypertables/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8DwNT-qox_OGUxc-w-dVavJ1akjq9d4TstseahE3qP0.jpg?auto=webp&amp;s=a0b0ab4d051bb692ef7a9e1d70a64211af379d61", "width": 1165, "height": 705}, "resolutions": [{"url": "https://external-preview.redd.it/8DwNT-qox_OGUxc-w-dVavJ1akjq9d4TstseahE3qP0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=bc3f07889f620bcb2376f9ab109c79412dc7203a", "width": 108, "height": 65}, {"url": "https://external-preview.redd.it/8DwNT-qox_OGUxc-w-dVavJ1akjq9d4TstseahE3qP0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1183a3b7f926efb753d30b343ccdd10eb6c50a2f", "width": 216, "height": 130}, {"url": "https://external-preview.redd.it/8DwNT-qox_OGUxc-w-dVavJ1akjq9d4TstseahE3qP0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=09bb048debb13c2ce4312f43d4a69f666ad5bd69", "width": 320, "height": 193}, {"url": "https://external-preview.redd.it/8DwNT-qox_OGUxc-w-dVavJ1akjq9d4TstseahE3qP0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b4b602ae74cbd92b7ecaf6e9f0fcb84ddd308994", "width": 640, "height": 387}, {"url": "https://external-preview.redd.it/8DwNT-qox_OGUxc-w-dVavJ1akjq9d4TstseahE3qP0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a4eb5ef3e3da98d949ba026331fdd5275dc59d78", "width": 960, "height": 580}, {"url": "https://external-preview.redd.it/8DwNT-qox_OGUxc-w-dVavJ1akjq9d4TstseahE3qP0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7452b4b00b45854ca0b197ba68220b34a6504482", "width": 1080, "height": 653}], "variants": {}, "id": "9W_IZL-D9EQCSVOv6_MIioRnc-UBvjIEgD9A_SuAtIc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1750it8", "is_robot_indexable": true, "report_reasons": null, "author": "carlotasoto", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1750it8/is_postgres_partitioning_really_that_hard_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.timescale.com/blog/is-postgres-partitioning-really-that-hard-introducing-hypertables/", "subreddit_subscribers": 133138, "created_utc": 1696983359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, my company has about 30GB total on a sharepoint site. I need to get all these files into an Azure storage account.\n\nI was planning on doing this simply with ADF but the catch is that I can't establish the connection due to permissions (no sharepoint linked service).\n\nDoes anyone have a suggestion on how to do this efficiently?\n\nCurrently I'm biting through the pain and downloading everything as zip -&gt; upload zip to storage and unpack using ADF.", "author_fullname": "t2_16t847", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I move 30GB from sharepoint to Azure storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174mh1z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696947696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, my company has about 30GB total on a sharepoint site. I need to get all these files into an Azure storage account.&lt;/p&gt;\n\n&lt;p&gt;I was planning on doing this simply with ADF but the catch is that I can&amp;#39;t establish the connection due to permissions (no sharepoint linked service).&lt;/p&gt;\n\n&lt;p&gt;Does anyone have a suggestion on how to do this efficiently?&lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m biting through the pain and downloading everything as zip -&amp;gt; upload zip to storage and unpack using ADF.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174mh1z", "is_robot_indexable": true, "report_reasons": null, "author": "drollerfoot7", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174mh1z/how_do_i_move_30gb_from_sharepoint_to_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174mh1z/how_do_i_move_30gb_from_sharepoint_to_azure/", "subreddit_subscribers": 133138, "created_utc": 1696947696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone, I have recently created a new project called [Data Catering](https://data.catering/). It is a data generation and validation tool that can automatically discover, generate and validate data in any format. This is my attempt at creating a tool that will aid in being proactive about data quality and testing across both batch and event data.\n\nYou can read more about it from the article I have [written here](https://medium.com/@pflooky/data-catering-how-you-could-replicate-your-production-data-flow-in-your-local-laptop-fd435b45ece7) or get hands on and try it out [yourself here](https://data.catering/get-started/docker/).\n\nAppreciate any feedback.", "author_fullname": "t2_h209j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Catering - How you could replicate your production data flow in your local laptop", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1753823", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696991144.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I have recently created a new project called &lt;a href=\"https://data.catering/\"&gt;Data Catering&lt;/a&gt;. It is a data generation and validation tool that can automatically discover, generate and validate data in any format. This is my attempt at creating a tool that will aid in being proactive about data quality and testing across both batch and event data.&lt;/p&gt;\n\n&lt;p&gt;You can read more about it from the article I have &lt;a href=\"https://medium.com/@pflooky/data-catering-how-you-could-replicate-your-production-data-flow-in-your-local-laptop-fd435b45ece7\"&gt;written here&lt;/a&gt; or get hands on and try it out &lt;a href=\"https://data.catering/get-started/docker/\"&gt;yourself here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Appreciate any feedback.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "1753823", "is_robot_indexable": true, "report_reasons": null, "author": "Pitah7", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1753823/data_catering_how_you_could_replicate_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1753823/data_catering_how_you_could_replicate_your/", "subreddit_subscribers": 133138, "created_utc": 1696991144.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, I am looking to gather some opinions or thoughts on some the major research areas in modern data engineering. To preface, I am a masters student designing a research proposal for my exit thesis and am struggling to think of a worthy research area.\n\nI\u2019ve considered a comparative research study on traditional vs. serverless architecture for real time data pipelines. Specifically impacts on scalability, costs, and latency. But this just seems like a blog topic, not academic research. \n\nSo for anyone who is highly experienced or on the research/academic side of technology, what are your thoughts on major research areas?", "author_fullname": "t2_9uqlze0a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predominant research areas in Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1752rut", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696989819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I am looking to gather some opinions or thoughts on some the major research areas in modern data engineering. To preface, I am a masters student designing a research proposal for my exit thesis and am struggling to think of a worthy research area.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve considered a comparative research study on traditional vs. serverless architecture for real time data pipelines. Specifically impacts on scalability, costs, and latency. But this just seems like a blog topic, not academic research. &lt;/p&gt;\n\n&lt;p&gt;So for anyone who is highly experienced or on the research/academic side of technology, what are your thoughts on major research areas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1752rut", "is_robot_indexable": true, "report_reasons": null, "author": "EarthEmbarrassed4301", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1752rut/predominant_research_areas_in_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1752rut/predominant_research_areas_in_data_engineering/", "subreddit_subscribers": 133138, "created_utc": 1696989819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working in a medium-sized company and due to regulatory reasons must work on-prem for now. \n\nI am setting up a data lake + warehouse solution to support our BI. The data isn't enormous (say 200 million rows across a bunch of SQL sources). \n\nI am considering a lake house type approach using either delta tables or Apache Iceberg tables so that a lot of the work would be reusable and easy to migrate if/when we get to move to Databricks or something. Does this sound reasonable?\n\nWhat I am a bit confused about is setting up the infrastructure for writing data into the deltalake tables. Do I really need to run Spark locally to do that, or am I getting something wrong? In terms of computation Spark seems a bit overkill for our usecase, but I would really like to use delta tables or iceberg for the metadata niceties.", "author_fullname": "t2_7qz9ccwa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On-prem setup for a lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174qp1c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696958474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working in a medium-sized company and due to regulatory reasons must work on-prem for now. &lt;/p&gt;\n\n&lt;p&gt;I am setting up a data lake + warehouse solution to support our BI. The data isn&amp;#39;t enormous (say 200 million rows across a bunch of SQL sources). &lt;/p&gt;\n\n&lt;p&gt;I am considering a lake house type approach using either delta tables or Apache Iceberg tables so that a lot of the work would be reusable and easy to migrate if/when we get to move to Databricks or something. Does this sound reasonable?&lt;/p&gt;\n\n&lt;p&gt;What I am a bit confused about is setting up the infrastructure for writing data into the deltalake tables. Do I really need to run Spark locally to do that, or am I getting something wrong? In terms of computation Spark seems a bit overkill for our usecase, but I would really like to use delta tables or iceberg for the metadata niceties.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "174qp1c", "is_robot_indexable": true, "report_reasons": null, "author": "s0uha1", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174qp1c/onprem_setup_for_a_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174qp1c/onprem_setup_for_a_lakehouse/", "subreddit_subscribers": 133138, "created_utc": 1696958474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hi all.\n\nBasically I will have multiple files (CSV, XML, etc.) ingested in our database but normally we use pipeline to ingest the file into a staging table and then a stored procedures with a match and merge T-SQL code to normalize the data and after that views that java developers can call. \n\nI want to transform this in more a Data Engineer way using python, airflow etc. I'm SQL Developer but I have some knowledge in python and some data engineer tools.\n\nI would like to know your opinion and what I could do to make this process more modern and use more data engineering tools and not just T-SQL code. If possible using only open-source tools.\n\nTIA.", "author_fullname": "t2_yvtk2r3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative method for a SQL Server T-SQL ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174q4x7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696957082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all.&lt;/p&gt;\n\n&lt;p&gt;Basically I will have multiple files (CSV, XML, etc.) ingested in our database but normally we use pipeline to ingest the file into a staging table and then a stored procedures with a match and merge T-SQL code to normalize the data and after that views that java developers can call. &lt;/p&gt;\n\n&lt;p&gt;I want to transform this in more a Data Engineer way using python, airflow etc. I&amp;#39;m SQL Developer but I have some knowledge in python and some data engineer tools.&lt;/p&gt;\n\n&lt;p&gt;I would like to know your opinion and what I could do to make this process more modern and use more data engineering tools and not just T-SQL code. If possible using only open-source tools.&lt;/p&gt;\n\n&lt;p&gt;TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174q4x7", "is_robot_indexable": true, "report_reasons": null, "author": "peixinho3", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174q4x7/alternative_method_for_a_sql_server_tsql_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174q4x7/alternative_method_for_a_sql_server_tsql_etl/", "subreddit_subscribers": 133138, "created_utc": 1696957082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, I'm a fresher in DA and DE. I was assigned a task to build a user dimension.\n\n**Purpose**: map user between 3 sources (firebase, MAX, appsflyer) in order to create a complete user journey\n\nIdentifiers that can be used in 3 tables: user\\_id (from firebase), idfa, idfv, appsflyer\\_id\n\nI started to analyze how each identifier would change:\n\n* for user\\_id, it will change after re-installs because my app doesn't require any login so the user\\_id is not consistent \n* idfa will change if a user reset OS or turn on limit ad tracking\n* idfv will change if a user switches to new device\n\nWhat I'm struggling is how i can identify a user and develop general logic, given one of real-life scenarios:\n\n* a user can have multiple devices. how can i identify these devices as 1 particular person?\n* if a user re-installs the app (user\\_id changes), how can i identify him/her as old user coming back?\n* what if a user change platform? (from ios to android) how can i identify this user as old one without treating him/her as new one?\n* not all records in 3 tables can be joined with user\\_id, idfa or idfv (separately); sometimes, user\\_id AND idfa; sometimes, idfa only; sometimes, user\\_id and idfv as i tried to figure out how to layer these ids (trying to put things in a nested field)\n* answering and solving above cases (separately) is not too hard but when those 3 happen at the same time. things starts to become too complex and tangled for me to process (it's demoralizing af :((( )\n\nWrong or missed identification will result in wrong analytics, e.g: wrong CLV as $40K revenue for 10K users is different from $40K revenue for 20K users\n\nIs there any aspects or approaches that i should consider to solve this? Thanks in advanced \\^\\^", "author_fullname": "t2_8wrp4ovv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to approach user identification when building user dimension?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174eeqe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696919412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I&amp;#39;m a fresher in DA and DE. I was assigned a task to build a user dimension.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: map user between 3 sources (firebase, MAX, appsflyer) in order to create a complete user journey&lt;/p&gt;\n\n&lt;p&gt;Identifiers that can be used in 3 tables: user_id (from firebase), idfa, idfv, appsflyer_id&lt;/p&gt;\n\n&lt;p&gt;I started to analyze how each identifier would change:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;for user_id, it will change after re-installs because my app doesn&amp;#39;t require any login so the user_id is not consistent &lt;/li&gt;\n&lt;li&gt;idfa will change if a user reset OS or turn on limit ad tracking&lt;/li&gt;\n&lt;li&gt;idfv will change if a user switches to new device&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What I&amp;#39;m struggling is how i can identify a user and develop general logic, given one of real-life scenarios:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;a user can have multiple devices. how can i identify these devices as 1 particular person?&lt;/li&gt;\n&lt;li&gt;if a user re-installs the app (user_id changes), how can i identify him/her as old user coming back?&lt;/li&gt;\n&lt;li&gt;what if a user change platform? (from ios to android) how can i identify this user as old one without treating him/her as new one?&lt;/li&gt;\n&lt;li&gt;not all records in 3 tables can be joined with user_id, idfa or idfv (separately); sometimes, user_id AND idfa; sometimes, idfa only; sometimes, user_id and idfv as i tried to figure out how to layer these ids (trying to put things in a nested field)&lt;/li&gt;\n&lt;li&gt;answering and solving above cases (separately) is not too hard but when those 3 happen at the same time. things starts to become too complex and tangled for me to process (it&amp;#39;s demoralizing af :((( )&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Wrong or missed identification will result in wrong analytics, e.g: wrong CLV as $40K revenue for 10K users is different from $40K revenue for 20K users&lt;/p&gt;\n\n&lt;p&gt;Is there any aspects or approaches that i should consider to solve this? Thanks in advanced ^^&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "174eeqe", "is_robot_indexable": true, "report_reasons": null, "author": "girlsyesboysno", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/174eeqe/how_to_approach_user_identification_when_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174eeqe/how_to_approach_user_identification_when_building/", "subreddit_subscribers": 133138, "created_utc": 1696919412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context this is happening within a Databricks DLT (basically Spark Structured Streaming) pipeline. I was messing around with the checkpoint folder trying to delete the previous checkpoints so that the stream would start from scratch during the next run. Well, in doing so I started receiving the below error for a specific table every pipeline run. I've tried the following, but nothing has worked so far:\n\n&amp;#x200B;\n\n1. Create a new pipeline\n2. Change target storage path so that checkpoint directory gets written to new path\n3. rename the table causing the problem\n\nI'm new to streaming data and am completely lost with this error, any help would be greatly appreciated!\n\n    org.apache.spark.sql.execution.streaming.state.InvalidUnsafeRowException: The streaming query failed by state format invalidation. The following reasons may cause this: 1. An old Spark version wrote the checkpoint that is incompatible with the current one; 2. Broken checkpoint files; 3. The query is changed among restart. For the first case, you can try to restart the application without checkpoint or use the legacy Spark version to process the streaming state.\n    [Value]Error message is: Variable-length field validation error:", "author_fullname": "t2_3i1tg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Fix InvalidUnsafeRowExeption Error In Databricks Streaming Pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17545sd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696993883.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context this is happening within a Databricks DLT (basically Spark Structured Streaming) pipeline. I was messing around with the checkpoint folder trying to delete the previous checkpoints so that the stream would start from scratch during the next run. Well, in doing so I started receiving the below error for a specific table every pipeline run. I&amp;#39;ve tried the following, but nothing has worked so far:&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Create a new pipeline&lt;/li&gt;\n&lt;li&gt;Change target storage path so that checkpoint directory gets written to new path&lt;/li&gt;\n&lt;li&gt;rename the table causing the problem&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m new to streaming data and am completely lost with this error, any help would be greatly appreciated!&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;org.apache.spark.sql.execution.streaming.state.InvalidUnsafeRowException: The streaming query failed by state format invalidation. The following reasons may cause this: 1. An old Spark version wrote the checkpoint that is incompatible with the current one; 2. Broken checkpoint files; 3. The query is changed among restart. For the first case, you can try to restart the application without checkpoint or use the legacy Spark version to process the streaming state.\n[Value]Error message is: Variable-length field validation error:\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17545sd", "is_robot_indexable": true, "report_reasons": null, "author": "Shatonmedeek", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17545sd/how_to_fix_invalidunsaferowexeption_error_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17545sd/how_to_fix_invalidunsaferowexeption_error_in/", "subreddit_subscribers": 133138, "created_utc": 1696993883.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was given a take home assignment from a well known company that requires more than a days worth of work and strongly considering turning down the interview to prepare for other interviews instead. Curious on your experience with take home assignments. What factors do you take into consideration? (Good company, higher pay, promotion, length of assignment, etc.)", "author_fullname": "t2_wmupx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do people feel about take home assignments?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1753giq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696991845.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was given a take home assignment from a well known company that requires more than a days worth of work and strongly considering turning down the interview to prepare for other interviews instead. Curious on your experience with take home assignments. What factors do you take into consideration? (Good company, higher pay, promotion, length of assignment, etc.)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1753giq", "is_robot_indexable": true, "report_reasons": null, "author": "omelettepancake", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1753giq/how_do_people_feel_about_take_home_assignments/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1753giq/how_do_people_feel_about_take_home_assignments/", "subreddit_subscribers": 133138, "created_utc": 1696991845.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking for your input on alternatives to packaged BI tools such as Power BI o Tableau.\n\nSo far, I've found Streamlit, which seems easy to learn but limited on scale and Plotly/Dash, which needs multiple tweaks on web servers and web development (cool, but non entirely inside the scope of a data engineering team) unless using the Premium version, which has no explicit pricing and could potentially cost a liver and a half.\n\n&amp;#x200B;", "author_fullname": "t2_yikhi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's a good production-ready tool/framework/library to create dashboard/visualizations for data engineers to serve enterprise users and their clients, as of 2023, that would, ideally, reduce the amount of time needed to deploy and configure web servers, build auth logic from scratch and such?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1751s1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696986967.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for your input on alternatives to packaged BI tools such as Power BI o Tableau.&lt;/p&gt;\n\n&lt;p&gt;So far, I&amp;#39;ve found Streamlit, which seems easy to learn but limited on scale and Plotly/Dash, which needs multiple tweaks on web servers and web development (cool, but non entirely inside the scope of a data engineering team) unless using the Premium version, which has no explicit pricing and could potentially cost a liver and a half.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1751s1q", "is_robot_indexable": true, "report_reasons": null, "author": "gglavida", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1751s1q/whats_a_good_productionready_toolframeworklibrary/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1751s1q/whats_a_good_productionready_toolframeworklibrary/", "subreddit_subscribers": 133138, "created_utc": 1696986967.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is it possible to somehow get data lineage from ssis packages.? If not, what would be the best solution to Document what ssis packages actually do, from high level?", "author_fullname": "t2_ugtaizjq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data lineage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174xlkf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696975565.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is it possible to somehow get data lineage from ssis packages.? If not, what would be the best solution to Document what ssis packages actually do, from high level?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174xlkf", "is_robot_indexable": true, "report_reasons": null, "author": "Last-Marzipan-2808", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174xlkf/data_lineage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174xlkf/data_lineage/", "subreddit_subscribers": 133138, "created_utc": 1696975565.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm US based and have been receiving phone screens and the occasional interview. My current stack is Python, R, SQL, Snowflake. I'd appreciate guidance on where to spend my time and perhaps a resume review.", "author_fullname": "t2_tb3wt9ao", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for mentorship as I try to break into data engineering! Is anyone open to connecting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174vubc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696971117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m US based and have been receiving phone screens and the occasional interview. My current stack is Python, R, SQL, Snowflake. I&amp;#39;d appreciate guidance on where to spend my time and perhaps a resume review.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "174vubc", "is_robot_indexable": true, "report_reasons": null, "author": "celestial_orchestra", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/174vubc/looking_for_mentorship_as_i_try_to_break_into/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174vubc/looking_for_mentorship_as_i_try_to_break_into/", "subreddit_subscribers": 133138, "created_utc": 1696971117.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}