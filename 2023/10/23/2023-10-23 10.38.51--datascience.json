{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi I'm fairly new to Data Science and I'm only now learning about MySQL. I have only previous experience on R and MySQL is really causing me problems. I understand everything when studying and watching content on the language but I get stuck when trying examples with real dataset. How do I get better on MySQL?", "author_fullname": "t2_7jw3rp26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you guys practise using MySQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17dtmqe", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 121, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 121, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697982303.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi I&amp;#39;m fairly new to Data Science and I&amp;#39;m only now learning about MySQL. I have only previous experience on R and MySQL is really causing me problems. I understand everything when studying and watching content on the language but I get stuck when trying examples with real dataset. How do I get better on MySQL?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17dtmqe", "is_robot_indexable": true, "report_reasons": null, "author": "jumpi3y", "discussion_type": null, "num_comments": 59, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17dtmqe/how_do_you_guys_practise_using_mysql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17dtmqe/how_do_you_guys_practise_using_mysql/", "subreddit_subscribers": 1095888, "created_utc": 1697982303.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "To all the data science professionals, enthusiasts and learners, do y'all remember the syntax of the libraries, languages and other tools most of the time? Or do you always have a reference resource that you use to code up the problems? \n\nI have just begun with data science through courses in mathematics, stochastics and machine learning at the uni. The basic Python syntax is fine. But using libraries like pandas, scikit learn and tensorflow, all vary in their syntax. Furthermore, there's also R, C++ and other languages that sometimes come into the picture. \n\nThis made me think about this question whether the professionals remember the syntax or they just keep the key steps in their mind. Later, when they need, they use resources to use the syntax. \n\nAlso, if you use any resources which are popular, please share in the comments.", "author_fullname": "t2_eac1tyvg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you remember the syntax of the tools you use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17e01li", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697999917.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;To all the data science professionals, enthusiasts and learners, do y&amp;#39;all remember the syntax of the libraries, languages and other tools most of the time? Or do you always have a reference resource that you use to code up the problems? &lt;/p&gt;\n\n&lt;p&gt;I have just begun with data science through courses in mathematics, stochastics and machine learning at the uni. The basic Python syntax is fine. But using libraries like pandas, scikit learn and tensorflow, all vary in their syntax. Furthermore, there&amp;#39;s also R, C++ and other languages that sometimes come into the picture. &lt;/p&gt;\n\n&lt;p&gt;This made me think about this question whether the professionals remember the syntax or they just keep the key steps in their mind. Later, when they need, they use resources to use the syntax. &lt;/p&gt;\n\n&lt;p&gt;Also, if you use any resources which are popular, please share in the comments.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17e01li", "is_robot_indexable": true, "report_reasons": null, "author": "Aware_Value4603", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17e01li/do_you_remember_the_syntax_of_the_tools_you_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17e01li/do_you_remember_the_syntax_of_the_tools_you_use/", "subreddit_subscribers": 1095888, "created_utc": 1697999917.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "It's fascinating to see how the field of Data Science has evolved in recent years. Just a few years ago, there weren't many dedicated PhD programs in Data Science, and professionals from various STEM backgrounds often considered it as an alternative career option. However, today, we have a plethora of Master's and even a few PhD programs specializing in Data Science. This transformation has turned Data Science into a distinct field, encompassing everything from analytics to ethics.\n\nWill candidates with PhDs in traditional STEM fields become less favored for Data Science jobs in the future, with Data Science program graduates taking the lead? \n\nWill the field place more emphasis on specialized education as it continues to mature?\n\nWhat are your thoughts on this matter?", "author_fullname": "t2_e3davsne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Changing Landscape of Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17dsyjh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697980293.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s fascinating to see how the field of Data Science has evolved in recent years. Just a few years ago, there weren&amp;#39;t many dedicated PhD programs in Data Science, and professionals from various STEM backgrounds often considered it as an alternative career option. However, today, we have a plethora of Master&amp;#39;s and even a few PhD programs specializing in Data Science. This transformation has turned Data Science into a distinct field, encompassing everything from analytics to ethics.&lt;/p&gt;\n\n&lt;p&gt;Will candidates with PhDs in traditional STEM fields become less favored for Data Science jobs in the future, with Data Science program graduates taking the lead? &lt;/p&gt;\n\n&lt;p&gt;Will the field place more emphasis on specialized education as it continues to mature?&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on this matter?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17dsyjh", "is_robot_indexable": true, "report_reasons": null, "author": "noserviceyet", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17dsyjh/the_changing_landscape_of_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17dsyjh/the_changing_landscape_of_data_science/", "subreddit_subscribers": 1095888, "created_utc": 1697980293.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I understand ALOT of online DS degrees are a cash grab with maybe a handful of conceptual courses that aren't technical in the slightest or give good real-world skills like writing efficient SQL queries or otherwise.\n\nThat being said, a ton of programs for DS out there including the one I'm taking currently are more or less a mix between CS and Stats with a few database or data science code or math-specific courses mixed in. Before my university had a DS degree path it was considered a specialty focus on data science but the main degree was CS until they swapped it to a full-on path.\n\n&amp;#x200B;\n\nJust a rant, I've been considering switching to CS in light of finding out people strongly dislike DS degrees but I enjoy my DS courses way more than a CS or Stats-focused degree that only covers those domains. Can a solid project on github overcome these objections?", "author_fullname": "t2_hdruw38yy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The obsession/hate for DS undergrad degrees", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17e02jy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Education", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697999994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I understand ALOT of online DS degrees are a cash grab with maybe a handful of conceptual courses that aren&amp;#39;t technical in the slightest or give good real-world skills like writing efficient SQL queries or otherwise.&lt;/p&gt;\n\n&lt;p&gt;That being said, a ton of programs for DS out there including the one I&amp;#39;m taking currently are more or less a mix between CS and Stats with a few database or data science code or math-specific courses mixed in. Before my university had a DS degree path it was considered a specialty focus on data science but the main degree was CS until they swapped it to a full-on path.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Just a rant, I&amp;#39;ve been considering switching to CS in light of finding out people strongly dislike DS degrees but I enjoy my DS courses way more than a CS or Stats-focused degree that only covers those domains. Can a solid project on github overcome these objections?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b37a3ae-70eb-11ee-b5c7-7e3a672f3d51", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#00a6a5", "id": "17e02jy", "is_robot_indexable": true, "report_reasons": null, "author": "errOnCaution_", "discussion_type": null, "num_comments": 77, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17e02jy/the_obsessionhate_for_ds_undergrad_degrees/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17e02jy/the_obsessionhate_for_ds_undergrad_degrees/", "subreddit_subscribers": 1095888, "created_utc": 1697999994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a data scientist looking to solve a problem that you have. My experience is on regressions, classification and scores for credit. Could it be somehing that exist and its expensive, something that it's not out there, etc. Looking to help :)", "author_fullname": "t2_80ydgoh1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What problems would you like to be solved?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17eafwm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698030264.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698029544.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data scientist looking to solve a problem that you have. My experience is on regressions, classification and scores for credit. Could it be somehing that exist and its expensive, something that it&amp;#39;s not out there, etc. Looking to help :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "17eafwm", "is_robot_indexable": true, "report_reasons": null, "author": "ResponsibleGazelle76", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17eafwm/what_problems_would_you_like_to_be_solved/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17eafwm/what_problems_would_you_like_to_be_solved/", "subreddit_subscribers": 1095888, "created_utc": 1698029544.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Not talking folks who work off linux servers or VMs, I'm talking about those of us who work on a linux install running on our local hardware that might also run other things (games, media, etc)\n\nI do all my work through windows (corporate laptop) but sometimes I want to try out toy problems and other things on a personal machine.\n\nI was using Anaconda, but something about the conda shell caused Arch to try to compile system packages within the conda environment and things went haywire.\n\nRolling my own python virtual env just feels like work, and again, I broke my window manager (qtile, runs on python) by setting it up.\n\nNot against going back to Anaconda, but I'm curious what other folks in my situation (daily drive linux on their primary personal machine, on which they also do some data work) do to keep a working data science environment going.", "author_fullname": "t2_rrh4y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Native Linux Users: How do you setup your DS Environment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17e7m1p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698020773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not talking folks who work off linux servers or VMs, I&amp;#39;m talking about those of us who work on a linux install running on our local hardware that might also run other things (games, media, etc)&lt;/p&gt;\n\n&lt;p&gt;I do all my work through windows (corporate laptop) but sometimes I want to try out toy problems and other things on a personal machine.&lt;/p&gt;\n\n&lt;p&gt;I was using Anaconda, but something about the conda shell caused Arch to try to compile system packages within the conda environment and things went haywire.&lt;/p&gt;\n\n&lt;p&gt;Rolling my own python virtual env just feels like work, and again, I broke my window manager (qtile, runs on python) by setting it up.&lt;/p&gt;\n\n&lt;p&gt;Not against going back to Anaconda, but I&amp;#39;m curious what other folks in my situation (daily drive linux on their primary personal machine, on which they also do some data work) do to keep a working data science environment going.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17e7m1p", "is_robot_indexable": true, "report_reasons": null, "author": "feldomatic", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17e7m1p/native_linux_users_how_do_you_setup_your_ds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17e7m1p/native_linux_users_how_do_you_setup_your_ds/", "subreddit_subscribers": 1095888, "created_utc": 1698020773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_amfdjuba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the non-data scientist tasks that you still do in your data scientist role?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17efkcz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698049934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17efkcz", "is_robot_indexable": true, "report_reasons": null, "author": "limedove", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17efkcz/what_are_the_nondata_scientist_tasks_that_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17efkcz/what_are_the_nondata_scientist_tasks_that_you/", "subreddit_subscribers": 1095888, "created_utc": 1698049934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "When do companies go in \"hibernation\" for the holidays? Has it already started? Is it worth applying to more jobs until February?", "author_fullname": "t2_jnnvdz39c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Has \"hibernation\" for the holidays already started?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ec592", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698035311.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When do companies go in &amp;quot;hibernation&amp;quot; for the holidays? Has it already started? Is it worth applying to more jobs until February?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17ec592", "is_robot_indexable": true, "report_reasons": null, "author": "daufoi21", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ec592/has_hibernation_for_the_holidays_already_started/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ec592/has_hibernation_for_the_holidays_already_started/", "subreddit_subscribers": 1095888, "created_utc": 1698035311.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m trying to model the probability of developing tooth decay for patients, which features do you think are relevant, and where can I find related datasets? Aside from the brushing frequency, brushing time, brushing quality, diet\u2026", "author_fullname": "t2_e4r051p5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which features/factors help determine the likelihood of developing tooth decay?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17egh5m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698054033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to model the probability of developing tooth decay for patients, which features do you think are relevant, and where can I find related datasets? Aside from the brushing frequency, brushing time, brushing quality, diet\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "17egh5m", "is_robot_indexable": true, "report_reasons": null, "author": "Mysterious_Run_5081", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17egh5m/which_featuresfactors_help_determine_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17egh5m/which_featuresfactors_help_determine_the/", "subreddit_subscribers": 1095888, "created_utc": 1698054033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "# A real-world case study of performance optimization in Numpy\n\nThis is a relatively brief article. In it, I will use a real-world scenario as an example to explain how to use [Numexpr expressions](https://numexpr.readthedocs.io/en/latest/user_guide.html?ref=dataleadsfuture.com#supported-functions) in multidimensional Numpy arrays to achieve substantial performance improvements.\n\nThere aren't many articles explaining how to use Numexpr in multidimensional Numpy arrays and how to use Numexpr expressions, so I hope this one will help you.\n\n# Introduction\n\nRecently, while reviewing some of my old work, I stumbled upon this piece of code:\n\n    def predict(X, w, b):\n        z = np.dot(X, w)\n        y_hat = sigmoid(z)\n        y_pred = np.zeros((y_hat.shape[0], 1))\n    \n        for i in range(y_hat.shape[0]):\n            if y_hat[i, 0] &lt; 0.5:\n                y_pred[i, 0] = 0\n            else:\n                y_pred[i, 0] = 1\n        return y_pred\n\n This code transforms prediction results from probabilities to classification results of 0 or 1 in the logistic regression model of machine learning. \n\n But heavens, who would use a `for loop` to iterate over Numpy ndarray? \n\n You can foresee that when the data reaches a certain amount, it will not only occupy a lot of memory, but the performance will also be inferior. \n\n That's right, the person who wrote this code was me when I was younger. \n\n With a sense of responsibility, I plan to rewrite this code with the Numexpr library today. \n\n Along the way, I will show you how to use Numexpr and Numexpr's `where` expression in multidimensional Numpy arrays to achieve significant performance improvements. \n\n## Code Implementation\n\n If you are not familiar with the basic usage of Numexpr, you can refer to this article: \n\n[https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/](https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/)\n\n This article uses a real-world example to demonstrate the specific usage of Numexpr's API and expressions in Numpy and Pandas. \n\n*where(bool, number1, number2): number* *- number1 if the bool condition is true, number2 otherwise.* \n\n The above is the usage of the where expression in Numpy. \n\n When dealing with matrix data, you may used to using Pandas `DataFrame`. But since the `eval` method of Pandas does not support the `where` expression, you can only choose to use Numexpr in multidimensional Numpy ndarray. \n\n Don't worry, I'll explain it to you right away. \n\n Before starting, we need to import the necessary packages and implement a `generate_ndarray` method to generate a specific size ndarray for testing: \n\n    from typing import Callable\n    import time\n    \n    import numpy as np\n    import numexpr as ne\n    import matplotlib.pyplot as plt\n    \n    rng = np.random.default_rng(seed=4000)\n    \n    def generate_ndarray(rows: int) -&gt; np.ndarray:\n        result_array = rng.random((rows, 1))\n        return result_array\n\n First, we generate a matrix of 200 rows to see if it is the test data we want: \n\n    In:  arr = generate_ndarray(200)\n         print(f\"The dimension of this array: {arr.ndim}\")\n         print(f\"The shape of this array: {arr.shape}\")\n    \n    \n    Out: The dimension of this array: 2\n         The shape of this array: (200, 1)\n\n To be close to the actual situation of the logistic regression model, we generate an ndarray of the shape `(200, 1)` Of course, you can also test other shapes of ndarray according to your needs. \n\n Then, we start writing the specific use of Numexpr in the `numexpr_to_binary` method: \n\n* First, we use the index to separate the columns that need to be processed.\n* Then, use the where expression of Numexpr to process the values.\n* Finally, merge the processed columns with other columns to generate the required results.\n\n Since the ndarray's shape here is `(200, 1)`, there is only one column, so I add a new dimension. \n\n The code is as follows: \n\n    def numexpr_to_binary(np_array: np.ndarray) -&gt; np.ndarray:\n        temp = np_array[:, 0]\n        temp = ne.evaluate(\"where(temp&lt;0.5, 0, 1)\")\n        return temp[:, np.newaxis]\n\n We can test the result with an array of 10 rows to see if it is what I want: \n\n    arr = generate_ndarray(10)\n    result = numexpr_to_binary(arr)\n    \n    mapping = np.column_stack((arr, result))\n    mapping\n\n[ I test an array of 10 rows and the result is what I want. Image by Author ](https://preview.redd.it/o1h5bwdn8xvb1.png?width=351&amp;format=png&amp;auto=webp&amp;s=d6977cc422be66a8c37980554c1478e76d2d326c)\n\n Look, the match is correct. Our task is completed. \n\n The entire process can be demonstrated with the following figure: \n\n&amp;#x200B;\n\n[ The entire process of how Numexpr transforms the multidimensional ndarray. Image by Author ](https://preview.redd.it/aw26lp8q8xvb1.png?width=915&amp;format=png&amp;auto=webp&amp;s=df44481e44b2dc48b3acd522b51327b9030e2335)\n\n## Performance Comparison\n\n After the code implementation, we need to compare the Numexpr implementation version with the previous `for each` implementation version to confirm that there has been a performance improvement. \n\n First, we implement a `numexpr_example` method. This method is based on the implementation of Numexpr: \n\n    def numexpr_example(rows: int) -&gt; np.ndarray:\n        orig_arr = generate_ndarray(rows)\n        the_result = numexpr_to_binary(orig_arr)\n        return the_result\n\n Then, we need to supplement a `for_loop_example` method. This method refers to the original code I need to rewrite and is used as a performance benchmark: \n\n    def for_loop_example(rows: int) -&gt; np.ndarray:\n        the_arr = generate_ndarray(rows)\n        for i in range(the_arr.shape[0]):\n            if the_arr[i][0] &lt; 0.5:\n                the_arr[i][0] = 0\n            else:\n                the_arr[i][0] = 1\n        return the_arr\n\n Then, I wrote a test method `time_method`. This method will generate data from 10 to 10 to the 9th power rows separately, call the corresponding method, and finally save the time required for different data amounts: \n\n    def time_method(method: Callable):\n        time_dict = dict()\n        for i in range(9):\n            begin = time.perf_counter()\n            rows = 10 ** i\n            method(rows)\n            end = time.perf_counter()\n            time_dict[i] = end - begin\n        return time_dict\n\n We test the numexpr version and the `for_loop` version separately, and use `matplotlib` to draw the time required for different amounts of data: \n\n    t_m = time_method(for_loop_example)\n    t_m_2 = time_method(numexpr_example)\n    plt.plot(t_m.keys(), t_m.values(), c=\"red\", linestyle=\"solid\")\n    plt.plot(t_m_2.keys(), t_m_2.values(), c=\"green\", linestyle=\"dashed\")\n    plt.legend([\"for loop\", \"numexpr\"])\n    plt.xlabel(\"exponent\")\n    plt.ylabel(\"time\")\n    plt.show()\n\n[ The Numexpr version of the implementation has a huge performance improvement. Image by Author ](https://preview.redd.it/i5trs6h79xvb1.png?width=595&amp;format=png&amp;auto=webp&amp;s=d508bddb500f8065c75921c1905f14e414ccf932)\n\n It can be seen that when the number of rows of data is greater than 10 to the 6th power, the Numexpr version of the implementation has a huge performance improvement. \n\n## Conclusion\n\n After explaining the basic usage of Numexpr in the previous article, this article uses a specific example in actual work to explain how to use Numexpr to rewrite existing code to obtain performance improvement. \n\n This article mainly uses two features of Numexpr:\n\n1. Numexpr allows calculations to be performed in a vectorized manner.\n2. During the calculation of Numexpr, no new arrays will be generated, thereby significantly reducing memory usage.\n\n Thank you for reading. If you have other solutions, please feel free to leave a message and discuss them with me. \n\n This article was originally published on my personal blog [Data Leads Future](https://www.dataleadsfuture.com/how-to-optimize-multidimensional-numpy-array-operations-with-numexpr/). ", "author_fullname": "t2_9r8ft2a0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Optimize Multidimensional Numpy Array Operations with Numexpr", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 94, "top_awarded_type": null, "hide_score": true, "media_metadata": {"i5trs6h79xvb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 78, "x": 108, "u": "https://preview.redd.it/i5trs6h79xvb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c265d077c76d74f45c5cb125f9355561a7f5e03b"}, {"y": 156, "x": 216, "u": "https://preview.redd.it/i5trs6h79xvb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=543d74bdf357b325082cbe4cb60187df5cd783c0"}, {"y": 231, "x": 320, "u": "https://preview.redd.it/i5trs6h79xvb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ed7c629584bc9b778eb0e7d678bb40a828d31a2f"}], "s": {"y": 430, "x": 595, "u": "https://preview.redd.it/i5trs6h79xvb1.png?width=595&amp;format=png&amp;auto=webp&amp;s=d508bddb500f8065c75921c1905f14e414ccf932"}, "id": "i5trs6h79xvb1"}, "aw26lp8q8xvb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 82, "x": 108, "u": "https://preview.redd.it/aw26lp8q8xvb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=82706ba0390facc4e733375417b45445f7c662a1"}, {"y": 165, "x": 216, "u": "https://preview.redd.it/aw26lp8q8xvb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=22228f5dad76a4b48ca4e453156a2901bb54b88e"}, {"y": 245, "x": 320, "u": "https://preview.redd.it/aw26lp8q8xvb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4e786249aa06a8e8f13a6a851ec5fe5987fe8eac"}, {"y": 490, "x": 640, "u": "https://preview.redd.it/aw26lp8q8xvb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=e8af89b6cbada268340bfd9195964ebdbf23bd67"}], "s": {"y": 701, "x": 915, "u": "https://preview.redd.it/aw26lp8q8xvb1.png?width=915&amp;format=png&amp;auto=webp&amp;s=df44481e44b2dc48b3acd522b51327b9030e2335"}, "id": "aw26lp8q8xvb1"}, "o1h5bwdn8xvb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 73, "x": 108, "u": "https://preview.redd.it/o1h5bwdn8xvb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=c4122e67f9a4134bc9caf07a853c9778f36b525c"}, {"y": 146, "x": 216, "u": "https://preview.redd.it/o1h5bwdn8xvb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d2086eaad1fc13fb23f5e326b05ba6d0b3a44da"}, {"y": 216, "x": 320, "u": "https://preview.redd.it/o1h5bwdn8xvb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb3d5913b3730778257fc3e0713c166604658b00"}], "s": {"y": 238, "x": 351, "u": "https://preview.redd.it/o1h5bwdn8xvb1.png?width=351&amp;format=png&amp;auto=webp&amp;s=d6977cc422be66a8c37980554c1478e76d2d326c"}, "id": "o1h5bwdn8xvb1"}}, "name": "t3_17egeux", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Coding", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/o70WJFqPqI6EUdOVwwXJ14JChf95JAzmiSS-05ekfcg.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698053752.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;h1&gt;A real-world case study of performance optimization in Numpy&lt;/h1&gt;\n\n&lt;p&gt;This is a relatively brief article. In it, I will use a real-world scenario as an example to explain how to use &lt;a href=\"https://numexpr.readthedocs.io/en/latest/user_guide.html?ref=dataleadsfuture.com#supported-functions\"&gt;Numexpr expressions&lt;/a&gt; in multidimensional Numpy arrays to achieve substantial performance improvements.&lt;/p&gt;\n\n&lt;p&gt;There aren&amp;#39;t many articles explaining how to use Numexpr in multidimensional Numpy arrays and how to use Numexpr expressions, so I hope this one will help you.&lt;/p&gt;\n\n&lt;h1&gt;Introduction&lt;/h1&gt;\n\n&lt;p&gt;Recently, while reviewing some of my old work, I stumbled upon this piece of code:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def predict(X, w, b):\n    z = np.dot(X, w)\n    y_hat = sigmoid(z)\n    y_pred = np.zeros((y_hat.shape[0], 1))\n\n    for i in range(y_hat.shape[0]):\n        if y_hat[i, 0] &amp;lt; 0.5:\n            y_pred[i, 0] = 0\n        else:\n            y_pred[i, 0] = 1\n    return y_pred\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This code transforms prediction results from probabilities to classification results of 0 or 1 in the logistic regression model of machine learning. &lt;/p&gt;\n\n&lt;p&gt;But heavens, who would use a &lt;code&gt;for loop&lt;/code&gt; to iterate over Numpy ndarray? &lt;/p&gt;\n\n&lt;p&gt;You can foresee that when the data reaches a certain amount, it will not only occupy a lot of memory, but the performance will also be inferior. &lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s right, the person who wrote this code was me when I was younger. &lt;/p&gt;\n\n&lt;p&gt;With a sense of responsibility, I plan to rewrite this code with the Numexpr library today. &lt;/p&gt;\n\n&lt;p&gt;Along the way, I will show you how to use Numexpr and Numexpr&amp;#39;s &lt;code&gt;where&lt;/code&gt; expression in multidimensional Numpy arrays to achieve significant performance improvements. &lt;/p&gt;\n\n&lt;h2&gt;Code Implementation&lt;/h2&gt;\n\n&lt;p&gt;If you are not familiar with the basic usage of Numexpr, you can refer to this article: &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/\"&gt;https://www.dataleadsfuture.com/exploring-numexpr-a-powerful-engine-behind-pandas/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This article uses a real-world example to demonstrate the specific usage of Numexpr&amp;#39;s API and expressions in Numpy and Pandas. &lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;where(bool, number1, number2): number&lt;/em&gt; &lt;em&gt;- number1 if the bool condition is true, number2 otherwise.&lt;/em&gt; &lt;/p&gt;\n\n&lt;p&gt;The above is the usage of the where expression in Numpy. &lt;/p&gt;\n\n&lt;p&gt;When dealing with matrix data, you may used to using Pandas &lt;code&gt;DataFrame&lt;/code&gt;. But since the &lt;code&gt;eval&lt;/code&gt; method of Pandas does not support the &lt;code&gt;where&lt;/code&gt; expression, you can only choose to use Numexpr in multidimensional Numpy ndarray. &lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t worry, I&amp;#39;ll explain it to you right away. &lt;/p&gt;\n\n&lt;p&gt;Before starting, we need to import the necessary packages and implement a &lt;code&gt;generate_ndarray&lt;/code&gt; method to generate a specific size ndarray for testing: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from typing import Callable\nimport time\n\nimport numpy as np\nimport numexpr as ne\nimport matplotlib.pyplot as plt\n\nrng = np.random.default_rng(seed=4000)\n\ndef generate_ndarray(rows: int) -&amp;gt; np.ndarray:\n    result_array = rng.random((rows, 1))\n    return result_array\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;First, we generate a matrix of 200 rows to see if it is the test data we want: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;In:  arr = generate_ndarray(200)\n     print(f&amp;quot;The dimension of this array: {arr.ndim}&amp;quot;)\n     print(f&amp;quot;The shape of this array: {arr.shape}&amp;quot;)\n\n\nOut: The dimension of this array: 2\n     The shape of this array: (200, 1)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;To be close to the actual situation of the logistic regression model, we generate an ndarray of the shape &lt;code&gt;(200, 1)&lt;/code&gt; Of course, you can also test other shapes of ndarray according to your needs. &lt;/p&gt;\n\n&lt;p&gt;Then, we start writing the specific use of Numexpr in the &lt;code&gt;numexpr_to_binary&lt;/code&gt; method: &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;First, we use the index to separate the columns that need to be processed.&lt;/li&gt;\n&lt;li&gt;Then, use the where expression of Numexpr to process the values.&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Finally, merge the processed columns with other columns to generate the required results.&lt;/p&gt;\n\n&lt;p&gt;Since the ndarray&amp;#39;s shape here is &lt;code&gt;(200, 1)&lt;/code&gt;, there is only one column, so I add a new dimension. &lt;/p&gt;\n\n&lt;p&gt;The code is as follows: &lt;/p&gt;\n\n&lt;p&gt;def numexpr_to_binary(np_array: np.ndarray) -&amp;gt; np.ndarray:\n    temp = np_array[:, 0]\n    temp = ne.evaluate(&amp;quot;where(temp&amp;lt;0.5, 0, 1)&amp;quot;)\n    return temp[:, np.newaxis]&lt;/p&gt;\n\n&lt;p&gt;We can test the result with an array of 10 rows to see if it is what I want: &lt;/p&gt;\n\n&lt;p&gt;arr = generate_ndarray(10)\nresult = numexpr_to_binary(arr)&lt;/p&gt;\n\n&lt;p&gt;mapping = np.column_stack((arr, result))\nmapping&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/o1h5bwdn8xvb1.png?width=351&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d6977cc422be66a8c37980554c1478e76d2d326c\"&gt; I test an array of 10 rows and the result is what I want. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Look, the match is correct. Our task is completed. &lt;/p&gt;\n\n&lt;p&gt;The entire process can be demonstrated with the following figure: &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/aw26lp8q8xvb1.png?width=915&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=df44481e44b2dc48b3acd522b51327b9030e2335\"&gt; The entire process of how Numexpr transforms the multidimensional ndarray. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;h2&gt;Performance Comparison&lt;/h2&gt;\n\n&lt;p&gt;After the code implementation, we need to compare the Numexpr implementation version with the previous &lt;code&gt;for each&lt;/code&gt; implementation version to confirm that there has been a performance improvement. &lt;/p&gt;\n\n&lt;p&gt;First, we implement a &lt;code&gt;numexpr_example&lt;/code&gt; method. This method is based on the implementation of Numexpr: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def numexpr_example(rows: int) -&amp;gt; np.ndarray:\n    orig_arr = generate_ndarray(rows)\n    the_result = numexpr_to_binary(orig_arr)\n    return the_result\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then, we need to supplement a &lt;code&gt;for_loop_example&lt;/code&gt; method. This method refers to the original code I need to rewrite and is used as a performance benchmark: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def for_loop_example(rows: int) -&amp;gt; np.ndarray:\n    the_arr = generate_ndarray(rows)\n    for i in range(the_arr.shape[0]):\n        if the_arr[i][0] &amp;lt; 0.5:\n            the_arr[i][0] = 0\n        else:\n            the_arr[i][0] = 1\n    return the_arr\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Then, I wrote a test method &lt;code&gt;time_method&lt;/code&gt;. This method will generate data from 10 to 10 to the 9th power rows separately, call the corresponding method, and finally save the time required for different data amounts: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;def time_method(method: Callable):\n    time_dict = dict()\n    for i in range(9):\n        begin = time.perf_counter()\n        rows = 10 ** i\n        method(rows)\n        end = time.perf_counter()\n        time_dict[i] = end - begin\n    return time_dict\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;We test the numexpr version and the &lt;code&gt;for_loop&lt;/code&gt; version separately, and use &lt;code&gt;matplotlib&lt;/code&gt; to draw the time required for different amounts of data: &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;t_m = time_method(for_loop_example)\nt_m_2 = time_method(numexpr_example)\nplt.plot(t_m.keys(), t_m.values(), c=&amp;quot;red&amp;quot;, linestyle=&amp;quot;solid&amp;quot;)\nplt.plot(t_m_2.keys(), t_m_2.values(), c=&amp;quot;green&amp;quot;, linestyle=&amp;quot;dashed&amp;quot;)\nplt.legend([&amp;quot;for loop&amp;quot;, &amp;quot;numexpr&amp;quot;])\nplt.xlabel(&amp;quot;exponent&amp;quot;)\nplt.ylabel(&amp;quot;time&amp;quot;)\nplt.show()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/i5trs6h79xvb1.png?width=595&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=d508bddb500f8065c75921c1905f14e414ccf932\"&gt; The Numexpr version of the implementation has a huge performance improvement. Image by Author &lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It can be seen that when the number of rows of data is greater than 10 to the 6th power, the Numexpr version of the implementation has a huge performance improvement. &lt;/p&gt;\n\n&lt;h2&gt;Conclusion&lt;/h2&gt;\n\n&lt;p&gt;After explaining the basic usage of Numexpr in the previous article, this article uses a specific example in actual work to explain how to use Numexpr to rewrite existing code to obtain performance improvement. &lt;/p&gt;\n\n&lt;p&gt;This article mainly uses two features of Numexpr:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Numexpr allows calculations to be performed in a vectorized manner.&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;During the calculation of Numexpr, no new arrays will be generated, thereby significantly reducing memory usage.&lt;/p&gt;\n\n&lt;p&gt;Thank you for reading. If you have other solutions, please feel free to leave a message and discuss them with me. &lt;/p&gt;\n\n&lt;p&gt;This article was originally published on my personal blog &lt;a href=\"https://www.dataleadsfuture.com/how-to-optimize-multidimensional-numpy-array-operations-with-numexpr/\"&gt;Data Leads Future&lt;/a&gt;. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4ab9c418-70eb-11ee-8a37-4a495429ae82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17egeux", "is_robot_indexable": true, "report_reasons": null, "author": "qtalen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17egeux/how_to_optimize_multidimensional_numpy_array/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17egeux/how_to_optimize_multidimensional_numpy_array/", "subreddit_subscribers": 1095888, "created_utc": 1698053752.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\nI'm using the sentiment140 dataset from kaggle and have done average daily sentiment using Vader, nltk and textblob.\n\nIn all cases I can see a few problems:\n\n* gaps with no data (tried filling in - red)\n* a sudden drop in sentiment from 15th June\n\nHow would you go about doing a forecast on that data? What's advice can you give?", "author_fullname": "t2_p5mn5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to do a time series forecast on sentiment?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": 61, "top_awarded_type": null, "hide_score": false, "name": "t3_17ef06x", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Analysis", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/WVitn7UQ_KK50or7nZNLFexKfEsa9oqTz9ydUHoR7mU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698047310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m using the sentiment140 dataset from kaggle and have done average daily sentiment using Vader, nltk and textblob.&lt;/p&gt;\n\n&lt;p&gt;In all cases I can see a few problems:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;gaps with no data (tried filling in - red)&lt;/li&gt;\n&lt;li&gt;a sudden drop in sentiment from 15th June&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;How would you go about doing a forecast on that data? What&amp;#39;s advice can you give?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/slcxmqkgqwvb1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/slcxmqkgqwvb1.jpg?auto=webp&amp;s=92f4adefc340461d5b346528a0ac48e18272ffae", "width": 1346, "height": 590}, "resolutions": [{"url": "https://preview.redd.it/slcxmqkgqwvb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a59853d709cfaf43116abf21e4a61164807a291a", "width": 108, "height": 47}, {"url": "https://preview.redd.it/slcxmqkgqwvb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5d2ea73ee19a02bd0878210aa1d324b707583d7a", "width": 216, "height": 94}, {"url": "https://preview.redd.it/slcxmqkgqwvb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=24e7349a27d3405c3ad02c9d91a102811361898a", "width": 320, "height": 140}, {"url": "https://preview.redd.it/slcxmqkgqwvb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a83ddb812aa4c693bc4ff58e82cb30cc2fb95855", "width": 640, "height": 280}, {"url": "https://preview.redd.it/slcxmqkgqwvb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7cc0584193145d099f4cd5b55fa7f3c65e81d853", "width": 960, "height": 420}, {"url": "https://preview.redd.it/slcxmqkgqwvb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3acf9ea24d74a5f29f52ecca6fad47c7815ca8fe", "width": 1080, "height": 473}], "variants": {}, "id": "7tobCBYAmnS3TUnXCDGrbiRB9HPiDqsVsi3Gwy9VYAI"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17ef06x", "is_robot_indexable": true, "report_reasons": null, "author": "balackdynamite", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ef06x/how_to_do_a_time_series_forecast_on_sentiment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/slcxmqkgqwvb1.jpg", "subreddit_subscribers": 1095888, "created_utc": 1698047310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am studying a master\u2019s in data science and working as a \u201cjunior data scientist\u201d as my first ever job at a start up. Problem is, even though I have ended the more \u201cdata science\u201d part of my degree (ML, advanced math/statistics etc.), at work, I\u2019m working more on reporting (power bi, excel, sql). I have never built or implemented any model, except for the finals I passed like 5 months ago. Sadly, I don\u2019t remember anything from them. \n\nI\u2019m approaching 1 year in experience, and my goal is to apply for junior/entry level jobs preferably in the UK or Netherlands. However, I fear that even if I land an interview, there\u2019s no way I can make it past any of them because of the discrepency between my title and actual experience.", "author_fullname": "t2_m826ekr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Title not matching tasks, am I making it a big deal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17eeucx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698046517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am studying a master\u2019s in data science and working as a \u201cjunior data scientist\u201d as my first ever job at a start up. Problem is, even though I have ended the more \u201cdata science\u201d part of my degree (ML, advanced math/statistics etc.), at work, I\u2019m working more on reporting (power bi, excel, sql). I have never built or implemented any model, except for the finals I passed like 5 months ago. Sadly, I don\u2019t remember anything from them. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m approaching 1 year in experience, and my goal is to apply for junior/entry level jobs preferably in the UK or Netherlands. However, I fear that even if I land an interview, there\u2019s no way I can make it past any of them because of the discrepency between my title and actual experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17eeucx", "is_robot_indexable": true, "report_reasons": null, "author": "Utterizi", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17eeucx/title_not_matching_tasks_am_i_making_it_a_big_deal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17eeucx/title_not_matching_tasks_am_i_making_it_a_big_deal/", "subreddit_subscribers": 1095888, "created_utc": 1698046517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Context:** A year ago I graduated with a bachelor's degree in data science and artificial intelligence. Given what the job market requires degree-wise, I decided to embark on a master's degree. I realise that starting out with a data science bachelor's is quite unusual and rightfully so. After taking on multiple internships I noticed I was lacking some foundations in e.g. distributed systems, cloud computing or more generally well rounded SE skills.\n\nI'm just scared now that employers will overlook my bachelor's degree in data science and AI and will just consider me as a software grad (which I am technically, despite taking the AI major of my programme). Is this a career blunder as far as modern data science goes?\n\nI have a solid foundation in statistics and simulation (or mathematics more generally) because of my bachelor's.\n\nI have found that my interests lie more around deploying models in production or more generally infrastructure for ML systems (which is also the ground on which I made this decision).\n\nWould you consider that as a career blunder?\n\nThank you for your answer!\n\nCheers, ", "author_fullname": "t2_161fpq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I went from a bachelor's in data science and Artificial intelligence to a master's in computer science. Is that a career blunder for Data Science and ML?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17eebwt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698044256.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt; A year ago I graduated with a bachelor&amp;#39;s degree in data science and artificial intelligence. Given what the job market requires degree-wise, I decided to embark on a master&amp;#39;s degree. I realise that starting out with a data science bachelor&amp;#39;s is quite unusual and rightfully so. After taking on multiple internships I noticed I was lacking some foundations in e.g. distributed systems, cloud computing or more generally well rounded SE skills.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just scared now that employers will overlook my bachelor&amp;#39;s degree in data science and AI and will just consider me as a software grad (which I am technically, despite taking the AI major of my programme). Is this a career blunder as far as modern data science goes?&lt;/p&gt;\n\n&lt;p&gt;I have a solid foundation in statistics and simulation (or mathematics more generally) because of my bachelor&amp;#39;s.&lt;/p&gt;\n\n&lt;p&gt;I have found that my interests lie more around deploying models in production or more generally infrastructure for ML systems (which is also the ground on which I made this decision).&lt;/p&gt;\n\n&lt;p&gt;Would you consider that as a career blunder?&lt;/p&gt;\n\n&lt;p&gt;Thank you for your answer!&lt;/p&gt;\n\n&lt;p&gt;Cheers, &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17eebwt", "is_robot_indexable": true, "report_reasons": null, "author": "Inquation", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17eebwt/i_went_from_a_bachelors_in_data_science_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17eebwt/i_went_from_a_bachelors_in_data_science_and/", "subreddit_subscribers": 1095888, "created_utc": 1698044256.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello together. I (M24) am studying Finance and I had a course in data science last semester. I really enjoyed and I know that I want to work in that area in my career.\n\nBut I am not sure if the standards I learn are enough to be successful. I basically just no R and I am learning Python right now. And at this point I kind of feel like I am not good enough in finance, because I am focusing on data science, but I am also not good enough at what I want to do, because others who studied computer science are much better then me. \n\nSo right now I am thinking about starting computer science after I am done with finance (with 25 then). Would it make sense or do you think I should maybe just continue to educate myself by myself or is a good knowledge in finance and a good knowledge in data science maybe even better?\n\n(I am not a native speaker btw, don\u2019t judge it)", "author_fullname": "t2_c00h03za", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Career in computer science after finance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ee6ao", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698043562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello together. I (M24) am studying Finance and I had a course in data science last semester. I really enjoyed and I know that I want to work in that area in my career.&lt;/p&gt;\n\n&lt;p&gt;But I am not sure if the standards I learn are enough to be successful. I basically just no R and I am learning Python right now. And at this point I kind of feel like I am not good enough in finance, because I am focusing on data science, but I am also not good enough at what I want to do, because others who studied computer science are much better then me. &lt;/p&gt;\n\n&lt;p&gt;So right now I am thinking about starting computer science after I am done with finance (with 25 then). Would it make sense or do you think I should maybe just continue to educate myself by myself or is a good knowledge in finance and a good knowledge in data science maybe even better?&lt;/p&gt;\n\n&lt;p&gt;(I am not a native speaker btw, don\u2019t judge it)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17ee6ao", "is_robot_indexable": true, "report_reasons": null, "author": "DeutschlandHooligan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ee6ao/career_in_computer_science_after_finance/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ee6ao/career_in_computer_science_after_finance/", "subreddit_subscribers": 1095888, "created_utc": 1698043562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a question for data science enthusiasts who love football: is there a way to scrape data from FPL? Do they provide an API or does this niche community( data X football) follow any best practices for doing it?\nNot really aware of FPLs data privacy and governance laws. If it's against those laws, then please do let me know.\nP.S I would love to collaborate with anyone interested and nuanced in football-data analytics.", "author_fullname": "t2_eo907yrs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scraping data from FPL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ed4tn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698039061.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a question for data science enthusiasts who love football: is there a way to scrape data from FPL? Do they provide an API or does this niche community( data X football) follow any best practices for doing it?\nNot really aware of FPLs data privacy and governance laws. If it&amp;#39;s against those laws, then please do let me know.\nP.S I would love to collaborate with anyone interested and nuanced in football-data analytics.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "17ed4tn", "is_robot_indexable": true, "report_reasons": null, "author": "avg_ali", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ed4tn/scraping_data_from_fpl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ed4tn/scraping_data_from_fpl/", "subreddit_subscribers": 1095888, "created_utc": 1698039061.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 23 Oct, 2023 - 30 Oct, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "fun", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17eboh0", "quarantine": false, "link_flair_text_color": null, "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698033686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "b026063c-d780-11e7-aba9-0e030591a4b4", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17eboh0", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17eboh0/weekly_entering_transitioning_thread_23_oct_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/17eboh0/weekly_entering_transitioning_thread_23_oct_2023/", "subreddit_subscribers": 1095888, "created_utc": 1698033686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "After completing my Ph.D. and a short postdoc, I've recently begun applying for jobs in data science.\n\nI would greatly appreciate your feedback on my CV, as I've faced three consecutive rejections for positions in data science and machine learning engineering so far. Constructive feedback is invaluable to me at this stage. Please give your feedback.  \nHere is my cv link: [https://ibb.co/F64KRjv](https://ibb.co/F64KRjv)  \nThank you!", "author_fullname": "t2_98ytn9l8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17egkrg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698054495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;After completing my Ph.D. and a short postdoc, I&amp;#39;ve recently begun applying for jobs in data science.&lt;/p&gt;\n\n&lt;p&gt;I would greatly appreciate your feedback on my CV, as I&amp;#39;ve faced three consecutive rejections for positions in data science and machine learning engineering so far. Constructive feedback is invaluable to me at this stage. Please give your feedback.&lt;br/&gt;\nHere is my cv link: &lt;a href=\"https://ibb.co/F64KRjv\"&gt;https://ibb.co/F64KRjv&lt;/a&gt;&lt;br/&gt;\nThank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DOpk4q3_iJyjAgz2H2TP35na-FtGjzni_IpkqOidFpQ.jpg?auto=webp&amp;s=2cf79f1f0b69a85ed375cfec8f50027915386540", "width": 1836, "height": 4752}, "resolutions": [{"url": "https://external-preview.redd.it/DOpk4q3_iJyjAgz2H2TP35na-FtGjzni_IpkqOidFpQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c8e1afa361360340ce2c6c962a2e82a075b802ef", "width": 108, "height": 216}, {"url": "https://external-preview.redd.it/DOpk4q3_iJyjAgz2H2TP35na-FtGjzni_IpkqOidFpQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bb8e77f19d54a24795af45fe0ec521b979a37fd3", "width": 216, "height": 432}, {"url": "https://external-preview.redd.it/DOpk4q3_iJyjAgz2H2TP35na-FtGjzni_IpkqOidFpQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c184fe556545baa395a45b05bfec2f97be81630a", "width": 320, "height": 640}, {"url": "https://external-preview.redd.it/DOpk4q3_iJyjAgz2H2TP35na-FtGjzni_IpkqOidFpQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=015bf0ced6a5144dfe163f7ebf4ff58ac3654403", "width": 640, "height": 1280}, {"url": "https://external-preview.redd.it/DOpk4q3_iJyjAgz2H2TP35na-FtGjzni_IpkqOidFpQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8fcd9c57f7755c4583f7f161cd0f55d1a3a732cc", "width": 960, "height": 1920}, {"url": "https://external-preview.redd.it/DOpk4q3_iJyjAgz2H2TP35na-FtGjzni_IpkqOidFpQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ddd468375ff59f166a09caf44242b711bfa4e41e", "width": 1080, "height": 2160}], "variants": {}, "id": "e4FNncJT7XkFKSU_eYflMI0VbKLha-PLYw8CQm5hJbs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#1a1a1b", "id": "17egkrg", "is_robot_indexable": true, "report_reasons": null, "author": "stardust901", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17egkrg/need_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17egkrg/need_help/", "subreddit_subscribers": 1095888, "created_utc": 1698054495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Like I am working in a startup and from what I have heard , mongodb should be used only when we want pictures or videos to store , so as long as the data is in text SQL works fine too . \nSo the question is how different No SQL is from SQL . Like can anyone give me an idea how to get started and they use mongodb for analytical task ?", "author_fullname": "t2_b5ou545yj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey guys how is mongodb for analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ebi8s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tools", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698033083.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Like I am working in a startup and from what I have heard , mongodb should be used only when we want pictures or videos to store , so as long as the data is in text SQL works fine too . \nSo the question is how different No SQL is from SQL . Like can anyone give me an idea how to get started and they use mongodb for analytical task ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#a06324", "id": "17ebi8s", "is_robot_indexable": true, "report_reasons": null, "author": "charlesowo445", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ebi8s/hey_guys_how_is_mongodb_for_analytics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ebi8s/hey_guys_how_is_mongodb_for_analytics/", "subreddit_subscribers": 1095888, "created_utc": 1698033083.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello everyone, this is my first post here. I am currently in second year pursuing ai and data science as an undergraduate degree. I am currently working on a student complaint dashboard using Power bi. I was thinking of collecting the data through google form using various questionnaire to provide to my classmates and then performing ETL on it in power bi. \nBut i am having trouble regarding the questions that would provide me with valuable insights.\nSo far i have categorised the complaints in category for example:-\n1) hostel/mess\n2) infrastructure\n3) fee\netc\nAnd then i would further ask questions regarding hygiene of the mess for ex and then provide a rating for their answer.\n\nWhat measures/ questions should i incorporate to draw some good insights from this?", "author_fullname": "t2_c7nlscew", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project help regarding dashboard", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ebaha", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698032328.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, this is my first post here. I am currently in second year pursuing ai and data science as an undergraduate degree. I am currently working on a student complaint dashboard using Power bi. I was thinking of collecting the data through google form using various questionnaire to provide to my classmates and then performing ETL on it in power bi. \nBut i am having trouble regarding the questions that would provide me with valuable insights.\nSo far i have categorised the complaints in category for example:-\n1) hostel/mess\n2) infrastructure\n3) fee\netc\nAnd then i would further ask questions regarding hygiene of the mess for ex and then provide a rating for their answer.&lt;/p&gt;\n\n&lt;p&gt;What measures/ questions should i incorporate to draw some good insights from this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#7193ff", "id": "17ebaha", "is_robot_indexable": true, "report_reasons": null, "author": "Lazy_Telephone6759", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ebaha/project_help_regarding_dashboard/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ebaha/project_help_regarding_dashboard/", "subreddit_subscribers": 1095888, "created_utc": 1698032328.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}