{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What makes an effective portfolio project and how can the impact of doing them improve? We read a lot in this and other subs about doing projects to get a job, but I think there are a lot of misconceptions out there. Can we discuss projects? What has worked for you? What hasn't? Where am I wrong? \n\nCommon misconceptions:\n\n* Hiring managers will look at your projects. Yes, occasionally someone has looked at my projects, but it is rare. Most aren't interested. The bigger value is the knowledge you gain and your ability to discuss technical challenges you have solved. Being able to say things like \"CSV to BigQuery, how many bad characters did you have to filter out?\" or \"On-prem Spark? How long did it take to tune the settings?\" Little things that demonstrate experience. \n\n* Doing tutorials counts as a project. Sure, you may have outputs from the tutorials, but you don't have the right inputs. No design. No decision making. Few challenges. Projects should be your own work built through your own struggle. Anyone looking can tell if your \"project\" is just a tutorial you completed. \n\n*  A great Github account full of repos is a good portfolio. Sure, once you get to a fellow geek involved with hiring, they may look at your Github page. But, that is too far along in the hiring process. Even if you have good outputs in a reporting tool or web site, they may never get more than cursory glances. LinkedIn is your portfolio. Companies find you on LinkedIn. \n\nWhat makes a better project?\n\n1.  Find a problem (real or made up) and solve it with data. Automate ingestion, modeling and business logic using the tools you want to learn. Focus on using docs and Google, but feel free to do short tutorials as needed to learn something. Make sure you do the project on your own. \n\n2. Use data you care about. Can't say this applies to everyone, but I learn better when I have a reason to do the work. It could be part of my job or just a topic I'm interested in. Do you like movies? Do something with IMDB or TMDB data. Sports? Music? Migration patterns of mallards? As long as you know enough to generate questions you want answered, it's good. \n\n3. Make sure your project has these components: design doc, architecture doc, data model doc, code, user documentation. Even if no one looks at these, you will get comfortable creating them. Something many experienced DEs are not. \n\n4. If you can, find a customer for your project. I don't mean a paying customer, but someone who will use the outputs of the project. Someone you can practice the fine art of sussing out requirements with. This is another skill many experienced DEs lack. A customer will also give you ideas.    \n\nHow do you find customers? Do you know any small business owners that might be interested in automated data? Can you do something in your current job? How about looking through /r/database or /r/sql for people who need data for their hobby, but aren't trying to get into data? Maybe look for web developers who are looking for help. Try to get creative.", "author_fullname": "t2_8ov8i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can we talk about portfolio projects?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17id58n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698497555.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What makes an effective portfolio project and how can the impact of doing them improve? We read a lot in this and other subs about doing projects to get a job, but I think there are a lot of misconceptions out there. Can we discuss projects? What has worked for you? What hasn&amp;#39;t? Where am I wrong? &lt;/p&gt;\n\n&lt;p&gt;Common misconceptions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Hiring managers will look at your projects. Yes, occasionally someone has looked at my projects, but it is rare. Most aren&amp;#39;t interested. The bigger value is the knowledge you gain and your ability to discuss technical challenges you have solved. Being able to say things like &amp;quot;CSV to BigQuery, how many bad characters did you have to filter out?&amp;quot; or &amp;quot;On-prem Spark? How long did it take to tune the settings?&amp;quot; Little things that demonstrate experience. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Doing tutorials counts as a project. Sure, you may have outputs from the tutorials, but you don&amp;#39;t have the right inputs. No design. No decision making. Few challenges. Projects should be your own work built through your own struggle. Anyone looking can tell if your &amp;quot;project&amp;quot; is just a tutorial you completed. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A great Github account full of repos is a good portfolio. Sure, once you get to a fellow geek involved with hiring, they may look at your Github page. But, that is too far along in the hiring process. Even if you have good outputs in a reporting tool or web site, they may never get more than cursory glances. LinkedIn is your portfolio. Companies find you on LinkedIn. &lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What makes a better project?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Find a problem (real or made up) and solve it with data. Automate ingestion, modeling and business logic using the tools you want to learn. Focus on using docs and Google, but feel free to do short tutorials as needed to learn something. Make sure you do the project on your own. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Use data you care about. Can&amp;#39;t say this applies to everyone, but I learn better when I have a reason to do the work. It could be part of my job or just a topic I&amp;#39;m interested in. Do you like movies? Do something with IMDB or TMDB data. Sports? Music? Migration patterns of mallards? As long as you know enough to generate questions you want answered, it&amp;#39;s good. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Make sure your project has these components: design doc, architecture doc, data model doc, code, user documentation. Even if no one looks at these, you will get comfortable creating them. Something many experienced DEs are not. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;If you can, find a customer for your project. I don&amp;#39;t mean a paying customer, but someone who will use the outputs of the project. Someone you can practice the fine art of sussing out requirements with. This is another skill many experienced DEs lack. A customer will also give you ideas.    &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;How do you find customers? Do you know any small business owners that might be interested in automated data? Can you do something in your current job? How about looking through &lt;a href=\"/r/database\"&gt;/r/database&lt;/a&gt; or &lt;a href=\"/r/sql\"&gt;/r/sql&lt;/a&gt; for people who need data for their hobby, but aren&amp;#39;t trying to get into data? Maybe look for web developers who are looking for help. Try to get creative.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17id58n", "is_robot_indexable": true, "report_reasons": null, "author": "leogodin217", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17id58n/can_we_talk_about_portfolio_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17id58n/can_we_talk_about_portfolio_projects/", "subreddit_subscribers": 136638, "created_utc": 1698497555.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "title", "author_fullname": "t2_i8g7wg1n0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any ex-Software Engineers here who miss writing code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17imtpm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698526359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17imtpm", "is_robot_indexable": true, "report_reasons": null, "author": "Large-Translator-759", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17imtpm/any_exsoftware_engineers_here_who_miss_writing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17imtpm/any_exsoftware_engineers_here_who_miss_writing/", "subreddit_subscribers": 136638, "created_utc": 1698526359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most likely it is a position that writes a lot of Airflow DAGs. Ask the team (during the panel interview or hiring manager interview) how they write DAGs. Specifically, ask them this question: \"Do you write your pipelines in a programming language (Python, C#, Java, Scala, whatever) or in YAML?\".\n\nIf the answer is \"in a programming language\", ask them whether they have a data platform team, and how does it work.\n\nBasically, be very aware of any DE job that got invaded/abstracted away by upstream data platform teams. It is good for the data platform team as they can bag nice projects for CV, and it is sometimes good for the company because a replaceable screw is a lot better than a non-replaceable one. I'm 100% fine about platform team taking over deployment or whatever, but taking over the fun of programming is absolutely No No. If it is the way it works, join the data platform team instead.\n\nThink about this: you don't want to work a couple of years and write \"I wrote a lot of YAML pipelines\" on CV. Actually, at a mid-senior level, I would never accept any position that PURELY writes SQL while the DAGs are simply a wrapper around those queries. Very bad for your career path.\n\nIn one sentence, avoid any programming jobs that doesn't actually write/read a lot of code (aside from SQL, which for sure you will write a lot).", "author_fullname": "t2_bmsha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One recommendation for whoever is applying for a DE role, especially if you want to take a technical path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17istl5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698544890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most likely it is a position that writes a lot of Airflow DAGs. Ask the team (during the panel interview or hiring manager interview) how they write DAGs. Specifically, ask them this question: &amp;quot;Do you write your pipelines in a programming language (Python, C#, Java, Scala, whatever) or in YAML?&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;If the answer is &amp;quot;in a programming language&amp;quot;, ask them whether they have a data platform team, and how does it work.&lt;/p&gt;\n\n&lt;p&gt;Basically, be very aware of any DE job that got invaded/abstracted away by upstream data platform teams. It is good for the data platform team as they can bag nice projects for CV, and it is sometimes good for the company because a replaceable screw is a lot better than a non-replaceable one. I&amp;#39;m 100% fine about platform team taking over deployment or whatever, but taking over the fun of programming is absolutely No No. If it is the way it works, join the data platform team instead.&lt;/p&gt;\n\n&lt;p&gt;Think about this: you don&amp;#39;t want to work a couple of years and write &amp;quot;I wrote a lot of YAML pipelines&amp;quot; on CV. Actually, at a mid-senior level, I would never accept any position that PURELY writes SQL while the DAGs are simply a wrapper around those queries. Very bad for your career path.&lt;/p&gt;\n\n&lt;p&gt;In one sentence, avoid any programming jobs that doesn&amp;#39;t actually write/read a lot of code (aside from SQL, which for sure you will write a lot).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17istl5", "is_robot_indexable": true, "report_reasons": null, "author": "levelworm", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17istl5/one_recommendation_for_whoever_is_applying_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17istl5/one_recommendation_for_whoever_is_applying_for_a/", "subreddit_subscribers": 136638, "created_utc": 1698544890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've inherited a project that merges and standardizes about 8 different data formats of electronic health records (EHR).  Currently, the system parses the messages into a complex nested dictionary, and then passed through a clunky set of pydantic schemas to push the data fields around before ultimately pushing the data as a large json object to a REST API for DB insertion (postgres).   \n\nI want to be clear about the use of the term \"standardizing\" here.  We are talking about unifying key names across the data object that is returned, so that any message input returns a uniform json structure as output.\n\nThis project has hit a lot of snags due to bad design and I've been asked to step in and make changes to improve.  I have fairly free reign to do whatever is necessary.\n\nThe problem is I don't have much knowledge in data architecture -- I'm more of a software engineer.  I suspect there is a far better way of doing what this system is doing, but I have no idea where to start looking.  This data is better suited for a nosql database than it is postgres, but even if we were to do that, the problem of transformation and merging is the major meat of this project. \n\nCan anyone suggest a better path or set of technologies that I can start looking at?\n\nEDIT:  just to clarify, I'm talking mostly about tech for standardizing and merging, but I'll take suggestions for any/all of it", "author_fullname": "t2_8a3p7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best architecture for data merging/standardization of multiple EHR formats?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17iof3j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698530896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve inherited a project that merges and standardizes about 8 different data formats of electronic health records (EHR).  Currently, the system parses the messages into a complex nested dictionary, and then passed through a clunky set of pydantic schemas to push the data fields around before ultimately pushing the data as a large json object to a REST API for DB insertion (postgres).   &lt;/p&gt;\n\n&lt;p&gt;I want to be clear about the use of the term &amp;quot;standardizing&amp;quot; here.  We are talking about unifying key names across the data object that is returned, so that any message input returns a uniform json structure as output.&lt;/p&gt;\n\n&lt;p&gt;This project has hit a lot of snags due to bad design and I&amp;#39;ve been asked to step in and make changes to improve.  I have fairly free reign to do whatever is necessary.&lt;/p&gt;\n\n&lt;p&gt;The problem is I don&amp;#39;t have much knowledge in data architecture -- I&amp;#39;m more of a software engineer.  I suspect there is a far better way of doing what this system is doing, but I have no idea where to start looking.  This data is better suited for a nosql database than it is postgres, but even if we were to do that, the problem of transformation and merging is the major meat of this project. &lt;/p&gt;\n\n&lt;p&gt;Can anyone suggest a better path or set of technologies that I can start looking at?&lt;/p&gt;\n\n&lt;p&gt;EDIT:  just to clarify, I&amp;#39;m talking mostly about tech for standardizing and merging, but I&amp;#39;ll take suggestions for any/all of it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17iof3j", "is_robot_indexable": true, "report_reasons": null, "author": "EmptyMargins", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17iof3j/what_is_the_best_architecture_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17iof3j/what_is_the_best_architecture_for_data/", "subreddit_subscribers": 136638, "created_utc": 1698530896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Went to a dbt meetup a few days ago and this guy from the Barcelona Supercomputing Lab presented his fully open source on-prem modern data stack. Pretty cool imo. They were working with health data from hundreds of hospitals all across EU so they couldn\u2019t use the cloud.", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great on-prem open source source modern data stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_17iyl70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ShbKYOEmDBBpeIvJxfyPxzi-mTm2Ne3XAWlNyXi8WrE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698568562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Went to a dbt meetup a few days ago and this guy from the Barcelona Supercomputing Lab presented his fully open source on-prem modern data stack. Pretty cool imo. They were working with health data from hundreds of hospitals all across EU so they couldn\u2019t use the cloud.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/bmpkp2jes3xb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?auto=webp&amp;s=efc6615578a44031ad503bd4594ff0666047671d", "width": 4032, "height": 3024}, "resolutions": [{"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=11cd215e83f2196c7c523876ce8e4c63c78aabea", "width": 108, "height": 81}, {"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6cbaef31df6a879ad5fac466f305947d8237627c", "width": 216, "height": 162}, {"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3f53f87fcb0c4c13e1466bb0569249b4fe2ff20b", "width": 320, "height": 240}, {"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d161d0cbff1ef192c1231773970bd4b0bedc1082", "width": 640, "height": 480}, {"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=27b46c3bd02cf8b574f10ed2b1d89aa38e979228", "width": 960, "height": 720}, {"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6174414c58a6620dcaf937daa3fe91a27869dc70", "width": 1080, "height": 810}], "variants": {}, "id": "Ct6fAw3tkH9nRo3I6cCjMWAXabjcSfPdpC2cmje8hFg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17iyl70", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17iyl70/great_onprem_open_source_source_modern_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/bmpkp2jes3xb1.jpg", "subreddit_subscribers": 136638, "created_utc": 1698568562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was in a data engineering class the other day and someone asked when to use a serverless compute service (like GCP Cloud Functions or AWS Lambda) instead of Apache Beam or Spark.\n\nMy initial thought is that a serverless compute service might actually be cheaper and easier for streaming workloads in some cases. I think I would opt for Apache Beam or Spark in cases where I am dealing with performance-critical sequencing of transforms.\n\nI would love to hear what others think.", "author_fullname": "t2_49jyg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serverless Options v. Beam / Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ihelf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698510564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was in a data engineering class the other day and someone asked when to use a serverless compute service (like GCP Cloud Functions or AWS Lambda) instead of Apache Beam or Spark.&lt;/p&gt;\n\n&lt;p&gt;My initial thought is that a serverless compute service might actually be cheaper and easier for streaming workloads in some cases. I think I would opt for Apache Beam or Spark in cases where I am dealing with performance-critical sequencing of transforms.&lt;/p&gt;\n\n&lt;p&gt;I would love to hear what others think.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ihelf", "is_robot_indexable": true, "report_reasons": null, "author": "ColoSean", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ihelf/serverless_options_v_beam_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ihelf/serverless_options_v_beam_spark/", "subreddit_subscribers": 136638, "created_utc": 1698510564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello Redditors,\n\nI'm currently working as a Data/BI Analyst on a contract basis and I'm looking to gain practical experience in tasks similar to those in Data Engineering. I've been mostly working on developing and maintaining Alteryx ETL workflows and Power BI dashboards for my team. Recently, I've started incorporating Python into our daily work, and now we're handling most of the ETL processes using code.\n\nI'm skilled at writing SQL queries but don't deal with databases in this role. All the information is contained in Excel files. On a weekly basis, I typically merge around 40 files from different sources, such as ServiceNow and other ERPs, to generate the data for our dashboards.\n\nMy manager, although not very technically inclined, is usually open to suggestions and new ideas. While I may not earn a lot in this job, I see an opportunity to build something here that could pave the way for a Data Engineering role in the future.\n\nCould you share some insights or suggestions? What would you do in my position? What are some tasks I could undertake without requiring significant buy-in from upper stakeholders? ", "author_fullname": "t2_emxgn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incorporating DE tasks into a BI Analyst role - Transition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ig6sd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698516418.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698507038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Redditors,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working as a Data/BI Analyst on a contract basis and I&amp;#39;m looking to gain practical experience in tasks similar to those in Data Engineering. I&amp;#39;ve been mostly working on developing and maintaining Alteryx ETL workflows and Power BI dashboards for my team. Recently, I&amp;#39;ve started incorporating Python into our daily work, and now we&amp;#39;re handling most of the ETL processes using code.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m skilled at writing SQL queries but don&amp;#39;t deal with databases in this role. All the information is contained in Excel files. On a weekly basis, I typically merge around 40 files from different sources, such as ServiceNow and other ERPs, to generate the data for our dashboards.&lt;/p&gt;\n\n&lt;p&gt;My manager, although not very technically inclined, is usually open to suggestions and new ideas. While I may not earn a lot in this job, I see an opportunity to build something here that could pave the way for a Data Engineering role in the future.&lt;/p&gt;\n\n&lt;p&gt;Could you share some insights or suggestions? What would you do in my position? What are some tasks I could undertake without requiring significant buy-in from upper stakeholders? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17ig6sd", "is_robot_indexable": true, "report_reasons": null, "author": "xloadx", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ig6sd/incorporating_de_tasks_into_a_bi_analyst_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ig6sd/incorporating_de_tasks_into_a_bi_analyst_role/", "subreddit_subscribers": 136638, "created_utc": 1698507038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I come from the MLOps-side, so I have made ETL pipelines as necessary elements, but it isn't my primary focus.  Simultaneously, the company's data engineers tend to be recent grads, so not ideal for mentoring.\n\n**I'm trying to understand why the additional overhead of Prefect/Airflow (or any other workflow orchestrator) is worth it in an event-driven, serverless ETL + ML pipeline?**\n\nIt seems I could just as easily (at least because I'm familiar with it) have an S3 trigger that fires off a series of Lambda transforms that are then ultimately consumed by a model on Fargate, which the last Lambda invokes with an API call.  With DLQs and log-based alerts, I have an element of resiliency and the team is aware if there is an issue with the alerting.  If I want batch scheduling, then I use an EventBridge alert instead.  What is Prefect/Airflow improving that offsets the need to manage and maintain it?\n\n**If it doesn't benefit these use cases, how are people using it then, as this seems like a fairly common enterprise pattern?**", "author_fullname": "t2_8ksqiw0s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Point of Prefect/Airflow in Event-Driven ETL+ML Pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17idwkw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698500025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I come from the MLOps-side, so I have made ETL pipelines as necessary elements, but it isn&amp;#39;t my primary focus.  Simultaneously, the company&amp;#39;s data engineers tend to be recent grads, so not ideal for mentoring.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I&amp;#39;m trying to understand why the additional overhead of Prefect/Airflow (or any other workflow orchestrator) is worth it in an event-driven, serverless ETL + ML pipeline?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;It seems I could just as easily (at least because I&amp;#39;m familiar with it) have an S3 trigger that fires off a series of Lambda transforms that are then ultimately consumed by a model on Fargate, which the last Lambda invokes with an API call.  With DLQs and log-based alerts, I have an element of resiliency and the team is aware if there is an issue with the alerting.  If I want batch scheduling, then I use an EventBridge alert instead.  What is Prefect/Airflow improving that offsets the need to manage and maintain it?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;If it doesn&amp;#39;t benefit these use cases, how are people using it then, as this seems like a fairly common enterprise pattern?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17idwkw", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Strain4832", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17idwkw/point_of_prefectairflow_in_eventdriven_etlml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17idwkw/point_of_prefectairflow_in_eventdriven_etlml/", "subreddit_subscribers": 136638, "created_utc": 1698500025.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m learning DBT core. At first, I was confused by how often it\u2019s referenced as a main industry tool, yet so few books exist on it (Amazon only sells 3). I bought one\u2026\n\nAfter a dedicated week doing a deep dive, and being disappointed in the book (much of the content was setup for DBT Cloud, Snowflake, and rudimentary primer of SQL), I found my self looking at the official DBT online docs. Often, a vendors documentation is an MVP for sysadmin config and structure mostly, but I\u2019ve been pretty impressed by DBTs docs.\n\nJust as much a lay (and profound at times) discourse of modern SWE principles applied to ETL, as much about how to use DBT to fulfill the concepts.\n\nI\u2019m sure many here agree and have known this for some time, but thought I\u2019d share for other in similar boats.", "author_fullname": "t2_f1kbimm96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Books", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17iuius", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698550855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m learning DBT core. At first, I was confused by how often it\u2019s referenced as a main industry tool, yet so few books exist on it (Amazon only sells 3). I bought one\u2026&lt;/p&gt;\n\n&lt;p&gt;After a dedicated week doing a deep dive, and being disappointed in the book (much of the content was setup for DBT Cloud, Snowflake, and rudimentary primer of SQL), I found my self looking at the official DBT online docs. Often, a vendors documentation is an MVP for sysadmin config and structure mostly, but I\u2019ve been pretty impressed by DBTs docs.&lt;/p&gt;\n\n&lt;p&gt;Just as much a lay (and profound at times) discourse of modern SWE principles applied to ETL, as much about how to use DBT to fulfill the concepts.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m sure many here agree and have known this for some time, but thought I\u2019d share for other in similar boats.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17iuius", "is_robot_indexable": true, "report_reasons": null, "author": "No-Database2068", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17iuius/dbt_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17iuius/dbt_books/", "subreddit_subscribers": 136638, "created_utc": 1698550855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to enter an entry level data engineer position, but the main advice I have got is to find a problem of your own and build a solution for it. Not watching a tutorial on youtube and follow it. As I was trying to find a real problem to solve, my cousin told me he had a problem with his restaurant. He started his restaurant 2 weeks ago, and is looking for a systematic way to record and preserve all the data of the restaurant, be it billing, restaurant expenses, salaries of employees and inventory stock. And he has asked me if I could help in any way. I know there are already softwares for this, and he is ready for that too, but he wants me to take care of it. I am not even looking to get paid for this, I just want a good experience for my next data job. I think this is a perfect opportunity for me to work on a data engineer project to get my first data job. So I was wondering if you guys have idea on how I could help my cousin in this situation that will help me land my first data engineer job.", "author_fullname": "t2_gwz0jems", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project for a restaurant", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17izkja", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698572964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to enter an entry level data engineer position, but the main advice I have got is to find a problem of your own and build a solution for it. Not watching a tutorial on youtube and follow it. As I was trying to find a real problem to solve, my cousin told me he had a problem with his restaurant. He started his restaurant 2 weeks ago, and is looking for a systematic way to record and preserve all the data of the restaurant, be it billing, restaurant expenses, salaries of employees and inventory stock. And he has asked me if I could help in any way. I know there are already softwares for this, and he is ready for that too, but he wants me to take care of it. I am not even looking to get paid for this, I just want a good experience for my next data job. I think this is a perfect opportunity for me to work on a data engineer project to get my first data job. So I was wondering if you guys have idea on how I could help my cousin in this situation that will help me land my first data engineer job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17izkja", "is_robot_indexable": true, "report_reasons": null, "author": "Available_Chicken510", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17izkja/project_for_a_restaurant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17izkja/project_for_a_restaurant/", "subreddit_subscribers": 136638, "created_utc": 1698572964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an interview tomorrow. \n\n1 hour management interview (in which I believe I\u2019ll be very comfortable)\nFollowed by \n1 hour tech interview (not so confident)\n\nA little about me: I have consulting experience, know SQL, R &amp; have worked on Tableau. \n\nThe role: Data Quality Lead\n\nCan send the JD in chat.", "author_fullname": "t2_bo6y7ima3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Tomorrow. Need Collibra Crash Course!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ixs5d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698564853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an interview tomorrow. &lt;/p&gt;\n\n&lt;p&gt;1 hour management interview (in which I believe I\u2019ll be very comfortable)\nFollowed by \n1 hour tech interview (not so confident)&lt;/p&gt;\n\n&lt;p&gt;A little about me: I have consulting experience, know SQL, R &amp;amp; have worked on Tableau. &lt;/p&gt;\n\n&lt;p&gt;The role: Data Quality Lead&lt;/p&gt;\n\n&lt;p&gt;Can send the JD in chat.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ixs5d", "is_robot_indexable": true, "report_reasons": null, "author": "zamonk8", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ixs5d/interview_tomorrow_need_collibra_crash_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ixs5d/interview_tomorrow_need_collibra_crash_course/", "subreddit_subscribers": 136638, "created_utc": 1698564853.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello everyone! I'm in a bit of a challenge and could seriously use your collective wisdom!\n\nI've been spinning my wheels trying to find an ETL tool that checks all the boxes for our current project. We're mainly dealing with a maelstrom of Excel files and different data layouts that we need to wrangle into MySQL and eventually visualize in Tableau. I discovered Rivery but they do not support MySQL as a target.\n\nHere's the scoop on our needs:\n\n1. **Excel Maestro:** We're talking about importing various formats (\\*.xls, \\*.xlsx, \\*.xlsm, \\*.csv). It has to smoothly handle data from specific/multiple sheets and ranges within these Excel files. We're dealing with a LOT of custom data scenarios here.\n2. **Workflow Wizardry:** The tool needs to be a powerhouse for data transformation and aggregation. We're not just moving data; we're molding it like it's data Play-Doh.\n3. **Repeat with a Twist:** Here's the kicker - we want to save complete ETL workflows (since the data layout often stays the same), but we need the flexibility to duplicate and tinker with the ETL process for those pesky outlier files with unique layouts.\n4. **Quality Control:** We can't afford slip-ups, so data validation and quality checks are a must. Garbage in, garbage out, right?\n5. **MySQL &amp; Tableau Friendly:** Our target database is MySQL, and all this data needs to be prim and proper for some serious Tableau action.\n6. **No Clouds, Please:** SAAS solutions are off the table. We're looking for something we can host locally/self-host, or even a robust desktop application.\n7. **Web Interface Love:** A browser-based user interface would be the cherry on top for ease of use across the team.\n\nHas anyone faced a similar challenge or used a tool that meets these needs? I'm hoping for something that doesn't require a PhD to operate but is still powerful enough to handle our complex requirements.\n\nPlease bombard me with your recommendations! If you've got tales of triumph or woe with certain tools, I'm all ears.", "author_fullname": "t2_e5ga8nya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Desperately Need Help Finding an ETL Tool for Complex Excel Data Workflows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17io0ue", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698529749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! I&amp;#39;m in a bit of a challenge and could seriously use your collective wisdom!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been spinning my wheels trying to find an ETL tool that checks all the boxes for our current project. We&amp;#39;re mainly dealing with a maelstrom of Excel files and different data layouts that we need to wrangle into MySQL and eventually visualize in Tableau. I discovered Rivery but they do not support MySQL as a target.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the scoop on our needs:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Excel Maestro:&lt;/strong&gt; We&amp;#39;re talking about importing various formats (*.xls, *.xlsx, *.xlsm, *.csv). It has to smoothly handle data from specific/multiple sheets and ranges within these Excel files. We&amp;#39;re dealing with a LOT of custom data scenarios here.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Workflow Wizardry:&lt;/strong&gt; The tool needs to be a powerhouse for data transformation and aggregation. We&amp;#39;re not just moving data; we&amp;#39;re molding it like it&amp;#39;s data Play-Doh.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Repeat with a Twist:&lt;/strong&gt; Here&amp;#39;s the kicker - we want to save complete ETL workflows (since the data layout often stays the same), but we need the flexibility to duplicate and tinker with the ETL process for those pesky outlier files with unique layouts.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Quality Control:&lt;/strong&gt; We can&amp;#39;t afford slip-ups, so data validation and quality checks are a must. Garbage in, garbage out, right?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;MySQL &amp;amp; Tableau Friendly:&lt;/strong&gt; Our target database is MySQL, and all this data needs to be prim and proper for some serious Tableau action.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;No Clouds, Please:&lt;/strong&gt; SAAS solutions are off the table. We&amp;#39;re looking for something we can host locally/self-host, or even a robust desktop application.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Web Interface Love:&lt;/strong&gt; A browser-based user interface would be the cherry on top for ease of use across the team.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Has anyone faced a similar challenge or used a tool that meets these needs? I&amp;#39;m hoping for something that doesn&amp;#39;t require a PhD to operate but is still powerful enough to handle our complex requirements.&lt;/p&gt;\n\n&lt;p&gt;Please bombard me with your recommendations! If you&amp;#39;ve got tales of triumph or woe with certain tools, I&amp;#39;m all ears.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17io0ue", "is_robot_indexable": true, "report_reasons": null, "author": "volturnalia", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17io0ue/desperately_need_help_finding_an_etl_tool_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17io0ue/desperately_need_help_finding_an_etl_tool_for/", "subreddit_subscribers": 136638, "created_utc": 1698529749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I work in a SAAS startup and have been with them for a little over 3yrs. I was hired on from a contractor role doing data entry to work on migrating client data. I was new to this and the company had not yet done much in this regard besides building a tool that actually loads the data.\n\nThat said, I dove in and started building tools to perform the E and the T processes, but due to the different formats these client\u2019s data comes in (I.e. different previous providers), there\u2019s only a little continuity in how my tools can operate. For example, our clients bring us data from their previous providers in one of: SQL server .bak files, huge json files, zips of correlated csvs, zips of correlated json files, data I collect from scraping their old platforms. \n\nThe nature of the data involves a ton of mapping, and this mapping can be different from one client to the next coming from the same previous system based on how they implemented the previous software in their business, updates to the old software, etc. \n\nI know these are typical challenges in the field, but having no prior experience and not much guidance on scaling this process, I feel my tooling/process needs re-somethinged. I\u2019m currently using a stack of (primarily) Python, SQLite, sql server (on a vm), Google sheets. There are so many moving parts, \u201cworkarounds\u201d, exceptions I have to deal with, while also considering the clients\u2019 typically tall requests. \n\nI\u2019m hoping, from this post, to gain some insight from others about what stack they use, ways to improve existing processes, anything else to possibly help preserve my sanity. I enjoy this work a lot, but I feel my lack of prior experience left me at a slight disadvantage. \n\nThanks in advance for any and all feedback, input, etc.!", "author_fullname": "t2_5am908px", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Client data migration questions and/or discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17iggeg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698507820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I work in a SAAS startup and have been with them for a little over 3yrs. I was hired on from a contractor role doing data entry to work on migrating client data. I was new to this and the company had not yet done much in this regard besides building a tool that actually loads the data.&lt;/p&gt;\n\n&lt;p&gt;That said, I dove in and started building tools to perform the E and the T processes, but due to the different formats these client\u2019s data comes in (I.e. different previous providers), there\u2019s only a little continuity in how my tools can operate. For example, our clients bring us data from their previous providers in one of: SQL server .bak files, huge json files, zips of correlated csvs, zips of correlated json files, data I collect from scraping their old platforms. &lt;/p&gt;\n\n&lt;p&gt;The nature of the data involves a ton of mapping, and this mapping can be different from one client to the next coming from the same previous system based on how they implemented the previous software in their business, updates to the old software, etc. &lt;/p&gt;\n\n&lt;p&gt;I know these are typical challenges in the field, but having no prior experience and not much guidance on scaling this process, I feel my tooling/process needs re-somethinged. I\u2019m currently using a stack of (primarily) Python, SQLite, sql server (on a vm), Google sheets. There are so many moving parts, \u201cworkarounds\u201d, exceptions I have to deal with, while also considering the clients\u2019 typically tall requests. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m hoping, from this post, to gain some insight from others about what stack they use, ways to improve existing processes, anything else to possibly help preserve my sanity. I enjoy this work a lot, but I feel my lack of prior experience left me at a slight disadvantage. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any and all feedback, input, etc.!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17iggeg", "is_robot_indexable": true, "report_reasons": null, "author": "iambatmanman", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17iggeg/client_data_migration_questions_andor_discussion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17iggeg/client_data_migration_questions_andor_discussion/", "subreddit_subscribers": 136638, "created_utc": 1698507820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone used language models for cleaning data? I'm thinking about using a small language model to clean and standardize property records. What models did you try/are using? What kind of prompting do you have?", "author_fullname": "t2_10z7c3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "language models for data cleaning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ipv7s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698535237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone used language models for cleaning data? I&amp;#39;m thinking about using a small language model to clean and standardize property records. What models did you try/are using? What kind of prompting do you have?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ipv7s", "is_robot_indexable": true, "report_reasons": null, "author": "tantanchen", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ipv7s/language_models_for_data_cleaning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ipv7s/language_models_for_data_cleaning/", "subreddit_subscribers": 136638, "created_utc": 1698535237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a common pattern for sharing data across a bunch of EC2 instances processing data in Python where they would need immediate responses? I'm new to DE so there may just be an obvious answer or total issue with my current approach, but I feel like there has to be a way to handle this kind of scenario.\n\nI have a bunch of EC2 instances transforming data from JSON to parquet and then write the resulting parquet files to S3. There's data that associates a some subset of users with a website that they've posted to\n\n    {\n      \"users\": [\n        {\n          \"groupid\": 1,\n          \"ids\": [1, 2, 3, 4],\n          \"website\": 'A'\n        },\n        {\n          \"groupid\": 2,\n          \"ids\": [1, 2],\n          \"website\": 'B'\n        },\n        {\n          \"groupid\": 3,\n          \"ids\": [4, 5, 6],\n          \"website\": 'C'\n        },\n      ]\n    }\n\nRight now the \"groupid\" would apply only to the data in that JSON file, however this would cause billions of duplicated rows in the resulting parquet files. If I wanted to give these user groups a unique identifier across all of the files/servers doing the transformations, what are some options for accomplishing that?\n\nI've experimented with the servers reading and writing to a DynamoDB instance or Redis cache whenever they find a group of ids associated with a website for the first time (i.e. the key would be \"web:C#ids:4,5,6\" and would point to a new custom ID), but those both seem to have pretty substantial impacts on the performance of the transformations. Is there some other option besides fundamentally redesigning the pipeline?  \n\n\nEdit: Maybe a separate post-processing script that runs at the end?", "author_fullname": "t2_sgbjn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to share data across distributed servers doing transformation in ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ih2km", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698511255.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698509583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a common pattern for sharing data across a bunch of EC2 instances processing data in Python where they would need immediate responses? I&amp;#39;m new to DE so there may just be an obvious answer or total issue with my current approach, but I feel like there has to be a way to handle this kind of scenario.&lt;/p&gt;\n\n&lt;p&gt;I have a bunch of EC2 instances transforming data from JSON to parquet and then write the resulting parquet files to S3. There&amp;#39;s data that associates a some subset of users with a website that they&amp;#39;ve posted to&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n  &amp;quot;users&amp;quot;: [\n    {\n      &amp;quot;groupid&amp;quot;: 1,\n      &amp;quot;ids&amp;quot;: [1, 2, 3, 4],\n      &amp;quot;website&amp;quot;: &amp;#39;A&amp;#39;\n    },\n    {\n      &amp;quot;groupid&amp;quot;: 2,\n      &amp;quot;ids&amp;quot;: [1, 2],\n      &amp;quot;website&amp;quot;: &amp;#39;B&amp;#39;\n    },\n    {\n      &amp;quot;groupid&amp;quot;: 3,\n      &amp;quot;ids&amp;quot;: [4, 5, 6],\n      &amp;quot;website&amp;quot;: &amp;#39;C&amp;#39;\n    },\n  ]\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Right now the &amp;quot;groupid&amp;quot; would apply only to the data in that JSON file, however this would cause billions of duplicated rows in the resulting parquet files. If I wanted to give these user groups a unique identifier across all of the files/servers doing the transformations, what are some options for accomplishing that?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve experimented with the servers reading and writing to a DynamoDB instance or Redis cache whenever they find a group of ids associated with a website for the first time (i.e. the key would be &amp;quot;web:C#ids:4,5,6&amp;quot; and would point to a new custom ID), but those both seem to have pretty substantial impacts on the performance of the transformations. Is there some other option besides fundamentally redesigning the pipeline?  &lt;/p&gt;\n\n&lt;p&gt;Edit: Maybe a separate post-processing script that runs at the end?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ih2km", "is_robot_indexable": true, "report_reasons": null, "author": "IamSerenity", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ih2km/how_to_share_data_across_distributed_servers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ih2km/how_to_share_data_across_distributed_servers/", "subreddit_subscribers": 136638, "created_utc": 1698509583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nCurrently, I'm holding a position as a Project Analyst at a retail company. I am currently at 11 months. I graduated in 2022 with an English BA. In current my role, I frequently engage in tasks that require creating conditions through Agile Methodologies, troubleshooting our software product, collaborating with business teams to iron out functional issues, designing dashboards using SQL and Power Query, and occasionally dabbling with light python scripts. \n\nI'm enrolling in WGU for a Computer Science degree this coming November with aspirations to complete my studies in roughly a year and a half (I came in with a BA Degree and completed 50% of my degree). My primary goal at WGU has always been to transition into a junior data engineering position. But recently, I received a job offer for a DevOps engineer position from a startup. The offer presents a 10k salary hike from my current 60k.\n\nTo give you all a snapshot of my personal backdrop: I'm currently without kids, have a wonderful girlfriend, and have 2 cats. My commute, at the moment, is about 30 minutes. The new role would add an 10-minute stretch to that. Additionally, I'd lose one day of remote working (currently have 2), though I'm hopeful this could change in time.\n\nGiven my aspirations in data engineering, this sudden opportunity in DevOps has me at a crossroads. While I recognize it as a potential avenue for growth and a fresh learning experience, I'm wrestling with the decision and am not so sure.\n\nI'd truly appreciate any insights, especially from those who've ventured into DevOps or from those rooted in data engineering and data science roles. What's your take on this?\n\nThank you so much in advance for your thoughts and shared experiences!", "author_fullname": "t2_vafm3k96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prospective Career Change", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17id4at", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698497460.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Currently, I&amp;#39;m holding a position as a Project Analyst at a retail company. I am currently at 11 months. I graduated in 2022 with an English BA. In current my role, I frequently engage in tasks that require creating conditions through Agile Methodologies, troubleshooting our software product, collaborating with business teams to iron out functional issues, designing dashboards using SQL and Power Query, and occasionally dabbling with light python scripts. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m enrolling in WGU for a Computer Science degree this coming November with aspirations to complete my studies in roughly a year and a half (I came in with a BA Degree and completed 50% of my degree). My primary goal at WGU has always been to transition into a junior data engineering position. But recently, I received a job offer for a DevOps engineer position from a startup. The offer presents a 10k salary hike from my current 60k.&lt;/p&gt;\n\n&lt;p&gt;To give you all a snapshot of my personal backdrop: I&amp;#39;m currently without kids, have a wonderful girlfriend, and have 2 cats. My commute, at the moment, is about 30 minutes. The new role would add an 10-minute stretch to that. Additionally, I&amp;#39;d lose one day of remote working (currently have 2), though I&amp;#39;m hopeful this could change in time.&lt;/p&gt;\n\n&lt;p&gt;Given my aspirations in data engineering, this sudden opportunity in DevOps has me at a crossroads. While I recognize it as a potential avenue for growth and a fresh learning experience, I&amp;#39;m wrestling with the decision and am not so sure.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d truly appreciate any insights, especially from those who&amp;#39;ve ventured into DevOps or from those rooted in data engineering and data science roles. What&amp;#39;s your take on this?&lt;/p&gt;\n\n&lt;p&gt;Thank you so much in advance for your thoughts and shared experiences!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17id4at", "is_robot_indexable": true, "report_reasons": null, "author": "mexicaprogrammer", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17id4at/prospective_career_change/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17id4at/prospective_career_change/", "subreddit_subscribers": 136638, "created_utc": 1698497460.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say I encounter an error with one of the rows in the file. I'm wondering what the best approach is in this situation:\n\n1. Should I load the records without error and isolate the record with the error?\n2. Or should I fail the entire load of the file?\n\nI would appreciate any insights or experiences you have on this topic. Thank you!", "author_fullname": "t2_mbbdv7y98", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Handling rows with errors in CSV files", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17id054", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698497057.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say I encounter an error with one of the rows in the file. I&amp;#39;m wondering what the best approach is in this situation:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Should I load the records without error and isolate the record with the error?&lt;/li&gt;\n&lt;li&gt;Or should I fail the entire load of the file?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I would appreciate any insights or experiences you have on this topic. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17id054", "is_robot_indexable": true, "report_reasons": null, "author": "Kindly-Screen-2557", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17id054/handling_rows_with_errors_in_csv_files/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17id054/handling_rows_with_errors_in_csv_files/", "subreddit_subscribers": 136638, "created_utc": 1698497057.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}