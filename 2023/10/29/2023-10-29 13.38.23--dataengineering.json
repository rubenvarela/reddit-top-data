{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Went to a dbt meetup a few days ago and this guy from the Barcelona Supercomputing Lab presented his fully open source on-prem modern data stack. Pretty cool imo. They were working with health data from hundreds of hospitals all across EU so they couldn\u2019t use the cloud.", "author_fullname": "t2_4s2dogl9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great on-prem open source source modern data stack", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_17iyl70", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/ShbKYOEmDBBpeIvJxfyPxzi-mTm2Ne3XAWlNyXi8WrE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698568562.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Went to a dbt meetup a few days ago and this guy from the Barcelona Supercomputing Lab presented his fully open source on-prem modern data stack. Pretty cool imo. They were working with health data from hundreds of hospitals all across EU so they couldn\u2019t use the cloud.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/bmpkp2jes3xb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?auto=webp&amp;s=efc6615578a44031ad503bd4594ff0666047671d", "width": 4032, "height": 3024}, "resolutions": [{"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=11cd215e83f2196c7c523876ce8e4c63c78aabea", "width": 108, "height": 81}, {"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6cbaef31df6a879ad5fac466f305947d8237627c", "width": 216, "height": 162}, {"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3f53f87fcb0c4c13e1466bb0569249b4fe2ff20b", "width": 320, "height": 240}, {"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d161d0cbff1ef192c1231773970bd4b0bedc1082", "width": 640, "height": 480}, {"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=27b46c3bd02cf8b574f10ed2b1d89aa38e979228", "width": 960, "height": 720}, {"url": "https://preview.redd.it/bmpkp2jes3xb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6174414c58a6620dcaf937daa3fe91a27869dc70", "width": 1080, "height": 810}], "variants": {}, "id": "Ct6fAw3tkH9nRo3I6cCjMWAXabjcSfPdpC2cmje8hFg"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17iyl70", "is_robot_indexable": true, "report_reasons": null, "author": "rudboi12", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17iyl70/great_onprem_open_source_source_modern_data_stack/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/bmpkp2jes3xb1.jpg", "subreddit_subscribers": 136662, "created_utc": 1698568562.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most likely it is a position that writes a lot of Airflow DAGs. Ask the team (during the panel interview or hiring manager interview) how they write DAGs. Specifically, ask them this question: \"Do you write your pipelines in a programming language (Python, C#, Java, Scala, whatever) or in YAML?\".\n\nIf the answer is \"in a programming language\", ask them whether they have a data platform team, and how does it work.\n\nBasically, be very aware of any DE job that got invaded/abstracted away by upstream data platform teams. It is good for the data platform team as they can bag nice projects for CV, and it is sometimes good for the company because a replaceable screw is a lot better than a non-replaceable one. I'm 100% fine about platform team taking over deployment or whatever, but taking over the fun of programming is absolutely No No. If it is the way it works, join the data platform team instead.\n\nThink about this: you don't want to work a couple of years and write \"I wrote a lot of YAML pipelines\" on CV. Actually, at a mid-senior level, I would never accept any position that PURELY writes SQL while the DAGs are simply a wrapper around those queries. Very bad for your career path.\n\nIn one sentence, avoid any programming jobs that doesn't actually write/read a lot of code (aside from SQL, which for sure you will write a lot).", "author_fullname": "t2_bmsha", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "One recommendation for whoever is applying for a DE role, especially if you want to take a technical path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17istl5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698544890.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most likely it is a position that writes a lot of Airflow DAGs. Ask the team (during the panel interview or hiring manager interview) how they write DAGs. Specifically, ask them this question: &amp;quot;Do you write your pipelines in a programming language (Python, C#, Java, Scala, whatever) or in YAML?&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;If the answer is &amp;quot;in a programming language&amp;quot;, ask them whether they have a data platform team, and how does it work.&lt;/p&gt;\n\n&lt;p&gt;Basically, be very aware of any DE job that got invaded/abstracted away by upstream data platform teams. It is good for the data platform team as they can bag nice projects for CV, and it is sometimes good for the company because a replaceable screw is a lot better than a non-replaceable one. I&amp;#39;m 100% fine about platform team taking over deployment or whatever, but taking over the fun of programming is absolutely No No. If it is the way it works, join the data platform team instead.&lt;/p&gt;\n\n&lt;p&gt;Think about this: you don&amp;#39;t want to work a couple of years and write &amp;quot;I wrote a lot of YAML pipelines&amp;quot; on CV. Actually, at a mid-senior level, I would never accept any position that PURELY writes SQL while the DAGs are simply a wrapper around those queries. Very bad for your career path.&lt;/p&gt;\n\n&lt;p&gt;In one sentence, avoid any programming jobs that doesn&amp;#39;t actually write/read a lot of code (aside from SQL, which for sure you will write a lot).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17istl5", "is_robot_indexable": true, "report_reasons": null, "author": "levelworm", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17istl5/one_recommendation_for_whoever_is_applying_for_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17istl5/one_recommendation_for_whoever_is_applying_for_a/", "subreddit_subscribers": 136662, "created_utc": 1698544890.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "title", "author_fullname": "t2_i8g7wg1n0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any ex-Software Engineers here who miss writing code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17imtpm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698526359.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;title&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17imtpm", "is_robot_indexable": true, "report_reasons": null, "author": "Large-Translator-759", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17imtpm/any_exsoftware_engineers_here_who_miss_writing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17imtpm/any_exsoftware_engineers_here_who_miss_writing/", "subreddit_subscribers": 136662, "created_utc": 1698526359.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've inherited a project that merges and standardizes about 8 different data formats of electronic health records (EHR).  Currently, the system parses the messages into a complex nested dictionary, and then passed through a clunky set of pydantic schemas to push the data fields around before ultimately pushing the data as a large json object to a REST API for DB insertion (postgres).   \n\nI want to be clear about the use of the term \"standardizing\" here.  We are talking about unifying key names across the data object that is returned, so that any message input returns a uniform json structure as output.\n\nThis project has hit a lot of snags due to bad design and I've been asked to step in and make changes to improve.  I have fairly free reign to do whatever is necessary.\n\nThe problem is I don't have much knowledge in data architecture -- I'm more of a software engineer.  I suspect there is a far better way of doing what this system is doing, but I have no idea where to start looking.  This data is better suited for a nosql database than it is postgres, but even if we were to do that, the problem of transformation and merging is the major meat of this project. \n\nCan anyone suggest a better path or set of technologies that I can start looking at?\n\nEDIT:  just to clarify, I'm talking mostly about tech for standardizing and merging, but I'll take suggestions for any/all of it", "author_fullname": "t2_8a3p7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best architecture for data merging/standardization of multiple EHR formats?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17iof3j", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698530896.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve inherited a project that merges and standardizes about 8 different data formats of electronic health records (EHR).  Currently, the system parses the messages into a complex nested dictionary, and then passed through a clunky set of pydantic schemas to push the data fields around before ultimately pushing the data as a large json object to a REST API for DB insertion (postgres).   &lt;/p&gt;\n\n&lt;p&gt;I want to be clear about the use of the term &amp;quot;standardizing&amp;quot; here.  We are talking about unifying key names across the data object that is returned, so that any message input returns a uniform json structure as output.&lt;/p&gt;\n\n&lt;p&gt;This project has hit a lot of snags due to bad design and I&amp;#39;ve been asked to step in and make changes to improve.  I have fairly free reign to do whatever is necessary.&lt;/p&gt;\n\n&lt;p&gt;The problem is I don&amp;#39;t have much knowledge in data architecture -- I&amp;#39;m more of a software engineer.  I suspect there is a far better way of doing what this system is doing, but I have no idea where to start looking.  This data is better suited for a nosql database than it is postgres, but even if we were to do that, the problem of transformation and merging is the major meat of this project. &lt;/p&gt;\n\n&lt;p&gt;Can anyone suggest a better path or set of technologies that I can start looking at?&lt;/p&gt;\n\n&lt;p&gt;EDIT:  just to clarify, I&amp;#39;m talking mostly about tech for standardizing and merging, but I&amp;#39;ll take suggestions for any/all of it&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17iof3j", "is_robot_indexable": true, "report_reasons": null, "author": "EmptyMargins", "discussion_type": null, "num_comments": 12, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17iof3j/what_is_the_best_architecture_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17iof3j/what_is_the_best_architecture_for_data/", "subreddit_subscribers": 136662, "created_utc": 1698530896.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I got an offer for a job but the project is very difficult. This is not a problem for me. I am used to work in migrations but this project looks like another thing.\n\nOriginal database is a relational database with 10+ year old and without good documentation. Is sensible data so they provide it to us anonymized. There are more than 1000 tables, and the schema I suppose is very \"snowflake\" style and highly normalized, because the database is optimized for transactions.\n\nThe project consist in migrating the database to a new schema, that integrates some of the data. All the data from the original database must be moved to the new schema, and this process has to happen smoothly and quickly (the downtime cannot be long and data integrity cannot be lost). So the team must understand the whole original database without much documentation, must understand the new schema and must develop an ETL process from the old database to new database that runs quickly and does not lose any data. \n\nI find it a very hard challenge, migrating relational databases is a pain in the ass, but adding the \"speed\" needed, deprecated technologies and no documentation make me thing it is a project designed to fail.\n\nThey're desperate and paying large sums of money (they will x2 my salary). I have experience with migrations, but nothing as large and sensible as this one.\n\nWhat do you think? Good opportunity or project that will fail?", "author_fullname": "t2_247d5tdk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how difficult is a project like this? huge migration of relational database", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17j0t6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698578323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I got an offer for a job but the project is very difficult. This is not a problem for me. I am used to work in migrations but this project looks like another thing.&lt;/p&gt;\n\n&lt;p&gt;Original database is a relational database with 10+ year old and without good documentation. Is sensible data so they provide it to us anonymized. There are more than 1000 tables, and the schema I suppose is very &amp;quot;snowflake&amp;quot; style and highly normalized, because the database is optimized for transactions.&lt;/p&gt;\n\n&lt;p&gt;The project consist in migrating the database to a new schema, that integrates some of the data. All the data from the original database must be moved to the new schema, and this process has to happen smoothly and quickly (the downtime cannot be long and data integrity cannot be lost). So the team must understand the whole original database without much documentation, must understand the new schema and must develop an ETL process from the old database to new database that runs quickly and does not lose any data. &lt;/p&gt;\n\n&lt;p&gt;I find it a very hard challenge, migrating relational databases is a pain in the ass, but adding the &amp;quot;speed&amp;quot; needed, deprecated technologies and no documentation make me thing it is a project designed to fail.&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;re desperate and paying large sums of money (they will x2 my salary). I have experience with migrations, but nothing as large and sensible as this one.&lt;/p&gt;\n\n&lt;p&gt;What do you think? Good opportunity or project that will fail?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17j0t6p", "is_robot_indexable": true, "report_reasons": null, "author": "CardGameFanboy", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17j0t6p/how_difficult_is_a_project_like_this_huge/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17j0t6p/how_difficult_is_a_project_like_this_huge/", "subreddit_subscribers": 136662, "created_utc": 1698578323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was in a data engineering class the other day and someone asked when to use a serverless compute service (like GCP Cloud Functions or AWS Lambda) instead of Apache Beam or Spark.\n\nMy initial thought is that a serverless compute service might actually be cheaper and easier for streaming workloads in some cases. I think I would opt for Apache Beam or Spark in cases where I am dealing with performance-critical sequencing of transforms.\n\nI would love to hear what others think.", "author_fullname": "t2_49jyg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serverless Options v. Beam / Spark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ihelf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698510564.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was in a data engineering class the other day and someone asked when to use a serverless compute service (like GCP Cloud Functions or AWS Lambda) instead of Apache Beam or Spark.&lt;/p&gt;\n\n&lt;p&gt;My initial thought is that a serverless compute service might actually be cheaper and easier for streaming workloads in some cases. I think I would opt for Apache Beam or Spark in cases where I am dealing with performance-critical sequencing of transforms.&lt;/p&gt;\n\n&lt;p&gt;I would love to hear what others think.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ihelf", "is_robot_indexable": true, "report_reasons": null, "author": "ColoSean", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ihelf/serverless_options_v_beam_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ihelf/serverless_options_v_beam_spark/", "subreddit_subscribers": 136662, "created_utc": 1698510564.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello Redditors,\n\nI'm currently working as a Data/BI Analyst on a contract basis and I'm looking to gain practical experience in tasks similar to those in Data Engineering. I've been mostly working on developing and maintaining Alteryx ETL workflows and Power BI dashboards for my team. Recently, I've started incorporating Python into our daily work, and now we're handling most of the ETL processes using code.\n\nI'm skilled at writing SQL queries but don't deal with databases in this role. All the information is contained in Excel files. On a weekly basis, I typically merge around 40 files from different sources, such as ServiceNow and other ERPs, to generate the data for our dashboards.\n\nMy manager, although not very technically inclined, is usually open to suggestions and new ideas. While I may not earn a lot in this job, I see an opportunity to build something here that could pave the way for a Data Engineering role in the future.\n\nCould you share some insights or suggestions? What would you do in my position? What are some tasks I could undertake without requiring significant buy-in from upper stakeholders? ", "author_fullname": "t2_emxgn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Incorporating DE tasks into a BI Analyst role - Transition", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ig6sd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698516418.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698507038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Redditors,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently working as a Data/BI Analyst on a contract basis and I&amp;#39;m looking to gain practical experience in tasks similar to those in Data Engineering. I&amp;#39;ve been mostly working on developing and maintaining Alteryx ETL workflows and Power BI dashboards for my team. Recently, I&amp;#39;ve started incorporating Python into our daily work, and now we&amp;#39;re handling most of the ETL processes using code.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m skilled at writing SQL queries but don&amp;#39;t deal with databases in this role. All the information is contained in Excel files. On a weekly basis, I typically merge around 40 files from different sources, such as ServiceNow and other ERPs, to generate the data for our dashboards.&lt;/p&gt;\n\n&lt;p&gt;My manager, although not very technically inclined, is usually open to suggestions and new ideas. While I may not earn a lot in this job, I see an opportunity to build something here that could pave the way for a Data Engineering role in the future.&lt;/p&gt;\n\n&lt;p&gt;Could you share some insights or suggestions? What would you do in my position? What are some tasks I could undertake without requiring significant buy-in from upper stakeholders? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17ig6sd", "is_robot_indexable": true, "report_reasons": null, "author": "xloadx", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ig6sd/incorporating_de_tasks_into_a_bi_analyst_role/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ig6sd/incorporating_de_tasks_into_a_bi_analyst_role/", "subreddit_subscribers": 136662, "created_utc": 1698507038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I come from the MLOps-side, so I have made ETL pipelines as necessary elements, but it isn't my primary focus.  Simultaneously, the company's data engineers tend to be recent grads, so not ideal for mentoring.\n\n**I'm trying to understand why the additional overhead of Prefect/Airflow (or any other workflow orchestrator) is worth it in an event-driven, serverless ETL + ML pipeline?**\n\nIt seems I could just as easily (at least because I'm familiar with it) have an S3 trigger that fires off a series of Lambda transforms that are then ultimately consumed by a model on Fargate, which the last Lambda invokes with an API call.  With DLQs and log-based alerts, I have an element of resiliency and the team is aware if there is an issue with the alerting.  If I want batch scheduling, then I use an EventBridge alert instead.  What is Prefect/Airflow improving that offsets the need to manage and maintain it?\n\n**If it doesn't benefit these use cases, how are people using it then, as this seems like a fairly common enterprise pattern?**", "author_fullname": "t2_8ksqiw0s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Point of Prefect/Airflow in Event-Driven ETL+ML Pipeline?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17idwkw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698500025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I come from the MLOps-side, so I have made ETL pipelines as necessary elements, but it isn&amp;#39;t my primary focus.  Simultaneously, the company&amp;#39;s data engineers tend to be recent grads, so not ideal for mentoring.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I&amp;#39;m trying to understand why the additional overhead of Prefect/Airflow (or any other workflow orchestrator) is worth it in an event-driven, serverless ETL + ML pipeline?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;It seems I could just as easily (at least because I&amp;#39;m familiar with it) have an S3 trigger that fires off a series of Lambda transforms that are then ultimately consumed by a model on Fargate, which the last Lambda invokes with an API call.  With DLQs and log-based alerts, I have an element of resiliency and the team is aware if there is an issue with the alerting.  If I want batch scheduling, then I use an EventBridge alert instead.  What is Prefect/Airflow improving that offsets the need to manage and maintain it?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;If it doesn&amp;#39;t benefit these use cases, how are people using it then, as this seems like a fairly common enterprise pattern?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17idwkw", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Strain4832", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17idwkw/point_of_prefectairflow_in_eventdriven_etlml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17idwkw/point_of_prefectairflow_in_eventdriven_etlml/", "subreddit_subscribers": 136662, "created_utc": 1698500025.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am trying to enter an entry level data engineer position, but the main advice I have got is to find a problem of your own and build a solution for it. Not watching a tutorial on youtube and follow it. As I was trying to find a real problem to solve, my cousin told me he had a problem with his restaurant. He started his restaurant 2 weeks ago, and is looking for a systematic way to record and preserve all the data of the restaurant, be it billing, restaurant expenses, salaries of employees and inventory stock. And he has asked me if I could help in any way. I know there are already softwares for this, and he is ready for that too, but he wants me to take care of it. I am not even looking to get paid for this, I just want a good experience for my next data job. I think this is a perfect opportunity for me to work on a data engineer project to get my first data job. So I was wondering if you guys have idea on how I could help my cousin in this situation that will help me land my first data engineer job.", "author_fullname": "t2_gwz0jems", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project for a restaurant", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17izkja", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698572964.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to enter an entry level data engineer position, but the main advice I have got is to find a problem of your own and build a solution for it. Not watching a tutorial on youtube and follow it. As I was trying to find a real problem to solve, my cousin told me he had a problem with his restaurant. He started his restaurant 2 weeks ago, and is looking for a systematic way to record and preserve all the data of the restaurant, be it billing, restaurant expenses, salaries of employees and inventory stock. And he has asked me if I could help in any way. I know there are already softwares for this, and he is ready for that too, but he wants me to take care of it. I am not even looking to get paid for this, I just want a good experience for my next data job. I think this is a perfect opportunity for me to work on a data engineer project to get my first data job. So I was wondering if you guys have idea on how I could help my cousin in this situation that will help me land my first data engineer job.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17izkja", "is_robot_indexable": true, "report_reasons": null, "author": "Available_Chicken510", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17izkja/project_for_a_restaurant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17izkja/project_for_a_restaurant/", "subreddit_subscribers": 136662, "created_utc": 1698572964.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m learning DBT core. At first, I was confused by how often it\u2019s referenced as a main industry tool, yet so few books exist on it (Amazon only sells 3). I bought one\u2026\n\nAfter a dedicated week doing a deep dive, and being disappointed in the book (much of the content was setup for DBT Cloud, Snowflake, and rudimentary primer of SQL), I found my self looking at the official DBT online docs. Often, a vendors documentation is an MVP for sysadmin config and structure mostly, but I\u2019ve been pretty impressed by DBTs docs.\n\nJust as much a lay (and profound at times) discourse of modern SWE principles applied to ETL, as much about how to use DBT to fulfill the concepts.\n\nI\u2019m sure many here agree and have known this for some time, but thought I\u2019d share for other in similar boats.", "author_fullname": "t2_f1kbimm96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Books", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17iuius", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698550855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m learning DBT core. At first, I was confused by how often it\u2019s referenced as a main industry tool, yet so few books exist on it (Amazon only sells 3). I bought one\u2026&lt;/p&gt;\n\n&lt;p&gt;After a dedicated week doing a deep dive, and being disappointed in the book (much of the content was setup for DBT Cloud, Snowflake, and rudimentary primer of SQL), I found my self looking at the official DBT online docs. Often, a vendors documentation is an MVP for sysadmin config and structure mostly, but I\u2019ve been pretty impressed by DBTs docs.&lt;/p&gt;\n\n&lt;p&gt;Just as much a lay (and profound at times) discourse of modern SWE principles applied to ETL, as much about how to use DBT to fulfill the concepts.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m sure many here agree and have known this for some time, but thought I\u2019d share for other in similar boats.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17iuius", "is_robot_indexable": true, "report_reasons": null, "author": "No-Database2068", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17iuius/dbt_books/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17iuius/dbt_books/", "subreddit_subscribers": 136662, "created_utc": 1698550855.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am diving deep into the intricate realms of \"Business Intelligence, Semantic Layer, Modern OLAP, and Data Virtualization.\" Despite their distinct purposes, they often gravitate towards overlapping goals. Here's a brief breakdown:\n\n* **Business Intelligence Dashboard/Report**: The cockpit for businesses! At its core, it offers a simplified overview, a unified source of truth, drill-down capabilities, and empowers every user to analyze data.\n* **Semantic Layer**: Picture it as the bridge between raw data and business users. This translation layer brings clarity by converting complex data structures into digestible business concepts. It had its roots in 1991, but in 2021, it saw its resurgence with tools like MetriQL, Minerva, and Cube.\n* **Modern OLAP Systems**: The next-gen analytics powerhouses, like Druid and ClickHouse, thrive by handling business logic at query time. They\u2019re designed for real-time, multidimensional business data analysis, offering sub-second, predefined responses to user queries.\n* **Data Virtualizations/Data Federation**: It\u2019s about accessing multiple data sources seamlessly, without duplication. Virtualization ensures data accessibility without the hassles of copying or movement. Yet, one must be wary of potential challenges, like data inconsistency and real-time query interferences.\n\n[Evolution of the different terms over time.](https://preview.redd.it/zfhrz64a05xb1.jpg?width=1446&amp;format=pjpg&amp;auto=webp&amp;s=1d7cf265ad024f5d62f1f409f5a7eb27823155d9)\n\nBut what ties all these together? Common patterns emerge:\n\n1. **Visualization/Business Focus**: Making data meaningful for business decisions.\n2. **Translation/Abstraction**: Layering data structures into relatable business terms, often through SQL or YAML.\n3. **Speed and Efficiency**: Rapid and reliable data processing.\n4. **Single Source of Truth**: Unwavering emphasis on data consistency.\n5. **Metrics and KPIs**: The cornerstone of each evolution's value.\n\nLastly, `Ad-hoc Querying` and `Caching` are two pivotal patterns that underline the importance of dynamic query flexibility and rapid data retrieval.\n\nRemember, as technology evolves, so do our tools and methodologies. Keeping a pulse on these evolutions ensures we always leverage the best for our business insights.\n\nFor those of you who've been in the field for a while, have you worked with multiple paradigms throughout your career? How have you navigated the evolution of tools and methodologies, and what insights or advice would you offer to those grappling with these transitions today?", "author_fullname": "t2_84xrtbqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Navigating the Shifts in Data Engineering: From Business Intelligence to Modern OLAP and Data Virtualization - How Have You Adapted?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 86, "top_awarded_type": null, "hide_score": true, "media_metadata": {"zfhrz64a05xb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 66, "x": 108, "u": "https://preview.redd.it/zfhrz64a05xb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3a3f6a31055b8e0b21bfb97fbb69cdf009c6afd1"}, {"y": 132, "x": 216, "u": "https://preview.redd.it/zfhrz64a05xb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f2c21644c34532e5eb52557e9d63003a5346ef29"}, {"y": 196, "x": 320, "u": "https://preview.redd.it/zfhrz64a05xb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=52a6ed62a255d917ec5c96fb7067fda0c03b9595"}, {"y": 393, "x": 640, "u": "https://preview.redd.it/zfhrz64a05xb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=69eaee1e54cc9c060816b4e8a78d4d35ca551f99"}, {"y": 590, "x": 960, "u": "https://preview.redd.it/zfhrz64a05xb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f4d19b6158e0e5d769ae42aebfb60c0db538f67b"}, {"y": 664, "x": 1080, "u": "https://preview.redd.it/zfhrz64a05xb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=52b4d7e8913c04059af2cbade95de1d189a7dbf1"}], "s": {"y": 890, "x": 1446, "u": "https://preview.redd.it/zfhrz64a05xb1.jpg?width=1446&amp;format=pjpg&amp;auto=webp&amp;s=1d7cf265ad024f5d62f1f409f5a7eb27823155d9"}, "id": "zfhrz64a05xb1"}}, "name": "t3_17j24fr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/CVBCfcHv_le_WUWKFXpOhrSrMjUdQ22tf0u6VA0Oe1w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698583351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am diving deep into the intricate realms of &amp;quot;Business Intelligence, Semantic Layer, Modern OLAP, and Data Virtualization.&amp;quot; Despite their distinct purposes, they often gravitate towards overlapping goals. Here&amp;#39;s a brief breakdown:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Business Intelligence Dashboard/Report&lt;/strong&gt;: The cockpit for businesses! At its core, it offers a simplified overview, a unified source of truth, drill-down capabilities, and empowers every user to analyze data.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Semantic Layer&lt;/strong&gt;: Picture it as the bridge between raw data and business users. This translation layer brings clarity by converting complex data structures into digestible business concepts. It had its roots in 1991, but in 2021, it saw its resurgence with tools like MetriQL, Minerva, and Cube.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Modern OLAP Systems&lt;/strong&gt;: The next-gen analytics powerhouses, like Druid and ClickHouse, thrive by handling business logic at query time. They\u2019re designed for real-time, multidimensional business data analysis, offering sub-second, predefined responses to user queries.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Data Virtualizations/Data Federation&lt;/strong&gt;: It\u2019s about accessing multiple data sources seamlessly, without duplication. Virtualization ensures data accessibility without the hassles of copying or movement. Yet, one must be wary of potential challenges, like data inconsistency and real-time query interferences.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/zfhrz64a05xb1.jpg?width=1446&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=1d7cf265ad024f5d62f1f409f5a7eb27823155d9\"&gt;Evolution of the different terms over time.&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But what ties all these together? Common patterns emerge:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Visualization/Business Focus&lt;/strong&gt;: Making data meaningful for business decisions.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Translation/Abstraction&lt;/strong&gt;: Layering data structures into relatable business terms, often through SQL or YAML.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Speed and Efficiency&lt;/strong&gt;: Rapid and reliable data processing.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Single Source of Truth&lt;/strong&gt;: Unwavering emphasis on data consistency.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Metrics and KPIs&lt;/strong&gt;: The cornerstone of each evolution&amp;#39;s value.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Lastly, &lt;code&gt;Ad-hoc Querying&lt;/code&gt; and &lt;code&gt;Caching&lt;/code&gt; are two pivotal patterns that underline the importance of dynamic query flexibility and rapid data retrieval.&lt;/p&gt;\n\n&lt;p&gt;Remember, as technology evolves, so do our tools and methodologies. Keeping a pulse on these evolutions ensures we always leverage the best for our business insights.&lt;/p&gt;\n\n&lt;p&gt;For those of you who&amp;#39;ve been in the field for a while, have you worked with multiple paradigms throughout your career? How have you navigated the evolution of tools and methodologies, and what insights or advice would you offer to those grappling with these transitions today?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17j24fr", "is_robot_indexable": true, "report_reasons": null, "author": "sspaeti", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17j24fr/navigating_the_shifts_in_data_engineering_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17j24fr/navigating_the_shifts_in_data_engineering_from/", "subreddit_subscribers": 136662, "created_utc": 1698583351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI'm embarking on a journey to learn Azure Data Factory and PySpark with Databricks. Can you recommend the best platform for this? I stumbled upon a course on Udemy by Ramesh Retnasamy \u2013 is it worth considering? Please share any other platforms you think are suitable.\n\nThanks!", "author_fullname": "t2_kgk078ub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Datafactory and PySpark", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17j0wmb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698578707.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m embarking on a journey to learn Azure Data Factory and PySpark with Databricks. Can you recommend the best platform for this? I stumbled upon a course on Udemy by Ramesh Retnasamy \u2013 is it worth considering? Please share any other platforms you think are suitable.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17j0wmb", "is_robot_indexable": true, "report_reasons": null, "author": "Beginning-Forever597", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17j0wmb/azure_datafactory_and_pyspark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17j0wmb/azure_datafactory_and_pyspark/", "subreddit_subscribers": 136662, "created_utc": 1698578707.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello everyone! I'm in a bit of a challenge and could seriously use your collective wisdom!\n\nI've been spinning my wheels trying to find an ETL tool that checks all the boxes for our current project. We're mainly dealing with a maelstrom of Excel files and different data layouts that we need to wrangle into MySQL and eventually visualize in Tableau. I discovered Rivery but they do not support MySQL as a target.\n\nHere's the scoop on our needs:\n\n1. **Excel Maestro:** We're talking about importing various formats (\\*.xls, \\*.xlsx, \\*.xlsm, \\*.csv). It has to smoothly handle data from specific/multiple sheets and ranges within these Excel files. We're dealing with a LOT of custom data scenarios here.\n2. **Workflow Wizardry:** The tool needs to be a powerhouse for data transformation and aggregation. We're not just moving data; we're molding it like it's data Play-Doh.\n3. **Repeat with a Twist:** Here's the kicker - we want to save complete ETL workflows (since the data layout often stays the same), but we need the flexibility to duplicate and tinker with the ETL process for those pesky outlier files with unique layouts.\n4. **Quality Control:** We can't afford slip-ups, so data validation and quality checks are a must. Garbage in, garbage out, right?\n5. **MySQL &amp; Tableau Friendly:** Our target database is MySQL, and all this data needs to be prim and proper for some serious Tableau action.\n6. **No Clouds, Please:** SAAS solutions are off the table. We're looking for something we can host locally/self-host, or even a robust desktop application.\n7. **Web Interface Love:** A browser-based user interface would be the cherry on top for ease of use across the team.\n\nHas anyone faced a similar challenge or used a tool that meets these needs? I'm hoping for something that doesn't require a PhD to operate but is still powerful enough to handle our complex requirements.\n\nPlease bombard me with your recommendations! If you've got tales of triumph or woe with certain tools, I'm all ears.", "author_fullname": "t2_e5ga8nya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Desperately Need Help Finding an ETL Tool for Complex Excel Data Workflows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17io0ue", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698529749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone! I&amp;#39;m in a bit of a challenge and could seriously use your collective wisdom!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been spinning my wheels trying to find an ETL tool that checks all the boxes for our current project. We&amp;#39;re mainly dealing with a maelstrom of Excel files and different data layouts that we need to wrangle into MySQL and eventually visualize in Tableau. I discovered Rivery but they do not support MySQL as a target.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the scoop on our needs:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Excel Maestro:&lt;/strong&gt; We&amp;#39;re talking about importing various formats (*.xls, *.xlsx, *.xlsm, *.csv). It has to smoothly handle data from specific/multiple sheets and ranges within these Excel files. We&amp;#39;re dealing with a LOT of custom data scenarios here.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Workflow Wizardry:&lt;/strong&gt; The tool needs to be a powerhouse for data transformation and aggregation. We&amp;#39;re not just moving data; we&amp;#39;re molding it like it&amp;#39;s data Play-Doh.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Repeat with a Twist:&lt;/strong&gt; Here&amp;#39;s the kicker - we want to save complete ETL workflows (since the data layout often stays the same), but we need the flexibility to duplicate and tinker with the ETL process for those pesky outlier files with unique layouts.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Quality Control:&lt;/strong&gt; We can&amp;#39;t afford slip-ups, so data validation and quality checks are a must. Garbage in, garbage out, right?&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;MySQL &amp;amp; Tableau Friendly:&lt;/strong&gt; Our target database is MySQL, and all this data needs to be prim and proper for some serious Tableau action.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;No Clouds, Please:&lt;/strong&gt; SAAS solutions are off the table. We&amp;#39;re looking for something we can host locally/self-host, or even a robust desktop application.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Web Interface Love:&lt;/strong&gt; A browser-based user interface would be the cherry on top for ease of use across the team.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Has anyone faced a similar challenge or used a tool that meets these needs? I&amp;#39;m hoping for something that doesn&amp;#39;t require a PhD to operate but is still powerful enough to handle our complex requirements.&lt;/p&gt;\n\n&lt;p&gt;Please bombard me with your recommendations! If you&amp;#39;ve got tales of triumph or woe with certain tools, I&amp;#39;m all ears.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17io0ue", "is_robot_indexable": true, "report_reasons": null, "author": "volturnalia", "discussion_type": null, "num_comments": 4, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17io0ue/desperately_need_help_finding_an_etl_tool_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17io0ue/desperately_need_help_finding_an_etl_tool_for/", "subreddit_subscribers": 136662, "created_utc": 1698529749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For context, I work in a SAAS startup and have been with them for a little over 3yrs. I was hired on from a contractor role doing data entry to work on migrating client data. I was new to this and the company had not yet done much in this regard besides building a tool that actually loads the data.\n\nThat said, I dove in and started building tools to perform the E and the T processes, but due to the different formats these client\u2019s data comes in (I.e. different previous providers), there\u2019s only a little continuity in how my tools can operate. For example, our clients bring us data from their previous providers in one of: SQL server .bak files, huge json files, zips of correlated csvs, zips of correlated json files, data I collect from scraping their old platforms. \n\nThe nature of the data involves a ton of mapping, and this mapping can be different from one client to the next coming from the same previous system based on how they implemented the previous software in their business, updates to the old software, etc. \n\nI know these are typical challenges in the field, but having no prior experience and not much guidance on scaling this process, I feel my tooling/process needs re-somethinged. I\u2019m currently using a stack of (primarily) Python, SQLite, sql server (on a vm), Google sheets. There are so many moving parts, \u201cworkarounds\u201d, exceptions I have to deal with, while also considering the clients\u2019 typically tall requests. \n\nI\u2019m hoping, from this post, to gain some insight from others about what stack they use, ways to improve existing processes, anything else to possibly help preserve my sanity. I enjoy this work a lot, but I feel my lack of prior experience left me at a slight disadvantage. \n\nThanks in advance for any and all feedback, input, etc.!", "author_fullname": "t2_5am908px", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Client data migration questions and/or discussion", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17iggeg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698507820.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For context, I work in a SAAS startup and have been with them for a little over 3yrs. I was hired on from a contractor role doing data entry to work on migrating client data. I was new to this and the company had not yet done much in this regard besides building a tool that actually loads the data.&lt;/p&gt;\n\n&lt;p&gt;That said, I dove in and started building tools to perform the E and the T processes, but due to the different formats these client\u2019s data comes in (I.e. different previous providers), there\u2019s only a little continuity in how my tools can operate. For example, our clients bring us data from their previous providers in one of: SQL server .bak files, huge json files, zips of correlated csvs, zips of correlated json files, data I collect from scraping their old platforms. &lt;/p&gt;\n\n&lt;p&gt;The nature of the data involves a ton of mapping, and this mapping can be different from one client to the next coming from the same previous system based on how they implemented the previous software in their business, updates to the old software, etc. &lt;/p&gt;\n\n&lt;p&gt;I know these are typical challenges in the field, but having no prior experience and not much guidance on scaling this process, I feel my tooling/process needs re-somethinged. I\u2019m currently using a stack of (primarily) Python, SQLite, sql server (on a vm), Google sheets. There are so many moving parts, \u201cworkarounds\u201d, exceptions I have to deal with, while also considering the clients\u2019 typically tall requests. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m hoping, from this post, to gain some insight from others about what stack they use, ways to improve existing processes, anything else to possibly help preserve my sanity. I enjoy this work a lot, but I feel my lack of prior experience left me at a slight disadvantage. &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for any and all feedback, input, etc.!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17iggeg", "is_robot_indexable": true, "report_reasons": null, "author": "iambatmanman", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17iggeg/client_data_migration_questions_andor_discussion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17iggeg/client_data_migration_questions_andor_discussion/", "subreddit_subscribers": 136662, "created_utc": 1698507820.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone used language models for cleaning data? I'm thinking about using a small language model to clean and standardize property records. What models did you try/are using? What kind of prompting do you have?", "author_fullname": "t2_10z7c3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "language models for data cleaning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ipv7s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698535237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone used language models for cleaning data? I&amp;#39;m thinking about using a small language model to clean and standardize property records. What models did you try/are using? What kind of prompting do you have?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17ipv7s", "is_robot_indexable": true, "report_reasons": null, "author": "tantanchen", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ipv7s/language_models_for_data_cleaning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ipv7s/language_models_for_data_cleaning/", "subreddit_subscribers": 136662, "created_utc": 1698535237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a common pattern for sharing data across a bunch of EC2 instances processing data in Python where they would need immediate responses? I'm new to DE so there may just be an obvious answer or total issue with my current approach, but I feel like there has to be a way to handle this kind of scenario.\n\nI have a bunch of EC2 instances transforming data from JSON to parquet and then write the resulting parquet files to S3. There's data that associates a some subset of users with a website that they've posted to\n\n    {\n      \"users\": [\n        {\n          \"groupid\": 1,\n          \"ids\": [1, 2, 3, 4],\n          \"website\": 'A'\n        },\n        {\n          \"groupid\": 2,\n          \"ids\": [1, 2],\n          \"website\": 'B'\n        },\n        {\n          \"groupid\": 3,\n          \"ids\": [4, 5, 6],\n          \"website\": 'C'\n        },\n      ]\n    }\n\nRight now the \"groupid\" would apply only to the data in that JSON file, however this would cause billions of duplicated rows in the resulting parquet files. If I wanted to give these user groups a unique identifier across all of the files/servers doing the transformations, what are some options for accomplishing that?\n\nI've experimented with the servers reading and writing to a DynamoDB instance or Redis cache whenever they find a group of ids associated with a website for the first time (i.e. the key would be \"web:C#ids:4,5,6\" and would point to a new custom ID), but those both seem to have pretty substantial impacts on the performance of the transformations. Is there some other option besides fundamentally redesigning the pipeline?  \n\n\nEdit: Maybe a separate post-processing script that runs at the end?", "author_fullname": "t2_sgbjn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to share data across distributed servers doing transformation in ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ih2km", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698511255.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698509583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a common pattern for sharing data across a bunch of EC2 instances processing data in Python where they would need immediate responses? I&amp;#39;m new to DE so there may just be an obvious answer or total issue with my current approach, but I feel like there has to be a way to handle this kind of scenario.&lt;/p&gt;\n\n&lt;p&gt;I have a bunch of EC2 instances transforming data from JSON to parquet and then write the resulting parquet files to S3. There&amp;#39;s data that associates a some subset of users with a website that they&amp;#39;ve posted to&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n  &amp;quot;users&amp;quot;: [\n    {\n      &amp;quot;groupid&amp;quot;: 1,\n      &amp;quot;ids&amp;quot;: [1, 2, 3, 4],\n      &amp;quot;website&amp;quot;: &amp;#39;A&amp;#39;\n    },\n    {\n      &amp;quot;groupid&amp;quot;: 2,\n      &amp;quot;ids&amp;quot;: [1, 2],\n      &amp;quot;website&amp;quot;: &amp;#39;B&amp;#39;\n    },\n    {\n      &amp;quot;groupid&amp;quot;: 3,\n      &amp;quot;ids&amp;quot;: [4, 5, 6],\n      &amp;quot;website&amp;quot;: &amp;#39;C&amp;#39;\n    },\n  ]\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Right now the &amp;quot;groupid&amp;quot; would apply only to the data in that JSON file, however this would cause billions of duplicated rows in the resulting parquet files. If I wanted to give these user groups a unique identifier across all of the files/servers doing the transformations, what are some options for accomplishing that?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve experimented with the servers reading and writing to a DynamoDB instance or Redis cache whenever they find a group of ids associated with a website for the first time (i.e. the key would be &amp;quot;web:C#ids:4,5,6&amp;quot; and would point to a new custom ID), but those both seem to have pretty substantial impacts on the performance of the transformations. Is there some other option besides fundamentally redesigning the pipeline?  &lt;/p&gt;\n\n&lt;p&gt;Edit: Maybe a separate post-processing script that runs at the end?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ih2km", "is_robot_indexable": true, "report_reasons": null, "author": "IamSerenity", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ih2km/how_to_share_data_across_distributed_servers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ih2km/how_to_share_data_across_distributed_servers/", "subreddit_subscribers": 136662, "created_utc": 1698509583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an interview tomorrow. \n\n1 hour management interview (in which I believe I\u2019ll be very comfortable)\nFollowed by \n1 hour tech interview (not so confident)\n\nA little about me: I have consulting experience, know SQL, R &amp; have worked on Tableau. \n\nThe role: Data Quality Lead\n\nCan send the JD in chat.", "author_fullname": "t2_bo6y7ima3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Tomorrow. Need Collibra Crash Course!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ixs5d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698564853.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an interview tomorrow. &lt;/p&gt;\n\n&lt;p&gt;1 hour management interview (in which I believe I\u2019ll be very comfortable)\nFollowed by \n1 hour tech interview (not so confident)&lt;/p&gt;\n\n&lt;p&gt;A little about me: I have consulting experience, know SQL, R &amp;amp; have worked on Tableau. &lt;/p&gt;\n\n&lt;p&gt;The role: Data Quality Lead&lt;/p&gt;\n\n&lt;p&gt;Can send the JD in chat.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ixs5d", "is_robot_indexable": true, "report_reasons": null, "author": "zamonk8", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ixs5d/interview_tomorrow_need_collibra_crash_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ixs5d/interview_tomorrow_need_collibra_crash_course/", "subreddit_subscribers": 136662, "created_utc": 1698564853.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}