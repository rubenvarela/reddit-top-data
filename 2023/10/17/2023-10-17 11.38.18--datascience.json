{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1nnh1bpq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meme Mondays", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 130, "top_awarded_type": null, "hide_score": false, "name": "t3_179huzu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "ups": 552, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 552, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/BdGMg8NR_z8b0B8Rfbl09b-bmsvud6q9Csn2tMDUsw8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697493093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/zxdz4pm6ymub1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/zxdz4pm6ymub1.png?auto=webp&amp;s=bafa17f40ac4179a1a5101469047fdf761d9e368", "width": 680, "height": 635}, "resolutions": [{"url": "https://preview.redd.it/zxdz4pm6ymub1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=050c61142ad3c3a892a954c5a0050105a0d017ac", "width": 108, "height": 100}, {"url": "https://preview.redd.it/zxdz4pm6ymub1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e6f2a05e3dcdd7a7a9262d4c6c18ef3167c286a", "width": 216, "height": 201}, {"url": "https://preview.redd.it/zxdz4pm6ymub1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f3ceaa5fb8aec7bedacb24e0d1397aa04efac36d", "width": 320, "height": 298}, {"url": "https://preview.redd.it/zxdz4pm6ymub1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=83f219046f9b0a24698eb124ca95c5252dc5fb23", "width": 640, "height": 597}], "variants": {}, "id": "k5LehGeHkzqss6xyqVg5nrMab3CMDiKroOLp715TRoc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "179huzu", "is_robot_indexable": true, "report_reasons": null, "author": "softwareitcounts", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179huzu/meme_mondays/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/zxdz4pm6ymub1.png", "subreddit_subscribers": 1087917, "created_utc": 1697493093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Creativity**: We often focus a lot on hard skills, but creativity is the most important attribute for a data scientist. You will get some crazy requests. For example, I was once asked to build a recommendation system with NO DATA. Many other data scientists dismissed the project saying it couldn't be done. I was able to accomplish it by building a simple model were I manually entered weights depending on how important I thought each feature was. I then set up a pipeline to update these weights as real data would come in. Was it perfect? No. But it did a good enough job while we were waiting for data and made the client happy. I have had many crazy requests like this. So many data scientists out there have to be told what to do, very few can come up with creative solutions. The best never use phrases like, \"that is impossible.\" How do you learn this creativity? By working on real world problems. This skill is not developed when you are given a toy dataset and told what the output should look like. Sure, you might learn some technical modeling, but virtually no creativity. I wish more bootcamps would give \"impossible\" tasks.\n\n**Dirty Data**: I understand that provided or toy datasets can sometimes be dirty. They don't come close to real world data. Imagine you are asked to build a model using datasets you do not know exist yet, coming from source systems with little-to-no descriptions of what the features mean. Somehow you need to find the right data in a sea of millions of irrelevant features. You will need to fight political battles to even get access to the features you do not yet know if you even need. You will need to track down knowledgeable people who can tell you the weird quirks in the data (e.g. missing months were poorly imputed when this random country suffered a natural disaster 12 years ago). You then need to build a full pipeline that pulls the data from 10 different data sources that don't link to each other naturally, do regression tests because they don't update consistently, transform it, do feature engineering, feed it to a model, monitor the model for drift, redo everything after you find out a feature is completely different from what you were told, and the list goes on. This is not an exaggeration, it is typical. It goes way beyond cleaning up a few outliers and training a prototype model. This experience can only be gained by doing it.\n\n**Being easy to work with**: A bad hire can be a disaster! One person can ruin group moral and be difficult to get rid of. It can be difficult to judge personality from a few interviews. Haveing work experience where you got along with the same team for years greatly reduces that risk.\n\nThere are many others, but these are three big ones. If you don't have these skillsets, that is fine! But you have to start smaller. Get a more Jr level position where you are not expected to know all of these. Get experience working on them with more senior mentors. Even if you are one of the lucky few who get a job out of college in this market, your manager is probably clueless of these issues (i.e. won't be able to help you) and setting you up for failure. Many on this sub are looking for shortcuts or complaining about their job after they took a shortcut. You will have a much better career if you take the patient route.", "author_fullname": "t2_4fiyncpa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why employers want experience over education", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179ebar", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 104, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 104, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697484790.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697484333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Creativity&lt;/strong&gt;: We often focus a lot on hard skills, but creativity is the most important attribute for a data scientist. You will get some crazy requests. For example, I was once asked to build a recommendation system with NO DATA. Many other data scientists dismissed the project saying it couldn&amp;#39;t be done. I was able to accomplish it by building a simple model were I manually entered weights depending on how important I thought each feature was. I then set up a pipeline to update these weights as real data would come in. Was it perfect? No. But it did a good enough job while we were waiting for data and made the client happy. I have had many crazy requests like this. So many data scientists out there have to be told what to do, very few can come up with creative solutions. The best never use phrases like, &amp;quot;that is impossible.&amp;quot; How do you learn this creativity? By working on real world problems. This skill is not developed when you are given a toy dataset and told what the output should look like. Sure, you might learn some technical modeling, but virtually no creativity. I wish more bootcamps would give &amp;quot;impossible&amp;quot; tasks.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Dirty Data&lt;/strong&gt;: I understand that provided or toy datasets can sometimes be dirty. They don&amp;#39;t come close to real world data. Imagine you are asked to build a model using datasets you do not know exist yet, coming from source systems with little-to-no descriptions of what the features mean. Somehow you need to find the right data in a sea of millions of irrelevant features. You will need to fight political battles to even get access to the features you do not yet know if you even need. You will need to track down knowledgeable people who can tell you the weird quirks in the data (e.g. missing months were poorly imputed when this random country suffered a natural disaster 12 years ago). You then need to build a full pipeline that pulls the data from 10 different data sources that don&amp;#39;t link to each other naturally, do regression tests because they don&amp;#39;t update consistently, transform it, do feature engineering, feed it to a model, monitor the model for drift, redo everything after you find out a feature is completely different from what you were told, and the list goes on. This is not an exaggeration, it is typical. It goes way beyond cleaning up a few outliers and training a prototype model. This experience can only be gained by doing it.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Being easy to work with&lt;/strong&gt;: A bad hire can be a disaster! One person can ruin group moral and be difficult to get rid of. It can be difficult to judge personality from a few interviews. Haveing work experience where you got along with the same team for years greatly reduces that risk.&lt;/p&gt;\n\n&lt;p&gt;There are many others, but these are three big ones. If you don&amp;#39;t have these skillsets, that is fine! But you have to start smaller. Get a more Jr level position where you are not expected to know all of these. Get experience working on them with more senior mentors. Even if you are one of the lucky few who get a job out of college in this market, your manager is probably clueless of these issues (i.e. won&amp;#39;t be able to help you) and setting you up for failure. Many on this sub are looking for shortcuts or complaining about their job after they took a shortcut. You will have a much better career if you take the patient route.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179ebar", "is_robot_indexable": true, "report_reasons": null, "author": "Expendable_0", "discussion_type": null, "num_comments": 61, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179ebar/why_employers_want_experience_over_education/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179ebar/why_employers_want_experience_over_education/", "subreddit_subscribers": 1087917, "created_utc": 1697484333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have been working as a \"data scientist\" in supply chain for a little over a year at a fortune 500 company. I am the only person with a data related title on my team. There is one small team of people with \"data scientist\" titles in the whole org but they are in a separate silo from me. \n\nGenerally I am tossed tasks that don't make a whole lot of sense: for example comparing forecast accuracy for the exact same models between a no-code out of the box forecaster like SAP IBP with Python models that a contractor they hired built. Other times I will get requests so vague like \"build us a chatbot\". I have always hounded them with questions and shared my opinions on these asks, but basically get told to shut up and go away each time.  \n\nNow they have cut what I can only assume is a few million dollar check with a large consulting company to build out a demand and inventory forecasting model. The thing is, they just launched an out-of-the-box SAP solution less than 2 years ago which does exactly that: inventory and demand forecasting. I can't imagine that project was less than a few million as well. \n\nIn all of this, no one can ever really articulate to me why we are doing this or what specifically they are trying to improve. It seems like they don't even realize the consultants will likely build a very similar model to SAP. \n\nAre most companies like this? Only some? It has been very stressful for me, as 4 people have also been let go from my team within the year I've worked here. It seems like they have no vision or clue what they are doing.", "author_fullname": "t2_dbvtg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How many companies actually have a clear plan for their data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179945p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 102, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 102, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697471271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working as a &amp;quot;data scientist&amp;quot; in supply chain for a little over a year at a fortune 500 company. I am the only person with a data related title on my team. There is one small team of people with &amp;quot;data scientist&amp;quot; titles in the whole org but they are in a separate silo from me. &lt;/p&gt;\n\n&lt;p&gt;Generally I am tossed tasks that don&amp;#39;t make a whole lot of sense: for example comparing forecast accuracy for the exact same models between a no-code out of the box forecaster like SAP IBP with Python models that a contractor they hired built. Other times I will get requests so vague like &amp;quot;build us a chatbot&amp;quot;. I have always hounded them with questions and shared my opinions on these asks, but basically get told to shut up and go away each time.  &lt;/p&gt;\n\n&lt;p&gt;Now they have cut what I can only assume is a few million dollar check with a large consulting company to build out a demand and inventory forecasting model. The thing is, they just launched an out-of-the-box SAP solution less than 2 years ago which does exactly that: inventory and demand forecasting. I can&amp;#39;t imagine that project was less than a few million as well. &lt;/p&gt;\n\n&lt;p&gt;In all of this, no one can ever really articulate to me why we are doing this or what specifically they are trying to improve. It seems like they don&amp;#39;t even realize the consultants will likely build a very similar model to SAP. &lt;/p&gt;\n\n&lt;p&gt;Are most companies like this? Only some? It has been very stressful for me, as 4 people have also been let go from my team within the year I&amp;#39;ve worked here. It seems like they have no vision or clue what they are doing.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179945p", "is_robot_indexable": true, "report_reasons": null, "author": "MikeyCyrus", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179945p/how_many_companies_actually_have_a_clear_plan_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179945p/how_many_companies_actually_have_a_clear_plan_for/", "subreddit_subscribers": 1087917, "created_utc": 1697471271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was wondering if there are other people out there who regret choosing data science as a career path.\n\nFor context: I got my B.S. in Mathematics in 2018. I worked 1 year as a program associate for a non-profit, managing their database and writing reports for grants/funding purposes. I then switched to a job in retirement investing as an analyst. I was originally going to start grad school (for a Masters in DS) in the Fall of 2020 but delayed to 2021 due to covid so I stayed at that job for 2 years.\n\nI enjoyed working with data and numbers, I kind of like how it feels to develop that tunnel vision and fixate on numbers lol. So I thought data science would be a good fit given those jobs revolved around data and it would be something financially stable (of course having no idea just how much covid et al. would impact the job market).\n\nIn the fall of the 2nd year of my Master's I received an offer to work for a large Healthcare company, which is where I am currently employed. To be honest, I genuinely hate it. I'm stuck working on the insurance side and it just feels miserable and unethical to me on a daily basis. I was hoping to join a team on the clinical side but wound up on the healthcare side due to the way the company matches employees to teams. I realized I miss working more directly with people, as I am on the west coast and the entirety of my team is on the East Coast or in India.\n\nI can't really tell if my misery is because of the company I work for itself or the field in general. I think I want something more interesting than what I am currently doing. I work with insurance plan design data. I applied to this job on a whim, because of the condition of the job market I felt I had to apply to all sorts of things. I'm personally opposed to for- profit healthcare but accepted because I didnt feel I had much choice as it was the only offer I received after hundreds of applications over many months. \n\nDoes anyone else feel extremely unsatisfied as a data scientist or as a data engineer? I guess I feel really under-stimulated and extremely unsatisfied. I don't know if every job feels like this and I have to suck it up, or if I should just leave. I've only been here 3 months and my resume is inconsistent enough as is so it feels too risky to leave even if I had a different offer lined up.\n\nI'd love to hear about people who switched into data science / engineering then changed their mind. Also, id appreciate input on the longevity of this career. I'm having a hard time setting career goals for myself and understand what career growth in this industry looks like and what I should aim for.", "author_fullname": "t2_iljnct2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Regretting Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179etbr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697514908.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697485575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if there are other people out there who regret choosing data science as a career path.&lt;/p&gt;\n\n&lt;p&gt;For context: I got my B.S. in Mathematics in 2018. I worked 1 year as a program associate for a non-profit, managing their database and writing reports for grants/funding purposes. I then switched to a job in retirement investing as an analyst. I was originally going to start grad school (for a Masters in DS) in the Fall of 2020 but delayed to 2021 due to covid so I stayed at that job for 2 years.&lt;/p&gt;\n\n&lt;p&gt;I enjoyed working with data and numbers, I kind of like how it feels to develop that tunnel vision and fixate on numbers lol. So I thought data science would be a good fit given those jobs revolved around data and it would be something financially stable (of course having no idea just how much covid et al. would impact the job market).&lt;/p&gt;\n\n&lt;p&gt;In the fall of the 2nd year of my Master&amp;#39;s I received an offer to work for a large Healthcare company, which is where I am currently employed. To be honest, I genuinely hate it. I&amp;#39;m stuck working on the insurance side and it just feels miserable and unethical to me on a daily basis. I was hoping to join a team on the clinical side but wound up on the healthcare side due to the way the company matches employees to teams. I realized I miss working more directly with people, as I am on the west coast and the entirety of my team is on the East Coast or in India.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t really tell if my misery is because of the company I work for itself or the field in general. I think I want something more interesting than what I am currently doing. I work with insurance plan design data. I applied to this job on a whim, because of the condition of the job market I felt I had to apply to all sorts of things. I&amp;#39;m personally opposed to for- profit healthcare but accepted because I didnt feel I had much choice as it was the only offer I received after hundreds of applications over many months. &lt;/p&gt;\n\n&lt;p&gt;Does anyone else feel extremely unsatisfied as a data scientist or as a data engineer? I guess I feel really under-stimulated and extremely unsatisfied. I don&amp;#39;t know if every job feels like this and I have to suck it up, or if I should just leave. I&amp;#39;ve only been here 3 months and my resume is inconsistent enough as is so it feels too risky to leave even if I had a different offer lined up.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear about people who switched into data science / engineering then changed their mind. Also, id appreciate input on the longevity of this career. I&amp;#39;m having a hard time setting career goals for myself and understand what career growth in this industry looks like and what I should aim for.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179etbr", "is_robot_indexable": true, "report_reasons": null, "author": "Relative_Practice_93", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179etbr/regretting_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179etbr/regretting_data_science/", "subreddit_subscribers": 1087917, "created_utc": 1697485575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nBuilding off our last research post, we wanted to figure out ways to quantify \"ambiguity\" and \"uncertainty\" in prompts/responses to LLMs. We ended up discovering two useful forms of uncertainty: \"Structural\" and \"Conceptual\" uncertainty.\n\nIn a nutshell: Conceptual uncertainty is when the model isn't sure what to say, and Structural uncertainty is when the model isn't sure how to say it.\n\nYou can play around with this yourself in the [demo](https://uncertainty.demos.watchful.io/) or read about it in more detail in the [blog post](https://www.watchful.io/blog/decoding-llm-uncertainties-for-better-predictability)", "author_fullname": "t2_9o36o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Decoding LLM Uncertainties for Better Predictability", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1799oao", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697472672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Building off our last research post, we wanted to figure out ways to quantify &amp;quot;ambiguity&amp;quot; and &amp;quot;uncertainty&amp;quot; in prompts/responses to LLMs. We ended up discovering two useful forms of uncertainty: &amp;quot;Structural&amp;quot; and &amp;quot;Conceptual&amp;quot; uncertainty.&lt;/p&gt;\n\n&lt;p&gt;In a nutshell: Conceptual uncertainty is when the model isn&amp;#39;t sure what to say, and Structural uncertainty is when the model isn&amp;#39;t sure how to say it.&lt;/p&gt;\n\n&lt;p&gt;You can play around with this yourself in the &lt;a href=\"https://uncertainty.demos.watchful.io/\"&gt;demo&lt;/a&gt; or read about it in more detail in the &lt;a href=\"https://www.watchful.io/blog/decoding-llm-uncertainties-for-better-predictability\"&gt;blog post&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1799oao", "is_robot_indexable": true, "report_reasons": null, "author": "shayanjm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1799oao/decoding_llm_uncertainties_for_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1799oao/decoding_llm_uncertainties_for_better/", "subreddit_subscribers": 1087917, "created_utc": 1697472672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Basically, the title. I would really like to hear from the  experts in the forecasting what do you think are the most important things to learn to be a competent professional in a forecasting field and where to pick it up? I am.especially interested in the dand forecasting. Thank you very much!", "author_fullname": "t2_a0o64rxa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would be a good curriculum for a data scientist to learn about forecasting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17941v2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697456671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically, the title. I would really like to hear from the  experts in the forecasting what do you think are the most important things to learn to be a competent professional in a forecasting field and where to pick it up? I am.especially interested in the dand forecasting. Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17941v2", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious-Class-65", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17941v2/what_would_be_a_good_curriculum_for_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17941v2/what_would_be_a_good_curriculum_for_a_data/", "subreddit_subscribers": 1087917, "created_utc": 1697456671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi r/datascience,\n\nFrom my experience working with data orchestration tools (Airflow primarily), I tend to deal with a lot of repetitive fixes with flaky pipelines such as resource exhaustion issues, single malformed entries or other edge cases, figuring out why a task isn't running, and so on. I was wondering whether any of you had the same experience in your day-to-day work. How much of the job is actually just dealing with repetitive issues and maintenance of pipelines, and do any of you know of any tools or tips to make the experience of working with these pipelines less time-consuming?\n\nThanks!", "author_fullname": "t2_mk6o8gs2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Repetitive airflow pipeline problems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179r5li", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697520996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;From my experience working with data orchestration tools (Airflow primarily), I tend to deal with a lot of repetitive fixes with flaky pipelines such as resource exhaustion issues, single malformed entries or other edge cases, figuring out why a task isn&amp;#39;t running, and so on. I was wondering whether any of you had the same experience in your day-to-day work. How much of the job is actually just dealing with repetitive issues and maintenance of pipelines, and do any of you know of any tools or tips to make the experience of working with these pipelines less time-consuming?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179r5li", "is_robot_indexable": true, "report_reasons": null, "author": "dec_dev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/", "subreddit_subscribers": 1087917, "created_utc": 1697520996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a musical director on a large cruise ship and am responsible for scheduling sets for 10 different bands around the ships 10 different music venues. I have to work around trivias, parties and shows in the aqua theatre and Theatre and other various venues on the ship. I want to analyze the data I have from Day 1 of the cruise a few weeks ago in a chart. How would you guys go about doing this? Thanks!", "author_fullname": "t2_a3amxwo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cruise Ship Musicians Scheduling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179q91p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697517644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a musical director on a large cruise ship and am responsible for scheduling sets for 10 different bands around the ships 10 different music venues. I have to work around trivias, parties and shows in the aqua theatre and Theatre and other various venues on the ship. I want to analyze the data I have from Day 1 of the cruise a few weeks ago in a chart. How would you guys go about doing this? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179q91p", "is_robot_indexable": true, "report_reasons": null, "author": "SaxTeacher1988", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/", "subreddit_subscribers": 1087917, "created_utc": 1697517644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone, I\u2019m one of the people who work on [Evidently](https://github.com/evidentlyai/evidently), an open-source Python library for ML monitoring. I want to share with you our free ML observability course that starts today, Oct 16.\n\nWe cover the key concepts of ML monitoring and observability, different types of evaluations, and how to integrate them into ML pipelines. We also look into different ML monitoring architectures and explore how to monitor unstructured data, including LLM and NLP models.\n\n\ud83d\udcbb Code examples and end-to-end deployment blueprints.  \n\u2705 Open-source focused. You\u2019ll work with tools like Evidently, MLflow, Airflow, and Grafana.  \n\u2764\ufe0f Free and open to everyone.  \n\ud83d\uddd3 You can join the cohort that starts on October 16, 2023, or learn at your own pace.\n\nCourse info and notes: [https://learn.evidentlyai.com/](https://learn.evidentlyai.com/)\n\nHope you\u2019ll find the course useful!", "author_fullname": "t2_ms6x3icc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Free Open-source ML observability course: starts today \ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1796r3n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697465098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I\u2019m one of the people who work on &lt;a href=\"https://github.com/evidentlyai/evidently\"&gt;Evidently&lt;/a&gt;, an open-source Python library for ML monitoring. I want to share with you our free ML observability course that starts today, Oct 16.&lt;/p&gt;\n\n&lt;p&gt;We cover the key concepts of ML monitoring and observability, different types of evaluations, and how to integrate them into ML pipelines. We also look into different ML monitoring architectures and explore how to monitor unstructured data, including LLM and NLP models.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udcbb Code examples and end-to-end deployment blueprints.&lt;br/&gt;\n\u2705 Open-source focused. You\u2019ll work with tools like Evidently, MLflow, Airflow, and Grafana.&lt;br/&gt;\n\u2764\ufe0f Free and open to everyone.&lt;br/&gt;\n\ud83d\uddd3 You can join the cohort that starts on October 16, 2023, or learn at your own pace.&lt;/p&gt;\n\n&lt;p&gt;Course info and notes: &lt;a href=\"https://learn.evidentlyai.com/\"&gt;https://learn.evidentlyai.com/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Hope you\u2019ll find the course useful!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?auto=webp&amp;s=a4460012747f80368067bbc08cf0bfaf4f04a83b", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=cd64ef2ff79951860bb08a39d4bb1fc52b1b3235", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a2f4805ca7f9815fec0e0fab3beec74eff8e36c1", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=aa5b0ccd7ceec7492d4dbeff29cd97ffac1bee9e", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=1523ca7e3809e3ea9762304b5ec40bc4cd7633aa", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=412fe868629247abf7f561dacacb8742a7bd5897", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/JLR75ll18VcU4sk0XazNveIOlccO8MfhHztkoe7_Ykg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7306ec6454df06e21404184bfa2e867ed5a447cc", "width": 1080, "height": 540}], "variants": {}, "id": "vpmpbE4KKp-X8MJmt4x46ZJk-dHdBfNmLnmk67S6TUc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1796r3n", "is_robot_indexable": true, "report_reasons": null, "author": "dmalyugina", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1796r3n/free_opensource_ml_observability_course_starts/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1796r3n/free_opensource_ml_observability_course_starts/", "subreddit_subscribers": 1087917, "created_utc": 1697465098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " - Git\n   - public only otherwise on GitHub\n   - limited repos otherwise on Bitbucket\n - Webhost\n   - (the nice ones seem to all be trial only / require a CC)\n - Cloud compute\n   - limited otherwise on Colab\n   - trial only on AWS\n\nGetting ready for the next round of jobseeking, and all my student trials will be over. _Not_ intermingling with work.\n\nWhich do you consider worthwhile? Which not so much?", "author_fullname": "t2_fem4lsdf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What services do you pay for for your personal portfolio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179do5q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697482719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;Git\n\n&lt;ul&gt;\n&lt;li&gt;public only otherwise on GitHub&lt;/li&gt;\n&lt;li&gt;limited repos otherwise on Bitbucket&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Webhost\n\n&lt;ul&gt;\n&lt;li&gt;(the nice ones seem to all be trial only / require a CC)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Cloud compute\n\n&lt;ul&gt;\n&lt;li&gt;limited otherwise on Colab&lt;/li&gt;\n&lt;li&gt;trial only on AWS&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Getting ready for the next round of jobseeking, and all my student trials will be over. &lt;em&gt;Not&lt;/em&gt; intermingling with work.&lt;/p&gt;\n\n&lt;p&gt;Which do you consider worthwhile? Which not so much?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179do5q", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway20220717", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179do5q/what_services_do_you_pay_for_for_your_personal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179do5q/what_services_do_you_pay_for_for_your_personal/", "subreddit_subscribers": 1087917, "created_utc": 1697482719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_l7pjiir72", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When using bagging or boosting to combine decision trees, which algorithm takes more time to train?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1794e1d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697457843.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1794e1d", "is_robot_indexable": true, "report_reasons": null, "author": "Hasneverbeenhere", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1794e1d/when_using_bagging_or_boosting_to_combine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1794e1d/when_using_bagging_or_boosting_to_combine/", "subreddit_subscribers": 1087917, "created_utc": 1697457843.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Folks\n\nI am currently working as  Senior ML Engineer on a startup in Dubai. I am 28 years old and getting 120k USD yearly. (no tax).\n\nActually, I am living a good life here, its close to my home country (Turkey), so I can see my family easily and we are almost in same timezone. But the quality of things we are doing here not that good, and I am not sure can I grow in my career here in long run. I don't want to move to Europe because as I can see salaries are very low . If I stay in Dubai getting a salary around 150k in 2 years in here is very doable for me now.\n\nI started considering to move to USA. I found hybrid master programs (first year is remote second year is USA and I can OPT). So I don't have to sacrifice my 2 years to go USA. Probably I will stay without a job just one year.\n\nDo you have any advice for me? Is moving to USA changing my lifestyle, and making sacrifices (time, masters, moving to USA, money etc) worth it?  \n\n\n&amp;#x200B;", "author_fullname": "t2_auxp06r9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving to USA or Staying in UAE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_179uwm2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697537235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Folks&lt;/p&gt;\n\n&lt;p&gt;I am currently working as  Senior ML Engineer on a startup in Dubai. I am 28 years old and getting 120k USD yearly. (no tax).&lt;/p&gt;\n\n&lt;p&gt;Actually, I am living a good life here, its close to my home country (Turkey), so I can see my family easily and we are almost in same timezone. But the quality of things we are doing here not that good, and I am not sure can I grow in my career here in long run. I don&amp;#39;t want to move to Europe because as I can see salaries are very low . If I stay in Dubai getting a salary around 150k in 2 years in here is very doable for me now.&lt;/p&gt;\n\n&lt;p&gt;I started considering to move to USA. I found hybrid master programs (first year is remote second year is USA and I can OPT). So I don&amp;#39;t have to sacrifice my 2 years to go USA. Probably I will stay without a job just one year.&lt;/p&gt;\n\n&lt;p&gt;Do you have any advice for me? Is moving to USA changing my lifestyle, and making sacrifices (time, masters, moving to USA, money etc) worth it?  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179uwm2", "is_robot_indexable": true, "report_reasons": null, "author": "Round_Inflation_2199", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/", "subreddit_subscribers": 1087917, "created_utc": 1697537235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! I am dealing with a specific problem: predicting the maximum number of cars that can stop in a parking lot on a daily basis. We have multiple parking lots in a region, each with a fixed number of parking slots. These slots are used multiple times throughout the day. I have access to historical data, including information on the time cars spent in the slots, the number of cars in any given period, the number of empty slots during specific time periods, and statistics for nearby areas.\n\nThe goal is to predict, for each parking lot, the maximum number of cars it can accommodate on each day during the pre-Christmas period. It's important to note that historically, none of the parking lots have probably reached their maximum capacity.\n\nAdditionally, we are faced with a challenge related to new parking lots. These lots lack extensive historical data, and many people may not be aware of their existence.\n\nHow would you recommend approaching this task?", "author_fullname": "t2_lku7zyn1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predict maximum capacity of parking lots", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179ub5l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697534713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I am dealing with a specific problem: predicting the maximum number of cars that can stop in a parking lot on a daily basis. We have multiple parking lots in a region, each with a fixed number of parking slots. These slots are used multiple times throughout the day. I have access to historical data, including information on the time cars spent in the slots, the number of cars in any given period, the number of empty slots during specific time periods, and statistics for nearby areas.&lt;/p&gt;\n\n&lt;p&gt;The goal is to predict, for each parking lot, the maximum number of cars it can accommodate on each day during the pre-Christmas period. It&amp;#39;s important to note that historically, none of the parking lots have probably reached their maximum capacity.&lt;/p&gt;\n\n&lt;p&gt;Additionally, we are faced with a challenge related to new parking lots. These lots lack extensive historical data, and many people may not be aware of their existence.&lt;/p&gt;\n\n&lt;p&gt;How would you recommend approaching this task?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179ub5l", "is_robot_indexable": true, "report_reasons": null, "author": "VGFenohmen", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/", "subreddit_subscribers": 1087917, "created_utc": 1697534713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey fellow Redditors!\n\nEver wondered how technology can tackle a range of challenges like signature authentication, detecting cheaters in games, assessing neurological conditions, or dealing with pesky bots? The answer lies in the fascinating world of human motion analysis!\n\nIn this discussion, we delve into the concept of \"features\" in the context of human motion. Features are scalar values obtained from motion segments, offering insights into movement patterns. We explore how these features are essential in addressing diverse challenges and share insights into the basic features of movements.\n\n# \ud83d\udca1 What's a Feature?  \n\nIn this context, a feature refers to a scalar value obtained from a motion segment. For example, the average acceleration of a cursor. As depicted in the diagram below, users cannot be distinguished solely based on their average acceleration, but there are discernible individual tendencies.\n\n The next step involves constructing our feature space by identifying features that contain relevant information about movement patterns. \n\n# \ud83d\udcca Analyzing the appropriate time series\n\nThe majority of the data we work with consists of x and y coordinates that change over time, such as the position of a cursor or a pen on a screen. Therefore, we already have two time series. Additionally, we calculate directional speeds, accelerations, jerks, as well as direction-independent speed, acceleration, and jerk. \n\n**Unmasking forgery through speed analysis**\n\nLet\u2019s explain the use of derivatives through an example of **signature forgery**. Suppose someone attempts to replicate a signature they have seen before, familiar with its form. How would you approach this situation? Initially, one might **meticulously trace the line to be replicated, proceeding slowly and accurately**, inch by inch. The result would be a slow, nearly constant-speed movement. **The speed time series would exhibit an approximately constant value.**\n\nNow, imagine **someone writing their own signature**. **The speed can vary significantly**, but it won\u2019t remain constant. They would draw longer, straight lines more quickly and slow down at tight turns. When moving right and upwards, the arcs would be faster and more dynamic than when turning left. Even if the forged signature\u2019s image is an exact copy of the genuine one in terms of x-y coordinates, **the speed profiles would look entirely different.**\n\nOf course, this was a rather clumsy attempt at forgery; there are far more skilled individuals in this field. The speed of a signature can be estimated based on the signature image alone, either by assuming faster movement on straight lines and slower movement on curves or by considering the line quality.\n\nDelving into the details is beyond the scope of this discussion, but the key point is that estimating and replicating the speed of motion requires practice and talent. It is more challenging than simply replicating the x-y coordinates of the signature image. Moreover, forging the acceleration and other factors becomes even more difficult.\n\nIn theory, we could **take derivatives of our time series as many times as desired**. However, there is a practical limit as, **after a certain point, the derivative becomes more noise than meaningful information.**\n\nFrom this example, it becomes apparent why we thought utilizing derivatives (speed, acceleration, jerk) was a valuable approach for motion analysis. **When we began using this method, the results demonstrated exceptional accuracy**.\n\n# \ud83d\udd0d Describing Time Series with Scalar Values \n\n We have extracted various time series from our motion sample. To condense the valuable information of a lengthy time series into scalar values, **we employ a straightforward approach: calculating a few statistical characteristics**. Our selection criteria ensure that these characteristics effectively represent the distribution of the time series.\n\nSome of these characteristics are expected, such as the minimum, maximum, mean, and standard deviation.\n\nTo understand how the values progress from the minimum to the maximum, we utilize percentiles, including the 10th, 25th, 50th, 75th, and 90th percentiles. The minimum and maximum values are also considered as percentiles, specifically the 0th and 100th percentiles.\n\nTwo lesser-known statistical values are skewness and kurtosis. **Skewness measures the asymmetry of a distribution**. For instance, if the speed values below and above the average speed are evenly spaced, the skewness will be around zero. However, if there are numerous values below the mean but close to it, with only a few exceptionally high values above, the skewness will be positive.\n\nIn the context of cursor movement, this suggests that an individual typically uses the cursor at a relatively constant speed, but occasionally makes sudden moves. This could be a personal habit or characteristic.\n\nOn the other hand, **kurtosis indicates whether the values are concentrated around the mean or spread out across a broader range**.\n\nThese are the basic features we utilize for analysis.\n\nFeel free to join the discussion and share your thoughts on this fascinating intersection of technology and human motion analysis! \ud83d\udcac\ud83d\udd7a\ud83c\udffd\ud83d\udcbb", "author_fullname": "t2_gbypvyyx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cracking the Code of Human Motion: Describing Movement Patterns with Scalar Values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179u12d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697533471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors!&lt;/p&gt;\n\n&lt;p&gt;Ever wondered how technology can tackle a range of challenges like signature authentication, detecting cheaters in games, assessing neurological conditions, or dealing with pesky bots? The answer lies in the fascinating world of human motion analysis!&lt;/p&gt;\n\n&lt;p&gt;In this discussion, we delve into the concept of &amp;quot;features&amp;quot; in the context of human motion. Features are scalar values obtained from motion segments, offering insights into movement patterns. We explore how these features are essential in addressing diverse challenges and share insights into the basic features of movements.&lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udca1 What&amp;#39;s a Feature?&lt;/h1&gt;\n\n&lt;p&gt;In this context, a feature refers to a scalar value obtained from a motion segment. For example, the average acceleration of a cursor. As depicted in the diagram below, users cannot be distinguished solely based on their average acceleration, but there are discernible individual tendencies.&lt;/p&gt;\n\n&lt;p&gt;The next step involves constructing our feature space by identifying features that contain relevant information about movement patterns. &lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udcca Analyzing the appropriate time series&lt;/h1&gt;\n\n&lt;p&gt;The majority of the data we work with consists of x and y coordinates that change over time, such as the position of a cursor or a pen on a screen. Therefore, we already have two time series. Additionally, we calculate directional speeds, accelerations, jerks, as well as direction-independent speed, acceleration, and jerk. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Unmasking forgery through speed analysis&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Let\u2019s explain the use of derivatives through an example of &lt;strong&gt;signature forgery&lt;/strong&gt;. Suppose someone attempts to replicate a signature they have seen before, familiar with its form. How would you approach this situation? Initially, one might &lt;strong&gt;meticulously trace the line to be replicated, proceeding slowly and accurately&lt;/strong&gt;, inch by inch. The result would be a slow, nearly constant-speed movement. &lt;strong&gt;The speed time series would exhibit an approximately constant value.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Now, imagine &lt;strong&gt;someone writing their own signature&lt;/strong&gt;. &lt;strong&gt;The speed can vary significantly&lt;/strong&gt;, but it won\u2019t remain constant. They would draw longer, straight lines more quickly and slow down at tight turns. When moving right and upwards, the arcs would be faster and more dynamic than when turning left. Even if the forged signature\u2019s image is an exact copy of the genuine one in terms of x-y coordinates, &lt;strong&gt;the speed profiles would look entirely different.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Of course, this was a rather clumsy attempt at forgery; there are far more skilled individuals in this field. The speed of a signature can be estimated based on the signature image alone, either by assuming faster movement on straight lines and slower movement on curves or by considering the line quality.&lt;/p&gt;\n\n&lt;p&gt;Delving into the details is beyond the scope of this discussion, but the key point is that estimating and replicating the speed of motion requires practice and talent. It is more challenging than simply replicating the x-y coordinates of the signature image. Moreover, forging the acceleration and other factors becomes even more difficult.&lt;/p&gt;\n\n&lt;p&gt;In theory, we could &lt;strong&gt;take derivatives of our time series as many times as desired&lt;/strong&gt;. However, there is a practical limit as, &lt;strong&gt;after a certain point, the derivative becomes more noise than meaningful information.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;From this example, it becomes apparent why we thought utilizing derivatives (speed, acceleration, jerk) was a valuable approach for motion analysis. &lt;strong&gt;When we began using this method, the results demonstrated exceptional accuracy&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udd0d Describing Time Series with Scalar Values&lt;/h1&gt;\n\n&lt;p&gt;We have extracted various time series from our motion sample. To condense the valuable information of a lengthy time series into scalar values, &lt;strong&gt;we employ a straightforward approach: calculating a few statistical characteristics&lt;/strong&gt;. Our selection criteria ensure that these characteristics effectively represent the distribution of the time series.&lt;/p&gt;\n\n&lt;p&gt;Some of these characteristics are expected, such as the minimum, maximum, mean, and standard deviation.&lt;/p&gt;\n\n&lt;p&gt;To understand how the values progress from the minimum to the maximum, we utilize percentiles, including the 10th, 25th, 50th, 75th, and 90th percentiles. The minimum and maximum values are also considered as percentiles, specifically the 0th and 100th percentiles.&lt;/p&gt;\n\n&lt;p&gt;Two lesser-known statistical values are skewness and kurtosis. &lt;strong&gt;Skewness measures the asymmetry of a distribution&lt;/strong&gt;. For instance, if the speed values below and above the average speed are evenly spaced, the skewness will be around zero. However, if there are numerous values below the mean but close to it, with only a few exceptionally high values above, the skewness will be positive.&lt;/p&gt;\n\n&lt;p&gt;In the context of cursor movement, this suggests that an individual typically uses the cursor at a relatively constant speed, but occasionally makes sudden moves. This could be a personal habit or characteristic.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, &lt;strong&gt;kurtosis indicates whether the values are concentrated around the mean or spread out across a broader range&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;These are the basic features we utilize for analysis.&lt;/p&gt;\n\n&lt;p&gt;Feel free to join the discussion and share your thoughts on this fascinating intersection of technology and human motion analysis! \ud83d\udcac\ud83d\udd7a\ud83c\udffd\ud83d\udcbb&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179u12d", "is_robot_indexable": true, "report_reasons": null, "author": "CursorInsight", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/", "subreddit_subscribers": 1087917, "created_utc": 1697533471.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi, all! I am a Data Scientist experienced in Marketing Science, and am writing a small online book regarding topics that are important in marketing science. I wrote a chapter regarding:\n\n\\- The law of diminishing returns\n\n\\- ROAS and Marginal ROAS\n\n\\- Advertisement elasticity on Returns\n\nHope that it is useful for everybody. Any feedback is welcome.\n\n[https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html](https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html)", "author_fullname": "t2_47oo16kh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Applied Data Science in Marketing] How to measure marginal returns and elasticity of marketing campaigns", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1798de7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697469358.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, all! I am a Data Scientist experienced in Marketing Science, and am writing a small online book regarding topics that are important in marketing science. I wrote a chapter regarding:&lt;/p&gt;\n\n&lt;p&gt;- The law of diminishing returns&lt;/p&gt;\n\n&lt;p&gt;- ROAS and Marginal ROAS&lt;/p&gt;\n\n&lt;p&gt;- Advertisement elasticity on Returns&lt;/p&gt;\n\n&lt;p&gt;Hope that it is useful for everybody. Any feedback is welcome.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html\"&gt;https://phc4rdoso.github.io/2.%20The%20Law%20of%20Diminishing%20Returns.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1798de7", "is_robot_indexable": true, "report_reasons": null, "author": "G4L1C", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1798de7/applied_data_science_in_marketing_how_to_measure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1798de7/applied_data_science_in_marketing_how_to_measure/", "subreddit_subscribers": 1087917, "created_utc": 1697469358.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm in a part of my life where I hate my job. I work as a SAP EP consultant with little SAP ABAP handson. Should I continue with this or should I opt to something I am interested in I.e data science/compute vision? \n\nMainly looking from future, career , job security and money. Which one has more benefits say in years so that my future self feels good about today's decision", "author_fullname": "t2_jtjumdnvw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sap ui5 fiori vs data science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1796r9j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697465111.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in a part of my life where I hate my job. I work as a SAP EP consultant with little SAP ABAP handson. Should I continue with this or should I opt to something I am interested in I.e data science/compute vision? &lt;/p&gt;\n\n&lt;p&gt;Mainly looking from future, career , job security and money. Which one has more benefits say in years so that my future self feels good about today&amp;#39;s decision&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1796r9j", "is_robot_indexable": true, "report_reasons": null, "author": "Tasty_Potential7670", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1796r9j/sap_ui5_fiori_vs_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1796r9j/sap_ui5_fiori_vs_data_science/", "subreddit_subscribers": 1087917, "created_utc": 1697465111.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_cj9opj0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Forecasting Using Clickhouse Machine Learning Functions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1796piu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/AhmmTvbhWKsH7k3_B379d_lRqpRHz37iKmo6AX8_PyM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697464979.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "ensembleanalytics.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://ensembleanalytics.io/blog/forecasting-using-clickhouse", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/GDXgjkY_wxXuzWKFmBqEEFo7MQHLxK6vuxRzQCyLf7k.jpg?auto=webp&amp;s=db4ddec34f6a691c4fcfcdd008429da2d2185b17", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/GDXgjkY_wxXuzWKFmBqEEFo7MQHLxK6vuxRzQCyLf7k.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9be836a4b01fe0053375560a5952e61946ccb23f", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/GDXgjkY_wxXuzWKFmBqEEFo7MQHLxK6vuxRzQCyLf7k.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0c150a48cbf8b05a2d0020fb89653c98de49a610", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/GDXgjkY_wxXuzWKFmBqEEFo7MQHLxK6vuxRzQCyLf7k.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8fd41b186c07aad6f3e0b37a23293382db2b6d7d", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/GDXgjkY_wxXuzWKFmBqEEFo7MQHLxK6vuxRzQCyLf7k.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=33e02b2de025c621d7d73c6b61e391c9adf6ebf2", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/GDXgjkY_wxXuzWKFmBqEEFo7MQHLxK6vuxRzQCyLf7k.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a5e8a10d033d693a25136ef2ab403cd9c140af6e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/GDXgjkY_wxXuzWKFmBqEEFo7MQHLxK6vuxRzQCyLf7k.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c19c549c5e58c468bf6e719056ca091f0e0a5603", "width": 1080, "height": 567}], "variants": {}, "id": "aPomnYzYWNP9Z-UauYWgFXore9FRRkxtIboWdYT8bdw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "1796piu", "is_robot_indexable": true, "report_reasons": null, "author": "benjaminwootton81", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1796piu/forecasting_using_clickhouse_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://ensembleanalytics.io/blog/forecasting-using-clickhouse", "subreddit_subscribers": 1087917, "created_utc": 1697464979.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "For my project, I need to identify existing to users to start using a product. \n\nI have different ideas that I want to try, but I would like to have your input.\n\n&amp;#x200B;\n\n**Idea 1**: Cluster existing clients and see if within a cluster a majority of clients are already using the product, meaning that we can recommend it to all clients inside that cluster\n\n&amp;#x200B;\n\n**Idea 2:** Calculate the centroid of all clients that use the product, and using Eucledian distance, find which clients are closest to the centroid, meaning that we could get them to start using the product.\n\n&amp;#x200B;\n\n**Idea 3:** Run a clustering algorithm. Then, select a cluster where the product usage is very high, and another where product usage is very low. From there, I could randomly sample each cluster to train a classifier and run it on other samples to see which clients do we predict could use the product.\n\n&amp;#x200B;\n\nLet me know what you think or if I am on the right track!", "author_fullname": "t2_3mn8s3hq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on my approach for a project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1796ecp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697464128.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For my project, I need to identify existing to users to start using a product. &lt;/p&gt;\n\n&lt;p&gt;I have different ideas that I want to try, but I would like to have your input.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Idea 1&lt;/strong&gt;: Cluster existing clients and see if within a cluster a majority of clients are already using the product, meaning that we can recommend it to all clients inside that cluster&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Idea 2:&lt;/strong&gt; Calculate the centroid of all clients that use the product, and using Eucledian distance, find which clients are closest to the centroid, meaning that we could get them to start using the product.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Idea 3:&lt;/strong&gt; Run a clustering algorithm. Then, select a cluster where the product usage is very high, and another where product usage is very low. From there, I could randomly sample each cluster to train a classifier and run it on other samples to see which clients do we predict could use the product.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Let me know what you think or if I am on the right track!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1796ecp", "is_robot_indexable": true, "report_reasons": null, "author": "datasciencewithmarco", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1796ecp/advice_on_my_approach_for_a_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1796ecp/advice_on_my_approach_for_a_project/", "subreddit_subscribers": 1087917, "created_utc": 1697464128.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a lofistic regression that predicts the probability a customer converta to sale. It has different intercepts based on demographic segment and a coefficient to advertising.\n\nThe problem is very unbalanced, most people will not concert.\n\nNow....I want to use this logistic regression to say how many sales advertising delivered, in absolute terms.\nI.e. you had 1000 sales, 800 were baseline /intercept and 200 are from TV.\n\nHow would you go about solving this?", "author_fullname": "t2_ao7p8weu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interpretation of logistic regression in absolute terms", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17950k5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697459906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a lofistic regression that predicts the probability a customer converta to sale. It has different intercepts based on demographic segment and a coefficient to advertising.&lt;/p&gt;\n\n&lt;p&gt;The problem is very unbalanced, most people will not concert.&lt;/p&gt;\n\n&lt;p&gt;Now....I want to use this logistic regression to say how many sales advertising delivered, in absolute terms.\nI.e. you had 1000 sales, 800 were baseline /intercept and 200 are from TV.&lt;/p&gt;\n\n&lt;p&gt;How would you go about solving this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17950k5", "is_robot_indexable": true, "report_reasons": null, "author": "CombinationThese993", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17950k5/interpretation_of_logistic_regression_in_absolute/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17950k5/interpretation_of_logistic_regression_in_absolute/", "subreddit_subscribers": 1087917, "created_utc": 1697459906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Sharing is caring - Creators can share your trade diary with your Members any time using [Gorudo.io](https://Gorudo.io)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/kyec0yu6hkub1.jpg?width=2048&amp;format=pjpg&amp;auto=webp&amp;s=5bb8633dcf5fb1d7a240fc7d86f5376a0db4e2e3", "author_fullname": "t2_36py9z15", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sharing is caring - with Gorudo.io", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"kyec0yu6hkub1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/kyec0yu6hkub1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fe4f8a3dc8f342ba4e5904a086933f2b8a2b456d"}, {"y": 110, "x": 216, "u": "https://preview.redd.it/kyec0yu6hkub1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b4721b634398351ffdbd7a129a8faaefa8b94a9c"}, {"y": 164, "x": 320, "u": "https://preview.redd.it/kyec0yu6hkub1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ba02126596107c86d13a5ed94f4b5064d1b7233c"}, {"y": 328, "x": 640, "u": "https://preview.redd.it/kyec0yu6hkub1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2ef114dfaa2277834d7137303b660527dda607b4"}, {"y": 493, "x": 960, "u": "https://preview.redd.it/kyec0yu6hkub1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2e1663390ec820f2ad40f7849a461ce86a168d35"}, {"y": 554, "x": 1080, "u": "https://preview.redd.it/kyec0yu6hkub1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=ae2b26ffb57b9e4f3c0acd8c27396b0767157bf6"}], "s": {"y": 1052, "x": 2048, "u": "https://preview.redd.it/kyec0yu6hkub1.jpg?width=2048&amp;format=pjpg&amp;auto=webp&amp;s=5bb8633dcf5fb1d7a240fc7d86f5376a0db4e2e3"}, "id": "kyec0yu6hkub1"}}, "name": "t3_17961eu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/vg2Zv5AzMlOOPvjEGrsTBfgehwy74j9CnqzUjUNbGKQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697463079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sharing is caring - Creators can share your trade diary with your Members any time using &lt;a href=\"https://Gorudo.io\"&gt;Gorudo.io&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/kyec0yu6hkub1.jpg?width=2048&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=5bb8633dcf5fb1d7a240fc7d86f5376a0db4e2e3\"&gt;https://preview.redd.it/kyec0yu6hkub1.jpg?width=2048&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=5bb8633dcf5fb1d7a240fc7d86f5376a0db4e2e3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17961eu", "is_robot_indexable": true, "report_reasons": null, "author": "orangepie000", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17961eu/sharing_is_caring_with_gorudoio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17961eu/sharing_is_caring_with_gorudoio/", "subreddit_subscribers": 1087917, "created_utc": 1697463079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My company is starting to roll out AI tools (think Github Co-Pilot and internal chatbots). I told my boss that I have already been using these things and basically use them every day (which is true). He was very impressed and told me to present to the team about how to use AI to do our job.\n\n Overall I think this was a good way to score free points with my boss, who is somewhat technical but also boomer. In reality I think my team is already using these tools to some extent and will be hard to teach them anything new by doing this. However, I still want to do the training mostly to show off to my boss. He says he wants to use it but has never gotten around to it.\n\nI really do use these tools often and could show real-world cases where it's helped out. That being said, I still want to be careful about how I do this to avoid it being gimmicky.\nHow should I approach this? Anything in particular I should show?\n\nI am not specifically a data scientist but assume we use a similar tech setup (Python / R / SQL, creating reports etc)", "author_fullname": "t2_19f7pjd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I do an AI Training for my team without it being totally gimmicky? Is it even possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179kwrd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697501264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is starting to roll out AI tools (think Github Co-Pilot and internal chatbots). I told my boss that I have already been using these things and basically use them every day (which is true). He was very impressed and told me to present to the team about how to use AI to do our job.&lt;/p&gt;\n\n&lt;p&gt;Overall I think this was a good way to score free points with my boss, who is somewhat technical but also boomer. In reality I think my team is already using these tools to some extent and will be hard to teach them anything new by doing this. However, I still want to do the training mostly to show off to my boss. He says he wants to use it but has never gotten around to it.&lt;/p&gt;\n\n&lt;p&gt;I really do use these tools often and could show real-world cases where it&amp;#39;s helped out. That being said, I still want to be careful about how I do this to avoid it being gimmicky.\nHow should I approach this? Anything in particular I should show?&lt;/p&gt;\n\n&lt;p&gt;I am not specifically a data scientist but assume we use a similar tech setup (Python / R / SQL, creating reports etc)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179kwrd", "is_robot_indexable": true, "report_reasons": null, "author": "throwaWayne2", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/", "subreddit_subscribers": 1087917, "created_utc": 1697501264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Why we cannot use GAN's inplace of LSTM for any recurrent neural network for time series forcasting.\nAs we can plot univariate time series on plot and train GaN's to complete that plot.\n\nNot so much work is in going on this feild.\nWhy ?", "author_fullname": "t2_an5w3ncs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series forcasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179q60m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697517330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why we cannot use GAN&amp;#39;s inplace of LSTM for any recurrent neural network for time series forcasting.\nAs we can plot univariate time series on plot and train GaN&amp;#39;s to complete that plot.&lt;/p&gt;\n\n&lt;p&gt;Not so much work is in going on this feild.\nWhy ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179q60m", "is_robot_indexable": true, "report_reasons": null, "author": "Awkward-Block-5005", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179q60m/time_series_forcasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179q60m/time_series_forcasting/", "subreddit_subscribers": 1087917, "created_utc": 1697517330.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}