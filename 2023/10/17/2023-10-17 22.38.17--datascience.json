{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Folks\n\nI am currently working as  Senior ML Engineer on a startup in Dubai. I am 28 years old and getting 120k USD yearly. (no tax).\n\nActually, I am living a good life here, its close to my home country (Turkey), so I can see my family easily and we are almost in same timezone. But the quality of things we are doing here not that good, and I am not sure can I grow in my career here in long run. I don't want to move to Europe because as I can see salaries are very low . If I stay in Dubai getting a salary around 150k in 2 years in here is very doable for me now.\n\nI started considering to move to USA. I found hybrid master programs (first year is remote second year is USA and I can OPT). So I don't have to sacrifice my 2 years to go USA. Probably I will stay without a job just one year.\n\nDo you have any advice for me? Is moving to USA changing my lifestyle, and making sacrifices (time, masters, moving to USA, money etc) worth it?  \n\n\n&amp;#x200B;", "author_fullname": "t2_auxp06r9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving to USA or Staying in UAE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179uwm2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 40, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 40, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697537235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Folks&lt;/p&gt;\n\n&lt;p&gt;I am currently working as  Senior ML Engineer on a startup in Dubai. I am 28 years old and getting 120k USD yearly. (no tax).&lt;/p&gt;\n\n&lt;p&gt;Actually, I am living a good life here, its close to my home country (Turkey), so I can see my family easily and we are almost in same timezone. But the quality of things we are doing here not that good, and I am not sure can I grow in my career here in long run. I don&amp;#39;t want to move to Europe because as I can see salaries are very low . If I stay in Dubai getting a salary around 150k in 2 years in here is very doable for me now.&lt;/p&gt;\n\n&lt;p&gt;I started considering to move to USA. I found hybrid master programs (first year is remote second year is USA and I can OPT). So I don&amp;#39;t have to sacrifice my 2 years to go USA. Probably I will stay without a job just one year.&lt;/p&gt;\n\n&lt;p&gt;Do you have any advice for me? Is moving to USA changing my lifestyle, and making sacrifices (time, masters, moving to USA, money etc) worth it?  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179uwm2", "is_robot_indexable": true, "report_reasons": null, "author": "Round_Inflation_2199", "discussion_type": null, "num_comments": 55, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/", "subreddit_subscribers": 1088599, "created_utc": 1697537235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! I am dealing with a specific problem: predicting the maximum number of cars that can stop in a parking lot on a daily basis. We have multiple parking lots in a region, each with a fixed number of parking slots. These slots are used multiple times throughout the day. I have access to historical data, including information on the time cars spent in the slots, the number of cars in any given period, the number of empty slots during specific time periods, and statistics for nearby areas.\n\nThe goal is to predict, for each parking lot, the maximum number of cars it can accommodate on each day during the pre-Christmas period. It's important to note that historically, none of the parking lots have probably reached their maximum capacity.\n\nAdditionally, we are faced with a challenge related to new parking lots. These lots lack extensive historical data, and many people may not be aware of their existence.\n\nHow would you recommend approaching this task?", "author_fullname": "t2_lku7zyn1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predict maximum capacity of parking lots", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179ub5l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697534713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I am dealing with a specific problem: predicting the maximum number of cars that can stop in a parking lot on a daily basis. We have multiple parking lots in a region, each with a fixed number of parking slots. These slots are used multiple times throughout the day. I have access to historical data, including information on the time cars spent in the slots, the number of cars in any given period, the number of empty slots during specific time periods, and statistics for nearby areas.&lt;/p&gt;\n\n&lt;p&gt;The goal is to predict, for each parking lot, the maximum number of cars it can accommodate on each day during the pre-Christmas period. It&amp;#39;s important to note that historically, none of the parking lots have probably reached their maximum capacity.&lt;/p&gt;\n\n&lt;p&gt;Additionally, we are faced with a challenge related to new parking lots. These lots lack extensive historical data, and many people may not be aware of their existence.&lt;/p&gt;\n\n&lt;p&gt;How would you recommend approaching this task?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179ub5l", "is_robot_indexable": true, "report_reasons": null, "author": "VGFenohmen", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/", "subreddit_subscribers": 1088599, "created_utc": 1697534713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am finishing my my masters degree in data analytics. Previously I've worked as a business analyst for three years. I just had an interview for a data analyst position and I was asked to complete a take home assignment with two parts: a written analysis, and an R project that included a business report with a summary and discussion for recommendations on improving the data reporting. I had 24 from after my interview to return the assignment. I got the exam at 2pm yesterday, so I had until 2pm today. \n\nI got home at 3pm and got the first written portion done yesterday. It involved some simple excel manipulations. Then I had to go to class at 5. Didn't get home till 10pm.\n\nFast forward this morning. I wake up at 8.i get started on the R project at 9am.\n\nThe data was some of the messiness I've seen, and cleaning and transforming the data took four hours. The analysis and visualizations took about one. I know there were some mistakes, and I got the written summary done. But I could not submit the discussion on recommendations. \n\nI'm not here to ask about my likelihood of getting the job. But this task seemed monumental for just 24 hours (i have other obligations like class and a family). Even my worst professors haven't asked me to do anything like that in such a short time. Is this to be expected going forward?", "author_fullname": "t2_fypd1w6xt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Take Home task seemed unreasonable", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a79kw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697572997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am finishing my my masters degree in data analytics. Previously I&amp;#39;ve worked as a business analyst for three years. I just had an interview for a data analyst position and I was asked to complete a take home assignment with two parts: a written analysis, and an R project that included a business report with a summary and discussion for recommendations on improving the data reporting. I had 24 from after my interview to return the assignment. I got the exam at 2pm yesterday, so I had until 2pm today. &lt;/p&gt;\n\n&lt;p&gt;I got home at 3pm and got the first written portion done yesterday. It involved some simple excel manipulations. Then I had to go to class at 5. Didn&amp;#39;t get home till 10pm.&lt;/p&gt;\n\n&lt;p&gt;Fast forward this morning. I wake up at 8.i get started on the R project at 9am.&lt;/p&gt;\n\n&lt;p&gt;The data was some of the messiness I&amp;#39;ve seen, and cleaning and transforming the data took four hours. The analysis and visualizations took about one. I know there were some mistakes, and I got the written summary done. But I could not submit the discussion on recommendations. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not here to ask about my likelihood of getting the job. But this task seemed monumental for just 24 hours (i have other obligations like class and a family). Even my worst professors haven&amp;#39;t asked me to do anything like that in such a short time. Is this to be expected going forward?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a79kw", "is_robot_indexable": true, "report_reasons": null, "author": "wildwildwildebeast", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a79kw/interview_take_home_task_seemed_unreasonable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a79kw/interview_take_home_task_seemed_unreasonable/", "subreddit_subscribers": 1088599, "created_utc": 1697572997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi r/datascience,\n\nFrom my experience working with data orchestration tools (Airflow primarily), I tend to deal with a lot of repetitive fixes with flaky pipelines such as resource exhaustion issues, single malformed entries or other edge cases, figuring out why a task isn't running, and so on. I was wondering whether any of you had the same experience in your day-to-day work. How much of the job is actually just dealing with repetitive issues and maintenance of pipelines, and do any of you know of any tools or tips to make the experience of working with these pipelines less time-consuming?\n\nThanks!", "author_fullname": "t2_mk6o8gs2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Repetitive airflow pipeline problems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179r5li", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697520996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;From my experience working with data orchestration tools (Airflow primarily), I tend to deal with a lot of repetitive fixes with flaky pipelines such as resource exhaustion issues, single malformed entries or other edge cases, figuring out why a task isn&amp;#39;t running, and so on. I was wondering whether any of you had the same experience in your day-to-day work. How much of the job is actually just dealing with repetitive issues and maintenance of pipelines, and do any of you know of any tools or tips to make the experience of working with these pipelines less time-consuming?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179r5li", "is_robot_indexable": true, "report_reasons": null, "author": "dec_dev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/", "subreddit_subscribers": 1088599, "created_utc": 1697520996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This has happened to me twice now, dunno if it\u2019s a new trend in recruitment processes. I\u2019m fine with it, to be honest, because it lets me show that I have the skills necessary for the job. I\u2019m not currently working in DS but in finance with some data analysis, but not much modeling work to show for (even though I have my master\u2019s in a computational quantitative field and so know the stats/theory behind most models).\n\n I didn\u2019t get the first job that required a live-coding exercise because they could only schedule it while I was on vacation and I didn\u2019t feel like I could really prepare, but now with this second position I passed the assignment and I have a 45 minute behavioral interview tomorrow. \n\nJust wondering for anyone who has had a similar recruitment process, does this mean that this recruitment process should be relatively quick? Just this interview and maybe one more technical one? (Am a bit desperate to switch jobs as my current job has a crazy high tempo and it\u2019s hard to find time to interview, which is the main reason I don\u2019t want a super dragged out process)", "author_fullname": "t2_ls91v62g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does it mean to get a take-home assignment before screening call?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179yve1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697551029.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697550765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This has happened to me twice now, dunno if it\u2019s a new trend in recruitment processes. I\u2019m fine with it, to be honest, because it lets me show that I have the skills necessary for the job. I\u2019m not currently working in DS but in finance with some data analysis, but not much modeling work to show for (even though I have my master\u2019s in a computational quantitative field and so know the stats/theory behind most models).&lt;/p&gt;\n\n&lt;p&gt;I didn\u2019t get the first job that required a live-coding exercise because they could only schedule it while I was on vacation and I didn\u2019t feel like I could really prepare, but now with this second position I passed the assignment and I have a 45 minute behavioral interview tomorrow. &lt;/p&gt;\n\n&lt;p&gt;Just wondering for anyone who has had a similar recruitment process, does this mean that this recruitment process should be relatively quick? Just this interview and maybe one more technical one? (Am a bit desperate to switch jobs as my current job has a crazy high tempo and it\u2019s hard to find time to interview, which is the main reason I don\u2019t want a super dragged out process)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179yve1", "is_robot_indexable": true, "report_reasons": null, "author": "Whole-Ad-8370", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/", "subreddit_subscribers": 1088599, "created_utc": 1697550765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,   \n\n\nWe just hired a data analyst to analyse a time series representing a certain commodity value over time, we offered them the possibility to take the price data from a source of their choice, but they insisted that we provide it ourselves. Is this good or bad practice? Could someone give pros and cons of letting the analyst find their own publicly available data vs. the company providing them the data set?   \n\n\nThank you", "author_fullname": "t2_97o8m0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should data-scientists look for their own datasets or be provided by the hiring company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179ztob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697553394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,   &lt;/p&gt;\n\n&lt;p&gt;We just hired a data analyst to analyse a time series representing a certain commodity value over time, we offered them the possibility to take the price data from a source of their choice, but they insisted that we provide it ourselves. Is this good or bad practice? Could someone give pros and cons of letting the analyst find their own publicly available data vs. the company providing them the data set?   &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179ztob", "is_robot_indexable": true, "report_reasons": null, "author": "Cryptocheets", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/", "subreddit_subscribers": 1088599, "created_utc": 1697553394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a musical director on a large cruise ship and am responsible for scheduling sets for 10 different bands around the ships 10 different music venues. I have to work around trivias, parties and shows in the aqua theatre and Theatre and other various venues on the ship. I want to analyze the data I have from Day 1 of the cruise a few weeks ago in a chart. How would you guys go about doing this? Thanks!", "author_fullname": "t2_a3amxwo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cruise Ship Musicians Scheduling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179q91p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697517644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a musical director on a large cruise ship and am responsible for scheduling sets for 10 different bands around the ships 10 different music venues. I have to work around trivias, parties and shows in the aqua theatre and Theatre and other various venues on the ship. I want to analyze the data I have from Day 1 of the cruise a few weeks ago in a chart. How would you guys go about doing this? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179q91p", "is_robot_indexable": true, "report_reasons": null, "author": "SaxTeacher1988", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/", "subreddit_subscribers": 1088599, "created_utc": 1697517644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am aware of a few tools that aid in converting XGBoost decision trees to \"if-then\" statements. I'm curious if anyone has experience with this approach, and how feasible/successful was the outcome?", "author_fullname": "t2_8qqebrm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting XGBoost decision models to \"if-then\" statements", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a6ken", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697571198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am aware of a few tools that aid in converting XGBoost decision trees to &amp;quot;if-then&amp;quot; statements. I&amp;#39;m curious if anyone has experience with this approach, and how feasible/successful was the outcome?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a6ken", "is_robot_indexable": true, "report_reasons": null, "author": "MultiPass10", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a6ken/converting_xgboost_decision_models_to_ifthen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a6ken/converting_xgboost_decision_models_to_ifthen/", "subreddit_subscribers": 1088599, "created_utc": 1697571198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**TL;DR:**\n\nBelow, I describe the info I'm tracking, and an algorithm I want to follow to produce a model that shows which factors matter and which don't. **My question is, does this algorithm already exist in some code library?** Or do I have to code it myself?\n\n**Background:**\n\nI've been keeping a spreadsheet of my sleep habits and energy levels for the last 60 days. I have looked a bit at simple correlations -- the highest correlation so far is (no surprise) the correlation between the number of hours a night I have been sleeping recently, and the energy level I feel in the morning. Other correlations, like drinks of alcohol or caffeine, are lower, but I wonder if they would show a stronger effect if I controlled for other factors.\n\n**Regression algorithm:**\n\nI used to work at a data science company where we would run studies we called \"regression hill climbs\", where we would iterate like this:\n\n1. identify the output factor (AKA \"dependent variable\"); in this case, it would be energy level on a given day\n2. for every input factor (AKA \"independent variable\", e.g. whether I taped my mouth shut the night before), calculate the correlations between it and each other input factor\n3. start with an empty \"model\", a set of independent variables\n4. start with a correlation between model and dependent variable of 0\n5. repeat until no more variables are selected to add to the model:\n   1. filter all candidate independent variables, omitting any with too high a correlation to any of the already selected variables in the model (e.g., must be under a threshold of 0.3; this avoids over-fitting) \n   2. of all remaining candidate independent variables, try adding each to the model, and running a new regression on the model's variables (to best predict the dependent variable)\n   3. select the candidate independent variable that most increased the resulting correlation between model and dependent variable, if and only if the increase is above some threshold (e.g., .02 improvement in correlation)\n\nThis results in a model whose total number of independent variables is small, where each is not influenced too much by the others, and where you can see how significant it is (and whether it is positive or negative!). \n\n**Why it matters:**\n\nFor instance, if I have nights where I'm more disciplined overall -- say, when I don't drink, I go to bed early, I set up my CPAP machine and use it all night, etc. -- it might turn out that there's a high (negative) correlation between drinking and sleep quality, but the model may omit alcohol as a variable because its value is really just captured entirely in hours of sleep and in CPAP compliance.\n\nOr, maybe, even taking these things into account, drinking alcohol does consistently disturb my sleep quality, and I should stop. Or maybe it has a slight positive effect! The point is, it's very hard to isolate it as a factor; this algorithm helps.\n\n**What I'm looking for:**\n\nA code library -- presumably in python -- that is built to perform such a \"regression hill climb\", and allow for the various thresholds and other settings to be specified.\n\nDoes anyone know of such a library? Or, is there something different I should do, or some way I'm misunderstanding the problem?\n\nThanks!", "author_fullname": "t2_1why", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Q: How to extract learnings from my spreadsheets, beyond simple correlations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a2wb4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697561640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Below, I describe the info I&amp;#39;m tracking, and an algorithm I want to follow to produce a model that shows which factors matter and which don&amp;#39;t. &lt;strong&gt;My question is, does this algorithm already exist in some code library?&lt;/strong&gt; Or do I have to code it myself?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been keeping a spreadsheet of my sleep habits and energy levels for the last 60 days. I have looked a bit at simple correlations -- the highest correlation so far is (no surprise) the correlation between the number of hours a night I have been sleeping recently, and the energy level I feel in the morning. Other correlations, like drinks of alcohol or caffeine, are lower, but I wonder if they would show a stronger effect if I controlled for other factors.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Regression algorithm:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I used to work at a data science company where we would run studies we called &amp;quot;regression hill climbs&amp;quot;, where we would iterate like this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;identify the output factor (AKA &amp;quot;dependent variable&amp;quot;); in this case, it would be energy level on a given day&lt;/li&gt;\n&lt;li&gt;for every input factor (AKA &amp;quot;independent variable&amp;quot;, e.g. whether I taped my mouth shut the night before), calculate the correlations between it and each other input factor&lt;/li&gt;\n&lt;li&gt;start with an empty &amp;quot;model&amp;quot;, a set of independent variables&lt;/li&gt;\n&lt;li&gt;start with a correlation between model and dependent variable of 0&lt;/li&gt;\n&lt;li&gt;repeat until no more variables are selected to add to the model:\n\n&lt;ol&gt;\n&lt;li&gt;filter all candidate independent variables, omitting any with too high a correlation to any of the already selected variables in the model (e.g., must be under a threshold of 0.3; this avoids over-fitting) &lt;/li&gt;\n&lt;li&gt;of all remaining candidate independent variables, try adding each to the model, and running a new regression on the model&amp;#39;s variables (to best predict the dependent variable)&lt;/li&gt;\n&lt;li&gt;select the candidate independent variable that most increased the resulting correlation between model and dependent variable, if and only if the increase is above some threshold (e.g., .02 improvement in correlation)&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This results in a model whose total number of independent variables is small, where each is not influenced too much by the others, and where you can see how significant it is (and whether it is positive or negative!). &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why it matters:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;For instance, if I have nights where I&amp;#39;m more disciplined overall -- say, when I don&amp;#39;t drink, I go to bed early, I set up my CPAP machine and use it all night, etc. -- it might turn out that there&amp;#39;s a high (negative) correlation between drinking and sleep quality, but the model may omit alcohol as a variable because its value is really just captured entirely in hours of sleep and in CPAP compliance.&lt;/p&gt;\n\n&lt;p&gt;Or, maybe, even taking these things into account, drinking alcohol does consistently disturb my sleep quality, and I should stop. Or maybe it has a slight positive effect! The point is, it&amp;#39;s very hard to isolate it as a factor; this algorithm helps.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I&amp;#39;m looking for:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;A code library -- presumably in python -- that is built to perform such a &amp;quot;regression hill climb&amp;quot;, and allow for the various thresholds and other settings to be specified.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know of such a library? Or, is there something different I should do, or some way I&amp;#39;m misunderstanding the problem?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a2wb4", "is_robot_indexable": true, "report_reasons": null, "author": "brw12", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a2wb4/q_how_to_extract_learnings_from_my_spreadsheets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a2wb4/q_how_to_extract_learnings_from_my_spreadsheets/", "subreddit_subscribers": 1088599, "created_utc": 1697561640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey Guys,  \nIt seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo'd vector dbs.   \n\n\nDo you guys think there's any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone's raving about today)  \n\n\n\\-  \n\n\nFor context, I'm building a social media product we're users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche's classification string. Essentially we're aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. ", "author_fullname": "t2_13im86", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shared Public Contextual Database for RAG", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179z4yq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697551500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Guys,&lt;br/&gt;\nIt seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo&amp;#39;d vector dbs.   &lt;/p&gt;\n\n&lt;p&gt;Do you guys think there&amp;#39;s any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone&amp;#39;s raving about today)  &lt;/p&gt;\n\n&lt;p&gt;-  &lt;/p&gt;\n\n&lt;p&gt;For context, I&amp;#39;m building a social media product we&amp;#39;re users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche&amp;#39;s classification string. Essentially we&amp;#39;re aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179z4yq", "is_robot_indexable": true, "report_reasons": null, "author": "niksteel123", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/", "subreddit_subscribers": 1088599, "created_utc": 1697551500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Build Data Products? Deploy: Part 3/4 - Doubling down on the power of Unified Experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_179ykfd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fIAPxsCawPBu-N75Vvoyg_keOmRvMjS4W4feJpzH2AE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697549881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/how-to-build-data-products-deploy", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?auto=webp&amp;s=ea619a7c524f8c5536cc06f8b13ba792caddd5b5", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=66add8fac528d26de7feccdd0c5022d39fd89850", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=85446cd271d715b3865f735be872ce747366b093", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=929b190abb183f4784a7d725a150dbb2083ba894", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e4c400d8251d52d7421fc6640499a17ea524db3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5e716ed51284478d9d2a2569fdf859fe895fdf91", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5219b40b806ce0099e4650da1d92ec438c0e19d8", "width": 1080, "height": 540}], "variants": {}, "id": "_WJ_OVW7dv_Q8Y2muH3UxiO88vjiOO6xTcwW1zV8-tA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "179ykfd", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179ykfd/how_to_build_data_products_deploy_part_34/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/how-to-build-data-products-deploy", "subreddit_subscribers": 1088599, "created_utc": 1697549881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My company is starting to roll out AI tools (think Github Co-Pilot and internal chatbots). I told my boss that I have already been using these things and basically use them every day (which is true). He was very impressed and told me to present to the team about how to use AI to do our job.\n\n Overall I think this was a good way to score free points with my boss, who is somewhat technical but also boomer. In reality I think my team is already using these tools to some extent and will be hard to teach them anything new by doing this. However, I still want to do the training mostly to show off to my boss. He says he wants to use it but has never gotten around to it.\n\nI really do use these tools often and could show real-world cases where it's helped out. That being said, I still want to be careful about how I do this to avoid it being gimmicky.\nHow should I approach this? Anything in particular I should show?\n\nI am not specifically a data scientist but assume we use a similar tech setup (Python / R / SQL, creating reports etc)", "author_fullname": "t2_19f7pjd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I do an AI Training for my team without it being totally gimmicky? Is it even possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179kwrd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697501264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is starting to roll out AI tools (think Github Co-Pilot and internal chatbots). I told my boss that I have already been using these things and basically use them every day (which is true). He was very impressed and told me to present to the team about how to use AI to do our job.&lt;/p&gt;\n\n&lt;p&gt;Overall I think this was a good way to score free points with my boss, who is somewhat technical but also boomer. In reality I think my team is already using these tools to some extent and will be hard to teach them anything new by doing this. However, I still want to do the training mostly to show off to my boss. He says he wants to use it but has never gotten around to it.&lt;/p&gt;\n\n&lt;p&gt;I really do use these tools often and could show real-world cases where it&amp;#39;s helped out. That being said, I still want to be careful about how I do this to avoid it being gimmicky.\nHow should I approach this? Anything in particular I should show?&lt;/p&gt;\n\n&lt;p&gt;I am not specifically a data scientist but assume we use a similar tech setup (Python / R / SQL, creating reports etc)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179kwrd", "is_robot_indexable": true, "report_reasons": null, "author": "throwaWayne2", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/", "subreddit_subscribers": 1088599, "created_utc": 1697501264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What factors should I consider when deciding between enrolling in a traditional course or attending a boot camp for data science? I want to make a career switch and was wondering the difference between them. Any suggestions on where to begin would be greatly appreciated.", "author_fullname": "t2_m7ciapyh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where to start?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17a8iv1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697576512.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697576302.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What factors should I consider when deciding between enrolling in a traditional course or attending a boot camp for data science? I want to make a career switch and was wondering the difference between them. Any suggestions on where to begin would be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a8iv1", "is_robot_indexable": true, "report_reasons": null, "author": "CompetitiveCollar991", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a8iv1/where_to_start/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a8iv1/where_to_start/", "subreddit_subscribers": 1088599, "created_utc": 1697576302.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHello, fellow data science enthusiasts! I'm participating in some machine learning competitions and I'm looking for insights on the strengths and weaknesses of various ML algorithms, along with their ideal use cases. This will help me choose the most suitable model for my competition tasks. Your expert opinions would be highly valuable!\n\n1. Could you please share your thoughts on the strengths and weaknesses of different ML algorithms, considering factors like accuracy, interpretability, computational requirements, etc.?\n2. What are some specific use cases or scenarios where certain ML algorithms excel? For example, which algorithms are best for image classification, natural language processing, or time series forecasting?\n3. Are there any resources, articles, or books that you would recommend for a deeper understanding of ML algorithm selection?\n\nYour insights will be greatly appreciated and will aid me in making more informed decisions for my competition endeavors. Thanks in advance!\"", "author_fullname": "t2_hhycptpk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice on Machine Learning Algorithm Selection for Competitions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a6t46", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697571824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, fellow data science enthusiasts! I&amp;#39;m participating in some machine learning competitions and I&amp;#39;m looking for insights on the strengths and weaknesses of various ML algorithms, along with their ideal use cases. This will help me choose the most suitable model for my competition tasks. Your expert opinions would be highly valuable!&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Could you please share your thoughts on the strengths and weaknesses of different ML algorithms, considering factors like accuracy, interpretability, computational requirements, etc.?&lt;/li&gt;\n&lt;li&gt;What are some specific use cases or scenarios where certain ML algorithms excel? For example, which algorithms are best for image classification, natural language processing, or time series forecasting?&lt;/li&gt;\n&lt;li&gt;Are there any resources, articles, or books that you would recommend for a deeper understanding of ML algorithm selection?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Your insights will be greatly appreciated and will aid me in making more informed decisions for my competition endeavors. Thanks in advance!&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a6t46", "is_robot_indexable": true, "report_reasons": null, "author": "After_Reception1696", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a6t46/seeking_advice_on_machine_learning_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a6t46/seeking_advice_on_machine_learning_algorithm/", "subreddit_subscribers": 1088599, "created_utc": 1697571824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm building price tracker and want to plot prices over time for few dozens products. Seaborn relplot alike functions are pretty slow and I want to limit script run time to minimum.\n\nI thought about 2 solutions:\n\n1. sample data for each product in a way that keeps 'outliers' in dataset (i.e. spikes for visibility and dips to get notified that maybe it's time to buy it). Not sure if it's easy \n2. get rid of data points for which data trends flat based on moving average\n\n&amp;#x200B;\n\nAny better idea that is easy to implement?\n\n&amp;#x200B;", "author_fullname": "t2_5iv2njiq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series data filtering - keep outliers and remove only flat trend", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a5u8t", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697569289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m building price tracker and want to plot prices over time for few dozens products. Seaborn relplot alike functions are pretty slow and I want to limit script run time to minimum.&lt;/p&gt;\n\n&lt;p&gt;I thought about 2 solutions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;sample data for each product in a way that keeps &amp;#39;outliers&amp;#39; in dataset (i.e. spikes for visibility and dips to get notified that maybe it&amp;#39;s time to buy it). Not sure if it&amp;#39;s easy &lt;/li&gt;\n&lt;li&gt;get rid of data points for which data trends flat based on moving average&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any better idea that is easy to implement?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a5u8t", "is_robot_indexable": true, "report_reasons": null, "author": "ratatsnow", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a5u8t/time_series_data_filtering_keep_outliers_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a5u8t/time_series_data_filtering_keep_outliers_and/", "subreddit_subscribers": 1088599, "created_utc": 1697569289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking for a detailed glossary of terms in data scientist that an experienced data scientist should know. It's mostly for myself to test my knowledge. Anything from regression types to p values and much more.", "author_fullname": "t2_k79vgi4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have a good glossary for data science?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a5thj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697569244.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for a detailed glossary of terms in data scientist that an experienced data scientist should know. It&amp;#39;s mostly for myself to test my knowledge. Anything from regression types to p values and much more.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a5thj", "is_robot_indexable": true, "report_reasons": null, "author": "TheOmerAngi", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a5thj/does_anyone_have_a_good_glossary_for_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a5thj/does_anyone_have_a_good_glossary_for_data_science/", "subreddit_subscribers": 1088599, "created_utc": 1697569244.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey fellow Redditors!\n\nEver wondered how technology can tackle a range of challenges like signature authentication, detecting cheaters in games, assessing neurological conditions, or dealing with pesky bots? The answer lies in the fascinating world of human motion analysis!\n\nIn this discussion, we delve into the concept of \"features\" in the context of human motion. Features are scalar values obtained from motion segments, offering insights into movement patterns. We explore how these features are essential in addressing diverse challenges and share insights into the basic features of movements.\n\n# \ud83d\udca1 What's a Feature?  \n\nIn this context, a feature refers to a scalar value obtained from a motion segment. For example, the average acceleration of a cursor. As depicted in the diagram below, users cannot be distinguished solely based on their average acceleration, but there are discernible individual tendencies.\n\n The next step involves constructing our feature space by identifying features that contain relevant information about movement patterns. \n\n# \ud83d\udcca Analyzing the appropriate time series\n\nThe majority of the data we work with consists of x and y coordinates that change over time, such as the position of a cursor or a pen on a screen. Therefore, we already have two time series. Additionally, we calculate directional speeds, accelerations, jerks, as well as direction-independent speed, acceleration, and jerk. \n\n**Unmasking forgery through speed analysis**\n\nLet\u2019s explain the use of derivatives through an example of **signature forgery**. Suppose someone attempts to replicate a signature they have seen before, familiar with its form. How would you approach this situation? Initially, one might **meticulously trace the line to be replicated, proceeding slowly and accurately**, inch by inch. The result would be a slow, nearly constant-speed movement. **The speed time series would exhibit an approximately constant value.**\n\nNow, imagine **someone writing their own signature**. **The speed can vary significantly**, but it won\u2019t remain constant. They would draw longer, straight lines more quickly and slow down at tight turns. When moving right and upwards, the arcs would be faster and more dynamic than when turning left. Even if the forged signature\u2019s image is an exact copy of the genuine one in terms of x-y coordinates, **the speed profiles would look entirely different.**\n\nOf course, this was a rather clumsy attempt at forgery; there are far more skilled individuals in this field. The speed of a signature can be estimated based on the signature image alone, either by assuming faster movement on straight lines and slower movement on curves or by considering the line quality.\n\nDelving into the details is beyond the scope of this discussion, but the key point is that estimating and replicating the speed of motion requires practice and talent. It is more challenging than simply replicating the x-y coordinates of the signature image. Moreover, forging the acceleration and other factors becomes even more difficult.\n\nIn theory, we could **take derivatives of our time series as many times as desired**. However, there is a practical limit as, **after a certain point, the derivative becomes more noise than meaningful information.**\n\nFrom this example, it becomes apparent why we thought utilizing derivatives (speed, acceleration, jerk) was a valuable approach for motion analysis. **When we began using this method, the results demonstrated exceptional accuracy**.\n\n# \ud83d\udd0d Describing Time Series with Scalar Values \n\n We have extracted various time series from our motion sample. To condense the valuable information of a lengthy time series into scalar values, **we employ a straightforward approach: calculating a few statistical characteristics**. Our selection criteria ensure that these characteristics effectively represent the distribution of the time series.\n\nSome of these characteristics are expected, such as the minimum, maximum, mean, and standard deviation.\n\nTo understand how the values progress from the minimum to the maximum, we utilize percentiles, including the 10th, 25th, 50th, 75th, and 90th percentiles. The minimum and maximum values are also considered as percentiles, specifically the 0th and 100th percentiles.\n\nTwo lesser-known statistical values are skewness and kurtosis. **Skewness measures the asymmetry of a distribution**. For instance, if the speed values below and above the average speed are evenly spaced, the skewness will be around zero. However, if there are numerous values below the mean but close to it, with only a few exceptionally high values above, the skewness will be positive.\n\nIn the context of cursor movement, this suggests that an individual typically uses the cursor at a relatively constant speed, but occasionally makes sudden moves. This could be a personal habit or characteristic.\n\nOn the other hand, **kurtosis indicates whether the values are concentrated around the mean or spread out across a broader range**.\n\nThese are the basic features we utilize for analysis.\n\nFeel free to join the discussion and share your thoughts on this fascinating intersection of technology and human motion analysis! \ud83d\udcac\ud83d\udd7a\ud83c\udffd\ud83d\udcbb", "author_fullname": "t2_gbypvyyx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cracking the Code of Human Motion: Describing Movement Patterns with Scalar Values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179u12d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697533471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors!&lt;/p&gt;\n\n&lt;p&gt;Ever wondered how technology can tackle a range of challenges like signature authentication, detecting cheaters in games, assessing neurological conditions, or dealing with pesky bots? The answer lies in the fascinating world of human motion analysis!&lt;/p&gt;\n\n&lt;p&gt;In this discussion, we delve into the concept of &amp;quot;features&amp;quot; in the context of human motion. Features are scalar values obtained from motion segments, offering insights into movement patterns. We explore how these features are essential in addressing diverse challenges and share insights into the basic features of movements.&lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udca1 What&amp;#39;s a Feature?&lt;/h1&gt;\n\n&lt;p&gt;In this context, a feature refers to a scalar value obtained from a motion segment. For example, the average acceleration of a cursor. As depicted in the diagram below, users cannot be distinguished solely based on their average acceleration, but there are discernible individual tendencies.&lt;/p&gt;\n\n&lt;p&gt;The next step involves constructing our feature space by identifying features that contain relevant information about movement patterns. &lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udcca Analyzing the appropriate time series&lt;/h1&gt;\n\n&lt;p&gt;The majority of the data we work with consists of x and y coordinates that change over time, such as the position of a cursor or a pen on a screen. Therefore, we already have two time series. Additionally, we calculate directional speeds, accelerations, jerks, as well as direction-independent speed, acceleration, and jerk. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Unmasking forgery through speed analysis&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Let\u2019s explain the use of derivatives through an example of &lt;strong&gt;signature forgery&lt;/strong&gt;. Suppose someone attempts to replicate a signature they have seen before, familiar with its form. How would you approach this situation? Initially, one might &lt;strong&gt;meticulously trace the line to be replicated, proceeding slowly and accurately&lt;/strong&gt;, inch by inch. The result would be a slow, nearly constant-speed movement. &lt;strong&gt;The speed time series would exhibit an approximately constant value.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Now, imagine &lt;strong&gt;someone writing their own signature&lt;/strong&gt;. &lt;strong&gt;The speed can vary significantly&lt;/strong&gt;, but it won\u2019t remain constant. They would draw longer, straight lines more quickly and slow down at tight turns. When moving right and upwards, the arcs would be faster and more dynamic than when turning left. Even if the forged signature\u2019s image is an exact copy of the genuine one in terms of x-y coordinates, &lt;strong&gt;the speed profiles would look entirely different.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Of course, this was a rather clumsy attempt at forgery; there are far more skilled individuals in this field. The speed of a signature can be estimated based on the signature image alone, either by assuming faster movement on straight lines and slower movement on curves or by considering the line quality.&lt;/p&gt;\n\n&lt;p&gt;Delving into the details is beyond the scope of this discussion, but the key point is that estimating and replicating the speed of motion requires practice and talent. It is more challenging than simply replicating the x-y coordinates of the signature image. Moreover, forging the acceleration and other factors becomes even more difficult.&lt;/p&gt;\n\n&lt;p&gt;In theory, we could &lt;strong&gt;take derivatives of our time series as many times as desired&lt;/strong&gt;. However, there is a practical limit as, &lt;strong&gt;after a certain point, the derivative becomes more noise than meaningful information.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;From this example, it becomes apparent why we thought utilizing derivatives (speed, acceleration, jerk) was a valuable approach for motion analysis. &lt;strong&gt;When we began using this method, the results demonstrated exceptional accuracy&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udd0d Describing Time Series with Scalar Values&lt;/h1&gt;\n\n&lt;p&gt;We have extracted various time series from our motion sample. To condense the valuable information of a lengthy time series into scalar values, &lt;strong&gt;we employ a straightforward approach: calculating a few statistical characteristics&lt;/strong&gt;. Our selection criteria ensure that these characteristics effectively represent the distribution of the time series.&lt;/p&gt;\n\n&lt;p&gt;Some of these characteristics are expected, such as the minimum, maximum, mean, and standard deviation.&lt;/p&gt;\n\n&lt;p&gt;To understand how the values progress from the minimum to the maximum, we utilize percentiles, including the 10th, 25th, 50th, 75th, and 90th percentiles. The minimum and maximum values are also considered as percentiles, specifically the 0th and 100th percentiles.&lt;/p&gt;\n\n&lt;p&gt;Two lesser-known statistical values are skewness and kurtosis. &lt;strong&gt;Skewness measures the asymmetry of a distribution&lt;/strong&gt;. For instance, if the speed values below and above the average speed are evenly spaced, the skewness will be around zero. However, if there are numerous values below the mean but close to it, with only a few exceptionally high values above, the skewness will be positive.&lt;/p&gt;\n\n&lt;p&gt;In the context of cursor movement, this suggests that an individual typically uses the cursor at a relatively constant speed, but occasionally makes sudden moves. This could be a personal habit or characteristic.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, &lt;strong&gt;kurtosis indicates whether the values are concentrated around the mean or spread out across a broader range&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;These are the basic features we utilize for analysis.&lt;/p&gt;\n\n&lt;p&gt;Feel free to join the discussion and share your thoughts on this fascinating intersection of technology and human motion analysis! \ud83d\udcac\ud83d\udd7a\ud83c\udffd\ud83d\udcbb&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179u12d", "is_robot_indexable": true, "report_reasons": null, "author": "CursorInsight", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/", "subreddit_subscribers": 1088599, "created_utc": 1697533471.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\n\n I work at one of the big 4 consulting companies as a data scientist on their public sector accounts( with security clearance). I was a campus hire who started this year but I had a solid year of experience as a data science intern at a small tech company.  My bachelor degree was in statistics.\n\nI want to move to a data science or data analyst positions at big tech companies. I mainly want to work in analytics and data engineering. How many years of experience would I need to have a decent change?what would you recommend to increase my odds? Should I get a master degree? Where can I go to network other than cold email? Do certifications help?", "author_fullname": "t2_6cbsdgdj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving to Big Tech from big government contractor", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17a9bma", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697578283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I work at one of the big 4 consulting companies as a data scientist on their public sector accounts( with security clearance). I was a campus hire who started this year but I had a solid year of experience as a data science intern at a small tech company.  My bachelor degree was in statistics.&lt;/p&gt;\n\n&lt;p&gt;I want to move to a data science or data analyst positions at big tech companies. I mainly want to work in analytics and data engineering. How many years of experience would I need to have a decent change?what would you recommend to increase my odds? Should I get a master degree? Where can I go to network other than cold email? Do certifications help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a9bma", "is_robot_indexable": true, "report_reasons": null, "author": "Administrative_Bar46", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a9bma/moving_to_big_tech_from_big_government_contractor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a9bma/moving_to_big_tech_from_big_government_contractor/", "subreddit_subscribers": 1088599, "created_utc": 1697578283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "If I get a degree in software engineer. Is it still possible to become a data scientist. Or should I just get a data science degree instead. \n\nAlso. How hard is it to make it in this industry", "author_fullname": "t2_q9h7cz8c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data science with a software engineer degree", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a6ymj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697572214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If I get a degree in software engineer. Is it still possible to become a data scientist. Or should I just get a data science degree instead. &lt;/p&gt;\n\n&lt;p&gt;Also. How hard is it to make it in this industry&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a6ymj", "is_robot_indexable": true, "report_reasons": null, "author": "Comfortable_Owl8841", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a6ymj/data_science_with_a_software_engineer_degree/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a6ymj/data_science_with_a_software_engineer_degree/", "subreddit_subscribers": 1088599, "created_utc": 1697572214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Specifically for Kentucky but I'm trying to get an automated tracker by county (precinct if possible) to keep track of results coming in. I saw some 2020 ones using New York Times in this [comment](https://www.reddit.com/r/rstats/comments/jo1yuw/comment/gmnxfz3/?utm_source=share&amp;utm_medium=web2x&amp;context=3), but can't figure out what it would be for a single state's off off year election\n\n&amp;#x200B;", "author_fullname": "t2_fa0st", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Live 2023 Election Results (Also Future Results)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a5plc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697568957.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Specifically for Kentucky but I&amp;#39;m trying to get an automated tracker by county (precinct if possible) to keep track of results coming in. I saw some 2020 ones using New York Times in this &lt;a href=\"https://www.reddit.com/r/rstats/comments/jo1yuw/comment/gmnxfz3/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;comment&lt;/a&gt;, but can&amp;#39;t figure out what it would be for a single state&amp;#39;s off off year election&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a5plc", "is_robot_indexable": true, "report_reasons": null, "author": "KobeOrNotKobe", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a5plc/live_2023_election_results_also_future_results/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a5plc/live_2023_election_results_also_future_results/", "subreddit_subscribers": 1088599, "created_utc": 1697568957.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\n&amp;#x200B;\n\nI have access through my school to LinkedIn learning. I saw that they have different paths for python and data science, business intelligence, and data analyst.   \nHas anyone tried them or what do you guys think of them?  \nI saw these paths: Advance Your Python Skills for Data Science, Become a Business Intelligence Specialist, Getting Started as Business Analyst, and Become a Data Analyst.\n\n&amp;#x200B;\n\nIs it worth giving a try to any of these? I would be interested either in Business Intelligence or the Data Analyst one. I do have some time so could use the input before I just jump into one. My interest is to gain data analysis knowledge and make a transition over time. My background is in higher education and currently teach at the uni but do not see myself doing that for a long time.\n\n&amp;#x200B;\n\nAppreciate the input or help.", "author_fullname": "t2_3gvpw9l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How good are the Linkedin Learning Paths?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a25ns", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697559655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have access through my school to LinkedIn learning. I saw that they have different paths for python and data science, business intelligence, and data analyst.&lt;br/&gt;\nHas anyone tried them or what do you guys think of them?&lt;br/&gt;\nI saw these paths: Advance Your Python Skills for Data Science, Become a Business Intelligence Specialist, Getting Started as Business Analyst, and Become a Data Analyst.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Is it worth giving a try to any of these? I would be interested either in Business Intelligence or the Data Analyst one. I do have some time so could use the input before I just jump into one. My interest is to gain data analysis knowledge and make a transition over time. My background is in higher education and currently teach at the uni but do not see myself doing that for a long time.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Appreciate the input or help.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a25ns", "is_robot_indexable": true, "report_reasons": null, "author": "forgotendream", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a25ns/how_good_are_the_linkedin_learning_paths/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a25ns/how_good_are_the_linkedin_learning_paths/", "subreddit_subscribers": 1088599, "created_utc": 1697559655.0, "num_crossposts": 2, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "How to learn Data Science? Can somebody give me a clear guide.\n\nI am currently training to become a data engineer. I have basics in Cloud platforms like AWS and google. I have also worked with some tools. I was part of a few developed migration projects as well. I have good knowledge in python and sql(strong in basics). Currently, I am learning spark using databricks. I have certifications in Aws , google and a snowflake certification.\n\nWhat would be the best way for me to grow in the data industry.(become a data scientist).\n\nI also want to learn machine learning and deep learning in depth(any guides for this)?\n\nDo you know any books for me to learn the mathematics required in Data science, AI and machine learning(deep learning)", "author_fullname": "t2_gis6t0ly9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Science Help for fresher.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a6n6w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697571406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How to learn Data Science? Can somebody give me a clear guide.&lt;/p&gt;\n\n&lt;p&gt;I am currently training to become a data engineer. I have basics in Cloud platforms like AWS and google. I have also worked with some tools. I was part of a few developed migration projects as well. I have good knowledge in python and sql(strong in basics). Currently, I am learning spark using databricks. I have certifications in Aws , google and a snowflake certification.&lt;/p&gt;\n\n&lt;p&gt;What would be the best way for me to grow in the data industry.(become a data scientist).&lt;/p&gt;\n\n&lt;p&gt;I also want to learn machine learning and deep learning in depth(any guides for this)?&lt;/p&gt;\n\n&lt;p&gt;Do you know any books for me to learn the mathematics required in Data science, AI and machine learning(deep learning)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a6n6w", "is_robot_indexable": true, "report_reasons": null, "author": "LogicalMethod7055", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a6n6w/data_science_help_for_fresher/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a6n6w/data_science_help_for_fresher/", "subreddit_subscribers": 1088599, "created_utc": 1697571406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Why we cannot use GAN's inplace of LSTM for any recurrent neural network for time series forcasting.\nAs we can plot univariate time series on plot and train GaN's to complete that plot.\n\nNot so much work is in going on this feild.\nWhy ?", "author_fullname": "t2_an5w3ncs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series forcasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179q60m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697517330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why we cannot use GAN&amp;#39;s inplace of LSTM for any recurrent neural network for time series forcasting.\nAs we can plot univariate time series on plot and train GaN&amp;#39;s to complete that plot.&lt;/p&gt;\n\n&lt;p&gt;Not so much work is in going on this feild.\nWhy ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179q60m", "is_robot_indexable": true, "report_reasons": null, "author": "Awkward-Block-5005", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179q60m/time_series_forcasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179q60m/time_series_forcasting/", "subreddit_subscribers": 1088599, "created_utc": 1697517330.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}