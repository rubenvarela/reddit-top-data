{"kind": "Listing", "data": {"after": null, "dist": 18, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_1nnh1bpq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meme Mondays", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 130, "top_awarded_type": null, "hide_score": false, "name": "t3_179huzu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.98, "author_flair_background_color": null, "ups": 982, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 982, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/BdGMg8NR_z8b0B8Rfbl09b-bmsvud6q9Csn2tMDUsw8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697493093.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/zxdz4pm6ymub1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/zxdz4pm6ymub1.png?auto=webp&amp;s=bafa17f40ac4179a1a5101469047fdf761d9e368", "width": 680, "height": 635}, "resolutions": [{"url": "https://preview.redd.it/zxdz4pm6ymub1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=050c61142ad3c3a892a954c5a0050105a0d017ac", "width": 108, "height": 100}, {"url": "https://preview.redd.it/zxdz4pm6ymub1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=5e6f2a05e3dcdd7a7a9262d4c6c18ef3167c286a", "width": 216, "height": 201}, {"url": "https://preview.redd.it/zxdz4pm6ymub1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f3ceaa5fb8aec7bedacb24e0d1397aa04efac36d", "width": 320, "height": 298}, {"url": "https://preview.redd.it/zxdz4pm6ymub1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=83f219046f9b0a24698eb124ca95c5252dc5fb23", "width": 640, "height": 597}], "variants": {}, "id": "k5LehGeHkzqss6xyqVg5nrMab3CMDiKroOLp715TRoc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "179huzu", "is_robot_indexable": true, "report_reasons": null, "author": "softwareitcounts", "discussion_type": null, "num_comments": 49, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179huzu/meme_mondays/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/zxdz4pm6ymub1.png", "subreddit_subscribers": 1088227, "created_utc": 1697493093.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**Creativity**: We often focus a lot on hard skills, but creativity is the most important attribute for a data scientist. You will get some crazy requests. For example, I was once asked to build a recommendation system with NO DATA. Many other data scientists dismissed the project saying it couldn't be done. I was able to accomplish it by building a simple model were I manually entered weights depending on how important I thought each feature was. I then set up a pipeline to update these weights as real data would come in. Was it perfect? No. But it did a good enough job while we were waiting for data and made the client happy. I have had many crazy requests like this. So many data scientists out there have to be told what to do, very few can come up with creative solutions. The best never use phrases like, \"that is impossible.\" How do you learn this creativity? By working on real world problems. This skill is not developed when you are given a toy dataset and told what the output should look like. Sure, you might learn some technical modeling, but virtually no creativity. I wish more bootcamps would give \"impossible\" tasks.\n\n**Dirty Data**: I understand that provided or toy datasets can sometimes be dirty. They don't come close to real world data. Imagine you are asked to build a model using datasets you do not know exist yet, coming from source systems with little-to-no descriptions of what the features mean. Somehow you need to find the right data in a sea of millions of irrelevant features. You will need to fight political battles to even get access to the features you do not yet know if you even need. You will need to track down knowledgeable people who can tell you the weird quirks in the data (e.g. missing months were poorly imputed when this random country suffered a natural disaster 12 years ago). You then need to build a full pipeline that pulls the data from 10 different data sources that don't link to each other naturally, do regression tests because they don't update consistently, transform it, do feature engineering, feed it to a model, monitor the model for drift, redo everything after you find out a feature is completely different from what you were told, and the list goes on. This is not an exaggeration, it is typical. It goes way beyond cleaning up a few outliers and training a prototype model. This experience can only be gained by doing it.\n\n**Being easy to work with**: A bad hire can be a disaster! One person can ruin group moral and be difficult to get rid of. It can be difficult to judge personality from a few interviews. Haveing work experience where you got along with the same team for years greatly reduces that risk.\n\nThere are many others, but these are three big ones. If you don't have these skillsets, that is fine! But you have to start smaller. Get a more Jr level position where you are not expected to know all of these. Get experience working on them with more senior mentors. Even if you are one of the lucky few who get a job out of college in this market, your manager is probably clueless of these issues (i.e. won't be able to help you) and setting you up for failure. Many on this sub are looking for shortcuts or complaining about their job after they took a shortcut. You will have a much better career if you take the patient route.", "author_fullname": "t2_4fiyncpa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why employers want experience over education", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179ebar", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 124, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 124, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697484790.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697484333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Creativity&lt;/strong&gt;: We often focus a lot on hard skills, but creativity is the most important attribute for a data scientist. You will get some crazy requests. For example, I was once asked to build a recommendation system with NO DATA. Many other data scientists dismissed the project saying it couldn&amp;#39;t be done. I was able to accomplish it by building a simple model were I manually entered weights depending on how important I thought each feature was. I then set up a pipeline to update these weights as real data would come in. Was it perfect? No. But it did a good enough job while we were waiting for data and made the client happy. I have had many crazy requests like this. So many data scientists out there have to be told what to do, very few can come up with creative solutions. The best never use phrases like, &amp;quot;that is impossible.&amp;quot; How do you learn this creativity? By working on real world problems. This skill is not developed when you are given a toy dataset and told what the output should look like. Sure, you might learn some technical modeling, but virtually no creativity. I wish more bootcamps would give &amp;quot;impossible&amp;quot; tasks.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Dirty Data&lt;/strong&gt;: I understand that provided or toy datasets can sometimes be dirty. They don&amp;#39;t come close to real world data. Imagine you are asked to build a model using datasets you do not know exist yet, coming from source systems with little-to-no descriptions of what the features mean. Somehow you need to find the right data in a sea of millions of irrelevant features. You will need to fight political battles to even get access to the features you do not yet know if you even need. You will need to track down knowledgeable people who can tell you the weird quirks in the data (e.g. missing months were poorly imputed when this random country suffered a natural disaster 12 years ago). You then need to build a full pipeline that pulls the data from 10 different data sources that don&amp;#39;t link to each other naturally, do regression tests because they don&amp;#39;t update consistently, transform it, do feature engineering, feed it to a model, monitor the model for drift, redo everything after you find out a feature is completely different from what you were told, and the list goes on. This is not an exaggeration, it is typical. It goes way beyond cleaning up a few outliers and training a prototype model. This experience can only be gained by doing it.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Being easy to work with&lt;/strong&gt;: A bad hire can be a disaster! One person can ruin group moral and be difficult to get rid of. It can be difficult to judge personality from a few interviews. Haveing work experience where you got along with the same team for years greatly reduces that risk.&lt;/p&gt;\n\n&lt;p&gt;There are many others, but these are three big ones. If you don&amp;#39;t have these skillsets, that is fine! But you have to start smaller. Get a more Jr level position where you are not expected to know all of these. Get experience working on them with more senior mentors. Even if you are one of the lucky few who get a job out of college in this market, your manager is probably clueless of these issues (i.e. won&amp;#39;t be able to help you) and setting you up for failure. Many on this sub are looking for shortcuts or complaining about their job after they took a shortcut. You will have a much better career if you take the patient route.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179ebar", "is_robot_indexable": true, "report_reasons": null, "author": "Expendable_0", "discussion_type": null, "num_comments": 71, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179ebar/why_employers_want_experience_over_education/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179ebar/why_employers_want_experience_over_education/", "subreddit_subscribers": 1088227, "created_utc": 1697484333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I was wondering if there are other people out there who regret choosing data science as a career path.\n\nFor context: I got my B.S. in Mathematics in 2018. I worked 1 year as a program associate for a non-profit, managing their database and writing reports for grants/funding purposes. I then switched to a job in retirement investing as an analyst. I was originally going to start grad school (for a Masters in DS) in the Fall of 2020 but delayed to 2021 due to covid so I stayed at that job for 2 years.\n\nI enjoyed working with data and numbers, I kind of like how it feels to develop that tunnel vision and fixate on numbers lol. So I thought data science would be a good fit given those jobs revolved around data and it would be something financially stable (of course having no idea just how much covid et al. would impact the job market).\n\nIn the fall of the 2nd year of my Master's I received an offer to work for a large Healthcare company, which is where I am currently employed. To be honest, I genuinely hate it. I'm stuck working on the insurance side and it just feels miserable and unethical to me on a daily basis. I was hoping to join a team on the clinical side but wound up on the healthcare side due to the way the company matches employees to teams. I realized I miss working more directly with people, as I am on the west coast and the entirety of my team is on the East Coast or in India.\n\nI can't really tell if my misery is because of the company I work for itself or the field in general. I think I want something more interesting than what I am currently doing. I work with insurance plan design data. I applied to this job on a whim, because of the condition of the job market I felt I had to apply to all sorts of things. I'm personally opposed to for- profit healthcare but accepted because I didnt feel I had much choice as it was the only offer I received after hundreds of applications over many months. \n\nDoes anyone else feel extremely unsatisfied as a data scientist or as a data engineer? I guess I feel really under-stimulated and extremely unsatisfied. I don't know if every job feels like this and I have to suck it up, or if I should just leave. I've only been here 3 months and my resume is inconsistent enough as is so it feels too risky to leave even if I had a different offer lined up.\n\nI'd love to hear about people who switched into data science / engineering then changed their mind. Also, id appreciate input on the longevity of this career. I'm having a hard time setting career goals for myself and understand what career growth in this industry looks like and what I should aim for.", "author_fullname": "t2_iljnct2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Regretting Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179etbr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697514908.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697485575.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if there are other people out there who regret choosing data science as a career path.&lt;/p&gt;\n\n&lt;p&gt;For context: I got my B.S. in Mathematics in 2018. I worked 1 year as a program associate for a non-profit, managing their database and writing reports for grants/funding purposes. I then switched to a job in retirement investing as an analyst. I was originally going to start grad school (for a Masters in DS) in the Fall of 2020 but delayed to 2021 due to covid so I stayed at that job for 2 years.&lt;/p&gt;\n\n&lt;p&gt;I enjoyed working with data and numbers, I kind of like how it feels to develop that tunnel vision and fixate on numbers lol. So I thought data science would be a good fit given those jobs revolved around data and it would be something financially stable (of course having no idea just how much covid et al. would impact the job market).&lt;/p&gt;\n\n&lt;p&gt;In the fall of the 2nd year of my Master&amp;#39;s I received an offer to work for a large Healthcare company, which is where I am currently employed. To be honest, I genuinely hate it. I&amp;#39;m stuck working on the insurance side and it just feels miserable and unethical to me on a daily basis. I was hoping to join a team on the clinical side but wound up on the healthcare side due to the way the company matches employees to teams. I realized I miss working more directly with people, as I am on the west coast and the entirety of my team is on the East Coast or in India.&lt;/p&gt;\n\n&lt;p&gt;I can&amp;#39;t really tell if my misery is because of the company I work for itself or the field in general. I think I want something more interesting than what I am currently doing. I work with insurance plan design data. I applied to this job on a whim, because of the condition of the job market I felt I had to apply to all sorts of things. I&amp;#39;m personally opposed to for- profit healthcare but accepted because I didnt feel I had much choice as it was the only offer I received after hundreds of applications over many months. &lt;/p&gt;\n\n&lt;p&gt;Does anyone else feel extremely unsatisfied as a data scientist or as a data engineer? I guess I feel really under-stimulated and extremely unsatisfied. I don&amp;#39;t know if every job feels like this and I have to suck it up, or if I should just leave. I&amp;#39;ve only been here 3 months and my resume is inconsistent enough as is so it feels too risky to leave even if I had a different offer lined up.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear about people who switched into data science / engineering then changed their mind. Also, id appreciate input on the longevity of this career. I&amp;#39;m having a hard time setting career goals for myself and understand what career growth in this industry looks like and what I should aim for.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179etbr", "is_robot_indexable": true, "report_reasons": null, "author": "Relative_Practice_93", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179etbr/regretting_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179etbr/regretting_data_science/", "subreddit_subscribers": 1088227, "created_utc": 1697485575.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nBuilding off our last research post, we wanted to figure out ways to quantify \"ambiguity\" and \"uncertainty\" in prompts/responses to LLMs. We ended up discovering two useful forms of uncertainty: \"Structural\" and \"Conceptual\" uncertainty.\n\nIn a nutshell: Conceptual uncertainty is when the model isn't sure what to say, and Structural uncertainty is when the model isn't sure how to say it.\n\nYou can play around with this yourself in the [demo](https://uncertainty.demos.watchful.io/) or read about it in more detail in the [blog post](https://www.watchful.io/blog/decoding-llm-uncertainties-for-better-predictability)", "author_fullname": "t2_9o36o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Decoding LLM Uncertainties for Better Predictability", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1799oao", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697472672.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Building off our last research post, we wanted to figure out ways to quantify &amp;quot;ambiguity&amp;quot; and &amp;quot;uncertainty&amp;quot; in prompts/responses to LLMs. We ended up discovering two useful forms of uncertainty: &amp;quot;Structural&amp;quot; and &amp;quot;Conceptual&amp;quot; uncertainty.&lt;/p&gt;\n\n&lt;p&gt;In a nutshell: Conceptual uncertainty is when the model isn&amp;#39;t sure what to say, and Structural uncertainty is when the model isn&amp;#39;t sure how to say it.&lt;/p&gt;\n\n&lt;p&gt;You can play around with this yourself in the &lt;a href=\"https://uncertainty.demos.watchful.io/\"&gt;demo&lt;/a&gt; or read about it in more detail in the &lt;a href=\"https://www.watchful.io/blog/decoding-llm-uncertainties-for-better-predictability\"&gt;blog post&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1799oao", "is_robot_indexable": true, "report_reasons": null, "author": "shayanjm", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1799oao/decoding_llm_uncertainties_for_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1799oao/decoding_llm_uncertainties_for_better/", "subreddit_subscribers": 1088227, "created_utc": 1697472672.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello! I am dealing with a specific problem: predicting the maximum number of cars that can stop in a parking lot on a daily basis. We have multiple parking lots in a region, each with a fixed number of parking slots. These slots are used multiple times throughout the day. I have access to historical data, including information on the time cars spent in the slots, the number of cars in any given period, the number of empty slots during specific time periods, and statistics for nearby areas.\n\nThe goal is to predict, for each parking lot, the maximum number of cars it can accommodate on each day during the pre-Christmas period. It's important to note that historically, none of the parking lots have probably reached their maximum capacity.\n\nAdditionally, we are faced with a challenge related to new parking lots. These lots lack extensive historical data, and many people may not be aware of their existence.\n\nHow would you recommend approaching this task?", "author_fullname": "t2_lku7zyn1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predict maximum capacity of parking lots", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179ub5l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697534713.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! I am dealing with a specific problem: predicting the maximum number of cars that can stop in a parking lot on a daily basis. We have multiple parking lots in a region, each with a fixed number of parking slots. These slots are used multiple times throughout the day. I have access to historical data, including information on the time cars spent in the slots, the number of cars in any given period, the number of empty slots during specific time periods, and statistics for nearby areas.&lt;/p&gt;\n\n&lt;p&gt;The goal is to predict, for each parking lot, the maximum number of cars it can accommodate on each day during the pre-Christmas period. It&amp;#39;s important to note that historically, none of the parking lots have probably reached their maximum capacity.&lt;/p&gt;\n\n&lt;p&gt;Additionally, we are faced with a challenge related to new parking lots. These lots lack extensive historical data, and many people may not be aware of their existence.&lt;/p&gt;\n\n&lt;p&gt;How would you recommend approaching this task?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179ub5l", "is_robot_indexable": true, "report_reasons": null, "author": "VGFenohmen", "discussion_type": null, "num_comments": 20, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179ub5l/predict_maximum_capacity_of_parking_lots/", "subreddit_subscribers": 1088227, "created_utc": 1697534713.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Folks\n\nI am currently working as  Senior ML Engineer on a startup in Dubai. I am 28 years old and getting 120k USD yearly. (no tax).\n\nActually, I am living a good life here, its close to my home country (Turkey), so I can see my family easily and we are almost in same timezone. But the quality of things we are doing here not that good, and I am not sure can I grow in my career here in long run. I don't want to move to Europe because as I can see salaries are very low . If I stay in Dubai getting a salary around 150k in 2 years in here is very doable for me now.\n\nI started considering to move to USA. I found hybrid master programs (first year is remote second year is USA and I can OPT). So I don't have to sacrifice my 2 years to go USA. Probably I will stay without a job just one year.\n\nDo you have any advice for me? Is moving to USA changing my lifestyle, and making sacrifices (time, masters, moving to USA, money etc) worth it?  \n\n\n&amp;#x200B;", "author_fullname": "t2_auxp06r9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving to USA or Staying in UAE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179uwm2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697537235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Folks&lt;/p&gt;\n\n&lt;p&gt;I am currently working as  Senior ML Engineer on a startup in Dubai. I am 28 years old and getting 120k USD yearly. (no tax).&lt;/p&gt;\n\n&lt;p&gt;Actually, I am living a good life here, its close to my home country (Turkey), so I can see my family easily and we are almost in same timezone. But the quality of things we are doing here not that good, and I am not sure can I grow in my career here in long run. I don&amp;#39;t want to move to Europe because as I can see salaries are very low . If I stay in Dubai getting a salary around 150k in 2 years in here is very doable for me now.&lt;/p&gt;\n\n&lt;p&gt;I started considering to move to USA. I found hybrid master programs (first year is remote second year is USA and I can OPT). So I don&amp;#39;t have to sacrifice my 2 years to go USA. Probably I will stay without a job just one year.&lt;/p&gt;\n\n&lt;p&gt;Do you have any advice for me? Is moving to USA changing my lifestyle, and making sacrifices (time, masters, moving to USA, money etc) worth it?  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179uwm2", "is_robot_indexable": true, "report_reasons": null, "author": "Round_Inflation_2199", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179uwm2/moving_to_usa_or_staying_in_uae/", "subreddit_subscribers": 1088227, "created_utc": 1697537235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This has happened to me twice now, dunno if it\u2019s a new trend in recruitment processes. I\u2019m fine with it, to be honest, because it lets me show that I have the skills necessary for the job. I\u2019m not currently working in DS but in finance with some data analysis, but not much modeling work to show for (even though I have my master\u2019s in a computational quantitative field and so know the stats/theory behind most models).\n\n I didn\u2019t get the first job that required a live-coding exercise because they could only schedule it while I was on vacation and I didn\u2019t feel like I could really prepare, but now with this second position I passed the assignment and I have a 45 minute behavioral interview tomorrow. \n\nJust wondering for anyone who has had a similar recruitment process, does this mean that this recruitment process should be relatively quick? Just this interview and maybe one more technical one? (Am a bit desperate to switch jobs as my current job has a crazy high tempo and it\u2019s hard to find time to interview, which is the main reason I don\u2019t want a super dragged out process)", "author_fullname": "t2_ls91v62g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does it mean to get a take-home assignment before screening call?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179yve1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697551029.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697550765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This has happened to me twice now, dunno if it\u2019s a new trend in recruitment processes. I\u2019m fine with it, to be honest, because it lets me show that I have the skills necessary for the job. I\u2019m not currently working in DS but in finance with some data analysis, but not much modeling work to show for (even though I have my master\u2019s in a computational quantitative field and so know the stats/theory behind most models).&lt;/p&gt;\n\n&lt;p&gt;I didn\u2019t get the first job that required a live-coding exercise because they could only schedule it while I was on vacation and I didn\u2019t feel like I could really prepare, but now with this second position I passed the assignment and I have a 45 minute behavioral interview tomorrow. &lt;/p&gt;\n\n&lt;p&gt;Just wondering for anyone who has had a similar recruitment process, does this mean that this recruitment process should be relatively quick? Just this interview and maybe one more technical one? (Am a bit desperate to switch jobs as my current job has a crazy high tempo and it\u2019s hard to find time to interview, which is the main reason I don\u2019t want a super dragged out process)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179yve1", "is_robot_indexable": true, "report_reasons": null, "author": "Whole-Ad-8370", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/", "subreddit_subscribers": 1088227, "created_utc": 1697550765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi r/datascience,\n\nFrom my experience working with data orchestration tools (Airflow primarily), I tend to deal with a lot of repetitive fixes with flaky pipelines such as resource exhaustion issues, single malformed entries or other edge cases, figuring out why a task isn't running, and so on. I was wondering whether any of you had the same experience in your day-to-day work. How much of the job is actually just dealing with repetitive issues and maintenance of pipelines, and do any of you know of any tools or tips to make the experience of working with these pipelines less time-consuming?\n\nThanks!", "author_fullname": "t2_mk6o8gs2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Repetitive airflow pipeline problems", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179r5li", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697520996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/datascience\"&gt;r/datascience&lt;/a&gt;,&lt;/p&gt;\n\n&lt;p&gt;From my experience working with data orchestration tools (Airflow primarily), I tend to deal with a lot of repetitive fixes with flaky pipelines such as resource exhaustion issues, single malformed entries or other edge cases, figuring out why a task isn&amp;#39;t running, and so on. I was wondering whether any of you had the same experience in your day-to-day work. How much of the job is actually just dealing with repetitive issues and maintenance of pipelines, and do any of you know of any tools or tips to make the experience of working with these pipelines less time-consuming?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179r5li", "is_robot_indexable": true, "report_reasons": null, "author": "dec_dev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179r5li/repetitive_airflow_pipeline_problems/", "subreddit_subscribers": 1088227, "created_utc": 1697520996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a musical director on a large cruise ship and am responsible for scheduling sets for 10 different bands around the ships 10 different music venues. I have to work around trivias, parties and shows in the aqua theatre and Theatre and other various venues on the ship. I want to analyze the data I have from Day 1 of the cruise a few weeks ago in a chart. How would you guys go about doing this? Thanks!", "author_fullname": "t2_a3amxwo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cruise Ship Musicians Scheduling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179q91p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697517644.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a musical director on a large cruise ship and am responsible for scheduling sets for 10 different bands around the ships 10 different music venues. I have to work around trivias, parties and shows in the aqua theatre and Theatre and other various venues on the ship. I want to analyze the data I have from Day 1 of the cruise a few weeks ago in a chart. How would you guys go about doing this? Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179q91p", "is_robot_indexable": true, "report_reasons": null, "author": "SaxTeacher1988", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179q91p/cruise_ship_musicians_scheduling/", "subreddit_subscribers": 1088227, "created_utc": 1697517644.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey Guys,  \nIt seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo'd vector dbs.   \n\n\nDo you guys think there's any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone's raving about today)  \n\n\n\\-  \n\n\nFor context, I'm building a social media product we're users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche's classification string. Essentially we're aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. ", "author_fullname": "t2_13im86", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shared Public Contextual Database for RAG", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179z4yq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697551500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Guys,&lt;br/&gt;\nIt seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo&amp;#39;d vector dbs.   &lt;/p&gt;\n\n&lt;p&gt;Do you guys think there&amp;#39;s any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone&amp;#39;s raving about today)  &lt;/p&gt;\n\n&lt;p&gt;-  &lt;/p&gt;\n\n&lt;p&gt;For context, I&amp;#39;m building a social media product we&amp;#39;re users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche&amp;#39;s classification string. Essentially we&amp;#39;re aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179z4yq", "is_robot_indexable": true, "report_reasons": null, "author": "niksteel123", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/", "subreddit_subscribers": 1088227, "created_utc": 1697551500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Build Data Products? Deploy: Part 3/4 - Doubling down on the power of Unified Experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_179ykfd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fIAPxsCawPBu-N75Vvoyg_keOmRvMjS4W4feJpzH2AE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697549881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/how-to-build-data-products-deploy", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?auto=webp&amp;s=ea619a7c524f8c5536cc06f8b13ba792caddd5b5", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=66add8fac528d26de7feccdd0c5022d39fd89850", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=85446cd271d715b3865f735be872ce747366b093", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=929b190abb183f4784a7d725a150dbb2083ba894", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e4c400d8251d52d7421fc6640499a17ea524db3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5e716ed51284478d9d2a2569fdf859fe895fdf91", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5219b40b806ce0099e4650da1d92ec438c0e19d8", "width": 1080, "height": 540}], "variants": {}, "id": "_WJ_OVW7dv_Q8Y2muH3UxiO88vjiOO6xTcwW1zV8-tA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "179ykfd", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179ykfd/how_to_build_data_products_deploy_part_34/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/how-to-build-data-products-deploy", "subreddit_subscribers": 1088227, "created_utc": 1697549881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi there, \n\nI was wondering if some of you guys actually landed a job as Data Scientist/Analyst/Engineer after preparing with DataCamp and getting \"Job-Ready\" as DataCamp claims. ", "author_fullname": "t2_l41olfpk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting a Job after being \"Job-Ready\" according to DataCamp", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179xyzx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697548077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there, &lt;/p&gt;\n\n&lt;p&gt;I was wondering if some of you guys actually landed a job as Data Scientist/Analyst/Engineer after preparing with DataCamp and getting &amp;quot;Job-Ready&amp;quot; as DataCamp claims. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179xyzx", "is_robot_indexable": true, "report_reasons": null, "author": "snake_case_steve", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179xyzx/getting_a_job_after_being_jobready_according_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179xyzx/getting_a_job_after_being_jobready_according_to/", "subreddit_subscribers": 1088227, "created_utc": 1697548077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "My company is starting to roll out AI tools (think Github Co-Pilot and internal chatbots). I told my boss that I have already been using these things and basically use them every day (which is true). He was very impressed and told me to present to the team about how to use AI to do our job.\n\n Overall I think this was a good way to score free points with my boss, who is somewhat technical but also boomer. In reality I think my team is already using these tools to some extent and will be hard to teach them anything new by doing this. However, I still want to do the training mostly to show off to my boss. He says he wants to use it but has never gotten around to it.\n\nI really do use these tools often and could show real-world cases where it's helped out. That being said, I still want to be careful about how I do this to avoid it being gimmicky.\nHow should I approach this? Anything in particular I should show?\n\nI am not specifically a data scientist but assume we use a similar tech setup (Python / R / SQL, creating reports etc)", "author_fullname": "t2_19f7pjd0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I do an AI Training for my team without it being totally gimmicky? Is it even possible?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179kwrd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697501264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My company is starting to roll out AI tools (think Github Co-Pilot and internal chatbots). I told my boss that I have already been using these things and basically use them every day (which is true). He was very impressed and told me to present to the team about how to use AI to do our job.&lt;/p&gt;\n\n&lt;p&gt;Overall I think this was a good way to score free points with my boss, who is somewhat technical but also boomer. In reality I think my team is already using these tools to some extent and will be hard to teach them anything new by doing this. However, I still want to do the training mostly to show off to my boss. He says he wants to use it but has never gotten around to it.&lt;/p&gt;\n\n&lt;p&gt;I really do use these tools often and could show real-world cases where it&amp;#39;s helped out. That being said, I still want to be careful about how I do this to avoid it being gimmicky.\nHow should I approach this? Anything in particular I should show?&lt;/p&gt;\n\n&lt;p&gt;I am not specifically a data scientist but assume we use a similar tech setup (Python / R / SQL, creating reports etc)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179kwrd", "is_robot_indexable": true, "report_reasons": null, "author": "throwaWayne2", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179kwrd/how_can_i_do_an_ai_training_for_my_team_without/", "subreddit_subscribers": 1088227, "created_utc": 1697501264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " - Git\n   - public only otherwise on GitHub\n   - limited repos otherwise on Bitbucket\n - Webhost\n   - (the nice ones seem to all be trial only / require a CC)\n - Cloud compute\n   - limited otherwise on Colab\n   - trial only on AWS\n\nGetting ready for the next round of jobseeking, and all my student trials will be over. _Not_ intermingling with work.\n\nWhich do you consider worthwhile? Which not so much?", "author_fullname": "t2_fem4lsdf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What services do you pay for for your personal portfolio?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179do5q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697482719.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;ul&gt;\n&lt;li&gt;Git\n\n&lt;ul&gt;\n&lt;li&gt;public only otherwise on GitHub&lt;/li&gt;\n&lt;li&gt;limited repos otherwise on Bitbucket&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Webhost\n\n&lt;ul&gt;\n&lt;li&gt;(the nice ones seem to all be trial only / require a CC)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;Cloud compute\n\n&lt;ul&gt;\n&lt;li&gt;limited otherwise on Colab&lt;/li&gt;\n&lt;li&gt;trial only on AWS&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Getting ready for the next round of jobseeking, and all my student trials will be over. &lt;em&gt;Not&lt;/em&gt; intermingling with work.&lt;/p&gt;\n\n&lt;p&gt;Which do you consider worthwhile? Which not so much?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179do5q", "is_robot_indexable": true, "report_reasons": null, "author": "throwaway20220717", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179do5q/what_services_do_you_pay_for_for_your_personal/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179do5q/what_services_do_you_pay_for_for_your_personal/", "subreddit_subscribers": 1088227, "created_utc": 1697482719.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I read many posts saying that \"Data Analyst\" is not an entry level role. \n\nSo, MINIMUM how many years of prior relevant work experience does one need before moving into a Data Analyst role?", "author_fullname": "t2_403s9uzf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "MIN how many yrs of work exp will one need to be a Data Analyst?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17a1nt0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697558319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read many posts saying that &amp;quot;Data Analyst&amp;quot; is not an entry level role. &lt;/p&gt;\n\n&lt;p&gt;So, MINIMUM how many years of prior relevant work experience does one need before moving into a Data Analyst role?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a1nt0", "is_robot_indexable": true, "report_reasons": null, "author": "vich_lasagna", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a1nt0/min_how_many_yrs_of_work_exp_will_one_need_to_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a1nt0/min_how_many_yrs_of_work_exp_will_one_need_to_be/", "subreddit_subscribers": 1088227, "created_utc": 1697558319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,   \n\n\nWe just hired a data analyst to analyse a time series representing a certain commodity value over time, we offered them the possibility to take the price data from a source of their choice, but they insisted that we provide it ourselves. Is this good or bad practice? Could someone give pros and cons of letting the analyst find their own publicly available data vs. the company providing them the data set?   \n\n\nThank you", "author_fullname": "t2_97o8m0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should data-scientists look for their own datasets or be provided by the hiring company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179ztob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697553394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,   &lt;/p&gt;\n\n&lt;p&gt;We just hired a data analyst to analyse a time series representing a certain commodity value over time, we offered them the possibility to take the price data from a source of their choice, but they insisted that we provide it ourselves. Is this good or bad practice? Could someone give pros and cons of letting the analyst find their own publicly available data vs. the company providing them the data set?   &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179ztob", "is_robot_indexable": true, "report_reasons": null, "author": "Cryptocheets", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/", "subreddit_subscribers": 1088227, "created_utc": 1697553394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey fellow Redditors!\n\nEver wondered how technology can tackle a range of challenges like signature authentication, detecting cheaters in games, assessing neurological conditions, or dealing with pesky bots? The answer lies in the fascinating world of human motion analysis!\n\nIn this discussion, we delve into the concept of \"features\" in the context of human motion. Features are scalar values obtained from motion segments, offering insights into movement patterns. We explore how these features are essential in addressing diverse challenges and share insights into the basic features of movements.\n\n# \ud83d\udca1 What's a Feature?  \n\nIn this context, a feature refers to a scalar value obtained from a motion segment. For example, the average acceleration of a cursor. As depicted in the diagram below, users cannot be distinguished solely based on their average acceleration, but there are discernible individual tendencies.\n\n The next step involves constructing our feature space by identifying features that contain relevant information about movement patterns. \n\n# \ud83d\udcca Analyzing the appropriate time series\n\nThe majority of the data we work with consists of x and y coordinates that change over time, such as the position of a cursor or a pen on a screen. Therefore, we already have two time series. Additionally, we calculate directional speeds, accelerations, jerks, as well as direction-independent speed, acceleration, and jerk. \n\n**Unmasking forgery through speed analysis**\n\nLet\u2019s explain the use of derivatives through an example of **signature forgery**. Suppose someone attempts to replicate a signature they have seen before, familiar with its form. How would you approach this situation? Initially, one might **meticulously trace the line to be replicated, proceeding slowly and accurately**, inch by inch. The result would be a slow, nearly constant-speed movement. **The speed time series would exhibit an approximately constant value.**\n\nNow, imagine **someone writing their own signature**. **The speed can vary significantly**, but it won\u2019t remain constant. They would draw longer, straight lines more quickly and slow down at tight turns. When moving right and upwards, the arcs would be faster and more dynamic than when turning left. Even if the forged signature\u2019s image is an exact copy of the genuine one in terms of x-y coordinates, **the speed profiles would look entirely different.**\n\nOf course, this was a rather clumsy attempt at forgery; there are far more skilled individuals in this field. The speed of a signature can be estimated based on the signature image alone, either by assuming faster movement on straight lines and slower movement on curves or by considering the line quality.\n\nDelving into the details is beyond the scope of this discussion, but the key point is that estimating and replicating the speed of motion requires practice and talent. It is more challenging than simply replicating the x-y coordinates of the signature image. Moreover, forging the acceleration and other factors becomes even more difficult.\n\nIn theory, we could **take derivatives of our time series as many times as desired**. However, there is a practical limit as, **after a certain point, the derivative becomes more noise than meaningful information.**\n\nFrom this example, it becomes apparent why we thought utilizing derivatives (speed, acceleration, jerk) was a valuable approach for motion analysis. **When we began using this method, the results demonstrated exceptional accuracy**.\n\n# \ud83d\udd0d Describing Time Series with Scalar Values \n\n We have extracted various time series from our motion sample. To condense the valuable information of a lengthy time series into scalar values, **we employ a straightforward approach: calculating a few statistical characteristics**. Our selection criteria ensure that these characteristics effectively represent the distribution of the time series.\n\nSome of these characteristics are expected, such as the minimum, maximum, mean, and standard deviation.\n\nTo understand how the values progress from the minimum to the maximum, we utilize percentiles, including the 10th, 25th, 50th, 75th, and 90th percentiles. The minimum and maximum values are also considered as percentiles, specifically the 0th and 100th percentiles.\n\nTwo lesser-known statistical values are skewness and kurtosis. **Skewness measures the asymmetry of a distribution**. For instance, if the speed values below and above the average speed are evenly spaced, the skewness will be around zero. However, if there are numerous values below the mean but close to it, with only a few exceptionally high values above, the skewness will be positive.\n\nIn the context of cursor movement, this suggests that an individual typically uses the cursor at a relatively constant speed, but occasionally makes sudden moves. This could be a personal habit or characteristic.\n\nOn the other hand, **kurtosis indicates whether the values are concentrated around the mean or spread out across a broader range**.\n\nThese are the basic features we utilize for analysis.\n\nFeel free to join the discussion and share your thoughts on this fascinating intersection of technology and human motion analysis! \ud83d\udcac\ud83d\udd7a\ud83c\udffd\ud83d\udcbb", "author_fullname": "t2_gbypvyyx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cracking the Code of Human Motion: Describing Movement Patterns with Scalar Values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179u12d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697533471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey fellow Redditors!&lt;/p&gt;\n\n&lt;p&gt;Ever wondered how technology can tackle a range of challenges like signature authentication, detecting cheaters in games, assessing neurological conditions, or dealing with pesky bots? The answer lies in the fascinating world of human motion analysis!&lt;/p&gt;\n\n&lt;p&gt;In this discussion, we delve into the concept of &amp;quot;features&amp;quot; in the context of human motion. Features are scalar values obtained from motion segments, offering insights into movement patterns. We explore how these features are essential in addressing diverse challenges and share insights into the basic features of movements.&lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udca1 What&amp;#39;s a Feature?&lt;/h1&gt;\n\n&lt;p&gt;In this context, a feature refers to a scalar value obtained from a motion segment. For example, the average acceleration of a cursor. As depicted in the diagram below, users cannot be distinguished solely based on their average acceleration, but there are discernible individual tendencies.&lt;/p&gt;\n\n&lt;p&gt;The next step involves constructing our feature space by identifying features that contain relevant information about movement patterns. &lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udcca Analyzing the appropriate time series&lt;/h1&gt;\n\n&lt;p&gt;The majority of the data we work with consists of x and y coordinates that change over time, such as the position of a cursor or a pen on a screen. Therefore, we already have two time series. Additionally, we calculate directional speeds, accelerations, jerks, as well as direction-independent speed, acceleration, and jerk. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Unmasking forgery through speed analysis&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Let\u2019s explain the use of derivatives through an example of &lt;strong&gt;signature forgery&lt;/strong&gt;. Suppose someone attempts to replicate a signature they have seen before, familiar with its form. How would you approach this situation? Initially, one might &lt;strong&gt;meticulously trace the line to be replicated, proceeding slowly and accurately&lt;/strong&gt;, inch by inch. The result would be a slow, nearly constant-speed movement. &lt;strong&gt;The speed time series would exhibit an approximately constant value.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Now, imagine &lt;strong&gt;someone writing their own signature&lt;/strong&gt;. &lt;strong&gt;The speed can vary significantly&lt;/strong&gt;, but it won\u2019t remain constant. They would draw longer, straight lines more quickly and slow down at tight turns. When moving right and upwards, the arcs would be faster and more dynamic than when turning left. Even if the forged signature\u2019s image is an exact copy of the genuine one in terms of x-y coordinates, &lt;strong&gt;the speed profiles would look entirely different.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Of course, this was a rather clumsy attempt at forgery; there are far more skilled individuals in this field. The speed of a signature can be estimated based on the signature image alone, either by assuming faster movement on straight lines and slower movement on curves or by considering the line quality.&lt;/p&gt;\n\n&lt;p&gt;Delving into the details is beyond the scope of this discussion, but the key point is that estimating and replicating the speed of motion requires practice and talent. It is more challenging than simply replicating the x-y coordinates of the signature image. Moreover, forging the acceleration and other factors becomes even more difficult.&lt;/p&gt;\n\n&lt;p&gt;In theory, we could &lt;strong&gt;take derivatives of our time series as many times as desired&lt;/strong&gt;. However, there is a practical limit as, &lt;strong&gt;after a certain point, the derivative becomes more noise than meaningful information.&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;From this example, it becomes apparent why we thought utilizing derivatives (speed, acceleration, jerk) was a valuable approach for motion analysis. &lt;strong&gt;When we began using this method, the results demonstrated exceptional accuracy&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;h1&gt;\ud83d\udd0d Describing Time Series with Scalar Values&lt;/h1&gt;\n\n&lt;p&gt;We have extracted various time series from our motion sample. To condense the valuable information of a lengthy time series into scalar values, &lt;strong&gt;we employ a straightforward approach: calculating a few statistical characteristics&lt;/strong&gt;. Our selection criteria ensure that these characteristics effectively represent the distribution of the time series.&lt;/p&gt;\n\n&lt;p&gt;Some of these characteristics are expected, such as the minimum, maximum, mean, and standard deviation.&lt;/p&gt;\n\n&lt;p&gt;To understand how the values progress from the minimum to the maximum, we utilize percentiles, including the 10th, 25th, 50th, 75th, and 90th percentiles. The minimum and maximum values are also considered as percentiles, specifically the 0th and 100th percentiles.&lt;/p&gt;\n\n&lt;p&gt;Two lesser-known statistical values are skewness and kurtosis. &lt;strong&gt;Skewness measures the asymmetry of a distribution&lt;/strong&gt;. For instance, if the speed values below and above the average speed are evenly spaced, the skewness will be around zero. However, if there are numerous values below the mean but close to it, with only a few exceptionally high values above, the skewness will be positive.&lt;/p&gt;\n\n&lt;p&gt;In the context of cursor movement, this suggests that an individual typically uses the cursor at a relatively constant speed, but occasionally makes sudden moves. This could be a personal habit or characteristic.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, &lt;strong&gt;kurtosis indicates whether the values are concentrated around the mean or spread out across a broader range&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;p&gt;These are the basic features we utilize for analysis.&lt;/p&gt;\n\n&lt;p&gt;Feel free to join the discussion and share your thoughts on this fascinating intersection of technology and human motion analysis! \ud83d\udcac\ud83d\udd7a\ud83c\udffd\ud83d\udcbb&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179u12d", "is_robot_indexable": true, "report_reasons": null, "author": "CursorInsight", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179u12d/cracking_the_code_of_human_motion_describing/", "subreddit_subscribers": 1088227, "created_utc": 1697533471.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Why we cannot use GAN's inplace of LSTM for any recurrent neural network for time series forcasting.\nAs we can plot univariate time series on plot and train GaN's to complete that plot.\n\nNot so much work is in going on this feild.\nWhy ?", "author_fullname": "t2_an5w3ncs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Time series forcasting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179q60m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697517330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why we cannot use GAN&amp;#39;s inplace of LSTM for any recurrent neural network for time series forcasting.\nAs we can plot univariate time series on plot and train GaN&amp;#39;s to complete that plot.&lt;/p&gt;\n\n&lt;p&gt;Not so much work is in going on this feild.\nWhy ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179q60m", "is_robot_indexable": true, "report_reasons": null, "author": "Awkward-Block-5005", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179q60m/time_series_forcasting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179q60m/time_series_forcasting/", "subreddit_subscribers": 1088227, "created_utc": 1697517330.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}