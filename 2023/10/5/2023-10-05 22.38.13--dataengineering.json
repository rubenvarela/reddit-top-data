{"kind": "Listing", "data": {"after": "t3_170twld", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've got a task to consolidate the 'database' at work, into a proper database.\n\nIssues:\n1) The current database is 2584 Excel files, all with different structures and information, though they all have a unique key within them.\n2) Information within the document is in the wrong columns in some of of the files.\n3) I am not allowed to use scripts, except for vba coded in Access.\n4) Some of the files only contain some of the information, others double the same information, some are missing fields.\n\nAnyone have any tips? Spent a few hours on a it today to work out where the data was as the previous people left.", "author_fullname": "t2_gam51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oh god why, Help Consolidating \"Excel\" Database 2584 files in 246 folders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170azqv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 35, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 35, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696488301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve got a task to consolidate the &amp;#39;database&amp;#39; at work, into a proper database.&lt;/p&gt;\n\n&lt;p&gt;Issues:\n1) The current database is 2584 Excel files, all with different structures and information, though they all have a unique key within them.\n2) Information within the document is in the wrong columns in some of of the files.\n3) I am not allowed to use scripts, except for vba coded in Access.\n4) Some of the files only contain some of the information, others double the same information, some are missing fields.&lt;/p&gt;\n\n&lt;p&gt;Anyone have any tips? Spent a few hours on a it today to work out where the data was as the previous people left.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170azqv", "is_robot_indexable": true, "report_reasons": null, "author": "CYOA_With_Hitler", "discussion_type": null, "num_comments": 75, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170azqv/oh_god_why_help_consolidating_excel_database_2584/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170azqv/oh_god_why_help_consolidating_excel_database_2584/", "subreddit_subscribers": 132286, "created_utc": 1696488301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI\u2019m at a crossroads in my career and could really use some insight. I\u2019ve previously worked as a Data Analyst, and have now been presented with an opportunity to train in either Data Engineering or DevOps from scratch, courtesy of a company I\u2019m considering joining. I\u2019m intrigued by both roles but also drawn by the attractive pay scales I\u2019ve seen in the DevOps field.\n\nShould I stick closer to my roots with Data Engineering, or explore the dynamic world of DevOps? I\u2019d love to hear your experiences and perspectives.\n\nThanks in advance!", "author_fullname": "t2_8fi5ln6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer vs Devops?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1709g07", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696482683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m at a crossroads in my career and could really use some insight. I\u2019ve previously worked as a Data Analyst, and have now been presented with an opportunity to train in either Data Engineering or DevOps from scratch, courtesy of a company I\u2019m considering joining. I\u2019m intrigued by both roles but also drawn by the attractive pay scales I\u2019ve seen in the DevOps field.&lt;/p&gt;\n\n&lt;p&gt;Should I stick closer to my roots with Data Engineering, or explore the dynamic world of DevOps? I\u2019d love to hear your experiences and perspectives.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1709g07", "is_robot_indexable": true, "report_reasons": null, "author": "sailor_Moon_Pie", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1709g07/data_engineer_vs_devops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1709g07/data_engineer_vs_devops/", "subreddit_subscribers": 132286, "created_utc": 1696482683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have worked with Data in some capacity for the last 5-6 years of my career. I am self-taught and have experience with SQL, Python and Bash (as well as specific tools and database engines like MSSQL, MariaDB, Vertica etc).  \n\n\nI code a lot of custom ETL jobs for my work, and have begun to wonder - \\*how\\* can I evaluate performance, especially to identify room for improvement. It's one thing to benchmark script 1 vs script 2, but its more difficult to have a sense of how quickly a given amount of data should load. Are there ways to check network latency, the available computational resources etc to establish a baseline of performance to aim for? What are the best tools for feeling this out, especially ones easily available to me given what I know - ie SQL, Bash, Python? I'm out of my depth here but want to improve and feel answering or otherwise understanding this question is a necessary next step.  \n\n\nFor the sake of this exercise lets assume the data is fairly simple - floats, integers, char/varchar etc rather than more complex or larger formats like CLOB/BLOB.", "author_fullname": "t2_3v8tq4ba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I know the extent to which ETLs *could* be running faster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170lxza", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696522323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have worked with Data in some capacity for the last 5-6 years of my career. I am self-taught and have experience with SQL, Python and Bash (as well as specific tools and database engines like MSSQL, MariaDB, Vertica etc).  &lt;/p&gt;\n\n&lt;p&gt;I code a lot of custom ETL jobs for my work, and have begun to wonder - *how* can I evaluate performance, especially to identify room for improvement. It&amp;#39;s one thing to benchmark script 1 vs script 2, but its more difficult to have a sense of how quickly a given amount of data should load. Are there ways to check network latency, the available computational resources etc to establish a baseline of performance to aim for? What are the best tools for feeling this out, especially ones easily available to me given what I know - ie SQL, Bash, Python? I&amp;#39;m out of my depth here but want to improve and feel answering or otherwise understanding this question is a necessary next step.  &lt;/p&gt;\n\n&lt;p&gt;For the sake of this exercise lets assume the data is fairly simple - floats, integers, char/varchar etc rather than more complex or larger formats like CLOB/BLOB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170lxza", "is_robot_indexable": true, "report_reasons": null, "author": "vonkraush1010", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170lxza/how_do_i_know_the_extent_to_which_etls_could_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170lxza/how_do_i_know_the_extent_to_which_etls_could_be/", "subreddit_subscribers": 132286, "created_utc": 1696522323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Apologies as my background isn't in DE but come more from BI systems administration. In my career I've seen a lot but the craziest thing I've seen is business users using email heavily to send Excel and CSV data dumps using BI tools...at a huge scale. Of course there are also some secure file transfers out there, stuff you would see with MoveIT and IBM Sterling, etc. Both of these models beg the question to me which is -- why do we need this?\n\nIs it literally just because our system doesn't have a reliable REST API to pull the data easily? Is REST that insecure? So instead we rely on the other party generating a CSV and sending it to us in batch like it's 1995? Couldn't a REST API send a CSV over HTTPS anyway? Do we not trust it?\n\nIs data integration really that dirty? What can be done to eliminate these file transfer overhead monsters? Is progress with good REST APIs just moving that slow?\n\nI feel like there's something I'm fundamentally misunderstanding but not sure what it is...", "author_fullname": "t2_6c2aryt5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the reason SFTP file transfer in banks, healthcare, etc is so ubiquitous just because they are using older systems without robust REST APIs...?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170rvz3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696536440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies as my background isn&amp;#39;t in DE but come more from BI systems administration. In my career I&amp;#39;ve seen a lot but the craziest thing I&amp;#39;ve seen is business users using email heavily to send Excel and CSV data dumps using BI tools...at a huge scale. Of course there are also some secure file transfers out there, stuff you would see with MoveIT and IBM Sterling, etc. Both of these models beg the question to me which is -- why do we need this?&lt;/p&gt;\n\n&lt;p&gt;Is it literally just because our system doesn&amp;#39;t have a reliable REST API to pull the data easily? Is REST that insecure? So instead we rely on the other party generating a CSV and sending it to us in batch like it&amp;#39;s 1995? Couldn&amp;#39;t a REST API send a CSV over HTTPS anyway? Do we not trust it?&lt;/p&gt;\n\n&lt;p&gt;Is data integration really that dirty? What can be done to eliminate these file transfer overhead monsters? Is progress with good REST APIs just moving that slow?&lt;/p&gt;\n\n&lt;p&gt;I feel like there&amp;#39;s something I&amp;#39;m fundamentally misunderstanding but not sure what it is...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "170rvz3", "is_robot_indexable": true, "report_reasons": null, "author": "TheWikiJedi", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170rvz3/is_the_reason_sftp_file_transfer_in_banks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170rvz3/is_the_reason_sftp_file_transfer_in_banks/", "subreddit_subscribers": 132286, "created_utc": 1696536440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5puh1cdh2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kestra is an open source data orchestration platform for complex workflows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 107, "top_awarded_type": null, "hide_score": false, "name": "t3_170dilo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4H_RhvBn6ZNfOhZz_b6iWFeIJOUOreJeKrhxxrURA9Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696498135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "techcrunch.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://techcrunch.com/2023/10/04/kestra-is-an-open-source-data-orchestration-platform-for-complex-workflows/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?auto=webp&amp;s=68660ca9d2b2000fe79db81cb2ff27fcaf11d5d0", "width": 1200, "height": 924}, "resolutions": [{"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4cbf10b9426b1446ce397550d2bb99977cbd8686", "width": 108, "height": 83}, {"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f7d2266da09a1653f16549c3925b92e431913dad", "width": 216, "height": 166}, {"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e45b049021ce097e55829c0c0d1effef3beca9bc", "width": 320, "height": 246}, {"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe1a09047d7920c0e5cb584222749b96794faf54", "width": 640, "height": 492}, {"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9279d0089cd1d4431f2ee15542f58a4e6a80848e", "width": 960, "height": 739}, {"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=032caf5ea23a96b8879417feaf4dd73d47de7a83", "width": 1080, "height": 831}], "variants": {}, "id": "02Q-33t-h3gAREC-TESqt8J99md2QiL7EA9XzOYgtWo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "170dilo", "is_robot_indexable": true, "report_reasons": null, "author": "Merlich_RSt", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170dilo/kestra_is_an_open_source_data_orchestration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://techcrunch.com/2023/10/04/kestra-is-an-open-source-data-orchestration-platform-for-complex-workflows/", "subreddit_subscribers": 132286, "created_utc": 1696498135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering if anyone here transitioned from DA into DE can share what they enjoy or don\u2019t enjoy after changing careers. What advice you would give yourself looking back?\n\nI recently transitioned out of a decade of  teaching in a public high school into data analysis. I was so burned out, and it almost impossible to get any interviews, despite having a BS in Math from a top university, and finishing a Data Science boot camp with top marks. I finally got a job, but I\u2019m also hitting a ceiling with data analyst positions- currently, I\u2019m getting paid $75k in Los Angeles. \n\nI do feel underpaid for how quickly I pick up and complete work. My boss estimates that I saved them 10 hours of weekly manual labor in my first quarter,  because I taught myself JavaScript to write simple lines to automate some reports in their business analysis software.\n\nMost of my technical work entails Python to clean and format data, and graphs in Tableau. I found myself doing a lot of project management because my team is nice, but not very organized, and sitting in on calls to translate what someone wants into code or graphs. Now I\u2019m wondering if it\u2019s just hubris, and I should be happy with my salary for the type of work I do\u2026\n\nI am comfortable picking up code, since I learned C++ in college. I use Python and SQL for personal projects and certificates, but I do not fully understand the statistics behind data science projects, nor do I enjoy it, and these positions require a master\u2019s, so I feel uncomfortable continuing in the data science direction.\n\nThe most intimidating part of DE is all the tools listed, and unfamiliarity with the jargon. I signed up for a DE course, because the external motivation is helpful with the burnout, so I will share updates if it\u2019s helpful! I noticed a free DE bootcamp in this community in January, so I will keep an eye out for that as well.", "author_fullname": "t2_jzdhrzu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for a Data Analyst", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1707z40", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696477885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if anyone here transitioned from DA into DE can share what they enjoy or don\u2019t enjoy after changing careers. What advice you would give yourself looking back?&lt;/p&gt;\n\n&lt;p&gt;I recently transitioned out of a decade of  teaching in a public high school into data analysis. I was so burned out, and it almost impossible to get any interviews, despite having a BS in Math from a top university, and finishing a Data Science boot camp with top marks. I finally got a job, but I\u2019m also hitting a ceiling with data analyst positions- currently, I\u2019m getting paid $75k in Los Angeles. &lt;/p&gt;\n\n&lt;p&gt;I do feel underpaid for how quickly I pick up and complete work. My boss estimates that I saved them 10 hours of weekly manual labor in my first quarter,  because I taught myself JavaScript to write simple lines to automate some reports in their business analysis software.&lt;/p&gt;\n\n&lt;p&gt;Most of my technical work entails Python to clean and format data, and graphs in Tableau. I found myself doing a lot of project management because my team is nice, but not very organized, and sitting in on calls to translate what someone wants into code or graphs. Now I\u2019m wondering if it\u2019s just hubris, and I should be happy with my salary for the type of work I do\u2026&lt;/p&gt;\n\n&lt;p&gt;I am comfortable picking up code, since I learned C++ in college. I use Python and SQL for personal projects and certificates, but I do not fully understand the statistics behind data science projects, nor do I enjoy it, and these positions require a master\u2019s, so I feel uncomfortable continuing in the data science direction.&lt;/p&gt;\n\n&lt;p&gt;The most intimidating part of DE is all the tools listed, and unfamiliarity with the jargon. I signed up for a DE course, because the external motivation is helpful with the burnout, so I will share updates if it\u2019s helpful! I noticed a free DE bootcamp in this community in January, so I will keep an eye out for that as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1707z40", "is_robot_indexable": true, "report_reasons": null, "author": "blurry_forest", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1707z40/advice_for_a_data_analyst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1707z40/advice_for_a_data_analyst/", "subreddit_subscribers": 132286, "created_utc": 1696477885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fb83g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft Fabric: Should Databricks be Worried?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 83, "top_awarded_type": null, "hide_score": false, "name": "t3_170otm0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KqfXrZoRthY9_0rKj5OFsfqYtxhzW4XWdZseyT5_NcY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696529189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "vantage.sh", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.vantage.sh/blog/databricks-vs-microsoft-fabric-pricing-analysis", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?auto=webp&amp;s=af663ae0121ce0a4793363094c1fec8259eefa84", "width": 1270, "height": 760}, "resolutions": [{"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=57e13db27e90db4e7152be7e631452a796c7297a", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=deb5668b38d81175fea57b520a0c5c713c6d7ce9", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6222d395bbc71108823edfc2628acb961c3bb0cf", "width": 320, "height": 191}, {"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0fe04e60e1c5b79f9154ec4a8193c93ba8b7c109", "width": 640, "height": 382}, {"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6f33a26035314d4789bc40760d8a6abb6837980b", "width": 960, "height": 574}, {"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=394a654d23b5732bcba1b7573a3fc9a6da6897e6", "width": 1080, "height": 646}], "variants": {}, "id": "KJGb3So15RCrofadobr6rSw5w7wrNTNiPNLXDBWpF8o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "170otm0", "is_robot_indexable": true, "report_reasons": null, "author": "include_stdio_h", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170otm0/microsoft_fabric_should_databricks_be_worried/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.vantage.sh/blog/databricks-vs-microsoft-fabric-pricing-analysis", "subreddit_subscribers": 132286, "created_utc": 1696529189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all!\n\nI joined a team a few months ago as a senior from working at prior orgs, doing heavy DE infra work and Python &amp; Scala based coding in cloud first architectures, with a mix of modern data stack work &amp; Spark/Big Data work with Databricks &amp; the like.\n\nI was tasked with building a new data platform centered around best practices &amp; automation, and have delivered on a platform incorporating Dagster, templated SQL (no DBT yet\u2026), and Python work for a DSL based YAML workflow.\n\nI\u2019ve been able to compile YAML into orchestrated jobs, create CI/CD, build the application and publish containers, and provide monitoring &amp; reporting. Currently, it is being UAT\u2019d, but I\u2019m running into roadblocks because my team does not come from a OOP background at all. My boss is a heavy scripting-on prem healthcare environment experience, my juniors either come from Powershell scripting IT based automation or from no experience but SQL as DAs:\n\nThey\u2019ve built solid data infra so far, but there is a lot of risk for breakage and limits in scalability. Ingestion is mainly handled through Fivetran or through legacy orchestration  (think PS &amp; the like), git is somewhat used, but it has no affect on what\u2019s running in production, no testing, all jobs are run through Snowflake tasks, and everybody on the team has AccountAdmin access. \n\nI\u2019m worried my project won\u2019t get given a full green light because of these traditions. Any idea on how to get around it and fully show value, and teach the team quickly as we continue to scale?", "author_fullname": "t2_3ixkfqzx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to present and explain SWE DE practices to a green team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1704smu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696468808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!&lt;/p&gt;\n\n&lt;p&gt;I joined a team a few months ago as a senior from working at prior orgs, doing heavy DE infra work and Python &amp;amp; Scala based coding in cloud first architectures, with a mix of modern data stack work &amp;amp; Spark/Big Data work with Databricks &amp;amp; the like.&lt;/p&gt;\n\n&lt;p&gt;I was tasked with building a new data platform centered around best practices &amp;amp; automation, and have delivered on a platform incorporating Dagster, templated SQL (no DBT yet\u2026), and Python work for a DSL based YAML workflow.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been able to compile YAML into orchestrated jobs, create CI/CD, build the application and publish containers, and provide monitoring &amp;amp; reporting. Currently, it is being UAT\u2019d, but I\u2019m running into roadblocks because my team does not come from a OOP background at all. My boss is a heavy scripting-on prem healthcare environment experience, my juniors either come from Powershell scripting IT based automation or from no experience but SQL as DAs:&lt;/p&gt;\n\n&lt;p&gt;They\u2019ve built solid data infra so far, but there is a lot of risk for breakage and limits in scalability. Ingestion is mainly handled through Fivetran or through legacy orchestration  (think PS &amp;amp; the like), git is somewhat used, but it has no affect on what\u2019s running in production, no testing, all jobs are run through Snowflake tasks, and everybody on the team has AccountAdmin access. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m worried my project won\u2019t get given a full green light because of these traditions. Any idea on how to get around it and fully show value, and teach the team quickly as we continue to scale?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1704smu", "is_robot_indexable": true, "report_reasons": null, "author": "kharigardner", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1704smu/how_to_present_and_explain_swe_de_practices_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1704smu/how_to_present_and_explain_swe_de_practices_to_a/", "subreddit_subscribers": 132286, "created_utc": 1696468808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently working on a hobby project and am hoping to continuously stream some data from a web API into my Apache Kafka producer. I am currently using the Confluent Kafka library for python to write my producer and consumer and thus also intend for my API data retrieval to be written in Python as well. \n\n&amp;nbsp;\n\nIn terms of getting the data from the API my current solution is to do the following in a loop: 1. Send a GET request to the API with the requests library 2. Send the requested data to the Kafka producer 3. Add a sleep statement to not overwhelm the web server. \n\n&amp;nbsp;\n\nI was just wondering if this is the best way to get the data from the API or if there is a more elegant solution that I may not have considered? For example, I\u2019ve seen some Kafka code written in Java that uses the EventHandler class. I\u2019ve also looked into Pythons asyncio module but it doesn\u2019t look like there would be much benefit to using it when just getting data from a single API?", "author_fullname": "t2_5bha3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "More elegant solution to constantly get data from a web API?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1708lhd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696479847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently working on a hobby project and am hoping to continuously stream some data from a web API into my Apache Kafka producer. I am currently using the Confluent Kafka library for python to write my producer and consumer and thus also intend for my API data retrieval to be written in Python as well. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;In terms of getting the data from the API my current solution is to do the following in a loop: 1. Send a GET request to the API with the requests library 2. Send the requested data to the Kafka producer 3. Add a sleep statement to not overwhelm the web server. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;I was just wondering if this is the best way to get the data from the API or if there is a more elegant solution that I may not have considered? For example, I\u2019ve seen some Kafka code written in Java that uses the EventHandler class. I\u2019ve also looked into Pythons asyncio module but it doesn\u2019t look like there would be much benefit to using it when just getting data from a single API?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1708lhd", "is_robot_indexable": true, "report_reasons": null, "author": "GreenSquid", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1708lhd/more_elegant_solution_to_constantly_get_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1708lhd/more_elegant_solution_to_constantly_get_data_from/", "subreddit_subscribers": 132286, "created_utc": 1696479847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cube integrates its semantic layer with dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170n9rf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1696525451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/introducing-dbt-integration-with-cube", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "170n9rf", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170n9rf/cube_integrates_its_semantic_layer_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/introducing-dbt-integration-with-cube", "subreddit_subscribers": 132286, "created_utc": 1696525451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I need to know which tools is used to generate software architectures infographics like this?\n\ndespite the specific tool used for the below image, are there any other suggested tools to use to generate instagram posts for software architectures?\n\nhttps://preview.redd.it/rz6zkck1edsb1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=4081daef291deffb4f657364b56e0d1f6aeb831b\n\n&amp;#x200B;\n\nOr like those ones with moving arrows:\n\nhttps://preview.redd.it/i0bcjzo2edsb1.png?width=664&amp;format=png&amp;auto=webp&amp;s=052e1fa1e95bc0c888967550d408b38b7c8348bf", "author_fullname": "t2_i2h7dt11", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to generate DE architectures infographics like this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"i0bcjzo2edsb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 136, "x": 108, "u": "https://preview.redd.it/i0bcjzo2edsb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ad274224d642a1f04d329d789ca17a690197bc9"}, {"y": 273, "x": 216, "u": "https://preview.redd.it/i0bcjzo2edsb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a32dac75a8f7ddb40296d81014a7e1a0176fada6"}, {"y": 404, "x": 320, "u": "https://preview.redd.it/i0bcjzo2edsb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=161e2388a3e03b632397d342752453405bb8a97e"}, {"y": 809, "x": 640, "u": "https://preview.redd.it/i0bcjzo2edsb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=35684e0291acc7b160023f26bc160737ca949f9e"}], "s": {"y": 840, "x": 664, "u": "https://preview.redd.it/i0bcjzo2edsb1.png?width=664&amp;format=png&amp;auto=webp&amp;s=052e1fa1e95bc0c888967550d408b38b7c8348bf"}, "id": "i0bcjzo2edsb1"}, "rz6zkck1edsb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/rz6zkck1edsb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=59bb85de32473e01c960ab4d63b56d4e37e8fbad"}, {"y": 108, "x": 216, "u": "https://preview.redd.it/rz6zkck1edsb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=78572a7173b010602688524cad958967ea82d918"}, {"y": 160, "x": 320, "u": "https://preview.redd.it/rz6zkck1edsb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c01b34199162918c507f104806825efb0076f840"}, {"y": 320, "x": 640, "u": "https://preview.redd.it/rz6zkck1edsb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0b0a66fc6ba2985615048798d2139eeff4cd09bd"}, {"y": 480, "x": 960, "u": "https://preview.redd.it/rz6zkck1edsb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9b604b64517feb8ab9290764b3a999c837bc38b3"}], "s": {"y": 501, "x": 1000, "u": "https://preview.redd.it/rz6zkck1edsb1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=4081daef291deffb4f657364b56e0d1f6aeb831b"}, "id": "rz6zkck1edsb1"}}, "name": "t3_170fmce", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/n6lrokxk-_bD0N6_4fXZZdw9HFpIupAhulJLEc-O-To.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696505613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I need to know which tools is used to generate software architectures infographics like this?&lt;/p&gt;\n\n&lt;p&gt;despite the specific tool used for the below image, are there any other suggested tools to use to generate instagram posts for software architectures?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rz6zkck1edsb1.png?width=1000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4081daef291deffb4f657364b56e0d1f6aeb831b\"&gt;https://preview.redd.it/rz6zkck1edsb1.png?width=1000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4081daef291deffb4f657364b56e0d1f6aeb831b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Or like those ones with moving arrows:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/i0bcjzo2edsb1.png?width=664&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=052e1fa1e95bc0c888967550d408b38b7c8348bf\"&gt;https://preview.redd.it/i0bcjzo2edsb1.png?width=664&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=052e1fa1e95bc0c888967550d408b38b7c8348bf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170fmce", "is_robot_indexable": true, "report_reasons": null, "author": "Omar-Tech", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170fmce/how_to_generate_de_architectures_infographics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170fmce/how_to_generate_de_architectures_infographics/", "subreddit_subscribers": 132286, "created_utc": 1696505613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Posted this over in /r/Azure , but wanted to get yawls perspective too. \n\n  \nI  am looking to migrate off of dedicated sql pool - it is too expensive. We are currently using  azure synapse studio + dedicated sql pool + adl. here is some workflows  we do:\n\n1) incremental data loads from transnational sql databases. we load this data pretty much straight into the dwh.\n\n2) about  5-6 external sources we pull data via an API or maybe a excel  spreadsheet/csv for adhoc data from my customer facing teams. we load  the data from the external sources into our data lake. I just use azure  batch to execute python code that does this for me. from there we create  external tables to load them into our dedicated sql pool.\n\n3) once  all the data is loaded into the sql pool, we then do various  transformations and aggregations on the data, and store the results in  sql, which are then loaded into our PBI data model. The refreshes happen  1x per day, typically around 4am.\n\nthis  all being said, dedicated sql pools are SUPER expensive. I do like  being able to load the external sources directly into sql, so i was  thinking about migrating off of dedicated sql pool and just using  serverless sql in synapse. We would just export data from our  transactional sql databases onto the lake in parquet format. One of my  concerns with this is everything would essentially be views, as i dont  think you can create/manage the transformations using CTAS statements.  This doesnt seem like it would scale well as we continue to get more  data.\n\nHonestly, were around 266gb  of data total, so i wouldnt be opposed to just using sql, i think  dedicated sql pool is overkill. BUT,  i dont think azure SQL has all of  the virtualisation tech like serverless or dedicated sql pool has, and  my aggregations might take longer, but i think i can fine tune  a lot to  make that work (and azure sql database is MUCHHHH cheaper). If i look  at the pricing of azure sql server managed instance (which from my  understanding does have the virtualisation tech) its around the same as  the dedicated sql pool, so doesnt seem worth to me.\n\nhow  are ya'll doing this in a cost effective way? There are so many  buzzwords and buzz tech out there, im not sure what i should be looking at. The term Synapse is super confusing because it seems interchangable with serverless or dedicated sql pool, when it also can act as an orchestration tool. I seem a lot of people saying databricks + adl + datafactory is the  way to go, but then there is the added expensive of databricks and learning databricks.. I am  also a 1 man team on the reporting and data side, and i am also managing  another separate team on top of this (lol the tech recession is real).  point is, i feel very lost, and i dont want to spend a bunch of time migrating to a solution that wont scale or isnt cost effective. I appreciate any direction and advice you  fellow data engineers can give.\n\nThanks!", "author_fullname": "t2_jrmn04", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solutions to migrate off of dedicated SQL Pool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170ltz3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696522062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Posted this over in &lt;a href=\"/r/Azure\"&gt;/r/Azure&lt;/a&gt; , but wanted to get yawls perspective too. &lt;/p&gt;\n\n&lt;p&gt;I  am looking to migrate off of dedicated sql pool - it is too expensive. We are currently using  azure synapse studio + dedicated sql pool + adl. here is some workflows  we do:&lt;/p&gt;\n\n&lt;p&gt;1) incremental data loads from transnational sql databases. we load this data pretty much straight into the dwh.&lt;/p&gt;\n\n&lt;p&gt;2) about  5-6 external sources we pull data via an API or maybe a excel  spreadsheet/csv for adhoc data from my customer facing teams. we load  the data from the external sources into our data lake. I just use azure  batch to execute python code that does this for me. from there we create  external tables to load them into our dedicated sql pool.&lt;/p&gt;\n\n&lt;p&gt;3) once  all the data is loaded into the sql pool, we then do various  transformations and aggregations on the data, and store the results in  sql, which are then loaded into our PBI data model. The refreshes happen  1x per day, typically around 4am.&lt;/p&gt;\n\n&lt;p&gt;this  all being said, dedicated sql pools are SUPER expensive. I do like  being able to load the external sources directly into sql, so i was  thinking about migrating off of dedicated sql pool and just using  serverless sql in synapse. We would just export data from our  transactional sql databases onto the lake in parquet format. One of my  concerns with this is everything would essentially be views, as i dont  think you can create/manage the transformations using CTAS statements.  This doesnt seem like it would scale well as we continue to get more  data.&lt;/p&gt;\n\n&lt;p&gt;Honestly, were around 266gb  of data total, so i wouldnt be opposed to just using sql, i think  dedicated sql pool is overkill. BUT,  i dont think azure SQL has all of  the virtualisation tech like serverless or dedicated sql pool has, and  my aggregations might take longer, but i think i can fine tune  a lot to  make that work (and azure sql database is MUCHHHH cheaper). If i look  at the pricing of azure sql server managed instance (which from my  understanding does have the virtualisation tech) its around the same as  the dedicated sql pool, so doesnt seem worth to me.&lt;/p&gt;\n\n&lt;p&gt;how  are ya&amp;#39;ll doing this in a cost effective way? There are so many  buzzwords and buzz tech out there, im not sure what i should be looking at. The term Synapse is super confusing because it seems interchangable with serverless or dedicated sql pool, when it also can act as an orchestration tool. I seem a lot of people saying databricks + adl + datafactory is the  way to go, but then there is the added expensive of databricks and learning databricks.. I am  also a 1 man team on the reporting and data side, and i am also managing  another separate team on top of this (lol the tech recession is real).  point is, i feel very lost, and i dont want to spend a bunch of time migrating to a solution that wont scale or isnt cost effective. I appreciate any direction and advice you  fellow data engineers can give.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170ltz3", "is_robot_indexable": true, "report_reasons": null, "author": "soricellia", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170ltz3/solutions_to_migrate_off_of_dedicated_sql_pool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170ltz3/solutions_to_migrate_off_of_dedicated_sql_pool/", "subreddit_subscribers": 132286, "created_utc": 1696522062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Saw this post about how to get similar functionality to dbt Cloud using other OSS tools, wondering if anyone has done this and what your experience has been\n\n  \ntl;dr  \ndbt Cloud or dbt Core + vs code + airflow + cube.dev\n\nhttps://datacoves.com/post/dbt-core-vs-dbt-cloud-key-differences", "author_fullname": "t2_vx67of8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Cloud extra features worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170l0nw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696520038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Saw this post about how to get similar functionality to dbt Cloud using other OSS tools, wondering if anyone has done this and what your experience has been&lt;/p&gt;\n\n&lt;p&gt;tl;dr&lt;br/&gt;\ndbt Cloud or dbt Core + vs code + airflow + cube.dev&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://datacoves.com/post/dbt-core-vs-dbt-cloud-key-differences\"&gt;https://datacoves.com/post/dbt-core-vs-dbt-cloud-key-differences&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?auto=webp&amp;s=d3cc503fb34529b9e99c792a7117e5fc053ac06b", "width": 2400, "height": 1254}, "resolutions": [{"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c6aedf9503b00fdb31f500fd840357bf700d9507", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ec9a9837c66cb33c17898fd385442393eebb33b7", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=829d1b2e30c6aedbf56d477f7a8419d039d4be73", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a675320e601b25b36e1e6ac4f051e0b27f475414", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6a488a73fbc7d27fce74b0ca11a7b2c828a39519", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=099e281cdfcfe53d01e3290cb938387eb3cee441", "width": 1080, "height": 564}], "variants": {}, "id": "xUIE53y-az5HrMPPgq4ndFAPYxY_HJJQd0C1S2OtT0E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "170l0nw", "is_robot_indexable": true, "report_reasons": null, "author": "Hot_Map_7868", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170l0nw/dbt_cloud_extra_features_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170l0nw/dbt_cloud_extra_features_worth_it/", "subreddit_subscribers": 132286, "created_utc": 1696520038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello future fellows , \n\nI\u2019m a data analyst with almost 2 years of exp , \n&amp; I want to pursue a career with data engineering..\n\nI\u2019ve used sql for extraction &amp; analyze data at my work , &amp; python for deep dive analysis ,\n\n&amp; recently I\u2019m studying DSA , reading DWH toolkit book , \n\nIs that enough for me for cracking DE interviews ?\n&amp; \nIf you could suggest me one ETL tool to study &amp; practice with , what would be it ? \n\nI\u2019m asking for your help as I don\u2019t have a network in DE , \n\nThanks helpers \ud83e\udd0d", "author_fullname": "t2_t3nz93za", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1706dax", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696473160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello future fellows , &lt;/p&gt;\n\n&lt;p&gt;I\u2019m a data analyst with almost 2 years of exp , \n&amp;amp; I want to pursue a career with data engineering..&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve used sql for extraction &amp;amp; analyze data at my work , &amp;amp; python for deep dive analysis ,&lt;/p&gt;\n\n&lt;p&gt;&amp;amp; recently I\u2019m studying DSA , reading DWH toolkit book , &lt;/p&gt;\n\n&lt;p&gt;Is that enough for me for cracking DE interviews ?\n&amp;amp; \nIf you could suggest me one ETL tool to study &amp;amp; practice with , what would be it ? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m asking for your help as I don\u2019t have a network in DE , &lt;/p&gt;\n\n&lt;p&gt;Thanks helpers \ud83e\udd0d&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1706dax", "is_robot_indexable": true, "report_reasons": null, "author": "Repulsive-Ad7769", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1706dax/etl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1706dax/etl_tool/", "subreddit_subscribers": 132286, "created_utc": 1696473160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI have a dataset of 1 billion latitude and longitude coordinates for vessels, and let's say it comes out to about 500GB or 1TB. I want to store the dataset in s3 and then create a database in Athena and populate the dataset into an Athena table. Then, I want to create a front end tool where a user enters the name of a vessel, and it returns the coordinates for that vessel and displays them on a map. I would like to do this over and over and over.\n\nDoes anyone have any idea how much this would cost in storage and computing? Let's say I run 15 queries against the 1 billion rows every day for 3 months.\n\nThank you!\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_6f5ggoc3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cost for AWS Storage and Computation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1704cur", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696467621.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have a dataset of 1 billion latitude and longitude coordinates for vessels, and let&amp;#39;s say it comes out to about 500GB or 1TB. I want to store the dataset in s3 and then create a database in Athena and populate the dataset into an Athena table. Then, I want to create a front end tool where a user enters the name of a vessel, and it returns the coordinates for that vessel and displays them on a map. I would like to do this over and over and over.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any idea how much this would cost in storage and computing? Let&amp;#39;s say I run 15 queries against the 1 billion rows every day for 3 months.&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1704cur", "is_robot_indexable": true, "report_reasons": null, "author": "wackomama", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1704cur/cost_for_aws_storage_and_computation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1704cur/cost_for_aws_storage_and_computation/", "subreddit_subscribers": 132286, "created_utc": 1696467621.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work in the consumer packaged goods (CPG) industry. Specifically the US market. Think of the sorts of items you buy on a consistent basis at a grocery, big box, club, or drug store. Everything from bagged salad to cough syrup.\n\nOver the past several years I\u2019ve worked at a mid-size company and moved from a basic analyst role to wearing several hats. Mostly taking on data engineering and business intelligence tasks. The hot thing right now is Power BI reporting, so I build out data pipelines, create data models, and design Power BI reports. This has lead to a lot of career success at my company, but lately I\u2019ve been more and more frustrated by the seemingly antiquated data practices in the CPG industry.\n\nMy company is a bit unique in that we are not a single retailer or manufacturer. We work with CPG brands and retailers across the entire country. This means we rely heavily on syndicated retail data from providers like Circana (merger between IRI and The NPD Group) and NielsenIQ (NIQ). They get retail scan data from almost every CPG retailer in the country. Except some retailers are exclusive to one platform, so you\u2019ll never have a complete picture without both.\n\nUnfortunately, Circana and NIQ do not make it easy to extract what I consider medium-size data. Everything is a portal with data presented across various \u201cdashboards\u201d and rudimentary no-code report creator web apps. The minute you ask about an API or data transfer service they wonder why you would ever want to leave their platform. And when you do convince your company to purchase large data extract access or similar (why do we need that when we have \u201canalysts\u201d who can extract hundreds of small data pieces through the web portal?), you find out it\u2019s incredibly fragile, inflexible, slow, and unreliable. The pricing for access is never transparent either.\n\nIn some cases, I can access a retailers\u2019 data directly (for the manufacturers my company works with) though their web portal and reverse engineer an API. But that\u2019s typically a limited data set and more supply chain focused.\n\nHas anyone developed a successful data strategy in the CPG realm? Is there an opportunity here to solve these problems? I'm thinking about changing industries - are these normal problems in tech/other areas?", "author_fullname": "t2_3hkwv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Working with CPG Retail Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17033ot", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696464281.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in the consumer packaged goods (CPG) industry. Specifically the US market. Think of the sorts of items you buy on a consistent basis at a grocery, big box, club, or drug store. Everything from bagged salad to cough syrup.&lt;/p&gt;\n\n&lt;p&gt;Over the past several years I\u2019ve worked at a mid-size company and moved from a basic analyst role to wearing several hats. Mostly taking on data engineering and business intelligence tasks. The hot thing right now is Power BI reporting, so I build out data pipelines, create data models, and design Power BI reports. This has lead to a lot of career success at my company, but lately I\u2019ve been more and more frustrated by the seemingly antiquated data practices in the CPG industry.&lt;/p&gt;\n\n&lt;p&gt;My company is a bit unique in that we are not a single retailer or manufacturer. We work with CPG brands and retailers across the entire country. This means we rely heavily on syndicated retail data from providers like Circana (merger between IRI and The NPD Group) and NielsenIQ (NIQ). They get retail scan data from almost every CPG retailer in the country. Except some retailers are exclusive to one platform, so you\u2019ll never have a complete picture without both.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, Circana and NIQ do not make it easy to extract what I consider medium-size data. Everything is a portal with data presented across various \u201cdashboards\u201d and rudimentary no-code report creator web apps. The minute you ask about an API or data transfer service they wonder why you would ever want to leave their platform. And when you do convince your company to purchase large data extract access or similar (why do we need that when we have \u201canalysts\u201d who can extract hundreds of small data pieces through the web portal?), you find out it\u2019s incredibly fragile, inflexible, slow, and unreliable. The pricing for access is never transparent either.&lt;/p&gt;\n\n&lt;p&gt;In some cases, I can access a retailers\u2019 data directly (for the manufacturers my company works with) though their web portal and reverse engineer an API. But that\u2019s typically a limited data set and more supply chain focused.&lt;/p&gt;\n\n&lt;p&gt;Has anyone developed a successful data strategy in the CPG realm? Is there an opportunity here to solve these problems? I&amp;#39;m thinking about changing industries - are these normal problems in tech/other areas?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17033ot", "is_robot_indexable": true, "report_reasons": null, "author": "pennant", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17033ot/working_with_cpg_retail_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17033ot/working_with_cpg_retail_data/", "subreddit_subscribers": 132286, "created_utc": 1696464281.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just curious to know what are ya'lls favorite conferences are? Whether it's a conference dedicated to data engineering topics/tech or just a conference that had some/a few data-engineering related talks/presentations.\n\n Looking for a bit more insight on:\n\n1. **Conference Name**\n2. **Location &amp; Format** (in-person? Virtual?)\n3. **Frequency** (one time thing? Annual?)\n4. **Why was it great? What did you like the most about it?** ", "author_fullname": "t2_6l1e382d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite conferences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1700a2u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696457388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious to know what are ya&amp;#39;lls favorite conferences are? Whether it&amp;#39;s a conference dedicated to data engineering topics/tech or just a conference that had some/a few data-engineering related talks/presentations.&lt;/p&gt;\n\n&lt;p&gt;Looking for a bit more insight on:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Conference Name&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Location &amp;amp; Format&lt;/strong&gt; (in-person? Virtual?)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Frequency&lt;/strong&gt; (one time thing? Annual?)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Why was it great? What did you like the most about it?&lt;/strong&gt; &lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1700a2u", "is_robot_indexable": true, "report_reasons": null, "author": "unfair_pandah", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1700a2u/favorite_conferences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1700a2u/favorite_conferences/", "subreddit_subscribers": 132286, "created_utc": 1696457388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a DE with 4+ YOE, I work mostly with SQL, python, typescript and sometimes pyspark, but the latter only at a superficial level.\n\nFor career purposes I wanna deepen my spark knowledge and was recommended the spark bundle course from rockthejvm. However, the course is in scala and not pyspark.\n\nDo you think it's possible to follow the course properly without any experience in scala, and just figure it out on the go?\n\nLet me know what you think!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Think I can learn spark+scala at the same time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170dfah", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696497745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a DE with 4+ YOE, I work mostly with SQL, python, typescript and sometimes pyspark, but the latter only at a superficial level.&lt;/p&gt;\n\n&lt;p&gt;For career purposes I wanna deepen my spark knowledge and was recommended the spark bundle course from rockthejvm. However, the course is in scala and not pyspark.&lt;/p&gt;\n\n&lt;p&gt;Do you think it&amp;#39;s possible to follow the course properly without any experience in scala, and just figure it out on the go?&lt;/p&gt;\n\n&lt;p&gt;Let me know what you think!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "170dfah", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170dfah/think_i_can_learn_sparkscala_at_the_same_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170dfah/think_i_can_learn_sparkscala_at_the_same_time/", "subreddit_subscribers": 132286, "created_utc": 1696497745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! \ud83d\udc4b\n\nI hope you're all doing well. I'm a data engineer with 4 years of experience, and I'm contemplating a move to the United States from Australia as I'm looking for a change in environment and have been interested in experiencing living/working in the US.\n\nI have a few questions and would greatly appreciate any insights or recommendations from those who have experience in this field or have been in a similar situation:\n\n1. **Choosing a State/City:** First and foremost, I'm having a hard time deciding on the best state or city to settle in. Are there any particular areas in the US that are known for their strong data engineering job market or tech industry in general? What factors should I consider while making this decision, such as cost of living, job opportunities, or quality of life?\n\n2. **Job Hunting Process:** I'd like to know more about the process of looking for data engineering opportunities in the US. Which job boards, websites, or platforms are most effective for job searches in this field? Are there any specific resources tailored to international job seekers like me? \n\n3. **Typical Hiring Process:** What is the typical hiring process like for data engineering positions in the US? Any insights into the application, interview, and selection stages specifically for international applicants would be immensely helpful.\n\n4. **Relocation Experience:** If you've made a similar move from another country to the US, particularly in the tech industry, I'd love to hear about your experiences. What challenges did you face during the relocation process, and how did you overcome them? Any tips or lessons learned that you'd like to share?\n\nI'm excited about the potential opportunities in the US but want to ensure that I'm making an informed decision. Your input and advice would mean a lot to me as I embark on this journey! Thank you in advance for your time and help!", "author_fullname": "t2_itoec5nn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Guidance on Relocating to the US as a Data Engineer from Australia", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1704wfw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696469101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all doing well. I&amp;#39;m a data engineer with 4 years of experience, and I&amp;#39;m contemplating a move to the United States from Australia as I&amp;#39;m looking for a change in environment and have been interested in experiencing living/working in the US.&lt;/p&gt;\n\n&lt;p&gt;I have a few questions and would greatly appreciate any insights or recommendations from those who have experience in this field or have been in a similar situation:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Choosing a State/City:&lt;/strong&gt; First and foremost, I&amp;#39;m having a hard time deciding on the best state or city to settle in. Are there any particular areas in the US that are known for their strong data engineering job market or tech industry in general? What factors should I consider while making this decision, such as cost of living, job opportunities, or quality of life?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Job Hunting Process:&lt;/strong&gt; I&amp;#39;d like to know more about the process of looking for data engineering opportunities in the US. Which job boards, websites, or platforms are most effective for job searches in this field? Are there any specific resources tailored to international job seekers like me? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Typical Hiring Process:&lt;/strong&gt; What is the typical hiring process like for data engineering positions in the US? Any insights into the application, interview, and selection stages specifically for international applicants would be immensely helpful.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Relocation Experience:&lt;/strong&gt; If you&amp;#39;ve made a similar move from another country to the US, particularly in the tech industry, I&amp;#39;d love to hear about your experiences. What challenges did you face during the relocation process, and how did you overcome them? Any tips or lessons learned that you&amp;#39;d like to share?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m excited about the potential opportunities in the US but want to ensure that I&amp;#39;m making an informed decision. Your input and advice would mean a lot to me as I embark on this journey! Thank you in advance for your time and help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1704wfw", "is_robot_indexable": true, "report_reasons": null, "author": "CocoaDependent1664", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1704wfw/seeking_guidance_on_relocating_to_the_us_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1704wfw/seeking_guidance_on_relocating_to_the_us_as_a/", "subreddit_subscribers": 132286, "created_utc": 1696469101.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_y9qpd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I built an open-source scraping API that returns structured JSON data using GPT.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170m9lu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1696523115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/semanser/JsonGenius", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "170m9lu", "is_robot_indexable": true, "report_reasons": null, "author": "semanser", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170m9lu/i_built_an_opensource_scraping_api_that_returns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/semanser/JsonGenius", "subreddit_subscribers": 132286, "created_utc": 1696523115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to use shipyard to automate a bunch of PostgreSQL procedures. I\u2019m using shipyard as the data orchestrator. Their help desk support response is good, but it\u2019s taken 2 days for them so far not to come up with a solution. The problem \u2026it seems you can do all the pretty stuff like set up a connection to PostgreSQL\u2026and even when you grant execute on the user for PostgreSQL and for the specific procedures to run\u2026shipyard does not run the procedures!\n\nAm I missing something simple (probably!)?\n\nAre there any alternatives to use (airflow and prefect are a tad too involved for me right now\u2026a user interface for the main is what I\u2019m looking to use\u2026just to schedule and keep tabs on the jobs)\n\nCheers", "author_fullname": "t2_hg12i599c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shipyard - PostgreSQL fleet, not working", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170j5u8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696515444.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to use shipyard to automate a bunch of PostgreSQL procedures. I\u2019m using shipyard as the data orchestrator. Their help desk support response is good, but it\u2019s taken 2 days for them so far not to come up with a solution. The problem \u2026it seems you can do all the pretty stuff like set up a connection to PostgreSQL\u2026and even when you grant execute on the user for PostgreSQL and for the specific procedures to run\u2026shipyard does not run the procedures!&lt;/p&gt;\n\n&lt;p&gt;Am I missing something simple (probably!)?&lt;/p&gt;\n\n&lt;p&gt;Are there any alternatives to use (airflow and prefect are a tad too involved for me right now\u2026a user interface for the main is what I\u2019m looking to use\u2026just to schedule and keep tabs on the jobs)&lt;/p&gt;\n\n&lt;p&gt;Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170j5u8", "is_robot_indexable": true, "report_reasons": null, "author": "BumblyWurzle", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170j5u8/shipyard_postgresql_fleet_not_working/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170j5u8/shipyard_postgresql_fleet_not_working/", "subreddit_subscribers": 132286, "created_utc": 1696515444.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently using Looker to display carbon offset data that is stored in BigQuery. I am planning to develop my own JavaScript-based dashboard, and I am considering using Memorystore with Redis as a cache layer. However, I am concerned that Redis may be too expensive for my needs.\n\nMy data volume is small (less than 300 MB) and will not increase much in the future. I want my JavaScript dashboard to be as flexible as Looker.\n\n**Questions:**\n\n1. Can using materialized views and query caching in BigQuery provide good performance for a JavaScript dashboard?\n2. Is Redis necessary in my case? Won't it be too expensive?\n3. Can you share any links to articles or tutorials on how to implement a Looker-like dashboard using BigQuery and JavaScript?", "author_fullname": "t2_brrw1jso", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Caching Layer and Replacing Looker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170es90", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696502824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently using Looker to display carbon offset data that is stored in BigQuery. I am planning to develop my own JavaScript-based dashboard, and I am considering using Memorystore with Redis as a cache layer. However, I am concerned that Redis may be too expensive for my needs.&lt;/p&gt;\n\n&lt;p&gt;My data volume is small (less than 300 MB) and will not increase much in the future. I want my JavaScript dashboard to be as flexible as Looker.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can using materialized views and query caching in BigQuery provide good performance for a JavaScript dashboard?&lt;/li&gt;\n&lt;li&gt;Is Redis necessary in my case? Won&amp;#39;t it be too expensive?&lt;/li&gt;\n&lt;li&gt;Can you share any links to articles or tutorials on how to implement a Looker-like dashboard using BigQuery and JavaScript?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170es90", "is_robot_indexable": true, "report_reasons": null, "author": "No-Reflection-3622", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170es90/caching_layer_and_replacing_looker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170es90/caching_layer_and_replacing_looker/", "subreddit_subscribers": 132286, "created_utc": 1696502824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Friends,\n\nI need some guidance on our data journey. We currently use GCP as our vendor and have been storing loads of data in BQ for reporting,  it hasn't been fun. I've used traditional warehouses before but seeing BQ amazes me in good ways yet I feel its just not the right step for us considering we have data quality issues upstream that needs proper oversight which a traditional warehouses can provide.\n\n1. BQ doesn't have a concept of pk fk in a way that we can enforce referential integrity when loading data. \n\n2. With above true, would a right approach for us be to add a traditional cloud sql server relational warehouses (kimball methodology) where data is stored and maintained outside of BQ, then exporting summary/ clean data back into BQ for analysis.\n\n\nThoughts", "author_fullname": "t2_efykxnpyj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BigQuery warehouse VS Traditional", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170cyrb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696495962.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Friends,&lt;/p&gt;\n\n&lt;p&gt;I need some guidance on our data journey. We currently use GCP as our vendor and have been storing loads of data in BQ for reporting,  it hasn&amp;#39;t been fun. I&amp;#39;ve used traditional warehouses before but seeing BQ amazes me in good ways yet I feel its just not the right step for us considering we have data quality issues upstream that needs proper oversight which a traditional warehouses can provide.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;BQ doesn&amp;#39;t have a concept of pk fk in a way that we can enforce referential integrity when loading data. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;With above true, would a right approach for us be to add a traditional cloud sql server relational warehouses (kimball methodology) where data is stored and maintained outside of BQ, then exporting summary/ clean data back into BQ for analysis.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thoughts&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170cyrb", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Accountant9334", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170cyrb/bigquery_warehouse_vs_traditional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170cyrb/bigquery_warehouse_vs_traditional/", "subreddit_subscribers": 132286, "created_utc": 1696495962.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working in Palantir foundry daily. Sometimes when I check jobs I get worried because I\u2019m not sure if what Palantir use is industry standard.\nTo the best of what I can see this is what they have\n\nCode Repos / Codeworkbooks - Pyspark (widely applicable) however behind the scenes Palantir create the tables and have a concept of Input, Output which doesn\u2019t exist in real pyspark.\nPandas can be written in Codeworkbooks\n\nData lineage - low code visual tool for seeing data lineages and running schedule builds. It uses some type of Airflow technology behind the scenes. It\u2019s incredibly powerful once you get the gist of it and can super quickly run schedule builds. \n\nOne of my biggest \u201cfixes\u201d was finding out some idiot scheduled a build once minute for the past 2 years. My fix was to reduce it to once a day. \n\nContour - Qliksense, Apache Superset (maybe) you can do filtering, create charts, pivot tables and use a weird form of what I think is SQL (Expression language). Has no real world equivalent and is very different. Great tool. It helps me break down datasets and see what my deltas are. \n\nOntology - dataset storage uses some type of DeltaLake storage but the actual Ontology tool I\u2019ve idea if it has a real world equivalent. Maybe Business Objets in SAP. \n\nSlate - garbage piece of shit UI tech \n\nData Health - kinda useful confusing to use \n\nThey are the principal tools I use everyday in Palantir Foundry \n\nGeneral thoughts:\n\n- it\u2019s great if you\u2019re a beginner because it\u2019s pretty easy to get ok at it. It\u2019s frustrating if you want more control because they abstract a lot of stuff away. They have weird implementations of certain technologies.  Sometimes you want to really get into the Spark API or use the newest release and you\u2019re stuck with what Palantir have. \n\n- Data Expectations &amp; testing implementation is really good. \n\n- Their technical support seem pretty good. Their engineers are intimidatingly good. \n\n- really easy to find and search other datasets that could be related.\n\n- Can be slow unstable when pushing code. My code commits regular revert. Git is all point and click which is bad because for most devs Git is second nature.\n\nHas anyone worked with Palantir Foundry? How standard are their tech? I get worried I\u2019m pigeonholed and how to explain to other companies this weird proprietary technology.\n\nEdit: Just as a last aside it really shows how much some of these big companies have stolen everything from OpenSource and repackaged it as mind blowing technology to the C-suite. All those people who ever corrected something or helped make an open source library should really get a cheque from Amazon or Palantir anyway back to reality\u2026", "author_fullname": "t2_nutp89h4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How applicable is Palantir foundry to Data engineering in general?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_170u6u8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696541897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working in Palantir foundry daily. Sometimes when I check jobs I get worried because I\u2019m not sure if what Palantir use is industry standard.\nTo the best of what I can see this is what they have&lt;/p&gt;\n\n&lt;p&gt;Code Repos / Codeworkbooks - Pyspark (widely applicable) however behind the scenes Palantir create the tables and have a concept of Input, Output which doesn\u2019t exist in real pyspark.\nPandas can be written in Codeworkbooks&lt;/p&gt;\n\n&lt;p&gt;Data lineage - low code visual tool for seeing data lineages and running schedule builds. It uses some type of Airflow technology behind the scenes. It\u2019s incredibly powerful once you get the gist of it and can super quickly run schedule builds. &lt;/p&gt;\n\n&lt;p&gt;One of my biggest \u201cfixes\u201d was finding out some idiot scheduled a build once minute for the past 2 years. My fix was to reduce it to once a day. &lt;/p&gt;\n\n&lt;p&gt;Contour - Qliksense, Apache Superset (maybe) you can do filtering, create charts, pivot tables and use a weird form of what I think is SQL (Expression language). Has no real world equivalent and is very different. Great tool. It helps me break down datasets and see what my deltas are. &lt;/p&gt;\n\n&lt;p&gt;Ontology - dataset storage uses some type of DeltaLake storage but the actual Ontology tool I\u2019ve idea if it has a real world equivalent. Maybe Business Objets in SAP. &lt;/p&gt;\n\n&lt;p&gt;Slate - garbage piece of shit UI tech &lt;/p&gt;\n\n&lt;p&gt;Data Health - kinda useful confusing to use &lt;/p&gt;\n\n&lt;p&gt;They are the principal tools I use everyday in Palantir Foundry &lt;/p&gt;\n\n&lt;p&gt;General thoughts:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;it\u2019s great if you\u2019re a beginner because it\u2019s pretty easy to get ok at it. It\u2019s frustrating if you want more control because they abstract a lot of stuff away. They have weird implementations of certain technologies.  Sometimes you want to really get into the Spark API or use the newest release and you\u2019re stuck with what Palantir have. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Data Expectations &amp;amp; testing implementation is really good. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Their technical support seem pretty good. Their engineers are intimidatingly good. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;really easy to find and search other datasets that could be related.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Can be slow unstable when pushing code. My code commits regular revert. Git is all point and click which is bad because for most devs Git is second nature.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Has anyone worked with Palantir Foundry? How standard are their tech? I get worried I\u2019m pigeonholed and how to explain to other companies this weird proprietary technology.&lt;/p&gt;\n\n&lt;p&gt;Edit: Just as a last aside it really shows how much some of these big companies have stolen everything from OpenSource and repackaged it as mind blowing technology to the C-suite. All those people who ever corrected something or helped make an open source library should really get a cheque from Amazon or Palantir anyway back to reality\u2026&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "170u6u8", "is_robot_indexable": true, "report_reasons": null, "author": "hositir", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170u6u8/how_applicable_is_palantir_foundry_to_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170u6u8/how_applicable_is_palantir_foundry_to_data/", "subreddit_subscribers": 132286, "created_utc": 1696541897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All,\nWhat are your views on Microsoft Purview as a Data Cataloguing solution for enterprise?\nMy org is pivoting from Collibra as an Enterprise Data  Cataloguing solution to MS Purview and I don't feel good about this.", "author_fullname": "t2_cj0b4yt6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Catalog", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_170twld", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696541230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All,\nWhat are your views on Microsoft Purview as a Data Cataloguing solution for enterprise?\nMy org is pivoting from Collibra as an Enterprise Data  Cataloguing solution to MS Purview and I don&amp;#39;t feel good about this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "170twld", "is_robot_indexable": true, "report_reasons": null, "author": "Affectionate-Most564", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170twld/data_catalog/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170twld/data_catalog/", "subreddit_subscribers": 132286, "created_utc": 1696541230.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}