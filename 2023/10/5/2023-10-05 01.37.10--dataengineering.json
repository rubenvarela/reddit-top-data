{"kind": "Listing", "data": {"after": "t3_16zg10z", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All,\n\nJust wondering what data engineering tool(ETL, warehouse, what have you) is most widely used these days. Seems every week i get distracted and try to learn some new tool, and i really want to narrow it down so i can be more focused. \n\nSeems that SQL is the only constant, but i know there's more to that. tia \n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_649o8hy9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What data engineering tools are popular right now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zm47c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 89, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 89, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696423046.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All,&lt;/p&gt;\n\n&lt;p&gt;Just wondering what data engineering tool(ETL, warehouse, what have you) is most widely used these days. Seems every week i get distracted and try to learn some new tool, and i really want to narrow it down so i can be more focused. &lt;/p&gt;\n\n&lt;p&gt;Seems that SQL is the only constant, but i know there&amp;#39;s more to that. tia &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zm47c", "is_robot_indexable": true, "report_reasons": null, "author": "albertcuy", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zm47c/what_data_engineering_tools_are_popular_right_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zm47c/what_data_engineering_tools_are_popular_right_now/", "subreddit_subscribers": 132117, "created_utc": 1696423046.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there,\n\nI'm a nurse, so I have a batchelors albeit incredibly unrelated. I'm approaching 30 and I'm so very burnt out.\n\nI want to get into data engineering, it's always interested me and it has a much broader field than pidgeon-hole nursing. (Actually I'm quite downplaying my love of data, design and solutions...), however, I need to find a qualification that fits around my current job.\n\nWhat would you suggest?\n\nI've been looking at online academies and Microsoft certifications etc. Doing a masters isn't financially viable right now. But there's so many pros and cons and all the pathways are a little overwhelming for someone new to the industry. I've been dwelling on this for over a year and I just need to take the plunge.\n\nAlso, my current role is quite well paid so ideally I'd be looking for my first data job to be \u00a340K+ (about $50K+), to cover for mortgage payments etc. Is there a qualification I can do that would help me get there?\n\nPlease help \ud83d\ude05", "author_fullname": "t2_740fnu1l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From nurse to data engineer ...send help.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zjdbu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 26, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 26, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696414631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a nurse, so I have a batchelors albeit incredibly unrelated. I&amp;#39;m approaching 30 and I&amp;#39;m so very burnt out.&lt;/p&gt;\n\n&lt;p&gt;I want to get into data engineering, it&amp;#39;s always interested me and it has a much broader field than pidgeon-hole nursing. (Actually I&amp;#39;m quite downplaying my love of data, design and solutions...), however, I need to find a qualification that fits around my current job.&lt;/p&gt;\n\n&lt;p&gt;What would you suggest?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking at online academies and Microsoft certifications etc. Doing a masters isn&amp;#39;t financially viable right now. But there&amp;#39;s so many pros and cons and all the pathways are a little overwhelming for someone new to the industry. I&amp;#39;ve been dwelling on this for over a year and I just need to take the plunge.&lt;/p&gt;\n\n&lt;p&gt;Also, my current role is quite well paid so ideally I&amp;#39;d be looking for my first data job to be \u00a340K+ (about $50K+), to cover for mortgage payments etc. Is there a qualification I can do that would help me get there?&lt;/p&gt;\n\n&lt;p&gt;Please help \ud83d\ude05&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16zjdbu", "is_robot_indexable": true, "report_reasons": null, "author": "Lil_Cherry_Beary", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zjdbu/from_nurse_to_data_engineer_send_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zjdbu/from_nurse_to_data_engineer_send_help/", "subreddit_subscribers": 132117, "created_utc": 1696414631.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Background:**   \nI am an analyst in an oil &amp; gas company who is interested in data engineering. Been working for about 10 years, most of it not related my current role as an analyst but specific to my industry. My background is not computer science, but chemical engineering. I've been doing a lot more python &amp; SQL. I'm getting much more used to the AWS tech stack (Glue, s3, redshift). \n\nI was in a meeting with him and reached out after the meeting to tell him I am interested in data engineering. I asked if he'd be willing to talk to me. He nicely agreed.\n\n**Why I'm nervous:**\n\nI don't want to waste this opportunity. I am used to the corporate networking, but I'm trying to sell myself and pivot into something quite frankly I don't have a lot of expertise in. One of my concerns is that to get a role I've heard they require testing and a technical interview (coding interview) even for internal. So I'm mostly scared that I won't be able to handle the technical parts!\n\n**Here are some questions I was thinking about**\n\n* Tell me about yourself (always gotta start with the classics)\n* Are there any opportunities to practice or learn more of the DE side?\n* Is there any advice you'd give to someone without a CS background to demonstrate their capability?\n\nAny other advice, questions, or a reminder of \"hey you're overthinking this\"", "author_fullname": "t2_7upjb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Speaking with head of data engineering for career pivot, what should I ask?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zafs9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696384323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;br/&gt;\nI am an analyst in an oil &amp;amp; gas company who is interested in data engineering. Been working for about 10 years, most of it not related my current role as an analyst but specific to my industry. My background is not computer science, but chemical engineering. I&amp;#39;ve been doing a lot more python &amp;amp; SQL. I&amp;#39;m getting much more used to the AWS tech stack (Glue, s3, redshift). &lt;/p&gt;\n\n&lt;p&gt;I was in a meeting with him and reached out after the meeting to tell him I am interested in data engineering. I asked if he&amp;#39;d be willing to talk to me. He nicely agreed.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why I&amp;#39;m nervous:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to waste this opportunity. I am used to the corporate networking, but I&amp;#39;m trying to sell myself and pivot into something quite frankly I don&amp;#39;t have a lot of expertise in. One of my concerns is that to get a role I&amp;#39;ve heard they require testing and a technical interview (coding interview) even for internal. So I&amp;#39;m mostly scared that I won&amp;#39;t be able to handle the technical parts!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here are some questions I was thinking about&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Tell me about yourself (always gotta start with the classics)&lt;/li&gt;\n&lt;li&gt;Are there any opportunities to practice or learn more of the DE side?&lt;/li&gt;\n&lt;li&gt;Is there any advice you&amp;#39;d give to someone without a CS background to demonstrate their capability?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any other advice, questions, or a reminder of &amp;quot;hey you&amp;#39;re overthinking this&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16zafs9", "is_robot_indexable": true, "report_reasons": null, "author": "chlor8", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zafs9/speaking_with_head_of_data_engineering_for_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zafs9/speaking_with_head_of_data_engineering_for_career/", "subreddit_subscribers": 132117, "created_utc": 1696384323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Last Monday I started a new job at a company that started building projects in Databricks, but hasn't done much in terms of version control. In my previous job, I would provision and deploy everything with Terraform ran on a build agent and following some kind of CI/CD process. We mostly used open source stuff deployed on K8s and some managed services and resources. I really liked this approach because it allowed me to track everything with Git, enabled automation and scalability. \n\nI want to do the same with Databricks and noticed that there is quite a lot of Terraform support for Databricks. I was also reading [this article](https://www.databricks.com/blog/2022/12/5/databricks-workflows-through-terraform.html) which makes it seem possible to abstract the Databricks UI away for a big part. I can imagine that the notebooks would still be written in the Databricks UI (or maybe VSCode using dbx or something similar), but those can be pushed to a Git repository such that it can enter a CI/CD proces. \n\nI was wondering if anyone adopted a similar workflow, what your experience is and if you have any advice for me, as I'll be doing this task pretty much on my own. ", "author_fullname": "t2_sazjm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Abstract the Databricks UI away with Terraform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zq3xd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696433059.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Last Monday I started a new job at a company that started building projects in Databricks, but hasn&amp;#39;t done much in terms of version control. In my previous job, I would provision and deploy everything with Terraform ran on a build agent and following some kind of CI/CD process. We mostly used open source stuff deployed on K8s and some managed services and resources. I really liked this approach because it allowed me to track everything with Git, enabled automation and scalability. &lt;/p&gt;\n\n&lt;p&gt;I want to do the same with Databricks and noticed that there is quite a lot of Terraform support for Databricks. I was also reading &lt;a href=\"https://www.databricks.com/blog/2022/12/5/databricks-workflows-through-terraform.html\"&gt;this article&lt;/a&gt; which makes it seem possible to abstract the Databricks UI away for a big part. I can imagine that the notebooks would still be written in the Databricks UI (or maybe VSCode using dbx or something similar), but those can be pushed to a Git repository such that it can enter a CI/CD proces. &lt;/p&gt;\n\n&lt;p&gt;I was wondering if anyone adopted a similar workflow, what your experience is and if you have any advice for me, as I&amp;#39;ll be doing this task pretty much on my own. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/KM-7TotJtWtLYK7Va7_XOZWJfBIE1lwV-5TBPuq36CM.jpg?auto=webp&amp;s=7641e4e0d05da7c50b1774dca16dd34991c6123d", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/KM-7TotJtWtLYK7Va7_XOZWJfBIE1lwV-5TBPuq36CM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=480ed867f93c9b15811b118a79e565da5b6f3425", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/KM-7TotJtWtLYK7Va7_XOZWJfBIE1lwV-5TBPuq36CM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=89093a5fece2c36f4d4bc919630e4dd73cc8e696", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/KM-7TotJtWtLYK7Va7_XOZWJfBIE1lwV-5TBPuq36CM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8fa7d5fdd327ec6bb7892f709a884c845da70c4f", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/KM-7TotJtWtLYK7Va7_XOZWJfBIE1lwV-5TBPuq36CM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ae8bb002c94d175e5146e50a6fe1bb9ba8895174", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/KM-7TotJtWtLYK7Va7_XOZWJfBIE1lwV-5TBPuq36CM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4b09d81ca80267d2f759c74a80aa076a8291b14f", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/KM-7TotJtWtLYK7Va7_XOZWJfBIE1lwV-5TBPuq36CM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=834b237c02ce4e12eae2ec7cf08f1d6726eee012", "width": 1080, "height": 565}], "variants": {}, "id": "xPtgrA7P2SwuSuA4ez38m-IpL115xmy4eB08k92W2qc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zq3xd", "is_robot_indexable": true, "report_reasons": null, "author": "Danielloesoe", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zq3xd/abstract_the_databricks_ui_away_with_terraform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zq3xd/abstract_the_databricks_ui_away_with_terraform/", "subreddit_subscribers": 132117, "created_utc": 1696433059.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. I've been working as a Data Engineer for the past 1,5 years. For most of this time, I liked my job. I love getting data in shape, and talking to Dashboard experts. My skill, especially with iac are lacking, but there is always room to grow.\n\nFor the past couple of weeks, I have been feeling worse and worse on my project. We are under a lot of pressure, since the deadlines are coming closer, and we are missing many important parts. More than half of the team has been replaced at some point, and we lost good people due to budget cuts. Few people have been on the project longer than I have.\n\nMy work was valued a lot for most of the time, which is probably why I was never replaced. I am great with the client, the Dashboard team, and I understand our data.\n\nDue to bad management, I am expected to work on iac and a small ETL pipeline in another team's repo. I cannot deploy changes, and the team members don't talk to me, or are gone. Management does not seem to care, and constantly asks me when the pipeline will be ready. I have tried explaining the situation a few times.  \n\nIt's frustrating, and it has even been mentioned that my promotion will be moved a year back. I feel like the ones that left were lucky.  \nThe Senior Dev and the person in charge just talk to each other and hand out tickets to everyone else. The tickets usually have no descriptions, and I have to ask many questions. The Senior Dev hates talking to others. \n\nI wonder if I am too slow, or if this project is mismanaged.   \nIdeas? ", "author_fullname": "t2_6cgfmz1c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it me or the project?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zpykn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696432714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I&amp;#39;ve been working as a Data Engineer for the past 1,5 years. For most of this time, I liked my job. I love getting data in shape, and talking to Dashboard experts. My skill, especially with iac are lacking, but there is always room to grow.&lt;/p&gt;\n\n&lt;p&gt;For the past couple of weeks, I have been feeling worse and worse on my project. We are under a lot of pressure, since the deadlines are coming closer, and we are missing many important parts. More than half of the team has been replaced at some point, and we lost good people due to budget cuts. Few people have been on the project longer than I have.&lt;/p&gt;\n\n&lt;p&gt;My work was valued a lot for most of the time, which is probably why I was never replaced. I am great with the client, the Dashboard team, and I understand our data.&lt;/p&gt;\n\n&lt;p&gt;Due to bad management, I am expected to work on iac and a small ETL pipeline in another team&amp;#39;s repo. I cannot deploy changes, and the team members don&amp;#39;t talk to me, or are gone. Management does not seem to care, and constantly asks me when the pipeline will be ready. I have tried explaining the situation a few times.  &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s frustrating, and it has even been mentioned that my promotion will be moved a year back. I feel like the ones that left were lucky.&lt;br/&gt;\nThe Senior Dev and the person in charge just talk to each other and hand out tickets to everyone else. The tickets usually have no descriptions, and I have to ask many questions. The Senior Dev hates talking to others. &lt;/p&gt;\n\n&lt;p&gt;I wonder if I am too slow, or if this project is mismanaged.&lt;br/&gt;\nIdeas? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16zpykn", "is_robot_indexable": true, "report_reasons": null, "author": "BewitchedHare", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zpykn/is_it_me_or_the_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zpykn/is_it_me_or_the_project/", "subreddit_subscribers": 132117, "created_utc": 1696432714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! \n\nI am relatively new to DE. This is my first job in tech and in DE. Its been 1.5 years into the job now and I just want to take a step back to understand what I have learnt and what I might need to focus on next.\n\nIn current role, I am using fivetran, stitch for data ingestion, dbt for transformation. We are using Snowflake. Mainly I am creating new data pipelines and setting up testing for those. So all I am doing is writing SQL code. In process, I learnt SQL, data engineering and warehousing fundamentals, git, CI/CD. \n\nBut this all involves working with automations and already setup environment. If I were to setup a DE project from scratch, I don't think I will be able to. When I hear about people talking about using python for scripting, S3 for storage and airflow for orchestrating, I understand roughly what they are saying but dont know how to do it technically. \n\nWhat should I do to prepare myself where I might not have all the help available with automation?\n\nThanks!", "author_fullname": "t2_7kdleomd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering with Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zm4ll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696423078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! &lt;/p&gt;\n\n&lt;p&gt;I am relatively new to DE. This is my first job in tech and in DE. Its been 1.5 years into the job now and I just want to take a step back to understand what I have learnt and what I might need to focus on next.&lt;/p&gt;\n\n&lt;p&gt;In current role, I am using fivetran, stitch for data ingestion, dbt for transformation. We are using Snowflake. Mainly I am creating new data pipelines and setting up testing for those. So all I am doing is writing SQL code. In process, I learnt SQL, data engineering and warehousing fundamentals, git, CI/CD. &lt;/p&gt;\n\n&lt;p&gt;But this all involves working with automations and already setup environment. If I were to setup a DE project from scratch, I don&amp;#39;t think I will be able to. When I hear about people talking about using python for scripting, S3 for storage and airflow for orchestrating, I understand roughly what they are saying but dont know how to do it technically. &lt;/p&gt;\n\n&lt;p&gt;What should I do to prepare myself where I might not have all the help available with automation?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16zm4ll", "is_robot_indexable": true, "report_reasons": null, "author": "Puzzleheaded-Cod2051", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zm4ll/data_engineering_with_python/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zm4ll/data_engineering_with_python/", "subreddit_subscribers": 132117, "created_utc": 1696423078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cube introduces Python and Jinja to its semantic layer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_16zrqjo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/FJF3At29t_GqGAPFaJOskWVkK9aR__jTubssxjbtBYc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696436888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/introducing-python-and-jinja-for-data-modeling", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/v8_SuErLRQNw_sx7PVAtjWw7WsqfU1GvuLeH0w5L28g.jpg?auto=webp&amp;s=1de5d5d74afe65433021750b487c3efc43901f33", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/v8_SuErLRQNw_sx7PVAtjWw7WsqfU1GvuLeH0w5L28g.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7ca8159fa76d69f09057ece6f8873eece87f79eb", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/v8_SuErLRQNw_sx7PVAtjWw7WsqfU1GvuLeH0w5L28g.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=8d9f48e3d329f0bbe9f06bd888cd620fb5c257df", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/v8_SuErLRQNw_sx7PVAtjWw7WsqfU1GvuLeH0w5L28g.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e338bf7b10fd93b851d85c913da2afccc786d7b8", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/v8_SuErLRQNw_sx7PVAtjWw7WsqfU1GvuLeH0w5L28g.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=57b31ac69a520e1ac76e60473a70afdf09ffb6fc", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/v8_SuErLRQNw_sx7PVAtjWw7WsqfU1GvuLeH0w5L28g.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dcbd7cc49824d6ae03d1c6d76f79fed78dc83ca1", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/v8_SuErLRQNw_sx7PVAtjWw7WsqfU1GvuLeH0w5L28g.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f14959b21ad3ea520b97e27c1b4244b16a6cf40c", "width": 1080, "height": 567}], "variants": {}, "id": "aeNskG4JVKRRkw_ymyAo6NEX5QhglNJrFshaz2FaXkU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16zrqjo", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zrqjo/cube_introduces_python_and_jinja_to_its_semantic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/introducing-python-and-jinja-for-data-modeling", "subreddit_subscribers": 132117, "created_utc": 1696436888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nI just got to the US from LATAM, I will not be working until I get my SSN in a few weeks but before I start to apply to jobs here I wanted to ask all of you some questions if I may:\n\n\\- I have almost 10 years of experience, how much should I sharp my technical skills (i.e. Python + SQL + Tools)? I suppose \"it depends\" on the company but I'll rather prepare my leadership/design skills because f### Leetcode. \n\n\\- I wanted to look out for a non-senior role, at least until I get a glance on the US work culture, I don't want to call the shots yet... What do you think of this?\n\n\\- I will be looking for an in-person / hybrid role, is it true that you only take a super quick lunch break during the day? It used to take us 60-90 minutes on fridays with the team to grab some food ;(\n\n\\- I do mostly consulting, how prestigious are the large firms (i.e. Deloitte)? Or do they just look for warm bodies to fill the project headcount?\n\nP.D. The salaries are unreal in the US, you guys are so spoiled!", "author_fullname": "t2_110yzc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Specific tips on US work culture", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zzo5g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696455963.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;I just got to the US from LATAM, I will not be working until I get my SSN in a few weeks but before I start to apply to jobs here I wanted to ask all of you some questions if I may:&lt;/p&gt;\n\n&lt;p&gt;- I have almost 10 years of experience, how much should I sharp my technical skills (i.e. Python + SQL + Tools)? I suppose &amp;quot;it depends&amp;quot; on the company but I&amp;#39;ll rather prepare my leadership/design skills because f### Leetcode. &lt;/p&gt;\n\n&lt;p&gt;- I wanted to look out for a non-senior role, at least until I get a glance on the US work culture, I don&amp;#39;t want to call the shots yet... What do you think of this?&lt;/p&gt;\n\n&lt;p&gt;- I will be looking for an in-person / hybrid role, is it true that you only take a super quick lunch break during the day? It used to take us 60-90 minutes on fridays with the team to grab some food ;(&lt;/p&gt;\n\n&lt;p&gt;- I do mostly consulting, how prestigious are the large firms (i.e. Deloitte)? Or do they just look for warm bodies to fill the project headcount?&lt;/p&gt;\n\n&lt;p&gt;P.D. The salaries are unreal in the US, you guys are so spoiled!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16zzo5g", "is_robot_indexable": true, "report_reasons": null, "author": "Danzante", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zzo5g/specific_tips_on_us_work_culture/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zzo5g/specific_tips_on_us_work_culture/", "subreddit_subscribers": 132117, "created_utc": 1696455963.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nFor the past year I\u2019ve been incrementally replicating an on-premises MS SQL Sever into BigQuery using Mage (some kind of Airflow) on a daily basis. Then I use DBT to create models, relationships and business definitions.\n\nI am attending the Microsoft Power Platform conference and some of the features they are showing can solve some problems my company is having. But, of course, some of those features require that the data is in the Microsoft Universe instead of Google BigQuery.\n\nSo\u2026 should I migrate to Microsoft to achieve this? If so, how would you do it? What\u2019s a good way to incrementally replicate my on premises MS SQL Server tables into the Microsoft cloud?\n\nThanks", "author_fullname": "t2_il87ibi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Opinions on Microsoft Power Platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zqdha", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696433690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;For the past year I\u2019ve been incrementally replicating an on-premises MS SQL Sever into BigQuery using Mage (some kind of Airflow) on a daily basis. Then I use DBT to create models, relationships and business definitions.&lt;/p&gt;\n\n&lt;p&gt;I am attending the Microsoft Power Platform conference and some of the features they are showing can solve some problems my company is having. But, of course, some of those features require that the data is in the Microsoft Universe instead of Google BigQuery.&lt;/p&gt;\n\n&lt;p&gt;So\u2026 should I migrate to Microsoft to achieve this? If so, how would you do it? What\u2019s a good way to incrementally replicate my on premises MS SQL Server tables into the Microsoft cloud?&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zqdha", "is_robot_indexable": true, "report_reasons": null, "author": "thevangea", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zqdha/opinions_on_microsoft_power_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zqdha/opinions_on_microsoft_power_platform/", "subreddit_subscribers": 132117, "created_utc": 1696433690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Data Enthusiasts ,\n\nI'm facing a massive ETL migration challenge and could use some guidance and insights. My client currently has over 2000 ETL pipelines running on SSIS, and they've decided to migrate everything to Azure Data Factory (ADF) on Cloud.\n\nThe catch? They don't just want to run these pipelines in the cloud; they want to redevelop them in ADF. It's a massive undertaking, and we're looking for the best strategies, tips, and advice to make this transition as smooth as possible.  \nIs there any Microsoft tool to migrate this packages to be Normal -Editable- ADF Dataflow pipelines, without redevelop each pipeline?", "author_fullname": "t2_781u9ci8g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating 2000+ SSIS Pipelines to Azure Data Factory (ADF)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zqbk5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696433559.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Data Enthusiasts ,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m facing a massive ETL migration challenge and could use some guidance and insights. My client currently has over 2000 ETL pipelines running on SSIS, and they&amp;#39;ve decided to migrate everything to Azure Data Factory (ADF) on Cloud.&lt;/p&gt;\n\n&lt;p&gt;The catch? They don&amp;#39;t just want to run these pipelines in the cloud; they want to redevelop them in ADF. It&amp;#39;s a massive undertaking, and we&amp;#39;re looking for the best strategies, tips, and advice to make this transition as smooth as possible.&lt;br/&gt;\nIs there any Microsoft tool to migrate this packages to be Normal -Editable- ADF Dataflow pipelines, without redevelop each pipeline?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16zqbk5", "is_robot_indexable": true, "report_reasons": null, "author": "MuTatek74", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zqbk5/migrating_2000_ssis_pipelines_to_azure_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zqbk5/migrating_2000_ssis_pipelines_to_azure_data/", "subreddit_subscribers": 132117, "created_utc": 1696433559.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a table which contains more than 350 Million rows, the DS team needs to use this table for their research. One of their problems (which is understandable) is that querying the data takes too long.   \nCan you refer me to anything that can help?  \nOr have you ever dealt with an issue like that.", "author_fullname": "t2_zbab4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing Data Warehouse modeling on Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zit1h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696412580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a table which contains more than 350 Million rows, the DS team needs to use this table for their research. One of their problems (which is understandable) is that querying the data takes too long.&lt;br/&gt;\nCan you refer me to anything that can help?&lt;br/&gt;\nOr have you ever dealt with an issue like that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zit1h", "is_robot_indexable": true, "report_reasons": null, "author": "chenvili", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zit1h/optimizing_data_warehouse_modeling_on_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zit1h/optimizing_data_warehouse_modeling_on_snowflake/", "subreddit_subscribers": 132117, "created_utc": 1696412580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Redditors, I'm facing an issue where I only want to read some data (I used limit) from a folder full of parquet files. The folder has roughly 50 gb of data. \n\nWhen I trigger a read with limit it still reads the entire folder and then applies the limit. This is happening even after providing the schema. Not sure what is happening. \n\nI'm using EMR and data is on S3.", "author_fullname": "t2_t1rd5ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyspark reads entire folders parquet data even after limit is applied", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zgzll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696405492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Redditors, I&amp;#39;m facing an issue where I only want to read some data (I used limit) from a folder full of parquet files. The folder has roughly 50 gb of data. &lt;/p&gt;\n\n&lt;p&gt;When I trigger a read with limit it still reads the entire folder and then applies the limit. This is happening even after providing the schema. Not sure what is happening. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using EMR and data is on S3.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16zgzll", "is_robot_indexable": true, "report_reasons": null, "author": "PR0K1NG", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16zgzll/pyspark_reads_entire_folders_parquet_data_even/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zgzll/pyspark_reads_entire_folders_parquet_data_even/", "subreddit_subscribers": 132117, "created_utc": 1696405492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Greetings Data engineering community!\n\nI've been following this excellent forum for a while and I've found it a rather joyous experience. So here goes first question (which I think isconceptually  a common one, but didnt find a specific previous one that suited)\n\nSome context. Previous backround is primarily analytics engineering role, with emphasis on working from an extremely solid data foundation to creating machine learning models, data analysis, business intelligence. The whole analysis pipeline end  to end in a nutshell. From this experience, I've been instinctively impressed upon the enormous degree of freedom a solid data foundation provides, the speed/agility one can move on new problems and products, and just general confidence in data quality and integrity. Overall enormous respect to people who create these foundations and allow people to only have creativity be the limit to what can be made. \n\nNow, I've recently started a place where this thinking is turned entirely on its head. I dont want to go into specifics, but its essentially the opposite with products first and infrastructure later (or never)\n\nSo I've realised, like any good scientist,  I need to triuangulate my thinking. Maybe I am wrong in my thinking, and products need to come first before there really is any foundation, or will a foundation never come when one never attempts to build anything to scale and structure.  What do you guys think? I am hoping for conflicting explanations of how people have approached and solved this, so as to inform what approach i should pursue. To be clear, I do believe the foundation should be made, but I am rather worried my perspectives are very limited by selection and experience bias. \n\nAlso, this forum is awesome. Ive learnt so much \n\nAppreciate the responses! \n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_6fquucn5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What comes first: Solid data foundation/infrastructure or products?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zx2xk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696449823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings Data engineering community!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been following this excellent forum for a while and I&amp;#39;ve found it a rather joyous experience. So here goes first question (which I think isconceptually  a common one, but didnt find a specific previous one that suited)&lt;/p&gt;\n\n&lt;p&gt;Some context. Previous backround is primarily analytics engineering role, with emphasis on working from an extremely solid data foundation to creating machine learning models, data analysis, business intelligence. The whole analysis pipeline end  to end in a nutshell. From this experience, I&amp;#39;ve been instinctively impressed upon the enormous degree of freedom a solid data foundation provides, the speed/agility one can move on new problems and products, and just general confidence in data quality and integrity. Overall enormous respect to people who create these foundations and allow people to only have creativity be the limit to what can be made. &lt;/p&gt;\n\n&lt;p&gt;Now, I&amp;#39;ve recently started a place where this thinking is turned entirely on its head. I dont want to go into specifics, but its essentially the opposite with products first and infrastructure later (or never)&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;ve realised, like any good scientist,  I need to triuangulate my thinking. Maybe I am wrong in my thinking, and products need to come first before there really is any foundation, or will a foundation never come when one never attempts to build anything to scale and structure.  What do you guys think? I am hoping for conflicting explanations of how people have approached and solved this, so as to inform what approach i should pursue. To be clear, I do believe the foundation should be made, but I am rather worried my perspectives are very limited by selection and experience bias. &lt;/p&gt;\n\n&lt;p&gt;Also, this forum is awesome. Ive learnt so much &lt;/p&gt;\n\n&lt;p&gt;Appreciate the responses! &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zx2xk", "is_robot_indexable": true, "report_reasons": null, "author": "No-Buy-3530", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zx2xk/what_comes_first_solid_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zx2xk/what_comes_first_solid_data/", "subreddit_subscribers": 132117, "created_utc": 1696449823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We just launched [Evidence](https://www.producthunt.com/posts/evidence-3) on Product Hunt.\n\nEvidence is a tool for generating reports using SQL and markdown. It\u2019s an open source alternative to drag and drop BI tools.\n\nWe were mega frustrated with the dev experience of tools like PowerBI, and wished we had something more friendly to build and maintain dashboards with.\n\n**Why code based?**\n\nBuilding reporting in code allows you to:\n\n* **Version control your BI layer,** and use tools like GitHub to collaborate\n* **Add CI/CD processes to your reports,** so that they don\u2019t break unexpectedly\n* **Support text natively,** using markdown to explain your charts and tables\n* **Control what content is displayed,** using if statements, loops and page templates\n* **Deliver a better UX,** with fine-grained control over viz, layout and report architecture\n\nWould love to hear what you think!", "author_fullname": "t2_cv0bgwia", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Evidence - Business Intelligence as Code", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zrw80", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696438349.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696437257.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We just launched &lt;a href=\"https://www.producthunt.com/posts/evidence-3\"&gt;Evidence&lt;/a&gt; on Product Hunt.&lt;/p&gt;\n\n&lt;p&gt;Evidence is a tool for generating reports using SQL and markdown. It\u2019s an open source alternative to drag and drop BI tools.&lt;/p&gt;\n\n&lt;p&gt;We were mega frustrated with the dev experience of tools like PowerBI, and wished we had something more friendly to build and maintain dashboards with.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why code based?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Building reporting in code allows you to:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;Version control your BI layer,&lt;/strong&gt; and use tools like GitHub to collaborate&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Add CI/CD processes to your reports,&lt;/strong&gt; so that they don\u2019t break unexpectedly&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Support text natively,&lt;/strong&gt; using markdown to explain your charts and tables&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Control what content is displayed,&lt;/strong&gt; using if statements, loops and page templates&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Deliver a better UX,&lt;/strong&gt; with fine-grained control over viz, layout and report architecture&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Would love to hear what you think!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W1dgU8Te80vEljoDVgSdUGEXPbrQrEKzhFWmKZB1L0c.jpg?auto=webp&amp;s=2a8947a82b4e39880969f7f0520d1c391d49f5f2", "width": 1024, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/W1dgU8Te80vEljoDVgSdUGEXPbrQrEKzhFWmKZB1L0c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0163ec32925662898915f2d0d0c68cafe8c5eed8", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/W1dgU8Te80vEljoDVgSdUGEXPbrQrEKzhFWmKZB1L0c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=247cd25b8418fdfe709b11188c5815b983fba6ac", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/W1dgU8Te80vEljoDVgSdUGEXPbrQrEKzhFWmKZB1L0c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ced618d09f6764b28edf1dfdf8add24b0405e225", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/W1dgU8Te80vEljoDVgSdUGEXPbrQrEKzhFWmKZB1L0c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8aaea7c33a2282871f1043fa354b9a31fdd25da7", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/W1dgU8Te80vEljoDVgSdUGEXPbrQrEKzhFWmKZB1L0c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a348dac562fd50fb21a57e34bec43c8ee28961ab", "width": 960, "height": 480}], "variants": {}, "id": "o3nP3AFOFg2V4HOnEa-EKViJaPXKaKWIZ-oF4wJVlWM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "16zrw80", "is_robot_indexable": true, "report_reasons": null, "author": "Pleasant_Type_4547", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zrw80/evidence_business_intelligence_as_code/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zrw80/evidence_business_intelligence_as_code/", "subreddit_subscribers": 132117, "created_utc": 1696437257.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "hello\n\ni try to found some sucess stories of s3 minio backend of GX and cant found, does anyone has one?\n\nIve found some issues in GX github related to using s3like storages other that aws, but all closed on march with workaround", "author_fullname": "t2_89j762yi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Great Expectations with s3 MINIO", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zrltm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696436581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hello&lt;/p&gt;\n\n&lt;p&gt;i try to found some sucess stories of s3 minio backend of GX and cant found, does anyone has one?&lt;/p&gt;\n\n&lt;p&gt;Ive found some issues in GX github related to using s3like storages other that aws, but all closed on march with workaround&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16zrltm", "is_robot_indexable": true, "report_reasons": null, "author": "tehdima", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zrltm/great_expectations_with_s3_minio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zrltm/great_expectations_with_s3_minio/", "subreddit_subscribers": 132117, "created_utc": 1696436581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_29ua8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lost in the Haystack: Optimizing an Expensive ClickHouse Query", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 52, "top_awarded_type": null, "hide_score": false, "name": "t3_16zrlas", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/g_CDI8noT_k-TPcIqcM0IcgjY7xQD_zSBG-HacUb_k8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696436547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "sentry.engineering", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://sentry.engineering/blog/lost-in-the-haystack", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/McV0mTI0SRc1dsxVuv8iroIGtoy_N38EO4TyTILjOsg.jpg?auto=webp&amp;s=8136178d8e7fa2b7637f1b990ebb808415142e88", "width": 1260, "height": 473}, "resolutions": [{"url": "https://external-preview.redd.it/McV0mTI0SRc1dsxVuv8iroIGtoy_N38EO4TyTILjOsg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b7b57c17ebfb3685c4ec5d68bd86cbef4e39bbcf", "width": 108, "height": 40}, {"url": "https://external-preview.redd.it/McV0mTI0SRc1dsxVuv8iroIGtoy_N38EO4TyTILjOsg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=782c75d0d9ef218760467e557601841fa677978f", "width": 216, "height": 81}, {"url": "https://external-preview.redd.it/McV0mTI0SRc1dsxVuv8iroIGtoy_N38EO4TyTILjOsg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a865ed10cf81521cd79198b848cacbd655a16b8d", "width": 320, "height": 120}, {"url": "https://external-preview.redd.it/McV0mTI0SRc1dsxVuv8iroIGtoy_N38EO4TyTILjOsg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e982a5520ae5d0c1af0f305911976deb0152958", "width": 640, "height": 240}, {"url": "https://external-preview.redd.it/McV0mTI0SRc1dsxVuv8iroIGtoy_N38EO4TyTILjOsg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=497f3a765bf87538f68e2ddd92aec90d8baa0f1d", "width": 960, "height": 360}, {"url": "https://external-preview.redd.it/McV0mTI0SRc1dsxVuv8iroIGtoy_N38EO4TyTILjOsg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7beccbb8aa2f4f9e731b864f6577a1b65d8dadb3", "width": 1080, "height": 405}], "variants": {}, "id": "x2yiTU0EVrwtloN8yBSySaVDzloA2vh6EnYuIhIqP8w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16zrlas", "is_robot_indexable": true, "report_reasons": null, "author": "silent1mezzo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zrlas/lost_in_the_haystack_optimizing_an_expensive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://sentry.engineering/blog/lost-in-the-haystack", "subreddit_subscribers": 132117, "created_utc": 1696436547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just curious to know what are ya'lls favorite conferences are? Whether it's a conference dedicated to data engineering topics/tech or just a conference that had some/a few data-engineering related talks/presentations.\n\n Looking for a bit more insight on:\n\n1. **Conference Name**\n2. **Location &amp; Format** (in-person? Virtual?)\n3. **Frequency** (one time thing? Annual?)\n4. **Why was it great? What did you like the most about it?** ", "author_fullname": "t2_6l1e382d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Favorite conferences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1700a2u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696457388.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just curious to know what are ya&amp;#39;lls favorite conferences are? Whether it&amp;#39;s a conference dedicated to data engineering topics/tech or just a conference that had some/a few data-engineering related talks/presentations.&lt;/p&gt;\n\n&lt;p&gt;Looking for a bit more insight on:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;Conference Name&lt;/strong&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Location &amp;amp; Format&lt;/strong&gt; (in-person? Virtual?)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Frequency&lt;/strong&gt; (one time thing? Annual?)&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Why was it great? What did you like the most about it?&lt;/strong&gt; &lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1700a2u", "is_robot_indexable": true, "report_reasons": null, "author": "unfair_pandah", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1700a2u/favorite_conferences/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1700a2u/favorite_conferences/", "subreddit_subscribers": 132117, "created_utc": 1696457388.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I signed up for the 14-day Databricks trial so I can learn and complete the lessons on Databricks Learning Academy. To follow and complete the lessons, I had to setup an AWS account and spin up a cluster. After a week of working on Databricks, I got an email from AWS for cloud charges. How am I supposed to do complete the Learning if I have to pay to use AWS? Is there a way around this? I\u2019d like to follow the lesson plan on Databricks. How else are people studying for this? Are they paying for cloud usage too? I\u2019m studying for the Databricks Data Engineer Associate certification.", "author_fullname": "t2_3551lbmx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks trial; setup cluster on AWS but getting charged", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zyjkt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696453335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I signed up for the 14-day Databricks trial so I can learn and complete the lessons on Databricks Learning Academy. To follow and complete the lessons, I had to setup an AWS account and spin up a cluster. After a week of working on Databricks, I got an email from AWS for cloud charges. How am I supposed to do complete the Learning if I have to pay to use AWS? Is there a way around this? I\u2019d like to follow the lesson plan on Databricks. How else are people studying for this? Are they paying for cloud usage too? I\u2019m studying for the Databricks Data Engineer Associate certification.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16zyjkt", "is_robot_indexable": true, "report_reasons": null, "author": "msaki01", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zyjkt/databricks_trial_setup_cluster_on_aws_but_getting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zyjkt/databricks_trial_setup_cluster_on_aws_but_getting/", "subreddit_subscribers": 132117, "created_utc": 1696453335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nWhat are your thoughts on current Vector DB offerings? For instance:\n\n* Do you think the pricing for them is reasonable/viable?\n* Do you think there\u2019s a sufficient level of developer/user experience? What about for those who aren\u2019t necessarily specialized in data?\n* If you like a managed service, why do you prefer it over the open source alternatives?", "author_fullname": "t2_9pje88yp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Thoughts on current Vector DB landscape?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zw1ip", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696447271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;What are your thoughts on current Vector DB offerings? For instance:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Do you think the pricing for them is reasonable/viable?&lt;/li&gt;\n&lt;li&gt;Do you think there\u2019s a sufficient level of developer/user experience? What about for those who aren\u2019t necessarily specialized in data?&lt;/li&gt;\n&lt;li&gt;If you like a managed service, why do you prefer it over the open source alternatives?&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zw1ip", "is_robot_indexable": true, "report_reasons": null, "author": "LucasSaysHello", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zw1ip/thoughts_on_current_vector_db_landscape/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zw1ip/thoughts_on_current_vector_db_landscape/", "subreddit_subscribers": 132117, "created_utc": 1696447271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm grappling with mapping numeric data types from PostgreSQL to S3 in Parquet format using SnapLogic. Certain columns in PostgreSQL are defined as numerics with various values like integers, floats, and decimals. While ingesting, I employ a mapping table to assign the appropriate data type in Parquet. However, I'm facing issues with columns that have mixed numeric types (int, float, decimal). Mapping as an int causes loss of decimal data, and as a decimal, integers become decimals (e.g., 1 becomes 1.00). I could use some guidance on handling this situation. Thanks!", "author_fullname": "t2_m7vpczk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to map numeric data type", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zul9u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696443749.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m grappling with mapping numeric data types from PostgreSQL to S3 in Parquet format using SnapLogic. Certain columns in PostgreSQL are defined as numerics with various values like integers, floats, and decimals. While ingesting, I employ a mapping table to assign the appropriate data type in Parquet. However, I&amp;#39;m facing issues with columns that have mixed numeric types (int, float, decimal). Mapping as an int causes loss of decimal data, and as a decimal, integers become decimals (e.g., 1 becomes 1.00). I could use some guidance on handling this situation. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16zul9u", "is_robot_indexable": true, "report_reasons": null, "author": "shrishpratap", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zul9u/how_to_map_numeric_data_type/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zul9u/how_to_map_numeric_data_type/", "subreddit_subscribers": 132117, "created_utc": 1696443749.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have some nested jsons I need to \"flatten\" in databricks, but I don't need all the fields.\n\nI have a list of the required fields.\n\nWhat's the best way to go about transforming the data into csv/dataframe?\n\nI have two options I thinking:\n\n1. Flatten everything, then drop what's not needed (the issue here is that when I flatten the data I get a lot more rows and I'm not sure how to select the ones to drop). When I try json\\_normalize() on an entire json locally it quickly goes from say 80 columns and 5000 rows to over 150 columns and 100k+ rows.\n2. Build the dataframe by getting the desired columns and rows from the jsons using only the desired fields.\n3. another method?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_2qwbdyfo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting specific fields from nested json in azure databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ztwm9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696442067.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some nested jsons I need to &amp;quot;flatten&amp;quot; in databricks, but I don&amp;#39;t need all the fields.&lt;/p&gt;\n\n&lt;p&gt;I have a list of the required fields.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the best way to go about transforming the data into csv/dataframe?&lt;/p&gt;\n\n&lt;p&gt;I have two options I thinking:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Flatten everything, then drop what&amp;#39;s not needed (the issue here is that when I flatten the data I get a lot more rows and I&amp;#39;m not sure how to select the ones to drop). When I try json_normalize() on an entire json locally it quickly goes from say 80 columns and 5000 rows to over 150 columns and 100k+ rows.&lt;/li&gt;\n&lt;li&gt;Build the dataframe by getting the desired columns and rows from the jsons using only the desired fields.&lt;/li&gt;\n&lt;li&gt;another method?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ztwm9", "is_robot_indexable": true, "report_reasons": null, "author": "comstrader", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ztwm9/getting_specific_fields_from_nested_json_in_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ztwm9/getting_specific_fields_from_nested_json_in_azure/", "subreddit_subscribers": 132117, "created_utc": 1696442067.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone.\nI have a usecase in my current organisation where the current system/flow is not working as expected.\n\nUsecase:\n- There are 2 types of documents that we get from our customers. Let's call them \"Input\" and \"Feedback\"\n- The \"Input\" documents have an identifier defined by customer. It may or may not be unique i.e the customer sometimes send the same identifier again and again but we might have to consider it as different event/instance.\n- The \"Feedback\" document are basically the actual feedback for those input documents. So for any given identifier present in an input document we typically recieve a feedback from the Feedback document. Even here we encounter the same issue of identifiers getting duplicated.\nThese feedback documents are received after few days of the customer sending us the input.\n- Also, there are some instances where the data in these files do not obey some of our validation checks. In those scenarios we want to get rid of those bad data and push it in some kind of review queue where other folks can take a look at it.\n- We want to have exactly 1 input with it's corresponding \"right feedback\" based on the \"identifier\" mapping i.e an input cannot have multiple feedbacks or vice-versa.\n- We should be able to handle the scenarios where the customer sends \"Corrected\" version of the feedbacks if the earlier version had bad data or it was not correct though it passed out validation checks. This is a tricky part where I'm struggling with as these corrected/updated feedbacks are sent after few days of the earlier feedback version that was received from the customer. This impacts our down stream resources/tables.\n- We should also be able to handle the changes for down stream resources/tables which are using this data as a SOT. Basically these down stream resources/tables are being used for model training/analytics/reporting.\n\nWould love to hear your thoughts on this. Thanks!", "author_fullname": "t2_bt39kjks", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Architecture Decision", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zs5ix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696437875.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone.\nI have a usecase in my current organisation where the current system/flow is not working as expected.&lt;/p&gt;\n\n&lt;p&gt;Usecase:\n- There are 2 types of documents that we get from our customers. Let&amp;#39;s call them &amp;quot;Input&amp;quot; and &amp;quot;Feedback&amp;quot;\n- The &amp;quot;Input&amp;quot; documents have an identifier defined by customer. It may or may not be unique i.e the customer sometimes send the same identifier again and again but we might have to consider it as different event/instance.\n- The &amp;quot;Feedback&amp;quot; document are basically the actual feedback for those input documents. So for any given identifier present in an input document we typically recieve a feedback from the Feedback document. Even here we encounter the same issue of identifiers getting duplicated.\nThese feedback documents are received after few days of the customer sending us the input.\n- Also, there are some instances where the data in these files do not obey some of our validation checks. In those scenarios we want to get rid of those bad data and push it in some kind of review queue where other folks can take a look at it.\n- We want to have exactly 1 input with it&amp;#39;s corresponding &amp;quot;right feedback&amp;quot; based on the &amp;quot;identifier&amp;quot; mapping i.e an input cannot have multiple feedbacks or vice-versa.\n- We should be able to handle the scenarios where the customer sends &amp;quot;Corrected&amp;quot; version of the feedbacks if the earlier version had bad data or it was not correct though it passed out validation checks. This is a tricky part where I&amp;#39;m struggling with as these corrected/updated feedbacks are sent after few days of the earlier feedback version that was received from the customer. This impacts our down stream resources/tables.\n- We should also be able to handle the changes for down stream resources/tables which are using this data as a SOT. Basically these down stream resources/tables are being used for model training/analytics/reporting.&lt;/p&gt;\n\n&lt;p&gt;Would love to hear your thoughts on this. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16zs5ix", "is_robot_indexable": true, "report_reasons": null, "author": "tradax", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zs5ix/architecture_decision/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zs5ix/architecture_decision/", "subreddit_subscribers": 132117, "created_utc": 1696437875.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any tools in life which can graphically represent a big SQL script with their tables and relation more like a ER diagram in a click. ( something ai driven )\n\nI got a huge SQL script that I'm trying to understand, any tool exists that reads my SQL script and automatically shows how the tables and fields are related/connected inside the script visually like a mind map or an er diagram?", "author_fullname": "t2_aqp7hdzb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tool to represent a SQL script into Graphic diagram ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zo509", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696430739.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696428346.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any tools in life which can graphically represent a big SQL script with their tables and relation more like a ER diagram in a click. ( something ai driven )&lt;/p&gt;\n\n&lt;p&gt;I got a huge SQL script that I&amp;#39;m trying to understand, any tool exists that reads my SQL script and automatically shows how the tables and fields are related/connected inside the script visually like a mind map or an er diagram?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zo509", "is_robot_indexable": true, "report_reasons": null, "author": "johnyjohnyespappa", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zo509/any_tool_to_represent_a_sql_script_into_graphic/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zo509/any_tool_to_represent_a_sql_script_into_graphic/", "subreddit_subscribers": 132117, "created_utc": 1696428346.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Working on a school  project  where i designed a power bi dashbord   \nTechnically:\n\n\\- I have created views in BigQuery by consolidating data from various source tables within BigQuery.\n\n\\- I have scheduled queries using BigQuery's query scheduler, although I've been advised that this may not be considered a best practice.\n\n\\- I've connected these views to Power BI to create my dashboard.\n\n&amp;#x200B;\n\nMy question is: How can I professionalize and optimize my Power BI report with best practices? What tools within Google Cloud Platform (GCP) can I use to schedule my queries efficiently (to refresh automatically my dashbord)?\n\n&amp;#x200B;", "author_fullname": "t2_8li8rd9gr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Industrialisation of PowerBI report in a full GCP env", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zmiqf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696424142.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working on a school  project  where i designed a power bi dashbord&lt;br/&gt;\nTechnically:&lt;/p&gt;\n\n&lt;p&gt;- I have created views in BigQuery by consolidating data from various source tables within BigQuery.&lt;/p&gt;\n\n&lt;p&gt;- I have scheduled queries using BigQuery&amp;#39;s query scheduler, although I&amp;#39;ve been advised that this may not be considered a best practice.&lt;/p&gt;\n\n&lt;p&gt;- I&amp;#39;ve connected these views to Power BI to create my dashboard.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My question is: How can I professionalize and optimize my Power BI report with best practices? What tools within Google Cloud Platform (GCP) can I use to schedule my queries efficiently (to refresh automatically my dashbord)?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16zmiqf", "is_robot_indexable": true, "report_reasons": null, "author": "StatisticianFun3709", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zmiqf/industrialisation_of_powerbi_report_in_a_full_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zmiqf/industrialisation_of_powerbi_report_in_a_full_gcp/", "subreddit_subscribers": 132117, "created_utc": 1696424142.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI am currently working to help a client migrate from ddb to Snowflake. They have been ingesting data since 4 years from API into ddb which sorta helped them achieve their goals well initially but now it is getting expensive. Essentially it is one huge table which has api data ingested partitioned by the application rule name which is the partition key and the actual api response is dumped as raw json into a map field called payload for that key.\n\nComing in as consultants, we are thinking of exporting ddb to s3 as json and then running a one time pyspark (glue ET) json flatten job that spits out as many number of tables as there are keys in the ddb table and then run SQL queries using Athena to understand their use case better so that we can frame our MVP better. Is this something that seem like a resonable approach?\n\nDdb: 400Gb, 500M records - More than 50 keys. It's just so hard to explore the data as it is right now.  \n\n\nEdit: This is just to explore; Final solution suggested involved API dumps into s3 as json and being picked up via snowpipe into variant column and being flattened there after. ", "author_fullname": "t2_dv4ply58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Explore Big Data From Ddb", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zg10z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696401806.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I am currently working to help a client migrate from ddb to Snowflake. They have been ingesting data since 4 years from API into ddb which sorta helped them achieve their goals well initially but now it is getting expensive. Essentially it is one huge table which has api data ingested partitioned by the application rule name which is the partition key and the actual api response is dumped as raw json into a map field called payload for that key.&lt;/p&gt;\n\n&lt;p&gt;Coming in as consultants, we are thinking of exporting ddb to s3 as json and then running a one time pyspark (glue ET) json flatten job that spits out as many number of tables as there are keys in the ddb table and then run SQL queries using Athena to understand their use case better so that we can frame our MVP better. Is this something that seem like a resonable approach?&lt;/p&gt;\n\n&lt;p&gt;Ddb: 400Gb, 500M records - More than 50 keys. It&amp;#39;s just so hard to explore the data as it is right now.  &lt;/p&gt;\n\n&lt;p&gt;Edit: This is just to explore; Final solution suggested involved API dumps into s3 as json and being picked up via snowpipe into variant column and being flattened there after. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zg10z", "is_robot_indexable": true, "report_reasons": null, "author": "Outrageous_Apple_420", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zg10z/explore_big_data_from_ddb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zg10z/explore_big_data_from_ddb/", "subreddit_subscribers": 132117, "created_utc": 1696401806.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}