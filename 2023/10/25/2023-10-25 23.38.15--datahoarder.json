{"kind": "Listing", "data": {"after": "t3_17g693l", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "PSA, if anyone here is hoarding software you might want to mirror https://flings.vmware.com before 26.10. Full announcement from a VMware employee https://twitter.com/lamw/status/1716909940345045276?s=20 and https://www.reddit.com/r/vmware/comments/17fniqp/psa_vmware_fling_will_be_down_on_thur_1026_please/?utm_source=share&amp;utm_medium=web2x&amp;context=3\n\nContext: Broadcom is taking over VMware so the flings website would be down either permanently (speculation) or for an extended period of time. Many people rely on Flings to achieve some niche solutions using VMware software. If you hoard such data you might be interested. Unfortunately I don\u2019t have the resources currently to mirror the entire thing and given the short period I can\u2019t realistically buy enough storage on time. \n\nEnjoy and thanks to however preserves those invaluable resources!\n\nEdit: Now available here: https://archive.org/download/flings.vmware.com", "author_fullname": "t2_hhere4lkb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PSA: VMware Flings website to be taken offline indefinitely", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fvy4p", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698235934.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698205663.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;PSA, if anyone here is hoarding software you might want to mirror &lt;a href=\"https://flings.vmware.com\"&gt;https://flings.vmware.com&lt;/a&gt; before 26.10. Full announcement from a VMware employee &lt;a href=\"https://twitter.com/lamw/status/1716909940345045276?s=20\"&gt;https://twitter.com/lamw/status/1716909940345045276?s=20&lt;/a&gt; and &lt;a href=\"https://www.reddit.com/r/vmware/comments/17fniqp/psa_vmware_fling_will_be_down_on_thur_1026_please/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3\"&gt;https://www.reddit.com/r/vmware/comments/17fniqp/psa_vmware_fling_will_be_down_on_thur_1026_please/?utm_source=share&amp;amp;utm_medium=web2x&amp;amp;context=3&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Context: Broadcom is taking over VMware so the flings website would be down either permanently (speculation) or for an extended period of time. Many people rely on Flings to achieve some niche solutions using VMware software. If you hoard such data you might be interested. Unfortunately I don\u2019t have the resources currently to mirror the entire thing and given the short period I can\u2019t realistically buy enough storage on time. &lt;/p&gt;\n\n&lt;p&gt;Enjoy and thanks to however preserves those invaluable resources!&lt;/p&gt;\n\n&lt;p&gt;Edit: Now available here: &lt;a href=\"https://archive.org/download/flings.vmware.com\"&gt;https://archive.org/download/flings.vmware.com&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LFTMds0SDIoUDl_WDxgwXJkKa28lAavtal8huebgu2Q.jpg?auto=webp&amp;s=d073d57db5cc8bf41fdb15957274b08142891bd0", "width": 743, "height": 743}, "resolutions": [{"url": "https://external-preview.redd.it/LFTMds0SDIoUDl_WDxgwXJkKa28lAavtal8huebgu2Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=19eee4059fa03c7321a40b81b3212a9c6b48e6ee", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/LFTMds0SDIoUDl_WDxgwXJkKa28lAavtal8huebgu2Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e725264f4f4a6044d97d7c67c1423120e63532b6", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/LFTMds0SDIoUDl_WDxgwXJkKa28lAavtal8huebgu2Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7b6bd3655d4ce931ab1927be3c55703319c389f8", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/LFTMds0SDIoUDl_WDxgwXJkKa28lAavtal8huebgu2Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=84572871cf288f66a0b0b8f5e4e86416bd073c5c", "width": 640, "height": 640}], "variants": {}, "id": "zlmL2m712SPSuZaEjTxkb2xX_TxZkQ2wNjwtx7OhFE8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fvy4p", "is_robot_indexable": true, "report_reasons": null, "author": "Is-Not-El", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fvy4p/psa_vmware_flings_website_to_be_taken_offline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fvy4p/psa_vmware_flings_website_to_be_taken_offline/", "subreddit_subscribers": 708642, "created_utc": 1698205663.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It's time to ditch all my 2TB WD Green Drives. They are dying one by one...and I am losing my data.   \nI have been wanting to build a 200TB NAS with data protections for a long time. \n\nIt will be mainly used to HOARD all 4K remux Movies, TV Series, and Music.   \nAnd, It also will be used as Plex server, 4-6 family members will be using it with plex simultaneously. \n\nI have been lurking around forums and reddit posts. \n\nHardware I am thinking of getting is listed below   \nCPU: Intel W-1290P (Integrated GPU for plex transcoding)   \nMobo: Asus W480 ACE   \nRam: 128GB ECC DDR4 2933MHZ   \nSSD: 256GB M.2   \nHDD: Seagate EXOS 18TB   \nController Card:  LSI SAS 9300-16I    \nNIC: Asus 10gbps   \nCASE: Fractal Design 7 XL  \n\nSystem: TrueNas Scale   \nRaid: Raidz2 x2 \n\nSome Questions in my mind  \n\\- Does it need L2ARC ?  If so, what size ?   \n\\- Is 128GB Ram enough for this set up ?    \n\\- Will it hold 1000+ torrents seeding at the same time ? \n\nOr any suggestion to build it better would be appreciated !!", "author_fullname": "t2_4qm6o5ih", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Suggestion - Building 200TB NAS mainly for Media Hoarder", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fzrmy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698221206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s time to ditch all my 2TB WD Green Drives. They are dying one by one...and I am losing my data.&lt;br/&gt;\nI have been wanting to build a 200TB NAS with data protections for a long time. &lt;/p&gt;\n\n&lt;p&gt;It will be mainly used to HOARD all 4K remux Movies, TV Series, and Music.&lt;br/&gt;\nAnd, It also will be used as Plex server, 4-6 family members will be using it with plex simultaneously. &lt;/p&gt;\n\n&lt;p&gt;I have been lurking around forums and reddit posts. &lt;/p&gt;\n\n&lt;p&gt;Hardware I am thinking of getting is listed below&lt;br/&gt;\nCPU: Intel W-1290P (Integrated GPU for plex transcoding)&lt;br/&gt;\nMobo: Asus W480 ACE&lt;br/&gt;\nRam: 128GB ECC DDR4 2933MHZ&lt;br/&gt;\nSSD: 256GB M.2&lt;br/&gt;\nHDD: Seagate EXOS 18TB&lt;br/&gt;\nController Card:  LSI SAS 9300-16I&lt;br/&gt;\nNIC: Asus 10gbps&lt;br/&gt;\nCASE: Fractal Design 7 XL  &lt;/p&gt;\n\n&lt;p&gt;System: TrueNas Scale&lt;br/&gt;\nRaid: Raidz2 x2 &lt;/p&gt;\n\n&lt;p&gt;Some Questions in my mind&lt;br/&gt;\n- Does it need L2ARC ?  If so, what size ?&lt;br/&gt;\n- Is 128GB Ram enough for this set up ?&lt;br/&gt;\n- Will it hold 1000+ torrents seeding at the same time ? &lt;/p&gt;\n\n&lt;p&gt;Or any suggestion to build it better would be appreciated !!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fzrmy", "is_robot_indexable": true, "report_reasons": null, "author": "Local-Bag-1045", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fzrmy/need_suggestion_building_200tb_nas_mainly_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fzrmy/need_suggestion_building_200tb_nas_mainly_for/", "subreddit_subscribers": 708642, "created_utc": 1698221206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been running a TrueNAS server for some time now and while I think it is a pretty good OS, I would like to test out some other ones and compare their performance. I'd also like some more flexibility regarding storage. Ideally I would be able to throw all my HDDs and SSDs into a single pool where the SSDs act as a read and write cache and the OS automatically manages what data to put on the faster SSDs vs the slower HDDs (or just keeps copies of files on the SSDs). I have enough SSDs to have separate read/write caches if necessary, there's just not a good way of accomplishing this kind of set up via TrueNAS, to my knowledge. Any advice or recommendations are welcome. Thank you!", "author_fullname": "t2_bcjqvtx5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OS Recommendations", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gaj0u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698255809.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been running a TrueNAS server for some time now and while I think it is a pretty good OS, I would like to test out some other ones and compare their performance. I&amp;#39;d also like some more flexibility regarding storage. Ideally I would be able to throw all my HDDs and SSDs into a single pool where the SSDs act as a read and write cache and the OS automatically manages what data to put on the faster SSDs vs the slower HDDs (or just keeps copies of files on the SSDs). I have enough SSDs to have separate read/write caches if necessary, there&amp;#39;s just not a good way of accomplishing this kind of set up via TrueNAS, to my knowledge. Any advice or recommendations are welcome. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17gaj0u", "is_robot_indexable": true, "report_reasons": null, "author": "nathankrebs", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17gaj0u/os_recommendations/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17gaj0u/os_recommendations/", "subreddit_subscribers": 708642, "created_utc": 1698255809.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have got 50k photos in Amazon Photos and I am looking to cancel Amazon Prime. I have everything on a local drives plus Google Photos for mobile phone pics, but want to pull everything from Amazon just in case.\n\nAny methods to bulk download so I can dump to a local drive connected to PC running Win10?\n \nBackblaze still best value for deep archive (1-2TB)?", "author_fullname": "t2_w6q5h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bulk downloading from Amazon Photos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g0ey2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698224200.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have got 50k photos in Amazon Photos and I am looking to cancel Amazon Prime. I have everything on a local drives plus Google Photos for mobile phone pics, but want to pull everything from Amazon just in case.&lt;/p&gt;\n\n&lt;p&gt;Any methods to bulk download so I can dump to a local drive connected to PC running Win10?&lt;/p&gt;\n\n&lt;p&gt;Backblaze still best value for deep archive (1-2TB)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17g0ey2", "is_robot_indexable": true, "report_reasons": null, "author": "hd1080ts", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17g0ey2/bulk_downloading_from_amazon_photos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17g0ey2/bulk_downloading_from_amazon_photos/", "subreddit_subscribers": 708642, "created_utc": 1698224200.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Curious what people are using for distributed storage these days in terms of non-proprietary systems. I guess broadly this would include both block &amp; object storage. Tell me what you think.\n\n&amp;#x200B;\n\n* Ceph/CephFS? The tried and true classic\n* GlusterFS? End-of-life by Redhat\n* Lustre? Exotic HPC platform\n* HDFS? Going the hadoop way\n* MooseFS? Free version has no erasure coding\n* JuiceFS with POSIX support (with Minio as base layer)? The hype new kid\n* SeaweedFS? Don't know much about this one\n* CurveFS/CurveBS? Not sure about POSIX compatibility\n* Plain old NFS? Not really distributed but still.", "author_fullname": "t2_ioi0j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you use for distributed storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17gh48f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698272981.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Curious what people are using for distributed storage these days in terms of non-proprietary systems. I guess broadly this would include both block &amp;amp; object storage. Tell me what you think.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Ceph/CephFS? The tried and true classic&lt;/li&gt;\n&lt;li&gt;GlusterFS? End-of-life by Redhat&lt;/li&gt;\n&lt;li&gt;Lustre? Exotic HPC platform&lt;/li&gt;\n&lt;li&gt;HDFS? Going the hadoop way&lt;/li&gt;\n&lt;li&gt;MooseFS? Free version has no erasure coding&lt;/li&gt;\n&lt;li&gt;JuiceFS with POSIX support (with Minio as base layer)? The hype new kid&lt;/li&gt;\n&lt;li&gt;SeaweedFS? Don&amp;#39;t know much about this one&lt;/li&gt;\n&lt;li&gt;CurveFS/CurveBS? Not sure about POSIX compatibility&lt;/li&gt;\n&lt;li&gt;Plain old NFS? Not really distributed but still.&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17gh48f", "is_robot_indexable": true, "report_reasons": null, "author": "fourDnet", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17gh48f/what_do_you_use_for_distributed_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17gh48f/what_do_you_use_for_distributed_storage/", "subreddit_subscribers": 708642, "created_utc": 1698272981.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought my Lsi controller about 5yrs ago never had any issues until yesterday when I lost power. None of my drives start up anymore. I tried to troubleshoot and seen I should have 1 of the lights flashing like a heartbeat. They all stay solid. Is my card dead? Any help would be appreciated.", "author_fullname": "t2_4w2o2ea4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LSI 9201-8I lights.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g3sex", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698237494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought my Lsi controller about 5yrs ago never had any issues until yesterday when I lost power. None of my drives start up anymore. I tried to troubleshoot and seen I should have 1 of the lights flashing like a heartbeat. They all stay solid. Is my card dead? Any help would be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17g3sex", "is_robot_indexable": true, "report_reasons": null, "author": "jsandy83", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17g3sex/lsi_92018i_lights/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17g3sex/lsi_92018i_lights/", "subreddit_subscribers": 708642, "created_utc": 1698237494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm currently trying to find a flow chart that shows the amost used indexer and download tools like Sonarr, Radar, Jacket \nI just want to setup a server from scratch to host and stream all of my media, but I'm looking for some chart that I'd use as a reference. \nI looked all over the internet but couldn't find any reference.\nThanks!", "author_fullname": "t2_dy5jt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Indexer's Flowchart for selfhosted server?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gdcg6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698263336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently trying to find a flow chart that shows the amost used indexer and download tools like Sonarr, Radar, Jacket \nI just want to setup a server from scratch to host and stream all of my media, but I&amp;#39;m looking for some chart that I&amp;#39;d use as a reference. \nI looked all over the internet but couldn&amp;#39;t find any reference.\nThanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17gdcg6", "is_robot_indexable": true, "report_reasons": null, "author": "pulgalipe", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17gdcg6/indexers_flowchart_for_selfhosted_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17gdcg6/indexers_flowchart_for_selfhosted_server/", "subreddit_subscribers": 708642, "created_utc": 1698263336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been using Hitachi Deskstar 5K3000 2TB drives for many years and they are starting to fail.  They are used in a ZFS RAID-Z2 configuration so it's difficult to upgrade the entire setup.\n\nCan anybody give me any advice?\n\nIdeally I'd like to upgrade each drive to a WD RED PLUS/PRO (6TB+?) but that's going to cost a ton of money...", "author_fullname": "t2_8noa5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to upgrade/replace 10x 2TB drives? (re: ZFS, RAID-Z2)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g94jb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698252181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been using Hitachi Deskstar 5K3000 2TB drives for many years and they are starting to fail.  They are used in a ZFS RAID-Z2 configuration so it&amp;#39;s difficult to upgrade the entire setup.&lt;/p&gt;\n\n&lt;p&gt;Can anybody give me any advice?&lt;/p&gt;\n\n&lt;p&gt;Ideally I&amp;#39;d like to upgrade each drive to a WD RED PLUS/PRO (6TB+?) but that&amp;#39;s going to cost a ton of money...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17g94jb", "is_robot_indexable": true, "report_reasons": null, "author": "sofakng", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17g94jb/how_to_upgradereplace_10x_2tb_drives_re_zfs_raidz2/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17g94jb/how_to_upgradereplace_10x_2tb_drives_re_zfs_raidz2/", "subreddit_subscribers": 708642, "created_utc": 1698252181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "My mum has at least a document box worth of photo albums and film store packets that we want to scan. Most of them don't have the date overlay, but I'm sure she would know a rough time range for each set of photos. The current plan is to simply store the scans in rough year range folders, and in album folders within those year folders if they're clearly from a certain event. Then once most stuff is scanned bulk set the date taken property, and maybe the description field for some of them.\n\nIs there anyway this could be done better?\nMy main concern is having them as a folder structure at the end, with the date taken set to something roughly correct so I don't have to worry about applications being required. (am planning on throwing them in as an external immich library though)", "author_fullname": "t2_15trlf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to organise photos without definite dates", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fzqiz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698221050.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My mum has at least a document box worth of photo albums and film store packets that we want to scan. Most of them don&amp;#39;t have the date overlay, but I&amp;#39;m sure she would know a rough time range for each set of photos. The current plan is to simply store the scans in rough year range folders, and in album folders within those year folders if they&amp;#39;re clearly from a certain event. Then once most stuff is scanned bulk set the date taken property, and maybe the description field for some of them.&lt;/p&gt;\n\n&lt;p&gt;Is there anyway this could be done better?\nMy main concern is having them as a folder structure at the end, with the date taken set to something roughly correct so I don&amp;#39;t have to worry about applications being required. (am planning on throwing them in as an external immich library though)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "17TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fzqiz", "is_robot_indexable": true, "report_reasons": null, "author": "JayBigGuy10", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17fzqiz/best_way_to_organise_photos_without_definite_dates/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fzqiz/best_way_to_organise_photos_without_definite_dates/", "subreddit_subscribers": 708642, "created_utc": 1698221050.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have seen posters that will obfuscate the name of the rar set password protect it and encrypt the file name and once you enter the correct password it is another rar archive.  What is the point of that wouldn't just password protecting and encrypting the file names be enough to keep an indexer from seeing what is inside?", "author_fullname": "t2_e7a0d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "RAR why do posters do this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fwm2q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698207988.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have seen posters that will obfuscate the name of the rar set password protect it and encrypt the file name and once you enter the correct password it is another rar archive.  What is the point of that wouldn&amp;#39;t just password protecting and encrypting the file names be enough to keep an indexer from seeing what is inside?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fwm2q", "is_robot_indexable": true, "report_reasons": null, "author": "gutty976", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fwm2q/rar_why_do_posters_do_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fwm2q/rar_why_do_posters_do_this/", "subreddit_subscribers": 708642, "created_utc": 1698207988.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It seems to me Exos X is superior on every front, price: capacity, AFR, power consumption.\n\nWhat is the use case for Exos E? Why does it cost more? I don't understand.\n\n&amp;#x200B;\n\nDrives in question are here [https://www.seagate.com/products/enterprise-drives/](https://www.seagate.com/products/enterprise-drives/)\n\nI know their site says \"low TCO\" (total cost of ownership) but I don't see how that makes sense given X series is superior in terms of AFR (annualized failure rate) and MTBF", "author_fullname": "t2_13eqfc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Exos E vs Exos X", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fspmn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698195774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems to me Exos X is superior on every front, price: capacity, AFR, power consumption.&lt;/p&gt;\n\n&lt;p&gt;What is the use case for Exos E? Why does it cost more? I don&amp;#39;t understand.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Drives in question are here &lt;a href=\"https://www.seagate.com/products/enterprise-drives/\"&gt;https://www.seagate.com/products/enterprise-drives/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I know their site says &amp;quot;low TCO&amp;quot; (total cost of ownership) but I don&amp;#39;t see how that makes sense given X series is superior in terms of AFR (annualized failure rate) and MTBF&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?auto=webp&amp;s=b98f58f088fdf8fbeb225a485466816520892a66", "width": 1440, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=800aeac928e4d6917cdf3db161d37c173da92af5", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a9549b2c27b55813f6941439e0246cac408ff1d", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=708b52a8cc3161e776c554b1f4a488231d8bfce6", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=93eb129bea186541cdd32a88a0cb2d619f9a954c", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ad5e3bcc25ba7cdf8dd591fb8e247b839fe5aa7", "width": 960, "height": 600}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b52b8bf108499e8a6d3bd58f428c8f644af3085", "width": 1080, "height": 675}], "variants": {}, "id": "GJ9K1o7VNo6J4JXg3IrZBPizWfgWXRc6b6FmSaP5cNc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17fspmn", "is_robot_indexable": true, "report_reasons": null, "author": "tronicdude6", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fspmn/seagate_exos_e_vs_exos_x/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fspmn/seagate_exos_e_vs_exos_x/", "subreddit_subscribers": 708642, "created_utc": 1698195774.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know both is the best answer and I currently have that, however, I'm wondering what peoples thoughts are on only having offsite backups?\n\nIt's \\*only\\* about 70TB's currently so if I need to go grab the backup server and run it home I can easily do so and have it on my 10Gb network for restoring files quickly.\n\n&amp;#x200B;\n\nI'm just thinking that 14 less HDD's running at home and 1 less server (125 watts or so with all drives running) wouldn't be a bad thing.\n\nI'd need to move my QDevice VM for my Proxmox HA Cluster off of it but that's not a big deal.", "author_fullname": "t2_k35qoa9w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Local backups vs offsite backups when the offsite location is less than 10 minutes away?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gejw7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698266547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know both is the best answer and I currently have that, however, I&amp;#39;m wondering what peoples thoughts are on only having offsite backups?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s *only* about 70TB&amp;#39;s currently so if I need to go grab the backup server and run it home I can easily do so and have it on my 10Gb network for restoring files quickly.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just thinking that 14 less HDD&amp;#39;s running at home and 1 less server (125 watts or so with all drives running) wouldn&amp;#39;t be a bad thing.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d need to move my QDevice VM for my Proxmox HA Cluster off of it but that&amp;#39;s not a big deal.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17gejw7", "is_robot_indexable": true, "report_reasons": null, "author": "Firestarter321", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17gejw7/local_backups_vs_offsite_backups_when_the_offsite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17gejw7/local_backups_vs_offsite_backups_when_the_offsite/", "subreddit_subscribers": 708642, "created_utc": 1698266547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "***TL;DR:*** This is mostly for large amounts of data that I won't frequently access but that I would like peace of mind that it will remain in-tact for 10+ years with minimal thought other than making sure the storage medium is stored in a cool and dry place. Grappling with SD cards, flash drives, external HDD's, external SSD's, and Tape Storage. What do you think would be the most cost-effective and durable option? Access speeds are unimportant to me, though sequential write speeds would preferably be reasonable as taking an eon to record data in the first place (like a 256GB USB 2.0 Flash drive... shiver...) is pretty awful.\n\n&amp;#x200B;\n\n***Long version:***\n\nI would continue using a reputable service like Google Drive or Microsoft OneDrive given that these massive corporations are unlikely to stop providing service at any point in my lifetime realistically (I'm 29), however the problem comes down to the unreliability of funds and the over-time cost. Eventually paying a perpetual fee for storage will overtake the cost of ponying up for storage up front, and sometimes (like right now for example) I end up in random bouts of financial hardship where I can't justify spending money monthly just to ensure my data doesn't get deleted. \n\nI am in a situation where most of the time, the storage I need lines up pretty well with WORM mediums (Write Once, Read Many) as a lot of it is photographs and videos and a few audio files. Sometimes, it's just copies of old software I don't want to dredge up again, and I'd rather not have to keep downloading classic movies and then deleting them after watching to maintain storage space. So, I'd like to be able to store something in a pretty safe way that won't be accessed super often but will keep for a long time in a cost-effective manner.\n\nI considered Micro SD cards as they can be fairly reliable if treated well and are ejected safely from your PC and you use a decent reader, but they are not rated for long-term reliability. I don't want to pop my Micro SD into a computer 5-10 years from now to find all of my early-relationship videos and photos of my fiancee and I corrupted and unrecoverable just because it kinda degraded or something. Hard Drives are pretty safe I suppose, but then there's the worry of tendency to fail with a lot of usage / spin ups. It could potentially last a super long time, but I'm slightly paranoid because I lost a ton (3tb or so) of data about a year ago when a previously in-perfect-shape external drive of mine suddenly ate shit and I couldn't manage to recover most of the data. DVD's concern me because the dye in the written layer (or whatever composite material is used) is known for breaking down on consumer-writable discs after several years, and I don't like the idea of an optical disk just literally rotting on a shelf.\n\nI am aware of tape storage being a thing; it sucks for random-access purposes but is great for retaining long-term storage and can come in large capacity at relatively low cost, and magnetic tape media lasts for extraordinarily long time when stored properly. Should I look into that?\n\nAlternatively with the low cost of SD cards, should I perhaps just buy sets of SD cards and make duplicate backups? Or, maybe an SSD would be good since they are higher quality (though still are relatively volatile in that failure causes high rates of absolute loss of data) and just eat the price?", "author_fullname": "t2_yfioj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trying to pry myself away from cloud storage, but not sure how to proceed. Could you please help me determine the best way to preserve infrequently used data in a way that I won't need to worry about it surviving?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gdtc9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698264589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;TL;DR:&lt;/em&gt;&lt;/strong&gt; This is mostly for large amounts of data that I won&amp;#39;t frequently access but that I would like peace of mind that it will remain in-tact for 10+ years with minimal thought other than making sure the storage medium is stored in a cool and dry place. Grappling with SD cards, flash drives, external HDD&amp;#39;s, external SSD&amp;#39;s, and Tape Storage. What do you think would be the most cost-effective and durable option? Access speeds are unimportant to me, though sequential write speeds would preferably be reasonable as taking an eon to record data in the first place (like a 256GB USB 2.0 Flash drive... shiver...) is pretty awful.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;&lt;em&gt;Long version:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I would continue using a reputable service like Google Drive or Microsoft OneDrive given that these massive corporations are unlikely to stop providing service at any point in my lifetime realistically (I&amp;#39;m 29), however the problem comes down to the unreliability of funds and the over-time cost. Eventually paying a perpetual fee for storage will overtake the cost of ponying up for storage up front, and sometimes (like right now for example) I end up in random bouts of financial hardship where I can&amp;#39;t justify spending money monthly just to ensure my data doesn&amp;#39;t get deleted. &lt;/p&gt;\n\n&lt;p&gt;I am in a situation where most of the time, the storage I need lines up pretty well with WORM mediums (Write Once, Read Many) as a lot of it is photographs and videos and a few audio files. Sometimes, it&amp;#39;s just copies of old software I don&amp;#39;t want to dredge up again, and I&amp;#39;d rather not have to keep downloading classic movies and then deleting them after watching to maintain storage space. So, I&amp;#39;d like to be able to store something in a pretty safe way that won&amp;#39;t be accessed super often but will keep for a long time in a cost-effective manner.&lt;/p&gt;\n\n&lt;p&gt;I considered Micro SD cards as they can be fairly reliable if treated well and are ejected safely from your PC and you use a decent reader, but they are not rated for long-term reliability. I don&amp;#39;t want to pop my Micro SD into a computer 5-10 years from now to find all of my early-relationship videos and photos of my fiancee and I corrupted and unrecoverable just because it kinda degraded or something. Hard Drives are pretty safe I suppose, but then there&amp;#39;s the worry of tendency to fail with a lot of usage / spin ups. It could potentially last a super long time, but I&amp;#39;m slightly paranoid because I lost a ton (3tb or so) of data about a year ago when a previously in-perfect-shape external drive of mine suddenly ate shit and I couldn&amp;#39;t manage to recover most of the data. DVD&amp;#39;s concern me because the dye in the written layer (or whatever composite material is used) is known for breaking down on consumer-writable discs after several years, and I don&amp;#39;t like the idea of an optical disk just literally rotting on a shelf.&lt;/p&gt;\n\n&lt;p&gt;I am aware of tape storage being a thing; it sucks for random-access purposes but is great for retaining long-term storage and can come in large capacity at relatively low cost, and magnetic tape media lasts for extraordinarily long time when stored properly. Should I look into that?&lt;/p&gt;\n\n&lt;p&gt;Alternatively with the low cost of SD cards, should I perhaps just buy sets of SD cards and make duplicate backups? Or, maybe an SSD would be good since they are higher quality (though still are relatively volatile in that failure causes high rates of absolute loss of data) and just eat the price?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17gdtc9", "is_robot_indexable": true, "report_reasons": null, "author": "IDE_IS_LIFE", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17gdtc9/trying_to_pry_myself_away_from_cloud_storage_but/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17gdtc9/trying_to_pry_myself_away_from_cloud_storage_but/", "subreddit_subscribers": 708642, "created_utc": 1698264589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hya Hoarders,\n\nI could really use some help. I am having to move to local storage by the end of the year. I've never really considered a home server or NAS type solution. Now that I have too, I'm incredibly overwhelmed....\n\nI have to store about 120TB of media, which I'm trying to cut down to save on hard drive costs. I have a PC acting as my Plex media server right now but can't cram enough drives into it to hold everything. What would be the best route to go? \n\nTimes are tight as we get close to the holidays but I need to try and make something work since the cloud is a no go now. \n\nShould I just get a NAS that has 6+ bays and hook it to my PC? That seems the simplest thing to do but I know it might not be the smartest...\n\n&amp;#x200B;\n\nI have been looking over the Wiki and past posts for hours and am not getting anywhere myself. There are a lot of really talented people here and if anyone could help I would be very appreciative!", "author_fullname": "t2_16260q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving Local and Need Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g91z0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "eac073cc-b98a-11e2-84c9-12313d1841d1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "vhs", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698251997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hya Hoarders,&lt;/p&gt;\n\n&lt;p&gt;I could really use some help. I am having to move to local storage by the end of the year. I&amp;#39;ve never really considered a home server or NAS type solution. Now that I have too, I&amp;#39;m incredibly overwhelmed....&lt;/p&gt;\n\n&lt;p&gt;I have to store about 120TB of media, which I&amp;#39;m trying to cut down to save on hard drive costs. I have a PC acting as my Plex media server right now but can&amp;#39;t cram enough drives into it to hold everything. What would be the best route to go? &lt;/p&gt;\n\n&lt;p&gt;Times are tight as we get close to the holidays but I need to try and make something work since the cloud is a no go now. &lt;/p&gt;\n\n&lt;p&gt;Should I just get a NAS that has 6+ bays and hook it to my PC? That seems the simplest thing to do but I know it might not be the smartest...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have been looking over the Wiki and past posts for hours and am not getting anywhere myself. There are a lot of really talented people here and if anyone could help I would be very appreciative!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "100TB | Local and Reliable", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17g91z0", "is_robot_indexable": true, "report_reasons": null, "author": "rowdya22", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17g91z0/moving_local_and_need_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17g91z0/moving_local_and_need_help/", "subreddit_subscribers": 708642, "created_utc": 1698251997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am looking for a medium capacity scanner with high degree of OCR accuracy.  5,000 pages per day is fine, at least 50 ADP capacity.\n\nThe documents are medical-legal, so HIPAA compliance and the ability to retain the original image just in case, because the goal is to not have to keep 1,000 pages of paper in storage for years (per patient...it adds up).\n\nThis is mainly for QME medical record review - a lot of these documents are copies of copies, poor quality faxes, etc.\n\nHow important is it for a scanner to have accurate OCR, versus running it through an OCR program?\n\nBudget is under $700. \n\nI already checked out other threads on scanners and am looking at the Raven Pro and Canon Image formula RS40, but I still have questions about OCR accuracy mainly.", "author_fullname": "t2_fdqlsef1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Document scanning &amp; OCR", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g754o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698246999.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am looking for a medium capacity scanner with high degree of OCR accuracy.  5,000 pages per day is fine, at least 50 ADP capacity.&lt;/p&gt;\n\n&lt;p&gt;The documents are medical-legal, so HIPAA compliance and the ability to retain the original image just in case, because the goal is to not have to keep 1,000 pages of paper in storage for years (per patient...it adds up).&lt;/p&gt;\n\n&lt;p&gt;This is mainly for QME medical record review - a lot of these documents are copies of copies, poor quality faxes, etc.&lt;/p&gt;\n\n&lt;p&gt;How important is it for a scanner to have accurate OCR, versus running it through an OCR program?&lt;/p&gt;\n\n&lt;p&gt;Budget is under $700. &lt;/p&gt;\n\n&lt;p&gt;I already checked out other threads on scanners and am looking at the Raven Pro and Canon Image formula RS40, but I still have questions about OCR accuracy mainly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17g754o", "is_robot_indexable": true, "report_reasons": null, "author": "CBRit33", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17g754o/document_scanning_ocr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17g754o/document_scanning_ocr/", "subreddit_subscribers": 708642, "created_utc": 1698246999.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have 3x RAID1 pairs of 6 disks of the same size. I buy 2 more disks (same size). What's the best option for converting to a better array layout, while keeping the data (without passing through an external backup \ud83d\ude41), and ending up with more capacity and decent redundancy?\n\nSome options I've considered:\n\n1. Just add a 4th 2d RAID1 and call it a day. 4d capacity overall, 1 redundancy per set, and the option to upgrade any of the RAID1's to a larger disk size independently.\n2. 8d RAID6. I force-degrade the RAID1 arrays, use the 5 free disks to create a 5d RAID6, copy the data over, then add the 3 remaining disks to the RAID6 and grow the array to 8d. Big con: if the growth sequence is interrupted the whole thing is lost? Although I've read you can use a 16MB state file on a separate disk to recover. End up with 6d capacity and 2 drive redundancy.\n3. 5d RAID6 and 3d RAID5. Same as above but I leave the 5d RAID6 alone and make a 3d RAID5. End up with 5d capacity overall and 2 and 1 drive redundancy respectively.\n4. 2x 4d RAID6. Degrade the RAID1's as above but make a 4d RAID6 and then another. End up with 4d capacity overall and 2 drive redundancy respectively per RAID6. Big con: would need to trim some data during the copy from 3xDISK to 2xDISK capacity.\n5. 8d RAID60 or 8d RAID10. I would make up degraded RAID0 and expand it with new RAID6 or RAID1 mirrors. Not sure there's any benefit in this one, the RAID0 expansion(s) are vulnerable, and would end up with only 4d capacity and 2 or 1 redundancy per set.\n\nIs any of these a good idea? Do you have another? #4 and #5 in particular seem like too much hassle vs #1. The #2 option is interesting for capacity but risky and not that much redundancy. #3 seems like the safest.\n\nBonus question, can any of the new arrays use zfs strictly for the filesystem (self-check benefits), rather than volume management?\n\nAnd, related: can a RAID1 be converted from ext4 to zfs filesystem by degrading the array, using the removed disk to make a degraded RAID1 with zfs filesystem, copying the data over, then adding the 1st disk to the 2nd array?\n\nTIA for any insight and ideas.", "author_fullname": "t2_4o56qcsr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting RAID1 arrays to something better?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g6fcq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698245063.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 3x RAID1 pairs of 6 disks of the same size. I buy 2 more disks (same size). What&amp;#39;s the best option for converting to a better array layout, while keeping the data (without passing through an external backup \ud83d\ude41), and ending up with more capacity and decent redundancy?&lt;/p&gt;\n\n&lt;p&gt;Some options I&amp;#39;ve considered:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Just add a 4th 2d RAID1 and call it a day. 4d capacity overall, 1 redundancy per set, and the option to upgrade any of the RAID1&amp;#39;s to a larger disk size independently.&lt;/li&gt;\n&lt;li&gt;8d RAID6. I force-degrade the RAID1 arrays, use the 5 free disks to create a 5d RAID6, copy the data over, then add the 3 remaining disks to the RAID6 and grow the array to 8d. Big con: if the growth sequence is interrupted the whole thing is lost? Although I&amp;#39;ve read you can use a 16MB state file on a separate disk to recover. End up with 6d capacity and 2 drive redundancy.&lt;/li&gt;\n&lt;li&gt;5d RAID6 and 3d RAID5. Same as above but I leave the 5d RAID6 alone and make a 3d RAID5. End up with 5d capacity overall and 2 and 1 drive redundancy respectively.&lt;/li&gt;\n&lt;li&gt;2x 4d RAID6. Degrade the RAID1&amp;#39;s as above but make a 4d RAID6 and then another. End up with 4d capacity overall and 2 drive redundancy respectively per RAID6. Big con: would need to trim some data during the copy from 3xDISK to 2xDISK capacity.&lt;/li&gt;\n&lt;li&gt;8d RAID60 or 8d RAID10. I would make up degraded RAID0 and expand it with new RAID6 or RAID1 mirrors. Not sure there&amp;#39;s any benefit in this one, the RAID0 expansion(s) are vulnerable, and would end up with only 4d capacity and 2 or 1 redundancy per set.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Is any of these a good idea? Do you have another? #4 and #5 in particular seem like too much hassle vs #1. The #2 option is interesting for capacity but risky and not that much redundancy. #3 seems like the safest.&lt;/p&gt;\n\n&lt;p&gt;Bonus question, can any of the new arrays use zfs strictly for the filesystem (self-check benefits), rather than volume management?&lt;/p&gt;\n\n&lt;p&gt;And, related: can a RAID1 be converted from ext4 to zfs filesystem by degrading the array, using the removed disk to make a degraded RAID1 with zfs filesystem, copying the data over, then adding the 1st disk to the 2nd array?&lt;/p&gt;\n\n&lt;p&gt;TIA for any insight and ideas.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17g6fcq", "is_robot_indexable": true, "report_reasons": null, "author": "GolemancerVekk", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17g6fcq/converting_raid1_arrays_to_something_better/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17g6fcq/converting_raid1_arrays_to_something_better/", "subreddit_subscribers": 708642, "created_utc": 1698245063.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello guys, I've made this thread in hopes of getting some opinions and advice. I used to work in a rather small company where we used LTO tapes, rotating them weekly. I believe we used LTO-6. Since then, I've been interested in that backup method.\n\nMy home server runs inside a Fractal Define R5, which has two 5,25 slots. It's a consumer board (Z270-K, i7 7700k), and has been running as a home server with OpenMediaVault. It currently has two 2TB drives in raid1, a big, 8TB spare drive that I also use for my desktop backups, and two SSDs, one for docker containers, the other for the system itself. I'm currently starting to run out of space, and while I know hard drives are affordable, I'm not touching the data on them, so I want some good offline solution to keep working on my projects.\n\nI'm planning to store photography (preservation of negatives and slides, about 600MB per frame in most cases), video (digitized media for archival, sometimes lost media, again, for preservation), and audio, alongside huge server files I've been archiving since 2010.\n\nI've been thinking about getting a LTO drive for backing up my data, and so far, the info I've gathered is:\n\n* LTO-5 seems to be the most appropriate for my use case, having LTFS and about a terabyte per tape.\n* I would need a PCI-E SAS controller of some kind (this is where I have doubts).\n* Tapes are a good method for storing data over a long period of time, where as BD-R discs (my current method) are limited to 25GB (or 23,3GiB), forcing me to split backups into a few discs, and re-recording every 3-5 years.\n* Initial investment is higher but it's worth in the long run.\n* Should be able to check the drive's age and wear through software, although I'm unsure of how.\n* It should be able to run on linux, but this I will look up later when I need to test things out.\n\nSo, my doubts are in the following:\n\nWhat kind of PCI-E SAS controller card should I get or look up? I've seen RAID cards, which I assume are NOT the same thing. I've never used one, so I would need advice in this. This is where I'm completely lost.\n\nAnd about LTO-5 drives, any particular brand, or something specific I should look into? I'm primarily using linux on both server and desktop, I don't know if that's a problem compatibility-wise. I could deploy a windows VM on my server if necessary, or dual-boot into windows on my desktop.\n\nI don't care about the budget, I want the drive regardless. The data I'm storing is far more important, I wouldn't be here asking otherwise. Anyway, I hope this clarifies my doubts as much as possible.\n\nThanks in advance, guys.", "author_fullname": "t2_86u1b08y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for some advice about LTO storage.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g4r68", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698273894.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698240345.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I&amp;#39;ve made this thread in hopes of getting some opinions and advice. I used to work in a rather small company where we used LTO tapes, rotating them weekly. I believe we used LTO-6. Since then, I&amp;#39;ve been interested in that backup method.&lt;/p&gt;\n\n&lt;p&gt;My home server runs inside a Fractal Define R5, which has two 5,25 slots. It&amp;#39;s a consumer board (Z270-K, i7 7700k), and has been running as a home server with OpenMediaVault. It currently has two 2TB drives in raid1, a big, 8TB spare drive that I also use for my desktop backups, and two SSDs, one for docker containers, the other for the system itself. I&amp;#39;m currently starting to run out of space, and while I know hard drives are affordable, I&amp;#39;m not touching the data on them, so I want some good offline solution to keep working on my projects.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m planning to store photography (preservation of negatives and slides, about 600MB per frame in most cases), video (digitized media for archival, sometimes lost media, again, for preservation), and audio, alongside huge server files I&amp;#39;ve been archiving since 2010.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been thinking about getting a LTO drive for backing up my data, and so far, the info I&amp;#39;ve gathered is:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;LTO-5 seems to be the most appropriate for my use case, having LTFS and about a terabyte per tape.&lt;/li&gt;\n&lt;li&gt;I would need a PCI-E SAS controller of some kind (this is where I have doubts).&lt;/li&gt;\n&lt;li&gt;Tapes are a good method for storing data over a long period of time, where as BD-R discs (my current method) are limited to 25GB (or 23,3GiB), forcing me to split backups into a few discs, and re-recording every 3-5 years.&lt;/li&gt;\n&lt;li&gt;Initial investment is higher but it&amp;#39;s worth in the long run.&lt;/li&gt;\n&lt;li&gt;Should be able to check the drive&amp;#39;s age and wear through software, although I&amp;#39;m unsure of how.&lt;/li&gt;\n&lt;li&gt;It should be able to run on linux, but this I will look up later when I need to test things out.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;So, my doubts are in the following:&lt;/p&gt;\n\n&lt;p&gt;What kind of PCI-E SAS controller card should I get or look up? I&amp;#39;ve seen RAID cards, which I assume are NOT the same thing. I&amp;#39;ve never used one, so I would need advice in this. This is where I&amp;#39;m completely lost.&lt;/p&gt;\n\n&lt;p&gt;And about LTO-5 drives, any particular brand, or something specific I should look into? I&amp;#39;m primarily using linux on both server and desktop, I don&amp;#39;t know if that&amp;#39;s a problem compatibility-wise. I could deploy a windows VM on my server if necessary, or dual-boot into windows on my desktop.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t care about the budget, I want the drive regardless. The data I&amp;#39;m storing is far more important, I wouldn&amp;#39;t be here asking otherwise. Anyway, I hope this clarifies my doubts as much as possible.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance, guys.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "16TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17g4r68", "is_robot_indexable": true, "report_reasons": null, "author": "AirPlenty", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17g4r68/looking_for_some_advice_about_lto_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17g4r68/looking_for_some_advice_about_lto_storage/", "subreddit_subscribers": 708642, "created_utc": 1698240345.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a website \"mywebsite.com\" that requires login and complex verification method. I want to make a offline copy of it for personal use.\n\nHttrack, wget or any other method fails during login. I have logged on with chrome and attached webdriver. I want to clone it/ download all pages under the domain [www.mywebsite.com/\\\\](http://www.mywebsite.com/%5C)\\* for offline use. Using selenium I can only download one page. How to download the whole website that includes all the links under that domain in relative relation .\n\n**ps: any tool that could do that will also work**.\n\n    import time\n    from selenium import webdriver\n    from selenium.webdriver.chrome.options import Options \n    options = webdriver.ChromeOptions()\n    options.add_argument(\"user-data-dir=C:\\\\Users\\\\mrmin\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n    options.add_experimental_option(\"detach\", True)\n    driver = webdriver.Chrome(options=options)\n    driver.get(\"https://www.mywebsite.com\")```", "author_fullname": "t2_a3rs29dtt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Download whole website through chrome using selenium or any tool.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fwbh7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698206952.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a website &amp;quot;mywebsite.com&amp;quot; that requires login and complex verification method. I want to make a offline copy of it for personal use.&lt;/p&gt;\n\n&lt;p&gt;Httrack, wget or any other method fails during login. I have logged on with chrome and attached webdriver. I want to clone it/ download all pages under the domain [&lt;a href=\"http://www.mywebsite.com/%5C%5C%5D(http://www.mywebsite.com/%5C)%5C*\"&gt;www.mywebsite.com/\\\\](http://www.mywebsite.com/%5C)\\*&lt;/a&gt; for offline use. Using selenium I can only download one page. How to download the whole website that includes all the links under that domain in relative relation .&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;ps: any tool that could do that will also work&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import time\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options \noptions = webdriver.ChromeOptions()\noptions.add_argument(&amp;quot;user-data-dir=C:\\\\Users\\\\mrmin\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data&amp;quot;)\noptions.add_experimental_option(&amp;quot;detach&amp;quot;, True)\ndriver = webdriver.Chrome(options=options)\ndriver.get(&amp;quot;https://www.mywebsite.com&amp;quot;)```\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fwbh7", "is_robot_indexable": true, "report_reasons": null, "author": "mrmin87", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fwbh7/download_whole_website_through_chrome_using/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fwbh7/download_whole_website_through_chrome_using/", "subreddit_subscribers": 708642, "created_utc": 1698206952.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Been on google, github, stack overflow, and reddit for the last few days and have not been able to figure out how to accomplish what I am trying to do.   \n\n\nI have an index of a site I am trying to download. There are hundreds of folders, each folder has at least one subfolder, and some of the subfolders have subfolders. Files, mostly pdf's in all levels. The issue is, no matter what I use, best case scenario I am getting the main folders and the files in those. The subfolder will download, but it will be empty, or have an index of that subfolder.   \n\n\nManually downloading this is not an option. It would take me days to go one by one. My goal is to download as is, with all the folders, subfolder, files, etc... all in their place as it is listed in the sites index page.   \n\n\nSo far I have tried a few gui's like visualwget, jdownloader and a few chrome extensions.   \n\n\nOn my linux VM I have used wget with about every combination of flags I can think ok. Nothing has been able to work so far.  \n\n\nIs there any advice I can get from you guys?", "author_fullname": "t2_pyc58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Downloading from Index of", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ftd0y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698197680.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Been on google, github, stack overflow, and reddit for the last few days and have not been able to figure out how to accomplish what I am trying to do.   &lt;/p&gt;\n\n&lt;p&gt;I have an index of a site I am trying to download. There are hundreds of folders, each folder has at least one subfolder, and some of the subfolders have subfolders. Files, mostly pdf&amp;#39;s in all levels. The issue is, no matter what I use, best case scenario I am getting the main folders and the files in those. The subfolder will download, but it will be empty, or have an index of that subfolder.   &lt;/p&gt;\n\n&lt;p&gt;Manually downloading this is not an option. It would take me days to go one by one. My goal is to download as is, with all the folders, subfolder, files, etc... all in their place as it is listed in the sites index page.   &lt;/p&gt;\n\n&lt;p&gt;So far I have tried a few gui&amp;#39;s like visualwget, jdownloader and a few chrome extensions.   &lt;/p&gt;\n\n&lt;p&gt;On my linux VM I have used wget with about every combination of flags I can think ok. Nothing has been able to work so far.  &lt;/p&gt;\n\n&lt;p&gt;Is there any advice I can get from you guys?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ftd0y", "is_robot_indexable": true, "report_reasons": null, "author": "Kazelob", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ftd0y/downloading_from_index_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ftd0y/downloading_from_index_of/", "subreddit_subscribers": 708642, "created_utc": 1698197680.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, I am looking for a bit of guidance regarding what software and operating system will be the most appropriate for a project of mine. I have been using TrueNAS for quite some time now but have grown dissatisfied. I am currently looking for a replacement OS that can either achieve the following configuration natively or through installed software packages. I would also really prefer the ability to run programs such as plex and adguard as plugins rather than VMs where resource management is on the end user or worse, Docker containers which I am not familiar with using at all (I know, I'll get around to it lol).\n\n&amp;#x200B;\n\nMy desired configuration consists of three separate drive arrays which are presented to the OS as and act together as a single Pool for storing data and accessing via SMB on Windows. \n\n&amp;#x200B;\n\nArray 1: RAID6 (or equivalent) of high capacity HDDs that acts as the underlying mass storage of the server and where all data lives permanently until deleted by a user or program and regardless of its existence in read cache which brings me to my second array. Array 1 will need to be done via software RAID.\n\n&amp;#x200B;\n\nArray 2: RAID0 (or equivalent) of high speed NVMe SSDs which will act as a read cache for the server where the most frequently accessed data is copied to (NOT moved, important distinction) so that it can be read by a client machine or program (such as plex) with the highest possible speed. All the SSDs for Array 2 will live inside a PCIe adapter card and thus not need their RAID functionality managed by software. I am open to alternative devices for this such as a single SSD that uses a PCIe 4/5 x8/x16 interface however I am looking for blazing fast speed out of this array so it will have to outperform 4x WD Black SN850x SSDs in RAID0.\n\n&amp;#x200B;\n\nArray 3: For my final array (aside from a mirrored boot drive), I would like to use two NVMe SSDs in RAID1 (or equivalent) as a write cache where data is stored temporarily as it is transfered to the server via SMB or otherwise for quicker transfers, and then moved to the HDD array when the server is not actively in use by a user/program. This SSD mirror will occupy individual M.2 slots on the motherboard and thus will need to have its RAID functionality managed by software. \n\n&amp;#x200B;\n\nI have mostly been pointed towards unRAID and SnapRAID+MergerFS but have not been able to confirm that either of these choices will be able to achieve what I am setting out to do. Any advice or recommendations that any of you have to offer is greatly appreciated. Thank you for your time!", "author_fullname": "t2_bcjqvtx5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Which OS do I choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17gglyd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698271678.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I am looking for a bit of guidance regarding what software and operating system will be the most appropriate for a project of mine. I have been using TrueNAS for quite some time now but have grown dissatisfied. I am currently looking for a replacement OS that can either achieve the following configuration natively or through installed software packages. I would also really prefer the ability to run programs such as plex and adguard as plugins rather than VMs where resource management is on the end user or worse, Docker containers which I am not familiar with using at all (I know, I&amp;#39;ll get around to it lol).&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;My desired configuration consists of three separate drive arrays which are presented to the OS as and act together as a single Pool for storing data and accessing via SMB on Windows. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Array 1: RAID6 (or equivalent) of high capacity HDDs that acts as the underlying mass storage of the server and where all data lives permanently until deleted by a user or program and regardless of its existence in read cache which brings me to my second array. Array 1 will need to be done via software RAID.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Array 2: RAID0 (or equivalent) of high speed NVMe SSDs which will act as a read cache for the server where the most frequently accessed data is copied to (NOT moved, important distinction) so that it can be read by a client machine or program (such as plex) with the highest possible speed. All the SSDs for Array 2 will live inside a PCIe adapter card and thus not need their RAID functionality managed by software. I am open to alternative devices for this such as a single SSD that uses a PCIe 4/5 x8/x16 interface however I am looking for blazing fast speed out of this array so it will have to outperform 4x WD Black SN850x SSDs in RAID0.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Array 3: For my final array (aside from a mirrored boot drive), I would like to use two NVMe SSDs in RAID1 (or equivalent) as a write cache where data is stored temporarily as it is transfered to the server via SMB or otherwise for quicker transfers, and then moved to the HDD array when the server is not actively in use by a user/program. This SSD mirror will occupy individual M.2 slots on the motherboard and thus will need to have its RAID functionality managed by software. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I have mostly been pointed towards unRAID and SnapRAID+MergerFS but have not been able to confirm that either of these choices will be able to achieve what I am setting out to do. Any advice or recommendations that any of you have to offer is greatly appreciated. Thank you for your time!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17gglyd", "is_robot_indexable": true, "report_reasons": null, "author": "nathankrebs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17gglyd/which_os_do_i_choose/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17gglyd/which_os_do_i_choose/", "subreddit_subscribers": 708642, "created_utc": 1698271678.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a tweak to a setting in Windows Server that I can make to ensure that the HDD will spin down after a while?\n\n\\[For home use,\\] I'd like to add an HDD to a Windows Server 2012 R2 box that acts as a server and up until now has all SSDs.  With SSDs I didn't care about this aspect but I'd like the added HDD to spin down after some period of inactivity to avoid wear and tear.\n\n&amp;#x200B;\n\n\\--------\n\nBackground:\n\nMy NAS does this (spins drives down due to inactivity) and so 3 out of 4 WD 2TB Greens (yes!) have survived in it for over 10 years!  I don't think Windows Servers will spin down drives by default.\n\nI'm the only user of the data on that HDD.   And I use it sporadically.  For example, I've been away from home for 2 months.  And so if the drive had been spinning all that time, it would have done that pointlessly.  And even if I am home, the data on it could go for a month without access (it's mainly for photos and I edit them in batches, sometimes a long time between batches).", "author_fullname": "t2_42pbqjdl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Windows tweak to ensure HDDs spin down after a while?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gdt9o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698271019.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698264583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a tweak to a setting in Windows Server that I can make to ensure that the HDD will spin down after a while?&lt;/p&gt;\n\n&lt;p&gt;[For home use,] I&amp;#39;d like to add an HDD to a Windows Server 2012 R2 box that acts as a server and up until now has all SSDs.  With SSDs I didn&amp;#39;t care about this aspect but I&amp;#39;d like the added HDD to spin down after some period of inactivity to avoid wear and tear.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;--------&lt;/p&gt;\n\n&lt;p&gt;Background:&lt;/p&gt;\n\n&lt;p&gt;My NAS does this (spins drives down due to inactivity) and so 3 out of 4 WD 2TB Greens (yes!) have survived in it for over 10 years!  I don&amp;#39;t think Windows Servers will spin down drives by default.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m the only user of the data on that HDD.   And I use it sporadically.  For example, I&amp;#39;ve been away from home for 2 months.  And so if the drive had been spinning all that time, it would have done that pointlessly.  And even if I am home, the data on it could go for a month without access (it&amp;#39;s mainly for photos and I edit them in batches, sometimes a long time between batches).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17gdt9o", "is_robot_indexable": true, "report_reasons": null, "author": "tvv2018", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17gdt9o/windows_tweak_to_ensure_hdds_spin_down_after_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17gdt9o/windows_tweak_to_ensure_hdds_spin_down_after_a/", "subreddit_subscribers": 708642, "created_utc": 1698264583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm planing to build a CD/DVD ripper machine to digitize &gt;200 disks. Disks came from IT magazines.\n\nWhat I (will) have so far is a case with 10 DVD drives, Z170A GAMING PRO mother board with i7-6700k  CPU and a Cooler Master G650M PSU. \n\nWhat I plan to get is a [molex sata splitter](https://www.aliexpress.com/w/wholesale-molex-sata-splitter.html?spm=a2g0o.productlist.search.0) for power and a [sata pcie expansion card](https://www.aliexpress.com/w/wholesale-sata-pcie-card.html?spm=a2g0o.productlist.search.0) for additional 6 SATA connector.\n\nAny advice on the hardver/softver/digitization process ?", "author_fullname": "t2_sxbi0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "CD/DVD ripper machine build", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17gbio7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698258465.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m planing to build a CD/DVD ripper machine to digitize &amp;gt;200 disks. Disks came from IT magazines.&lt;/p&gt;\n\n&lt;p&gt;What I (will) have so far is a case with 10 DVD drives, Z170A GAMING PRO mother board with i7-6700k  CPU and a Cooler Master G650M PSU. &lt;/p&gt;\n\n&lt;p&gt;What I plan to get is a &lt;a href=\"https://www.aliexpress.com/w/wholesale-molex-sata-splitter.html?spm=a2g0o.productlist.search.0\"&gt;molex sata splitter&lt;/a&gt; for power and a &lt;a href=\"https://www.aliexpress.com/w/wholesale-sata-pcie-card.html?spm=a2g0o.productlist.search.0\"&gt;sata pcie expansion card&lt;/a&gt; for additional 6 SATA connector.&lt;/p&gt;\n\n&lt;p&gt;Any advice on the hardver/softver/digitization process ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17gbio7", "is_robot_indexable": true, "report_reasons": null, "author": "codebreaker101", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17gbio7/cddvd_ripper_machine_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17gbio7/cddvd_ripper_machine_build/", "subreddit_subscribers": 708642, "created_utc": 1698258465.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'd like to check that a HBA is functioning correctly is there a way to do it ?  I'm thinking of something along the likes of having a 1MB seed and writing pseudo random data to the disk until it is full, then verifying it was written correctly using the seed to verify the data.\n\nThis shouldn't be the same data repeated using dd\n\nIs this possible ?  How would you verify a storage controller ?\n\nSorry if this isn't an often asked question, but I wrote a firmware update to a HBA and want to ensure that it does what it is supposed to.\n\n&amp;#x200B;", "author_fullname": "t2_1w5zqtt8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "testing a HBA and disks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g2kyy", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698233361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d like to check that a HBA is functioning correctly is there a way to do it ?  I&amp;#39;m thinking of something along the likes of having a 1MB seed and writing pseudo random data to the disk until it is full, then verifying it was written correctly using the seed to verify the data.&lt;/p&gt;\n\n&lt;p&gt;This shouldn&amp;#39;t be the same data repeated using dd&lt;/p&gt;\n\n&lt;p&gt;Is this possible ?  How would you verify a storage controller ?&lt;/p&gt;\n\n&lt;p&gt;Sorry if this isn&amp;#39;t an often asked question, but I wrote a firmware update to a HBA and want to ensure that it does what it is supposed to.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17g2kyy", "is_robot_indexable": true, "report_reasons": null, "author": "simonmcnair", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17g2kyy/testing_a_hba_and_disks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17g2kyy/testing_a_hba_and_disks/", "subreddit_subscribers": 708642, "created_utc": 1698233361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is the genuine service system of wayback machine by internet archive work as of today?\n\nor is there a shutdown?", "author_fullname": "t2_cwz2d4tnx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does Wayback Machine work as per recent?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ge3w5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698265364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is the genuine service system of wayback machine by internet archive work as of today?&lt;/p&gt;\n\n&lt;p&gt;or is there a shutdown?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ge3w5", "is_robot_indexable": true, "report_reasons": null, "author": "dandelionseeds_", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ge3w5/does_wayback_machine_work_as_per_recent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ge3w5/does_wayback_machine_work_as_per_recent/", "subreddit_subscribers": 708642, "created_utc": 1698265364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For the last few years I have been downloading artwork. Mostly oil paintings from museum collections, Japanese Woodblock Prints, and 70s-90s pulp scifi/fantasy illustrations. \n\nI use them for a desktop background slideshow and inspiration in my own projects.\n\nI was thinking though, what all could I use this collection for? \n\nObviously I can upload the collection which I will do once I organize all the files but what else? \n\nI imagine there might be some interesting things I can do using image related AI but I know very little about that world other than using a few free text prompt image generators. Open to non-ai related suggestions as well. ", "author_fullname": "t2_bb7bm04g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interesting uses for digital art collection?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g693l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698244573.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For the last few years I have been downloading artwork. Mostly oil paintings from museum collections, Japanese Woodblock Prints, and 70s-90s pulp scifi/fantasy illustrations. &lt;/p&gt;\n\n&lt;p&gt;I use them for a desktop background slideshow and inspiration in my own projects.&lt;/p&gt;\n\n&lt;p&gt;I was thinking though, what all could I use this collection for? &lt;/p&gt;\n\n&lt;p&gt;Obviously I can upload the collection which I will do once I organize all the files but what else? &lt;/p&gt;\n\n&lt;p&gt;I imagine there might be some interesting things I can do using image related AI but I know very little about that world other than using a few free text prompt image generators. Open to non-ai related suggestions as well. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "11TB of nonsense", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17g693l", "is_robot_indexable": true, "report_reasons": null, "author": "TrashVHS", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17g693l/interesting_uses_for_digital_art_collection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17g693l/interesting_uses_for_digital_art_collection/", "subreddit_subscribers": 708642, "created_utc": 1698244573.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}