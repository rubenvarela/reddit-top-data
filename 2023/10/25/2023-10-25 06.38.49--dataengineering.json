{"kind": "Listing", "data": {"after": "t3_17fg0p8", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pulling back the charade for a moment here... as a vendor, I really empathize with all the DEs in the thread trying to sort through the noise.\n\nI'm not sure if it is the vast amount of VC funding that came into the space, the potential level of nuance to every pipeline, or something else (act of god?)... but it is borderline unimaginable how many new/different vendors exist for creating data pipelines.\n\nJust taking a basic example, googling say Postgres to Snowflake will quite literally yield hundreds of distinct possible vendors. I scrolled so long waiting for repeat vendor domains that I actually got bored and stopped. And this is just revealing all the companies that have put in the effort to try and hack Google SEO results (stitch even bought hundreds of domains of [https://postgres.tosnowflake.com/](https://postgres.tosnowflake.com/) \\-- IMHO: Google Search for B2B is increasingly a failed product for surfacing quality products/content... but I digress.)\n\nAdd in all the open-source, native tooling, or code-based ways to create a pipeline... and I think there might literally be 200+ legit ways to ETL from Postgres to Snowflake.\n\nHow is there possibly \\*SO\\* many solutions? Is massive consolidation of point-to-point ETL tools coming immediately?\n\nWhile I think what we do is somewhat unique ([estuary.dev](https://estuary.dev)), there is still a ton of overlap, and to my partially trained eye.... it feels like Rivery/Fivetran/Hevo/DMS/Stitch/Talend --- just all basically the exact same 'sometimes good enough' solution w/ up to 99% the same features\n\nEND RANT\n\n&amp;#x200B;", "author_fullname": "t2_sa3mbz4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "vendor confession: there's just too many ETL/ELT tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fgte6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698174129.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698164775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pulling back the charade for a moment here... as a vendor, I really empathize with all the DEs in the thread trying to sort through the noise.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if it is the vast amount of VC funding that came into the space, the potential level of nuance to every pipeline, or something else (act of god?)... but it is borderline unimaginable how many new/different vendors exist for creating data pipelines.&lt;/p&gt;\n\n&lt;p&gt;Just taking a basic example, googling say Postgres to Snowflake will quite literally yield hundreds of distinct possible vendors. I scrolled so long waiting for repeat vendor domains that I actually got bored and stopped. And this is just revealing all the companies that have put in the effort to try and hack Google SEO results (stitch even bought hundreds of domains of &lt;a href=\"https://postgres.tosnowflake.com/\"&gt;https://postgres.tosnowflake.com/&lt;/a&gt; -- IMHO: Google Search for B2B is increasingly a failed product for surfacing quality products/content... but I digress.)&lt;/p&gt;\n\n&lt;p&gt;Add in all the open-source, native tooling, or code-based ways to create a pipeline... and I think there might literally be 200+ legit ways to ETL from Postgres to Snowflake.&lt;/p&gt;\n\n&lt;p&gt;How is there possibly *SO* many solutions? Is massive consolidation of point-to-point ETL tools coming immediately?&lt;/p&gt;\n\n&lt;p&gt;While I think what we do is somewhat unique (&lt;a href=\"https://estuary.dev\"&gt;estuary.dev&lt;/a&gt;), there is still a ton of overlap, and to my partially trained eye.... it feels like Rivery/Fivetran/Hevo/DMS/Stitch/Talend --- just all basically the exact same &amp;#39;sometimes good enough&amp;#39; solution w/ up to 99% the same features&lt;/p&gt;\n\n&lt;p&gt;END RANT&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fgte6", "is_robot_indexable": true, "report_reasons": null, "author": "MooJerseyCreamery", "discussion_type": null, "num_comments": 32, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fgte6/vendor_confession_theres_just_too_many_etlelt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fgte6/vendor_confession_theres_just_too_many_etlelt/", "subreddit_subscribers": 135812, "created_utc": 1698164775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What made you get into data engineering and what is keeping you as one? I recently started self learning to become one but i\u2019m sure learning about data engineering is much different than actually being an engineer. Thanks", "author_fullname": "t2_2r5n0ce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To my data engineers: why do you like working as a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fr8d5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698191519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What made you get into data engineering and what is keeping you as one? I recently started self learning to become one but i\u2019m sure learning about data engineering is much different than actually being an engineer. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fr8d5", "is_robot_indexable": true, "report_reasons": null, "author": "naq98", "discussion_type": null, "num_comments": 63, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fr8d5/to_my_data_engineers_why_do_you_like_working_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fr8d5/to_my_data_engineers_why_do_you_like_working_as_a/", "subreddit_subscribers": 135812, "created_utc": 1698191519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pandas is a fantastic library for reading datasets on the go and performing daily data analysis tasks. However, is it advisable to use it in our Python production code?", "author_fullname": "t2_thjew3z6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should, a data engineer, uses Pandas in his production code?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 56, "top_awarded_type": null, "hide_score": false, "name": "t3_17f8xjx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.66, "author_flair_background_color": null, "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zhFEG8gMqYsGt5ayuiDID0lG830Z_9wJOWor8VEfAbo.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698140631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pandas is a fantastic library for reading datasets on the go and performing daily data analysis tasks. However, is it advisable to use it in our Python production code?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ka02hx4yf4wb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ka02hx4yf4wb1.jpg?auto=webp&amp;s=ee31c2efe3f8142ee0424e99c32174815efd2afb", "width": 352, "height": 143}, "resolutions": [{"url": "https://preview.redd.it/ka02hx4yf4wb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=17fbc3bc4ca58a1c4e0408104719c801a4d0833b", "width": 108, "height": 43}, {"url": "https://preview.redd.it/ka02hx4yf4wb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=11d535ed2c854ab9399bdc659fd600380dfc994e", "width": 216, "height": 87}, {"url": "https://preview.redd.it/ka02hx4yf4wb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=86e812dd9c71607f6a50a68ea8be9e616d9139f5", "width": 320, "height": 130}], "variants": {}, "id": "VEho78jGdiwibgJDgFfs2YXZdAGd0CAh4SxYqT363h4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17f8xjx", "is_robot_indexable": true, "report_reasons": null, "author": "Lower_Platform_4190", "discussion_type": null, "num_comments": 75, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17f8xjx/should_a_data_engineer_uses_pandas_in_his/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ka02hx4yf4wb1.jpg", "subreddit_subscribers": 135812, "created_utc": 1698140631.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I currently have experience working with Informatica as an ETL tool but want to switch to big data technologies. I have started learning different tools in hadoop ecosystem but there are so many of them for different purposes. I am confused on which one's to learn in depth.\nLooking at job openings I have seen Spark, Hive, Sqoop,   Kafka, Spark streaming, etc. being used more.\nBut what about other tools like Flume, Storm, Hue, Hbase, and many more. Should I completely skip them?\n\nOr\n\nPlease give me a list of big data tools to learn that will help me switch to big data roles. I dont want to waste time learning tools like Dril, phoenix which no one uses as far as I have seen.", "author_fullname": "t2_ht9x5dmh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "So many tools to learn!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17f6vkz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698131406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I currently have experience working with Informatica as an ETL tool but want to switch to big data technologies. I have started learning different tools in hadoop ecosystem but there are so many of them for different purposes. I am confused on which one&amp;#39;s to learn in depth.\nLooking at job openings I have seen Spark, Hive, Sqoop,   Kafka, Spark streaming, etc. being used more.\nBut what about other tools like Flume, Storm, Hue, Hbase, and many more. Should I completely skip them?&lt;/p&gt;\n\n&lt;p&gt;Or&lt;/p&gt;\n\n&lt;p&gt;Please give me a list of big data tools to learn that will help me switch to big data roles. I dont want to waste time learning tools like Dril, phoenix which no one uses as far as I have seen.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17f6vkz", "is_robot_indexable": true, "report_reasons": null, "author": "kaachejl", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17f6vkz/so_many_tools_to_learn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17f6vkz/so_many_tools_to_learn/", "subreddit_subscribers": 135812, "created_utc": 1698131406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Senior DE role, I've got this assignment.     \n\nBeen told it would take a couple of hours.    \n\nAssignment says(not the exact one, but similar):\n\n    Using an API(has streaming functionality), \n    stream data\n    model a data lake  \n    store the results in the data lake.\n    apply transformation for different layers.\n    store in a private github\n    \n    to consider: data quality, readability, maintaiabality of the code\n\nFrom experience, in an environment that works and all is prepared for development, creating a solution would take easily a day or two, depending on all the unforeseen complications that could come up, even more.    \n\nSetting it all up locally or applying for free tiers from the cloud providers would introduce a lot more time.     \n\nNot sure what I want to get posting this, just wanted to share my frustration. ", "author_fullname": "t2_mghwsvvb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think of this take home assignment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17flj6n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698176891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Senior DE role, I&amp;#39;ve got this assignment.     &lt;/p&gt;\n\n&lt;p&gt;Been told it would take a couple of hours.    &lt;/p&gt;\n\n&lt;p&gt;Assignment says(not the exact one, but similar):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Using an API(has streaming functionality), \nstream data\nmodel a data lake  \nstore the results in the data lake.\napply transformation for different layers.\nstore in a private github\n\nto consider: data quality, readability, maintaiabality of the code\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;From experience, in an environment that works and all is prepared for development, creating a solution would take easily a day or two, depending on all the unforeseen complications that could come up, even more.    &lt;/p&gt;\n\n&lt;p&gt;Setting it all up locally or applying for free tiers from the cloud providers would introduce a lot more time.     &lt;/p&gt;\n\n&lt;p&gt;Not sure what I want to get posting this, just wanted to share my frustration. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17flj6n", "is_robot_indexable": true, "report_reasons": null, "author": "No_Cancel_3754", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17flj6n/what_do_you_think_of_this_take_home_assignment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17flj6n/what_do_you_think_of_this_take_home_assignment/", "subreddit_subscribers": 135812, "created_utc": 1698176891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, I\u2019m currently an ETL developer and looking to prep myself up so that I can get into FAANG as a DE. Tools I currently use are SQL and Azure services. Can someone help me visualize the necessary tools I should have under my belt to get into FAANG ?", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL developer to FAANG DE: map?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ffhfw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698161297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I\u2019m currently an ETL developer and looking to prep myself up so that I can get into FAANG as a DE. Tools I currently use are SQL and Azure services. Can someone help me visualize the necessary tools I should have under my belt to get into FAANG ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17ffhfw", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ffhfw/etl_developer_to_faang_de_map/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ffhfw/etl_developer_to_faang_de_map/", "subreddit_subscribers": 135812, "created_utc": 1698161297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What\u2019s a good intermediate to advanced source that discusses data platform architectures? What works can what doesn\u2019t. When to use what and when. How are different technologies different. Real-time vs batch. Airflow and lake house vs dbt. Lake house vs data warehouse etc. \n\nBut not just a simple comparison, more of a detailed discussion of compete platform setups and comparing different ones. \n\nDoes this even exist?", "author_fullname": "t2_g7w5zhnv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Platform Architectures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fv5m1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698203097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What\u2019s a good intermediate to advanced source that discusses data platform architectures? What works can what doesn\u2019t. When to use what and when. How are different technologies different. Real-time vs batch. Airflow and lake house vs dbt. Lake house vs data warehouse etc. &lt;/p&gt;\n\n&lt;p&gt;But not just a simple comparison, more of a detailed discussion of compete platform setups and comparing different ones. &lt;/p&gt;\n\n&lt;p&gt;Does this even exist?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fv5m1", "is_robot_indexable": true, "report_reasons": null, "author": "long_spy200", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fv5m1/data_platform_architectures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fv5m1/data_platform_architectures/", "subreddit_subscribers": 135812, "created_utc": 1698203097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_io93l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Announcing v0.15: Interactive Declarative Migrations, Functions, Procedures and Domains", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_17fakcd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/nhBgVCSkn43mEZZuegXT044GK2frFJgTtRt1LS1YMJ4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698147009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "atlasgo.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://atlasgo.io/blog/2023/10/19/atlas-v-0-15", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/DDCXetSpUIFJ4t6xJYeeQ91De5Yug6Hw5xzosDHz7zU.jpg?auto=webp&amp;s=1414e9580f0d5089f4769ab2f2dcf09a48ef0eab", "width": 2400, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/DDCXetSpUIFJ4t6xJYeeQ91De5Yug6Hw5xzosDHz7zU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3f75cc7278b4601814b4fe2ac8c6d401e3d76a85", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/DDCXetSpUIFJ4t6xJYeeQ91De5Yug6Hw5xzosDHz7zU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a195df6f7b63ccc0ed1fc2acd6ff54e5892a64e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/DDCXetSpUIFJ4t6xJYeeQ91De5Yug6Hw5xzosDHz7zU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a24f0728b182efec43a4f4bcce3bba439970957b", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/DDCXetSpUIFJ4t6xJYeeQ91De5Yug6Hw5xzosDHz7zU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b72d2ebcc090ddfdb55d337b468a87ea00c6d0ef", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/DDCXetSpUIFJ4t6xJYeeQ91De5Yug6Hw5xzosDHz7zU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7a78605ab50cea5dc4a89f243953163ce50015b2", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/DDCXetSpUIFJ4t6xJYeeQ91De5Yug6Hw5xzosDHz7zU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b7452ef2bb59607883b5a2f7c165be3a43579b90", "width": 1080, "height": 567}], "variants": {}, "id": "YeWm-cV5fn_dffXIIXchwIx5O5_ErL1r2-7yIlehqe8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17fakcd", "is_robot_indexable": true, "report_reasons": null, "author": "rotemtam", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fakcd/announcing_v015_interactive_declarative/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://atlasgo.io/blog/2023/10/19/atlas-v-0-15", "subreddit_subscribers": 135812, "created_utc": 1698147009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Leetcode / hackerran don\u2019t have extensive problems related to the above and I would like more practice problems. I asked chatgpt to make up some but any idea on how to get more discrete practice questions like the above (ie a question that is ultimately reduced to - recursively loop through a python dictionary to get a result or transform it )", "author_fullname": "t2_32eyna18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On DE interviews I am seeing a fair bit of questions related to transforming / aggregating json (essentially dictionary) data in python via standard library - but no online resources to practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fpd4q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698186439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Leetcode / hackerran don\u2019t have extensive problems related to the above and I would like more practice problems. I asked chatgpt to make up some but any idea on how to get more discrete practice questions like the above (ie a question that is ultimately reduced to - recursively loop through a python dictionary to get a result or transform it )&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fpd4q", "is_robot_indexable": true, "report_reasons": null, "author": "acceptedcitizen", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fpd4q/on_de_interviews_i_am_seeing_a_fair_bit_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fpd4q/on_de_interviews_i_am_seeing_a_fair_bit_of/", "subreddit_subscribers": 135812, "created_utc": 1698186439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks\n\n  \nwe at dlthub added a very cool feature for copying production databases. By using ConnectorX and arrow, the sql -&gt; analytics copying can go up to 30x faster over the classic sqlite connector.\n\nRead about the benchmark comparison and the underlying technology here: [https://dlthub.com/docs/blog/dlt-arrow-loading](https://dlthub.com/docs/blog/dlt-arrow-loading) \n\nOne disclaimer is that since this method does not do row by row processing, we cannot microbatch the data through small buffers - so pay attention to the memory size on your extraction machine.  \nCode example how to use: [https://dlthub.com/docs/examples/connector\\_x\\_arrow/](https://dlthub.com/docs/examples/connector_x_arrow/)\n\nBy adding this support, we also enable these sources:  \n[https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas](https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas)  \n\n\nIf you need help, don't miss the gpt helper link at the bottom of our docs or the slack link at the top.\n\nFeedback is very welcome!\n\n&amp;#x200B;", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Get 30x speedups when reading databases with ConnectorX + Arrow + dlt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17f9arc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698142214.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks&lt;/p&gt;\n\n&lt;p&gt;we at dlthub added a very cool feature for copying production databases. By using ConnectorX and arrow, the sql -&amp;gt; analytics copying can go up to 30x faster over the classic sqlite connector.&lt;/p&gt;\n\n&lt;p&gt;Read about the benchmark comparison and the underlying technology here: &lt;a href=\"https://dlthub.com/docs/blog/dlt-arrow-loading\"&gt;https://dlthub.com/docs/blog/dlt-arrow-loading&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;One disclaimer is that since this method does not do row by row processing, we cannot microbatch the data through small buffers - so pay attention to the memory size on your extraction machine.&lt;br/&gt;\nCode example how to use: &lt;a href=\"https://dlthub.com/docs/examples/connector_x_arrow/\"&gt;https://dlthub.com/docs/examples/connector_x_arrow/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;By adding this support, we also enable these sources:&lt;br/&gt;\n&lt;a href=\"https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas\"&gt;https://dlthub.com/docs/dlt-ecosystem/verified-sources/arrow-pandas&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;If you need help, don&amp;#39;t miss the gpt helper link at the bottom of our docs or the slack link at the top.&lt;/p&gt;\n\n&lt;p&gt;Feedback is very welcome!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xDEk8_PXnpPC-6ge-45ltq0lViLX2u1w65DKMVA5FfA.jpg?auto=webp&amp;s=84b3e18f109f221a97f70a438603578a4cc30a30", "width": 1309, "height": 517}, "resolutions": [{"url": "https://external-preview.redd.it/xDEk8_PXnpPC-6ge-45ltq0lViLX2u1w65DKMVA5FfA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=07f5c414d1f377a0af62579d1879c251208a002d", "width": 108, "height": 42}, {"url": "https://external-preview.redd.it/xDEk8_PXnpPC-6ge-45ltq0lViLX2u1w65DKMVA5FfA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=0d366d379f340396f585011f76db6b5167876c8a", "width": 216, "height": 85}, {"url": "https://external-preview.redd.it/xDEk8_PXnpPC-6ge-45ltq0lViLX2u1w65DKMVA5FfA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=612a47aa4d36d7cbabd424857fa08ac068b5b251", "width": 320, "height": 126}, {"url": "https://external-preview.redd.it/xDEk8_PXnpPC-6ge-45ltq0lViLX2u1w65DKMVA5FfA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f9200099e81460a0137696884981d75dbcc7128", "width": 640, "height": 252}, {"url": "https://external-preview.redd.it/xDEk8_PXnpPC-6ge-45ltq0lViLX2u1w65DKMVA5FfA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f143bf5100e86da625d4b5c285d27a2019c5b024", "width": 960, "height": 379}, {"url": "https://external-preview.redd.it/xDEk8_PXnpPC-6ge-45ltq0lViLX2u1w65DKMVA5FfA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c7786c8602fd15012d8b83199f5529b88efbaee6", "width": 1080, "height": 426}], "variants": {}, "id": "RpQ31g0wFMUU1Y9Q5xC9JZd4FCRb2QH7tpQk_FkDslM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17f9arc", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17f9arc/get_30x_speedups_when_reading_databases_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17f9arc/get_30x_speedups_when_reading_databases_with/", "subreddit_subscribers": 135812, "created_utc": 1698142214.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Learning DBT (with Oracle\u2026 and maybe that\u2019s the root of my troubles) \u2026 am I missing something\u2026 I have a model materializing as a view, run it, created a view in the DB\u2026 and if I add a column to it, I get an error and have to log in to the DB and manually drop the view so DBT can materialize it again with my added column. Makes me wonder if it\u2019s a weakness of the Oracle adapter. Coming from a place of doing this type of stuff in SQL Developer where the VIEW code is \u201cCreate or Replace\u201d, and any change can just be recompiled, DBT View materialization seems like a one-time DBT-only functionality. What am I missing here. Full refresh doesn\u2019t work. Why the heck does this work better with materialized tables and not views?", "author_fullname": "t2_f1kbimm96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT manually drop VIEWs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17f7dsu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698134091.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698133620.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Learning DBT (with Oracle\u2026 and maybe that\u2019s the root of my troubles) \u2026 am I missing something\u2026 I have a model materializing as a view, run it, created a view in the DB\u2026 and if I add a column to it, I get an error and have to log in to the DB and manually drop the view so DBT can materialize it again with my added column. Makes me wonder if it\u2019s a weakness of the Oracle adapter. Coming from a place of doing this type of stuff in SQL Developer where the VIEW code is \u201cCreate or Replace\u201d, and any change can just be recompiled, DBT View materialization seems like a one-time DBT-only functionality. What am I missing here. Full refresh doesn\u2019t work. Why the heck does this work better with materialized tables and not views?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17f7dsu", "is_robot_indexable": true, "report_reasons": null, "author": "No-Database2068", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17f7dsu/dbt_manually_drop_views/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17f7dsu/dbt_manually_drop_views/", "subreddit_subscribers": 135812, "created_utc": 1698133620.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a bunch of real estate data from multiple counties. Of course, all of them use a different format, with different columns, etc...\n\nI'm applying some cleaning steps and reformatting so all counties have identical data formats. Then, I'm using the generated parquet files to create an OLAP database or maybe just use DuckDB.\n\nIt's mostly a one-time thing, so I started just going through each manually with a notebook. However, we may have to run it a few times.\n\nSo I am working on a local Polars data pipeline that I've written myself (basically pipe and filters) where you pass in info about the data and desired transformations.\n\nI'm not really familiar with tools like dagster and dbt- might these be useful instead? Unfortunately, I can't spend too long just learning the tool at the moment.\n\nAny advice is appreciated. Data size is a few GB. Want multiple people to be able to query the end database. I'm the only developer.", "author_fullname": "t2_4axj4apz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I Reinventing the Wheel (local-ish Polars data pipeline)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fusbl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698201947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bunch of real estate data from multiple counties. Of course, all of them use a different format, with different columns, etc...&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m applying some cleaning steps and reformatting so all counties have identical data formats. Then, I&amp;#39;m using the generated parquet files to create an OLAP database or maybe just use DuckDB.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s mostly a one-time thing, so I started just going through each manually with a notebook. However, we may have to run it a few times.&lt;/p&gt;\n\n&lt;p&gt;So I am working on a local Polars data pipeline that I&amp;#39;ve written myself (basically pipe and filters) where you pass in info about the data and desired transformations.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not really familiar with tools like dagster and dbt- might these be useful instead? Unfortunately, I can&amp;#39;t spend too long just learning the tool at the moment.&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated. Data size is a few GB. Want multiple people to be able to query the end database. I&amp;#39;m the only developer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17fusbl", "is_robot_indexable": true, "report_reasons": null, "author": "waytoopunkrock", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fusbl/am_i_reinventing_the_wheel_localish_polars_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fusbl/am_i_reinventing_the_wheel_localish_polars_data/", "subreddit_subscribers": 135812, "created_utc": 1698201947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to use the output of a query from big query in a query for an internal server. Is this at all possible with snaplogic?", "author_fullname": "t2_wr2c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snaplogic question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17flk2t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698176956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to use the output of a query from big query in a query for an internal server. Is this at all possible with snaplogic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17flk2t", "is_robot_indexable": true, "report_reasons": null, "author": "blud97", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17flk2t/snaplogic_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17flk2t/snaplogic_question/", "subreddit_subscribers": 135812, "created_utc": 1698176956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Say you use the payment date instead of the booking date. It will likely impact all the reports.\n\nThis kind of update is not that frequent, but how do you share a definition update ? A slack message ? An internal data newsletter ?\n\nI've talked with team that have a Notion page dedicated to this, with basic info like when it happened, who is the owner, what's the impact on the metric. And I have started [implementing it for my users](https://app.data-drift.io/drift-overview) mostly as an exploration (because in the end users want to see it in notion, not a new tool).\n\nWhat would you add to the update report ?\n\nOr, on the other way, do you never update a metric because of all the question it will raise ? ", "author_fullname": "t2_10uv2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Remodeling: when you update a metric definition, how do you communicate to your data consumers ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fd05d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698154590.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Say you use the payment date instead of the booking date. It will likely impact all the reports.&lt;/p&gt;\n\n&lt;p&gt;This kind of update is not that frequent, but how do you share a definition update ? A slack message ? An internal data newsletter ?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve talked with team that have a Notion page dedicated to this, with basic info like when it happened, who is the owner, what&amp;#39;s the impact on the metric. And I have started &lt;a href=\"https://app.data-drift.io/drift-overview\"&gt;implementing it for my users&lt;/a&gt; mostly as an exploration (because in the end users want to see it in notion, not a new tool).&lt;/p&gt;\n\n&lt;p&gt;What would you add to the update report ?&lt;/p&gt;\n\n&lt;p&gt;Or, on the other way, do you never update a metric because of all the question it will raise ? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fd05d", "is_robot_indexable": true, "report_reasons": null, "author": "Srammmy", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fd05d/remodeling_when_you_update_a_metric_definition/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fd05d/remodeling_when_you_update_a_metric_definition/", "subreddit_subscribers": 135812, "created_utc": 1698154590.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mxj2oz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database Backups and Disaster Recovery in PostgreSQL: Your Questions, Answered", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17ffcnu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/G_qJt4NDflLNlCGHHewhB1ViJl99-2oWBrx8eQK4iKU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698160953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "timescale.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.timescale.com/blog/database-backups-and-disaster-recovery-in-postgresql-your-questions-answered/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?auto=webp&amp;s=e0884e335526c884d524e7361055c600d01d7697", "width": 1099, "height": 615}, "resolutions": [{"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b0ca673870c0e201d58002cbfb96dd7da30a86a4", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6771ed607ac2448d4949f0bff69f8d6740beccfc", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fcd9cb51df0bfebe036aeb76af7227a3417a7a58", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3cdf55919640c238209b9657c66a9fee86be286a", "width": 640, "height": 358}, {"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2afc0d1180fb440817b20bd6957cae9a1264dc2a", "width": 960, "height": 537}, {"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7718034ac5a9bf775fa0f63e25b4469349e62c19", "width": 1080, "height": 604}], "variants": {}, "id": "cxqY9Qyo2mXSm20uQIaBfbnuBosNZob1dhXp9w_HwgA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17ffcnu", "is_robot_indexable": true, "report_reasons": null, "author": "carlotasoto", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ffcnu/database_backups_and_disaster_recovery_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.timescale.com/blog/database-backups-and-disaster-recovery-in-postgresql-your-questions-answered/", "subreddit_subscribers": 135812, "created_utc": 1698160953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey DE folks, I've been diving deep into data engineering in the fintech industry and found it challenging to manage the external data sources. Fintech relies on tons of vendor data *(KYC, KYB, Buearue, Risk &amp; Fraud, Lending, etc.)* for making important decisions such as risk assessment, fraud detection, onboarding, and transaction processing.\n\nThe current data ingestion platforms like Fivetran and Airbyte don't cover fintech-specific data sources. *(e.g. Socure, Sentilink, Equifax, Ekata, etc.)* On the other hand, fintech aggregators like Alloy primarily focus on data aggregation rather than data ingestion.\n\nI would love to know how are you currently tackling the challenge of integrating external fintech data sources into your systems. Are there any specialized tools or strategies you've found particularly effective?", "author_fullname": "t2_lk8c99fy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing External Data Sources in Fintech", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17fxwgi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698212972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey DE folks, I&amp;#39;ve been diving deep into data engineering in the fintech industry and found it challenging to manage the external data sources. Fintech relies on tons of vendor data &lt;em&gt;(KYC, KYB, Buearue, Risk &amp;amp; Fraud, Lending, etc.)&lt;/em&gt; for making important decisions such as risk assessment, fraud detection, onboarding, and transaction processing.&lt;/p&gt;\n\n&lt;p&gt;The current data ingestion platforms like Fivetran and Airbyte don&amp;#39;t cover fintech-specific data sources. &lt;em&gt;(e.g. Socure, Sentilink, Equifax, Ekata, etc.)&lt;/em&gt; On the other hand, fintech aggregators like Alloy primarily focus on data aggregation rather than data ingestion.&lt;/p&gt;\n\n&lt;p&gt;I would love to know how are you currently tackling the challenge of integrating external fintech data sources into your systems. Are there any specialized tools or strategies you&amp;#39;ve found particularly effective?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17fxwgi", "is_robot_indexable": true, "report_reasons": null, "author": "utsavshah17", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fxwgi/managing_external_data_sources_in_fintech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fxwgi/managing_external_data_sources_in_fintech/", "subreddit_subscribers": 135812, "created_utc": 1698212972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I have implemented Fivetran for extracting and loading data into a MySQL database. I have noticed that for every connector I build Fivetran generates a new database in the server. Is this consistent across all destinations or just MySQL? I\u2019ve found this to be extremely annoying.", "author_fullname": "t2_6y1og8oq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Fivetran creates a database for every connector", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17fx3jd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698209797.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I have implemented Fivetran for extracting and loading data into a MySQL database. I have noticed that for every connector I build Fivetran generates a new database in the server. Is this consistent across all destinations or just MySQL? I\u2019ve found this to be extremely annoying.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17fx3jd", "is_robot_indexable": true, "report_reasons": null, "author": "Professional-Ninja70", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fx3jd/fivetran_creates_a_database_for_every_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fx3jd/fivetran_creates_a_database_for_every_connector/", "subreddit_subscribers": 135812, "created_utc": 1698209797.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Everyone, \n\nI have this particular use case where we\u2019ve prepared a ML Model python code which we need to deploy of GCP. What would be the best approach since we can\u2019t afford to have any timeout errors. Time being on temporary basis we\u2019re using cloud functions. But due to 60 mins limitation for cloud functions we\u2019re looking for other alternatives. \n\nAny suggestions? \n\nThanks.", "author_fullname": "t2_3qc9b4bu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploying ML Model to GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17fx1n2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698209589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Everyone, &lt;/p&gt;\n\n&lt;p&gt;I have this particular use case where we\u2019ve prepared a ML Model python code which we need to deploy of GCP. What would be the best approach since we can\u2019t afford to have any timeout errors. Time being on temporary basis we\u2019re using cloud functions. But due to 60 mins limitation for cloud functions we\u2019re looking for other alternatives. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions? &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17fx1n2", "is_robot_indexable": true, "report_reasons": null, "author": "apache444", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fx1n2/deploying_ml_model_to_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fx1n2/deploying_ml_model_to_gcp/", "subreddit_subscribers": 135812, "created_utc": 1698209589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you recommend any good materials on Google Cloud Dataflow? (Book or a course)", "author_fullname": "t2_51p72ntqu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Dataflow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fljzb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698176949.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you recommend any good materials on Google Cloud Dataflow? (Book or a course)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17fljzb", "is_robot_indexable": true, "report_reasons": null, "author": "pientaa", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fljzb/dataflow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fljzb/dataflow/", "subreddit_subscribers": 135812, "created_utc": 1698176949.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all!\n\nI am relatively new to the space, and am wondering if anybody with current experience in the consulting world would be able to weigh in here. The use case is a data processing system, which will extract retail customer/txn data from a SQL server, clean it, land it in bigquery, and then use DBT on top to model the data into marketing automation profiles. Dagster would be the orchestration engine.\n\nHow much would this realistically cost using a consulting firm? What would be the estimated timeline on a project with this level of dev work?\n\nAny insight is appreciated, thanks!", "author_fullname": "t2_ronx0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pricing out a Bigquery/Dagster/DBT design + build", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fjmyp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "8cf4f390-e787-11ed-81a4-ca7b65282907", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698172068.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all!&lt;/p&gt;\n\n&lt;p&gt;I am relatively new to the space, and am wondering if anybody with current experience in the consulting world would be able to weigh in here. The use case is a data processing system, which will extract retail customer/txn data from a SQL server, clean it, land it in bigquery, and then use DBT on top to model the data into marketing automation profiles. Dagster would be the orchestration engine.&lt;/p&gt;\n\n&lt;p&gt;How much would this realistically cost using a consulting firm? What would be the estimated timeline on a project with this level of dev work?&lt;/p&gt;\n\n&lt;p&gt;Any insight is appreciated, thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Lead Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fjmyp", "is_robot_indexable": true, "report_reasons": null, "author": "seanpool3", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17fjmyp/pricing_out_a_bigquerydagsterdbt_design_build/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fjmyp/pricing_out_a_bigquerydagsterdbt_design_build/", "subreddit_subscribers": 135812, "created_utc": 1698172068.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello there!\n\nI've been working on a process to upload data from geopandas to postgis database and I was thinking if there are some other ways to deal with spatial data. \n\nIt's not very common to me, but maybe someone else have some experience working with maps, satellites, idk.\n\nJust for curiosity: have you ever been working with geospatial data? Which tools did you use it?\n\nI'm interested to keep learning about this, maybe someone else is on the same way ", "author_fullname": "t2_15ugpwt0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Better ways to manage geospatial data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fhtoa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698167452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello there!&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working on a process to upload data from geopandas to postgis database and I was thinking if there are some other ways to deal with spatial data. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not very common to me, but maybe someone else have some experience working with maps, satellites, idk.&lt;/p&gt;\n\n&lt;p&gt;Just for curiosity: have you ever been working with geospatial data? Which tools did you use it?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m interested to keep learning about this, maybe someone else is on the same way &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fhtoa", "is_robot_indexable": true, "report_reasons": null, "author": "NachxPeolx", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fhtoa/better_ways_to_manage_geospatial_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fhtoa/better_ways_to_manage_geospatial_data/", "subreddit_subscribers": 135812, "created_utc": 1698167452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Need help with extracting a excel file from share point site which updates as and when the user changes something on the excel file.\nHow tonread this file into qlikview? Any suggestions?", "author_fullname": "t2_udxf1u9n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody using qlikview in this group?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fhn1q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698166974.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Need help with extracting a excel file from share point site which updates as and when the user changes something on the excel file.\nHow tonread this file into qlikview? Any suggestions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17fhn1q", "is_robot_indexable": true, "report_reasons": null, "author": "Legal_Key_7212", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fhn1q/anybody_using_qlikview_in_this_group/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fhn1q/anybody_using_qlikview_in_this_group/", "subreddit_subscribers": 135812, "created_utc": 1698166974.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you track what data products your users actually use and which you can deprecate/stop supporting?", "author_fullname": "t2_12fc4o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data products usage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fhhw3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698166601.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you track what data products your users actually use and which you can deprecate/stop supporting?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fhhw3", "is_robot_indexable": true, "report_reasons": null, "author": "romanzdk", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fhhw3/data_products_usage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fhhw3/data_products_usage/", "subreddit_subscribers": 135812, "created_utc": 1698166601.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I am interested in the pro's and cons of clevertap vs a warehouse (tables from separate databases put together in the same place, star sch\u00e9me, for example redshift, snowflake, bigquery or postgresql). Also interested to know the technical limitations of each if any. For example, *is there something we can't do in clevertap that we can do in a warehouse* ?\nIf you have a strong opinion, please share !\nMany thanks in advance!", "author_fullname": "t2_8kenyeuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Clevertap vs a data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fgqnf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698164807.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698164571.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I am interested in the pro&amp;#39;s and cons of clevertap vs a warehouse (tables from separate databases put together in the same place, star sch\u00e9me, for example redshift, snowflake, bigquery or postgresql). Also interested to know the technical limitations of each if any. For example, &lt;em&gt;is there something we can&amp;#39;t do in clevertap that we can do in a warehouse&lt;/em&gt; ?\nIf you have a strong opinion, please share !\nMany thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Tech Lead", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fgqnf", "is_robot_indexable": true, "report_reasons": null, "author": "btenami", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17fgqnf/clevertap_vs_a_data_warehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fgqnf/clevertap_vs_a_data_warehouse/", "subreddit_subscribers": 135812, "created_utc": 1698164571.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I would like to know what are the scenario based interview questions based on data engineering role on cloud premises especially on AWS that the interviewers might ask.\n\nOne example is: Designing URL shortening cloud infrastructure based on AWS. \n\nIf you know the best answer, the please include the answer with questions as well.\n\nThank you", "author_fullname": "t2_4aji175n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scenario based interview questions that you guys faced during interview? Example: URL shortening", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fg0p8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698162693.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to know what are the scenario based interview questions based on data engineering role on cloud premises especially on AWS that the interviewers might ask.&lt;/p&gt;\n\n&lt;p&gt;One example is: Designing URL shortening cloud infrastructure based on AWS. &lt;/p&gt;\n\n&lt;p&gt;If you know the best answer, the please include the answer with questions as well.&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17fg0p8", "is_robot_indexable": true, "report_reasons": null, "author": "seeker112", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fg0p8/scenario_based_interview_questions_that_you_guys/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fg0p8/scenario_based_interview_questions_that_you_guys/", "subreddit_subscribers": 135812, "created_utc": 1698162693.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}