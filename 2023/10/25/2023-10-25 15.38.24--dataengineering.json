{"kind": "Listing", "data": {"after": "t3_17g3yu4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What made you get into data engineering and what is keeping you as one? I recently started self learning to become one but i\u2019m sure learning about data engineering is much different than actually being an engineer. Thanks", "author_fullname": "t2_2r5n0ce", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To my data engineers: why do you like working as a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fr8d5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 85, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 85, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698191519.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What made you get into data engineering and what is keeping you as one? I recently started self learning to become one but i\u2019m sure learning about data engineering is much different than actually being an engineer. Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fr8d5", "is_robot_indexable": true, "report_reasons": null, "author": "naq98", "discussion_type": null, "num_comments": 102, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fr8d5/to_my_data_engineers_why_do_you_like_working_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fr8d5/to_my_data_engineers_why_do_you_like_working_as_a/", "subreddit_subscribers": 135867, "created_utc": 1698191519.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Pulling back the charade for a moment here... as a vendor, I really empathize with all the DEs in the thread trying to sort through the noise.\n\nI'm not sure if it is the vast amount of VC funding that came into the space, the potential level of nuance to every pipeline, or something else (act of god?)... but it is borderline unimaginable how many new/different vendors exist for creating data pipelines.\n\nJust taking a basic example, googling say Postgres to Snowflake will quite literally yield hundreds of distinct possible vendors. I scrolled so long waiting for repeat vendor domains that I actually got bored and stopped. And this is just revealing all the companies that have put in the effort to try and hack Google SEO results (stitch even bought hundreds of domains of [https://postgres.tosnowflake.com/](https://postgres.tosnowflake.com/) \\-- IMHO: Google Search for B2B is increasingly a failed product for surfacing quality products/content... but I digress.)\n\nAdd in all the open-source, native tooling, or code-based ways to create a pipeline... and I think there might literally be 200+ legit ways to ETL from Postgres to Snowflake.\n\nHow is there possibly \\*SO\\* many solutions? Is massive consolidation of point-to-point ETL tools coming immediately?\n\nWhile I think what we do is somewhat unique ([estuary.dev](https://estuary.dev)), there is still a ton of overlap, and to my partially trained eye.... it feels like Rivery/Fivetran/Hevo/DMS/Stitch/Talend --- just all basically the exact same 'sometimes good enough' solution w/ up to 99% the same features\n\nEND RANT\n\n&amp;#x200B;", "author_fullname": "t2_sa3mbz4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "vendor confession: there's just too many ETL/ELT tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fgte6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 80, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 80, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698174129.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698164775.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Pulling back the charade for a moment here... as a vendor, I really empathize with all the DEs in the thread trying to sort through the noise.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure if it is the vast amount of VC funding that came into the space, the potential level of nuance to every pipeline, or something else (act of god?)... but it is borderline unimaginable how many new/different vendors exist for creating data pipelines.&lt;/p&gt;\n\n&lt;p&gt;Just taking a basic example, googling say Postgres to Snowflake will quite literally yield hundreds of distinct possible vendors. I scrolled so long waiting for repeat vendor domains that I actually got bored and stopped. And this is just revealing all the companies that have put in the effort to try and hack Google SEO results (stitch even bought hundreds of domains of &lt;a href=\"https://postgres.tosnowflake.com/\"&gt;https://postgres.tosnowflake.com/&lt;/a&gt; -- IMHO: Google Search for B2B is increasingly a failed product for surfacing quality products/content... but I digress.)&lt;/p&gt;\n\n&lt;p&gt;Add in all the open-source, native tooling, or code-based ways to create a pipeline... and I think there might literally be 200+ legit ways to ETL from Postgres to Snowflake.&lt;/p&gt;\n\n&lt;p&gt;How is there possibly *SO* many solutions? Is massive consolidation of point-to-point ETL tools coming immediately?&lt;/p&gt;\n\n&lt;p&gt;While I think what we do is somewhat unique (&lt;a href=\"https://estuary.dev\"&gt;estuary.dev&lt;/a&gt;), there is still a ton of overlap, and to my partially trained eye.... it feels like Rivery/Fivetran/Hevo/DMS/Stitch/Talend --- just all basically the exact same &amp;#39;sometimes good enough&amp;#39; solution w/ up to 99% the same features&lt;/p&gt;\n\n&lt;p&gt;END RANT&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fgte6", "is_robot_indexable": true, "report_reasons": null, "author": "MooJerseyCreamery", "discussion_type": null, "num_comments": 38, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fgte6/vendor_confession_theres_just_too_many_etlelt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fgte6/vendor_confession_theres_just_too_many_etlelt/", "subreddit_subscribers": 135867, "created_utc": 1698164775.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Senior DE role, I've got this assignment.     \n\nBeen told it would take a couple of hours.    \n\nAssignment says(not the exact one, but similar):\n\n    Using an API(has streaming functionality), \n    stream data\n    model a data lake  \n    store the results in the data lake.\n    apply transformation for different layers.\n    store in a private github\n    \n    to consider: data quality, readability, maintaiabality of the code\n\nFrom experience, in an environment that works and all is prepared for development, creating a solution would take easily a day or two, depending on all the unforeseen complications that could come up, even more.    \n\nSetting it all up locally or applying for free tiers from the cloud providers would introduce a lot more time.     \n\nNot sure what I want to get posting this, just wanted to share my frustration. ", "author_fullname": "t2_mghwsvvb5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do you think of this take home assignment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17flj6n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698176891.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Senior DE role, I&amp;#39;ve got this assignment.     &lt;/p&gt;\n\n&lt;p&gt;Been told it would take a couple of hours.    &lt;/p&gt;\n\n&lt;p&gt;Assignment says(not the exact one, but similar):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;Using an API(has streaming functionality), \nstream data\nmodel a data lake  \nstore the results in the data lake.\napply transformation for different layers.\nstore in a private github\n\nto consider: data quality, readability, maintaiabality of the code\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;From experience, in an environment that works and all is prepared for development, creating a solution would take easily a day or two, depending on all the unforeseen complications that could come up, even more.    &lt;/p&gt;\n\n&lt;p&gt;Setting it all up locally or applying for free tiers from the cloud providers would introduce a lot more time.     &lt;/p&gt;\n\n&lt;p&gt;Not sure what I want to get posting this, just wanted to share my frustration. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17flj6n", "is_robot_indexable": true, "report_reasons": null, "author": "No_Cancel_3754", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17flj6n/what_do_you_think_of_this_take_home_assignment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17flj6n/what_do_you_think_of_this_take_home_assignment/", "subreddit_subscribers": 135867, "created_utc": 1698176891.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello guys, I\u2019m currently an ETL developer and looking to prep myself up so that I can get into FAANG as a DE. Tools I currently use are SQL and Azure services. Can someone help me visualize the necessary tools I should have under my belt to get into FAANG ?", "author_fullname": "t2_n5fep10f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL developer to FAANG DE: map?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ffhfw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698161297.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello guys, I\u2019m currently an ETL developer and looking to prep myself up so that I can get into FAANG as a DE. Tools I currently use are SQL and Azure services. Can someone help me visualize the necessary tools I should have under my belt to get into FAANG ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17ffhfw", "is_robot_indexable": true, "report_reasons": null, "author": "Jealous-Bat-7812", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ffhfw/etl_developer_to_faang_de_map/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ffhfw/etl_developer_to_faang_de_map/", "subreddit_subscribers": 135867, "created_utc": 1698161297.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What\u2019s a good intermediate to advanced source that discusses data platform architectures? What works can what doesn\u2019t. When to use what and when. How are different technologies different. Real-time vs batch. Airflow and lake house vs dbt. Lake house vs data warehouse etc. \n\nBut not just a simple comparison, more of a detailed discussion of compete platform setups and comparing different ones. \n\nDoes this even exist?", "author_fullname": "t2_g7w5zhnv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Platform Architectures", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fv5m1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698203097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What\u2019s a good intermediate to advanced source that discusses data platform architectures? What works can what doesn\u2019t. When to use what and when. How are different technologies different. Real-time vs batch. Airflow and lake house vs dbt. Lake house vs data warehouse etc. &lt;/p&gt;\n\n&lt;p&gt;But not just a simple comparison, more of a detailed discussion of compete platform setups and comparing different ones. &lt;/p&gt;\n\n&lt;p&gt;Does this even exist?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fv5m1", "is_robot_indexable": true, "report_reasons": null, "author": "long_spy200", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fv5m1/data_platform_architectures/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fv5m1/data_platform_architectures/", "subreddit_subscribers": 135867, "created_utc": 1698203097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Leetcode / hackerran don\u2019t have extensive problems related to the above and I would like more practice problems. I asked chatgpt to make up some but any idea on how to get more discrete practice questions like the above (ie a question that is ultimately reduced to - recursively loop through a python dictionary to get a result or transform it )", "author_fullname": "t2_32eyna18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On DE interviews I am seeing a fair bit of questions related to transforming / aggregating json (essentially dictionary) data in python via standard library - but no online resources to practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fpd4q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698186439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Leetcode / hackerran don\u2019t have extensive problems related to the above and I would like more practice problems. I asked chatgpt to make up some but any idea on how to get more discrete practice questions like the above (ie a question that is ultimately reduced to - recursively loop through a python dictionary to get a result or transform it )&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17fpd4q", "is_robot_indexable": true, "report_reasons": null, "author": "acceptedcitizen", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fpd4q/on_de_interviews_i_am_seeing_a_fair_bit_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fpd4q/on_de_interviews_i_am_seeing_a_fair_bit_of/", "subreddit_subscribers": 135867, "created_utc": 1698186439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks, we are developing a managed Airflow service at DoubleCloud and have a few hypotheses that I want to validate. We are seeking additional feedback from users who are already using Airflow in various environments, including self-hosted, MWAA, Astronomer, and possibly Composer (who knows, there might be someone out there).   \n\n\nBelow is a list of hypotheses. Please respond in the comments regarding whether each point holds true for you or not, or feel free to spark a debate:\n\n1. Airflow is primarily used as an orchestrator, not as a worker itself; therefore, the most intensive tasks should be executed outside of the worker nodes. This implies that the worker nodes should be quite small, requiring only hundreds of megabytes of RAM and about 0.25% of CPU maybe capacity.\n2. Utilizing spot instances could significantly reduce costs (by 40-60%) due to the stateless nature of the workers.\n3. Some users still rely on Airflow to run heavy workloads. We hypothesize that these users would require a diverse range of worker sizes, including those with GPU capabilities.\n4. In most scenarios, Airflow orchestrates Docker jobs on EKS, ECS, or Lambda. And to make it beneficial to have a streamlined process for setting up such integrations.\n\np.s  \nAlso if somebody wants to preview our service already just drop me a message or request an access [on our console](https://app.double.cloud/create) we have some gift cards perks and credit grants for those users.", "author_fullname": "t2_ho9zq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow usage hypothesis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17g5crx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698242012.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks, we are developing a managed Airflow service at DoubleCloud and have a few hypotheses that I want to validate. We are seeking additional feedback from users who are already using Airflow in various environments, including self-hosted, MWAA, Astronomer, and possibly Composer (who knows, there might be someone out there).   &lt;/p&gt;\n\n&lt;p&gt;Below is a list of hypotheses. Please respond in the comments regarding whether each point holds true for you or not, or feel free to spark a debate:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Airflow is primarily used as an orchestrator, not as a worker itself; therefore, the most intensive tasks should be executed outside of the worker nodes. This implies that the worker nodes should be quite small, requiring only hundreds of megabytes of RAM and about 0.25% of CPU maybe capacity.&lt;/li&gt;\n&lt;li&gt;Utilizing spot instances could significantly reduce costs (by 40-60%) due to the stateless nature of the workers.&lt;/li&gt;\n&lt;li&gt;Some users still rely on Airflow to run heavy workloads. We hypothesize that these users would require a diverse range of worker sizes, including those with GPU capabilities.&lt;/li&gt;\n&lt;li&gt;In most scenarios, Airflow orchestrates Docker jobs on EKS, ECS, or Lambda. And to make it beneficial to have a streamlined process for setting up such integrations.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;p.s&lt;br/&gt;\nAlso if somebody wants to preview our service already just drop me a message or request an access &lt;a href=\"https://app.double.cloud/create\"&gt;on our console&lt;/a&gt; we have some gift cards perks and credit grants for those users.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17g5crx", "is_robot_indexable": true, "report_reasons": null, "author": "Gaploid", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17g5crx/airflow_usage_hypothesis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17g5crx/airflow_usage_hypothesis/", "subreddit_subscribers": 135867, "created_utc": 1698242012.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a bunch of real estate data from multiple counties. Of course, all of them use a different format, with different columns, etc...\n\nI'm applying some cleaning steps and reformatting so all counties have identical data formats. Then, I'm using the generated parquet files to create an OLAP database or maybe just use DuckDB.\n\nIt's mostly a one-time thing, so I started just going through each manually with a notebook. However, we may have to run it a few times.\n\nSo I am working on a local Polars data pipeline that I've written myself (basically pipe and filters) where you pass in info about the data and desired transformations.\n\nI'm not really familiar with tools like dagster and dbt- might these be useful instead? Unfortunately, I can't spend too long just learning the tool at the moment.\n\nAny advice is appreciated. Data size is a few GB. Want multiple people to be able to query the end database. I'm the only developer.", "author_fullname": "t2_4axj4apz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I Reinventing the Wheel (local-ish Polars data pipeline)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fusbl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698201947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bunch of real estate data from multiple counties. Of course, all of them use a different format, with different columns, etc...&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m applying some cleaning steps and reformatting so all counties have identical data formats. Then, I&amp;#39;m using the generated parquet files to create an OLAP database or maybe just use DuckDB.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s mostly a one-time thing, so I started just going through each manually with a notebook. However, we may have to run it a few times.&lt;/p&gt;\n\n&lt;p&gt;So I am working on a local Polars data pipeline that I&amp;#39;ve written myself (basically pipe and filters) where you pass in info about the data and desired transformations.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not really familiar with tools like dagster and dbt- might these be useful instead? Unfortunately, I can&amp;#39;t spend too long just learning the tool at the moment.&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated. Data size is a few GB. Want multiple people to be able to query the end database. I&amp;#39;m the only developer.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17fusbl", "is_robot_indexable": true, "report_reasons": null, "author": "waytoopunkrock", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fusbl/am_i_reinventing_the_wheel_localish_polars_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fusbl/am_i_reinventing_the_wheel_localish_polars_data/", "subreddit_subscribers": 135867, "created_utc": 1698201947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey DE folks, I've been diving deep into data engineering in the fintech industry and found it challenging to manage the external data sources. Fintech relies on tons of vendor data *(KYC, KYB, Buearue, Risk &amp; Fraud, Lending, etc.)* for making important decisions such as risk assessment, fraud detection, onboarding, and transaction processing.\n\nThe current data ingestion platforms like Fivetran and Airbyte don't cover fintech-specific data sources. *(e.g. Socure, Sentilink, Equifax, Ekata, etc.)* On the other hand, fintech aggregators like Alloy primarily focus on data aggregation rather than data ingestion.\n\nI would love to know how are you currently tackling the challenge of integrating external fintech data sources into your systems. Are there any specialized tools or strategies you've found particularly effective?", "author_fullname": "t2_lk8c99fy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Managing External Data Sources in Fintech", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fxwgi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698212972.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey DE folks, I&amp;#39;ve been diving deep into data engineering in the fintech industry and found it challenging to manage the external data sources. Fintech relies on tons of vendor data &lt;em&gt;(KYC, KYB, Buearue, Risk &amp;amp; Fraud, Lending, etc.)&lt;/em&gt; for making important decisions such as risk assessment, fraud detection, onboarding, and transaction processing.&lt;/p&gt;\n\n&lt;p&gt;The current data ingestion platforms like Fivetran and Airbyte don&amp;#39;t cover fintech-specific data sources. &lt;em&gt;(e.g. Socure, Sentilink, Equifax, Ekata, etc.)&lt;/em&gt; On the other hand, fintech aggregators like Alloy primarily focus on data aggregation rather than data ingestion.&lt;/p&gt;\n\n&lt;p&gt;I would love to know how are you currently tackling the challenge of integrating external fintech data sources into your systems. Are there any specialized tools or strategies you&amp;#39;ve found particularly effective?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17fxwgi", "is_robot_indexable": true, "report_reasons": null, "author": "utsavshah17", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fxwgi/managing_external_data_sources_in_fintech/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fxwgi/managing_external_data_sources_in_fintech/", "subreddit_subscribers": 135867, "created_utc": 1698212972.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Our team has been heavily using Databricks for two years for our engineering, ML, and analytics. Mostly use PySpark for data processing tasks and the SQL editor for querying and we like it. However, the contract costs are higher so we need to explore alternative platforms that could offer a similar level.\n\nMost of the data are stored in AWS S3 and ingested into Databricks for further processing. After some preliminary research, we are considering migrating to a self-managed solution on AWS, potentially leveraging EC2 instances for running PySpark jobs and possibly utilizing AWS EMR for a more managed experience. Our primary goal is to transition to a more cost-effective solution.\n\nGiven the volume of data we handle, we plan to commence this migration journey by testing with a smaller dataset (million rows) to evaluate the performance and compare the cost and cost-efficiency of EC2 and EMR in comparison to Databricks.\n\nWe're leaning towards an open-source approach as much as possible to keep costs in check and I have more questions about this.\n\n1. Have any of you undertaken a similar migration from Databricks to AWS (EC2/EMR)?\n2. Are there any significant challenges, in terms of setup, performance, or cost, that we should anticipate?\n\nWe are in the early stages of this exploration and your suggestions could greatly shape our migration strategy. We appreciate any advice or insights you can provide!\n\nThank you in advance for your time and advice.", "author_fullname": "t2_akunr53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migration from Databricks to EC2/EMR: Seeking Cost-Efficient Open-Source Alternatives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17g64c0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698244206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Our team has been heavily using Databricks for two years for our engineering, ML, and analytics. Mostly use PySpark for data processing tasks and the SQL editor for querying and we like it. However, the contract costs are higher so we need to explore alternative platforms that could offer a similar level.&lt;/p&gt;\n\n&lt;p&gt;Most of the data are stored in AWS S3 and ingested into Databricks for further processing. After some preliminary research, we are considering migrating to a self-managed solution on AWS, potentially leveraging EC2 instances for running PySpark jobs and possibly utilizing AWS EMR for a more managed experience. Our primary goal is to transition to a more cost-effective solution.&lt;/p&gt;\n\n&lt;p&gt;Given the volume of data we handle, we plan to commence this migration journey by testing with a smaller dataset (million rows) to evaluate the performance and compare the cost and cost-efficiency of EC2 and EMR in comparison to Databricks.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re leaning towards an open-source approach as much as possible to keep costs in check and I have more questions about this.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Have any of you undertaken a similar migration from Databricks to AWS (EC2/EMR)?&lt;/li&gt;\n&lt;li&gt;Are there any significant challenges, in terms of setup, performance, or cost, that we should anticipate?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;We are in the early stages of this exploration and your suggestions could greatly shape our migration strategy. We appreciate any advice or insights you can provide!&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance for your time and advice.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17g64c0", "is_robot_indexable": true, "report_reasons": null, "author": "north_pr", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17g64c0/migration_from_databricks_to_ec2emr_seeking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17g64c0/migration_from_databricks_to_ec2emr_seeking/", "subreddit_subscribers": 135867, "created_utc": 1698244206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Check out my latest Airflow video about  DockerOperator: End-to-End Machine Learning Pipeline with Docker Operator!", "author_fullname": "t2_h4j43yry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow DockerOperator: End-to-End Machine Learning Pipeline with Docker Operator", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_17fyyj4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/uZy2Lwioi3g?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow DockerOperator: End-to-End Machine Learning Pipeline with Docker Operator\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Airflow DockerOperator: End-to-End Machine Learning Pipeline with Docker Operator", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/uZy2Lwioi3g?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow DockerOperator: End-to-End Machine Learning Pipeline with Docker Operator\"&gt;&lt;/iframe&gt;", "author_name": "coder2j", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/uZy2Lwioi3g/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@coder2j"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/uZy2Lwioi3g?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow DockerOperator: End-to-End Machine Learning Pipeline with Docker Operator\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/17fyyj4", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/weHe6o4ePXHX6yUyqr5Fblyf2HFIuBoFjMROdYvoppc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698217506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Check out my latest Airflow video about  DockerOperator: End-to-End Machine Learning Pipeline with Docker Operator!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/uZy2Lwioi3g", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Cqk44cGcKpM6ONahoVlsOwjKH50G9fwL7UNl1pvmtQ4.jpg?auto=webp&amp;s=0104b45765142f14b834dd84a27cfc66f29d1c6c", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Cqk44cGcKpM6ONahoVlsOwjKH50G9fwL7UNl1pvmtQ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f0e284f8743e5a16fbeae39c2b2f545b7fdaa0c6", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Cqk44cGcKpM6ONahoVlsOwjKH50G9fwL7UNl1pvmtQ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=08c8e1b16bb828a6ff582b08e476c8008514f5d9", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Cqk44cGcKpM6ONahoVlsOwjKH50G9fwL7UNl1pvmtQ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ec6e6fd26dbd5e8091c2aeba0446896e22d95108", "width": 320, "height": 240}], "variants": {}, "id": "d6dxYUo_UD8-QH3xgWC2t-MJ_7oZM9piSnjGDJl4MRY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17fyyj4", "is_robot_indexable": true, "report_reasons": null, "author": "Coder2j", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fyyj4/airflow_dockeroperator_endtoend_machine_learning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/uZy2Lwioi3g", "subreddit_subscribers": 135867, "created_utc": 1698217506.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Airflow DockerOperator: End-to-End Machine Learning Pipeline with Docker Operator", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/uZy2Lwioi3g?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Airflow DockerOperator: End-to-End Machine Learning Pipeline with Docker Operator\"&gt;&lt;/iframe&gt;", "author_name": "coder2j", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/uZy2Lwioi3g/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@coder2j"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to use the output of a query from big query in a query for an internal server. Is this at all possible with snaplogic?", "author_fullname": "t2_wr2c4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snaplogic question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17flk2t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698176956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to use the output of a query from big query in a query for an internal server. Is this at all possible with snaplogic?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17flk2t", "is_robot_indexable": true, "report_reasons": null, "author": "blud97", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17flk2t/snaplogic_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17flk2t/snaplogic_question/", "subreddit_subscribers": 135867, "created_utc": 1698176956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've been a Data Scientist for a little over 7 years and don't necessarily see myself switching roles, but have recently thought that it would be nice to have the ability to take on some of the data engineering roles. I think it would also make myself more marketable if I could be more of a \"full stack\" DS as well as easier to work with from the perspective of the Data Engineers. \n\nI'm just curious if there are specific languages or environments that I should focus my learning efforts on? At my current company I know we use Kafka for the automated tasks and the data is housed in Snowflake. I've thought of learning Kafka since it's being used at my current role, but want to make sure that isn't somewhat of a wasted effort if I were to switch to a different company? ", "author_fullname": "t2_110aywvd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best Languages to Learn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17g6p2m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698245823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been a Data Scientist for a little over 7 years and don&amp;#39;t necessarily see myself switching roles, but have recently thought that it would be nice to have the ability to take on some of the data engineering roles. I think it would also make myself more marketable if I could be more of a &amp;quot;full stack&amp;quot; DS as well as easier to work with from the perspective of the Data Engineers. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m just curious if there are specific languages or environments that I should focus my learning efforts on? At my current company I know we use Kafka for the automated tasks and the data is housed in Snowflake. I&amp;#39;ve thought of learning Kafka since it&amp;#39;s being used at my current role, but want to make sure that isn&amp;#39;t somewhat of a wasted effort if I were to switch to a different company? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17g6p2m", "is_robot_indexable": true, "report_reasons": null, "author": "lambo630", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17g6p2m/best_languages_to_learn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17g6p2m/best_languages_to_learn/", "subreddit_subscribers": 135867, "created_utc": 1698245823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrating from ClickHouse to Apache Doris: What Happened?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g41pf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1698238319.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "doris.apache.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://doris.apache.org/zh-CN/blog/migrating-from-clickhouse-to-apache-doris-what-happened", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17g41pf", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17g41pf/migrating_from_clickhouse_to_apache_doris_what/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://doris.apache.org/zh-CN/blog/migrating-from-clickhouse-to-apache-doris-what-happened", "subreddit_subscribers": 135867, "created_utc": 1698238319.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New to DBT, looking around the interwebs for some kind of DBT package that lets me define specs for ERDs and displays them in the doc website.  Seems like people having been calling for this for a while, but not seeing any solid package recommendations.  Anybody got one?", "author_fullname": "t2_f1kbimm96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any update to a stable DBT ERD package?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fyf3m", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698215139.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New to DBT, looking around the interwebs for some kind of DBT package that lets me define specs for ERDs and displays them in the doc website.  Seems like people having been calling for this for a while, but not seeing any solid package recommendations.  Anybody got one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17fyf3m", "is_robot_indexable": true, "report_reasons": null, "author": "No-Database2068", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fyf3m/any_update_to_a_stable_dbt_erd_package/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fyf3m/any_update_to_a_stable_dbt_erd_package/", "subreddit_subscribers": 135867, "created_utc": 1698215139.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey Everyone, \n\nI have this particular use case where we\u2019ve prepared a ML Model python code which we need to deploy of GCP. What would be the best approach since we can\u2019t afford to have any timeout errors. Time being on temporary basis we\u2019re using cloud functions. But due to 60 mins limitation for cloud functions we\u2019re looking for other alternatives. \n\nAny suggestions? \n\nThanks.", "author_fullname": "t2_3qc9b4bu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Deploying ML Model to GCP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fx1n2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698209589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Everyone, &lt;/p&gt;\n\n&lt;p&gt;I have this particular use case where we\u2019ve prepared a ML Model python code which we need to deploy of GCP. What would be the best approach since we can\u2019t afford to have any timeout errors. Time being on temporary basis we\u2019re using cloud functions. But due to 60 mins limitation for cloud functions we\u2019re looking for other alternatives. &lt;/p&gt;\n\n&lt;p&gt;Any suggestions? &lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17fx1n2", "is_robot_indexable": true, "report_reasons": null, "author": "apache444", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17fx1n2/deploying_ml_model_to_gcp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17fx1n2/deploying_ml_model_to_gcp/", "subreddit_subscribers": 135867, "created_utc": 1698209589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mxj2oz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database Backups and Disaster Recovery in PostgreSQL: Your Questions, Answered", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17ffcnu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/G_qJt4NDflLNlCGHHewhB1ViJl99-2oWBrx8eQK4iKU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698160953.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "timescale.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.timescale.com/blog/database-backups-and-disaster-recovery-in-postgresql-your-questions-answered/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?auto=webp&amp;s=e0884e335526c884d524e7361055c600d01d7697", "width": 1099, "height": 615}, "resolutions": [{"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b0ca673870c0e201d58002cbfb96dd7da30a86a4", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6771ed607ac2448d4949f0bff69f8d6740beccfc", "width": 216, "height": 120}, {"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=fcd9cb51df0bfebe036aeb76af7227a3417a7a58", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3cdf55919640c238209b9657c66a9fee86be286a", "width": 640, "height": 358}, {"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2afc0d1180fb440817b20bd6957cae9a1264dc2a", "width": 960, "height": 537}, {"url": "https://external-preview.redd.it/qeM5n8uwqOjvAI8twpncx7A0fSnVAUpze9uHtpfAPWs.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7718034ac5a9bf775fa0f63e25b4469349e62c19", "width": 1080, "height": 604}], "variants": {}, "id": "cxqY9Qyo2mXSm20uQIaBfbnuBosNZob1dhXp9w_HwgA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17ffcnu", "is_robot_indexable": true, "report_reasons": null, "author": "carlotasoto", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ffcnu/database_backups_and_disaster_recovery_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.timescale.com/blog/database-backups-and-disaster-recovery-in-postgresql-your-questions-answered/", "subreddit_subscribers": 135867, "created_utc": 1698160953.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Date and DateTime Manipulation in Polars", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17g6ldz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1698245527.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "confessionsofadataguy.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.confessionsofadataguy.com/date-and-datetime-manipulation-in-polar/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17g6ldz", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17g6ldz/date_and_datetime_manipulation_in_polars/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.confessionsofadataguy.com/date-and-datetime-manipulation-in-polar/", "subreddit_subscribers": 135867, "created_utc": 1698245527.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nFor a hobby project, I currently have a pipeline, where each 20 minutes, some JSON files are added to an S3 bucket. I would like to run some analytics on the data in the S3 bucket.\n\nIn the past, I have used a Glue crawler that analyze the schema and add new data (using subfolder partitioning) into a table in AWS Data Catalog. This however costs me over 6$ running hourly for just three days (about 2000 small new files in three days). As this is a hobby project, I would like to keep the costs to a minimum.\n\nI decided that I would update the Athena table manually, after uploading the files to S3, I would invoke  a lambda function to add the data into the Athena table. This should be way more cost-effective. I don't know however if Athena accepts INSERT statements.\n\n**What is the best way to insert new data into Athena manually (using a Python Lambda function for example) ?**", "author_fullname": "t2_nq65wse7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to add data into Athena table without a Glue Crawler ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17g6i51", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698245278.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For a hobby project, I currently have a pipeline, where each 20 minutes, some JSON files are added to an S3 bucket. I would like to run some analytics on the data in the S3 bucket.&lt;/p&gt;\n\n&lt;p&gt;In the past, I have used a Glue crawler that analyze the schema and add new data (using subfolder partitioning) into a table in AWS Data Catalog. This however costs me over 6$ running hourly for just three days (about 2000 small new files in three days). As this is a hobby project, I would like to keep the costs to a minimum.&lt;/p&gt;\n\n&lt;p&gt;I decided that I would update the Athena table manually, after uploading the files to S3, I would invoke  a lambda function to add the data into the Athena table. This should be way more cost-effective. I don&amp;#39;t know however if Athena accepts INSERT statements.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What is the best way to insert new data into Athena manually (using a Python Lambda function for example) ?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17g6i51", "is_robot_indexable": true, "report_reasons": null, "author": "lancelot_of_camelot", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17g6i51/how_to_add_data_into_athena_table_without_a_glue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17g6i51/how_to_add_data_into_athena_table_without_a_glue/", "subreddit_subscribers": 135867, "created_utc": 1698245278.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any recs on tooling? Or an overview on a plausible process?\n\nSay we need to add a new column to an existing table. \n\n- Alter table, add column with a default\n- Re-load all data to correct the new column value to the correct value\n\nOr is something like inserting all values of the single column by matching row IDs/PKs viable. \n\nAnd can anyone confirm - CH doesn't have transactions, so if a migration fails part way through the change won't be rolled back?\n\nThanks for any and all pointers.", "author_fullname": "t2_gua18k7sg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Schema migration for Clickhouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17g6da9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698244900.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any recs on tooling? Or an overview on a plausible process?&lt;/p&gt;\n\n&lt;p&gt;Say we need to add a new column to an existing table. &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Alter table, add column with a default&lt;/li&gt;\n&lt;li&gt;Re-load all data to correct the new column value to the correct value&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Or is something like inserting all values of the single column by matching row IDs/PKs viable. &lt;/p&gt;\n\n&lt;p&gt;And can anyone confirm - CH doesn&amp;#39;t have transactions, so if a migration fails part way through the change won&amp;#39;t be rolled back?&lt;/p&gt;\n\n&lt;p&gt;Thanks for any and all pointers.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17g6da9", "is_robot_indexable": true, "report_reasons": null, "author": "alexcontrerasdppl", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17g6da9/schema_migration_for_clickhouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17g6da9/schema_migration_for_clickhouse/", "subreddit_subscribers": 135867, "created_utc": 1698244900.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI've got a new situation and can't find a lot of documentation about it online. The situation is that I've got json files in a storage container ADLS2. Those files need to be mapped and send to a VM throught a POST. API Documentation is available in our organisation about the VM.   \n\n\nAny idea's what the best approach is? I am familiar with Synapse en ADF. ", "author_fullname": "t2_a209artz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Post json data in Azure storage account to VM via POST", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17g5uru", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698243461.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve got a new situation and can&amp;#39;t find a lot of documentation about it online. The situation is that I&amp;#39;ve got json files in a storage container ADLS2. Those files need to be mapped and send to a VM throught a POST. API Documentation is available in our organisation about the VM.   &lt;/p&gt;\n\n&lt;p&gt;Any idea&amp;#39;s what the best approach is? I am familiar with Synapse en ADF. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17g5uru", "is_robot_indexable": true, "report_reasons": null, "author": "Necessary_Buy1496", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17g5uru/post_json_data_in_azure_storage_account_to_vm_via/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17g5uru/post_json_data_in_azure_storage_account_to_vm_via/", "subreddit_subscribers": 135867, "created_utc": 1698243461.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hello,\n\nI  am currently developing a data architecture which is as follows, the  aim being to retrieve, transform and store data from a .txt file sent by  an FTP server, then display it on grafana :\n\n&amp;#x200B;\n\nhttps://preview.redd.it/9j9ojnwlmcwb1.jpg?width=680&amp;format=pjpg&amp;auto=webp&amp;s=a6a78e04812695800b7c00a55bd49c64c4bb53d4\n\nHere is what i need to host:\n\n* ETL : python script\n* DB  : postgreSQL\n* Grafana\n\nAmount of data received: 3Kb/10 minutes (this sould increase)\n\n**I would like to know what i need to take with AWS to host this data architecture ?**\n\n Thanks in advance, ", "author_fullname": "t2_usmpgy0x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "how to host a data architecture with AWS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 56, "top_awarded_type": null, "hide_score": false, "media_metadata": {"9j9ojnwlmcwb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 43, "x": 108, "u": "https://preview.redd.it/9j9ojnwlmcwb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a2c473a2ad4746572b843e4f6f71ce1caf14eff5"}, {"y": 86, "x": 216, "u": "https://preview.redd.it/9j9ojnwlmcwb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=60e2edf3b6e8a3de178fe36141b934d971a69910"}, {"y": 128, "x": 320, "u": "https://preview.redd.it/9j9ojnwlmcwb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ff42ab4111da1be12b934638cbac87579763bdf0"}, {"y": 256, "x": 640, "u": "https://preview.redd.it/9j9ojnwlmcwb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe5d646100038a1e89254038b83b1cfbea7bd7a4"}], "s": {"y": 272, "x": 680, "u": "https://preview.redd.it/9j9ojnwlmcwb1.jpg?width=680&amp;format=pjpg&amp;auto=webp&amp;s=a6a78e04812695800b7c00a55bd49c64c4bb53d4"}, "id": "9j9ojnwlmcwb1"}}, "name": "t3_17g4lxo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/x9cJ-5NPrPRRp7zalKcAxqPaU5ruLyFVvkz1leCn-j8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698239938.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I  am currently developing a data architecture which is as follows, the  aim being to retrieve, transform and store data from a .txt file sent by  an FTP server, then display it on grafana :&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/9j9ojnwlmcwb1.jpg?width=680&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a6a78e04812695800b7c00a55bd49c64c4bb53d4\"&gt;https://preview.redd.it/9j9ojnwlmcwb1.jpg?width=680&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=a6a78e04812695800b7c00a55bd49c64c4bb53d4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Here is what i need to host:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;ETL : python script&lt;/li&gt;\n&lt;li&gt;DB  : postgreSQL&lt;/li&gt;\n&lt;li&gt;Grafana&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Amount of data received: 3Kb/10 minutes (this sould increase)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I would like to know what i need to take with AWS to host this data architecture ?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance, &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17g4lxo", "is_robot_indexable": true, "report_reasons": null, "author": "SeJikairos", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17g4lxo/how_to_host_a_data_architecture_with_aws/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17g4lxo/how_to_host_a_data_architecture_with_aws/", "subreddit_subscribers": 135867, "created_utc": 1698239938.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI come from a humanities background and have been working as a Data Engineer (DE) for roughly two years. Prior to landing this role, I familiarized myself with Java fundamentals and various big data tools. However, in my current position, my responsibilities revolve mainly around SQL with a bit of SHELL scripting. The internal platforms we use are pre-defined, and most of the data modeling tasks are handled by my supervisor. Lately, I've felt stagnant in my growth.\n\nWhile I understand that obtaining a master's degree may not be essential for everyone in this field, I'm keen on expanding my horizons, experiencing a different educational environment abroad, and possibly exploring other career opportunities.\n\nI'm currently contemplating master's programs in Computer Science, Data Analysis, or Business Analysis. However, I'm open to other fields as well, especially if they lead to well-paying roles with a good work-life balance, even if they are not directly related to data engineering.\n\nI'd appreciate any insights or suggestions on the following:\n\n1. Would a master's in Computer Science significantly benefit someone in a DE role?\n2. Are there other fields or programs you'd recommend considering, based on my aspirations?\n\nThank you in advance for your guidance!", "author_fullname": "t2_ahoq1nhr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice: Is a Master's Degree Necessary for a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g44zd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698238605.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I come from a humanities background and have been working as a Data Engineer (DE) for roughly two years. Prior to landing this role, I familiarized myself with Java fundamentals and various big data tools. However, in my current position, my responsibilities revolve mainly around SQL with a bit of SHELL scripting. The internal platforms we use are pre-defined, and most of the data modeling tasks are handled by my supervisor. Lately, I&amp;#39;ve felt stagnant in my growth.&lt;/p&gt;\n\n&lt;p&gt;While I understand that obtaining a master&amp;#39;s degree may not be essential for everyone in this field, I&amp;#39;m keen on expanding my horizons, experiencing a different educational environment abroad, and possibly exploring other career opportunities.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently contemplating master&amp;#39;s programs in Computer Science, Data Analysis, or Business Analysis. However, I&amp;#39;m open to other fields as well, especially if they lead to well-paying roles with a good work-life balance, even if they are not directly related to data engineering.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d appreciate any insights or suggestions on the following:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Would a master&amp;#39;s in Computer Science significantly benefit someone in a DE role?&lt;/li&gt;\n&lt;li&gt;Are there other fields or programs you&amp;#39;d recommend considering, based on my aspirations?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thank you in advance for your guidance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17g44zd", "is_robot_indexable": true, "report_reasons": null, "author": "Wanderer2333", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17g44zd/seeking_advice_is_a_masters_degree_necessary_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17g44zd/seeking_advice_is_a_masters_degree_necessary_for/", "subreddit_subscribers": 135867, "created_utc": 1698238605.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all.\r  \nThis is my first post here so I\u2019m sorry if I did it in the wrong place. \r  \nI have a question about JUNIOR data engineer/analyst jobs or any enter level data-related jobs. \r  \nI've been trying for some time now to break into the Data field (unsuccessfully)\r  \nThere are not many jobs entry-level and Junior positions and even if I find Junior level there is literally no difference to mid-level except salary, usually salary is for junior-level requirements for mid-level. \ud83d\ude0a .Requirements are quite high \r  \n\r  \nI'm looking for advice because I don't know what I'm doing wrong.\r  \nIs this because of my age (43)?\r  \nIs it my English language - far from perfect but good enough to communicate and learn all courses and pass exams in English? \r  \nor maybe just not enough skills for the Junior level?\r  \n\r  \n\r  \na short description of where I am and what I have done so far.\r  \nI came from Poland to the UK my first job wasn't related to IT jobs as I was focused on money to get a home loan as soon as possible also I came here with basic English. \r  \nIt took some time but as soon as I improved my English enough to learn I started passing exams and looking for jobs, unfortunately, COVID moved my plans. \r  \nIn 2022 I got my first job in IT as - an IT Service Desk Analyst unfortunately I had to learn everything even what I wasn't interested in, like networking, print servers, active directory etc\u2026\r  \nFortunately, the company noticed my interest in data, and I started to get more tickets and tasks related to SSMS, Oracle \r  \nIt was a hard time for me, I had to learn everything that was needed to do my job, and I spent about 2-3 hours a day after work learning SQL as I had remote access to company databases. \r  \nBetween 2019 and 2022 I passed 8 official exams:\r  \n70-761 Querying Data with Transact SQL\r  \nDP-900 Azure Data Fundamentals\r  \nAZ-900 Azure Fundamentals\r  \nAI -900 Azure AI Fundamentals\r  \n98-364 Database Administration Fundamentals   MTA\r  \nCompTIA A+ 220-1002\r  \nCompTIA A+ 220-1001\r  \nSDI \u2013 Service Desk Analyst v8 Certificate\n\nCurrently I'm working as Data Billing Analyst but this work is more related to using scripts already written rather than proper scripting writing \n\nI have dual citizenship and I expanded my search on Poland and Europe, There is a lot of work in this field, but apparently not for me \u2639 \r  \nANY ADVICE WELKOME GUYS \r  \n", "author_fullname": "t2_5xvw5nq2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Junior Data Engineer / Analyst", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17g433x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698238444.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all.&lt;/p&gt;\n\n&lt;p&gt;This is my first post here so I\u2019m sorry if I did it in the wrong place. &lt;/p&gt;\n\n&lt;p&gt;I have a question about JUNIOR data engineer/analyst jobs or any enter level data-related jobs. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been trying for some time now to break into the Data field (unsuccessfully)&lt;/p&gt;\n\n&lt;p&gt;There are not many jobs entry-level and Junior positions and even if I find Junior level there is literally no difference to mid-level except salary, usually salary is for junior-level requirements for mid-level. \ud83d\ude0a .Requirements are quite high &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m looking for advice because I don&amp;#39;t know what I&amp;#39;m doing wrong.&lt;/p&gt;\n\n&lt;p&gt;Is this because of my age (43)?&lt;/p&gt;\n\n&lt;p&gt;Is it my English language - far from perfect but good enough to communicate and learn all courses and pass exams in English? &lt;/p&gt;\n\n&lt;p&gt;or maybe just not enough skills for the Junior level?&lt;/p&gt;\n\n&lt;p&gt;a short description of where I am and what I have done so far.&lt;/p&gt;\n\n&lt;p&gt;I came from Poland to the UK my first job wasn&amp;#39;t related to IT jobs as I was focused on money to get a home loan as soon as possible also I came here with basic English. &lt;/p&gt;\n\n&lt;p&gt;It took some time but as soon as I improved my English enough to learn I started passing exams and looking for jobs, unfortunately, COVID moved my plans. &lt;/p&gt;\n\n&lt;p&gt;In 2022 I got my first job in IT as - an IT Service Desk Analyst unfortunately I had to learn everything even what I wasn&amp;#39;t interested in, like networking, print servers, active directory etc\u2026&lt;/p&gt;\n\n&lt;p&gt;Fortunately, the company noticed my interest in data, and I started to get more tickets and tasks related to SSMS, Oracle &lt;/p&gt;\n\n&lt;p&gt;It was a hard time for me, I had to learn everything that was needed to do my job, and I spent about 2-3 hours a day after work learning SQL as I had remote access to company databases. &lt;/p&gt;\n\n&lt;p&gt;Between 2019 and 2022 I passed 8 official exams:&lt;/p&gt;\n\n&lt;p&gt;70-761 Querying Data with Transact SQL&lt;/p&gt;\n\n&lt;p&gt;DP-900 Azure Data Fundamentals&lt;/p&gt;\n\n&lt;p&gt;AZ-900 Azure Fundamentals&lt;/p&gt;\n\n&lt;p&gt;AI -900 Azure AI Fundamentals&lt;/p&gt;\n\n&lt;p&gt;98-364 Database Administration Fundamentals   MTA&lt;/p&gt;\n\n&lt;p&gt;CompTIA A+ 220-1002&lt;/p&gt;\n\n&lt;p&gt;CompTIA A+ 220-1001&lt;/p&gt;\n\n&lt;p&gt;SDI \u2013 Service Desk Analyst v8 Certificate&lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m working as Data Billing Analyst but this work is more related to using scripts already written rather than proper scripting writing &lt;/p&gt;\n\n&lt;p&gt;I have dual citizenship and I expanded my search on Poland and Europe, There is a lot of work in this field, but apparently not for me \u2639 &lt;/p&gt;\n\n&lt;p&gt;ANY ADVICE WELKOME GUYS &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17g433x", "is_robot_indexable": true, "report_reasons": null, "author": "jacentyy79", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17g433x/junior_data_engineer_analyst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17g433x/junior_data_engineer_analyst/", "subreddit_subscribers": 135867, "created_utc": 1698238444.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview with Aklivity co-founders John and Leonid", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_17g3yu4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/TkrI6vRQqWOXDWb548Ls0mEbuGAG5VugdbGKV7if0Cc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698238066.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/hubertdulay/p/interview-with-aklivity-co-founders?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/yerUQyFLb6mfvhiRssutLlHpls8U-sr7BAXAlJx9tWQ.jpg?auto=webp&amp;s=9fe1615074d7be0f9f21af11297a14d39cfc6df1", "width": 200, "height": 200}, "resolutions": [{"url": "https://external-preview.redd.it/yerUQyFLb6mfvhiRssutLlHpls8U-sr7BAXAlJx9tWQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9e551e74a83750c76eb4837144de0ecb6757c972", "width": 108, "height": 108}], "variants": {}, "id": "ePdtROH2JO9xgyCevR6bjIKl9ESG0kcnHKUU_1aodcY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17g3yu4", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17g3yu4/interview_with_aklivity_cofounders_john_and_leonid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/hubertdulay/p/interview-with-aklivity-co-founders?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 135867, "created_utc": 1698238066.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}