{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm tired of streaming. I already purchase music through [Qobuz](https://www.qobuz.com/us-en/shop) and am going to start purchasing all of the movies/TV I've \"obtained\" over the years on BluRay (mix of 1080p and 4k). I just purchased a USB BluRay drive that's LibreDrive flashed and a MakeMKV license.\n\nHowever, doing some math, I'm going to need more storage. I've done a few tests and a 1hr BluRay (1080p) is like 15GB straight out of MakeMKV. This is going to easily eat through my storage, so I was considering re-encoding. Looking at Handbrake, I've played around with the following settings. However, re-encoding take A LOT of time and seems like a really deep rabbit hole.\n\n* MKV\n* x265 10-bit\n* CRF 20 slow\n* AAC audio \n\nIs it easier to just buy more/bigger hard drives and leave all of my media as MKVs straight from MakeMKV?\n\nFor reference, I already have a small homelab consisting of an [ASRock DeskMini H470](https://www.asrock.com/nettop/Intel/DeskMini%20H470%20Series/index.asp) w/ i5-10400 (running Proxmox) and a 2-bay Synology with 2x 14TB WD Red Plus (RAID 1).", "author_fullname": "t2_isjro", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Going to start ripping BluRays to watch on Jellyfin (Plex alternative). Do you guys generally re-encode them with Handbrake, or leave them as MKVs straight from MakeMKV?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ffifn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 79, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 79, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698161370.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m tired of streaming. I already purchase music through &lt;a href=\"https://www.qobuz.com/us-en/shop\"&gt;Qobuz&lt;/a&gt; and am going to start purchasing all of the movies/TV I&amp;#39;ve &amp;quot;obtained&amp;quot; over the years on BluRay (mix of 1080p and 4k). I just purchased a USB BluRay drive that&amp;#39;s LibreDrive flashed and a MakeMKV license.&lt;/p&gt;\n\n&lt;p&gt;However, doing some math, I&amp;#39;m going to need more storage. I&amp;#39;ve done a few tests and a 1hr BluRay (1080p) is like 15GB straight out of MakeMKV. This is going to easily eat through my storage, so I was considering re-encoding. Looking at Handbrake, I&amp;#39;ve played around with the following settings. However, re-encoding take A LOT of time and seems like a really deep rabbit hole.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;MKV&lt;/li&gt;\n&lt;li&gt;x265 10-bit&lt;/li&gt;\n&lt;li&gt;CRF 20 slow&lt;/li&gt;\n&lt;li&gt;AAC audio &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Is it easier to just buy more/bigger hard drives and leave all of my media as MKVs straight from MakeMKV?&lt;/p&gt;\n\n&lt;p&gt;For reference, I already have a small homelab consisting of an &lt;a href=\"https://www.asrock.com/nettop/Intel/DeskMini%20H470%20Series/index.asp\"&gt;ASRock DeskMini H470&lt;/a&gt; w/ i5-10400 (running Proxmox) and a 2-bay Synology with 2x 14TB WD Red Plus (RAID 1).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ffifn", "is_robot_indexable": true, "report_reasons": null, "author": "lmm7425", "discussion_type": null, "num_comments": 120, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ffifn/going_to_start_ripping_blurays_to_watch_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ffifn/going_to_start_ripping_blurays_to_watch_on/", "subreddit_subscribers": 708471, "created_utc": 1698161370.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4jurunac", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need help building scrapper for National Institute of Health nih.gov \u00b7 GitHub \u00b7 openzim/zim-requests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_17f74x9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7A7WCFnWgh6fnWgrzTF6PL4MMXlTvG9CpEo0L-64J0w.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698132517.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/openzim/zim-requests/issues/651", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ONY0ReBkKJ9iwnwSNWa8GiJoMGs1mjMRdTKWAvrUr0c.jpg?auto=webp&amp;s=7e0279dad7bbc91ca2ca1b8805407a759f7cac6f", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/ONY0ReBkKJ9iwnwSNWa8GiJoMGs1mjMRdTKWAvrUr0c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2f070ca58e64c8c17516cc78467e9ab154e817b0", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/ONY0ReBkKJ9iwnwSNWa8GiJoMGs1mjMRdTKWAvrUr0c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7dcc8012a5134db8e8c5f9db9898319ef87dbe30", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/ONY0ReBkKJ9iwnwSNWa8GiJoMGs1mjMRdTKWAvrUr0c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53339bef0c3c83c6a9e86c44c3d4434d9bb10f75", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/ONY0ReBkKJ9iwnwSNWa8GiJoMGs1mjMRdTKWAvrUr0c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3958492b128e67355fab8a9d48d5cbb9a306e434", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/ONY0ReBkKJ9iwnwSNWa8GiJoMGs1mjMRdTKWAvrUr0c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=2c24dc2ef692e44ce12382ecbdc33d8d253bacfc", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/ONY0ReBkKJ9iwnwSNWa8GiJoMGs1mjMRdTKWAvrUr0c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=b9339207e31d9326bd246154fd9d43f893b62aeb", "width": 1080, "height": 540}], "variants": {}, "id": "yrB_gyeSuVoZ3HcHwsQ3z8acujVQQOFQlcJ78_DOyGk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17f74x9", "is_robot_indexable": true, "report_reasons": null, "author": "RedditNoobie777", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17f74x9/need_help_building_scrapper_for_national/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/openzim/zim-requests/issues/651", "subreddit_subscribers": 708471, "created_utc": 1698132517.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like to find a way to build an all ssd DAS with either nvme or sata ssd. I need at least 10gbps speeds. I'm thinking about something like a PCIE enclosure with 3 or 4 slots in which I would put nvme cards in. I see Sonnet have solutions but it's quite expensive. Is there a DIY way ? By buying individual boards of some sort ?", "author_fullname": "t2_xmstz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PCIE to USB/Thunderbolt or similar solutions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fcc32", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698152706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to find a way to build an all ssd DAS with either nvme or sata ssd. I need at least 10gbps speeds. I&amp;#39;m thinking about something like a PCIE enclosure with 3 or 4 slots in which I would put nvme cards in. I see Sonnet have solutions but it&amp;#39;s quite expensive. Is there a DIY way ? By buying individual boards of some sort ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fcc32", "is_robot_indexable": true, "report_reasons": null, "author": "PhilippePaquet", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fcc32/pcie_to_usbthunderbolt_or_similar_solutions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fcc32/pcie_to_usbthunderbolt_or_similar_solutions/", "subreddit_subscribers": 708471, "created_utc": 1698152706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\nSorry if this is a duplicate post or it\u2019s been asked before but I couldn\u2019t specifically find an answer when looking.\n\nI have bought 2 lots of *new* Seagate Exos X18 16TB HDD from Amazon (sold, and shipped by Amazon - no 3rd parties) for \u00a3202.00 /ea. \n\nThe first one that arrived although the label even listing new, was labelled as certified refurbished (assuming this drive is not new?), and upon searching up the Serial on Seagates website stated that I needed to contact the place of purchase.\n\nI contacted Amazon and said the drive was labelled as certified refurbished and Seagate website listed warranty as contact seller and asked them if I did have a 5 year warranty and was the drive new. They wrote back and said likely no and no, but they dispatched the wrong item and they would return that for a refund and I could rebuy a new one.\n\nFast forward to today, and the second order I placed they have sent exactly the same drive. And checking the SN on Seagate yields the same results.\n\nAre these legit (and it\u2019s just me having a brain fart moment) or are these drives non-warranty and refurbished? Should I just send it back?\n\nI specifically avoided the \u201cOEM\u201d listings because of the warranty problem. This drive was not listed as OEM or refurbished.\n\nThanks", "author_fullname": "t2_3j9dm7sj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Exos 16TB Drives from Amazon have no warranty?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fhngu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698167002.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,\nSorry if this is a duplicate post or it\u2019s been asked before but I couldn\u2019t specifically find an answer when looking.&lt;/p&gt;\n\n&lt;p&gt;I have bought 2 lots of &lt;em&gt;new&lt;/em&gt; Seagate Exos X18 16TB HDD from Amazon (sold, and shipped by Amazon - no 3rd parties) for \u00a3202.00 /ea. &lt;/p&gt;\n\n&lt;p&gt;The first one that arrived although the label even listing new, was labelled as certified refurbished (assuming this drive is not new?), and upon searching up the Serial on Seagates website stated that I needed to contact the place of purchase.&lt;/p&gt;\n\n&lt;p&gt;I contacted Amazon and said the drive was labelled as certified refurbished and Seagate website listed warranty as contact seller and asked them if I did have a 5 year warranty and was the drive new. They wrote back and said likely no and no, but they dispatched the wrong item and they would return that for a refund and I could rebuy a new one.&lt;/p&gt;\n\n&lt;p&gt;Fast forward to today, and the second order I placed they have sent exactly the same drive. And checking the SN on Seagate yields the same results.&lt;/p&gt;\n\n&lt;p&gt;Are these legit (and it\u2019s just me having a brain fart moment) or are these drives non-warranty and refurbished? Should I just send it back?&lt;/p&gt;\n\n&lt;p&gt;I specifically avoided the \u201cOEM\u201d listings because of the warranty problem. This drive was not listed as OEM or refurbished.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fhngu", "is_robot_indexable": true, "report_reasons": null, "author": "NWSpitfire", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fhngu/seagate_exos_16tb_drives_from_amazon_have_no/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fhngu/seagate_exos_16tb_drives_from_amazon_have_no/", "subreddit_subscribers": 708471, "created_utc": 1698167002.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi Everyone, I have been doing some research for my next system build and I am now trying to find a decently priced case that holds 12, 3.5\" HDDs. If anyone could recommend some cases to me, I would be grateful. Thank you for your time. \n\nEdit: have to leave now. Will be back later.", "author_fullname": "t2_4isg4jj9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for cases with 12 HDD bays", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fhn2e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698169321.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698166975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Everyone, I have been doing some research for my next system build and I am now trying to find a decently priced case that holds 12, 3.5&amp;quot; HDDs. If anyone could recommend some cases to me, I would be grateful. Thank you for your time. &lt;/p&gt;\n\n&lt;p&gt;Edit: have to leave now. Will be back later.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fhn2e", "is_robot_indexable": true, "report_reasons": null, "author": "happypessoa", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fhn2e/looking_for_cases_with_12_hdd_bays/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fhn2e/looking_for_cases_with_12_hdd_bays/", "subreddit_subscribers": 708471, "created_utc": 1698166975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey!\n\nBasically, I want to expand my storage and tidy it up (atm I have more or less like 5 disks, external and internal ones).\n\nWhile researching, I saw two things that may be appropiate: docking stations and disk enclosures\n\nHowever, I am having some trouble understanding the difference (at least for my use case)\n\nMy use case is basically I have a server running ubuntu with all of my servers dockerized and just want to expand my storage to store movies and tv shows and make it look nicer. No RAID, no anything.\n\nI came across two options:\n\n[https://sabrent.com/collections/docking-station/products/ds-sc4b](https://sabrent.com/collections/docking-station/products/ds-sc4b)\n\nand\n\n[https://www.terra-master.com/global/d4-300.html](https://www.terra-master.com/global/d4-300.html)\n\nQuestions:\n\nWhich one do you think is better for my use case?\n\nWhat's the difference between docking stations and disk enclosures?\n\nAre there any differences for my use case?\n\nDo you know another device that may be better or have you had any bad experience with the aforementioned devices?\n\nThanks!", "author_fullname": "t2_3f7jceck", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Docking station vs disk enclosure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ffdh7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698161010.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey!&lt;/p&gt;\n\n&lt;p&gt;Basically, I want to expand my storage and tidy it up (atm I have more or less like 5 disks, external and internal ones).&lt;/p&gt;\n\n&lt;p&gt;While researching, I saw two things that may be appropiate: docking stations and disk enclosures&lt;/p&gt;\n\n&lt;p&gt;However, I am having some trouble understanding the difference (at least for my use case)&lt;/p&gt;\n\n&lt;p&gt;My use case is basically I have a server running ubuntu with all of my servers dockerized and just want to expand my storage to store movies and tv shows and make it look nicer. No RAID, no anything.&lt;/p&gt;\n\n&lt;p&gt;I came across two options:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://sabrent.com/collections/docking-station/products/ds-sc4b\"&gt;https://sabrent.com/collections/docking-station/products/ds-sc4b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;and&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.terra-master.com/global/d4-300.html\"&gt;https://www.terra-master.com/global/d4-300.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Questions:&lt;/p&gt;\n\n&lt;p&gt;Which one do you think is better for my use case?&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the difference between docking stations and disk enclosures?&lt;/p&gt;\n\n&lt;p&gt;Are there any differences for my use case?&lt;/p&gt;\n\n&lt;p&gt;Do you know another device that may be better or have you had any bad experience with the aforementioned devices?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XJhoIKemyPFGEZZtud1_Tp7lvMpWdkPrtkA0KJrknbM.jpg?auto=webp&amp;s=242e72ba0e875ca898b9d424c36b8c7f84cc0428", "width": 600, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/XJhoIKemyPFGEZZtud1_Tp7lvMpWdkPrtkA0KJrknbM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=734a688c5bed5f52526d1f6850016f06df403810", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/XJhoIKemyPFGEZZtud1_Tp7lvMpWdkPrtkA0KJrknbM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3b23ccd084a98047d34ed2512bb7188c6b960965", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/XJhoIKemyPFGEZZtud1_Tp7lvMpWdkPrtkA0KJrknbM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0b8a07675761cfdaa40e0f30a6304f5b46c1a7f8", "width": 320, "height": 320}], "variants": {}, "id": "Q30YM4gtHPbJq2cxDZJKbtqIndZyf4XzKFhKk2E0UJs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ffdh7", "is_robot_indexable": true, "report_reasons": null, "author": "Rafa130397", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ffdh7/docking_station_vs_disk_enclosure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ffdh7/docking_station_vs_disk_enclosure/", "subreddit_subscribers": 708471, "created_utc": 1698161010.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone,\n\nDoes anybody know if the reliability of Samsung 870 QVO is on par with other SSD like Micron 5210 ION Series (or possibly others). From the datasheets:\n\n* [https://download.semiconductor.samsung.com/resources/data-sheet/Samsung\\_SSD\\_870\\_QVO\\_Data\\_Sheet\\_Rev1.1.pdf](https://download.semiconductor.samsung.com/resources/data-sheet/Samsung_SSD_870_QVO_Data_Sheet_Rev1.1.pdf)\n* [https://www.micron.com/-/media/client/global/documents/products/product-flyer/5210\\_ion\\_ssd\\_product\\_brief.pdf](https://www.micron.com/-/media/client/global/documents/products/product-flyer/5210_ion_ssd_product_brief.pdf?la=en)\n\nI would choose the Micron over the Samsung, but given it is the same technology, I wonder if there is an actual difference?\n\nAny insight on this question?\n\nRegards,", "author_fullname": "t2_b3cz2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "QLC Nand SSD reliability: Samsung 870 QVO vs others", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ffoaf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698161788.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;Does anybody know if the reliability of Samsung 870 QVO is on par with other SSD like Micron 5210 ION Series (or possibly others). From the datasheets:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://download.semiconductor.samsung.com/resources/data-sheet/Samsung_SSD_870_QVO_Data_Sheet_Rev1.1.pdf\"&gt;https://download.semiconductor.samsung.com/resources/data-sheet/Samsung_SSD_870_QVO_Data_Sheet_Rev1.1.pdf&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.micron.com/-/media/client/global/documents/products/product-flyer/5210_ion_ssd_product_brief.pdf?la=en\"&gt;https://www.micron.com/-/media/client/global/documents/products/product-flyer/5210_ion_ssd_product_brief.pdf&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;I would choose the Micron over the Samsung, but given it is the same technology, I wonder if there is an actual difference?&lt;/p&gt;\n\n&lt;p&gt;Any insight on this question?&lt;/p&gt;\n\n&lt;p&gt;Regards,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ffoaf", "is_robot_indexable": true, "report_reasons": null, "author": "fpopineau", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ffoaf/qlc_nand_ssd_reliability_samsung_870_qvo_vs_others/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ffoaf/qlc_nand_ssd_reliability_samsung_870_qvo_vs_others/", "subreddit_subscribers": 708471, "created_utc": 1698161788.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Looking for solutions to power my DAS  I'm building (it will be in a mini ITX PC case now server chassis so no option for backplanes and what not). Now I will have 3x 6pin ports so will need to daisy chain some of my sata power cables (thinking 16-20 HDDs total so 4-7 HDDs per 6pin on PSU, but I came across this solution on aliexpress that chia miners have been using. Anyone have any experience with these? Worth a shot or is it a fire waiting to happen?", "author_fullname": "t2_3ebp9vth", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ATX 24pin to molex to power HDDs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 137, "top_awarded_type": null, "hide_score": false, "name": "t3_17f40f4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OukfIsJc1MAaCu4XZEs_atKjBTeqUUSvK6e71yvWpGY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698120237.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking for solutions to power my DAS  I&amp;#39;m building (it will be in a mini ITX PC case now server chassis so no option for backplanes and what not). Now I will have 3x 6pin ports so will need to daisy chain some of my sata power cables (thinking 16-20 HDDs total so 4-7 HDDs per 6pin on PSU, but I came across this solution on aliexpress that chia miners have been using. Anyone have any experience with these? Worth a shot or is it a fire waiting to happen?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/g61euj7br2wb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/g61euj7br2wb1.jpg?auto=webp&amp;s=e7fcde783a8f05f2ac4c5b71d8f2010bb683d606", "width": 1440, "height": 1417}, "resolutions": [{"url": "https://preview.redd.it/g61euj7br2wb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=793f5dc21e901a7946b7902c3271b85f7c3f7f51", "width": 108, "height": 106}, {"url": "https://preview.redd.it/g61euj7br2wb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=767dfdd1610cf6472621ac670be4916ef2355ffb", "width": 216, "height": 212}, {"url": "https://preview.redd.it/g61euj7br2wb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=81b3391602088fc9bb7f769a7e164d4fe5b83ce8", "width": 320, "height": 314}, {"url": "https://preview.redd.it/g61euj7br2wb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=62e9cf8bdf55c4b9a737cf1d941592cbaae54b70", "width": 640, "height": 629}, {"url": "https://preview.redd.it/g61euj7br2wb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dcdf8f2d4de992335a52d7ff4d5ec57d4f5299d9", "width": 960, "height": 944}, {"url": "https://preview.redd.it/g61euj7br2wb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7f3d2ac109dfe2b998baa16426808ef551fc7f34", "width": 1080, "height": 1062}], "variants": {}, "id": "_qy7ZCNHPz2pTz3WlqlCJxphGEYoyqwiHQDtEn6KRP4"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17f40f4", "is_robot_indexable": true, "report_reasons": null, "author": "RegeneratorRE4", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17f40f4/atx_24pin_to_molex_to_power_hdds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/g61euj7br2wb1.jpg", "subreddit_subscribers": 708471, "created_utc": 1698120237.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "It seems to me Exos X is superior on every front, price: capacity, AFR, power consumption.\n\nWhat is the use case for Exos E? Why does it cost more? I don't understand.\n\n&amp;#x200B;\n\nDrives in question are here [https://www.seagate.com/products/enterprise-drives/](https://www.seagate.com/products/enterprise-drives/)\n\nI know their site says \"low TCO\" (total cost of ownership) but I don't see how that makes sense given X series is superior in terms of AFR (annualized failure rate) and MTBF", "author_fullname": "t2_13eqfc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate Exos E vs Exos X", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fspmn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698195774.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;It seems to me Exos X is superior on every front, price: capacity, AFR, power consumption.&lt;/p&gt;\n\n&lt;p&gt;What is the use case for Exos E? Why does it cost more? I don&amp;#39;t understand.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Drives in question are here &lt;a href=\"https://www.seagate.com/products/enterprise-drives/\"&gt;https://www.seagate.com/products/enterprise-drives/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I know their site says &amp;quot;low TCO&amp;quot; (total cost of ownership) but I don&amp;#39;t see how that makes sense given X series is superior in terms of AFR (annualized failure rate) and MTBF&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?auto=webp&amp;s=b98f58f088fdf8fbeb225a485466816520892a66", "width": 1440, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=800aeac928e4d6917cdf3db161d37c173da92af5", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5a9549b2c27b55813f6941439e0246cac408ff1d", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=708b52a8cc3161e776c554b1f4a488231d8bfce6", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=93eb129bea186541cdd32a88a0cb2d619f9a954c", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6ad5e3bcc25ba7cdf8dd591fb8e247b839fe5aa7", "width": 960, "height": 600}, {"url": "https://external-preview.redd.it/pyk-9B2ErLhMX2ZNE7n3iEQrhNSAXceYQSAeV3d7G6Q.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8b52b8bf108499e8a6d3bd58f428c8f644af3085", "width": 1080, "height": 675}], "variants": {}, "id": "GJ9K1o7VNo6J4JXg3IrZBPizWfgWXRc6b6FmSaP5cNc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17fspmn", "is_robot_indexable": true, "report_reasons": null, "author": "tronicdude6", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fspmn/seagate_exos_e_vs_exos_x/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fspmn/seagate_exos_e_vs_exos_x/", "subreddit_subscribers": 708471, "created_utc": 1698195774.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've tried versions of YouTube-dl but everything I've tried grabs the trailer, not the movie. \n\nCan anyone figure out how to grab the actual movie from this site?\n\n[https://moviesjoyhd.to/watch-movie/ruby-62392.5463016](https://moviesjoyhd.to/watch-movie/ruby-62392.5463016)\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_rr4vx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for way to grab video from website", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fhvtl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698167612.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve tried versions of YouTube-dl but everything I&amp;#39;ve tried grabs the trailer, not the movie. &lt;/p&gt;\n\n&lt;p&gt;Can anyone figure out how to grab the actual movie from this site?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://moviesjoyhd.to/watch-movie/ruby-62392.5463016\"&gt;https://moviesjoyhd.to/watch-movie/ruby-62392.5463016&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/OVOuVlAm9DsB3VffIOKFIUBa6Hl9c6zfrDrYDWeLJiQ.jpg?auto=webp&amp;s=72d667fcb43d7ca350405433370ab9981d4c2304", "width": 648, "height": 425}, "resolutions": [{"url": "https://external-preview.redd.it/OVOuVlAm9DsB3VffIOKFIUBa6Hl9c6zfrDrYDWeLJiQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=048a3d82c4cb13d203b46c3451cd0e8bb68775b0", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/OVOuVlAm9DsB3VffIOKFIUBa6Hl9c6zfrDrYDWeLJiQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3cc81a74c95709658369e4919a6ea418ec810b9f", "width": 216, "height": 141}, {"url": "https://external-preview.redd.it/OVOuVlAm9DsB3VffIOKFIUBa6Hl9c6zfrDrYDWeLJiQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8de5120ff70363441983db2e5688ebb8662ea370", "width": 320, "height": 209}, {"url": "https://external-preview.redd.it/OVOuVlAm9DsB3VffIOKFIUBa6Hl9c6zfrDrYDWeLJiQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=abe2e9c03f2495d51373c0dc2bdb2bffe9d26ebb", "width": 640, "height": 419}], "variants": {}, "id": "s6SBce-yDMS7QNV49GiC-FcN3ZvbxXmSnyMPJ7Ncx1Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fhvtl", "is_robot_indexable": true, "report_reasons": null, "author": "MarkPugnerIII", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fhvtl/looking_for_way_to_grab_video_from_website/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fhvtl/looking_for_way_to_grab_video_from_website/", "subreddit_subscribers": 708471, "created_utc": 1698167612.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "S.M.A.R.T. and HDD longevity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fd0zv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_y1qvau", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "storage", "selftext": "Hi there.\n\nI have a bunch of disks at home. Mostly 2,5\" USB/external, but 3 or 4 are just regular 3,5\" SATA drives.\n\nNever worried too much to look at SMART data until last week one of them started making funny \"click-like\" noises when I connect it to the PC. Makes 4 or 5 clicks and then it goes silent and data can be accessed as usual. Weird. And most probably a bad sign. Very bad sign.\n\nSince the the disk appears to be imminent to fail, I immediately thought of transferring the data to another disk. But before that I decided to check the clicking unit with smartctl, Linux cli utility.  \nPlease find below SMART data for that particular disk which to be fair is already some good \\~10 years old.\n\nAnd to rescue the data I decided to go with the most recent disk I have laying around which is a WD Blue 1TB drive that I think I bought in 2016. New at time of buying. Now 7 years old drive.\n\nPlease note that both drives have very little usage. Both have been stored in a drawer for most of their lifetime.\n\nI was basically shocked when looking at the SMART data. There's \"pre fail\" written all over the place on both drives.\n\nSo I went out to a local major reseller and bought 2 brand new Seagate SkyHawk 2TB 5400RPM 256MB SATA III. Yes, I know these drives were designed with surveillance in mind but those were the best deal I could find around for two 2TB 3,5\" SATA drives. I just had to solve my problem. I would deal with the details later.\n\nSo, I got home, connected both drives to my Pi server, ran a smartctl on it and...yep, lots of \"pre fail\" warnings.  \nSo...what the heck am I doing wrong? Where can I learn to properly interpret SMART reports? Looking at both my disks' reports, am I in trouble? Or the disks are fine'ish? Is it normal that a new disk reports pre fails??\n\nThanks in advance.\n\nCheers  \n\n\n    SMART - clicking drive\n    \n    rcorreia@pi3srv:~ $ cat smart_toshiba.txt                                     \n    smartctl 7.3 2022-02-28 r5338 [aarch64-linux-6.1.0-rpi4-rpi-v8] (local build)                                                                               \n    Copyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org                                                                                 \n                                                                                                                                                                \n    === START OF INFORMATION SECTION ===                                                                                                                        \n    Model Family:     Toshiba 2.5\" HDD MK..59GSM (AF)                                                                                                           \n    Device Model:     TOSHIBA MK1059GSM                                                                                                                         \n    Serial Number:    Y1S7P2QQT                                                                                                                                 \n    LU WWN Device Id: 5 000039 3a248e756                                                                                                                        \n    Firmware Version: GU001U                                                                                                                                    \n    User Capacity:    1,000,204,886,016 bytes [1.00 TB]                                                                                                         \n    Sector Sizes:     512 bytes logical, 4096 bytes physical                                                                                                    \n    Rotation Rate:    5400 rpm                                                                                                                                  \n    Form Factor:      2.5 inches                                                                                                                                \n    Device is:        In smartctl database 7.3/5319                                                                                                             \n    ATA Version is:   ATA8-ACS (minor revision not indicated)                                                                                                   \n    SATA Version is:  SATA 2.6, 3.0 Gb/s (current: 3.0 Gb/s)                                                                                                    \n    Local Time is:    Mon Oct 23 23:29:39 2023 WEST                                                                                                             \n    SMART support is: Available - device has SMART capability.                                                                                                  \n    SMART support is: Enabled                                                                                                                                   \n                                                                                                                                                                \n    === START OF READ SMART DATA SECTION ===                                                                                                                    \n    SMART overall-health self-assessment test result: PASSED                                                                                                    \n                                                                                                                                                                \n    General SMART Values:                                                                                                                                       \n    Offline data collection status:  (0x00) Offline data collection activity                                                                                    \n                                            was never started.                                                                                                  \n                                            Auto Offline Data Collection: Disabled.                                                                             \n    Self-test execution status:      (  25) The self-test routine was aborted by                                                                                \n                                            the host.                                                                                                           \n    Total time to complete Offline                                                                                                                              \n    data collection:                (  120) seconds.                                                                                                            \n    Offline data collection                                                                                                                                     \n    capabilities:                    (0x5b) SMART execute Offline immediate.                                                                                    \n                                            Auto Offline data collection on/off support.                                                                        \n                                            Suspend Offline collection upon new                                                                                 \n                                            command.                                                                                                            \n                                            Offline surface scan supported.                                                                                     \n                                            Self-test supported.                                                                                                \n                                            No Conveyance Self-test supported.                                                                                  \n                                            Selective Self-test supported.                                                                                      \n    SMART capabilities:            (0x0003) Saves SMART data before entering                                                                                    \n                                            power-saving mode.                                                                                                  \n                                            Supports SMART auto save timer.                                                                                     \n    Error logging capability:        (0x01) Error logging supported.                                                                                            \n                                            General Purpose Logging supported.    \n    Short self-test routine                                                                                                                                     \n    recommended polling time:        (   2) minutes.                              \n    Extended self-test routine                                                                                                                                  \n    recommended polling time:        ( 299) minutes.                                                                                                            \n    SCT capabilities:              (0x003d) SCT Status supported.                                                                                               \n                                            SCT Error Recovery Control supported.                                                                               \n                                            SCT Feature Control supported.                                                                                      \n                                            SCT Data Table supported.                                                                                           \n                                                                                                                                                                \n    SMART Attributes Data Structure revision number: 16                                                                                                         \n    Vendor Specific SMART Attributes with Thresholds:                                                                                                           \n    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE                                                            \n      1 Raw_Read_Error_Rate     0x000b   100   100   050    Pre-fail  Always       -       0                                                                    \n      2 Throughput_Performance  0x0005   100   100   050    Pre-fail  Offline      -       0                                                                    \n      3 Spin_Up_Time            0x0027   100   100   001    Pre-fail  Always       -       3956                                                                 \n      4 Start_Stop_Count        0x0032   100   100   000    Old_age   Always       -       100177                                                               \n      5 Reallocated_Sector_Ct   0x0033   100   100   050    Pre-fail  Always       -       0                                                                    \n      7 Seek_Error_Rate         0x000b   100   100   050    Pre-fail  Always       -       0                                                                    \n      8 Seek_Time_Performance   0x0005   100   100   050    Pre-fail  Offline      -       0                                                                    \n      9 Power_On_Hours          0x0032   046   046   000    Old_age   Always       -       21858                                                                \n     10 Spin_Retry_Count        0x0033   253   100   030    Pre-fail  Always       -       0                                                                    \n     12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       145                                                                  \n    191 G-Sense_Error_Rate      0x0032   100   100   000    Old_age   Always       -       18                                                                   \n    192 Power-Off_Retract_Count 0x0032   100   100   000    Old_age   Always       -       24                                                                   \n    193 Load_Cycle_Count        0x0032   071   071   000    Old_age   Always       -       294403                                                               \n    194 Temperature_Celsius     0x0022   100   100   000    Old_age   Always       -       30 (Min/Max 17/51)                                                   \n    196 Reallocated_Event_Count 0x0032   100   100   000    Old_age   Always       -       0                                                                    \n    197 Current_Pending_Sector  0x0032   100   100   000    Old_age   Always       -       0                                                                    \n    198 Offline_Uncorrectable   0x0030   100   100   000    Old_age   Offline      -       0                                                                    \n    199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0                                                                    \n    220 Disk_Shift              0x0002   100   100   000    Old_age   Always       -       76                                                                   \n    222 Loaded_Hours            0x0032   095   095   000    Old_age   Always       -       2339                                                                 \n    223 Load_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0                                                                    \n    224 Load_Friction           0x0022   100   100   000    Old_age   Always       -       0                                                                    \n    226 Load-in_Time            0x0026   100   100   000    Old_age   Always       -       273                                                                  \n    240 Head_Flying_Hours       0x0001   100   100   001    Pre-fail  Offline      -       0                                                                    \n                                                                                  \n    SMART Error Log Version: 1                                                                                                                                  \n    No Errors Logged                                                              \n                                                                                                                                                                \n    SMART Self-test log structure revision number 1                                                                                                             \n    Num  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error                                                             \n    # 1  Extended offline    Aborted by host               90%     21838         -                                                                              \n                                                                                                                                                                \n    SMART Selective self-test log data structure revision number 1                                                                                              \n     SPAN  MIN_LBA  MAX_LBA  CURRENT_TEST_STATUS                                                                                                                \n        1        0        0  Not_testing                                                                                                                        \n        2        0        0  Not_testing                                                                                                                        \n        3        0        0  Not_testing                                                                                                                        \n        4        0        0  Not_testing                                                                                                                        \n        5        0        0  Not_testing                                                                                                                        \n    Selective self-test flags (0x0):                                                                                                                            \n      After scanning selected spans, do NOT read-scan remainder of disk.                                                                                        \n    If Selective self-test is pending on power-up, resume after 0 minute delay.                                                                                 \n    \n\n&amp;#x200B;\n\n    SMART - drive to rescue the data\n    \n    rcorreia@pi3srv:~ $ cat smart_wd.txt                                                                                                                [47/295]\n    smartctl 7.3 2022-02-28 r5338 [aarch64-linux-6.1.0-rpi4-rpi-v8] (local build)\n    Copyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org\n    \n    === START OF INFORMATION SECTION ===\n    Model Family:     Western Digital Blue\n    Device Model:     WDC WD10EZRZ-00HTKB0\n    Serial Number:    WD-WCC4J2SYEF97\n    LU WWN Device Id: 5 0014ee 264920e36\n    Firmware Version: 01.01A01\n    User Capacity:    1,000,204,886,016 bytes [1.00 TB]\n    Sector Sizes:     512 bytes logical, 4096 bytes physical\n    Rotation Rate:    5400 rpm\n    Device is:        In smartctl database 7.3/5319\n    ATA Version is:   ACS-2, ACS-3 T13/2161-D revision 3b\n    SATA Version is:  SATA 3.1, 6.0 Gb/s (current: 3.0 Gb/s)\n    Local Time is:    Mon Oct 23 23:29:57 2023 WEST\n    SMART support is: Available - device has SMART capability.\n    SMART support is: Enabled\n    \n    === START OF READ SMART DATA SECTION ===\n    SMART overall-health self-assessment test result: PASSED\n    \n    General SMART Values:\n    Offline data collection status:  (0x82) Offline data collection activity\n                                            was completed without error.\n                                            Auto Offline Data Collection: Enabled. \n    Self-test execution status:      (   0) The previous self-test routine completed\n                                            without error or no self-test has ever  \n                                            been run.\n    Total time to complete Offline \n    data collection:                (13140) seconds.\n    Offline data collection\n    capabilities:                    (0x7b) SMART execute Offline immediate.\n                                            Auto Offline data collection on/off support.\n                                            Suspend Offline collection upon new\n                                            command.\n                                            Offline surface scan supported.\n                                            Self-test supported.\n                                            Conveyance Self-test supported.\n                                            Selective Self-test supported.\n    SMART capabilities:            (0x0003) Saves SMART data before entering\n                                            power-saving mode.\n                                            Supports SMART auto save timer.\n    Error logging capability:        (0x01) Error logging supported.\n                                            General Purpose Logging supported.\n    Short self-test routine \n    recommended polling time:        (   2) minutes.\n    Extended self-test routine\n    recommended polling time:        ( 149) minutes.\n    Conveyance self-test routine\n    recommended polling time:        (   5) minutes.\n    SCT capabilities:              (0x3035) SCT Status supported.\n                                            SCT Feature Control supported.\n                                            SCT Data Table supported.\n    \n    SMART Attributes Data Structure revision number: 16\n    Vendor Specific SMART Attributes with Thresholds:\n    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n      1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       0\n      3 Spin_Up_Time            0x0027   137   136   021    Pre-fail  Always       -       4116\n      4 Start_Stop_Count        0x0032   100   100   000    Old_age   Always       -       168\n      5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n      7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n      9 Power_On_Hours          0x0032   099   098   000    Old_age   Always       -       1086\n     10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n     11 Calibration_Retry_Count 0x0032   100   253   000    Old_age   Always       -       0\n     12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       20\n    192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       3\n    193 Load_Cycle_Count        0x0032   199   199   000    Old_age   Always       -       3132\n    194 Temperature_Celsius     0x0022   114   102   000    Old_age   Always       -       29\n    196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n    \n    SMART Error Log Version: 1\n    No Errors Logged\n    \n    SMART Self-test log structure revision number 1\n    Num  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error\n    # 1  Short offline       Completed without error       00%      1049         - \n    \n    SMART Selective self-test log data structure revision number 1\n     SPAN  MIN_LBA  MAX_LBA  CURRENT_TEST_STATUS\n        1        0        0  Not_testing\n        2        0        0  Not_testing\n        3        0        0  Not_testing\n        4        0        0  Not_testing\n        5        0        0  Not_testing\n    Selective self-test flags (0x0):\n      After scanning selected spans, do NOT read-scan remainder of disk.\n    If Selective self-test is pending on power-up, resume after 0 minute delay.\n    \n    \n\n&amp;#x200B;", "author_fullname": "t2_y1qvau", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "S.M.A.R.T. and HDD longevity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/storage", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17exrvk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698101911.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.storage", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there.&lt;/p&gt;\n\n&lt;p&gt;I have a bunch of disks at home. Mostly 2,5&amp;quot; USB/external, but 3 or 4 are just regular 3,5&amp;quot; SATA drives.&lt;/p&gt;\n\n&lt;p&gt;Never worried too much to look at SMART data until last week one of them started making funny &amp;quot;click-like&amp;quot; noises when I connect it to the PC. Makes 4 or 5 clicks and then it goes silent and data can be accessed as usual. Weird. And most probably a bad sign. Very bad sign.&lt;/p&gt;\n\n&lt;p&gt;Since the the disk appears to be imminent to fail, I immediately thought of transferring the data to another disk. But before that I decided to check the clicking unit with smartctl, Linux cli utility.&lt;br/&gt;\nPlease find below SMART data for that particular disk which to be fair is already some good ~10 years old.&lt;/p&gt;\n\n&lt;p&gt;And to rescue the data I decided to go with the most recent disk I have laying around which is a WD Blue 1TB drive that I think I bought in 2016. New at time of buying. Now 7 years old drive.&lt;/p&gt;\n\n&lt;p&gt;Please note that both drives have very little usage. Both have been stored in a drawer for most of their lifetime.&lt;/p&gt;\n\n&lt;p&gt;I was basically shocked when looking at the SMART data. There&amp;#39;s &amp;quot;pre fail&amp;quot; written all over the place on both drives.&lt;/p&gt;\n\n&lt;p&gt;So I went out to a local major reseller and bought 2 brand new Seagate SkyHawk 2TB 5400RPM 256MB SATA III. Yes, I know these drives were designed with surveillance in mind but those were the best deal I could find around for two 2TB 3,5&amp;quot; SATA drives. I just had to solve my problem. I would deal with the details later.&lt;/p&gt;\n\n&lt;p&gt;So, I got home, connected both drives to my Pi server, ran a smartctl on it and...yep, lots of &amp;quot;pre fail&amp;quot; warnings.&lt;br/&gt;\nSo...what the heck am I doing wrong? Where can I learn to properly interpret SMART reports? Looking at both my disks&amp;#39; reports, am I in trouble? Or the disks are fine&amp;#39;ish? Is it normal that a new disk reports pre fails??&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance.&lt;/p&gt;\n\n&lt;p&gt;Cheers  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SMART - clicking drive\n\nrcorreia@pi3srv:~ $ cat smart_toshiba.txt                                     \nsmartctl 7.3 2022-02-28 r5338 [aarch64-linux-6.1.0-rpi4-rpi-v8] (local build)                                                                               \nCopyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org                                                                                 \n\n=== START OF INFORMATION SECTION ===                                                                                                                        \nModel Family:     Toshiba 2.5&amp;quot; HDD MK..59GSM (AF)                                                                                                           \nDevice Model:     TOSHIBA MK1059GSM                                                                                                                         \nSerial Number:    Y1S7P2QQT                                                                                                                                 \nLU WWN Device Id: 5 000039 3a248e756                                                                                                                        \nFirmware Version: GU001U                                                                                                                                    \nUser Capacity:    1,000,204,886,016 bytes [1.00 TB]                                                                                                         \nSector Sizes:     512 bytes logical, 4096 bytes physical                                                                                                    \nRotation Rate:    5400 rpm                                                                                                                                  \nForm Factor:      2.5 inches                                                                                                                                \nDevice is:        In smartctl database 7.3/5319                                                                                                             \nATA Version is:   ATA8-ACS (minor revision not indicated)                                                                                                   \nSATA Version is:  SATA 2.6, 3.0 Gb/s (current: 3.0 Gb/s)                                                                                                    \nLocal Time is:    Mon Oct 23 23:29:39 2023 WEST                                                                                                             \nSMART support is: Available - device has SMART capability.                                                                                                  \nSMART support is: Enabled                                                                                                                                   \n\n=== START OF READ SMART DATA SECTION ===                                                                                                                    \nSMART overall-health self-assessment test result: PASSED                                                                                                    \n\nGeneral SMART Values:                                                                                                                                       \nOffline data collection status:  (0x00) Offline data collection activity                                                                                    \n                                        was never started.                                                                                                  \n                                        Auto Offline Data Collection: Disabled.                                                                             \nSelf-test execution status:      (  25) The self-test routine was aborted by                                                                                \n                                        the host.                                                                                                           \nTotal time to complete Offline                                                                                                                              \ndata collection:                (  120) seconds.                                                                                                            \nOffline data collection                                                                                                                                     \ncapabilities:                    (0x5b) SMART execute Offline immediate.                                                                                    \n                                        Auto Offline data collection on/off support.                                                                        \n                                        Suspend Offline collection upon new                                                                                 \n                                        command.                                                                                                            \n                                        Offline surface scan supported.                                                                                     \n                                        Self-test supported.                                                                                                \n                                        No Conveyance Self-test supported.                                                                                  \n                                        Selective Self-test supported.                                                                                      \nSMART capabilities:            (0x0003) Saves SMART data before entering                                                                                    \n                                        power-saving mode.                                                                                                  \n                                        Supports SMART auto save timer.                                                                                     \nError logging capability:        (0x01) Error logging supported.                                                                                            \n                                        General Purpose Logging supported.    \nShort self-test routine                                                                                                                                     \nrecommended polling time:        (   2) minutes.                              \nExtended self-test routine                                                                                                                                  \nrecommended polling time:        ( 299) minutes.                                                                                                            \nSCT capabilities:              (0x003d) SCT Status supported.                                                                                               \n                                        SCT Error Recovery Control supported.                                                                               \n                                        SCT Feature Control supported.                                                                                      \n                                        SCT Data Table supported.                                                                                           \n\nSMART Attributes Data Structure revision number: 16                                                                                                         \nVendor Specific SMART Attributes with Thresholds:                                                                                                           \nID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE                                                            \n  1 Raw_Read_Error_Rate     0x000b   100   100   050    Pre-fail  Always       -       0                                                                    \n  2 Throughput_Performance  0x0005   100   100   050    Pre-fail  Offline      -       0                                                                    \n  3 Spin_Up_Time            0x0027   100   100   001    Pre-fail  Always       -       3956                                                                 \n  4 Start_Stop_Count        0x0032   100   100   000    Old_age   Always       -       100177                                                               \n  5 Reallocated_Sector_Ct   0x0033   100   100   050    Pre-fail  Always       -       0                                                                    \n  7 Seek_Error_Rate         0x000b   100   100   050    Pre-fail  Always       -       0                                                                    \n  8 Seek_Time_Performance   0x0005   100   100   050    Pre-fail  Offline      -       0                                                                    \n  9 Power_On_Hours          0x0032   046   046   000    Old_age   Always       -       21858                                                                \n 10 Spin_Retry_Count        0x0033   253   100   030    Pre-fail  Always       -       0                                                                    \n 12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       145                                                                  \n191 G-Sense_Error_Rate      0x0032   100   100   000    Old_age   Always       -       18                                                                   \n192 Power-Off_Retract_Count 0x0032   100   100   000    Old_age   Always       -       24                                                                   \n193 Load_Cycle_Count        0x0032   071   071   000    Old_age   Always       -       294403                                                               \n194 Temperature_Celsius     0x0022   100   100   000    Old_age   Always       -       30 (Min/Max 17/51)                                                   \n196 Reallocated_Event_Count 0x0032   100   100   000    Old_age   Always       -       0                                                                    \n197 Current_Pending_Sector  0x0032   100   100   000    Old_age   Always       -       0                                                                    \n198 Offline_Uncorrectable   0x0030   100   100   000    Old_age   Offline      -       0                                                                    \n199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0                                                                    \n220 Disk_Shift              0x0002   100   100   000    Old_age   Always       -       76                                                                   \n222 Loaded_Hours            0x0032   095   095   000    Old_age   Always       -       2339                                                                 \n223 Load_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0                                                                    \n224 Load_Friction           0x0022   100   100   000    Old_age   Always       -       0                                                                    \n226 Load-in_Time            0x0026   100   100   000    Old_age   Always       -       273                                                                  \n240 Head_Flying_Hours       0x0001   100   100   001    Pre-fail  Offline      -       0                                                                    \n\nSMART Error Log Version: 1                                                                                                                                  \nNo Errors Logged                                                              \n\nSMART Self-test log structure revision number 1                                                                                                             \nNum  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error                                                             \n# 1  Extended offline    Aborted by host               90%     21838         -                                                                              \n\nSMART Selective self-test log data structure revision number 1                                                                                              \n SPAN  MIN_LBA  MAX_LBA  CURRENT_TEST_STATUS                                                                                                                \n    1        0        0  Not_testing                                                                                                                        \n    2        0        0  Not_testing                                                                                                                        \n    3        0        0  Not_testing                                                                                                                        \n    4        0        0  Not_testing                                                                                                                        \n    5        0        0  Not_testing                                                                                                                        \nSelective self-test flags (0x0):                                                                                                                            \n  After scanning selected spans, do NOT read-scan remainder of disk.                                                                                        \nIf Selective self-test is pending on power-up, resume after 0 minute delay.                                                                                 \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SMART - drive to rescue the data\n\nrcorreia@pi3srv:~ $ cat smart_wd.txt                                                                                                                [47/295]\nsmartctl 7.3 2022-02-28 r5338 [aarch64-linux-6.1.0-rpi4-rpi-v8] (local build)\nCopyright (C) 2002-22, Bruce Allen, Christian Franke, www.smartmontools.org\n\n=== START OF INFORMATION SECTION ===\nModel Family:     Western Digital Blue\nDevice Model:     WDC WD10EZRZ-00HTKB0\nSerial Number:    WD-WCC4J2SYEF97\nLU WWN Device Id: 5 0014ee 264920e36\nFirmware Version: 01.01A01\nUser Capacity:    1,000,204,886,016 bytes [1.00 TB]\nSector Sizes:     512 bytes logical, 4096 bytes physical\nRotation Rate:    5400 rpm\nDevice is:        In smartctl database 7.3/5319\nATA Version is:   ACS-2, ACS-3 T13/2161-D revision 3b\nSATA Version is:  SATA 3.1, 6.0 Gb/s (current: 3.0 Gb/s)\nLocal Time is:    Mon Oct 23 23:29:57 2023 WEST\nSMART support is: Available - device has SMART capability.\nSMART support is: Enabled\n\n=== START OF READ SMART DATA SECTION ===\nSMART overall-health self-assessment test result: PASSED\n\nGeneral SMART Values:\nOffline data collection status:  (0x82) Offline data collection activity\n                                        was completed without error.\n                                        Auto Offline Data Collection: Enabled. \nSelf-test execution status:      (   0) The previous self-test routine completed\n                                        without error or no self-test has ever  \n                                        been run.\nTotal time to complete Offline \ndata collection:                (13140) seconds.\nOffline data collection\ncapabilities:                    (0x7b) SMART execute Offline immediate.\n                                        Auto Offline data collection on/off support.\n                                        Suspend Offline collection upon new\n                                        command.\n                                        Offline surface scan supported.\n                                        Self-test supported.\n                                        Conveyance Self-test supported.\n                                        Selective Self-test supported.\nSMART capabilities:            (0x0003) Saves SMART data before entering\n                                        power-saving mode.\n                                        Supports SMART auto save timer.\nError logging capability:        (0x01) Error logging supported.\n                                        General Purpose Logging supported.\nShort self-test routine \nrecommended polling time:        (   2) minutes.\nExtended self-test routine\nrecommended polling time:        ( 149) minutes.\nConveyance self-test routine\nrecommended polling time:        (   5) minutes.\nSCT capabilities:              (0x3035) SCT Status supported.\n                                        SCT Feature Control supported.\n                                        SCT Data Table supported.\n\nSMART Attributes Data Structure revision number: 16\nVendor Specific SMART Attributes with Thresholds:\nID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n  1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       0\n  3 Spin_Up_Time            0x0027   137   136   021    Pre-fail  Always       -       4116\n  4 Start_Stop_Count        0x0032   100   100   000    Old_age   Always       -       168\n  5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n  7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n  9 Power_On_Hours          0x0032   099   098   000    Old_age   Always       -       1086\n 10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n 11 Calibration_Retry_Count 0x0032   100   253   000    Old_age   Always       -       0\n 12 Power_Cycle_Count       0x0032   100   100   000    Old_age   Always       -       20\n192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       3\n193 Load_Cycle_Count        0x0032   199   199   000    Old_age   Always       -       3132\n194 Temperature_Celsius     0x0022   114   102   000    Old_age   Always       -       29\n196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n\nSMART Error Log Version: 1\nNo Errors Logged\n\nSMART Self-test log structure revision number 1\nNum  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error\n# 1  Short offline       Completed without error       00%      1049         - \n\nSMART Selective self-test log data structure revision number 1\n SPAN  MIN_LBA  MAX_LBA  CURRENT_TEST_STATUS\n    1        0        0  Not_testing\n    2        0        0  Not_testing\n    3        0        0  Not_testing\n    4        0        0  Not_testing\n    5        0        0  Not_testing\nSelective self-test flags (0x0):\n  After scanning selected spans, do NOT read-scan remainder of disk.\nIf Selective self-test is pending on power-up, resume after 0 minute delay.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2rgxx", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17exrvk", "is_robot_indexable": true, "report_reasons": null, "author": "rdscorreia", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/storage/comments/17exrvk/smart_and_hdd_longevity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/storage/comments/17exrvk/smart_and_hdd_longevity/", "subreddit_subscribers": 26764, "created_utc": 1698101911.0, "num_crossposts": 1, "media": null, "is_video": false}], "created": 1698154660.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.storage", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/storage/comments/17exrvk/smart_and_hdd_longevity/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fd0zv", "is_robot_indexable": true, "report_reasons": null, "author": "rdscorreia", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_17exrvk", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fd0zv/smart_and_hdd_longevity/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/storage/comments/17exrvk/smart_and_hdd_longevity/", "subreddit_subscribers": 708471, "created_utc": 1698154660.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI am moving all my documents out of Evernote. The goal is to go completely paperless and scan in older paper files that are still needed.\n\nI went with Evernote back before their many issues including security questions and price hikes. But my account was hacked a week ago and even though there were 47 logins from all over the world (including Russia, Korea, etc) within a single day, the only person locked out from my account - was me. (Evernote insists they are secure but even Wendy\u2019s fast food locked my account after a single suspicious login attempt - Evernote did nothing). \n\nRegardless, between never feeling secure with Evernote again and their over 60% price hike, I\u2019m looking to move my data. I\u2019d love to hear your thought on using something like Apple Notes or DevonThink vs a file/folder structure. I know the document software or Notes option is super popular. What are the advantages? Any advice would be greatly appreciated. Thanks in advance!", "author_fullname": "t2_v1lyd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Paperless setup - \u201cnotes\u201d based vs files/folders? (From Evernote)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17f6jp9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698130001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I am moving all my documents out of Evernote. The goal is to go completely paperless and scan in older paper files that are still needed.&lt;/p&gt;\n\n&lt;p&gt;I went with Evernote back before their many issues including security questions and price hikes. But my account was hacked a week ago and even though there were 47 logins from all over the world (including Russia, Korea, etc) within a single day, the only person locked out from my account - was me. (Evernote insists they are secure but even Wendy\u2019s fast food locked my account after a single suspicious login attempt - Evernote did nothing). &lt;/p&gt;\n\n&lt;p&gt;Regardless, between never feeling secure with Evernote again and their over 60% price hike, I\u2019m looking to move my data. I\u2019d love to hear your thought on using something like Apple Notes or DevonThink vs a file/folder structure. I know the document software or Notes option is super popular. What are the advantages? Any advice would be greatly appreciated. Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17f6jp9", "is_robot_indexable": true, "report_reasons": null, "author": "lifereinspired", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17f6jp9/paperless_setup_notes_based_vs_filesfolders_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17f6jp9/paperless_setup_notes_based_vs_filesfolders_from/", "subreddit_subscribers": 708471, "created_utc": 1698130001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Recently bought a 2TB T7 shield and its only giving me constant speeds between 150 MBps and 200MBps write speeds on my windows PC.\nAlso I did run it in the CrystalDiskMark software and i was able to get speeds advertised on them. It\u2019s only when i try to write something onto it for real this happens.\nWhat could be wrong ??", "author_fullname": "t2_58sjzl2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "T7 shield kinda slow", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17fumb0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698201439.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently bought a 2TB T7 shield and its only giving me constant speeds between 150 MBps and 200MBps write speeds on my windows PC.\nAlso I did run it in the CrystalDiskMark software and i was able to get speeds advertised on them. It\u2019s only when i try to write something onto it for real this happens.\nWhat could be wrong ??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fumb0", "is_robot_indexable": true, "report_reasons": null, "author": "nova_pyman", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fumb0/t7_shield_kinda_slow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fumb0/t7_shield_kinda_slow/", "subreddit_subscribers": 708471, "created_utc": 1698201439.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm in the process of uploading tons of family and work videos to the cloud, and I've run into an issue where uploads will get \"stuck\" on certain video files. Nearly all of them are raw videos from my Canon camera (eg files like **MVI\\_0950.mov**).\n\nUpon further inspection, not only are these files not upload-able, but when I try to copy them from one drive to another, the transfer fails midway through, and it says \"cannot read from the source file or disk.\"\n\nHowever, the files are fully playable in VLC. They will also load into my video editing software, but do  crap out as they're being played on the timeline.\n\nThe drive in question is a secondary (E:) on my machine, a **Samsung SSD 980 Pro 2TB**, and it's not that old - bought it 2 years ago with the pre-built machine itself.\n\nI have **no problems reading/writing large amounts of NEW data** to the drive, and anything that I've put there within the lifespan of the drive itself (2 years) has no problem being moved, copied or uploaded.\n\nThe backstory on the \"OLD\" data (created prior to this drive) is that it came off of another computer that failed a while ago, but it was copied from a secondary storage drive (not the C: that failed in the previous machine).\n\nAdditionally, I have the **exact same files** on an external SSD, and those versions ***can*** be moved and copied without issue.\n\nI have run CHECK DISK on the E: and there are no errors. Windows also doesn't show any errors or issues when I inspect the problem files themselves.\n\nGiven the above, I'm mainly trying to deduce:\n\n* Were these errors introduced into the old files when they moved over from the previous machine? ie are the problems specific to the files themselves, or;\n* Should I be worried about this drive?\n\nGrateful for any tools or tips beyond the usual CHKDSK stuff!", "author_fullname": "t2_45w7m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Specific older video files are playable but can't be copied or transferred (\"cannot read from the source file or disk\")", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fgmgl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698164277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m in the process of uploading tons of family and work videos to the cloud, and I&amp;#39;ve run into an issue where uploads will get &amp;quot;stuck&amp;quot; on certain video files. Nearly all of them are raw videos from my Canon camera (eg files like &lt;strong&gt;MVI_0950.mov&lt;/strong&gt;).&lt;/p&gt;\n\n&lt;p&gt;Upon further inspection, not only are these files not upload-able, but when I try to copy them from one drive to another, the transfer fails midway through, and it says &amp;quot;cannot read from the source file or disk.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;However, the files are fully playable in VLC. They will also load into my video editing software, but do  crap out as they&amp;#39;re being played on the timeline.&lt;/p&gt;\n\n&lt;p&gt;The drive in question is a secondary (E:) on my machine, a &lt;strong&gt;Samsung SSD 980 Pro 2TB&lt;/strong&gt;, and it&amp;#39;s not that old - bought it 2 years ago with the pre-built machine itself.&lt;/p&gt;\n\n&lt;p&gt;I have &lt;strong&gt;no problems reading/writing large amounts of NEW data&lt;/strong&gt; to the drive, and anything that I&amp;#39;ve put there within the lifespan of the drive itself (2 years) has no problem being moved, copied or uploaded.&lt;/p&gt;\n\n&lt;p&gt;The backstory on the &amp;quot;OLD&amp;quot; data (created prior to this drive) is that it came off of another computer that failed a while ago, but it was copied from a secondary storage drive (not the C: that failed in the previous machine).&lt;/p&gt;\n\n&lt;p&gt;Additionally, I have the &lt;strong&gt;exact same files&lt;/strong&gt; on an external SSD, and those versions &lt;strong&gt;&lt;em&gt;can&lt;/em&gt;&lt;/strong&gt; be moved and copied without issue.&lt;/p&gt;\n\n&lt;p&gt;I have run CHECK DISK on the E: and there are no errors. Windows also doesn&amp;#39;t show any errors or issues when I inspect the problem files themselves.&lt;/p&gt;\n\n&lt;p&gt;Given the above, I&amp;#39;m mainly trying to deduce:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Were these errors introduced into the old files when they moved over from the previous machine? ie are the problems specific to the files themselves, or;&lt;/li&gt;\n&lt;li&gt;Should I be worried about this drive?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Grateful for any tools or tips beyond the usual CHKDSK stuff!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fgmgl", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyLivingBoyInNY", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fgmgl/specific_older_video_files_are_playable_but_cant/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fgmgl/specific_older_video_files_are_playable_but_cant/", "subreddit_subscribers": 708471, "created_utc": 1698164277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently downloaded my entire iCloud library which was 4tb's and I have it spread out over 4 external 2tb SSD hard drives because that is all I had free at the time. I also have about 8 other external SSD's with random stuff on them. I'd like to transfer all of the iCloud data and also backup the other smaller externals onto 1 larger external HD and then duplicate that onto another larger external. \n\nI'd like to purchase two at least 8TB+ (maybe even 16tb's) hard drives and after checking the usual suspects I'm finding it tough to decide and can't find anything on sale. Any suggestions? ", "author_fullname": "t2_qhc3e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "best deal on 8TB + external HD's?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fsxlm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698196436.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently downloaded my entire iCloud library which was 4tb&amp;#39;s and I have it spread out over 4 external 2tb SSD hard drives because that is all I had free at the time. I also have about 8 other external SSD&amp;#39;s with random stuff on them. I&amp;#39;d like to transfer all of the iCloud data and also backup the other smaller externals onto 1 larger external HD and then duplicate that onto another larger external. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to purchase two at least 8TB+ (maybe even 16tb&amp;#39;s) hard drives and after checking the usual suspects I&amp;#39;m finding it tough to decide and can&amp;#39;t find anything on sale. Any suggestions? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fsxlm", "is_robot_indexable": true, "report_reasons": null, "author": "fatguybike", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fsxlm/best_deal_on_8tb_external_hds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fsxlm/best_deal_on_8tb_external_hds/", "subreddit_subscribers": 708471, "created_utc": 1698196436.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i'm building an ios app that needs to get the transcript and description of a tikotk video, given a link to the video. what should my approach be? is it possible to use a selenium script and not face any limit issues?\n\nthanks", "author_fullname": "t2_4awfqs53", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "scraping tiktok", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fmgss", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698179277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i&amp;#39;m building an ios app that needs to get the transcript and description of a tikotk video, given a link to the video. what should my approach be? is it possible to use a selenium script and not face any limit issues?&lt;/p&gt;\n\n&lt;p&gt;thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fmgss", "is_robot_indexable": true, "report_reasons": null, "author": "lavendercandy19", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fmgss/scraping_tiktok/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fmgss/scraping_tiktok/", "subreddit_subscribers": 708471, "created_utc": 1698179277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys. I just bought three 1TB 2,5\u201d drives from a guy that replaced them with SSDs, and was selling these really cheap and near me. I plan to use one of these on my ps3 and got the other two just because was really cheap. \nOne WD drive was from 2018 with 2000 hours with no bad blocks, other was Toshiba from 2015 with no bad blocks and 2500 hours, and the last one was Toshiba from 2015 too but with 8000 hours and 49 bad blocks. I used easeus partition master to check all hdds. \n\nSo should I stop using this hdd? Is there a way to fix the bad blocks? How can I monitor if bad blocks are increasing without the need to fully scan the disk? Because it took a really long time to scan it.", "author_fullname": "t2_astog32v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Bad sectors on used HDD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fm9mj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698178768.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys. I just bought three 1TB 2,5\u201d drives from a guy that replaced them with SSDs, and was selling these really cheap and near me. I plan to use one of these on my ps3 and got the other two just because was really cheap. \nOne WD drive was from 2018 with 2000 hours with no bad blocks, other was Toshiba from 2015 with no bad blocks and 2500 hours, and the last one was Toshiba from 2015 too but with 8000 hours and 49 bad blocks. I used easeus partition master to check all hdds. &lt;/p&gt;\n\n&lt;p&gt;So should I stop using this hdd? Is there a way to fix the bad blocks? How can I monitor if bad blocks are increasing without the need to fully scan the disk? Because it took a really long time to scan it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fm9mj", "is_robot_indexable": true, "report_reasons": null, "author": "Dependent_Pick8773", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fm9mj/bad_sectors_on_used_hdd/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fm9mj/bad_sectors_on_used_hdd/", "subreddit_subscribers": 708471, "created_utc": 1698178768.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to store some memories for a long time like 40-50years. What would be a good solution? Will a few normal hdd\u2019s work or will they loose data overtime? Im not really gonna access it at all and it will just stay put in place for years without moving. Any advice will be appreciated.", "author_fullname": "t2_3rxtl7pp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I want to store data for a long time.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fja8o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698171166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to store some memories for a long time like 40-50years. What would be a good solution? Will a few normal hdd\u2019s work or will they loose data overtime? Im not really gonna access it at all and it will just stay put in place for years without moving. Any advice will be appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fja8o", "is_robot_indexable": true, "report_reasons": null, "author": "sheryboy77", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fja8o/i_want_to_store_data_for_a_long_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fja8o/i_want_to_store_data_for_a_long_time/", "subreddit_subscribers": 708471, "created_utc": 1698171166.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Kind of a weird thought but ultimately it's all just data. Millions of memories, images, thoughts, history, names, dates, numbers, experiences, opinions, etc.\n\nPersonally, I thought we'd be closer to having some kind of interface and a raw backup of the human brain by now. Even if it was just an 'image' that couldn't be decoded or interpreted yet. I haven't really kept up with any news but I don't think it's happening super soon.\n\nI'd certainly buy a few hard drives to back up my brain though.", "author_fullname": "t2_khe3v13q8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you ever think about how much data is lost forever when someone dies? 100s of TBs? If you could, would you back up your mind? Your families?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17f41p1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.52, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698120364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Kind of a weird thought but ultimately it&amp;#39;s all just data. Millions of memories, images, thoughts, history, names, dates, numbers, experiences, opinions, etc.&lt;/p&gt;\n\n&lt;p&gt;Personally, I thought we&amp;#39;d be closer to having some kind of interface and a raw backup of the human brain by now. Even if it was just an &amp;#39;image&amp;#39; that couldn&amp;#39;t be decoded or interpreted yet. I haven&amp;#39;t really kept up with any news but I don&amp;#39;t think it&amp;#39;s happening super soon.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d certainly buy a few hard drives to back up my brain though.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17f41p1", "is_robot_indexable": true, "report_reasons": null, "author": "DownWithWankers", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17f41p1/do_you_ever_think_about_how_much_data_is_lost/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17f41p1/do_you_ever_think_about_how_much_data_is_lost/", "subreddit_subscribers": 708471, "created_utc": 1698120364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Currently running Synology and I love the OS and everything around it, but it is getting really expensive to actually increase the size.\n\nI have about 110 TB right now, and the prices of expanding are getting a bit out of hand.\n\nSeriously considering dumping Syno all together and moving to something cheaper and friendlier storage expansion wise.\n\nLet's say I am planning on 500TB or so. How would that work? Can I even add 15+ drives to one motherboard? Will I need multiple motherboards? What CPU/GPU will I need to make Plex transcode and work properly on multiple devices at once? I assume I will need an external rack as well for the drives + cooling.\n\nI was hoping someone could maybe make simple list on [https://pcpartpicker.com/list/](https://pcpartpicker.com/list/) of stuff I need to actually do it.\n\nI will do it in small steps when things maybe go on discount so pricing is not a deal breaker, I just want something that can be easily expandable and only limited by the amount of drives I have. So if I want 30 drives, being able to actually have 30 of them.\n\nI build my last few PCs so I can start working on this as I go, and then when it is complete I would just need to move all the drives from my Syno to the new build.\n\nI have these parts from my old PC - [https://pcpartpicker.com/list/KqzPTB](https://pcpartpicker.com/list/KqzPTB).\n\nIf any of those can be reused, even better.", "author_fullname": "t2_ia3wt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hardware list for a 500TB+ media server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17fpm6c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698187102.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently running Synology and I love the OS and everything around it, but it is getting really expensive to actually increase the size.&lt;/p&gt;\n\n&lt;p&gt;I have about 110 TB right now, and the prices of expanding are getting a bit out of hand.&lt;/p&gt;\n\n&lt;p&gt;Seriously considering dumping Syno all together and moving to something cheaper and friendlier storage expansion wise.&lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say I am planning on 500TB or so. How would that work? Can I even add 15+ drives to one motherboard? Will I need multiple motherboards? What CPU/GPU will I need to make Plex transcode and work properly on multiple devices at once? I assume I will need an external rack as well for the drives + cooling.&lt;/p&gt;\n\n&lt;p&gt;I was hoping someone could maybe make simple list on &lt;a href=\"https://pcpartpicker.com/list/\"&gt;https://pcpartpicker.com/list/&lt;/a&gt; of stuff I need to actually do it.&lt;/p&gt;\n\n&lt;p&gt;I will do it in small steps when things maybe go on discount so pricing is not a deal breaker, I just want something that can be easily expandable and only limited by the amount of drives I have. So if I want 30 drives, being able to actually have 30 of them.&lt;/p&gt;\n\n&lt;p&gt;I build my last few PCs so I can start working on this as I go, and then when it is complete I would just need to move all the drives from my Syno to the new build.&lt;/p&gt;\n\n&lt;p&gt;I have these parts from my old PC - &lt;a href=\"https://pcpartpicker.com/list/KqzPTB\"&gt;https://pcpartpicker.com/list/KqzPTB&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;If any of those can be reused, even better.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fpm6c", "is_robot_indexable": true, "report_reasons": null, "author": "nsoifer", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fpm6c/hardware_list_for_a_500tb_media_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17fpm6c/hardware_list_for_a_500tb_media_server/", "subreddit_subscribers": 708471, "created_utc": 1698187102.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have gone through some old posts here regarding the same but couldn't get any conclusion .... Can you guys share your experience which is better ? I am using Mega but i want yo know what better options are there \n\nA cloud storage where you can store and view very easily like the interface of MEGA and be scotfree that your porn won't get deleted ", "author_fullname": "t2_90hr6183", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best cloud storage for porn collection?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ffkt4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698164518.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698161535.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have gone through some old posts here regarding the same but couldn&amp;#39;t get any conclusion .... Can you guys share your experience which is better ? I am using Mega but i want yo know what better options are there &lt;/p&gt;\n\n&lt;p&gt;A cloud storage where you can store and view very easily like the interface of MEGA and be scotfree that your porn won&amp;#39;t get deleted &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ffkt4", "is_robot_indexable": true, "report_reasons": null, "author": "notfk", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ffkt4/best_cloud_storage_for_porn_collection/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ffkt4/best_cloud_storage_for_porn_collection/", "subreddit_subscribers": 708471, "created_utc": 1698161535.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Downloaded it years ago. Maybe 10+ years ago as a torrent pack but I loved the random books it had. From David Sedaris, to one about the life of a male pornstar, to books about murder mysteries. I loved having so many good books at once. Then my iPad broke and I never backed up or saved that collection anywhere. Might have been a hundered\n\nIs there any similar collections? There\u2019s so many books it\u2019s overwhelming and that book pack made it so easy to pick one and enjoy it.", "author_fullname": "t2_945qs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Long shot, but looking for a fiction book collection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17f4l27", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698122251.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Downloaded it years ago. Maybe 10+ years ago as a torrent pack but I loved the random books it had. From David Sedaris, to one about the life of a male pornstar, to books about murder mysteries. I loved having so many good books at once. Then my iPad broke and I never backed up or saved that collection anywhere. Might have been a hundered&lt;/p&gt;\n\n&lt;p&gt;Is there any similar collections? There\u2019s so many books it\u2019s overwhelming and that book pack made it so easy to pick one and enjoy it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17f4l27", "is_robot_indexable": true, "report_reasons": null, "author": "jescereal", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17f4l27/long_shot_but_looking_for_a_fiction_book/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17f4l27/long_shot_but_looking_for_a_fiction_book/", "subreddit_subscribers": 708471, "created_utc": 1698122251.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_2pxck4j6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "Are these drives okay to use together in a 2-bay nas in RAID 1?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"64n5pwi5g6wb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 116, "x": 108, "u": "https://preview.redd.it/64n5pwi5g6wb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=e66d1450ef9f4a21d2de2d8699263fa5c4705aa1"}, {"y": 233, "x": 216, "u": "https://preview.redd.it/64n5pwi5g6wb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=9d63cf02443ef0fb2f32a017bf29c5fec92f3b04"}, {"y": 345, "x": 320, "u": "https://preview.redd.it/64n5pwi5g6wb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5c3f731716a1ef446fe60c74604c10bcd8b7fe19"}], "s": {"y": 640, "x": 593, "u": "https://preview.redd.it/64n5pwi5g6wb1.png?width=593&amp;format=png&amp;auto=webp&amp;s=adb3d7b5fede3087d9c7623aab73a6b9e92223d8"}, "id": "64n5pwi5g6wb1"}, "9g1sri75g6wb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 115, "x": 108, "u": "https://preview.redd.it/9g1sri75g6wb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b467174150fb7ba57f0af2b442a64769843a66f1"}, {"y": 230, "x": 216, "u": "https://preview.redd.it/9g1sri75g6wb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d2122a1505376ac1fbb9743e13e54256410c60ad"}, {"y": 340, "x": 320, "u": "https://preview.redd.it/9g1sri75g6wb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=dda9c72f5fec5975f4b9cc205abd792e8741bc25"}], "s": {"y": 573, "x": 538, "u": "https://preview.redd.it/9g1sri75g6wb1.png?width=538&amp;format=png&amp;auto=webp&amp;s=78b1797e14a41c6590421ba9d981f09bbaf44bc8"}, "id": "9g1sri75g6wb1"}}, "name": "t3_17fgxno", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.36, "author_flair_background_color": null, "ups": 0, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"caption": "I plan on using these drives to store video footage and have a backup. They are both the 8tb Seagate Ironwolf drives. Im not sure if they are slightly different though. ", "media_id": "9g1sri75g6wb1", "id": 346753963}, {"media_id": "64n5pwi5g6wb1", "id": 346753964}]}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/5BzRU0Q4irtaP_EySI-ljO5v4nQHvGgG9g1vt-jQh6E.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698165086.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/17fgxno", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17fgxno", "is_robot_indexable": true, "report_reasons": null, "author": "BDOG1496", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17fgxno/are_these_drives_okay_to_use_together_in_a_2bay/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/17fgxno", "subreddit_subscribers": 708471, "created_utc": 1698165086.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, so for a project I'd need to download some of the buildings shown on the website here. Is there any way to download separate buildings? thx\n\n[https://www.wien.gv.at/stadtplan3d/#/](https://www.wien.gv.at/stadtplan3d/#/)", "author_fullname": "t2_28wkcmtm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "help me download this 3d model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17f6nub", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698130503.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, so for a project I&amp;#39;d need to download some of the buildings shown on the website here. Is there any way to download separate buildings? thx&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.wien.gv.at/stadtplan3d/#/\"&gt;https://www.wien.gv.at/stadtplan3d/#/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17f6nub", "is_robot_indexable": true, "report_reasons": null, "author": "kvier", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17f6nub/help_me_download_this_3d_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17f6nub/help_me_download_this_3d_model/", "subreddit_subscribers": 708471, "created_utc": 1698130503.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}