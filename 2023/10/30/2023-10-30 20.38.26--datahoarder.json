{"kind": "Listing", "data": {"after": "t3_17jsx37", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "XeNTaX was a website with a 20-year history dedicated to reverse engineering video games. The site's forum included a lot of technical discussion, speculation, etc that can't be found anywhere else. The reverse engineering community already lost a similar forum, Zenhax, earlier this year.\n\nThere is a fundraiser to archive the site's modding tools &amp; wiki, but the forum itself will be lost once the site shutters in less than 2 weeks (in fact, it's already privated).\n\nAnyway, the site's owner has been openly opposed to archival efforts. I've seen full, functional backups of the forum go offline after he's requested they be taken down. He's also floating the idea of requesting that the Internet Archive delete their copies of the site's webpages. \n\nThis is all completely within his rights to do, and he has valid reasons for it, but still, the information contained within this forum is invaluable.\n\nThat being said, I suggest that anyone interested in video game reverse engineering try to save their own backups (from the Internet Archive) for personal use, before those are gone too.", "author_fullname": "t2_uhrmyyh0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "20 years of game hacking knowledge about to disappear. Site admin taking down backups, including Internet Archive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17je8fd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 112, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 112, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698617864.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;XeNTaX was a website with a 20-year history dedicated to reverse engineering video games. The site&amp;#39;s forum included a lot of technical discussion, speculation, etc that can&amp;#39;t be found anywhere else. The reverse engineering community already lost a similar forum, Zenhax, earlier this year.&lt;/p&gt;\n\n&lt;p&gt;There is a fundraiser to archive the site&amp;#39;s modding tools &amp;amp; wiki, but the forum itself will be lost once the site shutters in less than 2 weeks (in fact, it&amp;#39;s already privated).&lt;/p&gt;\n\n&lt;p&gt;Anyway, the site&amp;#39;s owner has been openly opposed to archival efforts. I&amp;#39;ve seen full, functional backups of the forum go offline after he&amp;#39;s requested they be taken down. He&amp;#39;s also floating the idea of requesting that the Internet Archive delete their copies of the site&amp;#39;s webpages. &lt;/p&gt;\n\n&lt;p&gt;This is all completely within his rights to do, and he has valid reasons for it, but still, the information contained within this forum is invaluable.&lt;/p&gt;\n\n&lt;p&gt;That being said, I suggest that anyone interested in video game reverse engineering try to save their own backups (from the Internet Archive) for personal use, before those are gone too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17je8fd", "is_robot_indexable": true, "report_reasons": null, "author": "Doubloon00", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17je8fd/20_years_of_game_hacking_knowledge_about_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17je8fd/20_years_of_game_hacking_knowledge_about_to/", "subreddit_subscribers": 709500, "created_utc": 1698617864.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A decade old camera review channel on YouTube, [DigitalRev](https://youtube.com/@DigitalrevTV?si=YNltIv1lb2sBU76C), has removed hundreds of old videos from their channel. Only about 9 remain.\n\nWhile I\u2019m not a big camera guy, and wasn\u2019t aware of this channel beforehand, I heard about this on [Linus Tech Tips\u2019 WAN Show](https://youtu.be/ZOQOQqxemOI?t=9375) - apparently the page was a trusted resource for a lot of people.\n\nThe good news is, it does appear to be mostly(?) archived via [archive.org](https://archive.org/search?query=digitalrev). Not sure why it was pulled from YouTube, so there is a risk it could be pulled from Archive as well - if anyone wants to backup, now might be a good time.", "author_fullname": "t2_8zsdr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DigitalRev has deleted almost all of their content", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jklpm", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 74, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 74, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698637279.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A decade old camera review channel on YouTube, &lt;a href=\"https://youtube.com/@DigitalrevTV?si=YNltIv1lb2sBU76C\"&gt;DigitalRev&lt;/a&gt;, has removed hundreds of old videos from their channel. Only about 9 remain.&lt;/p&gt;\n\n&lt;p&gt;While I\u2019m not a big camera guy, and wasn\u2019t aware of this channel beforehand, I heard about this on &lt;a href=\"https://youtu.be/ZOQOQqxemOI?t=9375\"&gt;Linus Tech Tips\u2019 WAN Show&lt;/a&gt; - apparently the page was a trusted resource for a lot of people.&lt;/p&gt;\n\n&lt;p&gt;The good news is, it does appear to be mostly(?) archived via &lt;a href=\"https://archive.org/search?query=digitalrev\"&gt;archive.org&lt;/a&gt;. Not sure why it was pulled from YouTube, so there is a risk it could be pulled from Archive as well - if anyone wants to backup, now might be a good time.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/-hew7a9ulvDoQZn07NOwxFBL8YgjQzyWDDn6fdzFweg.jpg?auto=webp&amp;s=4048da8fde984a508aaa913a4258ff977d90501f", "width": 900, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/-hew7a9ulvDoQZn07NOwxFBL8YgjQzyWDDn6fdzFweg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=90c3a121087aa9de1e1f903924483e21176fe2de", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/-hew7a9ulvDoQZn07NOwxFBL8YgjQzyWDDn6fdzFweg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4cdc5890ed7d33eaddb953b44288243050540d6", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/-hew7a9ulvDoQZn07NOwxFBL8YgjQzyWDDn6fdzFweg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e7a5d9df72592b5fd259d5f8de4dd1fb483c7c95", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/-hew7a9ulvDoQZn07NOwxFBL8YgjQzyWDDn6fdzFweg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=5e919f63f22b6475d85c5f25e48754494f267c02", "width": 640, "height": 640}], "variants": {}, "id": "f5d7WODrgKNguUEaafrm_pM_pAu7O34IamnWsq0S4MI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jklpm", "is_robot_indexable": true, "report_reasons": null, "author": "Z3ppelinDude93", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jklpm/digitalrev_has_deleted_almost_all_of_their_content/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jklpm/digitalrev_has_deleted_almost_all_of_their_content/", "subreddit_subscribers": 709500, "created_utc": 1698637279.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_8kxat", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Western Digital is spinning off its flash memory business as sales decline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_17jvhc0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "ups": 81, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 81, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/OaPpc1JC_Sawltm5OlKgwx1QX83A0JLFjGRZPP8-STU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698678327.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "theverge.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.theverge.com/2023/10/30/23938334/western-digital-separating-hard-drive-flash-business", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6pEGelnMYQuTFUAV1uT6N7HSXGSxc_ltiBVGrptr21A.jpg?auto=webp&amp;s=e96539b51ddc0d02dbb28eb496d15b4823e8f998", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/6pEGelnMYQuTFUAV1uT6N7HSXGSxc_ltiBVGrptr21A.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=48713cdc7c0c4247ddf7e3e16cfdf890778d81f6", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/6pEGelnMYQuTFUAV1uT6N7HSXGSxc_ltiBVGrptr21A.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7d59b42b536b78710dc53064a7bff37602843f80", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/6pEGelnMYQuTFUAV1uT6N7HSXGSxc_ltiBVGrptr21A.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c0ee318ed87c84b07d9db6d0a2fa0de0c8066efb", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/6pEGelnMYQuTFUAV1uT6N7HSXGSxc_ltiBVGrptr21A.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b75fba3884f0f114ac3e4fc6b9a15924f37cdaf3", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/6pEGelnMYQuTFUAV1uT6N7HSXGSxc_ltiBVGrptr21A.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ea0682a44d32b359735480a7c8242830ebdb3c59", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/6pEGelnMYQuTFUAV1uT6N7HSXGSxc_ltiBVGrptr21A.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f0452187c3c60a380ed197c0814df94a575db905", "width": 1080, "height": 565}], "variants": {}, "id": "Hd4VynfJhz3m4QBmtw5riodt6Eyrn_Lhq7hW-E28P1c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jvhc0", "is_robot_indexable": true, "report_reasons": null, "author": "ragewinch", "discussion_type": null, "num_comments": 23, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jvhc0/western_digital_is_spinning_off_its_flash_memory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.theverge.com/2023/10/30/23938334/western-digital-separating-hard-drive-flash-business", "subreddit_subscribers": 709500, "created_utc": 1698678327.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "\nHi folks, \n\nHope you\u2019re having a lovely day. \n\nLooking for suggestions on what to do with 4 x 4TB Western Digital My Passport. I used to use rock these bad boys before I made the jump to Synology NAS. \n\nWhat do you guys do with old external hard drives?", "author_fullname": "t2_41wu1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Suggestions: 4 x 4 TB WD MyPassport", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_17jknr5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/8KCMvOQprr30uR2Q0FctNMD-_YCU3Yrupbh_0GqfKl0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698637495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks, &lt;/p&gt;\n\n&lt;p&gt;Hope you\u2019re having a lovely day. &lt;/p&gt;\n\n&lt;p&gt;Looking for suggestions on what to do with 4 x 4TB Western Digital My Passport. I used to use rock these bad boys before I made the jump to Synology NAS. &lt;/p&gt;\n\n&lt;p&gt;What do you guys do with old external hard drives?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/6zl2acidh9xb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/6zl2acidh9xb1.jpg?auto=webp&amp;s=0c74e1c59ff920dde69ab36783137b005f46af0a", "width": 3024, "height": 4032}, "resolutions": [{"url": "https://preview.redd.it/6zl2acidh9xb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=df80055fac033c909f06c8f78021865899f733ed", "width": 108, "height": 144}, {"url": "https://preview.redd.it/6zl2acidh9xb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c756d84be323b6d34c4996e097751dd6e11daa81", "width": 216, "height": 288}, {"url": "https://preview.redd.it/6zl2acidh9xb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=bd359ac7ab0e4d360822fd08437cb743a3d0d8e1", "width": 320, "height": 426}, {"url": "https://preview.redd.it/6zl2acidh9xb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d5c2900458368b3e0276a9df20699976be0e1f80", "width": 640, "height": 853}, {"url": "https://preview.redd.it/6zl2acidh9xb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e08fd275fb4a15690add5e504c228069a27be7fa", "width": 960, "height": 1280}, {"url": "https://preview.redd.it/6zl2acidh9xb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d675d46bf148708324101361fd72fe5d6c1a7c7c", "width": 1080, "height": 1440}], "variants": {}, "id": "txsx27BOFSjXLctpTof8oVCcN2z58Aon4h4yFHNzvJc"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jknr5", "is_robot_indexable": true, "report_reasons": null, "author": "jonjonijanagan", "discussion_type": null, "num_comments": 19, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jknr5/seeking_suggestions_4_x_4_tb_wd_mypassport/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/6zl2acidh9xb1.jpg", "subreddit_subscribers": 709500, "created_utc": 1698637495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Gday  \nI have some old PC games that I kept of when I was younger. Games i REALLY loved, but realistically-speaking, I will most likely never play again.\n\n(These are all pre-steam games)\n\nIs it worth grabbing an ISO of the disc and keeping it just in case? Will an Win XP game play on Win11 (or newer) one day?  \n\n\nor is it a bin-and-forget?  \n\n\nThank you", "author_fullname": "t2_timugpjb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Old PC games", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jk3l6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698635554.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Gday&lt;br/&gt;\nI have some old PC games that I kept of when I was younger. Games i REALLY loved, but realistically-speaking, I will most likely never play again.&lt;/p&gt;\n\n&lt;p&gt;(These are all pre-steam games)&lt;/p&gt;\n\n&lt;p&gt;Is it worth grabbing an ISO of the disc and keeping it just in case? Will an Win XP game play on Win11 (or newer) one day?  &lt;/p&gt;\n\n&lt;p&gt;or is it a bin-and-forget?  &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jk3l6", "is_robot_indexable": true, "report_reasons": null, "author": "Downtown-Pear-6509", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jk3l6/old_pc_games/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jk3l6/old_pc_games/", "subreddit_subscribers": 709500, "created_utc": 1698635554.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I read a lot of newspapers and like to save interesting articles but have not yet found a satisfactory way to do this.\n\nMost of the time i just \"print\" the article as a pdf, but often the formatting is terrible. Saving as pdf in reader mode works better but it's not working with images in an article. Saving the web page as a whole is also not the best option because it also saves a lot of data beside the article I'm not interested in.\n\nWith all these approaches there is also the major problem that the metadata and tags have to be set manually and I can't ensure the usability and searchability of my ever growing collection.\n\nAre there any tools to accomplish in at least someways:\n\n* readability\n* searchability\n* scalability\n* automatic tagging and proper metadata when adding articles\n* (bonus) future proofing and possibility to export anything\n\nThanks in advance!", "author_fullname": "t2_a0c14m06", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to archive online newspaper articles?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jnv9g", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698650791.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I read a lot of newspapers and like to save interesting articles but have not yet found a satisfactory way to do this.&lt;/p&gt;\n\n&lt;p&gt;Most of the time i just &amp;quot;print&amp;quot; the article as a pdf, but often the formatting is terrible. Saving as pdf in reader mode works better but it&amp;#39;s not working with images in an article. Saving the web page as a whole is also not the best option because it also saves a lot of data beside the article I&amp;#39;m not interested in.&lt;/p&gt;\n\n&lt;p&gt;With all these approaches there is also the major problem that the metadata and tags have to be set manually and I can&amp;#39;t ensure the usability and searchability of my ever growing collection.&lt;/p&gt;\n\n&lt;p&gt;Are there any tools to accomplish in at least someways:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;readability&lt;/li&gt;\n&lt;li&gt;searchability&lt;/li&gt;\n&lt;li&gt;scalability&lt;/li&gt;\n&lt;li&gt;automatic tagging and proper metadata when adding articles&lt;/li&gt;\n&lt;li&gt;(bonus) future proofing and possibility to export anything&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jnv9g", "is_robot_indexable": true, "report_reasons": null, "author": "v4l3r1u5", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jnv9g/how_to_archive_online_newspaper_articles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jnv9g/how_to_archive_online_newspaper_articles/", "subreddit_subscribers": 709500, "created_utc": 1698650791.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello All,\n\nI recently discovered that I had bought a 4TB WD blue drive from frys.com in 2017 to install in my desktop PC at that time, but never did it due to reasons.\n\nNow, I do not have desktop any more, just an ultrabook, so I'm trying to use it with an external HDD enclosure. I initially used the one from Sabrent, but I got some errors while transferring files and I ended up losing the files, this made me suspect if it's a disk issue or the sabrent controller issue. I checked the drive with HD Sentinel's S.M.A.R.T. analysis and it basically told me that the drive is almost dead. This disappointed me as Frys does not exist anymore and also the warranty is for 2 years. The Read + WRITE + read test (refresh data area) Surface test would hang after a few hours.\n\nBelow is the smartctl logs:\n\nxx@xxx-xxx:~&gt; sudo smartctl -i /dev/sda1\nsmartctl 7.4 2023-08-01 r5530 [x86_64-linux-6.5.8-1-default] (SUSE RPM)\nCopyright (C) 2002-23, Bruce Allen, Christian Franke, www.smartmontools.org\n\n=== START OF INFORMATION SECTION ===\nVendor:               TO Exter\nProduct:              nal USB 3.0\nRevision:             0104\nCompliance:           SPC-4\nUser Capacity:        4,000,787,030,016 bytes [4.00 TB]\nLogical block size:   512 bytes\nPhysical block size:  4096 bytes\nLU is fully provisioned\nLogical Unit id:      0x3020150331000810\nSerial number:        2015033100081\nDevice type:          disk\nLocal Time is:        Mon Oct 30 11:01:24 2023 EDT\nSMART support is:     Unavailable - device lacks SMART capability.\n\nxx@xxx-xxx:~&gt; sudo smartctl -i -d sat /dev/sda1\nsmartctl 7.4 2023-08-01 r5530 [x86_64-linux-6.5.8-1-default] (SUSE RPM)\nCopyright (C) 2002-23, Bruce Allen, Christian Franke, www.smartmontools.org\n\n=== START OF INFORMATION SECTION ===\nModel Family:     Western Digital Blue\nDevice Model:     WDC WD40EZRZ-00GXCB0\nSerial Number:    WD-XXXXXXXXXXXX\nLU WWN Device Id: 5 0014ee 2646f4f76\nFirmware Version: 80.00A80\nUser Capacity:    4,000,787,030,016 bytes [4.00 TB]\nSector Sizes:     512 bytes logical, 4096 bytes physical\nRotation Rate:    5400 rpm\nForm Factor:      3.5 inches\nDevice is:        In smartctl database 7.3/5528\nATA Version is:   ACS-3 T13/2161-D revision 5\nSATA Version is:  SATA 3.1, 6.0 Gb/s (current: 6.0 Gb/s)\nLocal Time is:    Mon Oct 30 11:01:55 2023 EDT\nSMART support is: Available - device has SMART capability.\nSMART support is: Enabled\n\n\nHoping that the issue is with the external HDD enclosure, I bought the 3.5 HDD enclosures by UGreen and Orico. UGreen also gave the same problem. So, I'm now trying with an Orico one.  \n\nI searched a lot and found that badblocks is best option to test the drive, so therefore I installed openSuse (I've been wanting to install it for a long time) and I ran the badblocks tool.\n\nBelow is the output\n\nxx@xxx-xxx:~&gt; sudo badblocks -s /dev/sda1\n[sudo] password for root: \nChecking for bad blocks (read-only test): 15367628done, 1:57 elapsed. (0/0/0 errors)\n15367629done, 2:01 elapsed. (1/0/0 errors)\n15367630done, 2:05 elapsed. (2/0/0 errors)\n15367631done, 2:10 elapsed. (3/0/0 errors)\n15423768done, 2:46 elapsed. (4/0/0 errors)\n15423769done, 2:50 elapsed. (5/0/0 errors)\n15423770done, 2:55 elapsed. (6/0/0 errors)\n15423771done, 2:59 elapsed. (7/0/0 errors)\n^C4.69% done, 20:07 elapsed. (8/0/0 errors)\n\nInterrupted at block 183444352\nxx@xxx-xxx:~&gt; badblocks -wvs /dev/sda\nsda   sda1  \nxx@xxx-xxx:~&gt; badblocks -wvs /dev/sda\nsda   sda1  \nxx@xxx-xxx:~&gt; badblocks -wvs /dev/sda1\nAbsolute path to 'badblocks' is '/usr/sbin/badblocks', so running it may require superuser privileges (eg. root).\nxx@xxx-xxx:~&gt; sudo badblocks -wvs /dev/sda1\n[sudo] password for root: \nChecking for bad blocks in read-write mode\nFrom block 0 to 3907016703\nTesting with pattern 0xaa: done                                                 \nReading and comparing: done                                                 \nTesting with pattern 0x55: done                                                 \nReading and comparing: done                                                 \nTesting with pattern 0xff: done                                                 \nReading and comparing: done                                                 \nTesting with pattern 0x00: done                                                 \nReading and comparing: done                                                 \nPass completed, 0 bad blocks found. (0/0/0 errors)\nxx@xxx-xxx:~&gt; sudo badblocks -s /dev/sda1\n[sudo] password for root: \nChecking for bad blocks (read-only test): 110932% done, 0:24 elapsed. (0/0/0 errors)\n110933% done, 0:29 elapsed. (1/0/0 errors)\n110944% done, 0:34 elapsed. (2/0/0 errors)\n110945% done, 0:39 elapsed. (3/0/0 errors)\n110948% done, 0:43 elapsed. (4/0/0 errors)\n114608% done, 1:13 elapsed. (5/0/0 errors)\n^C0.06% done, 1:44 elapsed. (6/0/0 errors)\n\nInterrupted at block 2345792\nxx@xxx-xxx:~&gt; sudo badblocks -s /dev/sda1\nChecking for bad blocks (read-only test): ^C7.26% done, 28:52 elapsed. (0/0/0 errors)\n\nInitially I tried the read test and it immediately started to give me errors, so i decided to try the destructive test. The test ran for about 76 hours and it gave no errors at all.\n\nSince the test completed overnight when I was sleeping, I decided to try the read test again and it gave me errors, so i immediately stopped the test and tried again and till 7.26% it did not give any errors.\n\nThis makes me think that the HDD enclosure takes a lot more time to initialize the disk which is giving errors, but once the drive is started, the errors don't happen. Something like waking up from sleep to run vs walking and then running.\n\nSo with the badblocks giving no errors on the write test, can I conclude that the issue is with the cheap $25 3.5\" HDD enclosures in amazon? If yes, then can someone recommend a good HDD enclosure? or Is the drive not safe to use?", "author_fullname": "t2_8tmbl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Badblocks and inconsistent results with WD BLUE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jzbdu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698688471.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello All,&lt;/p&gt;\n\n&lt;p&gt;I recently discovered that I had bought a 4TB WD blue drive from frys.com in 2017 to install in my desktop PC at that time, but never did it due to reasons.&lt;/p&gt;\n\n&lt;p&gt;Now, I do not have desktop any more, just an ultrabook, so I&amp;#39;m trying to use it with an external HDD enclosure. I initially used the one from Sabrent, but I got some errors while transferring files and I ended up losing the files, this made me suspect if it&amp;#39;s a disk issue or the sabrent controller issue. I checked the drive with HD Sentinel&amp;#39;s S.M.A.R.T. analysis and it basically told me that the drive is almost dead. This disappointed me as Frys does not exist anymore and also the warranty is for 2 years. The Read + WRITE + read test (refresh data area) Surface test would hang after a few hours.&lt;/p&gt;\n\n&lt;p&gt;Below is the smartctl logs:&lt;/p&gt;\n\n&lt;p&gt;xx@xxx-xxx:~&amp;gt; sudo smartctl -i /dev/sda1\nsmartctl 7.4 2023-08-01 r5530 [x86_64-linux-6.5.8-1-default] (SUSE RPM)\nCopyright (C) 2002-23, Bruce Allen, Christian Franke, &lt;a href=\"http://www.smartmontools.org\"&gt;www.smartmontools.org&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;=== START OF INFORMATION SECTION ===\nVendor:               TO Exter\nProduct:              nal USB 3.0\nRevision:             0104\nCompliance:           SPC-4\nUser Capacity:        4,000,787,030,016 bytes [4.00 TB]\nLogical block size:   512 bytes\nPhysical block size:  4096 bytes\nLU is fully provisioned\nLogical Unit id:      0x3020150331000810\nSerial number:        2015033100081\nDevice type:          disk\nLocal Time is:        Mon Oct 30 11:01:24 2023 EDT\nSMART support is:     Unavailable - device lacks SMART capability.&lt;/p&gt;\n\n&lt;p&gt;xx@xxx-xxx:~&amp;gt; sudo smartctl -i -d sat /dev/sda1\nsmartctl 7.4 2023-08-01 r5530 [x86_64-linux-6.5.8-1-default] (SUSE RPM)\nCopyright (C) 2002-23, Bruce Allen, Christian Franke, &lt;a href=\"http://www.smartmontools.org\"&gt;www.smartmontools.org&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;=== START OF INFORMATION SECTION ===\nModel Family:     Western Digital Blue\nDevice Model:     WDC WD40EZRZ-00GXCB0\nSerial Number:    WD-XXXXXXXXXXXX\nLU WWN Device Id: 5 0014ee 2646f4f76\nFirmware Version: 80.00A80\nUser Capacity:    4,000,787,030,016 bytes [4.00 TB]\nSector Sizes:     512 bytes logical, 4096 bytes physical\nRotation Rate:    5400 rpm\nForm Factor:      3.5 inches\nDevice is:        In smartctl database 7.3/5528\nATA Version is:   ACS-3 T13/2161-D revision 5\nSATA Version is:  SATA 3.1, 6.0 Gb/s (current: 6.0 Gb/s)\nLocal Time is:    Mon Oct 30 11:01:55 2023 EDT\nSMART support is: Available - device has SMART capability.\nSMART support is: Enabled&lt;/p&gt;\n\n&lt;p&gt;Hoping that the issue is with the external HDD enclosure, I bought the 3.5 HDD enclosures by UGreen and Orico. UGreen also gave the same problem. So, I&amp;#39;m now trying with an Orico one.  &lt;/p&gt;\n\n&lt;p&gt;I searched a lot and found that badblocks is best option to test the drive, so therefore I installed openSuse (I&amp;#39;ve been wanting to install it for a long time) and I ran the badblocks tool.&lt;/p&gt;\n\n&lt;p&gt;Below is the output&lt;/p&gt;\n\n&lt;p&gt;xx@xxx-xxx:~&amp;gt; sudo badblocks -s /dev/sda1\n[sudo] password for root: \nChecking for bad blocks (read-only test): 15367628done, 1:57 elapsed. (0/0/0 errors)\n15367629done, 2:01 elapsed. (1/0/0 errors)\n15367630done, 2:05 elapsed. (2/0/0 errors)\n15367631done, 2:10 elapsed. (3/0/0 errors)\n15423768done, 2:46 elapsed. (4/0/0 errors)\n15423769done, 2:50 elapsed. (5/0/0 errors)\n15423770done, 2:55 elapsed. (6/0/0 errors)\n15423771done, 2:59 elapsed. (7/0/0 errors)\n&lt;sup&gt;C4.69%&lt;/sup&gt; done, 20:07 elapsed. (8/0/0 errors)&lt;/p&gt;\n\n&lt;p&gt;Interrupted at block 183444352\nxx@xxx-xxx:~&amp;gt; badblocks -wvs /dev/sda\nsda   sda1&lt;br/&gt;\nxx@xxx-xxx:~&amp;gt; badblocks -wvs /dev/sda\nsda   sda1&lt;br/&gt;\nxx@xxx-xxx:~&amp;gt; badblocks -wvs /dev/sda1\nAbsolute path to &amp;#39;badblocks&amp;#39; is &amp;#39;/usr/sbin/badblocks&amp;#39;, so running it may require superuser privileges (eg. root).\nxx@xxx-xxx:~&amp;gt; sudo badblocks -wvs /dev/sda1\n[sudo] password for root: \nChecking for bad blocks in read-write mode\nFrom block 0 to 3907016703\nTesting with pattern 0xaa: done&lt;br/&gt;\nReading and comparing: done&lt;br/&gt;\nTesting with pattern 0x55: done&lt;br/&gt;\nReading and comparing: done&lt;br/&gt;\nTesting with pattern 0xff: done&lt;br/&gt;\nReading and comparing: done&lt;br/&gt;\nTesting with pattern 0x00: done&lt;br/&gt;\nReading and comparing: done&lt;br/&gt;\nPass completed, 0 bad blocks found. (0/0/0 errors)\nxx@xxx-xxx:~&amp;gt; sudo badblocks -s /dev/sda1\n[sudo] password for root: \nChecking for bad blocks (read-only test): 110932% done, 0:24 elapsed. (0/0/0 errors)\n110933% done, 0:29 elapsed. (1/0/0 errors)\n110944% done, 0:34 elapsed. (2/0/0 errors)\n110945% done, 0:39 elapsed. (3/0/0 errors)\n110948% done, 0:43 elapsed. (4/0/0 errors)\n114608% done, 1:13 elapsed. (5/0/0 errors)\n&lt;sup&gt;C0.06%&lt;/sup&gt; done, 1:44 elapsed. (6/0/0 errors)&lt;/p&gt;\n\n&lt;p&gt;Interrupted at block 2345792\nxx@xxx-xxx:~&amp;gt; sudo badblocks -s /dev/sda1\nChecking for bad blocks (read-only test): &lt;sup&gt;C7.26%&lt;/sup&gt; done, 28:52 elapsed. (0/0/0 errors)&lt;/p&gt;\n\n&lt;p&gt;Initially I tried the read test and it immediately started to give me errors, so i decided to try the destructive test. The test ran for about 76 hours and it gave no errors at all.&lt;/p&gt;\n\n&lt;p&gt;Since the test completed overnight when I was sleeping, I decided to try the read test again and it gave me errors, so i immediately stopped the test and tried again and till 7.26% it did not give any errors.&lt;/p&gt;\n\n&lt;p&gt;This makes me think that the HDD enclosure takes a lot more time to initialize the disk which is giving errors, but once the drive is started, the errors don&amp;#39;t happen. Something like waking up from sleep to run vs walking and then running.&lt;/p&gt;\n\n&lt;p&gt;So with the badblocks giving no errors on the write test, can I conclude that the issue is with the cheap $25 3.5&amp;quot; HDD enclosures in amazon? If yes, then can someone recommend a good HDD enclosure? or Is the drive not safe to use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jzbdu", "is_robot_indexable": true, "report_reasons": null, "author": "findingthyself", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jzbdu/badblocks_and_inconsistent_results_with_wd_blue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jzbdu/badblocks_and_inconsistent_results_with_wd_blue/", "subreddit_subscribers": 709500, "created_utc": 1698688471.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Context: I'm buying drives for my first NAS, I don't have a lot of experience.\n\nThe amazon page says \"new\" and has no mention about recertified drives. When it arrived today on the drive's sticker there was explicitly said that it has been recertified by Seagate.\n\nWhen I went to look for the warranty on Seagate's website I got a message to contact the seller for warranty claims instead which was not very reassuring.\n\nBy looking at [older posts](https://www.reddit.com/r/DataHoarder/comments/f1zl1q/recertified_hard_drives/) it sounds like it should be ok since it's recertified by the manufacturer and not some third party but still.. \n\nIs it normal to get recertified drives when buying new ones or should I return it and look for another seller?", "author_fullname": "t2_89axlrr3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Got a recertified drive instead of a new one. Should I use it anyways?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jxtg6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698684521.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Context: I&amp;#39;m buying drives for my first NAS, I don&amp;#39;t have a lot of experience.&lt;/p&gt;\n\n&lt;p&gt;The amazon page says &amp;quot;new&amp;quot; and has no mention about recertified drives. When it arrived today on the drive&amp;#39;s sticker there was explicitly said that it has been recertified by Seagate.&lt;/p&gt;\n\n&lt;p&gt;When I went to look for the warranty on Seagate&amp;#39;s website I got a message to contact the seller for warranty claims instead which was not very reassuring.&lt;/p&gt;\n\n&lt;p&gt;By looking at &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/f1zl1q/recertified_hard_drives/\"&gt;older posts&lt;/a&gt; it sounds like it should be ok since it&amp;#39;s recertified by the manufacturer and not some third party but still.. &lt;/p&gt;\n\n&lt;p&gt;Is it normal to get recertified drives when buying new ones or should I return it and look for another seller?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jxtg6", "is_robot_indexable": true, "report_reasons": null, "author": "billy4479", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jxtg6/got_a_recertified_drive_instead_of_a_new_one/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jxtg6/got_a_recertified_drive_instead_of_a_new_one/", "subreddit_subscribers": 709500, "created_utc": 1698684521.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Long time lurker, lifelong digital hoarder.\n\nAs AI enters a period of scrutiny (see Bidens Executive Order today), I'm very interested in archiving the available generative AI Models and related tools to interface with them. I'm a novice at this point (using mostly Huggingface, ChatGPT, Midjourney) but I know StableDiffusion (and Llama?) are models that run locally. Any others?\n\nHelp me build the list of everything we should collect to maintain access to this stuff if it disappears behind paywalls or censorship.", "author_fullname": "t2_hjmnnoylc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archive Generative AI Models/Tools", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jxhi9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698683641.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Long time lurker, lifelong digital hoarder.&lt;/p&gt;\n\n&lt;p&gt;As AI enters a period of scrutiny (see Bidens Executive Order today), I&amp;#39;m very interested in archiving the available generative AI Models and related tools to interface with them. I&amp;#39;m a novice at this point (using mostly Huggingface, ChatGPT, Midjourney) but I know StableDiffusion (and Llama?) are models that run locally. Any others?&lt;/p&gt;\n\n&lt;p&gt;Help me build the list of everything we should collect to maintain access to this stuff if it disappears behind paywalls or censorship.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jxhi9", "is_robot_indexable": true, "report_reasons": null, "author": "globnester", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jxhi9/archive_generative_ai_modelstools/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jxhi9/archive_generative_ai_modelstools/", "subreddit_subscribers": 709500, "created_utc": 1698683641.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There is this guy on Github making an open source program/file that people can simply copy and paste onto their sites so that devtool/inspect element is impossible to use, making data hoarding and scraping impossible.\n\n[https://github.com/theajack/disable-devtool](https://github.com/theajack/disable-devtool)\n\nHow are we supposed to bypass this? Would it do anything to report the site to browser developers so that they can patch the problem ?\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_mdu7e1s1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How are we supposed to counter this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jx5ia", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698682748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is this guy on Github making an open source program/file that people can simply copy and paste onto their sites so that devtool/inspect element is impossible to use, making data hoarding and scraping impossible.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/theajack/disable-devtool\"&gt;https://github.com/theajack/disable-devtool&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;How are we supposed to bypass this? Would it do anything to report the site to browser developers so that they can patch the problem ?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jx5ia", "is_robot_indexable": true, "report_reasons": null, "author": "theonewhosexes", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jx5ia/how_are_we_supposed_to_counter_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jx5ia/how_are_we_supposed_to_counter_this/", "subreddit_subscribers": 709500, "created_utc": 1698682748.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am a photographer, and among several other backups, I have two portable hard drives as backups specifically of my current jobs, of which one remains in my car (I rotate them once or twice a week).  I know it's not ideal to store any electronics in a hot car, but I have no secondary location where I can practically store an off-site backup (yes, I realize a drive in my car, which is in my garage, is not truly off-site... it's still vulnerable if the house burns completely down with my car in it).  I do maintain a cloud backup, but I want to have a local, at least somewhat off-site-ish backup as well.\n\nI'd love to shift these two drives to portable SSDs (probably Samsung T7 Shields) in order to speed up the backup process.  But I've read that SSDs stored in high ambient temperatures have extremely poor data retention, maybe even as little as a few days or a week.\n\nMy garage doesn't get too hot even in the Summer... maybe averaging 80-85 degrees (just guessing), and since I work mostly weekends, my car mostly stays in the garage, probably 5 days out of the week (aside from occasional brief errands).  But on those other couple of days, at least during about 3/4 of the year (I'm in the south), when I'm working, my car will likely be parked out in the hot sun, with ambient temperatures ranging from 70-100 degrees, and substantially hotter inside the car.\n\nIs it insane to even consider SSDs in this scenario?  Or, even if not ideal, would the fact that they would be exposed to high temperatures only a few days a week be ok?", "author_fullname": "t2_1w3uifz4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SSD Backup Stored in Hot Car", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jvk4u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698678522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a photographer, and among several other backups, I have two portable hard drives as backups specifically of my current jobs, of which one remains in my car (I rotate them once or twice a week).  I know it&amp;#39;s not ideal to store any electronics in a hot car, but I have no secondary location where I can practically store an off-site backup (yes, I realize a drive in my car, which is in my garage, is not truly off-site... it&amp;#39;s still vulnerable if the house burns completely down with my car in it).  I do maintain a cloud backup, but I want to have a local, at least somewhat off-site-ish backup as well.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to shift these two drives to portable SSDs (probably Samsung T7 Shields) in order to speed up the backup process.  But I&amp;#39;ve read that SSDs stored in high ambient temperatures have extremely poor data retention, maybe even as little as a few days or a week.&lt;/p&gt;\n\n&lt;p&gt;My garage doesn&amp;#39;t get too hot even in the Summer... maybe averaging 80-85 degrees (just guessing), and since I work mostly weekends, my car mostly stays in the garage, probably 5 days out of the week (aside from occasional brief errands).  But on those other couple of days, at least during about 3/4 of the year (I&amp;#39;m in the south), when I&amp;#39;m working, my car will likely be parked out in the hot sun, with ambient temperatures ranging from 70-100 degrees, and substantially hotter inside the car.&lt;/p&gt;\n\n&lt;p&gt;Is it insane to even consider SSDs in this scenario?  Or, even if not ideal, would the fact that they would be exposed to high temperatures only a few days a week be ok?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jvk4u", "is_robot_indexable": true, "report_reasons": null, "author": "macphoto469", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jvk4u/ssd_backup_stored_in_hot_car/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jvk4u/ssd_backup_stored_in_hot_car/", "subreddit_subscribers": 709500, "created_utc": 1698678522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone have any idea how to download videos from this place? I\u2019ve tried **yt-dlp** and various download sites. Please note that I am not asking about [archive.org](https://archive.org).\n\nThanks. May the Force be with you. Always.", "author_fullname": "t2_16xev0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to download from americanarchive.org", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jkrr7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698637893.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any idea how to download videos from this place? I\u2019ve tried &lt;strong&gt;yt-dlp&lt;/strong&gt; and various download sites. Please note that I am not asking about &lt;a href=\"https://archive.org\"&gt;archive.org&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Thanks. May the Force be with you. Always.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jkrr7", "is_robot_indexable": true, "report_reasons": null, "author": "GoalClimber", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jkrr7/how_to_download_from_americanarchiveorg/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jkrr7/how_to_download_from_americanarchiveorg/", "subreddit_subscribers": 709500, "created_utc": 1698637893.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all,\nI\u2019m new here and realizing that maybe I\u2019m a closet data hoarder. \n\nI\u2019m turning a Alienware Area 51 R6 into a Linux  Server. For the moment my storage needs are met, but I\u2019ll be working on some algorithms which have data sets in the terabytes in the near future. \n\nThe data is expensive so once I get a data set I want to store it permanently, even after immediate use. \n\nI\u2019m thinking that medium term I\u2019m probably going to need an external storage bay which can house 10s of terabytes. Preferably SSDs but I\u2019ll cross that bridge later. \n\nHere is my primary question. What is the best way to connect to this bay? I\u2019ll be using most of my PCIE bays but I could free one up if that\u2019s the best. \n\nI also have USBc and a second Ethernet  on this but not Thunderbolt. \n\nI\u2019m kinda inexperienced in this pseudo- enterprise space.\n\nAny relevant comments are welcome and appreciated.\n\nThank you all.", "author_fullname": "t2_7hpjfkdgq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expansion Bays", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jbsrc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698611271.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,\nI\u2019m new here and realizing that maybe I\u2019m a closet data hoarder. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m turning a Alienware Area 51 R6 into a Linux  Server. For the moment my storage needs are met, but I\u2019ll be working on some algorithms which have data sets in the terabytes in the near future. &lt;/p&gt;\n\n&lt;p&gt;The data is expensive so once I get a data set I want to store it permanently, even after immediate use. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m thinking that medium term I\u2019m probably going to need an external storage bay which can house 10s of terabytes. Preferably SSDs but I\u2019ll cross that bridge later. &lt;/p&gt;\n\n&lt;p&gt;Here is my primary question. What is the best way to connect to this bay? I\u2019ll be using most of my PCIE bays but I could free one up if that\u2019s the best. &lt;/p&gt;\n\n&lt;p&gt;I also have USBc and a second Ethernet  on this but not Thunderbolt. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m kinda inexperienced in this pseudo- enterprise space.&lt;/p&gt;\n\n&lt;p&gt;Any relevant comments are welcome and appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thank you all.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jbsrc", "is_robot_indexable": true, "report_reasons": null, "author": "BrokieTrader", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jbsrc/expansion_bays/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jbsrc/expansion_bays/", "subreddit_subscribers": 709500, "created_utc": 1698611271.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I would like to upgrade my offsite Backup Server from Odroid XU4 to a proper ZFS solution, so I can use `zfs send` to sync pools. I am looking at the `Supermicro Tower Server CSE-721TQ-350B`. It has 6x Sata Ports. I would like to use 4x 3,5 16TB Drives (Mirror) + 2x SSDs for the OS/VMs (Mirror2). \n\nHowever, I could not find how or whether it is possible to put in these two extra 2,5 SSDs. There was a mention somewhere that I need an extra bracket, to fix one SSD to the side of the HDD cage, but I could not verify this. Does anyone know?\n\nApart from this, I am ready to order - anything suspicious to your eye regarding my specs below?\n\n- `Supermicro Tower Server CSE-721TQ-350B Single Xeon E-2000 / i3 CPU`\n- `Supermicro SC721TQ-350B - Mini Tower - Mini-ITX 350 Watt (FlexATX)`\n- `Supermicro - X12STL-IF- C252 Chipsatz USB 3.2 Gen1 - 2 x Gigabit LAN (LGA 1200)`\n- `6x SATA3 (6Gb/s) via Intel\u00ae SW RAID Controller`\n- `2x RJ45 GBit LAN (onboard)`, `IPMI onboard`\n- `Intel Xeon E-2314 - 2.8 GHz - 4 Cores - 4 Threads 8 MB Cache`\n- `2HE Dynatron K-650 active Intel Socket LGA 1151, 1200 (E-2000)`\n- 2x `32GB (ECC UDIMM DDR4 3200)`\n- 2x `480GB Samsung PM897 Datacenter SSD - 2.5\" SATA 6Gb/s`\n- 4x `16TB WD Ultrastar - 3.5\" SATA 6Gb/s 7.2K (WUH721816ALE6L4)`\n\nAbout `2615,23 \u20ac`.", "author_fullname": "t2_38k1zqv9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for build comments - 6x Sata + 2x SSD in Supermicro Tower Server CSE-721TQ-350B?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17k18hh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698693578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I would like to upgrade my offsite Backup Server from Odroid XU4 to a proper ZFS solution, so I can use &lt;code&gt;zfs send&lt;/code&gt; to sync pools. I am looking at the &lt;code&gt;Supermicro Tower Server CSE-721TQ-350B&lt;/code&gt;. It has 6x Sata Ports. I would like to use 4x 3,5 16TB Drives (Mirror) + 2x SSDs for the OS/VMs (Mirror2). &lt;/p&gt;\n\n&lt;p&gt;However, I could not find how or whether it is possible to put in these two extra 2,5 SSDs. There was a mention somewhere that I need an extra bracket, to fix one SSD to the side of the HDD cage, but I could not verify this. Does anyone know?&lt;/p&gt;\n\n&lt;p&gt;Apart from this, I am ready to order - anything suspicious to your eye regarding my specs below?&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;code&gt;Supermicro Tower Server CSE-721TQ-350B Single Xeon E-2000 / i3 CPU&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;Supermicro SC721TQ-350B - Mini Tower - Mini-ITX 350 Watt (FlexATX)&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;Supermicro - X12STL-IF- C252 Chipsatz USB 3.2 Gen1 - 2 x Gigabit LAN (LGA 1200)&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;6x SATA3 (6Gb/s) via Intel\u00ae SW RAID Controller&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;2x RJ45 GBit LAN (onboard)&lt;/code&gt;, &lt;code&gt;IPMI onboard&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;Intel Xeon E-2314 - 2.8 GHz - 4 Cores - 4 Threads 8 MB Cache&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;&lt;code&gt;2HE Dynatron K-650 active Intel Socket LGA 1151, 1200 (E-2000)&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;2x &lt;code&gt;32GB (ECC UDIMM DDR4 3200)&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;2x &lt;code&gt;480GB Samsung PM897 Datacenter SSD - 2.5&amp;quot; SATA 6Gb/s&lt;/code&gt;&lt;/li&gt;\n&lt;li&gt;4x &lt;code&gt;16TB WD Ultrastar - 3.5&amp;quot; SATA 6Gb/s 7.2K (WUH721816ALE6L4)&lt;/code&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;About &lt;code&gt;2615,23 \u20ac&lt;/code&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17k18hh", "is_robot_indexable": true, "report_reasons": null, "author": "gromhelmu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17k18hh/looking_for_build_comments_6x_sata_2x_ssd_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17k18hh/looking_for_build_comments_6x_sata_2x_ssd_in/", "subreddit_subscribers": 709500, "created_utc": 1698693578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've purchased some recertified drives (from [serverpartdeals.com](https://serverpartdeals.com)) and I was researching how to test before using them.  (I know that some people are OK with just using them as-is but I'd like to perform a test if possible and not incredibly long)\n\nbadblocks sounds like the standard approach but Arch Linux [doesn't recommend it](https://wiki.archlinux.org/title/badblocks#Alternatives) and I'm also unsure how long it will take for 16 TB drives.  I saw a post where 8 TB took almost 4 days so I'm guessing these would take over a week (assuming no crashes, etc).\n\nInstead, Arch Linux suggests encrypting the drive (cryptsetup), filling with zeros, and then reading it back.  Is this sufficient or should be this be acceptable?\n\nThere is also a thread [here](https://www.reddit.com/r/DataHoarder/comments/wxrrov/is_it_worth_running_badblocks_on_brand_new_drives/) that talks about filling an encrypted drive with random bytes and then checking the sha256 hash.  This sounds better than the last approach since every byte could be unique but I'm not sure.", "author_fullname": "t2_8noa5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How long for badblocks to check 16 TB drives? (or other options?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jzf35", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698688747.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve purchased some recertified drives (from &lt;a href=\"https://serverpartdeals.com\"&gt;serverpartdeals.com&lt;/a&gt;) and I was researching how to test before using them.  (I know that some people are OK with just using them as-is but I&amp;#39;d like to perform a test if possible and not incredibly long)&lt;/p&gt;\n\n&lt;p&gt;badblocks sounds like the standard approach but Arch Linux &lt;a href=\"https://wiki.archlinux.org/title/badblocks#Alternatives\"&gt;doesn&amp;#39;t recommend it&lt;/a&gt; and I&amp;#39;m also unsure how long it will take for 16 TB drives.  I saw a post where 8 TB took almost 4 days so I&amp;#39;m guessing these would take over a week (assuming no crashes, etc).&lt;/p&gt;\n\n&lt;p&gt;Instead, Arch Linux suggests encrypting the drive (cryptsetup), filling with zeros, and then reading it back.  Is this sufficient or should be this be acceptable?&lt;/p&gt;\n\n&lt;p&gt;There is also a thread &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/wxrrov/is_it_worth_running_badblocks_on_brand_new_drives/\"&gt;here&lt;/a&gt; that talks about filling an encrypted drive with random bytes and then checking the sha256 hash.  This sounds better than the last approach since every byte could be unique but I&amp;#39;m not sure.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/LGkaIZoLDPH21g_97bH6VokGocsmBANtB9j84_C_I04.jpg?auto=webp&amp;s=5d1b92aacede02a2cd533065be2e80c8e499f1c0", "width": 2000, "height": 2000}, "resolutions": [{"url": "https://external-preview.redd.it/LGkaIZoLDPH21g_97bH6VokGocsmBANtB9j84_C_I04.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4ea6cf72bbc76c5e0dca433670a432a46687ed60", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/LGkaIZoLDPH21g_97bH6VokGocsmBANtB9j84_C_I04.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=47e1acbaf47daeac1c2c691978a22ae59bac6606", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/LGkaIZoLDPH21g_97bH6VokGocsmBANtB9j84_C_I04.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=700981f9d49424bce29b2b1957ba8183cc63569c", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/LGkaIZoLDPH21g_97bH6VokGocsmBANtB9j84_C_I04.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=bfd4a90a6191b9fcefd7fdd84b600dcbe1654d51", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/LGkaIZoLDPH21g_97bH6VokGocsmBANtB9j84_C_I04.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=33e6363d54f10b581d3f1e26f43ed03595ac6c3d", "width": 960, "height": 960}, {"url": "https://external-preview.redd.it/LGkaIZoLDPH21g_97bH6VokGocsmBANtB9j84_C_I04.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=98c5524ec5cb53e7808cd6a2f023c4349ec44464", "width": 1080, "height": 1080}], "variants": {}, "id": "K0YRiTXu10JV568UhWpDWrTiVgxQeLs5_Dz-kQiG_XQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jzf35", "is_robot_indexable": true, "report_reasons": null, "author": "sofakng", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jzf35/how_long_for_badblocks_to_check_16_tb_drives_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jzf35/how_long_for_badblocks_to_check_16_tb_drives_or/", "subreddit_subscribers": 709500, "created_utc": 1698688747.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am trying to figure out a system for all of my family photos/videos that is easy to use and also private/secure. I have about 5 TB of data that I am trying to figure out what to do with. (I am very new to backing up data/photos.)  \n\n\n Google, Amazon, OneDrive, Dropbox - Not private or secure without encryption which breaks most functionality.  \n\n\nMega - I always hear really bad things about them being sketchy. App has a lot of negative reviews lately from quality going downhill.\n\niDrive - Very ugly and seems like it's missing a lot of features and buggy.\n\npCloud - Seems outdated and lacking in features. Have to pay extra for additional encryption.\n\nProton Drive - Exactly what I am looking for but very new, lacking features, and super expensive for 5tb+.\n\nJottacloud - What I have been using currently and pretty good. However, with them being a smaller company I am not sure if they will be in business 10+ years from now? Will my photos be truly safe here?\n\nSo then I was looking into self-hosted options and it seems like there is only one software so far that looks good which is Immich. However, Immich is so new can I really trust using that for all of my photos that I can't lose?  \n\n\nHow is there no big company that offers E2EE like proton or Filen, that has a good mobile app and affordable storage for large amounts of data?  \n\n\nAny suggestions on which route I should take? I am thinking about just getting a 4 bay Synology and using Synology photos but I have also heard a lot of bad things about their app being broken and limited in features as well.  \n\n\ntldr: Looking for the perfect photo storage that has a lot of functionality, intuitive design, good mobile apps for Android/Apple and is affordable for 5tb of space.", "author_fullname": "t2_dbtfvtt6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "No \"perfect\" options for photo storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jyd7z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698685934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to figure out a system for all of my family photos/videos that is easy to use and also private/secure. I have about 5 TB of data that I am trying to figure out what to do with. (I am very new to backing up data/photos.)  &lt;/p&gt;\n\n&lt;p&gt;Google, Amazon, OneDrive, Dropbox - Not private or secure without encryption which breaks most functionality.  &lt;/p&gt;\n\n&lt;p&gt;Mega - I always hear really bad things about them being sketchy. App has a lot of negative reviews lately from quality going downhill.&lt;/p&gt;\n\n&lt;p&gt;iDrive - Very ugly and seems like it&amp;#39;s missing a lot of features and buggy.&lt;/p&gt;\n\n&lt;p&gt;pCloud - Seems outdated and lacking in features. Have to pay extra for additional encryption.&lt;/p&gt;\n\n&lt;p&gt;Proton Drive - Exactly what I am looking for but very new, lacking features, and super expensive for 5tb+.&lt;/p&gt;\n\n&lt;p&gt;Jottacloud - What I have been using currently and pretty good. However, with them being a smaller company I am not sure if they will be in business 10+ years from now? Will my photos be truly safe here?&lt;/p&gt;\n\n&lt;p&gt;So then I was looking into self-hosted options and it seems like there is only one software so far that looks good which is Immich. However, Immich is so new can I really trust using that for all of my photos that I can&amp;#39;t lose?  &lt;/p&gt;\n\n&lt;p&gt;How is there no big company that offers E2EE like proton or Filen, that has a good mobile app and affordable storage for large amounts of data?  &lt;/p&gt;\n\n&lt;p&gt;Any suggestions on which route I should take? I am thinking about just getting a 4 bay Synology and using Synology photos but I have also heard a lot of bad things about their app being broken and limited in features as well.  &lt;/p&gt;\n\n&lt;p&gt;tldr: Looking for the perfect photo storage that has a lot of functionality, intuitive design, good mobile apps for Android/Apple and is affordable for 5tb of space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17jyd7z", "is_robot_indexable": true, "report_reasons": null, "author": "Realistic-Joe", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jyd7z/no_perfect_options_for_photo_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jyd7z/no_perfect_options_for_photo_storage/", "subreddit_subscribers": 709500, "created_utc": 1698685934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Media I care about is being wiped from a lot of legal existence, so I downloaded the MP4 files of the episodes from my iTunes purchase of the series. Now I want to \"keep circulating the tapes\"\u2014but I also don't want the files passed around the internet to be able to trace back to me, or otherwise have some identifier relating to the iTunes account they were taken from. \n\nDoes anyone know exactly what sorts of metadata or risks there are to uploading iTunes-purchase video files? I assume there's probably some record of the original buyer in the file metadata, what's the best and safest way to scrub that and anonymize the files? And should I be worried about invisible watermarks on the video content itself, is there any knowledge of Apple having those? Any and all info and advice on this is appreciated :)", "author_fullname": "t2_6qk45nz7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help! Does anyone know about metadata risks in iTunes MP4 files? And how can I scrub metadata?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jwt6s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698681828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Media I care about is being wiped from a lot of legal existence, so I downloaded the MP4 files of the episodes from my iTunes purchase of the series. Now I want to &amp;quot;keep circulating the tapes&amp;quot;\u2014but I also don&amp;#39;t want the files passed around the internet to be able to trace back to me, or otherwise have some identifier relating to the iTunes account they were taken from. &lt;/p&gt;\n\n&lt;p&gt;Does anyone know exactly what sorts of metadata or risks there are to uploading iTunes-purchase video files? I assume there&amp;#39;s probably some record of the original buyer in the file metadata, what&amp;#39;s the best and safest way to scrub that and anonymize the files? And should I be worried about invisible watermarks on the video content itself, is there any knowledge of Apple having those? Any and all info and advice on this is appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jwt6s", "is_robot_indexable": true, "report_reasons": null, "author": "inkwell877", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jwt6s/help_does_anyone_know_about_metadata_risks_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jwt6s/help_does_anyone_know_about_metadata_risks_in/", "subreddit_subscribers": 709500, "created_utc": 1698681828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I need to save a livestream and am trying get something working before the actual stream starts.   \nI am using yt-dlp and am trying to save a stream from a url format like below (i dont want to share the actual url because its for a funeral but its the same format)\n\n[https://livestream.com/accounts/11707815/events/4299364](https://livestream.com/accounts/11707815/events/4299364)\n\nWhen trying to do yt-dlp 'url' its seems to find the video but doesn't download anything. I've read through the logs but can't see what i'm missing.\n\n     yt-dlp \u00a0https://livestream.com/accounts/11707815/events/4299364 \n[livestream] Extracting URL: https://livestream.com/accounts/11707815/events/4299364 \n[livestream] Downloading JSON metadata \n[download] Downloading playlist: Berry College Nest Cam 2 \n[livestream] 238256736: Downloading SMIL file \n[livestream] 238256736: Downloading m3u8 information \n[livestream] Playlist Berry College Nest Cam 2: Downloading 0 items \n[download] Finished downloading playlist: Berry College Nest Cam 2 \n\n&amp;#x200B;", "author_fullname": "t2_6p6fahr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for help saving a video feed from livestream.com with yt-dlp", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jqath", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698661692.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to save a livestream and am trying get something working before the actual stream starts.&lt;br/&gt;\nI am using yt-dlp and am trying to save a stream from a url format like below (i dont want to share the actual url because its for a funeral but its the same format)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://livestream.com/accounts/11707815/events/4299364\"&gt;https://livestream.com/accounts/11707815/events/4299364&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;When trying to do yt-dlp &amp;#39;url&amp;#39; its seems to find the video but doesn&amp;#39;t download anything. I&amp;#39;ve read through the logs but can&amp;#39;t see what i&amp;#39;m missing.&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt; yt-dlp \u00a0https://livestream.com/accounts/11707815/events/4299364 \n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;[livestream] Extracting URL: &lt;a href=\"https://livestream.com/accounts/11707815/events/4299364\"&gt;https://livestream.com/accounts/11707815/events/4299364&lt;/a&gt; \n[livestream] Downloading JSON metadata \n[download] Downloading playlist: Berry College Nest Cam 2 \n[livestream] 238256736: Downloading SMIL file \n[livestream] 238256736: Downloading m3u8 information \n[livestream] Playlist Berry College Nest Cam 2: Downloading 0 items \n[download] Finished downloading playlist: Berry College Nest Cam 2 &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T250BrweGbD3Ix1PJ0TU8eDaiPtr0IZt0HwV23V2dDM.jpg?auto=webp&amp;s=c53a7b8aad9cddd4e25ef1716b6a6064fdd7a357", "width": 170, "height": 255}, "resolutions": [{"url": "https://external-preview.redd.it/T250BrweGbD3Ix1PJ0TU8eDaiPtr0IZt0HwV23V2dDM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9bf0b82bb1293e52dcd01eee0f601bdd6dfc11de", "width": 108, "height": 162}], "variants": {}, "id": "m9ENncaU497fvWsLTLB5DNvGS8gI7wW-Tptdnwa2Njc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jqath", "is_robot_indexable": true, "report_reasons": null, "author": "dont_PM_me_everagain", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jqath/looking_for_help_saving_a_video_feed_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jqath/looking_for_help_saving_a_video_feed_from/", "subreddit_subscribers": 709500, "created_utc": 1698661692.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys, I've got a few HDD's flying around in external closures with mostly non-critical data.  \nAt the same time I've been thinking about getting a little home server to set up stuff like pihole, paperless-ngx, smart home connectivity, etc. and while doing that I was thinking about getting a 4-bay closure to bring all the HDD's together into one.\n\nWhile doing some research, I stumbled accross Backblaze which offer their personal service for around 70 bucks a year. Although most of the data being non-critical for that price I would rather pay that price than having the headache of trying to get that data back once a drive says goodbye.\n\nAnyone of you using Backblaze personal as sort of backup? If so, what are your experiences with it?  \nAs far as I know they do not offer a Linux client but I could probably set up a VM and passing through the HDD to it and use the Windows client, I guess?  \n", "author_fullname": "t2_9q6l1n2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backing up an external 4-Bay closure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jpc2u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698657612.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I&amp;#39;ve got a few HDD&amp;#39;s flying around in external closures with mostly non-critical data.&lt;br/&gt;\nAt the same time I&amp;#39;ve been thinking about getting a little home server to set up stuff like pihole, paperless-ngx, smart home connectivity, etc. and while doing that I was thinking about getting a 4-bay closure to bring all the HDD&amp;#39;s together into one.&lt;/p&gt;\n\n&lt;p&gt;While doing some research, I stumbled accross Backblaze which offer their personal service for around 70 bucks a year. Although most of the data being non-critical for that price I would rather pay that price than having the headache of trying to get that data back once a drive says goodbye.&lt;/p&gt;\n\n&lt;p&gt;Anyone of you using Backblaze personal as sort of backup? If so, what are your experiences with it?&lt;br/&gt;\nAs far as I know they do not offer a Linux client but I could probably set up a VM and passing through the HDD to it and use the Windows client, I guess?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jpc2u", "is_robot_indexable": true, "report_reasons": null, "author": "eqchin", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jpc2u/backing_up_an_external_4bay_closure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jpc2u/backing_up_an_external_4bay_closure/", "subreddit_subscribers": 709500, "created_utc": 1698657612.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've been meaning to automate my backup of my important files locally. I've heard about Macrium Reflect for a long time and have been deciding on implementing it. I know that they have moved away from the free home version. I still have a copy of the free 7, but I would be willing to pay a one time fee for 8 if it's worth it. What are everyone's thoughts?\n\nMy use case:\n\nLooking to implement versioning backups of 2-4 tb of personal photos, videos, and misc files. Don't care about system backups, just a select few folders stored on a dedicated drive, hopefully backed up to another drive, whether internal or external. \n\nMy less important media will likely just be manually copied to same said additional drive.", "author_fullname": "t2_2u4isjgz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Question between using Macrium Reflect 7 Free vs 8 Paid?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jg0qw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698622997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been meaning to automate my backup of my important files locally. I&amp;#39;ve heard about Macrium Reflect for a long time and have been deciding on implementing it. I know that they have moved away from the free home version. I still have a copy of the free 7, but I would be willing to pay a one time fee for 8 if it&amp;#39;s worth it. What are everyone&amp;#39;s thoughts?&lt;/p&gt;\n\n&lt;p&gt;My use case:&lt;/p&gt;\n\n&lt;p&gt;Looking to implement versioning backups of 2-4 tb of personal photos, videos, and misc files. Don&amp;#39;t care about system backups, just a select few folders stored on a dedicated drive, hopefully backed up to another drive, whether internal or external. &lt;/p&gt;\n\n&lt;p&gt;My less important media will likely just be manually copied to same said additional drive.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "26TB Raw + Some spare externals ", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jg0qw", "is_robot_indexable": true, "report_reasons": null, "author": "olympus321", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17jg0qw/question_between_using_macrium_reflect_7_free_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jg0qw/question_between_using_macrium_reflect_7_free_vs/", "subreddit_subscribers": 709500, "created_utc": 1698622997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for an HDD enclosure. Does anybody have experience with Fantec QB-35U31 (the US equivalent would be Mediasonic Probox, I think one of the HF2 models)? I haven't found any particularly bad reviews for this one (unlike many others) and it seems to offer what I need. From what I've seen, a couple of things I'm not sure about:\n\n1. Is the cooling sufficient? Particularly the front door seems too closed. I think some people said they leave it open while it's on.\n\n2. Does it support UASP? I think the RAID version does, but I couldn't find it mentioned for this one.\n\n3. Is this model even worth it over QB-35US3? It supports 10Gbps USB 3.2, compared to USB 3.0 and eSATA. Some people were saying how that's a waste, but if my math's correct, with 4 drives 5Gbit can be a bottleneck.\n\n4. This (10Gbps) model doesn't have eSATA. I've read on many posts on r/zfs that USB is not recommended for connecting drives in a ZFS pool (I'm planning to use ZFS here). For example, it can cause errors while scrubbing. But then again, for eSATA, I'd need a PCIe card with a port multiplier, and from what I've read they're of questionable quality/reliability.\n\n5. Would this enclosure allow accessing each drive's SMART data through USB?\n\nIf somebody knows of a better alternative, I'd be happy to hear it.", "author_fullname": "t2_9q9ux2vp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Fantec QB-35U31 a good enclosure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17k0rmk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698692340.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for an HDD enclosure. Does anybody have experience with Fantec QB-35U31 (the US equivalent would be Mediasonic Probox, I think one of the HF2 models)? I haven&amp;#39;t found any particularly bad reviews for this one (unlike many others) and it seems to offer what I need. From what I&amp;#39;ve seen, a couple of things I&amp;#39;m not sure about:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Is the cooling sufficient? Particularly the front door seems too closed. I think some people said they leave it open while it&amp;#39;s on.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Does it support UASP? I think the RAID version does, but I couldn&amp;#39;t find it mentioned for this one.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Is this model even worth it over QB-35US3? It supports 10Gbps USB 3.2, compared to USB 3.0 and eSATA. Some people were saying how that&amp;#39;s a waste, but if my math&amp;#39;s correct, with 4 drives 5Gbit can be a bottleneck.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;This (10Gbps) model doesn&amp;#39;t have eSATA. I&amp;#39;ve read on many posts on &lt;a href=\"/r/zfs\"&gt;r/zfs&lt;/a&gt; that USB is not recommended for connecting drives in a ZFS pool (I&amp;#39;m planning to use ZFS here). For example, it can cause errors while scrubbing. But then again, for eSATA, I&amp;#39;d need a PCIe card with a port multiplier, and from what I&amp;#39;ve read they&amp;#39;re of questionable quality/reliability.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Would this enclosure allow accessing each drive&amp;#39;s SMART data through USB?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;If somebody knows of a better alternative, I&amp;#39;d be happy to hear it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17k0rmk", "is_robot_indexable": true, "report_reasons": null, "author": "flyingpomegranate", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17k0rmk/is_fantec_qb35u31_a_good_enclosure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17k0rmk/is_fantec_qb35u31_a_good_enclosure/", "subreddit_subscribers": 709500, "created_utc": 1698692340.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "TLDR: What's the best way to backup years of important home video and photos? 2TB and growing.\n\nI have a Mac Studio running Ventura 13.6.1. External HDs are plugged directly into the rear USB-A ports on the back of my mac studio.\n\nI have 2TB (and growing) of photo/video memories on an External WD USB 4TB Hard drive (MainHD). I'm trying to back MainHD up to 2 other locations:  another 4TB external hard drive (BackHD) and Crashplan cloud backup.\n\nRight  now - when I look at MacHD &gt; Volumes &gt; it's showing several  different \"instances\" of my BackHD drive - each with a little red do not  enter sign - BackHD 1, BackHD 2, BackHD 3 --- all the way up to 7. Even when I eject the BackHD drive - these folders are still there.\n\nAlso my crashplan cloud backup and lightroom get confused because sometimes  it will rename the exHDx drive as well to multiple instances. Any  advice? It looks like Crashplan needs another 5 months to finish the last 1TB.\n\nI'm sure there's a better way.", "author_fullname": "t2_vp88ifr8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Trouble backing up in MacOS // Need new plan", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17juodz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698676145.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: What&amp;#39;s the best way to backup years of important home video and photos? 2TB and growing.&lt;/p&gt;\n\n&lt;p&gt;I have a Mac Studio running Ventura 13.6.1. External HDs are plugged directly into the rear USB-A ports on the back of my mac studio.&lt;/p&gt;\n\n&lt;p&gt;I have 2TB (and growing) of photo/video memories on an External WD USB 4TB Hard drive (MainHD). I&amp;#39;m trying to back MainHD up to 2 other locations:  another 4TB external hard drive (BackHD) and Crashplan cloud backup.&lt;/p&gt;\n\n&lt;p&gt;Right  now - when I look at MacHD &amp;gt; Volumes &amp;gt; it&amp;#39;s showing several  different &amp;quot;instances&amp;quot; of my BackHD drive - each with a little red do not  enter sign - BackHD 1, BackHD 2, BackHD 3 --- all the way up to 7. Even when I eject the BackHD drive - these folders are still there.&lt;/p&gt;\n\n&lt;p&gt;Also my crashplan cloud backup and lightroom get confused because sometimes  it will rename the exHDx drive as well to multiple instances. Any  advice? It looks like Crashplan needs another 5 months to finish the last 1TB.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m sure there&amp;#39;s a better way.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17juodz", "is_robot_indexable": true, "report_reasons": null, "author": "mc-rilers", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17juodz/trouble_backing_up_in_macos_need_new_plan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17juodz/trouble_backing_up_in_macos_need_new_plan/", "subreddit_subscribers": 709500, "created_utc": 1698676145.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everyone, I need some help with picking a new cloud storage, I'm a concept artist and I end up saving a lot of PSD files on my PC, long story short, my google drive is super full and my pc is getting crazy full, even my back-up disk is starting to blow-up, so my question is; what cloud storage do you guys suggest for this sort of scenario? I need to save a lot of large files and I don't like deleting stuff, always makes me nervous that I might have deleted something important.  \n\n\nLooking for a good quality/price balance, thanks in advance!", "author_fullname": "t2_43xeu60xg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud Storage suggestions for a concept artist", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jt9kb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698672106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone, I need some help with picking a new cloud storage, I&amp;#39;m a concept artist and I end up saving a lot of PSD files on my PC, long story short, my google drive is super full and my pc is getting crazy full, even my back-up disk is starting to blow-up, so my question is; what cloud storage do you guys suggest for this sort of scenario? I need to save a lot of large files and I don&amp;#39;t like deleting stuff, always makes me nervous that I might have deleted something important.  &lt;/p&gt;\n\n&lt;p&gt;Looking for a good quality/price balance, thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jt9kb", "is_robot_indexable": true, "report_reasons": null, "author": "Warm-Sun7986", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jt9kb/cloud_storage_suggestions_for_a_concept_artist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jt9kb/cloud_storage_suggestions_for_a_concept_artist/", "subreddit_subscribers": 709500, "created_utc": 1698672106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i spent 2 years uploading private videos then deleting them from my harddrive (i only have 3TB of storage) and then recently 3 videos (all uploaded in 2021) got flagged for hate speech. most of these videos and all the ones flagged were uncut recordings of competitive overwatch (and othr random videogames) matches with friends. Hundreds of videos are now no longer accessible since I got banned but when i go to youtube on chrome it bugs out and i can see my old youtube profile pic as if the account still exists but just cant be viewed by me. Is there any way to get these videos back? I want to back them up in hardware.", "author_fullname": "t2_2ylw32n5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can i recover youtube videos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jt4z4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698671721.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i spent 2 years uploading private videos then deleting them from my harddrive (i only have 3TB of storage) and then recently 3 videos (all uploaded in 2021) got flagged for hate speech. most of these videos and all the ones flagged were uncut recordings of competitive overwatch (and othr random videogames) matches with friends. Hundreds of videos are now no longer accessible since I got banned but when i go to youtube on chrome it bugs out and i can see my old youtube profile pic as if the account still exists but just cant be viewed by me. Is there any way to get these videos back? I want to back them up in hardware.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jt4z4", "is_robot_indexable": true, "report_reasons": null, "author": "MyCannonHasXwheels", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jt4z4/can_i_recover_youtube_videos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jt4z4/can_i_recover_youtube_videos/", "subreddit_subscribers": 709500, "created_utc": 1698671721.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hiya,\n\nso I have been set a project of creating backups for a small organisation that is very document-heavy, they have around 0.5TB in documents. \n\nIt is around 4 PCs, and so basically they want me to backup all the data including the OS and applications, as they are not very tech savvy.\n\nI believe they want 1 full back up including OS and applications, daily backups, and a backup where they can access previous versions of files.\n\nthey also want to be able to access the files remotely from their phone.\n\nI have researched but I am still a bit baffed as to what to do.\n\nBudget is not a worry, but they aren't tech savvy at all so I don't wanna go down the NAS route.\n\nI was thinking maybe Multiple 2TB SSDs and one drive.\n\nAny help would be greatly appreciated.\n\nThanks.", "author_fullname": "t2_uy4qcb2h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I am struggling with how to incorporate backups into a small organisation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jsx37", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698671042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hiya,&lt;/p&gt;\n\n&lt;p&gt;so I have been set a project of creating backups for a small organisation that is very document-heavy, they have around 0.5TB in documents. &lt;/p&gt;\n\n&lt;p&gt;It is around 4 PCs, and so basically they want me to backup all the data including the OS and applications, as they are not very tech savvy.&lt;/p&gt;\n\n&lt;p&gt;I believe they want 1 full back up including OS and applications, daily backups, and a backup where they can access previous versions of files.&lt;/p&gt;\n\n&lt;p&gt;they also want to be able to access the files remotely from their phone.&lt;/p&gt;\n\n&lt;p&gt;I have researched but I am still a bit baffed as to what to do.&lt;/p&gt;\n\n&lt;p&gt;Budget is not a worry, but they aren&amp;#39;t tech savvy at all so I don&amp;#39;t wanna go down the NAS route.&lt;/p&gt;\n\n&lt;p&gt;I was thinking maybe Multiple 2TB SSDs and one drive.&lt;/p&gt;\n\n&lt;p&gt;Any help would be greatly appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17jsx37", "is_robot_indexable": true, "report_reasons": null, "author": "Present-Condition419", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17jsx37/i_am_struggling_with_how_to_incorporate_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17jsx37/i_am_struggling_with_how_to_incorporate_backups/", "subreddit_subscribers": 709500, "created_utc": 1698671042.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}