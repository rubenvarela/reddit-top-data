{"kind": "Listing", "data": {"after": "t3_17jgtms", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Quick fact: 95% of the world is not eligible for the 95% of the jobs on this subreddit. This is to show my frustration with an existing job market for data engineers. Being a third world national I feel it is hard to get a decent job in a field of DE. Is the only way to become good DE is to migrate to the US, cause I feel there are small chances of getting good project here. I was outstaffed to a US company, but my work was without challenges. Sometimes I feel like third world nationals don't get interesting things. Am I the only one who feels frustrated on my DE path? Getting through textbooks may be interesting, but outcomes are unknown and it is very time consuming. Getting certified is extremely boring and also it's imo useless without hands on experience. Has anyone managed to break this wall? **What are the steps a third world national should take to become a distinguished data engineer?**", "author_fullname": "t2_g6ziwt5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Third world data engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17j7o18", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698599886.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Quick fact: 95% of the world is not eligible for the 95% of the jobs on this subreddit. This is to show my frustration with an existing job market for data engineers. Being a third world national I feel it is hard to get a decent job in a field of DE. Is the only way to become good DE is to migrate to the US, cause I feel there are small chances of getting good project here. I was outstaffed to a US company, but my work was without challenges. Sometimes I feel like third world nationals don&amp;#39;t get interesting things. Am I the only one who feels frustrated on my DE path? Getting through textbooks may be interesting, but outcomes are unknown and it is very time consuming. Getting certified is extremely boring and also it&amp;#39;s imo useless without hands on experience. Has anyone managed to break this wall? &lt;strong&gt;What are the steps a third world national should take to become a distinguished data engineer?&lt;/strong&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17j7o18", "is_robot_indexable": true, "report_reasons": null, "author": "fire_air", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17j7o18/third_world_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17j7o18/third_world_data_engineering/", "subreddit_subscribers": 136920, "created_utc": 1698599886.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Lately, i've done a few jobs consulting and one thing I found is a lot of teams are using the one big tabl approach as opposed to star schemas. Is anyone else noticing this or is it just me?", "author_fullname": "t2_daehbbsip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "i'm seeing less star schemas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jg1x5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 48, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 48, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698623091.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Lately, i&amp;#39;ve done a few jobs consulting and one thing I found is a lot of teams are using the one big tabl approach as opposed to star schemas. Is anyone else noticing this or is it just me?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17jg1x5", "is_robot_indexable": true, "report_reasons": null, "author": "Tough-Error520", "discussion_type": null, "num_comments": 58, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jg1x5/im_seeing_less_star_schemas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jg1x5/im_seeing_less_star_schemas/", "subreddit_subscribers": 136920, "created_utc": 1698623091.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you are prepping for the data engineering interview, you should include the data modeling loop as a key section of your prep. Here is a two part series that includes an overview of the signal that they are looking for, practice problems, and a deeb dive into some of the technical aspects you will need to know.  \n\n\n[https://medium.com/@seancoyne/cracking-the-data-modeling-interview-part-1-an-overview-b09e7d5a7938](https://medium.com/@seancoyne/cracking-the-data-modeling-interview-part-1-an-overview-b09e7d5a7938)  \n\n\n[https://medium.com/@seancoyne/cracking-the-data-modeling-interview-part-2-normalization-indexes-and-partitioning-fac334d767ca](https://medium.com/@seancoyne/cracking-the-data-modeling-interview-part-2-normalization-indexes-and-partitioning-fac334d767ca)", "author_fullname": "t2_4fpl974m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cracking the Data Modeling Interview", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jh22q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698626042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you are prepping for the data engineering interview, you should include the data modeling loop as a key section of your prep. Here is a two part series that includes an overview of the signal that they are looking for, practice problems, and a deeb dive into some of the technical aspects you will need to know.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@seancoyne/cracking-the-data-modeling-interview-part-1-an-overview-b09e7d5a7938\"&gt;https://medium.com/@seancoyne/cracking-the-data-modeling-interview-part-1-an-overview-b09e7d5a7938&lt;/a&gt;  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@seancoyne/cracking-the-data-modeling-interview-part-2-normalization-indexes-and-partitioning-fac334d767ca\"&gt;https://medium.com/@seancoyne/cracking-the-data-modeling-interview-part-2-normalization-indexes-and-partitioning-fac334d767ca&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/g_dhuJAfmQ1iNTX-NeX0K7pz1QFPNjgG39XY0gr5XRo.jpg?auto=webp&amp;s=4090b055bdc86a803c1f6b2c73b9004f54ddba8e", "width": 1200, "height": 557}, "resolutions": [{"url": "https://external-preview.redd.it/g_dhuJAfmQ1iNTX-NeX0K7pz1QFPNjgG39XY0gr5XRo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a2db5992e420edc82f4e1dc1f1849565ff085d58", "width": 108, "height": 50}, {"url": "https://external-preview.redd.it/g_dhuJAfmQ1iNTX-NeX0K7pz1QFPNjgG39XY0gr5XRo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ef17ec983bf531cd47ffe8c475fd585bedc4ed40", "width": 216, "height": 100}, {"url": "https://external-preview.redd.it/g_dhuJAfmQ1iNTX-NeX0K7pz1QFPNjgG39XY0gr5XRo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f7eb2456cff1d6d17a83d2b90861504e91330e8c", "width": 320, "height": 148}, {"url": "https://external-preview.redd.it/g_dhuJAfmQ1iNTX-NeX0K7pz1QFPNjgG39XY0gr5XRo.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=58336696dcdfbfa2f0306d9fef6cb38b5acc1882", "width": 640, "height": 297}, {"url": "https://external-preview.redd.it/g_dhuJAfmQ1iNTX-NeX0K7pz1QFPNjgG39XY0gr5XRo.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7e8ecae39f65c5ee5f3d6c9196d657381264e1de", "width": 960, "height": 445}, {"url": "https://external-preview.redd.it/g_dhuJAfmQ1iNTX-NeX0K7pz1QFPNjgG39XY0gr5XRo.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=2070f6d3d66ac2ee727fd392976a77d070e92a80", "width": 1080, "height": 501}], "variants": {}, "id": "oNoLwNsn-uU3Qx0q4ZAFYrBNCcGCimMegvkILgS8w3g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17jh22q", "is_robot_indexable": true, "report_reasons": null, "author": "coyne_operated", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jh22q/cracking_the_data_modeling_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jh22q/cracking_the_data_modeling_interview/", "subreddit_subscribers": 136920, "created_utc": 1698626042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m a cs student looking to become a data engineer at some point down the line - should I take a databases class? My school offers one next semester however it conflicts w another class I need to graduate time wise. I graduate next year so the database class won\u2019t be offered again before I graduate. Is it worth potentially putting off graduation by a semester or are databases something I can teach myself?", "author_fullname": "t2_kc7mg3akr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I take a databases class?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ji5fm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698629454.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m a cs student looking to become a data engineer at some point down the line - should I take a databases class? My school offers one next semester however it conflicts w another class I need to graduate time wise. I graduate next year so the database class won\u2019t be offered again before I graduate. Is it worth potentially putting off graduation by a semester or are databases something I can teach myself?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ji5fm", "is_robot_indexable": true, "report_reasons": null, "author": "Brief-Union-3493", "discussion_type": null, "num_comments": 32, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ji5fm/should_i_take_a_databases_class/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ji5fm/should_i_take_a_databases_class/", "subreddit_subscribers": 136920, "created_utc": 1698629454.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In the same vein as this [question](https://www.reddit.com/r/vim/comments/17ffelc/whats_the_vim_pareto_for_an_it_professional/) I asked for VIM, I'd like to know what according to you is the Data Engineering [Pareto](https://en.wikipedia.org/wiki/Pareto_principle)?\n\n20% of XYZ(concepts, frameworks, language constructs, libraries etc.) that are sufficient to accomplish 80% of DE tasks.", "author_fullname": "t2_g4v8h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What, according to you, is the Data Engineering Pareto?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17j85hu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698601242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the same vein as this &lt;a href=\"https://www.reddit.com/r/vim/comments/17ffelc/whats_the_vim_pareto_for_an_it_professional/\"&gt;question&lt;/a&gt; I asked for VIM, I&amp;#39;d like to know what according to you is the Data Engineering &lt;a href=\"https://en.wikipedia.org/wiki/Pareto_principle\"&gt;Pareto&lt;/a&gt;?&lt;/p&gt;\n\n&lt;p&gt;20% of XYZ(concepts, frameworks, language constructs, libraries etc.) that are sufficient to accomplish 80% of DE tasks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/z0KhRy4dT59epvVdLEHyL1O4pBEJiH6-5Byq7mgeKaY.jpg?auto=webp&amp;s=77108879ce1467c6179a7684cfc856c49520e8aa", "width": 539, "height": 560}, "resolutions": [{"url": "https://external-preview.redd.it/z0KhRy4dT59epvVdLEHyL1O4pBEJiH6-5Byq7mgeKaY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=59ee074ebffc935b18d0b1a063c2e363c75ad619", "width": 108, "height": 112}, {"url": "https://external-preview.redd.it/z0KhRy4dT59epvVdLEHyL1O4pBEJiH6-5Byq7mgeKaY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=e328266b558161fbc599f3a37e6129abf3340a6d", "width": 216, "height": 224}, {"url": "https://external-preview.redd.it/z0KhRy4dT59epvVdLEHyL1O4pBEJiH6-5Byq7mgeKaY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8cc77d7f54428ccd453adf9eea490bea7dc6925e", "width": 320, "height": 332}], "variants": {}, "id": "dA1Z5W9CE92S0TuslnqeO50Jk-gBx9H3l63KikMQOaA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17j85hu", "is_robot_indexable": true, "report_reasons": null, "author": "swapripper", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17j85hu/what_according_to_you_is_the_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17j85hu/what_according_to_you_is_the_data_engineering/", "subreddit_subscribers": 136920, "created_utc": 1698601242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello.\n\nI\u2019m sorry if this has already been talked about here, but I couldn\u2019t really find older posts on this. I\u2019m trying to get into DE coming from a SWE background. I thought about doing so firstly through a job as a DA, which seems the most common path where I\u2019m from, at least. My question is: what are the first certifications to get if I wanted to break into DE/DA? My main goal is to not come across as if this is a nine-day wonder. What are the ones that make me stand out for entry positions?\n\nThank you.", "author_fullname": "t2_fgp3mdj67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Certifications for someone trying to land an entrance position in DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jnb1u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698648277.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.&lt;/p&gt;\n\n&lt;p&gt;I\u2019m sorry if this has already been talked about here, but I couldn\u2019t really find older posts on this. I\u2019m trying to get into DE coming from a SWE background. I thought about doing so firstly through a job as a DA, which seems the most common path where I\u2019m from, at least. My question is: what are the first certifications to get if I wanted to break into DE/DA? My main goal is to not come across as if this is a nine-day wonder. What are the ones that make me stand out for entry positions?&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17jnb1u", "is_robot_indexable": true, "report_reasons": null, "author": "LusoDev", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jnb1u/certifications_for_someone_trying_to_land_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jnb1u/certifications_for_someone_trying_to_land_an/", "subreddit_subscribers": 136920, "created_utc": 1698648277.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Small community owned non-profit with a number of functions.  Two part time and one jr. developer. We prefer Python but we also know a bit of JS and C# but we are getting rusty with Java. Ops/IT has a bias against Java. As an organization we are not very cost averse but we could use the money on other very worthy things.\n\nWe have many different systems for billing, maintenance, finance, inventory, a few different analysis and metering systems and more. We need a system that will help us with cross system communications, sometimes with very different methods such as text files, XML, REST API and direct SQL selects, inserts and merges between different PostGres and MS SQL Server databases.  Some on a daily schedule and other information instantaneously or instantaneously using persisted data from older systems. This may have to run on-prem.\n\nOur latest plan is to make Prefect and Flask run together and just script the retries and logging into flask. ... or Dagster and FastAPI to do the same or another combination of similar platforms.\n\nSo a Hub and Spoke with a data orchestration tool and a simple as possible API.  I have had some exposure to Camel but it would probably take us a while to started and doing Prefect/Dagster \"Integrations\" is so much simpler. Companies/Organizations with overlapping functions and we are familiar with are using Azure servicebuses, Timextender, n-ServiceBus, Mule and I was hoping for something a bit more lightweight/easier, on-prem and avoid lock-in but we don't really know these platforms either. Perhaps we should simply be looking into these?\n\nAre we heading towards certain doom here or has someone here done anything similar? Alternatives we should be looking at?", "author_fullname": "t2_7no9p", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prefect&amp;Flask as a Hub and Spoke", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jqhvd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698671728.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698662486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Small community owned non-profit with a number of functions.  Two part time and one jr. developer. We prefer Python but we also know a bit of JS and C# but we are getting rusty with Java. Ops/IT has a bias against Java. As an organization we are not very cost averse but we could use the money on other very worthy things.&lt;/p&gt;\n\n&lt;p&gt;We have many different systems for billing, maintenance, finance, inventory, a few different analysis and metering systems and more. We need a system that will help us with cross system communications, sometimes with very different methods such as text files, XML, REST API and direct SQL selects, inserts and merges between different PostGres and MS SQL Server databases.  Some on a daily schedule and other information instantaneously or instantaneously using persisted data from older systems. This may have to run on-prem.&lt;/p&gt;\n\n&lt;p&gt;Our latest plan is to make Prefect and Flask run together and just script the retries and logging into flask. ... or Dagster and FastAPI to do the same or another combination of similar platforms.&lt;/p&gt;\n\n&lt;p&gt;So a Hub and Spoke with a data orchestration tool and a simple as possible API.  I have had some exposure to Camel but it would probably take us a while to started and doing Prefect/Dagster &amp;quot;Integrations&amp;quot; is so much simpler. Companies/Organizations with overlapping functions and we are familiar with are using Azure servicebuses, Timextender, n-ServiceBus, Mule and I was hoping for something a bit more lightweight/easier, on-prem and avoid lock-in but we don&amp;#39;t really know these platforms either. Perhaps we should simply be looking into these?&lt;/p&gt;\n\n&lt;p&gt;Are we heading towards certain doom here or has someone here done anything similar? Alternatives we should be looking at?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17jqhvd", "is_robot_indexable": true, "report_reasons": null, "author": "YourOldBuddy", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jqhvd/prefectflask_as_a_hub_and_spoke/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jqhvd/prefectflask_as_a_hub_and_spoke/", "subreddit_subscribers": 136920, "created_utc": 1698662486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am the Head of Data for a tech startup that provides services and SaaS-based tools for customers in the real estate industry. I need to start designing a governance framework for our data (and therefore determine the solution architecture). There is of course CCPA and the big names, but does anyone have advice on how I \u201cdiscover\u201d which laws, regulations, standards apply to the data of our business?", "author_fullname": "t2_52cbaf2f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Privacy Resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17jtq6w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1698677124.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698673478.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am the Head of Data for a tech startup that provides services and SaaS-based tools for customers in the real estate industry. I need to start designing a governance framework for our data (and therefore determine the solution architecture). There is of course CCPA and the big names, but does anyone have advice on how I \u201cdiscover\u201d which laws, regulations, standards apply to the data of our business?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17jtq6w", "is_robot_indexable": true, "report_reasons": null, "author": "yoquierodata", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jtq6w/data_privacy_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jtq6w/data_privacy_resources/", "subreddit_subscribers": 136920, "created_utc": 1698673478.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone! \n\nI\u2019m doing my last co-op (hence very important since I\u2019m not going to have any internships experience anymore) in Canada and I have the option to go with Samsung or P&amp;G? Both are for Data Engineer roles so I was wondering if anyone has any insights on this? Samsung is in the city I am in (Vancouver), and I have to relocate to North York Ontario if I end up with P&amp;G. I\u2019m in a big dilemma what to do in this case. Thank you so much! :\u201d)", "author_fullname": "t2_e5537ck7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineer Internship: P&amp;G or Samsung?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jafhq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698607486.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone! &lt;/p&gt;\n\n&lt;p&gt;I\u2019m doing my last co-op (hence very important since I\u2019m not going to have any internships experience anymore) in Canada and I have the option to go with Samsung or P&amp;amp;G? Both are for Data Engineer roles so I was wondering if anyone has any insights on this? Samsung is in the city I am in (Vancouver), and I have to relocate to North York Ontario if I end up with P&amp;amp;G. I\u2019m in a big dilemma what to do in this case. Thank you so much! :\u201d)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17jafhq", "is_robot_indexable": true, "report_reasons": null, "author": "angelicsmiless", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jafhq/data_engineer_internship_pg_or_samsung/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jafhq/data_engineer_internship_pg_or_samsung/", "subreddit_subscribers": 136920, "created_utc": 1698607486.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, I just uploaded a Python Pandas course on YouTube. I covered the introduction and installation of pandas, series and series operations, dataframes and basic dataframe creation, creating dataframes from various file formats, dataframe operations, identifying and handling missing data, data manipulation using loc and iloc, sorting and ranking data, combining and merging dataframes, data cleaning techniques, handling categorical data, data transformation techniques, handling date and time data, group by operations, aggregating data using functions, time series data visualization, advanced data manipulation techniques (apply, map, and apply map), data visualization with pandas tools, working with multi-index dataframes and text manipulation methods topics. I am leaving the course link below, have a great day!\n\nhttps://www.youtube.com/watch?v=KvFZf3cL_IY", "author_fullname": "t2_me12im5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I shared a Python Pandas course (1.5 Hrs) on YouTube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17jvf6p", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1698678171.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, I just uploaded a Python Pandas course on YouTube. I covered the introduction and installation of pandas, series and series operations, dataframes and basic dataframe creation, creating dataframes from various file formats, dataframe operations, identifying and handling missing data, data manipulation using loc and iloc, sorting and ranking data, combining and merging dataframes, data cleaning techniques, handling categorical data, data transformation techniques, handling date and time data, group by operations, aggregating data using functions, time series data visualization, advanced data manipulation techniques (apply, map, and apply map), data visualization with pandas tools, working with multi-index dataframes and text manipulation methods topics. I am leaving the course link below, have a great day!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=KvFZf3cL_IY\"&gt;https://www.youtube.com/watch?v=KvFZf3cL_IY&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/l3w_x32sW1ndSFuhwAmk4hpXmMXlpQcLmA7Cg0_N-UQ.jpg?auto=webp&amp;s=f1439e666963311860ed2bbc6d18d58138ab20ab", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/l3w_x32sW1ndSFuhwAmk4hpXmMXlpQcLmA7Cg0_N-UQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1160dcf6aa25a9ba5c8b7c522c6001b5a93c5bde", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/l3w_x32sW1ndSFuhwAmk4hpXmMXlpQcLmA7Cg0_N-UQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9047f27c215633f01e07e0e4e2dadf6e306dd0bd", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/l3w_x32sW1ndSFuhwAmk4hpXmMXlpQcLmA7Cg0_N-UQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=31180cc898c560b7db600f56a3d2fa228fdaabff", "width": 320, "height": 240}], "variants": {}, "id": "l-wENCMcE_8QSoQ-KSZE0RDTI-ogPC-MOsWTs7k42RI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17jvf6p", "is_robot_indexable": true, "report_reasons": null, "author": "onurbaltaci", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jvf6p/i_shared_a_python_pandas_course_15_hrs_on_youtube/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jvf6p/i_shared_a_python_pandas_course_15_hrs_on_youtube/", "subreddit_subscribers": 136920, "created_utc": 1698678171.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone take a good online course/mooc for this cert? \n\nAny bit would help! Thanks in advance", "author_fullname": "t2_16k0ev", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snowflake snowpro core cert", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17jvbd6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698677901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone take a good online course/mooc for this cert? &lt;/p&gt;\n\n&lt;p&gt;Any bit would help! Thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17jvbd6", "is_robot_indexable": true, "report_reasons": null, "author": "jovalabs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jvbd6/snowflake_snowpro_core_cert/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jvbd6/snowflake_snowpro_core_cert/", "subreddit_subscribers": 136920, "created_utc": 1698677901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been working in a bit of a silo at my company without many other human resources to brainstorm data solutions with, so... I'm curious to know about what kind of current, most important best practices there are out there for setting up a wholesale data stack. Not looking for every best practice at every part of the pipe, just the considerations that have been the most impactful to your workflows.\n\nFor some context, I'm looking at implementing Microsoft Fabric to replace our current system of exporting .xls, .xlsx, or .csv files from our handful of sources, manually wrangling each week/month/quarter, reporting via PDF. Our company deals with primarily financial and operational data in the staffing/contracting sector, no scientific data.", "author_fullname": "t2_gn8s9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Warehouse / Lakehouse / Data Set Best Practices", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17jv50c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698677418.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been working in a bit of a silo at my company without many other human resources to brainstorm data solutions with, so... I&amp;#39;m curious to know about what kind of current, most important best practices there are out there for setting up a wholesale data stack. Not looking for every best practice at every part of the pipe, just the considerations that have been the most impactful to your workflows.&lt;/p&gt;\n\n&lt;p&gt;For some context, I&amp;#39;m looking at implementing Microsoft Fabric to replace our current system of exporting .xls, .xlsx, or .csv files from our handful of sources, manually wrangling each week/month/quarter, reporting via PDF. Our company deals with primarily financial and operational data in the staffing/contracting sector, no scientific data.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17jv50c", "is_robot_indexable": true, "report_reasons": null, "author": "Thiseffingguy2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jv50c/warehouse_lakehouse_data_set_best_practices/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jv50c/warehouse_lakehouse_data_set_best_practices/", "subreddit_subscribers": 136920, "created_utc": 1698677418.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/nlboefgoocxb1.png?width=2480&amp;format=png&amp;auto=webp&amp;s=52a729f80c075a9f6fd64c43286f8ed2c8489390", "author_fullname": "t2_sw2luf69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "13 Crucial Steps for End-to-End File Testing by iceDQ \ud83d\udcdd\ud83d\ude80", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "media_metadata": {"nlboefgoocxb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 152, "x": 108, "u": "https://preview.redd.it/nlboefgoocxb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=5e7ece2ed0cf3a498074596648a071778bf681c2"}, {"y": 305, "x": 216, "u": "https://preview.redd.it/nlboefgoocxb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=55ee8561b09888eb5bc2a6593f2ec4373b8f990c"}, {"y": 452, "x": 320, "u": "https://preview.redd.it/nlboefgoocxb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5957f37ce22e5d778db788c12dc7a7f8cac848b9"}, {"y": 905, "x": 640, "u": "https://preview.redd.it/nlboefgoocxb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d3d77c6b9c42c21a0a5e0b3b61e95c074e6e834b"}, {"y": 1357, "x": 960, "u": "https://preview.redd.it/nlboefgoocxb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fd3a1bc09bcf33a0a54c8774b4d9e9d4af04ef4c"}, {"y": 1527, "x": 1080, "u": "https://preview.redd.it/nlboefgoocxb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c38ef27a54dc9a38c537ba668b899c2976a581ef"}], "s": {"y": 3508, "x": 2480, "u": "https://preview.redd.it/nlboefgoocxb1.png?width=2480&amp;format=png&amp;auto=webp&amp;s=52a729f80c075a9f6fd64c43286f8ed2c8489390"}, "id": "nlboefgoocxb1"}}, "name": "t3_17juzns", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bee6HOYrBoKyF9T9pqtVygDL1FKfzYwDr-vght6rGOE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698677009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/nlboefgoocxb1.png?width=2480&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=52a729f80c075a9f6fd64c43286f8ed2c8489390\"&gt;https://preview.redd.it/nlboefgoocxb1.png?width=2480&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=52a729f80c075a9f6fd64c43286f8ed2c8489390&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17juzns", "is_robot_indexable": true, "report_reasons": null, "author": "icedqengineer", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17juzns/13_crucial_steps_for_endtoend_file_testing_by/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17juzns/13_crucial_steps_for_endtoend_file_testing_by/", "subreddit_subscribers": 136920, "created_utc": 1698677009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Python vs Rust. Memory Usage and Speed.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 82, "top_awarded_type": null, "hide_score": true, "name": "t3_17juqsx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/ei0yUSDt2NwuqwwV5FcLfnU_XTJgOq2QCgpTdbPzkw8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698676320.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/python-vs-rust-memory-usage-and-speed", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/9ULxTgrddoVu3zdQCPuSbTZIYxps6zdrdavgj4kVnSg.jpg?auto=webp&amp;s=e6209acdd529ea86a157d4730d9f7089844d2a51", "width": 1024, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/9ULxTgrddoVu3zdQCPuSbTZIYxps6zdrdavgj4kVnSg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0398daaa752f40478b31d1ae988bf3e769338356", "width": 108, "height": 63}, {"url": "https://external-preview.redd.it/9ULxTgrddoVu3zdQCPuSbTZIYxps6zdrdavgj4kVnSg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=bb14e5cb3ae0cd1482f90c46e0168b8619e8fef7", "width": 216, "height": 126}, {"url": "https://external-preview.redd.it/9ULxTgrddoVu3zdQCPuSbTZIYxps6zdrdavgj4kVnSg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5554654cd57de3891185599d2fd3ce02435756e5", "width": 320, "height": 187}, {"url": "https://external-preview.redd.it/9ULxTgrddoVu3zdQCPuSbTZIYxps6zdrdavgj4kVnSg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=09940ba97769d8b4bf1795e63172c693b4d64673", "width": 640, "height": 375}, {"url": "https://external-preview.redd.it/9ULxTgrddoVu3zdQCPuSbTZIYxps6zdrdavgj4kVnSg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=224300bedb4245a712d39fb24dfeeaa6ddaa7d5c", "width": 960, "height": 562}], "variants": {}, "id": "jade9nZ_x7rhjjZazxzCNWWCeriynsT88Rz_VolVEkA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17juqsx", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17juqsx/python_vs_rust_memory_usage_and_speed/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/python-vs-rust-memory-usage-and-speed", "subreddit_subscribers": 136920, "created_utc": 1698676320.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey folks,\r\n\r\nI'm in my first FlutterFlow course and we're using Firestore. The course suggests duplicating some data from a popularDoctors collection to a bookings collection upon creating a booking. So, for each booking, we copy the doctor's info from popularDoctors to bookings.\r\n\r\nIs this a common practice? Or is it better to just reference the doctor in the bookings collection and pull the doctor's info from popularDoctors when needed? Concerned about data consistency and storage efficiency.\r\n\r\nWould love to hear your thoughts! \ud83d\ude4f", "author_fullname": "t2_w5eiso48", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Denormalization vs Normalization in Firestore:", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17ju8s8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698674910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey folks,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m in my first FlutterFlow course and we&amp;#39;re using Firestore. The course suggests duplicating some data from a popularDoctors collection to a bookings collection upon creating a booking. So, for each booking, we copy the doctor&amp;#39;s info from popularDoctors to bookings.&lt;/p&gt;\n\n&lt;p&gt;Is this a common practice? Or is it better to just reference the doctor in the bookings collection and pull the doctor&amp;#39;s info from popularDoctors when needed? Concerned about data consistency and storage efficiency.&lt;/p&gt;\n\n&lt;p&gt;Would love to hear your thoughts! \ud83d\ude4f&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17ju8s8", "is_robot_indexable": true, "report_reasons": null, "author": "Tom5542131845", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17ju8s8/denormalization_vs_normalization_in_firestore/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17ju8s8/denormalization_vs_normalization_in_firestore/", "subreddit_subscribers": 136920, "created_utc": 1698674910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am seeking advice on how to structure a database for an extremely wide dataset in a relational database management system (RDBMS).\n\nThe dataset is the \"final\" result of a research project and is contained in a SAS dataset:\n\n* The main data file \"data.sas7dat\" comprises approximately 3,000 columns and 4,000 rows, with each row representing a participant. This file includes demographic information, questionnaire responses, and average nutrient intake values. It also contains variable labels (column descriptions) as metadata.\n* The formats file \"formats.sas7bcat\" contains value labels for categorical variables, such as 1 is \"male\" and 2 is \"female\".\n\nChallenges I am facing include the size of the dataset, which makes it difficult to manage within most RDBMS, as we've actually hit the upper column limit and row sizes in RDBMS like MariaDB/MySQL, MSSQL, and PostgreSQL. Its current structure, while facilitating analysis, is too wide for effective database management.\n\nThe main reason I want to put this data into an RDBMS is to easily connect various analytical and statistical tools, like SPSS, Apache Superset, or programming languages used for data analysis like R or Python, most of which interact seamlessly with SQL. However, I cannot use cloud services like Google, Azure, or Amazon, only plain old self-hosted platforms (preferably open source).\n\nI have attempted the following solutions:\n\n1. Vertical Partitioning: I divided the dataset by subject into different dimension and fact tables (e.g., responses table, nutrients table, etc.), resulting in semi-wide tables with hundreds of columns. This created multiple fact tables with the same grain and a few dimension tables, with a 1:1 relationship between dimensions and facts, which essentially forms a fact constellation schema.\n2. Melting the Dataset: I transformed the columns into rows to create a \"long\" format, but this led to loss of data types, as categorical (integers), measurements (floating point numbers), and text responses (strings) ended up in the same column.\n\nThe users of this dataset would expect to be able to retrieve the data in its original columnar format. While they are not usually interested in all \\~3,000 columns at once, it is important that the database can reconstruct the long format efficiently, especially if the data needs to be exported to another system or analytical platform.\n\nI am considering a star schema but am unsure if that is the most effective approach given the dataset's complexity and the challenge of incorporating metadata. Any suggestions or advice on how to tackle this issue would be greatly appreciated. Thank you!", "author_fullname": "t2_s3w1zbjp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Structuring an extremely wide dataset in an RDBMS: Seeking advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17jtonq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698673351.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am seeking advice on how to structure a database for an extremely wide dataset in a relational database management system (RDBMS).&lt;/p&gt;\n\n&lt;p&gt;The dataset is the &amp;quot;final&amp;quot; result of a research project and is contained in a SAS dataset:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;The main data file &amp;quot;data.sas7dat&amp;quot; comprises approximately 3,000 columns and 4,000 rows, with each row representing a participant. This file includes demographic information, questionnaire responses, and average nutrient intake values. It also contains variable labels (column descriptions) as metadata.&lt;/li&gt;\n&lt;li&gt;The formats file &amp;quot;formats.sas7bcat&amp;quot; contains value labels for categorical variables, such as 1 is &amp;quot;male&amp;quot; and 2 is &amp;quot;female&amp;quot;.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Challenges I am facing include the size of the dataset, which makes it difficult to manage within most RDBMS, as we&amp;#39;ve actually hit the upper column limit and row sizes in RDBMS like MariaDB/MySQL, MSSQL, and PostgreSQL. Its current structure, while facilitating analysis, is too wide for effective database management.&lt;/p&gt;\n\n&lt;p&gt;The main reason I want to put this data into an RDBMS is to easily connect various analytical and statistical tools, like SPSS, Apache Superset, or programming languages used for data analysis like R or Python, most of which interact seamlessly with SQL. However, I cannot use cloud services like Google, Azure, or Amazon, only plain old self-hosted platforms (preferably open source).&lt;/p&gt;\n\n&lt;p&gt;I have attempted the following solutions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Vertical Partitioning: I divided the dataset by subject into different dimension and fact tables (e.g., responses table, nutrients table, etc.), resulting in semi-wide tables with hundreds of columns. This created multiple fact tables with the same grain and a few dimension tables, with a 1:1 relationship between dimensions and facts, which essentially forms a fact constellation schema.&lt;/li&gt;\n&lt;li&gt;Melting the Dataset: I transformed the columns into rows to create a &amp;quot;long&amp;quot; format, but this led to loss of data types, as categorical (integers), measurements (floating point numbers), and text responses (strings) ended up in the same column.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The users of this dataset would expect to be able to retrieve the data in its original columnar format. While they are not usually interested in all ~3,000 columns at once, it is important that the database can reconstruct the long format efficiently, especially if the data needs to be exported to another system or analytical platform.&lt;/p&gt;\n\n&lt;p&gt;I am considering a star schema but am unsure if that is the most effective approach given the dataset&amp;#39;s complexity and the challenge of incorporating metadata. Any suggestions or advice on how to tackle this issue would be greatly appreciated. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17jtonq", "is_robot_indexable": true, "report_reasons": null, "author": "BudgetAd1030", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jtonq/structuring_an_extremely_wide_dataset_in_an_rdbms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jtonq/structuring_an_extremely_wide_dataset_in_an_rdbms/", "subreddit_subscribers": 136920, "created_utc": 1698673351.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys,\n\nI am looking for an apache beam I/O connector that makes use of HTTPS. And also one that makes use of server sent events(SSE's). If these do not exist how would i go about creating one?", "author_fullname": "t2_fcsujw3l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I/O connectors apache beam", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jqt39", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698663725.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I am looking for an apache beam I/O connector that makes use of HTTPS. And also one that makes use of server sent events(SSE&amp;#39;s). If these do not exist how would i go about creating one?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17jqt39", "is_robot_indexable": true, "report_reasons": null, "author": "Abject-Battle1215", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jqt39/io_connectors_apache_beam/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jqt39/io_connectors_apache_beam/", "subreddit_subscribers": 136920, "created_utc": 1698663725.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nAnyone has been involved near or far with the decision of wether or not to build a warehouse in a **nascent** startup that is **just launching its product** ? Was the decision to go with the warehouse or not ? Which technical setup was chosen ?", "author_fullname": "t2_8kenyeuh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Warehouse in a small startup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jqoei", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "620fb7b8-ac9d-11eb-a99a-0ed5d8300de1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698663233.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Anyone has been involved near or far with the decision of wether or not to build a warehouse in a &lt;strong&gt;nascent&lt;/strong&gt; startup that is &lt;strong&gt;just launching its product&lt;/strong&gt; ? Was the decision to go with the warehouse or not ? Which technical setup was chosen ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Tech Lead", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17jqoei", "is_robot_indexable": true, "report_reasons": null, "author": "btenami", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17jqoei/warehouse_in_a_small_startup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jqoei/warehouse_in_a_small_startup/", "subreddit_subscribers": 136920, "created_utc": 1698663233.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_129ag6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Free E-Book] Vector Databases and AI Applications For Dummies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17jqd0e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/M_w6LCVKtZRxewkvpnjsbkZKjr4UMxwhA9ewz38LFIY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1698661933.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "singlestore.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.singlestore.com/resources/vector-databases-and-ai-applications-for-dummies/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/k9XLworLSn61Y1j3SAYp5kZzoypcnytvGRa4HiVT-48.jpg?auto=webp&amp;s=000c0c7064f64ca2b0cac6827b14d12e37d2d232", "width": 1201, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/k9XLworLSn61Y1j3SAYp5kZzoypcnytvGRa4HiVT-48.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0c12f0fce9010e3ce2b216f8fc5be7a47e302c73", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/k9XLworLSn61Y1j3SAYp5kZzoypcnytvGRa4HiVT-48.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3170483cb05e990313b8d326715900e87a6118ff", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/k9XLworLSn61Y1j3SAYp5kZzoypcnytvGRa4HiVT-48.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=46198771b44a5e88f556c346a5319e49d8f4d97a", "width": 320, "height": 179}, {"url": "https://external-preview.redd.it/k9XLworLSn61Y1j3SAYp5kZzoypcnytvGRa4HiVT-48.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3ace9f2c49ee51a37dc87fb35943cf69b5994e62", "width": 640, "height": 359}, {"url": "https://external-preview.redd.it/k9XLworLSn61Y1j3SAYp5kZzoypcnytvGRa4HiVT-48.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e29ac98a284e4cd1b2cc955e9610520b852f2439", "width": 960, "height": 539}, {"url": "https://external-preview.redd.it/k9XLworLSn61Y1j3SAYp5kZzoypcnytvGRa4HiVT-48.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e1a4c949414fc446017cc9a9c455e43df2938369", "width": 1080, "height": 606}], "variants": {}, "id": "CV6vqaEWO_WXiT53Pnv-OIpG-MTUtHAMri_KogAZW3k"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17jqd0e", "is_robot_indexable": true, "report_reasons": null, "author": "PavanBelagatti", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jqd0e/free_ebook_vector_databases_and_ai_applications/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.singlestore.com/resources/vector-databases-and-ai-applications-for-dummies/", "subreddit_subscribers": 136920, "created_utc": 1698661933.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For an environment with high stakes that necessitates proactive communication if a pipeline fails , how do you setup a safe way to promote new code / code changes and also maintain and monitor. \n\nIn a less data intensive and less pipeline stack , having a messaging system that pushed to slack and PagerDuty for errors , typically broken out by extraction then transformation jobs , typically catching api timeout errors and schema change errors , seems effective. But have a larger volume of data , a real sla , and using both data bricks / pyspark and snowflake. Any ideas on how to setup the system to scale and easily be monitored?", "author_fullname": "t2_32eyna18", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to implement scalable code deployment and monitoring system for a company that ingests pedabytes of data daily , 100 different pipelines while using airflow , snowflake , pyspark/databricks and AWS ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jmxzw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698646600.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For an environment with high stakes that necessitates proactive communication if a pipeline fails , how do you setup a safe way to promote new code / code changes and also maintain and monitor. &lt;/p&gt;\n\n&lt;p&gt;In a less data intensive and less pipeline stack , having a messaging system that pushed to slack and PagerDuty for errors , typically broken out by extraction then transformation jobs , typically catching api timeout errors and schema change errors , seems effective. But have a larger volume of data , a real sla , and using both data bricks / pyspark and snowflake. Any ideas on how to setup the system to scale and easily be monitored?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17jmxzw", "is_robot_indexable": true, "report_reasons": null, "author": "acceptedcitizen", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jmxzw/how_to_implement_scalable_code_deployment_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jmxzw/how_to_implement_scalable_code_deployment_and/", "subreddit_subscribers": 136920, "created_utc": 1698646600.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I recently learned about the data platform Promethium.ai. Does anyone have any reviews or insights to share about it?", "author_fullname": "t2_kgk078ub", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Promethium Reviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jmwjn", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698646416.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I recently learned about the data platform Promethium.ai. Does anyone have any reviews or insights to share about it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17jmwjn", "is_robot_indexable": true, "report_reasons": null, "author": "Beginning-Forever597", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jmwjn/promethium_reviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jmwjn/promethium_reviews/", "subreddit_subscribers": 136920, "created_utc": 1698646416.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've tried googling up on it, but it's often non-conclusive and I don't quite get much from it. They would say that it can be moved between storages and systems, but they don't ever give a counter example, or what would make something be non-portable.\n\nIt would help to have some point of reference, on what makes a database portable or not. \n\n&amp;#x200B;", "author_fullname": "t2_mdkpy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What makes a database portable or not.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jkkfc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698637149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve tried googling up on it, but it&amp;#39;s often non-conclusive and I don&amp;#39;t quite get much from it. They would say that it can be moved between storages and systems, but they don&amp;#39;t ever give a counter example, or what would make something be non-portable.&lt;/p&gt;\n\n&lt;p&gt;It would help to have some point of reference, on what makes a database portable or not. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17jkkfc", "is_robot_indexable": true, "report_reasons": null, "author": "WaifuMasterRace", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jkkfc/what_makes_a_database_portable_or_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jkkfc/what_makes_a_database_portable_or_not/", "subreddit_subscribers": 136920, "created_utc": 1698637149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Using explode or joins will create 1: 5000 rows, so is there any other way to query just the all values of a particular keys in a nested list and json column rows ?", "author_fullname": "t2_l1km19tsw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Query nested json and list column from a hive table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jk520", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698635703.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Using explode or joins will create 1: 5000 rows, so is there any other way to query just the all values of a particular keys in a nested list and json column rows ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17jk520", "is_robot_indexable": true, "report_reasons": null, "author": "Hopeful-Brilliant-21", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jk520/query_nested_json_and_list_column_from_a_hive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jk520/query_nested_json_and_list_column_from_a_hive/", "subreddit_subscribers": 136920, "created_utc": 1698635703.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Community. New to /r/dataengineering. Apology if this question has been asked before.\n\n&amp;#x200B;\n\nWhat is your recommendation for a modern, popular, yet simple tech / data engineering stack for querying data from AWS S3, Azure Storage, and Alibaba OSS that can be hosted in Kubernetes?  \n\n&amp;#x200B;\n\n* Definition of \"simple\": Easy enough to be set up and operated by a single person. \n* Definition of \"popular\": Widely used, with ample learning materials &amp; discussions available on O'Reilly, Udemy, and various community platforms. \n* Definition of \"modern\": Designed to solve querying data from AWS S3, Azure Storage, and Alibaba OSS in an efficient and quick way instead of retrofitted to solve that.\n\n&amp;#x200B;\n\nIn summary, I need to join JSON data based on IDs from AWS S3, Azure Storage, and Alibaba OSS. Thanks.", "author_fullname": "t2_h5ccypg68", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your recommendation for a modern, popular, yet simple tech / data engineering stack for querying data from AWS S3, Azure Storage, and Alibaba OSS that can be hosted in Kubernetes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jgug0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698625400.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Community. New to &lt;a href=\"/r/dataengineering\"&gt;/r/dataengineering&lt;/a&gt;. Apology if this question has been asked before.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What is your recommendation for a modern, popular, yet simple tech / data engineering stack for querying data from AWS S3, Azure Storage, and Alibaba OSS that can be hosted in Kubernetes?  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Definition of &amp;quot;simple&amp;quot;: Easy enough to be set up and operated by a single person. &lt;/li&gt;\n&lt;li&gt;Definition of &amp;quot;popular&amp;quot;: Widely used, with ample learning materials &amp;amp; discussions available on O&amp;#39;Reilly, Udemy, and various community platforms. &lt;/li&gt;\n&lt;li&gt;Definition of &amp;quot;modern&amp;quot;: Designed to solve querying data from AWS S3, Azure Storage, and Alibaba OSS in an efficient and quick way instead of retrofitted to solve that.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;In summary, I need to join JSON data based on IDs from AWS S3, Azure Storage, and Alibaba OSS. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17jgug0", "is_robot_indexable": true, "report_reasons": null, "author": "Big-Balance-6426", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jgug0/what_is_your_recommendation_for_a_modern_popular/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jgug0/what_is_your_recommendation_for_a_modern_popular/", "subreddit_subscribers": 136920, "created_utc": 1698625400.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Recently my organization has decided to step out of the dark ages and finally build a data warehouse. I've been tasked with finding a good solution. I've stumbled upon Astera and it seems to be what I'm looking for as far as functionality and costs but I don't see a lot of discussion about it here. Other forums have very vague descriptions of their experience with it.\n\nIf there are any Astera users here, I'd love your input. I'm new to the concept of Data Warehouses in general and would appreciate any advice in regards to building from ground up. Thanks!", "author_fullname": "t2_5hpq24rk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Astera Data Stack users here? Looking for advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17jgtms", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1698625334.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Recently my organization has decided to step out of the dark ages and finally build a data warehouse. I&amp;#39;ve been tasked with finding a good solution. I&amp;#39;ve stumbled upon Astera and it seems to be what I&amp;#39;m looking for as far as functionality and costs but I don&amp;#39;t see a lot of discussion about it here. Other forums have very vague descriptions of their experience with it.&lt;/p&gt;\n\n&lt;p&gt;If there are any Astera users here, I&amp;#39;d love your input. I&amp;#39;m new to the concept of Data Warehouses in general and would appreciate any advice in regards to building from ground up. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17jgtms", "is_robot_indexable": true, "report_reasons": null, "author": "letsgopablo", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17jgtms/any_astera_data_stack_users_here_looking_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17jgtms/any_astera_data_stack_users_here_looking_for/", "subreddit_subscribers": 136920, "created_utc": 1698625334.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}