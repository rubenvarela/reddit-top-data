{"kind": "Listing", "data": {"after": null, "dist": 10, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We're using AWS Managed Airflow and experiencing high resource utilization issues but have only 50 DAGs on a medium instance. DAGs are not dynamically created and they're all of the same type/using similar code to run. There's no clear culprit because nothing we're doing seems particularly resource-intensive. It doesn't seem to be related to DAG parse time based on relevant metrics. It might be related to memory usage but I haven't been able to find out what's taking up a lot of memory. What steps can we take to narrow down possible causes? Nothing stands out apart from the two areas I've just mentioned (DAG parsing or memory usage) so I'm looking for general guidance on areas to investigate further and how.", "author_fullname": "t2_jx5l6r0ay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow performance issues", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16wl0dz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 36, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 36, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696115602.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We&amp;#39;re using AWS Managed Airflow and experiencing high resource utilization issues but have only 50 DAGs on a medium instance. DAGs are not dynamically created and they&amp;#39;re all of the same type/using similar code to run. There&amp;#39;s no clear culprit because nothing we&amp;#39;re doing seems particularly resource-intensive. It doesn&amp;#39;t seem to be related to DAG parse time based on relevant metrics. It might be related to memory usage but I haven&amp;#39;t been able to find out what&amp;#39;s taking up a lot of memory. What steps can we take to narrow down possible causes? Nothing stands out apart from the two areas I&amp;#39;ve just mentioned (DAG parsing or memory usage) so I&amp;#39;m looking for general guidance on areas to investigate further and how.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16wl0dz", "is_robot_indexable": true, "report_reasons": null, "author": "IllRepresentative858", "discussion_type": null, "num_comments": 25, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16wl0dz/airflow_performance_issues/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16wl0dz/airflow_performance_issues/", "subreddit_subscribers": 131460, "created_utc": 1696115602.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Context**\n\nWe have data pipelines that are a mixture of SQL / python as they are a combo of:\n\n \\- more 'data engineering-y' transformations at the start (SQL)\n\n \\- more 'data science-y' operations further down (python)\n\nWe run on GCP so given we aren't at serious scale yet this manifests itself as cloudbuild to deploy our infra which consists of GCP workflows orchestrating http python cloud functions/run on top of Big Query.\n\nOrganising all of that logic into 1 repo per pipeline appears to make sense as we combine all business logic together (in python) along with its orchestration, triggers and deployment code - this allows us to release/version a pipeline repo and deploy that unit of logic all at once.\n\nHowever, our sql script management is currently just a bunch of parameterised sql queries inside a file in each repo (and sometimes manual view creation in the GCP console) that lacks the nice features of data testing, lineage, versioning etc that dbt involves so I'd like to bring it in to the pipelines.\n\n**Question**\n\nHow do you introduce dbt to this infrastructure?\n\nBy having a dbt project within each pipeline repo (and thus forgoing cross-pipeline dependencies in the lineage)?\n\nOr by starting with dbt's recommended monorepo, but then meaning a pipeline's logic is now split between:\n\n \\- pipeline repo\n\n \\- that pipeline's section in the dbt mono-repo\n\nI haven't been able to find much on this on line and was wondering if anyone else has encountered this and how they tackled it?", "author_fullname": "t2_576k5sn4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt mono-repo vs individual pipeline repos?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16wy2vv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696157594.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Context&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;We have data pipelines that are a mixture of SQL / python as they are a combo of:&lt;/p&gt;\n\n&lt;p&gt;- more &amp;#39;data engineering-y&amp;#39; transformations at the start (SQL)&lt;/p&gt;\n\n&lt;p&gt;- more &amp;#39;data science-y&amp;#39; operations further down (python)&lt;/p&gt;\n\n&lt;p&gt;We run on GCP so given we aren&amp;#39;t at serious scale yet this manifests itself as cloudbuild to deploy our infra which consists of GCP workflows orchestrating http python cloud functions/run on top of Big Query.&lt;/p&gt;\n\n&lt;p&gt;Organising all of that logic into 1 repo per pipeline appears to make sense as we combine all business logic together (in python) along with its orchestration, triggers and deployment code - this allows us to release/version a pipeline repo and deploy that unit of logic all at once.&lt;/p&gt;\n\n&lt;p&gt;However, our sql script management is currently just a bunch of parameterised sql queries inside a file in each repo (and sometimes manual view creation in the GCP console) that lacks the nice features of data testing, lineage, versioning etc that dbt involves so I&amp;#39;d like to bring it in to the pipelines.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;How do you introduce dbt to this infrastructure?&lt;/p&gt;\n\n&lt;p&gt;By having a dbt project within each pipeline repo (and thus forgoing cross-pipeline dependencies in the lineage)?&lt;/p&gt;\n\n&lt;p&gt;Or by starting with dbt&amp;#39;s recommended monorepo, but then meaning a pipeline&amp;#39;s logic is now split between:&lt;/p&gt;\n\n&lt;p&gt;- pipeline repo&lt;/p&gt;\n\n&lt;p&gt;- that pipeline&amp;#39;s section in the dbt mono-repo&lt;/p&gt;\n\n&lt;p&gt;I haven&amp;#39;t been able to find much on this on line and was wondering if anyone else has encountered this and how they tackled it?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16wy2vv", "is_robot_indexable": true, "report_reasons": null, "author": "mjam03", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16wy2vv/dbt_monorepo_vs_individual_pipeline_repos/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16wy2vv/dbt_monorepo_vs_individual_pipeline_repos/", "subreddit_subscribers": 131460, "created_utc": 1696157594.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have been using snowflake-pulumi to define database objects like storage integrations, users, roles, schemas and so on. It works well for connecting AWS to Snowflake but is very painful to use for Snowflake objects. \n\nSo we are looking into dedicated tools for this. This tool is mostly to define the Snowflake infrastructure  (schemas, RBAC, external tables etc) as we use DBT for tables/views.\n\nI am currently evaluating [schemachange by Snowflake](https://github.com/Snowflake-Labs/schemachange). What tools are you using for database change management?", "author_fullname": "t2_pbcof", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any recommendations for database change management for Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16wgdrw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696104264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have been using snowflake-pulumi to define database objects like storage integrations, users, roles, schemas and so on. It works well for connecting AWS to Snowflake but is very painful to use for Snowflake objects. &lt;/p&gt;\n\n&lt;p&gt;So we are looking into dedicated tools for this. This tool is mostly to define the Snowflake infrastructure  (schemas, RBAC, external tables etc) as we use DBT for tables/views.&lt;/p&gt;\n\n&lt;p&gt;I am currently evaluating &lt;a href=\"https://github.com/Snowflake-Labs/schemachange\"&gt;schemachange by Snowflake&lt;/a&gt;. What tools are you using for database change management?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/3hJfbrka6rAp8ffiR7y5l0vTl93-Z5hxKvrWWypdKJY.jpg?auto=webp&amp;s=2bedc3b4e62956c2fc668b3d9c76cfa446780aa0", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/3hJfbrka6rAp8ffiR7y5l0vTl93-Z5hxKvrWWypdKJY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dc4f9e13ee6cdbe7b9c1e3085b2baffef2c16ba4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/3hJfbrka6rAp8ffiR7y5l0vTl93-Z5hxKvrWWypdKJY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=eb3ef7f0f338c6d2194d6062539bede95f87f397", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/3hJfbrka6rAp8ffiR7y5l0vTl93-Z5hxKvrWWypdKJY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=d35415883c213b6580d54f1966b78559be0a5cb5", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/3hJfbrka6rAp8ffiR7y5l0vTl93-Z5hxKvrWWypdKJY.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=51aa4e03cf7358a2b214f58477e649a6b35606cc", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/3hJfbrka6rAp8ffiR7y5l0vTl93-Z5hxKvrWWypdKJY.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b86e3f7ae5b2bcb1f416de2a981556a3cef68115", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/3hJfbrka6rAp8ffiR7y5l0vTl93-Z5hxKvrWWypdKJY.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=3e1abd5d48ca5a2c595f3793d7192f6d353b174f", "width": 1080, "height": 540}], "variants": {}, "id": "yNb2wBkvBc5pn2HPMQUhawwmqIhcCNf5oUQ5id_qneA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16wgdrw", "is_robot_indexable": true, "report_reasons": null, "author": "vish4life", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16wgdrw/any_recommendations_for_database_change/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16wgdrw/any_recommendations_for_database_change/", "subreddit_subscribers": 131460, "created_utc": 1696104264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a bunch of files on S3 (minio) primarly in JSON and parquet format. We are searching for a simple solution to do some ad hoc sql queries against those files to verify data and see the structure. mainly for the engineers to build the data pipelines in dbt/dagster. we don't want a complex solution which involves many components and there's no need to scale computing beyond a single node.\n\nit seems there are many solutions with a hive metastore like trino/presto. but this requires multiple tools and manual registration of the single files.\n\nour preferred way would be something which we can point to a s3 bucket and it shows all the files as e.g. views in the database. it shouldn't require to manually specify the schema/structure of the files. just lookup the structure on read. the files are usually only around 1-20MB. so really small scale.\n\nanyone have an idea which tool could help us here? And what are you using to engineer your pipeline queries from unstructured data?", "author_fullname": "t2_mojp1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best way to query JSON and parquet files on S3 for data verification and pipeline building?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16wysjd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696159977.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a bunch of files on S3 (minio) primarly in JSON and parquet format. We are searching for a simple solution to do some ad hoc sql queries against those files to verify data and see the structure. mainly for the engineers to build the data pipelines in dbt/dagster. we don&amp;#39;t want a complex solution which involves many components and there&amp;#39;s no need to scale computing beyond a single node.&lt;/p&gt;\n\n&lt;p&gt;it seems there are many solutions with a hive metastore like trino/presto. but this requires multiple tools and manual registration of the single files.&lt;/p&gt;\n\n&lt;p&gt;our preferred way would be something which we can point to a s3 bucket and it shows all the files as e.g. views in the database. it shouldn&amp;#39;t require to manually specify the schema/structure of the files. just lookup the structure on read. the files are usually only around 1-20MB. so really small scale.&lt;/p&gt;\n\n&lt;p&gt;anyone have an idea which tool could help us here? And what are you using to engineer your pipeline queries from unstructured data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16wysjd", "is_robot_indexable": true, "report_reasons": null, "author": "OneCyrus", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16wysjd/what_is_the_best_way_to_query_json_and_parquet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16wysjd/what_is_the_best_way_to_query_json_and_parquet/", "subreddit_subscribers": 131460, "created_utc": 1696159977.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We just inherited a large LookML project with ~1000 .lkml files (and no tests). It has view / explore / model definitions that support internal dashboards and a metrics API hit by our web app backend for customer facing reports.\n\nWe\u2019re seeing avg API response times from Looker around 1+ seconds even when the Snowflake DB it\u2019s hitting is returning from the result cache with quick response. Some requests can be much, much slower too. This is causing downstream problems in our web app.\n\nMost of the team has used Looker before but none of us have had to build out a LookML layer like this before. It feels overly complex and harder to follow than the equivalent SQL / SQLAlechemy would be.\n\nOur initial instinct is to refactor this logic out of Looker and into our modeling layer (DBT), but the performance with the Looker API seems so bad that we\u2019re considering just rolling our own a python API with SQLAlchemy.\n\nHas anyone here been in a similar predicament with Looker / LookML? Any advice on how we can improve performance / maintainability?", "author_fullname": "t2_axl2rt05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have advice for optimizing a large LookML project that serves customer facing metics?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16wjyrx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696112995.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We just inherited a large LookML project with ~1000 .lkml files (and no tests). It has view / explore / model definitions that support internal dashboards and a metrics API hit by our web app backend for customer facing reports.&lt;/p&gt;\n\n&lt;p&gt;We\u2019re seeing avg API response times from Looker around 1+ seconds even when the Snowflake DB it\u2019s hitting is returning from the result cache with quick response. Some requests can be much, much slower too. This is causing downstream problems in our web app.&lt;/p&gt;\n\n&lt;p&gt;Most of the team has used Looker before but none of us have had to build out a LookML layer like this before. It feels overly complex and harder to follow than the equivalent SQL / SQLAlechemy would be.&lt;/p&gt;\n\n&lt;p&gt;Our initial instinct is to refactor this logic out of Looker and into our modeling layer (DBT), but the performance with the Looker API seems so bad that we\u2019re considering just rolling our own a python API with SQLAlchemy.&lt;/p&gt;\n\n&lt;p&gt;Has anyone here been in a similar predicament with Looker / LookML? Any advice on how we can improve performance / maintainability?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16wjyrx", "is_robot_indexable": true, "report_reasons": null, "author": "deepfuckingbass", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16wjyrx/does_anyone_have_advice_for_optimizing_a_large/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16wjyrx/does_anyone_have_advice_for_optimizing_a_large/", "subreddit_subscribers": 131460, "created_utc": 1696112995.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is there a way to link Github to Airbyte UI. From the documentation it seems like the only way is to have a repo with yaml or json config file that call the Airbyte API", "author_fullname": "t2_8cz53aie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airbyte Git Integration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16weia5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696099563.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a way to link Github to Airbyte UI. From the documentation it seems like the only way is to have a repo with yaml or json config file that call the Airbyte API&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16weia5", "is_robot_indexable": true, "report_reasons": null, "author": "solo_stooper", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16weia5/airbyte_git_integration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16weia5/airbyte_git_integration/", "subreddit_subscribers": 131460, "created_utc": 1696099563.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "What are the strengths and weaknesses of AWS Glue vs ADF?", "author_fullname": "t2_8cz53aie", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS Glue vs Azure Data Factory", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16wghdl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696104510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the strengths and weaknesses of AWS Glue vs ADF?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16wghdl", "is_robot_indexable": true, "report_reasons": null, "author": "solo_stooper", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16wghdl/aws_glue_vs_azure_data_factory/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16wghdl/aws_glue_vs_azure_data_factory/", "subreddit_subscribers": 131460, "created_utc": 1696104510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm trying to build a daily pipeline for Times and Sales derivatives data from this website name [https://www.sgx.com/research-education/derivatives](https://www.sgx.com/research-education/derivatives). Now I have a few question about exception handling:  \n1. If the downloading failed on some days how do you re-download the missed file(s)? What is the best strategy for it ?\n\n2. Some error can appear in the scenario of downloading file from here ?   \n   \n", "author_fullname": "t2_9axjxbxe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16wdfm7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696096914.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m trying to build a daily pipeline for Times and Sales derivatives data from this website name &lt;a href=\"https://www.sgx.com/research-education/derivatives\"&gt;https://www.sgx.com/research-education/derivatives&lt;/a&gt;. Now I have a few question about exception handling:&lt;br/&gt;\n1. If the downloading failed on some days how do you re-download the missed file(s)? What is the best strategy for it ?&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Some error can appear in the scenario of downloading file from here ?&lt;br/&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/0iF_CKP4g0IdRh-4dXTLlPQhDzp2twy5Kuo-6lfDuF0.jpg?auto=webp&amp;s=a8c317969beed8dd1702fa11050007b40fdcf368", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/0iF_CKP4g0IdRh-4dXTLlPQhDzp2twy5Kuo-6lfDuF0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8dc8bbbf9c6482d8cfe893ec398c5d11dbc5e096", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/0iF_CKP4g0IdRh-4dXTLlPQhDzp2twy5Kuo-6lfDuF0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c2d047300d275d67178b959b644f27f23f995d21", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/0iF_CKP4g0IdRh-4dXTLlPQhDzp2twy5Kuo-6lfDuF0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b6d994229174fb32061a3b10acece70d8fabcfc", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/0iF_CKP4g0IdRh-4dXTLlPQhDzp2twy5Kuo-6lfDuF0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0dd21e739827ab60ea488b67d69f6d6479f41b0b", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/0iF_CKP4g0IdRh-4dXTLlPQhDzp2twy5Kuo-6lfDuF0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ecd8ce5bb6303c6281d269eebd64f8083a5c5b29", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/0iF_CKP4g0IdRh-4dXTLlPQhDzp2twy5Kuo-6lfDuF0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6b1c732883a59218acfb8ff548a89d7ec4c1d8b1", "width": 1080, "height": 540}], "variants": {}, "id": "Z8FLd_bT6olULrx3zQDUG3CyuiZaCgt6N0QznAXq14s"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16wdfm7", "is_robot_indexable": true, "report_reasons": null, "author": "Previous_Aside_8863", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16wdfm7/data_engineering_project/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16wdfm7/data_engineering_project/", "subreddit_subscribers": 131460, "created_utc": 1696096914.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.\n\n**Community Links:**\n\n* [Monthly newsletter](https://dataengineeringcommunity.substack.com/)\n* [Data Engineering Events](https://dataengineering.wiki/Community/Events)\n* [Data Engineering Meetups](https://dataengineering.wiki/Community/Meetups)\n* [Get involved in the community](https://dataengineering.wiki/Community/Get+Involved)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion - Oct 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc", "t3_100nsr2", "t3_10qzpp1", "t3_11f8z5h", "t3_128qhe2", "t3_134qgn8", "t3_13xle38", "t3_14nylwl", "t3_15fgn9y", "t3_167b40e", "t3_16x4y7c"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1696176058.352, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16x4y7c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1696176058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Community Links:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;Monthly newsletter&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Events\"&gt;Data Engineering Events&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Meetups\"&gt;Data Engineering Meetups&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Get+Involved\"&gt;Get involved in the community&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/c1tDGdXyXGdsLQ6pwjWc8mXKh5-H7Rix5dx2etHXDU4.jpg?auto=webp&amp;s=02e6018b7f945f491d0b3a2effc39732c734f1e1", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/c1tDGdXyXGdsLQ6pwjWc8mXKh5-H7Rix5dx2etHXDU4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dccc2af8931f0a3ac9ada660b34e9cba537b2fd1", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/c1tDGdXyXGdsLQ6pwjWc8mXKh5-H7Rix5dx2etHXDU4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a24a390861290f321df46393893e52524fe7623f", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/c1tDGdXyXGdsLQ6pwjWc8mXKh5-H7Rix5dx2etHXDU4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53c673cdf215f673c496a58a993c4eac464fc2bb", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/c1tDGdXyXGdsLQ6pwjWc8mXKh5-H7Rix5dx2etHXDU4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db34a5d7735459993d15b53c8a1b7aff4d3b2ec4", "width": 640, "height": 333}], "variants": {}, "id": "FmCaWz0_zzuMIYjO5Y9qwrC5XQ9HEDt0Z1CdPOgLQk4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16x4y7c", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x4y7c/monthly_general_discussion_oct_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/16x4y7c/monthly_general_discussion_oct_2023/", "subreddit_subscribers": 131460, "created_utc": 1696176058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_94pk0qq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why is my query running slow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_16wqq39", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/NsPslzl4Q5I5XShWyGQI5NvoYxxJfjkW3zbcfBjxLOQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696131748.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "gizmodo.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://gizmodo.com/startup-moves-closer-building-data-centers-moon-1850192177", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/6ervbluLbV1xIJKhIF37R5xD9f847pCV3YkiGQcd2YM.jpg?auto=webp&amp;s=11ec4788f1d5867990e5c0c95bcf681df5bcaf68", "width": 970, "height": 546}, "resolutions": [{"url": "https://external-preview.redd.it/6ervbluLbV1xIJKhIF37R5xD9f847pCV3YkiGQcd2YM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=b9022cd4abb16e345d50ec9be4692bdd89b4e6e9", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/6ervbluLbV1xIJKhIF37R5xD9f847pCV3YkiGQcd2YM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7df4f067f183dfc2d16ce8da0fa64968850789cb", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/6ervbluLbV1xIJKhIF37R5xD9f847pCV3YkiGQcd2YM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4ea3a5a9799e1204278fcc11650de99051fc858e", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/6ervbluLbV1xIJKhIF37R5xD9f847pCV3YkiGQcd2YM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=da2874826788e12f20abac009f7964547a8c0b88", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/6ervbluLbV1xIJKhIF37R5xD9f847pCV3YkiGQcd2YM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a0e25d14c52b9d81a28a41c0ceeecb0fc199e4cc", "width": 960, "height": 540}], "variants": {}, "id": "2ahjXaciyCGSN3b6tmMi8DxjraHqmH4Cqpnx2GFHQrA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "16wqq39", "is_robot_indexable": true, "report_reasons": null, "author": "Badger-Flaky", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16wqq39/why_is_my_query_running_slow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://gizmodo.com/startup-moves-closer-building-data-centers-moon-1850192177", "subreddit_subscribers": 131460, "created_utc": 1696131748.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}