{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all!  To preface, I started a new job almost a year ago, I graduated with my MBA last year, and I had 2 years of experience as a data analyst prior. \n\nWhen I started my job, I was very excited because of all the glamor and hype that comes along with a space program, but that excitement is gone. My company is a start up, and everyone in my sector has started within the last year or two. A few months in, I realized how poor of processes this company had, if any, along with an evident lack of leadership. We had a major re-organization that left many people without jobs, and on top of that, we let go close to a third of our employees at the same time. We have had drastic funding issues and schedule issues because of that, so overall, the mood has not been good. Additionally, I was put on a \u201cneed to know\u201d program that will potentially take the company down an ethical path that I am not willing to go down. \n\nI kept holding on thinking that maybe just maybe things would get better, but I also had family health issues that required me to leave the state permanently right as my company put in a mandatory work from office policy.  \n\nWith all this being said, I was offered a very nice position at another company that would be a 15% increase in pay in the state I was moving to, but the position was one that I knew that I would be unfulfilled and very unhappy doing. Regardless, I decided that the stability and being able to move for my family was more important than the role, so I turned in my notice at my current job and prepared to take this new one. \n\nOur sector VP, however, made a counter offer for me to stay with the company remote, and they would not only match the opposing company but give me yet an additional 7% raise and a promotion and a sizeable bonus to move. I naively accepted the offer but with the catch that if I left within 12 months, I would have to pay back that bonus in full. \n\nFast forward, things have only gotten worse at this company, and the ethical concern is seeming to become a reality.  I am also in a bad situation in that I am not qualified to be in the promotion I was given, or at least I am not getting the support I need to be successful in this position. My family medical situation has become a major financial burden, and the raise that I was given is not enough to keep up. \n\nI desperately want to leave this company for good, but I feel like there is nothing I can do but wait for my bonus contract obligation to be fulfilled by staying for another year. I also feel like if I were to get another job, I would have to take a pay cut due to my lack of experience, but my current financial situation is already struggling. I don\u2019t know what to do anymore, and every day I work for this company I get more depressed.", "author_fullname": "t2_v54crjii", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I accepted my company\u2019s counter offer and it was a mistake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zeenf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 157, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 157, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696438694.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696396173.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!  To preface, I started a new job almost a year ago, I graduated with my MBA last year, and I had 2 years of experience as a data analyst prior. &lt;/p&gt;\n\n&lt;p&gt;When I started my job, I was very excited because of all the glamor and hype that comes along with a space program, but that excitement is gone. My company is a start up, and everyone in my sector has started within the last year or two. A few months in, I realized how poor of processes this company had, if any, along with an evident lack of leadership. We had a major re-organization that left many people without jobs, and on top of that, we let go close to a third of our employees at the same time. We have had drastic funding issues and schedule issues because of that, so overall, the mood has not been good. Additionally, I was put on a \u201cneed to know\u201d program that will potentially take the company down an ethical path that I am not willing to go down. &lt;/p&gt;\n\n&lt;p&gt;I kept holding on thinking that maybe just maybe things would get better, but I also had family health issues that required me to leave the state permanently right as my company put in a mandatory work from office policy.  &lt;/p&gt;\n\n&lt;p&gt;With all this being said, I was offered a very nice position at another company that would be a 15% increase in pay in the state I was moving to, but the position was one that I knew that I would be unfulfilled and very unhappy doing. Regardless, I decided that the stability and being able to move for my family was more important than the role, so I turned in my notice at my current job and prepared to take this new one. &lt;/p&gt;\n\n&lt;p&gt;Our sector VP, however, made a counter offer for me to stay with the company remote, and they would not only match the opposing company but give me yet an additional 7% raise and a promotion and a sizeable bonus to move. I naively accepted the offer but with the catch that if I left within 12 months, I would have to pay back that bonus in full. &lt;/p&gt;\n\n&lt;p&gt;Fast forward, things have only gotten worse at this company, and the ethical concern is seeming to become a reality.  I am also in a bad situation in that I am not qualified to be in the promotion I was given, or at least I am not getting the support I need to be successful in this position. My family medical situation has become a major financial burden, and the raise that I was given is not enough to keep up. &lt;/p&gt;\n\n&lt;p&gt;I desperately want to leave this company for good, but I feel like there is nothing I can do but wait for my bonus contract obligation to be fulfilled by staying for another year. I also feel like if I were to get another job, I would have to take a pay cut due to my lack of experience, but my current financial situation is already struggling. I don\u2019t know what to do anymore, and every day I work for this company I get more depressed.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16zeenf", "is_robot_indexable": true, "report_reasons": null, "author": "college_geek1", "discussion_type": null, "num_comments": 70, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16zeenf/i_accepted_my_companys_counter_offer_and_it_was_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16zeenf/i_accepted_my_companys_counter_offer_and_it_was_a/", "subreddit_subscribers": 1071966, "created_utc": 1696396173.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As a data scientist, if you could let someone else solve something for you what would it be?\n\nI was curious to know the problems data scientists face. This can be anywhere from collecting data and cleaning data to making and deploying machine learning models.", "author_fullname": "t2_l10ic37ez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What do corporate data scientists struggle with the most at work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16z8pez", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 110, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 110, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696379698.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a data scientist, if you could let someone else solve something for you what would it be?&lt;/p&gt;\n\n&lt;p&gt;I was curious to know the problems data scientists face. This can be anywhere from collecting data and cleaning data to making and deploying machine learning models.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16z8pez", "is_robot_indexable": true, "report_reasons": null, "author": "Potanee", "discussion_type": null, "num_comments": 101, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16z8pez/what_do_corporate_data_scientists_struggle_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16z8pez/what_do_corporate_data_scientists_struggle_with/", "subreddit_subscribers": 1071966, "created_utc": 1696379698.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I studied data science in college, and I\u2019m in my first job in a start up (been here about a year). There are three on our data science team (manager, another graduate and myself). Due to being in a start up, we all work on individual projects (as we do consultancy). Mainly data processing in sql/python + analysis\n\nMy manager is up to their neck in work, and I\u2019d like if they had more time to actually teach us things. I am just learning by googling and doing. I think ideally in my head I would like to work on more projects with them, or maybe even shadow them once in a while and see how they would approach a problem or see their workflow. Is this normal?\n\nI can read their code and analysis but I just feel isolated and would learn a lot more by actually interacting with them while working\n\nSince joining have learned a lot more about ETL pipelines and cloud technologies, but honestly I\u2019m not sure how much more I can learn here that I can\u2019t learn in any other job.\n\nI can do the work but I feel like I could be a lot more effective and efficient.\n\nDo you just learn by doing in your job? Am I gaining the most knowledge that I can here? Is this normal? How did you advance to the next level?", "author_fullname": "t2_175p3s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you just learn on the job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16z2cge", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696364509.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I studied data science in college, and I\u2019m in my first job in a start up (been here about a year). There are three on our data science team (manager, another graduate and myself). Due to being in a start up, we all work on individual projects (as we do consultancy). Mainly data processing in sql/python + analysis&lt;/p&gt;\n\n&lt;p&gt;My manager is up to their neck in work, and I\u2019d like if they had more time to actually teach us things. I am just learning by googling and doing. I think ideally in my head I would like to work on more projects with them, or maybe even shadow them once in a while and see how they would approach a problem or see their workflow. Is this normal?&lt;/p&gt;\n\n&lt;p&gt;I can read their code and analysis but I just feel isolated and would learn a lot more by actually interacting with them while working&lt;/p&gt;\n\n&lt;p&gt;Since joining have learned a lot more about ETL pipelines and cloud technologies, but honestly I\u2019m not sure how much more I can learn here that I can\u2019t learn in any other job.&lt;/p&gt;\n\n&lt;p&gt;I can do the work but I feel like I could be a lot more effective and efficient.&lt;/p&gt;\n\n&lt;p&gt;Do you just learn by doing in your job? Am I gaining the most knowledge that I can here? Is this normal? How did you advance to the next level?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16z2cge", "is_robot_indexable": true, "report_reasons": null, "author": "bic-boy", "discussion_type": null, "num_comments": 29, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16z2cge/do_you_just_learn_on_the_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16z2cge/do_you_just_learn_on_the_job/", "subreddit_subscribers": 1071966, "created_utc": 1696364509.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm playing around with adapting matrix profiles to my time series data and I want to ensure that the data and parameters are set correctly.\n\nI'm working with a month's worth of data placed into 5-minute bins (288 samples/day). I initially rebinned to 1-hour but I wasn't sure whether or not that might hide certain higher frequency patterns or if it would just make it too noisy.\n\nI'm also attempting to tune the window_size parameter used by the STUMPY python library (stumpy.stumpy function). This adjusts the length of the segments that the matrix profile algorithm uses to compare to measure similarity. If the window size is too small (fewer points), you are more likely to get incidental matches. If it's too large, you're less likely to appropriately match similar patterns.\n\nThere is seasonality in the series that reflects diurnal patters (activity spikes during peak operational hours and drops out during off-peak hours). Because of this, I wanted a window size of at least half a day (144 for 5m bins, 12 for 1h bins) or a third of a day (96 for 5m bins, 8 for 1h bins) to achieve the Nyquist frequency of the seasonality, if that makes sense.\n\nAre there any tests that I could run to help identify and optimize both the size of the time bins and the window size?\n\nOne thing I noticed is that when adjusting the window size, the rate of change of the number of detected motifs isn't linear. I have a hunch that I could probably plot it out and use the elbow method but I need a sanity check before I try it out.\n\nFor the bin size, I usually use a Power Spectral Density plot to identify dominant frequencies (I mostly use that for selecting seasonality parameters for decompositions). For the 1h bucket series, there are 1-3 dominant frequencies well above the noise floor, which is good. However, when I use the 5m bucket series, there doesn't appear to be any dominant frequencies, just noise. Would that suggest that the 5m bucket series is suboptimal in terms of bin size compared to the 1h series?\n\nI just need a second set of eyes on it to make sure I'm not misinterpreting or misunderstanding something. I'm also open to suggestions or ideas, if any are available.", "author_fullname": "t2_131bi6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "When building out a matrix profile for a time series, what tests can be used to determine that both the bin size and window size are optimal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zh6dt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696406203.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m playing around with adapting matrix profiles to my time series data and I want to ensure that the data and parameters are set correctly.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m working with a month&amp;#39;s worth of data placed into 5-minute bins (288 samples/day). I initially rebinned to 1-hour but I wasn&amp;#39;t sure whether or not that might hide certain higher frequency patterns or if it would just make it too noisy.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also attempting to tune the window_size parameter used by the STUMPY python library (stumpy.stumpy function). This adjusts the length of the segments that the matrix profile algorithm uses to compare to measure similarity. If the window size is too small (fewer points), you are more likely to get incidental matches. If it&amp;#39;s too large, you&amp;#39;re less likely to appropriately match similar patterns.&lt;/p&gt;\n\n&lt;p&gt;There is seasonality in the series that reflects diurnal patters (activity spikes during peak operational hours and drops out during off-peak hours). Because of this, I wanted a window size of at least half a day (144 for 5m bins, 12 for 1h bins) or a third of a day (96 for 5m bins, 8 for 1h bins) to achieve the Nyquist frequency of the seasonality, if that makes sense.&lt;/p&gt;\n\n&lt;p&gt;Are there any tests that I could run to help identify and optimize both the size of the time bins and the window size?&lt;/p&gt;\n\n&lt;p&gt;One thing I noticed is that when adjusting the window size, the rate of change of the number of detected motifs isn&amp;#39;t linear. I have a hunch that I could probably plot it out and use the elbow method but I need a sanity check before I try it out.&lt;/p&gt;\n\n&lt;p&gt;For the bin size, I usually use a Power Spectral Density plot to identify dominant frequencies (I mostly use that for selecting seasonality parameters for decompositions). For the 1h bucket series, there are 1-3 dominant frequencies well above the noise floor, which is good. However, when I use the 5m bucket series, there doesn&amp;#39;t appear to be any dominant frequencies, just noise. Would that suggest that the 5m bucket series is suboptimal in terms of bin size compared to the 1h series?&lt;/p&gt;\n\n&lt;p&gt;I just need a second set of eyes on it to make sure I&amp;#39;m not misinterpreting or misunderstanding something. I&amp;#39;m also open to suggestions or ideas, if any are available.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16zh6dt", "is_robot_indexable": true, "report_reasons": null, "author": "WadeEffingWilson", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16zh6dt/when_building_out_a_matrix_profile_for_a_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16zh6dt/when_building_out_a_matrix_profile_for_a_time/", "subreddit_subscribers": 1071966, "created_utc": 1696406203.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys\nI\u2019m looking for a project idea in Computer Vision. Been browsing through multiple datasets but haven\u2019t been able to think of an idea that has not been implemented before. Can you guys help me out with some ideas? I\u2019m a grad student. Thanks!", "author_fullname": "t2_6hsosf1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project Ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zcw19", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696391265.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys\nI\u2019m looking for a project idea in Computer Vision. Been browsing through multiple datasets but haven\u2019t been able to think of an idea that has not been implemented before. Can you guys help me out with some ideas? I\u2019m a grad student. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16zcw19", "is_robot_indexable": true, "report_reasons": null, "author": "Libran10", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16zcw19/project_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16zcw19/project_ideas/", "subreddit_subscribers": 1071966, "created_utc": 1696391265.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am considering comparing mutual information scores, but I also don't think I understand MI well enough. \n\nFor example, I(X;Y) = H(X) + H(Y) - H(X,Y). To me, visualizing H(X) and H(Y) as venn diagrams and H(X,Y) as the information from both X, Y (like an overlapping venn diagram) makes me think that when X, Y are disjoint, then MI is 0 and when X, Y overlap completely, then the MI score will be high. So, I'm thinking that a high MI value is \"bad\" since this means X, Y would be redundant. I am not sure if my understanding here is correct. \n\nAnother method I have tried is to binarize the data for each feature (represented as rows in my dataset) using \"present\" (1) and \"absent\" (0). The main issue I have run into doing this is that I am trying to then create a **distribution** to compare the features (such as seeing what percent of 1s and 0s I find in each feature), but here is the issue: \n\nLet's say that feature A has 50% 1s and 50% 0s, and feature B also has 50% 1s and 50% 0s. So, it will look as if the distribution of their values is identical, though it could be that feature A and B are \"opposites\":\n\nFeat. A: [0, 0, 1, 1]\n\nFeat. B: [1, 1, 0, 0]\n\nSo, I wonder if there is a better way to compare the distributions of the features once I have made the data \"present\" (1) and \"absent\" (0). \n\nI am also looking at making a Probability Density Function for each feature to compare them, but it's not clear to me how I would go about creating such a PDF for each feature given that I don't know what the probabilities associated actually are. Should I be binning the data then finding what percentage falls in these intervals?\n\n______\n\nOverall, I am looking for advice on where to find useful information on how to compare features for **unsupervised** feature selection, particularly in regards to how to use and compare mutual information scores, how to create PDFs for features, and how to compare distributions between features after they have been binned to avoid the problem I mentioned (with how [0, 0, 1, 1] and [1, 1, 0, 0] would appear to have the same distribution). \n\nRelevant textbook resources and other reliable source recommendations would be much appreciated. \n\nThank you.", "author_fullname": "t2_efotpocwb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some effective dimensionality reduction (unsupervised feature selection) techniques for a high dimensional, sparse dataset?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16z8v18", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696380115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am considering comparing mutual information scores, but I also don&amp;#39;t think I understand MI well enough. &lt;/p&gt;\n\n&lt;p&gt;For example, I(X;Y) = H(X) + H(Y) - H(X,Y). To me, visualizing H(X) and H(Y) as venn diagrams and H(X,Y) as the information from both X, Y (like an overlapping venn diagram) makes me think that when X, Y are disjoint, then MI is 0 and when X, Y overlap completely, then the MI score will be high. So, I&amp;#39;m thinking that a high MI value is &amp;quot;bad&amp;quot; since this means X, Y would be redundant. I am not sure if my understanding here is correct. &lt;/p&gt;\n\n&lt;p&gt;Another method I have tried is to binarize the data for each feature (represented as rows in my dataset) using &amp;quot;present&amp;quot; (1) and &amp;quot;absent&amp;quot; (0). The main issue I have run into doing this is that I am trying to then create a &lt;strong&gt;distribution&lt;/strong&gt; to compare the features (such as seeing what percent of 1s and 0s I find in each feature), but here is the issue: &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s say that feature A has 50% 1s and 50% 0s, and feature B also has 50% 1s and 50% 0s. So, it will look as if the distribution of their values is identical, though it could be that feature A and B are &amp;quot;opposites&amp;quot;:&lt;/p&gt;\n\n&lt;p&gt;Feat. A: [0, 0, 1, 1]&lt;/p&gt;\n\n&lt;p&gt;Feat. B: [1, 1, 0, 0]&lt;/p&gt;\n\n&lt;p&gt;So, I wonder if there is a better way to compare the distributions of the features once I have made the data &amp;quot;present&amp;quot; (1) and &amp;quot;absent&amp;quot; (0). &lt;/p&gt;\n\n&lt;p&gt;I am also looking at making a Probability Density Function for each feature to compare them, but it&amp;#39;s not clear to me how I would go about creating such a PDF for each feature given that I don&amp;#39;t know what the probabilities associated actually are. Should I be binning the data then finding what percentage falls in these intervals?&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;Overall, I am looking for advice on where to find useful information on how to compare features for &lt;strong&gt;unsupervised&lt;/strong&gt; feature selection, particularly in regards to how to use and compare mutual information scores, how to create PDFs for features, and how to compare distributions between features after they have been binned to avoid the problem I mentioned (with how [0, 0, 1, 1] and [1, 1, 0, 0] would appear to have the same distribution). &lt;/p&gt;\n\n&lt;p&gt;Relevant textbook resources and other reliable source recommendations would be much appreciated. &lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16z8v18", "is_robot_indexable": true, "report_reasons": null, "author": "MLquestionAccount", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16z8v18/what_are_some_effective_dimensionality_reduction/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16z8v18/what_are_some_effective_dimensionality_reduction/", "subreddit_subscribers": 1071966, "created_utc": 1696380115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "suppose that i have 1000 sites that i need to build a script to extract individually and need the data to be refreshed weekly, what are some tools/software that can help me to automate such task?", "author_fullname": "t2_8es0n3vl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some good scraping software to use for task automation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zldu3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696420998.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;suppose that i have 1000 sites that i need to build a script to extract individually and need the data to be refreshed weekly, what are some tools/software that can help me to automate such task?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16zldu3", "is_robot_indexable": true, "report_reasons": null, "author": "Breadskinjinhojiak", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16zldu3/what_are_some_good_scraping_software_to_use_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16zldu3/what_are_some_good_scraping_software_to_use_for/", "subreddit_subscribers": 1071966, "created_utc": 1696420998.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_2lyqh3jk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multilingual Reading Skills of Language Models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16z0pwh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": true, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1696360582.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "opensamizdat.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://www.opensamizdat.com/posts/belebele/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16z0pwh", "is_robot_indexable": true, "report_reasons": null, "author": "matus_pikuliak", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16z0pwh/multilingual_reading_skills_of_language_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.opensamizdat.com/posts/belebele/", "subreddit_subscribers": 1071966, "created_utc": 1696360582.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I've been working as an ML Engineer/Researcher intern for last three months first several months were cool, been writing scripts for cropping images, etc. everything went well. Not so long ago I've started working on NLP projects, and been asked to checkout how possible it is to fine-tune sota models on low-end hardware. \n\nI've started going through sota models and found some of them which would fit on gpu. However, what I came into is that for 10 different models you usually have 10 different APIs because of quantisation methods, chatlikenes, languages weights etc... \n\nI have to go through TONS of trial and error WAITING for model weights to load on my pc just to learn that I need to wait MORE to find out that it works at 1tok/eternity or doesn't work because of mismatch of versions, then you go to Collab go through the same process, get crashes, timeouts, etc., you get the idea. \n\nWhat frustrates me the most is the WAITING and NO results. I usually have 27281 pages opened to find the right guide (because half of them result in error and others are outdated because they are 2 seconds old). \n\nHow do I deal with such kind of frustration and not leave state of flow?\n\n It doesn't seem like I don't understand something during the job, I use as much ready solutions as I can, however it feels like poking a black box and waiting 30 minutes and trying again to make it work in comparison to more \"developmenty\" tasks when you just write the code and everything works as you suppose and it's easy to track you progress and you \"feel\" the progress or at least constantly in a flow state not waiting for something to happen.", "author_fullname": "t2_2hdao3wq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to do with frustrating tasks when you don't feel the progress or it's very slow?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ztxgl", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696442124.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been working as an ML Engineer/Researcher intern for last three months first several months were cool, been writing scripts for cropping images, etc. everything went well. Not so long ago I&amp;#39;ve started working on NLP projects, and been asked to checkout how possible it is to fine-tune sota models on low-end hardware. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve started going through sota models and found some of them which would fit on gpu. However, what I came into is that for 10 different models you usually have 10 different APIs because of quantisation methods, chatlikenes, languages weights etc... &lt;/p&gt;\n\n&lt;p&gt;I have to go through TONS of trial and error WAITING for model weights to load on my pc just to learn that I need to wait MORE to find out that it works at 1tok/eternity or doesn&amp;#39;t work because of mismatch of versions, then you go to Collab go through the same process, get crashes, timeouts, etc., you get the idea. &lt;/p&gt;\n\n&lt;p&gt;What frustrates me the most is the WAITING and NO results. I usually have 27281 pages opened to find the right guide (because half of them result in error and others are outdated because they are 2 seconds old). &lt;/p&gt;\n\n&lt;p&gt;How do I deal with such kind of frustration and not leave state of flow?&lt;/p&gt;\n\n&lt;p&gt;It doesn&amp;#39;t seem like I don&amp;#39;t understand something during the job, I use as much ready solutions as I can, however it feels like poking a black box and waiting 30 minutes and trying again to make it work in comparison to more &amp;quot;developmenty&amp;quot; tasks when you just write the code and everything works as you suppose and it&amp;#39;s easy to track you progress and you &amp;quot;feel&amp;quot; the progress or at least constantly in a flow state not waiting for something to happen.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16ztxgl", "is_robot_indexable": true, "report_reasons": null, "author": "gdl68", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16ztxgl/what_to_do_with_frustrating_tasks_when_you_dont/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16ztxgl/what_to_do_with_frustrating_tasks_when_you_dont/", "subreddit_subscribers": 1071966, "created_utc": 1696442124.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Greetings fellow Data Scientists !  \n\n\nI've been finding myself more inclined towards writing lately and I wanted to share something I've been working on for the past weeks.\n\nI recently updated the look and feel of my personal space: **ConsciousML Blog !**\n\nSome updates about the blog:  \n\u25cf Fresh, minimalist design.  \n\u25cf Focusing more on consciousness and productivity - topics close to my heart.  \n\u25cf Starting a newsletter for updates.  \n\u25cf Planning to release one AI or productivity article every week.\n\nThe core purpose is still the same: A space to share my thoughts and my experiences in building machine learning solutions.\n\nCheck it out here: [https://blog.axelmendoza.fr/](https://blog.axelmendoza.fr/)\n\nAppreciate everyone who takes a moment to read. Any feedback to improve the medium would be greatly appreciated !", "author_fullname": "t2_2g16z8fd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ConsciousML Blog - Mindful AI meets Productive Living", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zsvcp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696439610.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Greetings fellow Data Scientists !  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been finding myself more inclined towards writing lately and I wanted to share something I&amp;#39;ve been working on for the past weeks.&lt;/p&gt;\n\n&lt;p&gt;I recently updated the look and feel of my personal space: &lt;strong&gt;ConsciousML Blog !&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Some updates about the blog:&lt;br/&gt;\n\u25cf Fresh, minimalist design.&lt;br/&gt;\n\u25cf Focusing more on consciousness and productivity - topics close to my heart.&lt;br/&gt;\n\u25cf Starting a newsletter for updates.&lt;br/&gt;\n\u25cf Planning to release one AI or productivity article every week.&lt;/p&gt;\n\n&lt;p&gt;The core purpose is still the same: A space to share my thoughts and my experiences in building machine learning solutions.&lt;/p&gt;\n\n&lt;p&gt;Check it out here: &lt;a href=\"https://blog.axelmendoza.fr/\"&gt;https://blog.axelmendoza.fr/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Appreciate everyone who takes a moment to read. Any feedback to improve the medium would be greatly appreciated !&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/bq5kmCMB9ofoZ1V-9eqsfPQzLxA8boDfTu3_FhslsNU.jpg?auto=webp&amp;s=a4611ff5b3c9f2f57d91203d72196e2292fa2f76", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/bq5kmCMB9ofoZ1V-9eqsfPQzLxA8boDfTu3_FhslsNU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a7f48b1973a5fc2026b09d80f5bd9c5204cd1c37", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/bq5kmCMB9ofoZ1V-9eqsfPQzLxA8boDfTu3_FhslsNU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=699419753c65a606178ee7e406e9cb01a1caab93", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/bq5kmCMB9ofoZ1V-9eqsfPQzLxA8boDfTu3_FhslsNU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=60ec9896bb9fa996f5d53e35a4b7f8cafc07b2aa", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/bq5kmCMB9ofoZ1V-9eqsfPQzLxA8boDfTu3_FhslsNU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=4268e1134add01fcd119b076be18ee8170d0adcf", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/bq5kmCMB9ofoZ1V-9eqsfPQzLxA8boDfTu3_FhslsNU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=64a57403e31a1edc4a7a5e849e049dc974a71c96", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/bq5kmCMB9ofoZ1V-9eqsfPQzLxA8boDfTu3_FhslsNU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1fa1de61a612edafa2079254ed9bfb749426972a", "width": 1080, "height": 567}], "variants": {}, "id": "W_XA0S42nt_vH48VBqD6UiKnaAO2GCWnT_-19scpUjE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16zsvcp", "is_robot_indexable": true, "report_reasons": null, "author": "GrixisNow", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16zsvcp/consciousml_blog_mindful_ai_meets_productive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16zsvcp/consciousml_blog_mindful_ai_meets_productive/", "subreddit_subscribers": 1071966, "created_utc": 1696439610.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So, a few months ago, I started developing this deep learning model, which was made purely to differentiate whether the input image is driftwood floating in water or a crocodile. To my knowledge, I leveraged the resnet50 pre-trained SoTA model to train my deep learning model, and for that, I downloaded almost 5k images of driftwood and crocodiles for my model training. Once the training was complete, I took the next step and deployed my model on the Hugging Face Spaces app, allowing my friends to put it to the test. But here's where I ran into a significant challenge: users could even upload their own selfies, and my model would attempt to predict whether they were a crocodile or a piece of driftwood!\n\nSo how can I leverage object detection or the image segmentation pipeline so that when the user inputs their image, it tries to detect the object from the photo and then detect whether the detected object from the given image contains a crocodile or not? If the crocodile or driftwood is not found, then it should return \"No object found\" or like that.", "author_fullname": "t2_iygdn4q4v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I apply object detection and image segmentation functionality to my current custom-trained Image Classification model?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zsikw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696438757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So, a few months ago, I started developing this deep learning model, which was made purely to differentiate whether the input image is driftwood floating in water or a crocodile. To my knowledge, I leveraged the resnet50 pre-trained SoTA model to train my deep learning model, and for that, I downloaded almost 5k images of driftwood and crocodiles for my model training. Once the training was complete, I took the next step and deployed my model on the Hugging Face Spaces app, allowing my friends to put it to the test. But here&amp;#39;s where I ran into a significant challenge: users could even upload their own selfies, and my model would attempt to predict whether they were a crocodile or a piece of driftwood!&lt;/p&gt;\n\n&lt;p&gt;So how can I leverage object detection or the image segmentation pipeline so that when the user inputs their image, it tries to detect the object from the photo and then detect whether the detected object from the given image contains a crocodile or not? If the crocodile or driftwood is not found, then it should return &amp;quot;No object found&amp;quot; or like that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16zsikw", "is_robot_indexable": true, "report_reasons": null, "author": "meWhoObserves", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16zsikw/how_can_i_apply_object_detection_and_image/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16zsikw/how_can_i_apply_object_detection_and_image/", "subreddit_subscribers": 1071966, "created_utc": 1696438757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " Hey everyone!\n\nCurrently,  I am working on a project around music emotion classifcation/regression  model. Basically I am trying to predict a score to each emotion on a  given song.\n\nThe problem is that my  dataset has quite imbalanced scores (y). Most scores are centered  around a certain score range. Therefore, having difficulties predicting  scores that are further away of the mean values.\n\nI  had this idea to bring in pre-trained (on other datasets and problems)  audio classification models into this as there are a bunch of good  performing pre-trained classification models out there already. The  prediction of these pre-trained models should be used as features (e.g.  prediction of genre, instrument etc) beside the original spectorgram in  my model.\n\nI know this won't solve  the problem of imbalances in the scores but I thought maybe this could  improve the performance as the model would have more features to work  with.\n\nDoes this make sense?\n\nI appreciate any input.", "author_fullname": "t2_8puue", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Using pre-trained models as features?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zi4jk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696409924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;Currently,  I am working on a project around music emotion classifcation/regression  model. Basically I am trying to predict a score to each emotion on a  given song.&lt;/p&gt;\n\n&lt;p&gt;The problem is that my  dataset has quite imbalanced scores (y). Most scores are centered  around a certain score range. Therefore, having difficulties predicting  scores that are further away of the mean values.&lt;/p&gt;\n\n&lt;p&gt;I  had this idea to bring in pre-trained (on other datasets and problems)  audio classification models into this as there are a bunch of good  performing pre-trained classification models out there already. The  prediction of these pre-trained models should be used as features (e.g.  prediction of genre, instrument etc) beside the original spectorgram in  my model.&lt;/p&gt;\n\n&lt;p&gt;I know this won&amp;#39;t solve  the problem of imbalances in the scores but I thought maybe this could  improve the performance as the model would have more features to work  with.&lt;/p&gt;\n\n&lt;p&gt;Does this make sense?&lt;/p&gt;\n\n&lt;p&gt;I appreciate any input.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16zi4jk", "is_robot_indexable": true, "report_reasons": null, "author": "Kniggi", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16zi4jk/using_pretrained_models_as_features/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16zi4jk/using_pretrained_models_as_features/", "subreddit_subscribers": 1071966, "created_utc": 1696409924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Was wondering if anyone gave the Data Analytics Framework assessment. \n\nTime crunch is a major factor I feel. The last of the questions and ability not to view SQL ctes were nightmare. \n\n&amp;#x200B;\n\nScore 338/600 after solving 10 questions out of 15. Is this any good ? ", "author_fullname": "t2_54ssx12h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Code Signal Data Analytics Framework Questions ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16z0gck", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696359925.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Was wondering if anyone gave the Data Analytics Framework assessment. &lt;/p&gt;\n\n&lt;p&gt;Time crunch is a major factor I feel. The last of the questions and ability not to view SQL ctes were nightmare. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Score 338/600 after solving 10 questions out of 15. Is this any good ? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16z0gck", "is_robot_indexable": true, "report_reasons": null, "author": "Dry-Growth4940", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16z0gck/code_signal_data_analytics_framework_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16z0gck/code_signal_data_analytics_framework_questions/", "subreddit_subscribers": 1071966, "created_utc": 1696359925.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "We are in the process of developing a data analytics platform for our client. This platform is primarily built using Python and Dash. We're exploring options to allow our clients to provide comments on each section of the analytics platform containing multiple pages.\n\nDoes anyone know of any methods or tools that would facilitate this interactive feedback mechanism.\n\n&amp;#x200B;\n\nIt would be better if we could track individual user comments. ", "author_fullname": "t2_m0r3pnug", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Feedback Mechanism for Our Python/Dash Analytics Platform", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zi29z", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696410240.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696409667.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are in the process of developing a data analytics platform for our client. This platform is primarily built using Python and Dash. We&amp;#39;re exploring options to allow our clients to provide comments on each section of the analytics platform containing multiple pages.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know of any methods or tools that would facilitate this interactive feedback mechanism.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;It would be better if we could track individual user comments. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16zi29z", "is_robot_indexable": true, "report_reasons": null, "author": "Alertt_53", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16zi29z/seeking_feedback_mechanism_for_our_pythondash/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16zi29z/seeking_feedback_mechanism_for_our_pythondash/", "subreddit_subscribers": 1071966, "created_utc": 1696409667.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Everyone has problems related to building AI/ML models with data. Maybe it\u2019s collecting data, synthesizing data, training a model, etc.\n\nWhich part of the workflow sucks the most? What solution would you propose?", "author_fullname": "t2_l10ic37ez", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is a dream solution (software) to fix your problems at work?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zbst6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696388038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Everyone has problems related to building AI/ML models with data. Maybe it\u2019s collecting data, synthesizing data, training a model, etc.&lt;/p&gt;\n\n&lt;p&gt;Which part of the workflow sucks the most? What solution would you propose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16zbst6", "is_robot_indexable": true, "report_reasons": null, "author": "Potanee", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16zbst6/what_is_a_dream_solution_software_to_fix_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16zbst6/what_is_a_dream_solution_software_to_fix_your/", "subreddit_subscribers": 1071966, "created_utc": 1696388038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I work in consultancy but I'm considering a pivot into data analysis. However, I am worried that companies can easily hire data analysts and scientists in other countries for a lot cheaper whereas consultancy is better protected against this due to the importance of face to face meetings, on site work and local knowledge.\n\nDue to Covid, many companies have learnt how to create remote teams, which may accelerate this change further. \n\nIs this a major risk over the next five to 10 years? Can we expect fewer jobs in The West and lower wages due to outsourcing to other countries and remote working?", "author_fullname": "t2_d3239yyip", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you worry that outsourcing will take your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16z8d2e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696378790.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work in consultancy but I&amp;#39;m considering a pivot into data analysis. However, I am worried that companies can easily hire data analysts and scientists in other countries for a lot cheaper whereas consultancy is better protected against this due to the importance of face to face meetings, on site work and local knowledge.&lt;/p&gt;\n\n&lt;p&gt;Due to Covid, many companies have learnt how to create remote teams, which may accelerate this change further. &lt;/p&gt;\n\n&lt;p&gt;Is this a major risk over the next five to 10 years? Can we expect fewer jobs in The West and lower wages due to outsourcing to other countries and remote working?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16z8d2e", "is_robot_indexable": true, "report_reasons": null, "author": "John198777", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16z8d2e/do_you_worry_that_outsourcing_will_take_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16z8d2e/do_you_worry_that_outsourcing_will_take_your_job/", "subreddit_subscribers": 1071966, "created_utc": 1696378790.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm looking to read more on this topic mentioned in the title.\n\n&amp;#x200B;\n\nFeel free to suggest books and articles", "author_fullname": "t2_3c6tuua1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI\u2019s Data Cannibalism", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16znm3n", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.17, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696427020.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking to read more on this topic mentioned in the title.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Feel free to suggest books and articles&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16znm3n", "is_robot_indexable": true, "report_reasons": null, "author": "_rshaedy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16znm3n/ais_data_cannibalism/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16znm3n/ais_data_cannibalism/", "subreddit_subscribers": 1071966, "created_utc": 1696427020.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a data scientist. I usually build ML models and convert them into streamlit apps. Does anyone know any tools that helps automatically convert my python/ML code into streamlit app so i can save the hassle.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_ihuaripf1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone know any tools that helps people convert their python code into streamlit apps?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zgo76", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696404228.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a data scientist. I usually build ML models and convert them into streamlit apps. Does anyone know any tools that helps automatically convert my python/ML code into streamlit app so i can save the hassle.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16zgo76", "is_robot_indexable": true, "report_reasons": null, "author": "swesweee", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16zgo76/does_anyone_know_any_tools_that_helps_people/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16zgo76/does_anyone_know_any_tools_that_helps_people/", "subreddit_subscribers": 1071966, "created_utc": 1696404228.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a FAANG data scientist with 5+ years of experience; I've grown increasingly concerned that LLMs will begin to replace a LOT of the work that data professionals currently do. From easy things like dashboard generation to tough things like specific deep dive research questions, seem like we're walking into a world where the skillset of the analyst / scientist is a pre-req for a different position as opposed to a job in and of itself.\n\nThoughts? How are you preparing for much of this work to become automated? What other skills do you think are on the horizon (please don't say prompt engineering)?", "author_fullname": "t2_d0szud2kt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LLMs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16z3y8h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696368221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a FAANG data scientist with 5+ years of experience; I&amp;#39;ve grown increasingly concerned that LLMs will begin to replace a LOT of the work that data professionals currently do. From easy things like dashboard generation to tough things like specific deep dive research questions, seem like we&amp;#39;re walking into a world where the skillset of the analyst / scientist is a pre-req for a different position as opposed to a job in and of itself.&lt;/p&gt;\n\n&lt;p&gt;Thoughts? How are you preparing for much of this work to become automated? What other skills do you think are on the horizon (please don&amp;#39;t say prompt engineering)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "16z3y8h", "is_robot_indexable": true, "report_reasons": null, "author": "Particular-Yam-7117", "discussion_type": null, "num_comments": 115, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/16z3y8h/llms/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/16z3y8h/llms/", "subreddit_subscribers": 1071966, "created_utc": 1696368221.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}