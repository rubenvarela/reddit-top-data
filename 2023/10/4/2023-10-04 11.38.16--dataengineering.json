{"kind": "Listing", "data": {"after": "t3_16zb1ah", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Iv been a DE for around 5 years now. I love working with data, building pipelines, ML platforms, supporting BI/DA/DS teams, etc. But I HATE dev ops.\n\nI work for a company with a pretty complex cloud environment setup. Handling permissions and networking between microservices takes up about 80% of my daily energy.\n\nIt seems like a lot of DE jobs require quite a bit of devops work. Is this true?\n\nHow do I transition to a role that focuses less on devops and more on software design/performance? Iv been thinking of Skilling up and trying to transition into an ML. Engineer role. Would a role like that theoretically have less devops responsibility?", "author_fullname": "t2_hc5pt3hd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I get away from devops", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ysjx8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 49, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 49, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696341226.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Iv been a DE for around 5 years now. I love working with data, building pipelines, ML platforms, supporting BI/DA/DS teams, etc. But I HATE dev ops.&lt;/p&gt;\n\n&lt;p&gt;I work for a company with a pretty complex cloud environment setup. Handling permissions and networking between microservices takes up about 80% of my daily energy.&lt;/p&gt;\n\n&lt;p&gt;It seems like a lot of DE jobs require quite a bit of devops work. Is this true?&lt;/p&gt;\n\n&lt;p&gt;How do I transition to a role that focuses less on devops and more on software design/performance? Iv been thinking of Skilling up and trying to transition into an ML. Engineer role. Would a role like that theoretically have less devops responsibility?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16ysjx8", "is_robot_indexable": true, "report_reasons": null, "author": "burns_after_reading", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ysjx8/how_do_i_get_away_from_devops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ysjx8/how_do_i_get_away_from_devops/", "subreddit_subscribers": 131988, "created_utc": 1696341226.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019ve been reading a lot about polars but one thing about the industry I\u2019ve seen is that new technologies come and have a a lot of hype but do not cause any real change to the current accepted stack. \n\nI\u2019m wondering if this subreddit feels the same way about it as me. Obviously it\u2019s good to keep learning but between getting better at pyspark vs Polars I\u2019m wondering which should be the focus", "author_fullname": "t2_xzn0c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is Polaris worth learning over pyspark? Or is it just hype while the industry has no intention of moving away from a Apache/Cloud framework", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yx6f1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696388127.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696352149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve been reading a lot about polars but one thing about the industry I\u2019ve seen is that new technologies come and have a a lot of hype but do not cause any real change to the current accepted stack. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m wondering if this subreddit feels the same way about it as me. Obviously it\u2019s good to keep learning but between getting better at pyspark vs Polars I\u2019m wondering which should be the focus&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16yx6f1", "is_robot_indexable": true, "report_reasons": null, "author": "richhoods", "discussion_type": null, "num_comments": 52, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yx6f1/is_polaris_worth_learning_over_pyspark_or_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yx6f1/is_polaris_worth_learning_over_pyspark_or_is_it/", "subreddit_subscribers": 131988, "created_utc": 1696352149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI should preface this by saying I'm a complete noob but I'd like to learn about relational databases and SQL.\n\nI'm playing around with \"historical weather data\" produced by ERA5 which provides e.g. hourly temperatures globally at 0.25 degree resolution. The problem is that the data stretches back to 1940 so that's roughly (83 years) * (24*365 hours per year) * (360/0.25 * 180/0.25 grid points) = 754 billions rows per variable.\n\nI'm finding it very slow to copy the data into Postgres even using: https://www.psycopg.org/psycopg3/docs/basic/copy.html#writing-data-row-by-row\n\nI thought PostgresSQL might be a good option, possibly with PostGIS and/or TimescaleDB, but thought I'd start with just Postgres.\n\nAm I taking a bad approach here? Should I consider another kind of database? Or am I just not loading my data in properly?\n\nI'm also worried Postgres won't compress this data well, but haven't played around with this yet (might be where TimescaleDB helps?).\n\nThank you so much for any advice you guys might have!", "author_fullname": "t2_12i7gz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to efficiently load ~20 TiB of weather data into a new PostgresSQL database? Is PostgresSQL even a good option?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16z8h6l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 33, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 33, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696379095.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I should preface this by saying I&amp;#39;m a complete noob but I&amp;#39;d like to learn about relational databases and SQL.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m playing around with &amp;quot;historical weather data&amp;quot; produced by ERA5 which provides e.g. hourly temperatures globally at 0.25 degree resolution. The problem is that the data stretches back to 1940 so that&amp;#39;s roughly (83 years) * (24*365 hours per year) * (360/0.25 * 180/0.25 grid points) = 754 billions rows per variable.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m finding it very slow to copy the data into Postgres even using: &lt;a href=\"https://www.psycopg.org/psycopg3/docs/basic/copy.html#writing-data-row-by-row\"&gt;https://www.psycopg.org/psycopg3/docs/basic/copy.html#writing-data-row-by-row&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I thought PostgresSQL might be a good option, possibly with PostGIS and/or TimescaleDB, but thought I&amp;#39;d start with just Postgres.&lt;/p&gt;\n\n&lt;p&gt;Am I taking a bad approach here? Should I consider another kind of database? Or am I just not loading my data in properly?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m also worried Postgres won&amp;#39;t compress this data well, but haven&amp;#39;t played around with this yet (might be where TimescaleDB helps?).&lt;/p&gt;\n\n&lt;p&gt;Thank you so much for any advice you guys might have!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16z8h6l", "is_robot_indexable": true, "report_reasons": null, "author": "DeadDolphinResearch", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16z8h6l/how_to_efficiently_load_20_tib_of_weather_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16z8h6l/how_to_efficiently_load_20_tib_of_weather_data/", "subreddit_subscribers": 131988, "created_utc": 1696379095.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been working as a big data engineer for 5 years, and every day I realize that the topics are too broad and complex. I often get lost and don't know what to study in depth.\n\nDo you have any advice on how to become a good data engineer?\nHow many books do you read in a year?\nHow many hours a day do you study? (Outside of working hours).\n\nAny advice is welcome, thanks in advance", "author_fullname": "t2_6n4s0awu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much time do you study each day?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16z4nwt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696369828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been working as a big data engineer for 5 years, and every day I realize that the topics are too broad and complex. I often get lost and don&amp;#39;t know what to study in depth.&lt;/p&gt;\n\n&lt;p&gt;Do you have any advice on how to become a good data engineer?\nHow many books do you read in a year?\nHow many hours a day do you study? (Outside of working hours).&lt;/p&gt;\n\n&lt;p&gt;Any advice is welcome, thanks in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16z4nwt", "is_robot_indexable": true, "report_reasons": null, "author": "el_cortezzz", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16z4nwt/how_much_time_do_you_study_each_day/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16z4nwt/how_much_time_do_you_study_each_day/", "subreddit_subscribers": 131988, "created_utc": 1696369828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there, so ive been on the internship hunt for quite a long time now and 2 of the 3 interviews I've managed to get thus far I've wound up getting surprised with a surprising amount of DS questions (stats, ML modeling experience, prior work with DS/ML tools) along with typical SQL + Data Modeling, Python, Data Integration/Orchestration tooling questions.\n\nThe thing is this hasn't always been very explicit in the job posting and I've only really taken intro-level coursework in stats and ML (almost entirely intro-level supervised learning concepts and models, lightly touched unsupervised learning at the end) so I'm very weak footed when answering DS questions that go much further beyond basic regression in complexity. Im now wondering if I need to sit down and spend time improving that side of my skillset?\n\nIts also extra stressful because doing an internship is a mandatory part of my undergrad program to graduate and with how brutally slim job postings are on average I cant afford to keep slipping on these interviews", "author_fullname": "t2_pfwkw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it typical to see Data Engineer and Data Science duties intertwined on Internship roles with smaller companies?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yx85g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696352967.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696352268.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there, so ive been on the internship hunt for quite a long time now and 2 of the 3 interviews I&amp;#39;ve managed to get thus far I&amp;#39;ve wound up getting surprised with a surprising amount of DS questions (stats, ML modeling experience, prior work with DS/ML tools) along with typical SQL + Data Modeling, Python, Data Integration/Orchestration tooling questions.&lt;/p&gt;\n\n&lt;p&gt;The thing is this hasn&amp;#39;t always been very explicit in the job posting and I&amp;#39;ve only really taken intro-level coursework in stats and ML (almost entirely intro-level supervised learning concepts and models, lightly touched unsupervised learning at the end) so I&amp;#39;m very weak footed when answering DS questions that go much further beyond basic regression in complexity. Im now wondering if I need to sit down and spend time improving that side of my skillset?&lt;/p&gt;\n\n&lt;p&gt;Its also extra stressful because doing an internship is a mandatory part of my undergrad program to graduate and with how brutally slim job postings are on average I cant afford to keep slipping on these interviews&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16yx85g", "is_robot_indexable": true, "report_reasons": null, "author": "Anic135", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yx85g/is_it_typical_to_see_data_engineer_and_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yx85g/is_it_typical_to_see_data_engineer_and_data/", "subreddit_subscribers": 131988, "created_utc": 1696352268.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'd just like to get an idea of what some people have done in the field.", "author_fullname": "t2_imajwwpcb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone have any good GitHub profiles for data engineering examples? (Not SQL - ideally Python)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zg1po", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696401878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d just like to get an idea of what some people have done in the field.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zg1po", "is_robot_indexable": true, "report_reasons": null, "author": "al-hamal", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zg1po/does_anyone_have_any_good_github_profiles_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zg1po/does_anyone_have_any_good_github_profiles_for/", "subreddit_subscribers": 131988, "created_utc": 1696401878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "**Background:**   \nI am an analyst in an oil &amp; gas company who is interested in data engineering. Been working for about 10 years, most of it not related my current role as an analyst but specific to my industry. My background is not computer science, but chemical engineering. I've been doing a lot more python &amp; SQL. I'm getting much more used to the AWS tech stack (Glue, s3, redshift). \n\nI was in a meeting with him and reached out after the meeting to tell him I am interested in data engineering. I asked if he'd be willing to talk to me. He nicely agreed.\n\n**Why I'm nervous:**\n\nI don't want to waste this opportunity. I am used to the corporate networking, but I'm trying to sell myself and pivot into something quite frankly I don't have a lot of expertise in. One of my concerns is that to get a role I've heard they require testing and a technical interview (coding interview) even for internal. So I'm mostly scared that I won't be able to handle the technical parts!\n\n**Here are some questions I was thinking about**\n\n* Tell me about yourself (always gotta start with the classics)\n* Are there any opportunities to practice or learn more of the DE side?\n* Is there any advice you'd give to someone without a CS background to demonstrate their capability?\n\nAny other advice, questions, or a reminder of \"hey you're overthinking this\"", "author_fullname": "t2_7upjb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Speaking with head of data engineering for career pivot, what should I ask?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zafs9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696384323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;br/&gt;\nI am an analyst in an oil &amp;amp; gas company who is interested in data engineering. Been working for about 10 years, most of it not related my current role as an analyst but specific to my industry. My background is not computer science, but chemical engineering. I&amp;#39;ve been doing a lot more python &amp;amp; SQL. I&amp;#39;m getting much more used to the AWS tech stack (Glue, s3, redshift). &lt;/p&gt;\n\n&lt;p&gt;I was in a meeting with him and reached out after the meeting to tell him I am interested in data engineering. I asked if he&amp;#39;d be willing to talk to me. He nicely agreed.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why I&amp;#39;m nervous:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t want to waste this opportunity. I am used to the corporate networking, but I&amp;#39;m trying to sell myself and pivot into something quite frankly I don&amp;#39;t have a lot of expertise in. One of my concerns is that to get a role I&amp;#39;ve heard they require testing and a technical interview (coding interview) even for internal. So I&amp;#39;m mostly scared that I won&amp;#39;t be able to handle the technical parts!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Here are some questions I was thinking about&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Tell me about yourself (always gotta start with the classics)&lt;/li&gt;\n&lt;li&gt;Are there any opportunities to practice or learn more of the DE side?&lt;/li&gt;\n&lt;li&gt;Is there any advice you&amp;#39;d give to someone without a CS background to demonstrate their capability?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Any other advice, questions, or a reminder of &amp;quot;hey you&amp;#39;re overthinking this&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16zafs9", "is_robot_indexable": true, "report_reasons": null, "author": "chlor8", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zafs9/speaking_with_head_of_data_engineering_for_career/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zafs9/speaking_with_head_of_data_engineering_for_career/", "subreddit_subscribers": 131988, "created_utc": 1696384323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been tasked with centrally documenting a BI product and I am wondering how professionals approach this problem as I am relatively new to this field of work.\n\nThis product in short boils down to: get data from source system --&gt; select and transform data in SQL --&gt; store created tables in data warehouse --&gt; load in Power BI.\n\nOf course there is a number of standard approaches in place such as commenting the SQL queries etc. but I am trying to find the best way to centrally store all underlying relationships in this data product. Such that for every Power BI measure, I store the used data warehouse column(s) and the source column(s) used to generate said data warehouse column(s).\n\nI attached a visual example of the relationships I am trying to centrally document, quickly written up in MS Excel style. In the example *my\\_powerbi\\_measure\\_1* is created using *my\\_datawarehouse\\_column1*/*2*/*3* and *my\\_datawarehouse\\_column1* is created using *my\\_sourcedata\\_column1*.\n\n&amp;#x200B;\n\nWhat are tools or documentation approaches you guys use, or would use, to get to this central documentation of data flows? All ideas and tips are appreciated!\n\n&amp;#x200B;\n\n[Visual example](https://preview.redd.it/gkr7g6cs80sb1.png?width=1023&amp;format=png&amp;auto=webp&amp;s=2d61ee6c27f787bd23ec9074fdff6a4a1488fdc3)", "author_fullname": "t2_3tjzfxzi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Centrally documenting data flows of a BI product", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 37, "top_awarded_type": null, "hide_score": false, "media_metadata": {"gkr7g6cs80sb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 28, "x": 108, "u": "https://preview.redd.it/gkr7g6cs80sb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ddacf8e0df5a525fd12de3e7faff4cee91e28338"}, {"y": 57, "x": 216, "u": "https://preview.redd.it/gkr7g6cs80sb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=e90d278173bca8eef273915d4ec22c16f55f7e15"}, {"y": 85, "x": 320, "u": "https://preview.redd.it/gkr7g6cs80sb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=0b6d7fac4d1bdb877c7b34afab7627f52e9a6a4d"}, {"y": 171, "x": 640, "u": "https://preview.redd.it/gkr7g6cs80sb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=587548bb83d6e2ab9a4ff7031ad7b27e5c7720a2"}, {"y": 257, "x": 960, "u": "https://preview.redd.it/gkr7g6cs80sb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=7857a6bc212c9ce6086927a4113ecaac6ade0622"}], "s": {"y": 274, "x": 1023, "u": "https://preview.redd.it/gkr7g6cs80sb1.png?width=1023&amp;format=png&amp;auto=webp&amp;s=2d61ee6c27f787bd23ec9074fdff6a4a1488fdc3"}, "id": "gkr7g6cs80sb1"}}, "name": "t3_16yuq2k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nAeYY4IgGMBgUxkb7oPsBq8oEFo3Uy6L8SJPVkWvKic.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696346440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been tasked with centrally documenting a BI product and I am wondering how professionals approach this problem as I am relatively new to this field of work.&lt;/p&gt;\n\n&lt;p&gt;This product in short boils down to: get data from source system --&amp;gt; select and transform data in SQL --&amp;gt; store created tables in data warehouse --&amp;gt; load in Power BI.&lt;/p&gt;\n\n&lt;p&gt;Of course there is a number of standard approaches in place such as commenting the SQL queries etc. but I am trying to find the best way to centrally store all underlying relationships in this data product. Such that for every Power BI measure, I store the used data warehouse column(s) and the source column(s) used to generate said data warehouse column(s).&lt;/p&gt;\n\n&lt;p&gt;I attached a visual example of the relationships I am trying to centrally document, quickly written up in MS Excel style. In the example &lt;em&gt;my_powerbi_measure_1&lt;/em&gt; is created using &lt;em&gt;my_datawarehouse_column1&lt;/em&gt;/&lt;em&gt;2&lt;/em&gt;/&lt;em&gt;3&lt;/em&gt; and &lt;em&gt;my_datawarehouse_column1&lt;/em&gt; is created using &lt;em&gt;my_sourcedata_column1&lt;/em&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What are tools or documentation approaches you guys use, or would use, to get to this central documentation of data flows? All ideas and tips are appreciated!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/gkr7g6cs80sb1.png?width=1023&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=2d61ee6c27f787bd23ec9074fdff6a4a1488fdc3\"&gt;Visual example&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16yuq2k", "is_robot_indexable": true, "report_reasons": null, "author": "basr98", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yuq2k/centrally_documenting_data_flows_of_a_bi_product/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yuq2k/centrally_documenting_data_flows_of_a_bi_product/", "subreddit_subscribers": 131988, "created_utc": 1696346440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm pulling data from a realtime feed at the moment, about 200k records and then pushing them to a Kinesis Data Firehose.  I've experimented with batch sizes and the like, but at the moment I'm seeing that the 200k records when serialised is about 20MB, and the batch and write to disk as parquet via KDF is taking a couple of minutes.  \n\n\nThe realtime feed is updated every 15 seconds, but I'm so far unable to ingest at that rate, so I've dialled it back to every 2 minutes for the time being.\n\nCurrently the task is billed for Lambda, KDF and S3.\n\nI've been experimenting and using Polars to make the 200k records into a dataframe and then writing it directly to S3. It takes about 15 seconds and the parquet file is about 700kb. It's light years faster and cheaper than KDF and I can run it at a faster rate than the KDF.\n\nThe overhead is Lambda and S3.  \n\n\nNow I understand that if you can't afford to drop/loose any of the data, then you need to have a data stream manager of some flavour, but why is it so much slower and so much more expensive?  \n\n\nI'm missing something in regards to the sweet-spot for using the product.", "author_fullname": "t2_ahkdvv1hd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Lambda to Firehose vs directly to S3", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16z5j8q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696371824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m pulling data from a realtime feed at the moment, about 200k records and then pushing them to a Kinesis Data Firehose.  I&amp;#39;ve experimented with batch sizes and the like, but at the moment I&amp;#39;m seeing that the 200k records when serialised is about 20MB, and the batch and write to disk as parquet via KDF is taking a couple of minutes.  &lt;/p&gt;\n\n&lt;p&gt;The realtime feed is updated every 15 seconds, but I&amp;#39;m so far unable to ingest at that rate, so I&amp;#39;ve dialled it back to every 2 minutes for the time being.&lt;/p&gt;\n\n&lt;p&gt;Currently the task is billed for Lambda, KDF and S3.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been experimenting and using Polars to make the 200k records into a dataframe and then writing it directly to S3. It takes about 15 seconds and the parquet file is about 700kb. It&amp;#39;s light years faster and cheaper than KDF and I can run it at a faster rate than the KDF.&lt;/p&gt;\n\n&lt;p&gt;The overhead is Lambda and S3.  &lt;/p&gt;\n\n&lt;p&gt;Now I understand that if you can&amp;#39;t afford to drop/loose any of the data, then you need to have a data stream manager of some flavour, but why is it so much slower and so much more expensive?  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m missing something in regards to the sweet-spot for using the product.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16z5j8q", "is_robot_indexable": true, "report_reasons": null, "author": "Comfortable_Fee5361", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16z5j8q/lambda_to_firehose_vs_directly_to_s3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16z5j8q/lambda_to_firehose_vs_directly_to_s3/", "subreddit_subscribers": 131988, "created_utc": 1696371824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have published a medium article about a dynamic Database CDC Data Processing pipeline in AWS which we designed in one of my earlier projects. Thought it would be useful for someone who faced similar challenges.\n\nPlease take a look and let me know if the logic &amp; wording are clear, as the code is out of scope\n\n[https://medium.com/@sarath.mec/aws-dynamic-cdc-migration-using-dms-kinesis-and-lambda-d0ae8abff76f](https://medium.com/@sarath.mec/aws-dynamic-cdc-migration-using-dms-kinesis-and-lambda-d0ae8abff76f)[https://medium.com/@sarath.mec/kinesis-lambda-trigger-dlq-reprocessing-using-aws-glue-cb0a62710a84](https://medium.com/@sarath.mec/kinesis-lambda-trigger-dlq-reprocessing-using-aws-glue-cb0a62710a84)", "author_fullname": "t2_5rjlld07", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AWS: CDC using DMS, Kinesis &amp; Lambda with Dynamic SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16z0rp5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696360702.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have published a medium article about a dynamic Database CDC Data Processing pipeline in AWS which we designed in one of my earlier projects. Thought it would be useful for someone who faced similar challenges.&lt;/p&gt;\n\n&lt;p&gt;Please take a look and let me know if the logic &amp;amp; wording are clear, as the code is out of scope&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/@sarath.mec/aws-dynamic-cdc-migration-using-dms-kinesis-and-lambda-d0ae8abff76f\"&gt;https://medium.com/@sarath.mec/aws-dynamic-cdc-migration-using-dms-kinesis-and-lambda-d0ae8abff76f&lt;/a&gt;&lt;a href=\"https://medium.com/@sarath.mec/kinesis-lambda-trigger-dlq-reprocessing-using-aws-glue-cb0a62710a84\"&gt;https://medium.com/@sarath.mec/kinesis-lambda-trigger-dlq-reprocessing-using-aws-glue-cb0a62710a84&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/rmqzQRBE4DRJbJkIs9qJJ28cyE4nJFodTVD_OVnyy84.jpg?auto=webp&amp;s=0be128e94e89c94c6a4e9171a8a1f391db98af13", "width": 593, "height": 301}, "resolutions": [{"url": "https://external-preview.redd.it/rmqzQRBE4DRJbJkIs9qJJ28cyE4nJFodTVD_OVnyy84.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f76cfe6d6425c1696b32837924e80186df4c47f4", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/rmqzQRBE4DRJbJkIs9qJJ28cyE4nJFodTVD_OVnyy84.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=707f210772308542a18999572e922b6b2fa5af12", "width": 216, "height": 109}, {"url": "https://external-preview.redd.it/rmqzQRBE4DRJbJkIs9qJJ28cyE4nJFodTVD_OVnyy84.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=4f9fe7a413fd3d9d8d4ce743805bfa9f65149779", "width": 320, "height": 162}], "variants": {}, "id": "twy5yvGGvgN5mlBccSDJ8qoJUJbtAsgtGsXeZM5Pibc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16z0rp5", "is_robot_indexable": true, "report_reasons": null, "author": "DragonflyHumble", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16z0rp5/aws_cdc_using_dms_kinesis_lambda_with_dynamic_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16z0rp5/aws_cdc_using_dms_kinesis_lambda_with_dynamic_sql/", "subreddit_subscribers": 131988, "created_utc": 1696360702.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[ADVICE]\nHi All,\n\nI am a data engineer with 5 years of experience. I have got an offer for Senior DataOps and am applying for other Senior DE roles. \n\nThe DataOps role primarily comprises of supporting systems and DE teams and creating alerts for the existing pipelines. It is a support job. \n\nI am confused if this is the right path to take for my next Data Engineering role. Does going ahead with this restrict me to SRE/DevOps role?\n\nIt will be very helpful if you guys can give me some advice on this, if I should take it up or not? And would I get stuck in this and can I, in the future be eligible for Data Engineering roles?", "author_fullname": "t2_5ze1rxlx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Next Step as Senior DE vs Senior DataOps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yzsxa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696398337.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696358401.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;[ADVICE]\nHi All,&lt;/p&gt;\n\n&lt;p&gt;I am a data engineer with 5 years of experience. I have got an offer for Senior DataOps and am applying for other Senior DE roles. &lt;/p&gt;\n\n&lt;p&gt;The DataOps role primarily comprises of supporting systems and DE teams and creating alerts for the existing pipelines. It is a support job. &lt;/p&gt;\n\n&lt;p&gt;I am confused if this is the right path to take for my next Data Engineering role. Does going ahead with this restrict me to SRE/DevOps role?&lt;/p&gt;\n\n&lt;p&gt;It will be very helpful if you guys can give me some advice on this, if I should take it up or not? And would I get stuck in this and can I, in the future be eligible for Data Engineering roles?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16yzsxa", "is_robot_indexable": true, "report_reasons": null, "author": "ParticularDear5826", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yzsxa/next_step_as_senior_de_vs_senior_dataops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yzsxa/next_step_as_senior_de_vs_senior_dataops/", "subreddit_subscribers": 131988, "created_utc": 1696358401.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Redditors, I'm facing an issue where I only want to read some data (I used limit) from a folder full of parquet files. The folder has roughly 50 gb of data. \n\nWhen I trigger a read with limit it still reads the entire folder and then applies the limit. This is happening even after providing the schema. Not sure what is happening. \n\nI'm using EMR and data is on S3.", "author_fullname": "t2_t1rd5ph", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Pyspark reads entire folders parquet data even after limit is applied", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zgzll", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696405492.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Redditors, I&amp;#39;m facing an issue where I only want to read some data (I used limit) from a folder full of parquet files. The folder has roughly 50 gb of data. &lt;/p&gt;\n\n&lt;p&gt;When I trigger a read with limit it still reads the entire folder and then applies the limit. This is happening even after providing the schema. Not sure what is happening. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m using EMR and data is on S3.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16zgzll", "is_robot_indexable": true, "report_reasons": null, "author": "PR0K1NG", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/16zgzll/pyspark_reads_entire_folders_parquet_data_even/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zgzll/pyspark_reads_entire_folders_parquet_data_even/", "subreddit_subscribers": 131988, "created_utc": 1696405492.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "TLDR: For anyone that might be working two (full time/contract/both) jobs, is it possible?? How are you handling it? Any tips? How would you proceed if you want to find an extra side hustle in this space?\n\nI know this might be a little taboo or maybe even frowned upon, but does anyone work multiple full time jobs (either full time and/or contract) as a data engineer or similar data role? I\u2019m wondering how common this is. In every role I\u2019ve worked in this space, I\u2019m able to get by doing maybe 10 hours of actual work a week after my first 90 days. I\u2019m at the Senior level but not far from Principal. With this free time, it wouldn\u2019t be a stretch to do it for two environments, as I have nothing but time right now.\n\nAt the start of this year, I left an employer with a very small data team of which I was the sole person that knew how to keep things running. They begged for me to stay on, so I did part time. While working at my new full time job, I was continuing to keep my old employers stuff running for like 5 hours a week, although I billed for 20 and they were more than happy with that, but we cut that off a few months ago since they hired a full time replacement and ran into some budget issues.\n\nMy current employer has a policy that I can\u2019t have two jobs, but I don\u2019t care. I\u2019m good at keeping quiet and miss that additional income. It was worth the extra stress and anxiety and I\u2019m thinking of jumping back into a similar situation if I can.\n\n&amp;#x200B;", "author_fullname": "t2_5k5sp0q2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone work two DE jobs? (Double dip)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zf6rv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.55, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696398773.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;TLDR: For anyone that might be working two (full time/contract/both) jobs, is it possible?? How are you handling it? Any tips? How would you proceed if you want to find an extra side hustle in this space?&lt;/p&gt;\n\n&lt;p&gt;I know this might be a little taboo or maybe even frowned upon, but does anyone work multiple full time jobs (either full time and/or contract) as a data engineer or similar data role? I\u2019m wondering how common this is. In every role I\u2019ve worked in this space, I\u2019m able to get by doing maybe 10 hours of actual work a week after my first 90 days. I\u2019m at the Senior level but not far from Principal. With this free time, it wouldn\u2019t be a stretch to do it for two environments, as I have nothing but time right now.&lt;/p&gt;\n\n&lt;p&gt;At the start of this year, I left an employer with a very small data team of which I was the sole person that knew how to keep things running. They begged for me to stay on, so I did part time. While working at my new full time job, I was continuing to keep my old employers stuff running for like 5 hours a week, although I billed for 20 and they were more than happy with that, but we cut that off a few months ago since they hired a full time replacement and ran into some budget issues.&lt;/p&gt;\n\n&lt;p&gt;My current employer has a policy that I can\u2019t have two jobs, but I don\u2019t care. I\u2019m good at keeping quiet and miss that additional income. It was worth the extra stress and anxiety and I\u2019m thinking of jumping back into a similar situation if I can.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zf6rv", "is_robot_indexable": true, "report_reasons": null, "author": "Nebula_369", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zf6rv/anyone_work_two_de_jobs_double_dip/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zf6rv/anyone_work_two_de_jobs_double_dip/", "subreddit_subscribers": 131988, "created_utc": 1696398773.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,  \n\n\nCurrently an analyst looking to implement data engineering practices in my work. I've realized within our PowerBI workspace a lot of our reports run duplicate queries against the data warehouse (although sometimes out data isn't in the warehouse and we have to get it from external sources via r scripts). From reading around it seems like PowerBI data flows might be a solution for this but also they seem to scale poorly would it make sense to go about creating a data mart to subset common data sets to improve the workflow for the other analysts on my team? Or does anyone else have idea's for a scalable solution for creating various pipelines from our data warehouse/ external sources (csv's, api's)   \n", "author_fullname": "t2_141785", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to apply data engineering as an analyst", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16z668s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696373305.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,  &lt;/p&gt;\n\n&lt;p&gt;Currently an analyst looking to implement data engineering practices in my work. I&amp;#39;ve realized within our PowerBI workspace a lot of our reports run duplicate queries against the data warehouse (although sometimes out data isn&amp;#39;t in the warehouse and we have to get it from external sources via r scripts). From reading around it seems like PowerBI data flows might be a solution for this but also they seem to scale poorly would it make sense to go about creating a data mart to subset common data sets to improve the workflow for the other analysts on my team? Or does anyone else have idea&amp;#39;s for a scalable solution for creating various pipelines from our data warehouse/ external sources (csv&amp;#39;s, api&amp;#39;s)   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16z668s", "is_robot_indexable": true, "report_reasons": null, "author": "jotama0121", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16z668s/how_to_apply_data_engineering_as_an_analyst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16z668s/how_to_apply_data_engineering_as_an_analyst/", "subreddit_subscribers": 131988, "created_utc": 1696373305.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Could one senior data engineer with solid experience setup Apache Beam and real-time streaming from scratch for a startup organisation within a reasonable timeframe? Eg., 8-12 weeks, with earlier prototypes?\nJust getting a handle on the complexity compared to a non-streaming data warehouse like dbt, which I would have said definitely yes.\n\nAny thoughts or advice on complexities jumping to streaming and Apache Beam is much appreciated.\n\nThanks!!", "author_fullname": "t2_jkvzr8r3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Apache Beam Question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ysa9g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696340547.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Could one senior data engineer with solid experience setup Apache Beam and real-time streaming from scratch for a startup organisation within a reasonable timeframe? Eg., 8-12 weeks, with earlier prototypes?\nJust getting a handle on the complexity compared to a non-streaming data warehouse like dbt, which I would have said definitely yes.&lt;/p&gt;\n\n&lt;p&gt;Any thoughts or advice on complexities jumping to streaming and Apache Beam is much appreciated.&lt;/p&gt;\n\n&lt;p&gt;Thanks!!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ysa9g", "is_robot_indexable": true, "report_reasons": null, "author": "pbower2049", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ysa9g/apache_beam_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ysa9g/apache_beam_question/", "subreddit_subscribers": 131988, "created_utc": 1696340547.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi All. I have a requirement to read data from on-prem MySQL database to Azure Event Hub. This data will be later used in Power BI. \n\nWhat is the best way to get MySQL data to Event Hub in streaming fashion? I read that we can use bin logs of MySQL, which means I need to run a python process on on-prem system that can push data to Event Hub. Is there any other ways which are better? ", "author_fullname": "t2_2xxs9nne", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Streaming data from MySQL to Azure Event Hub", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16yqrwy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696336598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi All. I have a requirement to read data from on-prem MySQL database to Azure Event Hub. This data will be later used in Power BI. &lt;/p&gt;\n\n&lt;p&gt;What is the best way to get MySQL data to Event Hub in streaming fashion? I read that we can use bin logs of MySQL, which means I need to run a python process on on-prem system that can push data to Event Hub. Is there any other ways which are better? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16yqrwy", "is_robot_indexable": true, "report_reasons": null, "author": "inglocines", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16yqrwy/streaming_data_from_mysql_to_azure_event_hub/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16yqrwy/streaming_data_from_mysql_to_azure_event_hub/", "subreddit_subscribers": 131988, "created_utc": 1696336598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nDo you have some beginner resources (blog posts, books, videos) to start learning ML terminology and connection points with data engineering ?", "author_fullname": "t2_8ejk5itu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introductive ML lectures as DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16ypyoo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696334294.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nDo you have some beginner resources (blog posts, books, videos) to start learning ML terminology and connection points with data engineering ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16ypyoo", "is_robot_indexable": true, "report_reasons": null, "author": "ultimaRati0", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16ypyoo/introductive_ml_lectures_as_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16ypyoo/introductive_ml_lectures_as_de/", "subreddit_subscribers": 131988, "created_utc": 1696334294.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_yeda6sl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Top 5 Data Management Tools For Your Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_16zjejt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nInWTxL15yoyHVA9qOZusnzcR70hOTPFqm4yQEOTM_c.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696414756.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "kdnuggets.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.kdnuggets.com/top-5-data-management-tools-for-your-projects", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/idRAF6KQ4wQWnzAvyk9KCAU8fJBDM38sbPkoFMpnhkk.jpg?auto=webp&amp;s=24549b519083fc058b21b4e9698b1bda584afa5d", "width": 2240, "height": 1260}, "resolutions": [{"url": "https://external-preview.redd.it/idRAF6KQ4wQWnzAvyk9KCAU8fJBDM38sbPkoFMpnhkk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3d91f1eba06580a1778ac0a5b07fe37ca69c914f", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/idRAF6KQ4wQWnzAvyk9KCAU8fJBDM38sbPkoFMpnhkk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f9d94b37e4e109f86af5e64795a7d6b61ca6afb0", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/idRAF6KQ4wQWnzAvyk9KCAU8fJBDM38sbPkoFMpnhkk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=84384d282b954a16064321f535d8e5d53eeb9c22", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/idRAF6KQ4wQWnzAvyk9KCAU8fJBDM38sbPkoFMpnhkk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8c34e9a7af285a7f52a1f78ba8f5cb19dc0a1d11", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/idRAF6KQ4wQWnzAvyk9KCAU8fJBDM38sbPkoFMpnhkk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87925b73807a42183223e6ec5100e9d89c7da081", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/idRAF6KQ4wQWnzAvyk9KCAU8fJBDM38sbPkoFMpnhkk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=23aea082e14a8753042e6bbe390b5e1dfcba7ff5", "width": 1080, "height": 607}], "variants": {}, "id": "b3Wuqy2RHH8RQ_5GQsRhs2GwbCCd4529ulyCVBGp94g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16zjejt", "is_robot_indexable": true, "report_reasons": null, "author": "kingabzpro", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zjejt/the_top_5_data_management_tools_for_your_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.kdnuggets.com/top-5-data-management-tools-for-your-projects", "subreddit_subscribers": 131988, "created_utc": 1696414756.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey there,\n\nI'm a nurse, so I have a batchelors albeit incredibly unrelated. I'm approaching 30 and I'm so very burnt out.\n\nI want to get into data engineering, it's always interested me and it has a much broader field than pidgeon-hole nursing. (Actually I'm quite downplaying my love of data, design and solutions...), however, I need to find a qualification that fits around my current job.\n\nWhat would you suggest?\n\nI've been looking at online academies and Microsoft certifications etc. Doing a masters isn't financially viable right now. But there's so many pros and cons and all the pathways are a little overwhelming for someone new to the industry. I've been dwelling on this for over a year and I just need to take the plunge.\n\nAlso, my current role is quite well paid so ideally I'd be looking for my first data job to be \u00a340K+ (about $50K+), to cover for mortgage payments etc. Is there a qualification I can do that would help me get there?\n\nPlease help \ud83d\ude05", "author_fullname": "t2_740fnu1l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From nurse to data engineer ...send help.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16zjdbu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696414631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a nurse, so I have a batchelors albeit incredibly unrelated. I&amp;#39;m approaching 30 and I&amp;#39;m so very burnt out.&lt;/p&gt;\n\n&lt;p&gt;I want to get into data engineering, it&amp;#39;s always interested me and it has a much broader field than pidgeon-hole nursing. (Actually I&amp;#39;m quite downplaying my love of data, design and solutions...), however, I need to find a qualification that fits around my current job.&lt;/p&gt;\n\n&lt;p&gt;What would you suggest?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been looking at online academies and Microsoft certifications etc. Doing a masters isn&amp;#39;t financially viable right now. But there&amp;#39;s so many pros and cons and all the pathways are a little overwhelming for someone new to the industry. I&amp;#39;ve been dwelling on this for over a year and I just need to take the plunge.&lt;/p&gt;\n\n&lt;p&gt;Also, my current role is quite well paid so ideally I&amp;#39;d be looking for my first data job to be \u00a340K+ (about $50K+), to cover for mortgage payments etc. Is there a qualification I can do that would help me get there?&lt;/p&gt;\n\n&lt;p&gt;Please help \ud83d\ude05&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16zjdbu", "is_robot_indexable": true, "report_reasons": null, "author": "Lil_Cherry_Beary", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zjdbu/from_nurse_to_data_engineer_send_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zjdbu/from_nurse_to_data_engineer_send_help/", "subreddit_subscribers": 131988, "created_utc": 1696414631.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have a table which contains more than 350 Million rows, the DS team needs to use this table for their research. One of their problems (which is understandable) is that querying the data takes too long.   \nCan you refer me to anything that can help?  \nOr have you ever dealt with an issue like that.", "author_fullname": "t2_zbab4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Optimizing Data Warehouse modeling on Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16zit1h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696412580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have a table which contains more than 350 Million rows, the DS team needs to use this table for their research. One of their problems (which is understandable) is that querying the data takes too long.&lt;br/&gt;\nCan you refer me to anything that can help?&lt;br/&gt;\nOr have you ever dealt with an issue like that.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zit1h", "is_robot_indexable": true, "report_reasons": null, "author": "chenvili", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zit1h/optimizing_data_warehouse_modeling_on_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zit1h/optimizing_data_warehouse_modeling_on_snowflake/", "subreddit_subscribers": 131988, "created_utc": 1696412580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I may be going through their interview process soon so I wanted to check.", "author_fullname": "t2_imajwwpcb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a good repository of data engineering programming questions asked as part of Meta's interview process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zhn9l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696408025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I may be going through their interview process soon so I wanted to check.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16zhn9l", "is_robot_indexable": true, "report_reasons": null, "author": "al-hamal", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zhn9l/is_there_a_good_repository_of_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zhn9l/is_there_a_good_repository_of_data_engineering/", "subreddit_subscribers": 131988, "created_utc": 1696408025.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Currently in a small team with the only DE. We have a poor way of version control basically whatever SQL codes and ipynb files is on github and are reuploaded after any changes. I want to implement good version control practices and CI/CD. Would like to know from the community on starting points to implement this", "author_fullname": "t2_dpc2z7ubu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Implementing CI/CD &amp; Git/version control", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zfxto", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696401489.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently in a small team with the only DE. We have a poor way of version control basically whatever SQL codes and ipynb files is on github and are reuploaded after any changes. I want to implement good version control practices and CI/CD. Would like to know from the community on starting points to implement this&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zfxto", "is_robot_indexable": true, "report_reasons": null, "author": "cyamnihc", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zfxto/implementing_cicd_gitversion_control/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zfxto/implementing_cicd_gitversion_control/", "subreddit_subscribers": 131988, "created_utc": 1696401489.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So we parse a public API, most of data from which is 100% suitable for relation DBs.  Think about this data as user transactions - who, when, how, where send the money. The amount of data is around 1 mb per second.\n\nThe data is already cleaned and we only need to replace the user_id with corresponding primary key in transfer table and add new users to user table.\n\nSo we do that on the fly and store the results in postgres, from which backend grabs info for the FE. As public API support historical queries we don\u2019t need to store the raw data, so we like only doing the last step of ETL pipeline. \n\nNo I\u2019d want to train some logistic regression, make some EDA on that data etc. Tho exporting a lot of data from pg may be very slow. \n\nI\u2019m kind of curious what may be a better way to handle that?", "author_fullname": "t2_3ppayh15", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the options for storing 1Mb / s data for latter analytics", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zfc3b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696399292.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So we parse a public API, most of data from which is 100% suitable for relation DBs.  Think about this data as user transactions - who, when, how, where send the money. The amount of data is around 1 mb per second.&lt;/p&gt;\n\n&lt;p&gt;The data is already cleaned and we only need to replace the user_id with corresponding primary key in transfer table and add new users to user table.&lt;/p&gt;\n\n&lt;p&gt;So we do that on the fly and store the results in postgres, from which backend grabs info for the FE. As public API support historical queries we don\u2019t need to store the raw data, so we like only doing the last step of ETL pipeline. &lt;/p&gt;\n\n&lt;p&gt;No I\u2019d want to train some logistic regression, make some EDA on that data etc. Tho exporting a lot of data from pg may be very slow. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m kind of curious what may be a better way to handle that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16zfc3b", "is_robot_indexable": true, "report_reasons": null, "author": "dotaleaker", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zfc3b/what_are_the_options_for_storing_1mb_s_data_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zfc3b/what_are_the_options_for_storing_1mb_s_data_for/", "subreddit_subscribers": 131988, "created_utc": 1696399292.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. I am working as a Backend Developer and completed 9 months, I am planning to switch into Data engineering, Please provide suggestions on DE and also ETL project ideas. I'm open for any suggestions/feedback.\nThanks in advance.", "author_fullname": "t2_v4xmc73t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Project Ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zehvr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696396455.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I am working as a Backend Developer and completed 9 months, I am planning to switch into Data engineering, Please provide suggestions on DE and also ETL project ideas. I&amp;#39;m open for any suggestions/feedback.\nThanks in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16zehvr", "is_robot_indexable": true, "report_reasons": null, "author": "Navaneethan23", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zehvr/project_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zehvr/project_ideas/", "subreddit_subscribers": 131988, "created_utc": 1696396455.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "The title says almost everything my goals are to cover the basics of setting up data streaming using Kafka through confluence, any advice on what exercises would fit this or any tips for setup. I am just starting out and heard Kafka was a pain to work with.", "author_fullname": "t2_d1ss2q2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering student looking to setup streaming exercise with Kafka(confluence)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16zb1ah", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696385958.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title says almost everything my goals are to cover the basics of setting up data streaming using Kafka through confluence, any advice on what exercises would fit this or any tips for setup. I am just starting out and heard Kafka was a pain to work with.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16zb1ah", "is_robot_indexable": true, "report_reasons": null, "author": "wolfmaster58", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16zb1ah/data_engineering_student_looking_to_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16zb1ah/data_engineering_student_looking_to_setup/", "subreddit_subscribers": 131988, "created_utc": 1696385958.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}