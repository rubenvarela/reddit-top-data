{"kind": "Listing", "data": {"after": null, "dist": 12, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi friends, a total data engineer n00b here. So i got something im trying to sort out in my head for my own personal project, which I want to scrape and merge data from my social media profiles.\n\nI have a Postgres DB that im hosting my application datas. Pretty typical software dev stuff. But I do need to essentially enrich the said data with other sources (from other PG dbs + social media + web scrapped things)  to make things more useful.\n\nI was thinking to dump things into my applications PG, then use SQL to do data processing to clean up and merge data w/ my application data, but i felt this is not the right way to do it and that this should be done in a data warehouse. \n\nAt my previous companies we spent $$$ on redshift + teams of data engineers to do this. I personally can't spend that so looking for a cheap/free solution to do all this, so I've been running airbyte locally to do the syncing. \n\nWhat should I use as a cheap/free data engineering pipeline + data warehouse? Should i stick with throwing things at PG? \n\nI guess at this point, I'm really looking for an easy to use + cheap solution for all this, running this locally via docker takes a lot of mental overhead...\n\n&amp;#x200B;\n\nThanks!\n\n&amp;#x200B;", "author_fullname": "t2_s0001jox", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's an easy/cheap data engineering pipeline+ warehouse stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177yh79", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.97, "author_flair_background_color": null, "subreddit_type": "public", "ups": 54, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 54, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697316301.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697315830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi friends, a total data engineer n00b here. So i got something im trying to sort out in my head for my own personal project, which I want to scrape and merge data from my social media profiles.&lt;/p&gt;\n\n&lt;p&gt;I have a Postgres DB that im hosting my application datas. Pretty typical software dev stuff. But I do need to essentially enrich the said data with other sources (from other PG dbs + social media + web scrapped things)  to make things more useful.&lt;/p&gt;\n\n&lt;p&gt;I was thinking to dump things into my applications PG, then use SQL to do data processing to clean up and merge data w/ my application data, but i felt this is not the right way to do it and that this should be done in a data warehouse. &lt;/p&gt;\n\n&lt;p&gt;At my previous companies we spent $$$ on redshift + teams of data engineers to do this. I personally can&amp;#39;t spend that so looking for a cheap/free solution to do all this, so I&amp;#39;ve been running airbyte locally to do the syncing. &lt;/p&gt;\n\n&lt;p&gt;What should I use as a cheap/free data engineering pipeline + data warehouse? Should i stick with throwing things at PG? &lt;/p&gt;\n\n&lt;p&gt;I guess at this point, I&amp;#39;m really looking for an easy to use + cheap solution for all this, running this locally via docker takes a lot of mental overhead...&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "177yh79", "is_robot_indexable": true, "report_reasons": null, "author": "life_on_my_terms", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/177yh79/whats_an_easycheap_data_engineering_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/177yh79/whats_an_easycheap_data_engineering_pipeline/", "subreddit_subscribers": 134191, "created_utc": 1697315830.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Looking to see what approaches others use. Do you use Airflow or equivalent? Use some cloud event triggers? Run bash scripts in cron jobs from a Hadoop cluster? Let\u2019s discuss what DE\u2019s have tried. Also indicate if it was for batch vs streaming.", "author_fullname": "t2_v98q7m1n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you schedule Spark jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177xz4u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.98, "author_flair_background_color": null, "subreddit_type": "public", "ups": 28, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 28, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697314371.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Looking to see what approaches others use. Do you use Airflow or equivalent? Use some cloud event triggers? Run bash scripts in cron jobs from a Hadoop cluster? Let\u2019s discuss what DE\u2019s have tried. Also indicate if it was for batch vs streaming.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "177xz4u", "is_robot_indexable": true, "report_reasons": null, "author": "bryangoodrich", "discussion_type": null, "num_comments": 54, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/177xz4u/how_do_you_schedule_spark_jobs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/177xz4u/how_do_you_schedule_spark_jobs/", "subreddit_subscribers": 134191, "created_utc": 1697314371.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_rw355scd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Databricks Unity Catalog: Guide to Streamline Your Data Assets", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 120, "top_awarded_type": null, "hide_score": false, "name": "t3_178be0n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/KIu4Ih-rTVysMqeg_yMdNSuv4kSnP2cZ-BvcbyHfIq8.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697360541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "lakefs.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://lakefs.io/blog/unity-catalog-guide-streamline-data-assets/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fA1qIP_XtI43-KBUYT98KPtpRcCDvMOJFJ7DYVkzIgw.jpg?auto=webp&amp;s=9458e915e9dd1f4ab13fadc59535a0c65fac8b0e", "width": 350, "height": 300}, "resolutions": [{"url": "https://external-preview.redd.it/fA1qIP_XtI43-KBUYT98KPtpRcCDvMOJFJ7DYVkzIgw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=256e684f7534e8f29a0281ed7df436084d2538e4", "width": 108, "height": 92}, {"url": "https://external-preview.redd.it/fA1qIP_XtI43-KBUYT98KPtpRcCDvMOJFJ7DYVkzIgw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=206cc51f034151c6ecdedd754567eb117b61122c", "width": 216, "height": 185}, {"url": "https://external-preview.redd.it/fA1qIP_XtI43-KBUYT98KPtpRcCDvMOJFJ7DYVkzIgw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1cbef2474a7d55294e60b8529d7c8e3bbe3de98c", "width": 320, "height": 274}], "variants": {}, "id": "CRQEZJT75CK-lmF177mkcpqX8ry3JIX7rvkT9XblRjQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "178be0n", "is_robot_indexable": true, "report_reasons": null, "author": "henits784", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/178be0n/databricks_unity_catalog_guide_to_streamline_your/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://lakefs.io/blog/unity-catalog-guide-streamline-data-assets/", "subreddit_subscribers": 134191, "created_utc": 1697360541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_tjka5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "From MLOps to ML Systems with Feature/Training/Inference Pipelines - Hopsworks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_177yxwu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/HREOqn0jR8eyDnB9G_xWuL0ZYIVBtxvVczijdNoxjig.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697317185.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "hopsworks.ai", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.hopsworks.ai/post/mlops-to-ml-systems-with-fti-pipelines", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/ZAMiYSs8p0i8kv9zisx4jofC3oZ9WBIs3Xg1plq7oE4.jpg?auto=webp&amp;s=e584672affb31f55a28cb295b6ce0d3741ca9a27", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/ZAMiYSs8p0i8kv9zisx4jofC3oZ9WBIs3Xg1plq7oE4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=012fa05405997f1278ea1a29e6d9cb532605f60c", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/ZAMiYSs8p0i8kv9zisx4jofC3oZ9WBIs3Xg1plq7oE4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=1689dbb06e54895401d3994a6b5a63a5b499c26f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/ZAMiYSs8p0i8kv9zisx4jofC3oZ9WBIs3Xg1plq7oE4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=221bc774a997ed2693b683b00cb9e9db7f9e4618", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/ZAMiYSs8p0i8kv9zisx4jofC3oZ9WBIs3Xg1plq7oE4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=3d6748d204d3b9c43ff65ba132adf78e0036e43d", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/ZAMiYSs8p0i8kv9zisx4jofC3oZ9WBIs3Xg1plq7oE4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8e2993db7fd351f84200fd864973de1109720b40", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/ZAMiYSs8p0i8kv9zisx4jofC3oZ9WBIs3Xg1plq7oE4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=cb1676fce96da8ed128777fa31987308befd068d", "width": 1080, "height": 567}], "variants": {}, "id": "mWT0XPUROLLzz8SuoQWoDanA_b48E0ui60D5VzxrCwM"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "177yxwu", "is_robot_indexable": true, "report_reasons": null, "author": "jpdowlin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/177yxwu/from_mlops_to_ml_systems_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.hopsworks.ai/post/mlops-to-ml-systems-with-fti-pipelines", "subreddit_subscribers": 134191, "created_utc": 1697317185.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Maybe when you meet on a vacation, in a bus. \n(Spare the Tech Stack Question please)", "author_fullname": "t2_t9iw9tl2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Whats the first few questions you ask when you come across a Data Engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_178jc4k", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697387992.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Maybe when you meet on a vacation, in a bus. \n(Spare the Tech Stack Question please)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "178jc4k", "is_robot_indexable": true, "report_reasons": null, "author": "Straight-End4310", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/178jc4k/whats_the_first_few_questions_you_ask_when_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/178jc4k/whats_the_first_few_questions_you_ask_when_you/", "subreddit_subscribers": 134191, "created_utc": 1697387992.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "PowerBI is my preferred software for charting, however, constructing a motion chart can be cumbersome. Therefore, I am experimenting with websocket and chart.js. Any better suggestion?\n\nThe following use case involves executing a filter-innerjoin-groupby operation 100 times. The dataset used ranges from 1 million to 100 million rows, with each run increasing the row count by 1 million.\n\nThe video:  [https://youtu.be/YL4TeYP-GNA](https://youtu.be/YL4TeYP-GNA)\n\nThe full script for Polars, DuckDB and Peaks:   [https://github.com/hkpeaks/polars-cf-peaks/tree/main/cf-002%20InnerJoin-GroupBy/Narrow-Filter-Range](https://github.com/hkpeaks/polars-cf-peaks/tree/main/cf-002%20InnerJoin-GroupBy/Narrow-Filter-Range)\n\nThis is the query I use for the motion chart.js. \n\nquery1 := peakgo.**Query**(  \n \"filter\", \"Style(=F)\",  \n \"build\\_key\\_value\", \"Product, Style =&gt; Table(key\\_value)\")\n\n  \n master\\_df := peakgo.**RunBatch**(df, \"Inbox/Master.csv\", query1)\n\n  \n query2 := peakgo.**Query**(  \n \"filter\", \"Shop(S77..S78)\",  \n \"join\\_key\\_value\", \"Product, Style =&gt; Inner(key\\_value)\",  \n \"add\\_column\", \"Quantity, Unit\\_Price =&gt; Multiply(Amount)\",  \n \"filter\", \"Amount:Float(&gt;100000)\",  \n \"group\\_by\", \"Shop, Product =&gt; Count() Sum(Quantity) Sum(Amount)\")  \n source\\_file := peakgo.**GetCliFilePath**(\"10-MillionRows.csv\")  \n result\\_file := \\[\\]string{\"Outbox/PeakGo-Detail-Result-\" + filepath.**Base**(source\\_file),  \n \"Outbox/Peakgo-Summary-Result-\" + filepath.**Base**(source\\_file)}\n\n  \n peakgo.**RunStream**(df, &amp;master\\_df, source\\_file, query2, result\\_file)\n\n&amp;#x200B;", "author_fullname": "t2_9k0sxzns1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Demonstrate the Elapsed Time of DataFrame\u2019s InnerJoin-GroupBy Operation using Python Websocket and Chart.js", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1785650", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697336303.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697335975.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;PowerBI is my preferred software for charting, however, constructing a motion chart can be cumbersome. Therefore, I am experimenting with websocket and chart.js. Any better suggestion?&lt;/p&gt;\n\n&lt;p&gt;The following use case involves executing a filter-innerjoin-groupby operation 100 times. The dataset used ranges from 1 million to 100 million rows, with each run increasing the row count by 1 million.&lt;/p&gt;\n\n&lt;p&gt;The video:  &lt;a href=\"https://youtu.be/YL4TeYP-GNA\"&gt;https://youtu.be/YL4TeYP-GNA&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The full script for Polars, DuckDB and Peaks:   &lt;a href=\"https://github.com/hkpeaks/polars-cf-peaks/tree/main/cf-002%20InnerJoin-GroupBy/Narrow-Filter-Range\"&gt;https://github.com/hkpeaks/polars-cf-peaks/tree/main/cf-002%20InnerJoin-GroupBy/Narrow-Filter-Range&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is the query I use for the motion chart.js. &lt;/p&gt;\n\n&lt;p&gt;query1 := peakgo.&lt;strong&gt;Query&lt;/strong&gt;(&lt;br/&gt;\n &amp;quot;filter&amp;quot;, &amp;quot;Style(=F)&amp;quot;,&lt;br/&gt;\n &amp;quot;build_key_value&amp;quot;, &amp;quot;Product, Style =&amp;gt; Table(key_value)&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;master_df := peakgo.&lt;strong&gt;RunBatch&lt;/strong&gt;(df, &amp;quot;Inbox/Master.csv&amp;quot;, query1)&lt;/p&gt;\n\n&lt;p&gt;query2 := peakgo.&lt;strong&gt;Query&lt;/strong&gt;(&lt;br/&gt;\n &amp;quot;filter&amp;quot;, &amp;quot;Shop(S77..S78)&amp;quot;,&lt;br/&gt;\n &amp;quot;join_key_value&amp;quot;, &amp;quot;Product, Style =&amp;gt; Inner(key_value)&amp;quot;,&lt;br/&gt;\n &amp;quot;add_column&amp;quot;, &amp;quot;Quantity, Unit_Price =&amp;gt; Multiply(Amount)&amp;quot;,&lt;br/&gt;\n &amp;quot;filter&amp;quot;, &amp;quot;Amount:Float(&amp;gt;100000)&amp;quot;,&lt;br/&gt;\n &amp;quot;group_by&amp;quot;, &amp;quot;Shop, Product =&amp;gt; Count() Sum(Quantity) Sum(Amount)&amp;quot;)&lt;br/&gt;\n source_file := peakgo.&lt;strong&gt;GetCliFilePath&lt;/strong&gt;(&amp;quot;10-MillionRows.csv&amp;quot;)&lt;br/&gt;\n result_file := []string{&amp;quot;Outbox/PeakGo-Detail-Result-&amp;quot; + filepath.&lt;strong&gt;Base&lt;/strong&gt;(source_file),&lt;br/&gt;\n &amp;quot;Outbox/Peakgo-Summary-Result-&amp;quot; + filepath.&lt;strong&gt;Base&lt;/strong&gt;(source_file)}&lt;/p&gt;\n\n&lt;p&gt;peakgo.&lt;strong&gt;RunStream&lt;/strong&gt;(df, &amp;amp;master_df, source_file, query2, result_file)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AJabP9VIRjPmGTmcurjW_qzx-0saZQznw-4VPs7cJZY.jpg?auto=webp&amp;s=2aff142f52e27be6874fcd2644a50cbde0ae911b", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/AJabP9VIRjPmGTmcurjW_qzx-0saZQznw-4VPs7cJZY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=23eeb53d06fc23558196c5fdc0cb8aec4e8a3f58", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/AJabP9VIRjPmGTmcurjW_qzx-0saZQznw-4VPs7cJZY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=7a41bdeb1305e044556b4685a1f9f03e994485d4", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/AJabP9VIRjPmGTmcurjW_qzx-0saZQznw-4VPs7cJZY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=2ca2d8c2a234a3acb3aab693da69d36b68e38bc2", "width": 320, "height": 240}], "variants": {}, "id": "k4zGogCh-hB3FShJVR_vC1Mzoxuv_VBM7oVVkSZrIsE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1785650", "is_robot_indexable": true, "report_reasons": null, "author": "100GB-CSV", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1785650/demonstrate_the_elapsed_time_of_dataframes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1785650/demonstrate_the_elapsed_time_of_dataframes/", "subreddit_subscribers": 134191, "created_utc": 1697335975.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Giving access in Redshift to different users or groups becomes really cumbersome. We have been providing access manually everytime somebody asks for it. Is there a way to automate this process. Any tool you guys using for access management?", "author_fullname": "t2_96l36oyd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you manage access control in Redshift or any other data warehouse. Is there a way to automate this process?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177zkic", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697318942.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Giving access in Redshift to different users or groups becomes really cumbersome. We have been providing access manually everytime somebody asks for it. Is there a way to automate this process. Any tool you guys using for access management?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "177zkic", "is_robot_indexable": true, "report_reasons": null, "author": "veryuncanny_", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/177zkic/how_do_you_manage_access_control_in_redshift_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/177zkic/how_do_you_manage_access_control_in_redshift_or/", "subreddit_subscribers": 134191, "created_utc": 1697318942.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m building an application that accepts exercise data from devices then kicks off a ETL pipeline. This data is then displayed to users. Right now I get really slowed down when I have to test changes and as I add more devices this will only become a bigger problem. Does anyone have experience creating automated tests for something like this.", "author_fullname": "t2_5ntpnb49", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automated testing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_178j1j1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697387181.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m building an application that accepts exercise data from devices then kicks off a ETL pipeline. This data is then displayed to users. Right now I get really slowed down when I have to test changes and as I add more devices this will only become a bigger problem. Does anyone have experience creating automated tests for something like this.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "178j1j1", "is_robot_indexable": true, "report_reasons": null, "author": "ExtensionResearcher2", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/178j1j1/automated_testing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/178j1j1/automated_testing/", "subreddit_subscribers": 134191, "created_utc": 1697387181.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nIm currently working in a consulting company as a data engineer and loving everything about it. The pace, the exposure to different tech stacks and projects so far. What I\u2019m seeing is there is a ton of need for intermediate work and projects, so consulting makes sense for our clients. \n\nAll my clients have been BIG companies across pharmacy, entertainment and energy industries.\n\nNow question for the community, what\u2019s in house role like? \nSeems like mid size and smaller businesses are far behind the curve, since our massive clients are just now optimizing their pipelines. \nWould that imply that in house DE roles are mainly present for big companies or mid size with a team of a few DEs?\n\nMainly thinking through future moves, how long to stay, when to switch (if at all)?\n\nIs there enough tech exposure for in-house DE roles and are projects lengthy and boring? This is mainly in gaining experience in-house vs consulting. \n\nAny input is greatly appreciated.", "author_fullname": "t2_l2qjkxgyo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "In House Data Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_178kxkd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697394536.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697392578.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Im currently working in a consulting company as a data engineer and loving everything about it. The pace, the exposure to different tech stacks and projects so far. What I\u2019m seeing is there is a ton of need for intermediate work and projects, so consulting makes sense for our clients. &lt;/p&gt;\n\n&lt;p&gt;All my clients have been BIG companies across pharmacy, entertainment and energy industries.&lt;/p&gt;\n\n&lt;p&gt;Now question for the community, what\u2019s in house role like? \nSeems like mid size and smaller businesses are far behind the curve, since our massive clients are just now optimizing their pipelines. \nWould that imply that in house DE roles are mainly present for big companies or mid size with a team of a few DEs?&lt;/p&gt;\n\n&lt;p&gt;Mainly thinking through future moves, how long to stay, when to switch (if at all)?&lt;/p&gt;\n\n&lt;p&gt;Is there enough tech exposure for in-house DE roles and are projects lengthy and boring? This is mainly in gaining experience in-house vs consulting. &lt;/p&gt;\n\n&lt;p&gt;Any input is greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "178kxkd", "is_robot_indexable": true, "report_reasons": null, "author": "George_mate_", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/178kxkd/in_house_data_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/178kxkd/in_house_data_engineering/", "subreddit_subscribers": 134191, "created_utc": 1697392578.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking for a solution I can integrate into my app that can convert data stored in human readable formats from one schema to another. Ideally it would convert both ways from CSV, JSON, etc, but I need it to also be able to handle relational and nested data. \nSo it would need to be able to nest and un-nest data, flatten and un- flatten data, deal with arrays and hierarchy, etc. convert data from multiple tables into one and back. You get the picture.", "author_fullname": "t2_gjrwx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there an open source solution that handles complex conversion of data structures?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_178hvif", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697383892.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking for a solution I can integrate into my app that can convert data stored in human readable formats from one schema to another. Ideally it would convert both ways from CSV, JSON, etc, but I need it to also be able to handle relational and nested data. \nSo it would need to be able to nest and un-nest data, flatten and un- flatten data, deal with arrays and hierarchy, etc. convert data from multiple tables into one and back. You get the picture.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "178hvif", "is_robot_indexable": true, "report_reasons": null, "author": "prutwo", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/178hvif/is_there_an_open_source_solution_that_handles/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/178hvif/is_there_an_open_source_solution_that_handles/", "subreddit_subscribers": 134191, "created_utc": 1697383892.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am creating a medallion based data pipeline and am unsure at what state I should be storing data in the bronze layer.\n\nAs an example, I have json files being streamed into a data lake on s3, should I then read that data in a scheduled stream from the bucket and write it to delta with a defined schema into my bronze layer or should I keep it in the original json format (This seems basically like a pointless copy).\n\nTo me it seems better to do basic schema definition at the early pipeline stage where minimal transformation and enrichment is done as it makes it simpler to handle changes in the data that will inevitably occur.", "author_fullname": "t2_4e7vcqz8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Medallion - Databricks Bronze Layer Best Practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177x70q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697312149.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am creating a medallion based data pipeline and am unsure at what state I should be storing data in the bronze layer.&lt;/p&gt;\n\n&lt;p&gt;As an example, I have json files being streamed into a data lake on s3, should I then read that data in a scheduled stream from the bucket and write it to delta with a defined schema into my bronze layer or should I keep it in the original json format (This seems basically like a pointless copy).&lt;/p&gt;\n\n&lt;p&gt;To me it seems better to do basic schema definition at the early pipeline stage where minimal transformation and enrichment is done as it makes it simpler to handle changes in the data that will inevitably occur.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "177x70q", "is_robot_indexable": true, "report_reasons": null, "author": "noodlehead13", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/177x70q/medallion_databricks_bronze_layer_best_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/177x70q/medallion_databricks_bronze_layer_best_practice/", "subreddit_subscribers": 134191, "created_utc": 1697312149.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm an  developer, and I'll be presenting our new Azure Big Data stack architecture, including Databricks, devops,(medallion )Delta to a group of business analysts and SAP professionals who have limited knowledge of these tools. \n\nWhat are some of the fascinating facts, trivia, or impressive use cases about spark, big data stack that I can include in my keynote to wow the audience or show them the scale of these technologies?\n\nI was thinking of mentioning about Netflix and their used cases of handling the data volume using spark/big data techs.", "author_fullname": "t2_aqp7hdzb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help: Fascinating Spark/Big Data, Devops facts for my presentation!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17866lx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697340206.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697339357.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an  developer, and I&amp;#39;ll be presenting our new Azure Big Data stack architecture, including Databricks, devops,(medallion )Delta to a group of business analysts and SAP professionals who have limited knowledge of these tools. &lt;/p&gt;\n\n&lt;p&gt;What are some of the fascinating facts, trivia, or impressive use cases about spark, big data stack that I can include in my keynote to wow the audience or show them the scale of these technologies?&lt;/p&gt;\n\n&lt;p&gt;I was thinking of mentioning about Netflix and their used cases of handling the data volume using spark/big data techs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17866lx", "is_robot_indexable": true, "report_reasons": null, "author": "johnyjohnyespappa", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17866lx/help_fascinating_sparkbig_data_devops_facts_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17866lx/help_fascinating_sparkbig_data_devops_facts_for/", "subreddit_subscribers": 134191, "created_utc": 1697339357.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}