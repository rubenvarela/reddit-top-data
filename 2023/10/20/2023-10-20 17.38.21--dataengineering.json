{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yozg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The biggest new dbt Cloud features from Coalesce 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17bsage", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Pt2ZfLn9svd8KwEp2PFvdSkL16Ws3FifX7uUkLCUc9o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697746098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getdbt.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getdbt.com/blog/new-dbt-cloud-features-announced-at-coalesce-2023", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?auto=webp&amp;s=6347fcb3daf9a842bf820f8ccec577c12487f347", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77d0d353f5c6d77bfa60e43bbececf4b270a794e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=391a03e2803f86acb44234cf70a6db41d9a7fc63", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=991dad38adac8bb4c5ed0ffbc180ead7be80e687", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a5e9f4869a32ac351f89fc52effc05e53b3e0188", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f864e440c37ff7a996711d0a0e09e386defe2bf6", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=28f27d147ddf282fc9123b71c3e113168a518fcd", "width": 1080, "height": 607}], "variants": {}, "id": "jPyehZjVjFnnPXeUvtW24q2zxUIQShEm8Z8ELBIJQyw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17bsage", "is_robot_indexable": true, "report_reasons": null, "author": "gman1023", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bsage/the_biggest_new_dbt_cloud_features_from_coalesce/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getdbt.com/blog/new-dbt-cloud-features-announced-at-coalesce-2023", "subreddit_subscribers": 135015, "created_utc": 1697746098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wtf is data engineering\n\n\n\n\n\n\n\n\n\n\n\n^(this is a joke based on how every time I tell someone they ask me what data engineering is)", "author_fullname": "t2_4qppib05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I just accepted a data engineering internship", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c3u78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697782604.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697780241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wtf is data engineering&lt;/p&gt;\n\n&lt;p&gt;&lt;sup&gt;this is a joke based on how every time I tell someone they ask me what data engineering is&lt;/sup&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "17c3u78", "is_robot_indexable": true, "report_reasons": null, "author": "silvermoon_182", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c3u78/i_just_accepted_a_data_engineering_internship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17c3u78/i_just_accepted_a_data_engineering_internship/", "subreddit_subscribers": 135015, "created_utc": 1697780241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, wanted to get some input here\n\nWhat do you all do for database documentation / data catalog? Particularly for smaller organizations that might not have the budget to hop on calls with Atlan / Collibra / Alation and the other big enterprise Data Catalogs?\n\nFull disclosure: I'm [building a tool](https://datadocs.ai) in that area - something that's not about governance / enterprise integrations, but just about cataloging/search and documenting the db using AI.\n\nSo, I'm asking because I want to better understand how this problem is being solved by (small-medium) teams right now. I know that at my day job, we hopped on a call with the enterprise folks and got some pretty Enterprise price tags. We ended up kind of gluing something together ourselves, but it required a ton of continual manual work and is now dusty and out-of-date...", "author_fullname": "t2_npbdk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database Documentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c7gp0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697795510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, wanted to get some input here&lt;/p&gt;\n\n&lt;p&gt;What do you all do for database documentation / data catalog? Particularly for smaller organizations that might not have the budget to hop on calls with Atlan / Collibra / Alation and the other big enterprise Data Catalogs?&lt;/p&gt;\n\n&lt;p&gt;Full disclosure: I&amp;#39;m &lt;a href=\"https://datadocs.ai\"&gt;building a tool&lt;/a&gt; in that area - something that&amp;#39;s not about governance / enterprise integrations, but just about cataloging/search and documenting the db using AI.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m asking because I want to better understand how this problem is being solved by (small-medium) teams right now. I know that at my day job, we hopped on a call with the enterprise folks and got some pretty Enterprise price tags. We ended up kind of gluing something together ourselves, but it required a ton of continual manual work and is now dusty and out-of-date...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17c7gp0", "is_robot_indexable": true, "report_reasons": null, "author": "various1121", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c7gp0/database_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17c7gp0/database_documentation/", "subreddit_subscribers": 135015, "created_utc": 1697795510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Some data scientists can be annoying (haha) but man, a crazy platform engineer really shortens your lifespan.", "author_fullname": "t2_c37nxl2c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Platform engineers driving me nutz", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17cckie", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697812040.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Some data scientists can be annoying (haha) but man, a crazy platform engineer really shortens your lifespan.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "17cckie", "is_robot_indexable": true, "report_reasons": null, "author": "Rengar-Pounce", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17cckie/platform_engineers_driving_me_nutz/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17cckie/platform_engineers_driving_me_nutz/", "subreddit_subscribers": 135015, "created_utc": 1697812040.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need some support for a dimensional model I am trying to build. The data is about a marketplace. On the marketplace sellers can add their listings. Each Seller is associated with a specific country (country of residence). The listing itself and the price of the listing is something I want to model as a fact table:\n\nFACT fact\\_listings\n\n* Date\n* Listing\\_Key \n* Price of the listing\n\nBesides the listings table I want to add another dimension table describing the listings. \n\nDIMENSION dim\\_listings \n\n* Listing\\_Key\n* Type of Listing\n* Brand \n* Seller Key \n\nThe Sellers should also be a dimesion:\n\nDIMENSION dim\\_sellers\n\n* Seller\\_Key\n* Seller Name\n* Country Key \n\nDIMENSION dim\\_sountries\n\n* Country\\_Key\n* Country Name  \n\n&amp;#x200B;\n\nNow when the analyst query the data and try to get an overview of how many listings we have in a given county the analysts have to join firstly the FACT with the Dimension Listing &gt; Sellers &gt; Countries in order to create a query like:  \n\n\n    select\n        count(Listing_Key),\n        Country_Name, \n        Date\n    FROM\n        fact_listings \n        join dim_listings on dim_listings.Listing_Key = fact_listings.Listing_Key\n        join dim_sellers on dim_sellers.Seller_Key = dim_listings.Seller_Key\n        join dim_countries on dim_countries.Country_Key = dim_sellers.Country_Key\n    group by \n        Date,\n        Country_Name\n\nIt seems like there is a lot to join and not very efficient. So I am wondering if I should not add the Country\\_Key and Seller\\_Key directly to the FACT as well as to the dimensions? \n\nAny advise would be appreciated. ", "author_fullname": "t2_q1evb3a7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance on dimensional modelling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17caz8o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697807549.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need some support for a dimensional model I am trying to build. The data is about a marketplace. On the marketplace sellers can add their listings. Each Seller is associated with a specific country (country of residence). The listing itself and the price of the listing is something I want to model as a fact table:&lt;/p&gt;\n\n&lt;p&gt;FACT fact_listings&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Date&lt;/li&gt;\n&lt;li&gt;Listing_Key &lt;/li&gt;\n&lt;li&gt;Price of the listing&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Besides the listings table I want to add another dimension table describing the listings. &lt;/p&gt;\n\n&lt;p&gt;DIMENSION dim_listings &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Listing_Key&lt;/li&gt;\n&lt;li&gt;Type of Listing&lt;/li&gt;\n&lt;li&gt;Brand &lt;/li&gt;\n&lt;li&gt;Seller Key &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;The Sellers should also be a dimesion:&lt;/p&gt;\n\n&lt;p&gt;DIMENSION dim_sellers&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Seller_Key&lt;/li&gt;\n&lt;li&gt;Seller Name&lt;/li&gt;\n&lt;li&gt;Country Key &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;DIMENSION dim_sountries&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Country_Key&lt;/li&gt;\n&lt;li&gt;Country Name&lt;br/&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Now when the analyst query the data and try to get an overview of how many listings we have in a given county the analysts have to join firstly the FACT with the Dimension Listing &amp;gt; Sellers &amp;gt; Countries in order to create a query like:  &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;select\n    count(Listing_Key),\n    Country_Name, \n    Date\nFROM\n    fact_listings \n    join dim_listings on dim_listings.Listing_Key = fact_listings.Listing_Key\n    join dim_sellers on dim_sellers.Seller_Key = dim_listings.Seller_Key\n    join dim_countries on dim_countries.Country_Key = dim_sellers.Country_Key\ngroup by \n    Date,\n    Country_Name\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;It seems like there is a lot to join and not very efficient. So I am wondering if I should not add the Country_Key and Seller_Key directly to the FACT as well as to the dimensions? &lt;/p&gt;\n\n&lt;p&gt;Any advise would be appreciated. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17caz8o", "is_robot_indexable": true, "report_reasons": null, "author": "gordonnewland", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17caz8o/guidance_on_dimensional_modelling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17caz8o/guidance_on_dimensional_modelling/", "subreddit_subscribers": 135015, "created_utc": 1697807549.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey All\n\nI'm building a new data analytics platform product, and I'm looking to undertake market research and customer development to better understand pain points which will be turned into product features.\n\nMy question is what would incentivise you to participate in a 30 minute interview, and would you be ok with it being recorded?\n\nFor example, I was thinking:\n- Donate $20 to a charity of your choice\n- $20 Amazon voucher\n- Align with social impact and ask people to volunteer their time as it is for a good cause... My company is a social impact company where a large percentage of profits go towards solving United Nations Sustainable Development Goals\n\nHere's the idea: https://bit.ly/CanglerPitchDeck\nAnd here's the underlying social impact vision: https://www.elliseeaglingfoundation.org/\n\nThe question I'm grappling with is how to recruit data engineers, data architects, data scientists, data analysis, chief data officers and data management professionals to provide insights by participating in customer development research\n\nThanks in advance!", "author_fullname": "t2_6kft4j6w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Customer Development", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17cb7r5", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697811563.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697808263.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey All&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m building a new data analytics platform product, and I&amp;#39;m looking to undertake market research and customer development to better understand pain points which will be turned into product features.&lt;/p&gt;\n\n&lt;p&gt;My question is what would incentivise you to participate in a 30 minute interview, and would you be ok with it being recorded?&lt;/p&gt;\n\n&lt;p&gt;For example, I was thinking:\n- Donate $20 to a charity of your choice\n- $20 Amazon voucher\n- Align with social impact and ask people to volunteer their time as it is for a good cause... My company is a social impact company where a large percentage of profits go towards solving United Nations Sustainable Development Goals&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the idea: &lt;a href=\"https://bit.ly/CanglerPitchDeck\"&gt;https://bit.ly/CanglerPitchDeck&lt;/a&gt;\nAnd here&amp;#39;s the underlying social impact vision: &lt;a href=\"https://www.elliseeaglingfoundation.org/\"&gt;https://www.elliseeaglingfoundation.org/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The question I&amp;#39;m grappling with is how to recruit data engineers, data architects, data scientists, data analysis, chief data officers and data management professionals to provide insights by participating in customer development research&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17cb7r5", "is_robot_indexable": true, "report_reasons": null, "author": "drhobbi", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17cb7r5/customer_development/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17cb7r5/customer_development/", "subreddit_subscribers": 135015, "created_utc": 1697808263.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/vxcoyhmlldvb1.png?width=2032&amp;format=png&amp;auto=webp&amp;s=ec44219c419d20bd8698b9cd561b30c0eee4f3b3", "author_fullname": "t2_d3q0tuqi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Quote of the day....\"Experts often posses more data than judgement\"", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 75, "top_awarded_type": null, "hide_score": false, "media_metadata": {"vxcoyhmlldvb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 57, "x": 108, "u": "https://preview.redd.it/vxcoyhmlldvb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=53e0262ca2e43e90cfd5628ad50b83757d6ba0c6"}, {"y": 115, "x": 216, "u": "https://preview.redd.it/vxcoyhmlldvb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=6991b1a58fbce6b4de658648636241ce8c9abba8"}, {"y": 171, "x": 320, "u": "https://preview.redd.it/vxcoyhmlldvb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=f3253ec921818f0c13bd57c3dc31df40a2657241"}, {"y": 343, "x": 640, "u": "https://preview.redd.it/vxcoyhmlldvb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=26a5864dbddd1a65d055e357193b47aaf32e2fa7"}, {"y": 514, "x": 960, "u": "https://preview.redd.it/vxcoyhmlldvb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=98aa9d03c7573ec180021789ec05fe8fcb48dcae"}, {"y": 579, "x": 1080, "u": "https://preview.redd.it/vxcoyhmlldvb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9d3ad602419f2eefb96b73af34429ce3ab3a7341"}], "s": {"y": 1090, "x": 2032, "u": "https://preview.redd.it/vxcoyhmlldvb1.png?width=2032&amp;format=png&amp;auto=webp&amp;s=ec44219c419d20bd8698b9cd561b30c0eee4f3b3"}, "id": "vxcoyhmlldvb1"}}, "name": "t3_17cdy02", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rvvTw8NHjgdIABgzsTUwBYB8eBmB1k8J98NfSbtjQQw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697815700.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/vxcoyhmlldvb1.png?width=2032&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec44219c419d20bd8698b9cd561b30c0eee4f3b3\"&gt;https://preview.redd.it/vxcoyhmlldvb1.png?width=2032&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=ec44219c419d20bd8698b9cd561b30c0eee4f3b3&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "17cdy02", "is_robot_indexable": true, "report_reasons": null, "author": "JohnAnthonyRyan", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17cdy02/quote_of_the_dayexperts_often_posses_more_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17cdy02/quote_of_the_dayexperts_often_posses_more_data/", "subreddit_subscribers": 135015, "created_utc": 1697815700.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vawnhgn9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scaling to 15000 functions and beyond", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17cay76", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/vsTM2k9gAC710BohbjKvL42QX9gESZf2z6g8tch-Cv0.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697807461.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "openfaas.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.openfaas.com/blog/large-scale-functions/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/eMOPDroA5s0d0qFEK8Rh-TZF3AhKQvcIva81pJhAoOM.jpg?auto=webp&amp;s=2ddbd981a8798a2841a45800ca5d883448e4fdbe", "width": 1600, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/eMOPDroA5s0d0qFEK8Rh-TZF3AhKQvcIva81pJhAoOM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c573cbb6f35765eab8d29013cca70333a1868133", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/eMOPDroA5s0d0qFEK8Rh-TZF3AhKQvcIva81pJhAoOM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=76bc35c681171b2eb935819ff0655be482e77356", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/eMOPDroA5s0d0qFEK8Rh-TZF3AhKQvcIva81pJhAoOM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3b6abd18b8a77ee65847822b67a90fb2a547727f", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/eMOPDroA5s0d0qFEK8Rh-TZF3AhKQvcIva81pJhAoOM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0bfdcb7475f0536d5c301cecdf65b3c96499212b", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/eMOPDroA5s0d0qFEK8Rh-TZF3AhKQvcIva81pJhAoOM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=904a8a1806c009e92970946c2430001a3180aba4", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/eMOPDroA5s0d0qFEK8Rh-TZF3AhKQvcIva81pJhAoOM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=e28df4f7d0b0f09b2ba868549f98555276fe20d0", "width": 1080, "height": 607}], "variants": {}, "id": "G68h-cEyIE2NpCyCAeq1JQmaR39cw1vvHl_8ZlNFKCw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17cay76", "is_robot_indexable": true, "report_reasons": null, "author": "warhatrye", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17cay76/scaling_to_15000_functions_and_beyond/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.openfaas.com/blog/large-scale-functions/", "subreddit_subscribers": 135015, "created_utc": 1697807461.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For now it is driftdb. But I'm thinking bi-temporaldb, but it is too long.\n\nThe goal is to store some metrics, and understand what happened between 2 \"measurements\". and in the end have something like that [workinprogress](https://app.data-drift.io/41231518/Samox/dbt-example/overview?snapshotDate=2023-10-18&amp;commitSha=37467fb6ce76d26fad8b09d7582ed3f6ad5d61e3)\n\n&amp;#x200B;\n\nTo try on your computer (I have tested on mac only):\n\n`pip install driftdb`\n\n`driftdb seed create`\n\n`driftdb seed update`\n\n`driftdb start`\n\nAnd if you want to see more variations, do more \"driftdb seed update\"\n\nWould love to get feedback or suggestions!\n\n&amp;#x200B;\n\n[https://pypi.org/project/driftdb/0.0.1a8/](https://pypi.org/project/driftdb/0.0.1a8/)\n\n&amp;#x200B;", "author_fullname": "t2_10uv2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone wants to try my database ? Also I need a name \ud83e\udd17", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c7fqt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697804076.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697795402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For now it is driftdb. But I&amp;#39;m thinking bi-temporaldb, but it is too long.&lt;/p&gt;\n\n&lt;p&gt;The goal is to store some metrics, and understand what happened between 2 &amp;quot;measurements&amp;quot;. and in the end have something like that &lt;a href=\"https://app.data-drift.io/41231518/Samox/dbt-example/overview?snapshotDate=2023-10-18&amp;amp;commitSha=37467fb6ce76d26fad8b09d7582ed3f6ad5d61e3\"&gt;workinprogress&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To try on your computer (I have tested on mac only):&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;pip install driftdb&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;driftdb seed create&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;driftdb seed update&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;driftdb start&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;And if you want to see more variations, do more &amp;quot;driftdb seed update&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Would love to get feedback or suggestions!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pypi.org/project/driftdb/0.0.1a8/\"&gt;https://pypi.org/project/driftdb/0.0.1a8/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17c7fqt", "is_robot_indexable": true, "report_reasons": null, "author": "Srammmy", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c7fqt/anyone_wants_to_try_my_database_also_i_need_a_name/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17c7fqt/anyone_wants_to_try_my_database_also_i_need_a_name/", "subreddit_subscribers": 135015, "created_utc": 1697795402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working in a project where the company is working with Siebel CRM and has the backend database Oracle db.  They have some process to mass update but it's really kind of complicated, they're preparing csv file which needs to be placed in a particular for the night job to run.  \n\n\nI have the need to move Siebel objects from one account to another and there isn't any template prepared for re-linking certain CRM objects like Activities, Opportunities or Contacts.  \n\n\nMy question, since Siebel is so old and lacks any kind of Data Loader and ease of use, wouldn't it be better to directly do it in the database? \n\nOr even a better option, to have some integration tool such as Jitterbit or Boomi (I only know these two tools for now).\n\nWhich would solve the most basic CRUD needs an enterprise ERP?\n\nThoughts?", "author_fullname": "t2_9sk2qr0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Integration or Middleware for CRM Application mass changes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c745l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697794041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working in a project where the company is working with Siebel CRM and has the backend database Oracle db.  They have some process to mass update but it&amp;#39;s really kind of complicated, they&amp;#39;re preparing csv file which needs to be placed in a particular for the night job to run.  &lt;/p&gt;\n\n&lt;p&gt;I have the need to move Siebel objects from one account to another and there isn&amp;#39;t any template prepared for re-linking certain CRM objects like Activities, Opportunities or Contacts.  &lt;/p&gt;\n\n&lt;p&gt;My question, since Siebel is so old and lacks any kind of Data Loader and ease of use, wouldn&amp;#39;t it be better to directly do it in the database? &lt;/p&gt;\n\n&lt;p&gt;Or even a better option, to have some integration tool such as Jitterbit or Boomi (I only know these two tools for now).&lt;/p&gt;\n\n&lt;p&gt;Which would solve the most basic CRUD needs an enterprise ERP?&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17c745l", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious_Flow_465", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c745l/data_integration_or_middleware_for_crm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17c745l/data_integration_or_middleware_for_crm/", "subreddit_subscribers": 135015, "created_utc": 1697794041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3dyum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10 Trends of Business Intelligence to Facilitate Data Analytics and Decision Making", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_17c5nua", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/I3tK0poKOUvEDfeW35QRNETKGsMORUfdwonOQE7bcKM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697787905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bigdataanalyticsnews.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bigdataanalyticsnews.com/business-intelligence-trends-to-facilitate-data-analytics-decision-making/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?auto=webp&amp;s=b83541515bc8c127e291b451a190d76fbe86c878", "width": 1024, "height": 536}, "resolutions": [{"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b7b03a49512b697769a0b52ebdab52c40560082", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3f3be8c16d5d971bf2ac22d4c86f4f121a158676", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4bb4cb5f3dea2d7ba4b96f251bbc10d7c6cd942", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c8e84f93c9943ac1a5c173668a52c5fd7aabee3a", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a5d5b777a9089effa445ae26e3803a847cd5504c", "width": 960, "height": 502}], "variants": {}, "id": "gsMTE-5CAzFfCBXOV7R2jJw4mLTVMPNP7Cr5uXnjJ-8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17c5nua", "is_robot_indexable": true, "report_reasons": null, "author": "Veerans", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c5nua/10_trends_of_business_intelligence_to_facilitate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bigdataanalyticsnews.com/business-intelligence-trends-to-facilitate-data-analytics-decision-making/", "subreddit_subscribers": 135015, "created_utc": 1697787905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There is a task in hand to automate the migration of 1000 jobs to Adf. My approach to problem statement is \n\n1) identify the rest apis that provide the job details\n2) Have custom mapping for informatica to add functions\n3) Have custom scripts generating the pseudo code as the conversation might not be straight forward\n4) Deploy in the ARM template or any iaac code\n\nThoughts ? Can we brainstorm ?", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automate informatica job migration to Adf", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c2lwh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697775617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is a task in hand to automate the migration of 1000 jobs to Adf. My approach to problem statement is &lt;/p&gt;\n\n&lt;p&gt;1) identify the rest apis that provide the job details\n2) Have custom mapping for informatica to add functions\n3) Have custom scripts generating the pseudo code as the conversation might not be straight forward\n4) Deploy in the ARM template or any iaac code&lt;/p&gt;\n\n&lt;p&gt;Thoughts ? Can we brainstorm ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17c2lwh", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c2lwh/automate_informatica_job_migration_to_adf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17c2lwh/automate_informatica_job_migration_to_adf/", "subreddit_subscribers": 135015, "created_utc": 1697775617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I mount the volumes from a CSI (Rook with Ceph). InitContainers with permissions for the volumes for both Zeppelin and Spark.\n\nIf I also deploy a second Spark (spark2 from now) and submit an app from spark2 using spark1 cluster i can write on the volume. Do the same in Zeppelin and get permissions denied. \n\nI know for a fact that it is because of the user.  But cannot figure out why it works for an app with same permissions that the other has but is not working for the other. \n\nWilling to share conf files if needed. \n\nThanks a lot \ud83d\ude4f\ud83c\udffc", "author_fullname": "t2_d0ifg2cb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone know about Zeppelin and Spark with Kubernetes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17btopz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697749666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mount the volumes from a CSI (Rook with Ceph). InitContainers with permissions for the volumes for both Zeppelin and Spark.&lt;/p&gt;\n\n&lt;p&gt;If I also deploy a second Spark (spark2 from now) and submit an app from spark2 using spark1 cluster i can write on the volume. Do the same in Zeppelin and get permissions denied. &lt;/p&gt;\n\n&lt;p&gt;I know for a fact that it is because of the user.  But cannot figure out why it works for an app with same permissions that the other has but is not working for the other. &lt;/p&gt;\n\n&lt;p&gt;Willing to share conf files if needed. &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot \ud83d\ude4f\ud83c\udffc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17btopz", "is_robot_indexable": true, "report_reasons": null, "author": "Awkward-Cupcake6219", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17btopz/does_anyone_know_about_zeppelin_and_spark_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17btopz/does_anyone_know_about_zeppelin_and_spark_with/", "subreddit_subscribers": 135015, "created_utc": 1697749666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,\n\nI am currently developing a data architecture which is as follows, the aim being to retrieve, transform and store data from a .txt file sent by an FTP server, then display it on grafana :\n\n&amp;#x200B;\n\nhttps://preview.redd.it/g9v89vjqpdvb1.jpg?width=680&amp;format=pjpg&amp;auto=webp&amp;s=b0841d195fa0d8ca13d969bde536e333d020be36\n\nI'd like to be able to carry out tests on various points:\n\n* FTP: connectivity, file format\n*  ETL (python script): data formatting, loading, extraction, errors and exceptions\n*  DB (postgreSQL): query performance, backup\n* Grafana: display, alerts\n\n&amp;#x200B;\n\nbefore hosting the various elements on a dedicated server to avoid errors.\n\nBut as I don't know enough about devops, I'd like some advice on tools that could potentially be compatible with my needs and on other elements that are important to test in a data architecture?\n\n&amp;#x200B;\n\nAmount of data: +-5 GB\n\n&amp;#x200B;\n\nThanks in advance,", "author_fullname": "t2_usmpgy0x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need advice on setting up automated tests?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 56, "top_awarded_type": null, "hide_score": true, "media_metadata": {"g9v89vjqpdvb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 43, "x": 108, "u": "https://preview.redd.it/g9v89vjqpdvb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c949155bcbe67a47fc41a67a0447e6fcef5eab31"}, {"y": 86, "x": 216, "u": "https://preview.redd.it/g9v89vjqpdvb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=450a2e4abb4a6d2fe0ed0398db00132015b83001"}, {"y": 128, "x": 320, "u": "https://preview.redd.it/g9v89vjqpdvb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=96f1172ea24024020275bf1abeac3f9be7a669dc"}, {"y": 256, "x": 640, "u": "https://preview.redd.it/g9v89vjqpdvb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e744c44c2588313a3153c325210c92b724f84a83"}], "s": {"y": 272, "x": 680, "u": "https://preview.redd.it/g9v89vjqpdvb1.jpg?width=680&amp;format=pjpg&amp;auto=webp&amp;s=b0841d195fa0d8ca13d969bde536e333d020be36"}, "id": "g9v89vjqpdvb1"}}, "name": "t3_17cehcs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/i4_nUFhUv8Qmc5fNFoBXi6ZHZJW9NXCvxawG-DK2Md4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697817120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I am currently developing a data architecture which is as follows, the aim being to retrieve, transform and store data from a .txt file sent by an FTP server, then display it on grafana :&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/g9v89vjqpdvb1.jpg?width=680&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b0841d195fa0d8ca13d969bde536e333d020be36\"&gt;https://preview.redd.it/g9v89vjqpdvb1.jpg?width=680&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=b0841d195fa0d8ca13d969bde536e333d020be36&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to be able to carry out tests on various points:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;FTP: connectivity, file format&lt;/li&gt;\n&lt;li&gt; ETL (python script): data formatting, loading, extraction, errors and exceptions&lt;/li&gt;\n&lt;li&gt; DB (postgreSQL): query performance, backup&lt;/li&gt;\n&lt;li&gt;Grafana: display, alerts&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;before hosting the various elements on a dedicated server to avoid errors.&lt;/p&gt;\n\n&lt;p&gt;But as I don&amp;#39;t know enough about devops, I&amp;#39;d like some advice on tools that could potentially be compatible with my needs and on other elements that are important to test in a data architecture?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Amount of data: +-5 GB&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance,&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17cehcs", "is_robot_indexable": true, "report_reasons": null, "author": "SeJikairos", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17cehcs/need_advice_on_setting_up_automated_tests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17cehcs/need_advice_on_setting_up_automated_tests/", "subreddit_subscribers": 135015, "created_utc": 1697817120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you all serve up product data ( usage , enriched backend) to engineers to help them improve products at the road map design level or even just experience/ experience ?", "author_fullname": "t2_13551s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serving product data to product engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bx6ix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697758906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you all serve up product data ( usage , enriched backend) to engineers to help them improve products at the road map design level or even just experience/ experience ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17bx6ix", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bx6ix/serving_product_data_to_product_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bx6ix/serving_product_data_to_product_engineers/", "subreddit_subscribers": 135015, "created_utc": 1697758906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello.\n\nI've been using SQL Server to BULK import .csv files stored in Azure Blob Storage, using scoped credentials, external data source, master key, etc.\n\nThis works fine. However, I'd like to upsert an existing table, say Invoices, with a new version of the .csv file corresponding to the Invoices table.\n\nI know that I can use MERGE, USING, ON, WHEN MATCHED, WHEN NOT MATCHED, etc, if I load the new source .csv file in a temp_Invoices table and then do the merge between the two.\n\nHowever, this defeats the whole purpose, since... I'd be loading the full table anyways, and I just want to load the new and modified data.\n\nIs this possible to do?\n\nI know CDC exists but the source databases doesn't allow this. If this is not possible, is full load the only practical solution?", "author_fullname": "t2_h920ytdnk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upserting SQL Server table with .csv file, directly (incremental loading?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bv9ou", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697753655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using SQL Server to BULK import .csv files stored in Azure Blob Storage, using scoped credentials, external data source, master key, etc.&lt;/p&gt;\n\n&lt;p&gt;This works fine. However, I&amp;#39;d like to upsert an existing table, say Invoices, with a new version of the .csv file corresponding to the Invoices table.&lt;/p&gt;\n\n&lt;p&gt;I know that I can use MERGE, USING, ON, WHEN MATCHED, WHEN NOT MATCHED, etc, if I load the new source .csv file in a temp_Invoices table and then do the merge between the two.&lt;/p&gt;\n\n&lt;p&gt;However, this defeats the whole purpose, since... I&amp;#39;d be loading the full table anyways, and I just want to load the new and modified data.&lt;/p&gt;\n\n&lt;p&gt;Is this possible to do?&lt;/p&gt;\n\n&lt;p&gt;I know CDC exists but the source databases doesn&amp;#39;t allow this. If this is not possible, is full load the only practical solution?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17bv9ou", "is_robot_indexable": true, "report_reasons": null, "author": "ineedanswersiswear", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bv9ou/upserting_sql_server_table_with_csv_file_directly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bv9ou/upserting_sql_server_table_with_csv_file_directly/", "subreddit_subscribers": 135015, "created_utc": 1697753655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! i've been asked to connect/pull data from SAP successfactors but i'm a bit confused, wondering if there is some help here.\n\nThe docs they gave us basically says \"get a saml assertion\" and that's about it... so i guess my question is has anyone had success with getting connected/might have some resources?\n\nThe SAML bit is new to me, so i'm looking to understand a bit better on that piece, specifically generating the assertions. We are an azure house with AD sign in for it, so i feel like there is something there?\n\nWe are looking to pull the data out for storing in the warehouse for Power BI reporting internally. Looking to target the odata feed endpoints (which i am comfortable with!)\n\nalternatively, is there any paid platforms that have this like fivetran...\n\nThanks!\n\nhttps://help.sap.com/docs/SAP_SUCCESSFACTORS_PLATFORM/d599f15995d348a1b45ba5603e2aba9b/d9a9545305004187986c866de2b66987.html?locale=en-US", "author_fullname": "t2_ahu1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SAP Successfactors HXM - SAML", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17brk05", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697744225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! i&amp;#39;ve been asked to connect/pull data from SAP successfactors but i&amp;#39;m a bit confused, wondering if there is some help here.&lt;/p&gt;\n\n&lt;p&gt;The docs they gave us basically says &amp;quot;get a saml assertion&amp;quot; and that&amp;#39;s about it... so i guess my question is has anyone had success with getting connected/might have some resources?&lt;/p&gt;\n\n&lt;p&gt;The SAML bit is new to me, so i&amp;#39;m looking to understand a bit better on that piece, specifically generating the assertions. We are an azure house with AD sign in for it, so i feel like there is something there?&lt;/p&gt;\n\n&lt;p&gt;We are looking to pull the data out for storing in the warehouse for Power BI reporting internally. Looking to target the odata feed endpoints (which i am comfortable with!)&lt;/p&gt;\n\n&lt;p&gt;alternatively, is there any paid platforms that have this like fivetran...&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://help.sap.com/docs/SAP_SUCCESSFACTORS_PLATFORM/d599f15995d348a1b45ba5603e2aba9b/d9a9545305004187986c866de2b66987.html?locale=en-US\"&gt;https://help.sap.com/docs/SAP_SUCCESSFACTORS_PLATFORM/d599f15995d348a1b45ba5603e2aba9b/d9a9545305004187986c866de2b66987.html?locale=en-US&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17brk05", "is_robot_indexable": true, "report_reasons": null, "author": "Namur007", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17brk05/sap_successfactors_hxm_saml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17brk05/sap_successfactors_hxm_saml/", "subreddit_subscribers": 135015, "created_utc": 1697744225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We currently have a use case where scientists generate large volumes of datasets on an output S3 bucket. They annotate metadata for each dataset on an XLSX hosted in SharePoint (feature-wise, it's very important to them that they can \"drag-and-drop\" rows down to quickly create like rows because they can work with up to 50 replicates at a time, all with very similar columns). This SharePoint site is polled and any update to the XLSX triggers ingestion of both XLSX and associated datasets (rows).\n\nThis solution works, and it's simple (i.e. we don't need to build a custom application that needs to be maintained). The challenge here was always that we didn't have any source system to inject metadata from, so XLSX was an easy solution when we first started.\n\nHowever, now we're in production, and management doesn't like having XLSX involved in our automation. We need to find a new solution, but without building an entirely custom LIMS application here, I'm not sure how to solve this in a simple way! I'm looking for an open source solution for users to enter data through a UI, preferably as a table. It would be great if the solution had API integration and some sort of quality checks built in!\n\nDoes something like this exist? I'm curious how others deal with these problems?", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for open source tools for users to manually enter data in tables (but not Excel)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bqz6r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697742727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We currently have a use case where scientists generate large volumes of datasets on an output S3 bucket. They annotate metadata for each dataset on an XLSX hosted in SharePoint (feature-wise, it&amp;#39;s very important to them that they can &amp;quot;drag-and-drop&amp;quot; rows down to quickly create like rows because they can work with up to 50 replicates at a time, all with very similar columns). This SharePoint site is polled and any update to the XLSX triggers ingestion of both XLSX and associated datasets (rows).&lt;/p&gt;\n\n&lt;p&gt;This solution works, and it&amp;#39;s simple (i.e. we don&amp;#39;t need to build a custom application that needs to be maintained). The challenge here was always that we didn&amp;#39;t have any source system to inject metadata from, so XLSX was an easy solution when we first started.&lt;/p&gt;\n\n&lt;p&gt;However, now we&amp;#39;re in production, and management doesn&amp;#39;t like having XLSX involved in our automation. We need to find a new solution, but without building an entirely custom LIMS application here, I&amp;#39;m not sure how to solve this in a simple way! I&amp;#39;m looking for an open source solution for users to enter data through a UI, preferably as a table. It would be great if the solution had API integration and some sort of quality checks built in!&lt;/p&gt;\n\n&lt;p&gt;Does something like this exist? I&amp;#39;m curious how others deal with these problems?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17bqz6r", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bqz6r/looking_for_open_source_tools_for_users_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bqz6r/looking_for_open_source_tools_for_users_to/", "subreddit_subscribers": 135015, "created_utc": 1697742727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an good friend  (bachelors in politics and and another in CS) who is a senior data engineer, and I thought it would be valuable to share his knowledge with others who are interested in getting into the same field. This is kind of a \u2018if you don\u2019t know, you don\u2019t know\u2019 what to ask situation for me. So, I would like to know what questions would be of value to you. I can post the questions and his answers here if you want as well.", "author_fullname": "t2_102ywc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What questions would you like to ask a Senior Data engineer in the Health Management Industry (medicare plans)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bx78h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697758969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an good friend  (bachelors in politics and and another in CS) who is a senior data engineer, and I thought it would be valuable to share his knowledge with others who are interested in getting into the same field. This is kind of a \u2018if you don\u2019t know, you don\u2019t know\u2019 what to ask situation for me. So, I would like to know what questions would be of value to you. I can post the questions and his answers here if you want as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17bx78h", "is_robot_indexable": true, "report_reasons": null, "author": "escis", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bx78h/what_questions_would_you_like_to_ask_a_senior/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bx78h/what_questions_would_you_like_to_ask_a_senior/", "subreddit_subscribers": 135015, "created_utc": 1697758969.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}