{"kind": "Listing", "data": {"after": null, "dist": 17, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Mods, where are you? There are countless posts every week with questions that were answered already.  \n\nShould I learn Python? \nMasters degree worth it?\nJob market sucks, what projects should I do?\n\nAll of these are valid questions, and my heart goes out to those who are struggling to land their first job. BUT, a quick lookup will yield answers for most of the questions online. It also frustrating to find the same question to which you have answered a day ago.  Let alone the fact that many of these posts are low effort ones and their questions aren\u2019t even phrased correctly.\n\nAll of this spam drives seniors away, and instead of making a discussion about ds content, hopefully more advanced stuff, we keep answering questions about which is better, a project of a master.", "author_fullname": "t2_4udseb4x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[rant] Required - A designated tread for transitioning to DS and repeating questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bmc70", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697730631.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Mods, where are you? There are countless posts every week with questions that were answered already.  &lt;/p&gt;\n\n&lt;p&gt;Should I learn Python? \nMasters degree worth it?\nJob market sucks, what projects should I do?&lt;/p&gt;\n\n&lt;p&gt;All of these are valid questions, and my heart goes out to those who are struggling to land their first job. BUT, a quick lookup will yield answers for most of the questions online. It also frustrating to find the same question to which you have answered a day ago.  Let alone the fact that many of these posts are low effort ones and their questions aren\u2019t even phrased correctly.&lt;/p&gt;\n\n&lt;p&gt;All of this spam drives seniors away, and instead of making a discussion about ds content, hopefully more advanced stuff, we keep answering questions about which is better, a project of a master.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17bmc70", "is_robot_indexable": true, "report_reasons": null, "author": "David202023", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17bmc70/rant_required_a_designated_tread_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17bmc70/rant_required_a_designated_tread_for/", "subreddit_subscribers": 1091871, "created_utc": 1697730631.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently a DA for a company that uses data sets from clients with PII. The client I was assigned requires all people handling their data to take a drug test. I happen to smoke a lot of weed. I\u2019m debating trying to cheat the test or just coming clean to my boss and asking to get taken off the assignment. \n\nI never thought this was a possibility and wanted to know if this is common for jobs handling sensitive data. Any advice would be appreciated too. Thanks!", "author_fullname": "t2_aknrbt9i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody ever been drug tested for handling sensitive data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c29v4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 25, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 25, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "nsfw", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697774469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a DA for a company that uses data sets from clients with PII. The client I was assigned requires all people handling their data to take a drug test. I happen to smoke a lot of weed. I\u2019m debating trying to cheat the test or just coming clean to my boss and asking to get taken off the assignment. &lt;/p&gt;\n\n&lt;p&gt;I never thought this was a possibility and wanted to know if this is common for jobs handling sensitive data. Any advice would be appreciated too. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": true, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17c29v4", "is_robot_indexable": true, "report_reasons": null, "author": "FaithlessnessProof92", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17c29v4/anybody_ever_been_drug_tested_for_handling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17c29v4/anybody_ever_been_drug_tested_for_handling/", "subreddit_subscribers": 1091871, "created_utc": 1697774469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "hi ppl. I'm wondering if it is useful to learn standard DSA and algorithms for data science or machine learning. i mean algos like trees, BFS or even dynamic programming. Because it really take some time and i don't know if its worth.", "author_fullname": "t2_d0e7m1i5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Structures &amp; Algorithms in Data Science", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bv17l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697753030.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;hi ppl. I&amp;#39;m wondering if it is useful to learn standard DSA and algorithms for data science or machine learning. i mean algos like trees, BFS or even dynamic programming. Because it really take some time and i don&amp;#39;t know if its worth.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17bv17l", "is_robot_indexable": true, "report_reasons": null, "author": "scarysticks0w", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17bv17l/data_structures_algorithms_in_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17bv17l/data_structures_algorithms_in_data_science/", "subreddit_subscribers": 1091871, "created_utc": 1697753030.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I come from a Math background, and im fascinated by Math topics like Functional Analysis, Differential Geometry, Topology, Manifold Learning etc, Im actually looking for ways where i can apply these Math topics in my day to day Data Science/ML work. Is there any DS or ML roles which can allow me to delve deep into these Math topics? This has been my dream job. Where can i find roles that will allow me to such expertise, my main issue being that im unable to find such roles.", "author_fullname": "t2_k17nck5e2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Use cases of Advanced Math in Data Science and Machine Learning", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bg00y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697711887.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697711491.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I come from a Math background, and im fascinated by Math topics like Functional Analysis, Differential Geometry, Topology, Manifold Learning etc, Im actually looking for ways where i can apply these Math topics in my day to day Data Science/ML work. Is there any DS or ML roles which can allow me to delve deep into these Math topics? This has been my dream job. Where can i find roles that will allow me to such expertise, my main issue being that im unable to find such roles.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17bg00y", "is_robot_indexable": true, "report_reasons": null, "author": "honghuiying", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17bg00y/use_cases_of_advanced_math_in_data_science_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17bg00y/use_cases_of_advanced_math_in_data_science_and/", "subreddit_subscribers": 1091871, "created_utc": 1697711491.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In my past work I've become familiar with various techniques for *predictive* modeling--NNs, of course, but also more \"classical\" methods like random forests or LASSO regression (along with their implementations in Python, which was probably one of the best decisions I ever made was picking up Python--I've loved using sklearn and nltk, and I haven't even gotten to using pytorch yet).\n\nAll that said, I haven't worked as much so far with *explanatory* modeling and I'm looking to get more into it. I understand the conceptual differences: in predictive tasks, we care more about signal than significance--we might, for example, include variables that are predictive but not statistically significant, or exclude variables that are significant but not predictive. What's more, in the explanatory environment, there's a much greater emphasis on *model interpretability*--that is to say, models like NNs or even random forests that can get kind of \"black boxy\" are disfavored compared to simpler models with much more straightforward interpretability.\n\nSo what's the state-of-the-art, go-to model(s) for explanatory tasks? Stepwise regression??", "author_fullname": "t2_jzcyr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Predictive vs Explanatory modeling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bqhb0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697741452.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my past work I&amp;#39;ve become familiar with various techniques for &lt;em&gt;predictive&lt;/em&gt; modeling--NNs, of course, but also more &amp;quot;classical&amp;quot; methods like random forests or LASSO regression (along with their implementations in Python, which was probably one of the best decisions I ever made was picking up Python--I&amp;#39;ve loved using sklearn and nltk, and I haven&amp;#39;t even gotten to using pytorch yet).&lt;/p&gt;\n\n&lt;p&gt;All that said, I haven&amp;#39;t worked as much so far with &lt;em&gt;explanatory&lt;/em&gt; modeling and I&amp;#39;m looking to get more into it. I understand the conceptual differences: in predictive tasks, we care more about signal than significance--we might, for example, include variables that are predictive but not statistically significant, or exclude variables that are significant but not predictive. What&amp;#39;s more, in the explanatory environment, there&amp;#39;s a much greater emphasis on &lt;em&gt;model interpretability&lt;/em&gt;--that is to say, models like NNs or even random forests that can get kind of &amp;quot;black boxy&amp;quot; are disfavored compared to simpler models with much more straightforward interpretability.&lt;/p&gt;\n\n&lt;p&gt;So what&amp;#39;s the state-of-the-art, go-to model(s) for explanatory tasks? Stepwise regression??&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17bqhb0", "is_robot_indexable": true, "report_reasons": null, "author": "19andoverlol", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17bqhb0/predictive_vs_explanatory_modeling/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17bqhb0/predictive_vs_explanatory_modeling/", "subreddit_subscribers": 1091871, "created_utc": 1697741452.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, \n\nI\u2019ve been reading up some articles from kaggle and blogs about data imputation. I\u2019m wondering if there\u2019s a complete guide that introduces all the methods to data imputation. I\u2019m interested to see all the pros and cons and the usage of different situations. \n\nThanks for sharing!", "author_fullname": "t2_snz8uvf5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any data imputation technique shares?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c0z6e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697770197.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been reading up some articles from kaggle and blogs about data imputation. I\u2019m wondering if there\u2019s a complete guide that introduces all the methods to data imputation. I\u2019m interested to see all the pros and cons and the usage of different situations. &lt;/p&gt;\n\n&lt;p&gt;Thanks for sharing!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17c0z6e", "is_robot_indexable": true, "report_reasons": null, "author": "EthicalArtisan", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17c0z6e/any_data_imputation_technique_shares/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17c0z6e/any_data_imputation_technique_shares/", "subreddit_subscribers": 1091871, "created_utc": 1697770197.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a CS final sem grad student from Georgia Tech and was recently offered a full time Data Scientist role in Atlanta.\n\nThe compensation included 97K USD in base salary and 2500 stock units. \n\nis this a fair offer for an experienced data scientist? ( I have 1.5 years of work experience as a Data Scientist  in China)\n\nShould I accept it considering the weird market right now?", "author_fullname": "t2_tc3fp2l3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "97K in Atlanta?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17c5g4f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697786966.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a CS final sem grad student from Georgia Tech and was recently offered a full time Data Scientist role in Atlanta.&lt;/p&gt;\n\n&lt;p&gt;The compensation included 97K USD in base salary and 2500 stock units. &lt;/p&gt;\n\n&lt;p&gt;is this a fair offer for an experienced data scientist? ( I have 1.5 years of work experience as a Data Scientist  in China)&lt;/p&gt;\n\n&lt;p&gt;Should I accept it considering the weird market right now?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17c5g4f", "is_robot_indexable": true, "report_reasons": null, "author": "aiden12wade97", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17c5g4f/97k_in_atlanta/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17c5g4f/97k_in_atlanta/", "subreddit_subscribers": 1091871, "created_utc": 1697786966.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI am currently writing my master thesis about gaze estimation and i am using a combination of a cnn for finding feature map and transformer for the regression task. The gaze angular error is a common metric in this field, because it calculates the angle and ignores the depth of two gaze predictions. But in most of the papers about this topic the L1 or L2 loss is used and gaze angular error is only the evaluation metric.\n\nDo you know why gaze angular error is not used as loss as well?", "author_fullname": "t2_8hi7gpok", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Different loss function than evaluation metric", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17becn2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697704437.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I am currently writing my master thesis about gaze estimation and i am using a combination of a cnn for finding feature map and transformer for the regression task. The gaze angular error is a common metric in this field, because it calculates the angle and ignores the depth of two gaze predictions. But in most of the papers about this topic the L1 or L2 loss is used and gaze angular error is only the evaluation metric.&lt;/p&gt;\n\n&lt;p&gt;Do you know why gaze angular error is not used as loss as well?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17becn2", "is_robot_indexable": true, "report_reasons": null, "author": "mesheaa", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17becn2/different_loss_function_than_evaluation_metric/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17becn2/different_loss_function_than_evaluation_metric/", "subreddit_subscribers": 1091871, "created_utc": 1697704437.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have 8 years of experience as a data analyst, but haven't worked in the field since 2020. I want to get back into it professionally, but am worried that potential employers might be put off due to the three year gap.\n\nHas anyone here had any experience with doing data analysis on a volunteer basis? I've done some research but figured it can't hurt to cast a wider net.\n\nTIA!", "author_fullname": "t2_bxvv44pxt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Analysis Volunteer Opportunities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17c5wp3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697788931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 8 years of experience as a data analyst, but haven&amp;#39;t worked in the field since 2020. I want to get back into it professionally, but am worried that potential employers might be put off due to the three year gap.&lt;/p&gt;\n\n&lt;p&gt;Has anyone here had any experience with doing data analysis on a volunteer basis? I&amp;#39;ve done some research but figured it can&amp;#39;t hurt to cast a wider net.&lt;/p&gt;\n\n&lt;p&gt;TIA!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17c5wp3", "is_robot_indexable": true, "report_reasons": null, "author": "Specialist-Title-847", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17c5wp3/data_analysis_volunteer_opportunities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17c5wp3/data_analysis_volunteer_opportunities/", "subreddit_subscribers": 1091871, "created_utc": 1697788931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm a top rated data analyst freelancer on upwork and i'm starting to feel uncertain about data analysis market.\nThe thing is i feel it has such a small market in comparison to other freelancing fields and most jobs are low rates with crazy requirements on each job , demanding you to know every technique and technology which is rediculous.  And you barely make it into good jobs that come once in 3 days \n\nI'm here seeking for opinion and  guidance from any fellow data analyst/scientist freelancers , should i stop using upwork and attempt to land clients worldwide, or just switch my field and learn something new , or i'm just worried a lot , please let me know.", "author_fullname": "t2_dxqp82sj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm feeling uncertain about my freelancing field", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17c5srd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697788495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a top rated data analyst freelancer on upwork and i&amp;#39;m starting to feel uncertain about data analysis market.\nThe thing is i feel it has such a small market in comparison to other freelancing fields and most jobs are low rates with crazy requirements on each job , demanding you to know every technique and technology which is rediculous.  And you barely make it into good jobs that come once in 3 days &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m here seeking for opinion and  guidance from any fellow data analyst/scientist freelancers , should i stop using upwork and attempt to land clients worldwide, or just switch my field and learn something new , or i&amp;#39;m just worried a lot , please let me know.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17c5srd", "is_robot_indexable": true, "report_reasons": null, "author": "SantoryuuOgu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17c5srd/im_feeling_uncertain_about_my_freelancing_field/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17c5srd/im_feeling_uncertain_about_my_freelancing_field/", "subreddit_subscribers": 1091871, "created_utc": 1697788495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_3dyum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10 Trends of Business Intelligence to Facilitate Data Analytics and Decision Making", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": true, "name": "t3_17c5mjo", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/I3tK0poKOUvEDfeW35QRNETKGsMORUfdwonOQE7bcKM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697787737.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bigdataanalyticsnews.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://bigdataanalyticsnews.com/business-intelligence-trends-to-facilitate-data-analytics-decision-making/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?auto=webp&amp;s=b83541515bc8c127e291b451a190d76fbe86c878", "width": 1024, "height": 536}, "resolutions": [{"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b7b03a49512b697769a0b52ebdab52c40560082", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3f3be8c16d5d971bf2ac22d4c86f4f121a158676", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4bb4cb5f3dea2d7ba4b96f251bbc10d7c6cd942", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c8e84f93c9943ac1a5c173668a52c5fd7aabee3a", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a5d5b777a9089effa445ae26e3803a847cd5504c", "width": 960, "height": 502}], "variants": {}, "id": "gsMTE-5CAzFfCBXOV7R2jJw4mLTVMPNP7Cr5uXnjJ-8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "17c5mjo", "is_robot_indexable": true, "report_reasons": null, "author": "Veerans", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17c5mjo/10_trends_of_business_intelligence_to_facilitate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bigdataanalyticsnews.com/business-intelligence-trends-to-facilitate-data-analytics-decision-making/", "subreddit_subscribers": 1091871, "created_utc": 1697787737.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am not sure if this topic really fits Data Science. However.\n\nI am a DS and I have to create some kind of planning. I haven't had any contact with anything like that yet. If I understand correctly, then this is a kind of graph problem, consisting of nodes and edges, right?\n\nI would like to create a first very simple scheduling based on an available algorithm. It doesn't have to be super perfect. I do not want to make it too complex.\n\nMy data looks as follows:\n\n \n\n| Job | Machine | Duration | Position in this job | Priority |\n|-----|---------|----------|----------------------|----------|\n| A   | 1       | 11       | 1                    | 1        |\n| A   | 2       | 4        | 1                    | 1        |\n| A   | 3       | 6        | 2                    | 1        |\n| A   | 1       | 4        | 2                    | 1        |\n| A   | 2       | 9        | 3                    | 1        |\n| B   | 3       | 3        | 1                    | 2        |\n| B   | 1       | 2        | 2                    | 2        |\n| B   | 3       | 6        | 2                    | 2        |\n| C   | 2       | 5        | 1                    | 3        |\n| C   | 1       | 9        | 2                    | 3        |\n\n&amp;#x200B;\n\nChatGPT says this is a List Shop Schedule Problem and I could use for example the Branch-and-Bound-Algo. Is this correct or any other recommendations? Or Tools from Google? Sometimes there are tasks which are in parallel (same Position in this job). These tasks can be in parallel if possible, but it does not have to be strictly in parallel. When there is a small difference in the starting time, this is not a problem.", "author_fullname": "t2_jl102v3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "List Shop Scheduling Problem", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c4hdw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697783563.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697782828.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am not sure if this topic really fits Data Science. However.&lt;/p&gt;\n\n&lt;p&gt;I am a DS and I have to create some kind of planning. I haven&amp;#39;t had any contact with anything like that yet. If I understand correctly, then this is a kind of graph problem, consisting of nodes and edges, right?&lt;/p&gt;\n\n&lt;p&gt;I would like to create a first very simple scheduling based on an available algorithm. It doesn&amp;#39;t have to be super perfect. I do not want to make it too complex.&lt;/p&gt;\n\n&lt;p&gt;My data looks as follows:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th&gt;Job&lt;/th&gt;\n&lt;th&gt;Machine&lt;/th&gt;\n&lt;th&gt;Duration&lt;/th&gt;\n&lt;th&gt;Position in this job&lt;/th&gt;\n&lt;th&gt;Priority&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td&gt;A&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;11&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;A&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;A&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;6&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;A&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;4&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;A&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;B&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;B&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;B&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;td&gt;6&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;C&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;5&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td&gt;C&lt;/td&gt;\n&lt;td&gt;1&lt;/td&gt;\n&lt;td&gt;9&lt;/td&gt;\n&lt;td&gt;2&lt;/td&gt;\n&lt;td&gt;3&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;ChatGPT says this is a List Shop Schedule Problem and I could use for example the Branch-and-Bound-Algo. Is this correct or any other recommendations? Or Tools from Google? Sometimes there are tasks which are in parallel (same Position in this job). These tasks can be in parallel if possible, but it does not have to be strictly in parallel. When there is a small difference in the starting time, this is not a problem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17c4hdw", "is_robot_indexable": true, "report_reasons": null, "author": "Fluid-Improvement-84", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17c4hdw/list_shop_scheduling_problem/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17c4hdw/list_shop_scheduling_problem/", "subreddit_subscribers": 1091871, "created_utc": 1697782828.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anyone got some cool ideas for sharing large files? We use DataBricks but every now and then we need to share a big csv or pkl. I worked at a Computer Vision company previously and we had an onprem NAS - this won't suit my current job. I'm thinking S3, but wondering if anyone has a better idea. Haven't used Git LFS either so curious about this one too. Cheers", "author_fullname": "t2_xfx8ms4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sharing large files for collaboration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bxccu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697759392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone got some cool ideas for sharing large files? We use DataBricks but every now and then we need to share a big csv or pkl. I worked at a Computer Vision company previously and we had an onprem NAS - this won&amp;#39;t suit my current job. I&amp;#39;m thinking S3, but wondering if anyone has a better idea. Haven&amp;#39;t used Git LFS either so curious about this one too. Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17bxccu", "is_robot_indexable": true, "report_reasons": null, "author": "HStuart18", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17bxccu/sharing_large_files_for_collaboration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17bxccu/sharing_large_files_for_collaboration/", "subreddit_subscribers": 1091871, "created_utc": 1697759392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I have a very broad question about building a model using xgboost and feature selection. \n\nAs an example, let\u2019s say I have tabular dataset and build a binary classification model using xgboost to predict a purchase. I run the model with a 10 fold cv and get an auc score of x. I then remove some columns and rerun the model, everything else the same, and get an auc score &gt; x. \n\nIn this case, would the columns that were removed be random / wrong and is this common? I believe I can use a t-test to compare the scores and see if it\u2019s due to random chance. \n\nMy assumption was that xgboost would automatically find the best split in the data but wanted to know other peoples thoughts.", "author_fullname": "t2_hs2uczj7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Wrong data in dataset", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bobx9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697735878.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a very broad question about building a model using xgboost and feature selection. &lt;/p&gt;\n\n&lt;p&gt;As an example, let\u2019s say I have tabular dataset and build a binary classification model using xgboost to predict a purchase. I run the model with a 10 fold cv and get an auc score of x. I then remove some columns and rerun the model, everything else the same, and get an auc score &amp;gt; x. &lt;/p&gt;\n\n&lt;p&gt;In this case, would the columns that were removed be random / wrong and is this common? I believe I can use a t-test to compare the scores and see if it\u2019s due to random chance. &lt;/p&gt;\n\n&lt;p&gt;My assumption was that xgboost would automatically find the best split in the data but wanted to know other peoples thoughts.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17bobx9", "is_robot_indexable": true, "report_reasons": null, "author": "Kilroy_was_here__", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17bobx9/wrong_data_in_dataset/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17bobx9/wrong_data_in_dataset/", "subreddit_subscribers": 1091871, "created_utc": 1697735878.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi everyone!  \nIs it possible to create a market timing strategy using unsupervised learning? \n\nLet's find out.\n\nRelevant Topics:\n\n* Used S&amp;P500 data\n* Segmenting Time series using Online Change Detection Point\n* Clustering segments with KMeans\n* Risk Allocation\n* Value at Risk\n\nHere's the notebook:  \n[https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook](https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook)\n\nEvery and each comment / feedback is greatly appreciated!\n\nThank you!  \nM&amp;M", "author_fullname": "t2_81hr0pq4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Market Timing &amp; Risk Management - Portfolio allocation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bdzis", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697702807.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone!&lt;br/&gt;\nIs it possible to create a market timing strategy using unsupervised learning? &lt;/p&gt;\n\n&lt;p&gt;Let&amp;#39;s find out.&lt;/p&gt;\n\n&lt;p&gt;Relevant Topics:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Used S&amp;amp;P500 data&lt;/li&gt;\n&lt;li&gt;Segmenting Time series using Online Change Detection Point&lt;/li&gt;\n&lt;li&gt;Clustering segments with KMeans&lt;/li&gt;\n&lt;li&gt;Risk Allocation&lt;/li&gt;\n&lt;li&gt;Value at Risk&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Here&amp;#39;s the notebook:&lt;br/&gt;\n&lt;a href=\"https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook\"&gt;https://www.kaggle.com/code/mandmdatascience/mt-rm-portfolio-allocation/notebook&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Every and each comment / feedback is greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;Thank you!&lt;br/&gt;\nM&amp;amp;M&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/pGkUiqnzs5jbCTZHIr5iqbS-02twocrs_Rcv-L6QkD8.jpg?auto=webp&amp;s=22521ebf2516bed4d65862aff258ed16364f9bc0", "width": 100, "height": 100}, "resolutions": [], "variants": {}, "id": "1jf__EqbE3dYF9fUHKWvv0as9QmxITBOHBbPBchNPHQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17bdzis", "is_robot_indexable": true, "report_reasons": null, "author": "MandM-DataScience", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17bdzis/market_timing_risk_management_portfolio_allocation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17bdzis/market_timing_risk_management_portfolio_allocation/", "subreddit_subscribers": 1091871, "created_utc": 1697702807.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "In my about 5 years of experience working for a medium sized organization, I have seen a lot of value in building and maintaining CRUD or CRUD like apps that allows business users input, interact, and distribute data and models. Yet, I don't see much talk about this skill/use case of analytics. So curious to hear other's thoughts and experiences. Do you concur? Why or why not?\n\nPS: I understand it's probably not the case for big techs or companies with a very mature data science culture. But I would guess 90%+ orgs don't fall in this category. Pls feel free to bunk this too!", "author_fullname": "t2_9axqyq8u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you use CRUD or like apps to bridge the gap between business users and DS/DA teams?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c2u6b", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697782002.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697776462.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my about 5 years of experience working for a medium sized organization, I have seen a lot of value in building and maintaining CRUD or CRUD like apps that allows business users input, interact, and distribute data and models. Yet, I don&amp;#39;t see much talk about this skill/use case of analytics. So curious to hear other&amp;#39;s thoughts and experiences. Do you concur? Why or why not?&lt;/p&gt;\n\n&lt;p&gt;PS: I understand it&amp;#39;s probably not the case for big techs or companies with a very mature data science culture. But I would guess 90%+ orgs don&amp;#39;t fall in this category. Pls feel free to bunk this too!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17c2u6b", "is_robot_indexable": true, "report_reasons": null, "author": "Difficult-Big-3890", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17c2u6b/do_you_use_crud_or_like_apps_to_bridge_the_gap/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17c2u6b/do_you_use_crud_or_like_apps_to_bridge_the_gap/", "subreddit_subscribers": 1091871, "created_utc": 1697776462.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "&amp;#x200B;\n\n## Python\n\nUndoubtedly,\u00a0**the uncrowned king**\u00a0of machine learning and data analysis, the ubiquitous language that data scientists turn to for a bit of number crunching,\u00a0**is Python**. This is down to several reasons; the three most important among them are its\u00a0**maturity**, the enormous\u00a0**community**, and, last but not least, a\u00a0**vast array of robust third-party libraries**. But even if Python is a magnanimous sovereign that many developers love, it doesn\u2019t mean that there can\u2019t be contenders occasionally.\n\n## Julia\n\nFourteen years ago, in a bold attempt to combine all the good properties of well-established programming languages while getting rid of the less favorable ones, four developers came up with the idea of a new programming language that has a\u00a0**friendly syntax**, offers\u00a0**efficient mathematical computations**\u00a0out of the box, at a\u00a0**performance on par with compiled languages**. And thus,\u00a0[**Julia**](https://julialang.org/)\u00a0was born (here\u2019s a manifesto explaining\u00a0[**why**](https://julialang.org/blog/2012/02/why-we-created-julia/)\u00a0in more detail). Its first version was launched a bit more than eleven years ago.\n\n## Our choice\n\nMany in-depth comparisons of Python and Julia on the web (such as\u00a0[**this one**](https://richardpelgrim.medium.com/julia-vs-python-for-data-science-in-2022-1f5f6f38f3ac)\u00a0or\u00a0[**this**](https://www.turing.com/kb/julia-vs-python)) cover both the objective and subjective benefits and drawbacks of choosing one over the other. And given Julia\u2019s growing popularity, we are sure more will follow. In the rest of this blog post, however, let\u2019s explore why we picked Julia for our purposes. And that\u2019s not to say that we don\u2019t use Python for data science. On the contrary, we\u00a0**often run analyses in both ecosystems simultaneously**\u00a0to help each other out where one is lacking or to reduce the chances of mistakes by comparing their results.\n\n## The advantages of Julia\n\nSo what makes Julia so compelling to us?\n\n## Language features\n\nJulia has:\n\n* a friendly, easy-to-read (and write) syntax;\n* \u00a0a flexible and expressive (part static, part dynamic) type system;\n* \u00a0powerful mathematical notations, such as built-in vector and matrix operations;\n* \u00a0efficient\u00a0[**multiple dispatches**](https://en.wikipedia.org/wiki/Multiple_dispatch), a form of function polymorphism working with runtime types;\n* \u00a0convenient and reliable parallel computing facilities;\n* \u00a0meta-programming with macros and generated functions.\n\n## Fast code execution\n\nJulia compiles the source code to\u00a0**native binary at runtime**\u00a0via LLVM. This approach combines the flexibility of interpreters, such as Python, with the performance of compiled languages, like C++ or Rust. The drawback is that code loading and the first run takes longer;\u00a0**the benefits start to shine when a piece of code is run multiple times**. This unique feature makes it an excellent tool for number crunching but less than ideal for scripting.\n\n## Built-in package management\n\nJulia has a pretty good (albeit not perfect) built-in package management tool, implemented as a base library; and a general registry of open-source packages. The offering of\u00a0**stable and well-designed packages**\u00a0is growing steadily along with the Julia community, especially in data science. Unit testing utilities are also part of the standard library.\n\n## Interactive tools\n\nJulia offers an\u00a0**advanced**\u00a0[**REPL**](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop)\u00a0with all the goodies of an interpreted language environment. These include:\n\n* code and variable inspection,\n* \u00a0code completion,\n* \u00a0an interactive debugger,\n* \u00a0benchmarking and profiling tools,\n* \u00a0and a built-in help system.\n\n**With third-party libraries, it can also be extended**\u00a0with\u00a0[**syntax highlighting**](https://github.com/KristofferC/OhMyREPL.jl),\u00a0[**source code lookup**](https://github.com/tkf/InteractiveCodeSearch.jl)\u00a0(even for base libraries), automatic\u00a0[**code reload**](https://timholy.github.io/Revise.jl/stable/), and many more exciting, modern features.\n\nAll these together make Julia an\u00a0**ideal environment for rapid prototyping**.\n\n## From prototyping to production code\n\nBecause of the high-level interactive tools and fast code execution,\u00a0**the transition from a rapid prototype to production-ready code can be as continuous as you\u2019d like**. More often than not, we find that most of the code that implements our business logic in the research code can also be used in the final product.\n\nThanks to its friendly syntax and built-in package management,\u00a0**the road to maintainable code is well paved**. Nothing replaces good API design, coding discipline, and rigorous testing, but Julia helps you to focus on these topics.\n\nAs a consequence, a computation pieced together in the REPL can easily become a piece of prototyping code in a POC module; then later, after some refactoring and unit testing, turn into a chunk of core code in an internal library, and finally, following more cleanup, find itself in a production package.\n\n## The disadvantages of Julia\n\nThat said, every benefit comes at a cost, and Julia is not free from issues. Here are a few stumbling blocks worthy of mentioning:\n\n* the very powerful tool of broadcasting and vectorization can be intimidating at first;\n* [**time to first plot**](https://discourse.julialang.org/t/time-to-first-plot-clarification/58534)\u00a0can be surprising, sometimes inconveniently long, although considerable effort has been put into making it shorter;\n* \u00a0many packages never reach a stable state or just become unmaintained; others are poorly designed or written;\n* [**releasing a binary package**](https://github.com/JuliaLang/PackageCompiler.jl)\u00a0can be challenging, and compilation time can be unexpectedly long, not to mention obfuscation, which can also be tricky.\n\n## Summary\n\nIn conclusion, the choice between programming languages for data analysis is not always clear-cut. While Python has been the go-to language for many data scientists, Julia is rapidly gaining popularity for its unique set of features that make it an attractive option. In this blog post, we explored why we chose Julia over Python for our purposes, highlighting its language features, fast code execution, built-in package management, interactive tools, and ease of transitioning from prototyping to production code. However, we also acknowledged that Julia has challenges, including overcoming some learning curves and the occasional instability of packages. Ultimately, the choice between Julia and Python (or any other programming language) will depend on specific project requirements, personal preferences, and available resources.\n\nStill, in the past years,\u00a0**Julia has proved to be our reliable and faithful companion**. It has evolved, matured, and improved significantly, and we would be less happy and less successful without it. So cheers, Julia; we are excited to see what your future brings!", "author_fullname": "t2_gbypvyyx9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Programming language for machine learning and data analysis \u2013 Our choice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bf3cx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697707699.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;h2&gt;Python&lt;/h2&gt;\n\n&lt;p&gt;Undoubtedly,\u00a0&lt;strong&gt;the uncrowned king&lt;/strong&gt;\u00a0of machine learning and data analysis, the ubiquitous language that data scientists turn to for a bit of number crunching,\u00a0&lt;strong&gt;is Python&lt;/strong&gt;. This is down to several reasons; the three most important among them are its\u00a0&lt;strong&gt;maturity&lt;/strong&gt;, the enormous\u00a0&lt;strong&gt;community&lt;/strong&gt;, and, last but not least, a\u00a0&lt;strong&gt;vast array of robust third-party libraries&lt;/strong&gt;. But even if Python is a magnanimous sovereign that many developers love, it doesn\u2019t mean that there can\u2019t be contenders occasionally.&lt;/p&gt;\n\n&lt;h2&gt;Julia&lt;/h2&gt;\n\n&lt;p&gt;Fourteen years ago, in a bold attempt to combine all the good properties of well-established programming languages while getting rid of the less favorable ones, four developers came up with the idea of a new programming language that has a\u00a0&lt;strong&gt;friendly syntax&lt;/strong&gt;, offers\u00a0&lt;strong&gt;efficient mathematical computations&lt;/strong&gt;\u00a0out of the box, at a\u00a0&lt;strong&gt;performance on par with compiled languages&lt;/strong&gt;. And thus,\u00a0&lt;a href=\"https://julialang.org/\"&gt;&lt;strong&gt;Julia&lt;/strong&gt;&lt;/a&gt;\u00a0was born (here\u2019s a manifesto explaining\u00a0&lt;a href=\"https://julialang.org/blog/2012/02/why-we-created-julia/\"&gt;&lt;strong&gt;why&lt;/strong&gt;&lt;/a&gt;\u00a0in more detail). Its first version was launched a bit more than eleven years ago.&lt;/p&gt;\n\n&lt;h2&gt;Our choice&lt;/h2&gt;\n\n&lt;p&gt;Many in-depth comparisons of Python and Julia on the web (such as\u00a0&lt;a href=\"https://richardpelgrim.medium.com/julia-vs-python-for-data-science-in-2022-1f5f6f38f3ac\"&gt;&lt;strong&gt;this one&lt;/strong&gt;&lt;/a&gt;\u00a0or\u00a0&lt;a href=\"https://www.turing.com/kb/julia-vs-python\"&gt;&lt;strong&gt;this&lt;/strong&gt;&lt;/a&gt;) cover both the objective and subjective benefits and drawbacks of choosing one over the other. And given Julia\u2019s growing popularity, we are sure more will follow. In the rest of this blog post, however, let\u2019s explore why we picked Julia for our purposes. And that\u2019s not to say that we don\u2019t use Python for data science. On the contrary, we\u00a0&lt;strong&gt;often run analyses in both ecosystems simultaneously&lt;/strong&gt;\u00a0to help each other out where one is lacking or to reduce the chances of mistakes by comparing their results.&lt;/p&gt;\n\n&lt;h2&gt;The advantages of Julia&lt;/h2&gt;\n\n&lt;p&gt;So what makes Julia so compelling to us?&lt;/p&gt;\n\n&lt;h2&gt;Language features&lt;/h2&gt;\n\n&lt;p&gt;Julia has:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;a friendly, easy-to-read (and write) syntax;&lt;/li&gt;\n&lt;li&gt;\u00a0a flexible and expressive (part static, part dynamic) type system;&lt;/li&gt;\n&lt;li&gt;\u00a0powerful mathematical notations, such as built-in vector and matrix operations;&lt;/li&gt;\n&lt;li&gt;\u00a0efficient\u00a0&lt;a href=\"https://en.wikipedia.org/wiki/Multiple_dispatch\"&gt;&lt;strong&gt;multiple dispatches&lt;/strong&gt;&lt;/a&gt;, a form of function polymorphism working with runtime types;&lt;/li&gt;\n&lt;li&gt;\u00a0convenient and reliable parallel computing facilities;&lt;/li&gt;\n&lt;li&gt;\u00a0meta-programming with macros and generated functions.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Fast code execution&lt;/h2&gt;\n\n&lt;p&gt;Julia compiles the source code to\u00a0&lt;strong&gt;native binary at runtime&lt;/strong&gt;\u00a0via LLVM. This approach combines the flexibility of interpreters, such as Python, with the performance of compiled languages, like C++ or Rust. The drawback is that code loading and the first run takes longer;\u00a0&lt;strong&gt;the benefits start to shine when a piece of code is run multiple times&lt;/strong&gt;. This unique feature makes it an excellent tool for number crunching but less than ideal for scripting.&lt;/p&gt;\n\n&lt;h2&gt;Built-in package management&lt;/h2&gt;\n\n&lt;p&gt;Julia has a pretty good (albeit not perfect) built-in package management tool, implemented as a base library; and a general registry of open-source packages. The offering of\u00a0&lt;strong&gt;stable and well-designed packages&lt;/strong&gt;\u00a0is growing steadily along with the Julia community, especially in data science. Unit testing utilities are also part of the standard library.&lt;/p&gt;\n\n&lt;h2&gt;Interactive tools&lt;/h2&gt;\n\n&lt;p&gt;Julia offers an\u00a0&lt;strong&gt;advanced&lt;/strong&gt;\u00a0&lt;a href=\"https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop\"&gt;&lt;strong&gt;REPL&lt;/strong&gt;&lt;/a&gt;\u00a0with all the goodies of an interpreted language environment. These include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;code and variable inspection,&lt;/li&gt;\n&lt;li&gt;\u00a0code completion,&lt;/li&gt;\n&lt;li&gt;\u00a0an interactive debugger,&lt;/li&gt;\n&lt;li&gt;\u00a0benchmarking and profiling tools,&lt;/li&gt;\n&lt;li&gt;\u00a0and a built-in help system.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;With third-party libraries, it can also be extended&lt;/strong&gt;\u00a0with\u00a0&lt;a href=\"https://github.com/KristofferC/OhMyREPL.jl\"&gt;&lt;strong&gt;syntax highlighting&lt;/strong&gt;&lt;/a&gt;,\u00a0&lt;a href=\"https://github.com/tkf/InteractiveCodeSearch.jl\"&gt;&lt;strong&gt;source code lookup&lt;/strong&gt;&lt;/a&gt;\u00a0(even for base libraries), automatic\u00a0&lt;a href=\"https://timholy.github.io/Revise.jl/stable/\"&gt;&lt;strong&gt;code reload&lt;/strong&gt;&lt;/a&gt;, and many more exciting, modern features.&lt;/p&gt;\n\n&lt;p&gt;All these together make Julia an\u00a0&lt;strong&gt;ideal environment for rapid prototyping&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;h2&gt;From prototyping to production code&lt;/h2&gt;\n\n&lt;p&gt;Because of the high-level interactive tools and fast code execution,\u00a0&lt;strong&gt;the transition from a rapid prototype to production-ready code can be as continuous as you\u2019d like&lt;/strong&gt;. More often than not, we find that most of the code that implements our business logic in the research code can also be used in the final product.&lt;/p&gt;\n\n&lt;p&gt;Thanks to its friendly syntax and built-in package management,\u00a0&lt;strong&gt;the road to maintainable code is well paved&lt;/strong&gt;. Nothing replaces good API design, coding discipline, and rigorous testing, but Julia helps you to focus on these topics.&lt;/p&gt;\n\n&lt;p&gt;As a consequence, a computation pieced together in the REPL can easily become a piece of prototyping code in a POC module; then later, after some refactoring and unit testing, turn into a chunk of core code in an internal library, and finally, following more cleanup, find itself in a production package.&lt;/p&gt;\n\n&lt;h2&gt;The disadvantages of Julia&lt;/h2&gt;\n\n&lt;p&gt;That said, every benefit comes at a cost, and Julia is not free from issues. Here are a few stumbling blocks worthy of mentioning:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;the very powerful tool of broadcasting and vectorization can be intimidating at first;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://discourse.julialang.org/t/time-to-first-plot-clarification/58534\"&gt;&lt;strong&gt;time to first plot&lt;/strong&gt;&lt;/a&gt;\u00a0can be surprising, sometimes inconveniently long, although considerable effort has been put into making it shorter;&lt;/li&gt;\n&lt;li&gt;\u00a0many packages never reach a stable state or just become unmaintained; others are poorly designed or written;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://github.com/JuliaLang/PackageCompiler.jl\"&gt;&lt;strong&gt;releasing a binary package&lt;/strong&gt;&lt;/a&gt;\u00a0can be challenging, and compilation time can be unexpectedly long, not to mention obfuscation, which can also be tricky.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h2&gt;Summary&lt;/h2&gt;\n\n&lt;p&gt;In conclusion, the choice between programming languages for data analysis is not always clear-cut. While Python has been the go-to language for many data scientists, Julia is rapidly gaining popularity for its unique set of features that make it an attractive option. In this blog post, we explored why we chose Julia over Python for our purposes, highlighting its language features, fast code execution, built-in package management, interactive tools, and ease of transitioning from prototyping to production code. However, we also acknowledged that Julia has challenges, including overcoming some learning curves and the occasional instability of packages. Ultimately, the choice between Julia and Python (or any other programming language) will depend on specific project requirements, personal preferences, and available resources.&lt;/p&gt;\n\n&lt;p&gt;Still, in the past years,\u00a0&lt;strong&gt;Julia has proved to be our reliable and faithful companion&lt;/strong&gt;. It has evolved, matured, and improved significantly, and we would be less happy and less successful without it. So cheers, Julia; we are excited to see what your future brings!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17bf3cx", "is_robot_indexable": true, "report_reasons": null, "author": "CursorInsight", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17bf3cx/programming_language_for_machine_learning_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17bf3cx/programming_language_for_machine_learning_and/", "subreddit_subscribers": 1091871, "created_utc": 1697707699.0, "num_crossposts": 1, "media": null, "is_video": false}}], "before": null}}