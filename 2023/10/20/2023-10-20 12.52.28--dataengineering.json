{"kind": "Listing", "data": {"after": null, "dist": 19, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am an experienced ETL developer with over 10 years and I am skilled in using tools like SSIS, Informatica and Python for ETL development.\n\nI am currently trying to Advance my career in the field and I was wondering which path to take. My major consideration is one that will still be in-demand for the 10 years or more and also one that has good pay grade as well as WFH opportunities.\n\nI am considering going into full blown career in data engineering (pipeline design, a good programming and server experience as well as  Containerization. **OR** one that focuses more on BIG DATA development.\n\nI know big data has been the buzz word since some years now but I am a bit concerned that its gradually not as loud as it used to be.\n\nI will appreciate your advise so much.", "author_fullname": "t2_dcnhwe2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A career in Data Engineering or Big Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17blv3d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697729350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am an experienced ETL developer with over 10 years and I am skilled in using tools like SSIS, Informatica and Python for ETL development.&lt;/p&gt;\n\n&lt;p&gt;I am currently trying to Advance my career in the field and I was wondering which path to take. My major consideration is one that will still be in-demand for the 10 years or more and also one that has good pay grade as well as WFH opportunities.&lt;/p&gt;\n\n&lt;p&gt;I am considering going into full blown career in data engineering (pipeline design, a good programming and server experience as well as  Containerization. &lt;strong&gt;OR&lt;/strong&gt; one that focuses more on BIG DATA development.&lt;/p&gt;\n\n&lt;p&gt;I know big data has been the buzz word since some years now but I am a bit concerned that its gradually not as loud as it used to be.&lt;/p&gt;\n\n&lt;p&gt;I will appreciate your advise so much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17blv3d", "is_robot_indexable": true, "report_reasons": null, "author": "MediumCat4064", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17blv3d/a_career_in_data_engineering_or_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17blv3d/a_career_in_data_engineering_or_big_data/", "subreddit_subscribers": 134980, "created_utc": 1697729350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3yozg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The biggest new dbt Cloud features from Coalesce 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17bsage", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Pt2ZfLn9svd8KwEp2PFvdSkL16Ws3FifX7uUkLCUc9o.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697746098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "getdbt.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.getdbt.com/blog/new-dbt-cloud-features-announced-at-coalesce-2023", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?auto=webp&amp;s=6347fcb3daf9a842bf820f8ccec577c12487f347", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=77d0d353f5c6d77bfa60e43bbececf4b270a794e", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=391a03e2803f86acb44234cf70a6db41d9a7fc63", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=991dad38adac8bb4c5ed0ffbc180ead7be80e687", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a5e9f4869a32ac351f89fc52effc05e53b3e0188", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f864e440c37ff7a996711d0a0e09e386defe2bf6", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/nT3InHJvC8X2psQSmTIchUUyztBUfSYy0lynLmMS0b8.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=28f27d147ddf282fc9123b71c3e113168a518fcd", "width": 1080, "height": 607}], "variants": {}, "id": "jPyehZjVjFnnPXeUvtW24q2zxUIQShEm8Z8ELBIJQyw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17bsage", "is_robot_indexable": true, "report_reasons": null, "author": "gman1023", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bsage/the_biggest_new_dbt_cloud_features_from_coalesce/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.getdbt.com/blog/new-dbt-cloud-features-announced-at-coalesce-2023", "subreddit_subscribers": 134980, "created_utc": 1697746098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At the moment, when we \"run\" a dbt project, we are more or less running every model in the project. Our largest project has ~450 models and takes under an hour to complete. We have a cron schedule that invokes the run and a step function that defines the flow between states (projects and their various dbt operations).\n\nDo folks who use airflow run smaller batches at a time? This seems hard to manage, also seems like you would end up duplicating steps as you build a shared dependency multiple times.", "author_fullname": "t2_6nf2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How exactly are you using airflow with dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bmbov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697730598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At the moment, when we &amp;quot;run&amp;quot; a dbt project, we are more or less running every model in the project. Our largest project has ~450 models and takes under an hour to complete. We have a cron schedule that invokes the run and a step function that defines the flow between states (projects and their various dbt operations).&lt;/p&gt;\n\n&lt;p&gt;Do folks who use airflow run smaller batches at a time? This seems hard to manage, also seems like you would end up duplicating steps as you build a shared dependency multiple times.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17bmbov", "is_robot_indexable": true, "report_reasons": null, "author": "radil", "discussion_type": null, "num_comments": 24, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bmbov/how_exactly_are_you_using_airflow_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bmbov/how_exactly_are_you_using_airflow_with_dbt/", "subreddit_subscribers": 134980, "created_utc": 1697730598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Wtf is data engineering\n\n\n\n\n\n\n\n\n\n\n\n^(this is a joke based on how every time I tell someone they ask me what data engineering is)", "author_fullname": "t2_4qppib05", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I just accepted a data engineering internship", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c3u78", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.68, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meme", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697782604.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697780241.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Wtf is data engineering&lt;/p&gt;\n\n&lt;p&gt;&lt;sup&gt;this is a joke based on how every time I tell someone they ask me what data engineering is&lt;/sup&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff66ac", "id": "17c3u78", "is_robot_indexable": true, "report_reasons": null, "author": "silvermoon_182", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c3u78/i_just_accepted_a_data_engineering_internship/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17c3u78/i_just_accepted_a_data_engineering_internship/", "subreddit_subscribers": 134980, "created_utc": 1697780241.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, wanted to get some input here\n\nWhat do you all do for database documentation / data catalog? Particularly for smaller organizations that might not have the budget to hop on calls with Atlan / Collibra / Alation and the other big enterprise Data Catalogs?\n\nFull disclosure: I'm [building a tool](https://datadocs.ai) in that area - something that's not about governance / enterprise integrations, but just about cataloging/search and documenting the db using AI.\n\nSo, I'm asking because I want to better understand how this problem is being solved by (small-medium) teams right now. I know that at my day job, we hopped on a call with the enterprise folks and got some pretty Enterprise price tags. We ended up kind of gluing something together ourselves, but it required a ton of continual manual work and is now dusty and out-of-date...", "author_fullname": "t2_npbdk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Database Documentation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c7gp0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697795510.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, wanted to get some input here&lt;/p&gt;\n\n&lt;p&gt;What do you all do for database documentation / data catalog? Particularly for smaller organizations that might not have the budget to hop on calls with Atlan / Collibra / Alation and the other big enterprise Data Catalogs?&lt;/p&gt;\n\n&lt;p&gt;Full disclosure: I&amp;#39;m &lt;a href=\"https://datadocs.ai\"&gt;building a tool&lt;/a&gt; in that area - something that&amp;#39;s not about governance / enterprise integrations, but just about cataloging/search and documenting the db using AI.&lt;/p&gt;\n\n&lt;p&gt;So, I&amp;#39;m asking because I want to better understand how this problem is being solved by (small-medium) teams right now. I know that at my day job, we hopped on a call with the enterprise folks and got some pretty Enterprise price tags. We ended up kind of gluing something together ourselves, but it required a ton of continual manual work and is now dusty and out-of-date...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17c7gp0", "is_robot_indexable": true, "report_reasons": null, "author": "various1121", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c7gp0/database_documentation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17c7gp0/database_documentation/", "subreddit_subscribers": 134980, "created_utc": 1697795510.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am facing a problem when importing DAGs into Apache Airflow using a script, as I am not able to see the DAG code in the Airflow UI. It only displays the code used for importation. Here's the code I'm using:\n\n    import os\n    from airflow.models import DagBag\n    import sys\n    \n    dags_dirs = [\n        '/opt/airflow/projetos/basevinculos_py',\n        '/opt/airflow/projetos/pdi_consulta'\n    ]\n    \n    for dir in dags_dirs:\n        sys.path.append(os.path.expanduser(dir))\n    \n    for dir in dags_dirs:\n        dag_bag = DagBag(os.path.expanduser(dir))\n    \n        if dag_bag:\n            for dag_id, dag in dag_bag.dags.items():\n                globals()[dag_id] = dag\n\nI have verified that the DAGs are successfully imported into Airflow, but the Airflow UI does not display the code for the imported DAGs. I've ensured that the DAG definition files are correctly formatted and contain the necessary DAG structure. I'm using Apache Airflow 2.7.2\n\n&amp;#x200B;\n\nhttps://preview.redd.it/qg9bjqmxibvb1.png?width=1540&amp;format=png&amp;auto=webp&amp;s=be675983a60a09b029110ead2aa3c16823203ccf\n\nThe Graph tab shows correctly the tasks flow correctly, but unfortunately in the code tab shows me only the code that I am using to deal with the DagBag.", "author_fullname": "t2_651eszek", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Issue with Importing and Displaying DAG Code in Apache Airflow UI when use a subproject", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 83, "top_awarded_type": null, "hide_score": false, "media_metadata": {"qg9bjqmxibvb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 64, "x": 108, "u": "https://preview.redd.it/qg9bjqmxibvb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=502769a425287e022ce6a7d36eabafb40324dd81"}, {"y": 128, "x": 216, "u": "https://preview.redd.it/qg9bjqmxibvb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=94bbe7cee50ce38775c7c6dec19074afb07637c0"}, {"y": 189, "x": 320, "u": "https://preview.redd.it/qg9bjqmxibvb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ef296beddd97f892434a762e3141c542b3d26da"}, {"y": 379, "x": 640, "u": "https://preview.redd.it/qg9bjqmxibvb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fef987f4908027b959a5278ff6cb096b088b54ac"}, {"y": 569, "x": 960, "u": "https://preview.redd.it/qg9bjqmxibvb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=fa2e0b7f93fd840ab8204fb7259833c7415d3452"}, {"y": 640, "x": 1080, "u": "https://preview.redd.it/qg9bjqmxibvb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0b4b7637219bdfde8556432d233fa83c0171bff1"}], "s": {"y": 914, "x": 1540, "u": "https://preview.redd.it/qg9bjqmxibvb1.png?width=1540&amp;format=png&amp;auto=webp&amp;s=be675983a60a09b029110ead2aa3c16823203ccf"}, "id": "qg9bjqmxibvb1"}}, "name": "t3_17c6a7g", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3VYJOIJQ6gophjgUokvbBCIu3ocLkUXohHz-aKVtIQc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697790543.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am facing a problem when importing DAGs into Apache Airflow using a script, as I am not able to see the DAG code in the Airflow UI. It only displays the code used for importation. Here&amp;#39;s the code I&amp;#39;m using:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import os\nfrom airflow.models import DagBag\nimport sys\n\ndags_dirs = [\n    &amp;#39;/opt/airflow/projetos/basevinculos_py&amp;#39;,\n    &amp;#39;/opt/airflow/projetos/pdi_consulta&amp;#39;\n]\n\nfor dir in dags_dirs:\n    sys.path.append(os.path.expanduser(dir))\n\nfor dir in dags_dirs:\n    dag_bag = DagBag(os.path.expanduser(dir))\n\n    if dag_bag:\n        for dag_id, dag in dag_bag.dags.items():\n            globals()[dag_id] = dag\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I have verified that the DAGs are successfully imported into Airflow, but the Airflow UI does not display the code for the imported DAGs. I&amp;#39;ve ensured that the DAG definition files are correctly formatted and contain the necessary DAG structure. I&amp;#39;m using Apache Airflow 2.7.2&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/qg9bjqmxibvb1.png?width=1540&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=be675983a60a09b029110ead2aa3c16823203ccf\"&gt;https://preview.redd.it/qg9bjqmxibvb1.png?width=1540&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=be675983a60a09b029110ead2aa3c16823203ccf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The Graph tab shows correctly the tasks flow correctly, but unfortunately in the code tab shows me only the code that I am using to deal with the DagBag.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17c6a7g", "is_robot_indexable": true, "report_reasons": null, "author": "brunojustino", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c6a7g/issue_with_importing_and_displaying_dag_code_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17c6a7g/issue_with_importing_and_displaying_dag_code_in/", "subreddit_subscribers": 134980, "created_utc": 1697790543.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For now it is driftdb. But I'm thinking bi-temporaldb, but it is too long.\n\nThe goal is to store some metrics, and understand what happened between 2 \"measurements\". and in the end have something like that [workinprogress](https://app.data-drift.io/41231518/Samox/dbt-example/overview?snapshotDate=2023-10-18&amp;commitSha=37467fb6ce76d26fad8b09d7582ed3f6ad5d61e3)\n\n&amp;#x200B;\n\nTo try on your computer (I have tested on mac only):\n\n`pip install driftdb`\n\n`driftdb seed create`\n\n`driftdb seed update`\n\n`driftdb start`\n\nAnd if you want to see more variations, do more \"driftdb seed update\"\n\nWould love to get feedback or suggestions!\n\n&amp;#x200B;\n\n[https://pypi.org/project/driftdb/0.0.1a8/](https://pypi.org/project/driftdb/0.0.1a8/)\n\n&amp;#x200B;", "author_fullname": "t2_10uv2n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone wants to try my database ? Also I need a name \ud83e\udd17", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c7fqt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697804076.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697795402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For now it is driftdb. But I&amp;#39;m thinking bi-temporaldb, but it is too long.&lt;/p&gt;\n\n&lt;p&gt;The goal is to store some metrics, and understand what happened between 2 &amp;quot;measurements&amp;quot;. and in the end have something like that &lt;a href=\"https://app.data-drift.io/41231518/Samox/dbt-example/overview?snapshotDate=2023-10-18&amp;amp;commitSha=37467fb6ce76d26fad8b09d7582ed3f6ad5d61e3\"&gt;workinprogress&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;To try on your computer (I have tested on mac only):&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;pip install driftdb&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;driftdb seed create&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;driftdb seed update&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;code&gt;driftdb start&lt;/code&gt;&lt;/p&gt;\n\n&lt;p&gt;And if you want to see more variations, do more &amp;quot;driftdb seed update&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Would love to get feedback or suggestions!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://pypi.org/project/driftdb/0.0.1a8/\"&gt;https://pypi.org/project/driftdb/0.0.1a8/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17c7fqt", "is_robot_indexable": true, "report_reasons": null, "author": "Srammmy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c7fqt/anyone_wants_to_try_my_database_also_i_need_a_name/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17c7fqt/anyone_wants_to_try_my_database_also_i_need_a_name/", "subreddit_subscribers": 134980, "created_utc": 1697795402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working in a project where the company is working with Siebel CRM and has the backend database Oracle db.  They have some process to mass update but it's really kind of complicated, they're preparing csv file which needs to be placed in a particular for the night job to run.  \n\n\nI have the need to move Siebel objects from one account to another and there isn't any template prepared for re-linking certain CRM objects like Activities, Opportunities or Contacts.  \n\n\nMy question, since Siebel is so old and lacks any kind of Data Loader and ease of use, wouldn't it be better to directly do it in the database? \n\nOr even a better option, to have some integration tool such as Jitterbit or Boomi (I only know these two tools for now).\n\nWhich would solve the most basic CRUD needs an enterprise ERP?\n\nThoughts?", "author_fullname": "t2_9sk2qr0q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Integration or Middleware for CRM Application mass changes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c745l", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697794041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working in a project where the company is working with Siebel CRM and has the backend database Oracle db.  They have some process to mass update but it&amp;#39;s really kind of complicated, they&amp;#39;re preparing csv file which needs to be placed in a particular for the night job to run.  &lt;/p&gt;\n\n&lt;p&gt;I have the need to move Siebel objects from one account to another and there isn&amp;#39;t any template prepared for re-linking certain CRM objects like Activities, Opportunities or Contacts.  &lt;/p&gt;\n\n&lt;p&gt;My question, since Siebel is so old and lacks any kind of Data Loader and ease of use, wouldn&amp;#39;t it be better to directly do it in the database? &lt;/p&gt;\n\n&lt;p&gt;Or even a better option, to have some integration tool such as Jitterbit or Boomi (I only know these two tools for now).&lt;/p&gt;\n\n&lt;p&gt;Which would solve the most basic CRUD needs an enterprise ERP?&lt;/p&gt;\n\n&lt;p&gt;Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17c745l", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious_Flow_465", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c745l/data_integration_or_middleware_for_crm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17c745l/data_integration_or_middleware_for_crm/", "subreddit_subscribers": 134980, "created_utc": 1697794041.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I mount the volumes from a CSI (Rook with Ceph). InitContainers with permissions for the volumes for both Zeppelin and Spark.\n\nIf I also deploy a second Spark (spark2 from now) and submit an app from spark2 using spark1 cluster i can write on the volume. Do the same in Zeppelin and get permissions denied. \n\nI know for a fact that it is because of the user.  But cannot figure out why it works for an app with same permissions that the other has but is not working for the other. \n\nWilling to share conf files if needed. \n\nThanks a lot \ud83d\ude4f\ud83c\udffc", "author_fullname": "t2_d0ifg2cb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Does anyone know about Zeppelin and Spark with Kubernetes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17btopz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697749666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I mount the volumes from a CSI (Rook with Ceph). InitContainers with permissions for the volumes for both Zeppelin and Spark.&lt;/p&gt;\n\n&lt;p&gt;If I also deploy a second Spark (spark2 from now) and submit an app from spark2 using spark1 cluster i can write on the volume. Do the same in Zeppelin and get permissions denied. &lt;/p&gt;\n\n&lt;p&gt;I know for a fact that it is because of the user.  But cannot figure out why it works for an app with same permissions that the other has but is not working for the other. &lt;/p&gt;\n\n&lt;p&gt;Willing to share conf files if needed. &lt;/p&gt;\n\n&lt;p&gt;Thanks a lot \ud83d\ude4f\ud83c\udffc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17btopz", "is_robot_indexable": true, "report_reasons": null, "author": "Awkward-Cupcake6219", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17btopz/does_anyone_know_about_zeppelin_and_spark_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17btopz/does_anyone_know_about_zeppelin_and_spark_with/", "subreddit_subscribers": 134980, "created_utc": 1697749666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, someone of you know how to do that?\nI'm looking in internet about bulk copy but if i have a dagster/mage orchestration how can i do that?", "author_fullname": "t2_bvpnqeta", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can copy data bethween csv in S3/GCS to SQL server DB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bnfsc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697733545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, someone of you know how to do that?\nI&amp;#39;m looking in internet about bulk copy but if i have a dagster/mage orchestration how can i do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17bnfsc", "is_robot_indexable": true, "report_reasons": null, "author": "aaaasd12", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bnfsc/how_can_copy_data_bethween_csv_in_s3gcs_to_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bnfsc/how_can_copy_data_bethween_csv_in_s3gcs_to_sql/", "subreddit_subscribers": 134980, "created_utc": 1697733545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3dyum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "10 Trends of Business Intelligence to Facilitate Data Analytics and Decision Making", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_17c5nua", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/I3tK0poKOUvEDfeW35QRNETKGsMORUfdwonOQE7bcKM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697787905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bigdataanalyticsnews.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bigdataanalyticsnews.com/business-intelligence-trends-to-facilitate-data-analytics-decision-making/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?auto=webp&amp;s=b83541515bc8c127e291b451a190d76fbe86c878", "width": 1024, "height": 536}, "resolutions": [{"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4b7b03a49512b697769a0b52ebdab52c40560082", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=3f3be8c16d5d971bf2ac22d4c86f4f121a158676", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4bb4cb5f3dea2d7ba4b96f251bbc10d7c6cd942", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c8e84f93c9943ac1a5c173668a52c5fd7aabee3a", "width": 640, "height": 335}, {"url": "https://external-preview.redd.it/XieP3qOosskUvG8SRXmYyYvuVAM9hqFpK2dqVAkXQ4o.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=a5d5b777a9089effa445ae26e3803a847cd5504c", "width": 960, "height": 502}], "variants": {}, "id": "gsMTE-5CAzFfCBXOV7R2jJw4mLTVMPNP7Cr5uXnjJ-8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17c5nua", "is_robot_indexable": true, "report_reasons": null, "author": "Veerans", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c5nua/10_trends_of_business_intelligence_to_facilitate/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bigdataanalyticsnews.com/business-intelligence-trends-to-facilitate-data-analytics-decision-making/", "subreddit_subscribers": 134980, "created_utc": 1697787905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There is a task in hand to automate the migration of 1000 jobs to Adf. My approach to problem statement is \n\n1) identify the rest apis that provide the job details\n2) Have custom mapping for informatica to add functions\n3) Have custom scripts generating the pseudo code as the conversation might not be straight forward\n4) Deploy in the ARM template or any iaac code\n\nThoughts ? Can we brainstorm ?", "author_fullname": "t2_qinvsb2g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automate informatica job migration to Adf", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c2lwh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697775617.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is a task in hand to automate the migration of 1000 jobs to Adf. My approach to problem statement is &lt;/p&gt;\n\n&lt;p&gt;1) identify the rest apis that provide the job details\n2) Have custom mapping for informatica to add functions\n3) Have custom scripts generating the pseudo code as the conversation might not be straight forward\n4) Deploy in the ARM template or any iaac code&lt;/p&gt;\n\n&lt;p&gt;Thoughts ? Can we brainstorm ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17c2lwh", "is_robot_indexable": true, "report_reasons": null, "author": "cida1205", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17c2lwh/automate_informatica_job_migration_to_adf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17c2lwh/automate_informatica_job_migration_to_adf/", "subreddit_subscribers": 134980, "created_utc": 1697775617.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "How do you all serve up product data ( usage , enriched backend) to engineers to help them improve products at the road map design level or even just experience/ experience ?", "author_fullname": "t2_13551s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Serving product data to product engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bx6ix", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697758906.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How do you all serve up product data ( usage , enriched backend) to engineers to help them improve products at the road map design level or even just experience/ experience ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17bx6ix", "is_robot_indexable": true, "report_reasons": null, "author": "citizenofacceptance2", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bx6ix/serving_product_data_to_product_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bx6ix/serving_product_data_to_product_engineers/", "subreddit_subscribers": 134980, "created_utc": 1697758906.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello.\n\nI've been using SQL Server to BULK import .csv files stored in Azure Blob Storage, using scoped credentials, external data source, master key, etc.\n\nThis works fine. However, I'd like to upsert an existing table, say Invoices, with a new version of the .csv file corresponding to the Invoices table.\n\nI know that I can use MERGE, USING, ON, WHEN MATCHED, WHEN NOT MATCHED, etc, if I load the new source .csv file in a temp_Invoices table and then do the merge between the two.\n\nHowever, this defeats the whole purpose, since... I'd be loading the full table anyways, and I just want to load the new and modified data.\n\nIs this possible to do?\n\nI know CDC exists but the source databases doesn't allow this. If this is not possible, is full load the only practical solution?", "author_fullname": "t2_h920ytdnk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Upserting SQL Server table with .csv file, directly (incremental loading?)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bv9ou", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697753655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been using SQL Server to BULK import .csv files stored in Azure Blob Storage, using scoped credentials, external data source, master key, etc.&lt;/p&gt;\n\n&lt;p&gt;This works fine. However, I&amp;#39;d like to upsert an existing table, say Invoices, with a new version of the .csv file corresponding to the Invoices table.&lt;/p&gt;\n\n&lt;p&gt;I know that I can use MERGE, USING, ON, WHEN MATCHED, WHEN NOT MATCHED, etc, if I load the new source .csv file in a temp_Invoices table and then do the merge between the two.&lt;/p&gt;\n\n&lt;p&gt;However, this defeats the whole purpose, since... I&amp;#39;d be loading the full table anyways, and I just want to load the new and modified data.&lt;/p&gt;\n\n&lt;p&gt;Is this possible to do?&lt;/p&gt;\n\n&lt;p&gt;I know CDC exists but the source databases doesn&amp;#39;t allow this. If this is not possible, is full load the only practical solution?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17bv9ou", "is_robot_indexable": true, "report_reasons": null, "author": "ineedanswersiswear", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bv9ou/upserting_sql_server_table_with_csv_file_directly/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bv9ou/upserting_sql_server_table_with_csv_file_directly/", "subreddit_subscribers": 134980, "created_utc": 1697753655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi! i've been asked to connect/pull data from SAP successfactors but i'm a bit confused, wondering if there is some help here.\n\nThe docs they gave us basically says \"get a saml assertion\" and that's about it... so i guess my question is has anyone had success with getting connected/might have some resources?\n\nThe SAML bit is new to me, so i'm looking to understand a bit better on that piece, specifically generating the assertions. We are an azure house with AD sign in for it, so i feel like there is something there?\n\nWe are looking to pull the data out for storing in the warehouse for Power BI reporting internally. Looking to target the odata feed endpoints (which i am comfortable with!)\n\nalternatively, is there any paid platforms that have this like fivetran...\n\nThanks!\n\nhttps://help.sap.com/docs/SAP_SUCCESSFACTORS_PLATFORM/d599f15995d348a1b45ba5603e2aba9b/d9a9545305004187986c866de2b66987.html?locale=en-US", "author_fullname": "t2_ahu1o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SAP Successfactors HXM - SAML", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17brk05", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697744225.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi! i&amp;#39;ve been asked to connect/pull data from SAP successfactors but i&amp;#39;m a bit confused, wondering if there is some help here.&lt;/p&gt;\n\n&lt;p&gt;The docs they gave us basically says &amp;quot;get a saml assertion&amp;quot; and that&amp;#39;s about it... so i guess my question is has anyone had success with getting connected/might have some resources?&lt;/p&gt;\n\n&lt;p&gt;The SAML bit is new to me, so i&amp;#39;m looking to understand a bit better on that piece, specifically generating the assertions. We are an azure house with AD sign in for it, so i feel like there is something there?&lt;/p&gt;\n\n&lt;p&gt;We are looking to pull the data out for storing in the warehouse for Power BI reporting internally. Looking to target the odata feed endpoints (which i am comfortable with!)&lt;/p&gt;\n\n&lt;p&gt;alternatively, is there any paid platforms that have this like fivetran...&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://help.sap.com/docs/SAP_SUCCESSFACTORS_PLATFORM/d599f15995d348a1b45ba5603e2aba9b/d9a9545305004187986c866de2b66987.html?locale=en-US\"&gt;https://help.sap.com/docs/SAP_SUCCESSFACTORS_PLATFORM/d599f15995d348a1b45ba5603e2aba9b/d9a9545305004187986c866de2b66987.html?locale=en-US&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17brk05", "is_robot_indexable": true, "report_reasons": null, "author": "Namur007", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17brk05/sap_successfactors_hxm_saml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17brk05/sap_successfactors_hxm_saml/", "subreddit_subscribers": 134980, "created_utc": 1697744225.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We currently have a use case where scientists generate large volumes of datasets on an output S3 bucket. They annotate metadata for each dataset on an XLSX hosted in SharePoint (feature-wise, it's very important to them that they can \"drag-and-drop\" rows down to quickly create like rows because they can work with up to 50 replicates at a time, all with very similar columns). This SharePoint site is polled and any update to the XLSX triggers ingestion of both XLSX and associated datasets (rows).\n\nThis solution works, and it's simple (i.e. we don't need to build a custom application that needs to be maintained). The challenge here was always that we didn't have any source system to inject metadata from, so XLSX was an easy solution when we first started.\n\nHowever, now we're in production, and management doesn't like having XLSX involved in our automation. We need to find a new solution, but without building an entirely custom LIMS application here, I'm not sure how to solve this in a simple way! I'm looking for an open source solution for users to enter data through a UI, preferably as a table. It would be great if the solution had API integration and some sort of quality checks built in!\n\nDoes something like this exist? I'm curious how others deal with these problems?", "author_fullname": "t2_jbc55q4c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for open source tools for users to manually enter data in tables (but not Excel)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bqz6r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697742727.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We currently have a use case where scientists generate large volumes of datasets on an output S3 bucket. They annotate metadata for each dataset on an XLSX hosted in SharePoint (feature-wise, it&amp;#39;s very important to them that they can &amp;quot;drag-and-drop&amp;quot; rows down to quickly create like rows because they can work with up to 50 replicates at a time, all with very similar columns). This SharePoint site is polled and any update to the XLSX triggers ingestion of both XLSX and associated datasets (rows).&lt;/p&gt;\n\n&lt;p&gt;This solution works, and it&amp;#39;s simple (i.e. we don&amp;#39;t need to build a custom application that needs to be maintained). The challenge here was always that we didn&amp;#39;t have any source system to inject metadata from, so XLSX was an easy solution when we first started.&lt;/p&gt;\n\n&lt;p&gt;However, now we&amp;#39;re in production, and management doesn&amp;#39;t like having XLSX involved in our automation. We need to find a new solution, but without building an entirely custom LIMS application here, I&amp;#39;m not sure how to solve this in a simple way! I&amp;#39;m looking for an open source solution for users to enter data through a UI, preferably as a table. It would be great if the solution had API integration and some sort of quality checks built in!&lt;/p&gt;\n\n&lt;p&gt;Does something like this exist? I&amp;#39;m curious how others deal with these problems?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17bqz6r", "is_robot_indexable": true, "report_reasons": null, "author": "mccarthycodes", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bqz6r/looking_for_open_source_tools_for_users_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bqz6r/looking_for_open_source_tools_for_users_to/", "subreddit_subscribers": 134980, "created_utc": 1697742727.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " The  data is being made available as SQL Server Analysis Services Cubes. I  know I can use a program like Microsoft Power BI to connect directly to  these, but if I have a PHP site, how can I either connect to these to  query them (even if I have to do MDX query or likewise), or, how can I  convert the output from these Cubes back into a regular database so I  can query it using regular SQL?\n\nI  just need some way to get the data I need out of these cubes to use on a  website which uses php. whether its directly or by snapshotting the  data into a DB periodically to run queries against.\n\nThanks", "author_fullname": "t2_9lf6bs4dn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Query SSAS OLAP/MOLAP Cube with PHP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bngc2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697733588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The  data is being made available as SQL Server Analysis Services Cubes. I  know I can use a program like Microsoft Power BI to connect directly to  these, but if I have a PHP site, how can I either connect to these to  query them (even if I have to do MDX query or likewise), or, how can I  convert the output from these Cubes back into a regular database so I  can query it using regular SQL?&lt;/p&gt;\n\n&lt;p&gt;I  just need some way to get the data I need out of these cubes to use on a  website which uses php. whether its directly or by snapshotting the  data into a DB periodically to run queries against.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17bngc2", "is_robot_indexable": true, "report_reasons": null, "author": "Intense_011", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bngc2/query_ssas_olapmolap_cube_with_php/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bngc2/query_ssas_olapmolap_cube_with_php/", "subreddit_subscribers": 134980, "created_utc": 1697733588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\nI have a spark application which requires a token to access a certain sysyem. The lib I am using to connect the said sysyem requires token in application.conf file. How can I make sure that my spark scala job have the conf file at runtime. As of now I am manually copying the file to hdfs directory. But if I put it in src/main/resources directory workers are not able to find it. As its a access token I cannot commit the application.conf to git repo. It will fail security check.  What options I have to make a resource available to all workers at runtime?", "author_fullname": "t2_gzyg3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cannot find application.conf issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bmk9x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697731230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi\nI have a spark application which requires a token to access a certain sysyem. The lib I am using to connect the said sysyem requires token in application.conf file. How can I make sure that my spark scala job have the conf file at runtime. As of now I am manually copying the file to hdfs directory. But if I put it in src/main/resources directory workers are not able to find it. As its a access token I cannot commit the application.conf to git repo. It will fail security check.  What options I have to make a resource available to all workers at runtime?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17bmk9x", "is_robot_indexable": true, "report_reasons": null, "author": "ps2931", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bmk9x/cannot_find_applicationconf_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bmk9x/cannot_find_applicationconf_issue/", "subreddit_subscribers": 134980, "created_utc": 1697731230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an good friend  (bachelors in politics and and another in CS) who is a senior data engineer, and I thought it would be valuable to share his knowledge with others who are interested in getting into the same field. This is kind of a \u2018if you don\u2019t know, you don\u2019t know\u2019 what to ask situation for me. So, I would like to know what questions would be of value to you. I can post the questions and his answers here if you want as well.", "author_fullname": "t2_102ywc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What questions would you like to ask a Senior Data engineer in the Health Management Industry (medicare plans)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bx78h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.44, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697758969.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an good friend  (bachelors in politics and and another in CS) who is a senior data engineer, and I thought it would be valuable to share his knowledge with others who are interested in getting into the same field. This is kind of a \u2018if you don\u2019t know, you don\u2019t know\u2019 what to ask situation for me. So, I would like to know what questions would be of value to you. I can post the questions and his answers here if you want as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17bx78h", "is_robot_indexable": true, "report_reasons": null, "author": "escis", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bx78h/what_questions_would_you_like_to_ask_a_senior/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bx78h/what_questions_would_you_like_to_ask_a_senior/", "subreddit_subscribers": 134980, "created_utc": 1697758969.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}