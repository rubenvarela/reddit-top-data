{"kind": "Listing", "data": {"after": "t3_17bss87", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The X24 is being released", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seagate unleases Hard Drives with 24TB Storage Capacity", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_17bl6ux", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 225, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 225, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DMJgkcAcw7f0iFGlNk5XI0VnNlE27dv1zZ6P2pVna4Y.jpg", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697727604.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "guru3d.com", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The X24 is being released&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.guru3d.com/story/seagate-unleases-hard-drives-with-24tb-storage-capacity/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_AfyhiQlKYY4e7Q6hW_K-yT0fB1C6nnGQ-zaVrndChA.jpg?auto=webp&amp;s=21d1e93c5461462e4126153f98136c6196bc4358", "width": 640, "height": 640}, "resolutions": [{"url": "https://external-preview.redd.it/_AfyhiQlKYY4e7Q6hW_K-yT0fB1C6nnGQ-zaVrndChA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=aea5988028851f23fba764d364c2b27e95a83eb3", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/_AfyhiQlKYY4e7Q6hW_K-yT0fB1C6nnGQ-zaVrndChA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4219bede6df7277cc5b0523b95df08a0a6711622", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/_AfyhiQlKYY4e7Q6hW_K-yT0fB1C6nnGQ-zaVrndChA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7fbc49559406bf3d3a0d288b8ff603ba92970cd6", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/_AfyhiQlKYY4e7Q6hW_K-yT0fB1C6nnGQ-zaVrndChA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c74cd02526ccef47a23a48ee95a39dc22854f933", "width": 640, "height": 640}], "variants": {}, "id": "toqLiPggpSPq6boCyjgLxiAWP7ECNO785V__2oSwtkg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "74TB", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bl6ux", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 68, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17bl6ux/seagate_unleases_hard_drives_with_24tb_storage/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.guru3d.com/story/seagate-unleases-hard-drives-with-24tb-storage-capacity/", "subreddit_subscribers": 707648, "created_utc": 1697727604.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Someone is selling these for 90 dollars each of FB and claims they are new but I feel off out about them, cant find much info on WD site for them.", "author_fullname": "t2_13gpto", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cant find any information on these drives, are they worth picking up or potentially fake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_17c2eia", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "ups": 60, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 60, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bAELPYOTJeHHLRoLz785Shccqqx5myOgR0t60iB7-8Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697774905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Someone is selling these for 90 dollars each of FB and claims they are new but I feel off out about them, cant find much info on WD site for them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/i6if9aig8avb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/i6if9aig8avb1.jpg?auto=webp&amp;s=11048feff708686b46549d1a1d6ab0eda6c24a4e", "width": 1440, "height": 3200}, "resolutions": [{"url": "https://preview.redd.it/i6if9aig8avb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7818cd3f0c7e79bd31d1443f5103599fefca4743", "width": 108, "height": 216}, {"url": "https://preview.redd.it/i6if9aig8avb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=789c57714707ebf3bf771734655a509ae4de139e", "width": 216, "height": 432}, {"url": "https://preview.redd.it/i6if9aig8avb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f8a9cb40eb930277bf37df8399ca3d5d9233b749", "width": 320, "height": 640}, {"url": "https://preview.redd.it/i6if9aig8avb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6aa435e01af14ac9af68f439251e2c2c33aadfa7", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/i6if9aig8avb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5f7be24bda06855af1e17e68fa87c57404601e7", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/i6if9aig8avb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7e2e814bd95e2a67247dfee313e2c3143d4bca2b", "width": 1080, "height": 2160}], "variants": {}, "id": "tgpCevzeVcwZCjFsFDGU9jGET0EwV6wU50HIPTFnz08"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c2eia", "is_robot_indexable": true, "report_reasons": null, "author": "nnhalo360nn", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c2eia/cant_find_any_information_on_these_drives_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/i6if9aig8avb1.jpg", "subreddit_subscribers": 707648, "created_utc": 1697774905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4aynv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "British Museum sets out plans to digitise fully the collection", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "news", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bpro3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 17, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "News", "can_mod_post": false, "score": 17, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1697739630.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "britishmuseum.org", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.britishmuseum.org/sites/default/files/2023-10/British_Museum_sets_out_plans_to_digitise_fully_the_collection.pdf", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "ed4936de-4bf6-11e3-8e8d-12313d184137", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bpro3", "is_robot_indexable": true, "report_reasons": null, "author": "retrac1324", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bpro3/british_museum_sets_out_plans_to_digitise_fully/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.britishmuseum.org/sites/default/files/2023-10/British_Museum_sets_out_plans_to_digitise_fully_the_collection.pdf", "subreddit_subscribers": 707648, "created_utc": 1697739630.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Trying to build my library of audiobooks.  I found a free site that lets me play them on the site but I can't figure out how to download the files so I can play in a player (on my phone the site stops playing when I close browser and other times).  The site is tokybook.com\n\nCan anyone recommend a program or something that will get these audio files?  In bulk would be great but even one by one at least I'd have something to keep me busy.  I looked at the page source on the player but can't seem to find the full path to the media (I did find the file names with .mp3 extension) its in java so it's a bit foreign to me.", "author_fullname": "t2_fbbrfkqd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to scrape this site", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bulnk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697751934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to build my library of audiobooks.  I found a free site that lets me play them on the site but I can&amp;#39;t figure out how to download the files so I can play in a player (on my phone the site stops playing when I close browser and other times).  The site is tokybook.com&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend a program or something that will get these audio files?  In bulk would be great but even one by one at least I&amp;#39;d have something to keep me busy.  I looked at the page source on the player but can&amp;#39;t seem to find the full path to the media (I did find the file names with .mp3 extension) its in java so it&amp;#39;s a bit foreign to me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bulnk", "is_robot_indexable": true, "report_reasons": null, "author": "CryGeneral9999", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bulnk/best_way_to_scrape_this_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bulnk/best_way_to_scrape_this_site/", "subreddit_subscribers": 707648, "created_utc": 1697751934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everybody, so I am re-organizing my data backup now and purchased a few drives for redundancy as well. What I was wondering is, how to you structure and build your backup? What would you do without buying a NAS or whatever :)   \nMy issue is: \n\nI now got around 7,5TB of Data, that I need to backup regularly. The data types are (very simple speaking)   \n\n\n* family stuff + personal documents (500GB (size is 1TB)) \n* music and audio files / recordings (2TB)\n* video files / recordings (4TB)\n* movie files / recordings (1TB)\n\nThis is also the current structure. Each \"type\" is on an external drive. Those are backed up onto a second hard drive the same size. And the most important personal files are also encrypted in a cloud. The personal stuff might also be burned on blu rays soon.   \n\n\nI bought myself a 8TB Seagate One Touch Hub now as well. My ideas would be:   \n\n\na) Use the Hub (connected to the computer) as extended space, give every data types their own space on there, work on that and then back up to smaller hard drives organized by the structure above.   \n\n\nOr...  \nb) Use external drives to work on, connected to the computer, and backup all on the HUB regularly.   \n\n\nLet me know what you think? What would be your ideas? ", "author_fullname": "t2_8mefawmx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organizing your data / backups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c4ded", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697782364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody, so I am re-organizing my data backup now and purchased a few drives for redundancy as well. What I was wondering is, how to you structure and build your backup? What would you do without buying a NAS or whatever :)&lt;br/&gt;\nMy issue is: &lt;/p&gt;\n\n&lt;p&gt;I now got around 7,5TB of Data, that I need to backup regularly. The data types are (very simple speaking)   &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;family stuff + personal documents (500GB (size is 1TB)) &lt;/li&gt;\n&lt;li&gt;music and audio files / recordings (2TB)&lt;/li&gt;\n&lt;li&gt;video files / recordings (4TB)&lt;/li&gt;\n&lt;li&gt;movie files / recordings (1TB)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This is also the current structure. Each &amp;quot;type&amp;quot; is on an external drive. Those are backed up onto a second hard drive the same size. And the most important personal files are also encrypted in a cloud. The personal stuff might also be burned on blu rays soon.   &lt;/p&gt;\n\n&lt;p&gt;I bought myself a 8TB Seagate One Touch Hub now as well. My ideas would be:   &lt;/p&gt;\n\n&lt;p&gt;a) Use the Hub (connected to the computer) as extended space, give every data types their own space on there, work on that and then back up to smaller hard drives organized by the structure above.   &lt;/p&gt;\n\n&lt;p&gt;Or...&lt;br/&gt;\nb) Use external drives to work on, connected to the computer, and backup all on the HUB regularly.   &lt;/p&gt;\n\n&lt;p&gt;Let me know what you think? What would be your ideas? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c4ded", "is_robot_indexable": true, "report_reasons": null, "author": "kollektivintim", "discussion_type": null, "num_comments": 5, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c4ded/organizing_your_data_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c4ded/organizing_your_data_backups/", "subreddit_subscribers": 707648, "created_utc": 1697782364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "For cold storage, I got a pack of 50 Blu-rays, all rewritable... but when I tried again to find more, all sellers only had BD-R. One even said it's getting harder to find any BD-RE (rewritable discs). Is this true? How hard it is to find these everywhere?\n\nAlso, can I expect some issues, even if I store all of them correctly, compared to BD-R? I don't like the idea of having that ammount of data in a way that can't be modified a single bit.\n\nEDIT: Thoughts on BD-RE: [https://www.iljitsch.com/2022/01-09-longevity-of-recordable-blu-ray-discs-bd-r-bd-re.html](https://www.iljitsch.com/2022/01-09-longevity-of-recordable-blu-ray-discs-bd-r-bd-re.html)\n\nThis link says they last more:\n\n[https://www.canada.ca/en/conservation-institute/services/conservation-preservation-publications/canadian-conservation-institute-notes/longevity-recordable-cds-dvds.html](https://www.canada.ca/en/conservation-institute/services/conservation-preservation-publications/canadian-conservation-institute-notes/longevity-recordable-cds-dvds.html)", "author_fullname": "t2_1utoiwm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can't find BD-RE, and even if I do, should I opt for this instead of BD-R?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bmsfx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697772707.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697731816.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For cold storage, I got a pack of 50 Blu-rays, all rewritable... but when I tried again to find more, all sellers only had BD-R. One even said it&amp;#39;s getting harder to find any BD-RE (rewritable discs). Is this true? How hard it is to find these everywhere?&lt;/p&gt;\n\n&lt;p&gt;Also, can I expect some issues, even if I store all of them correctly, compared to BD-R? I don&amp;#39;t like the idea of having that ammount of data in a way that can&amp;#39;t be modified a single bit.&lt;/p&gt;\n\n&lt;p&gt;EDIT: Thoughts on BD-RE: &lt;a href=\"https://www.iljitsch.com/2022/01-09-longevity-of-recordable-blu-ray-discs-bd-r-bd-re.html\"&gt;https://www.iljitsch.com/2022/01-09-longevity-of-recordable-blu-ray-discs-bd-r-bd-re.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This link says they last more:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.canada.ca/en/conservation-institute/services/conservation-preservation-publications/canadian-conservation-institute-notes/longevity-recordable-cds-dvds.html\"&gt;https://www.canada.ca/en/conservation-institute/services/conservation-preservation-publications/canadian-conservation-institute-notes/longevity-recordable-cds-dvds.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bmsfx", "is_robot_indexable": true, "report_reasons": null, "author": "Maratocarde", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bmsfx/cant_find_bdre_and_even_if_i_do_should_i_opt_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bmsfx/cant_find_bdre_and_even_if_i_do_should_i_opt_for/", "subreddit_subscribers": 707648, "created_utc": 1697731816.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Just recently 2 HDDs I had(1 4TB WD Elements and 1 3TB Seagate) stopped working suddenly, and since I can't find a way to mount them on my PCs anymore, I had to consider their data fully lost. This made me realize the importance of having data backed up in at least one additional HDD, since years of my life were stolen from this event, and now I'm trying to back up a set of HDDs I have. My problem is that Copy/Pasting from Windows seems like an slow process, and also one that requires having my PC on, which limits the amount of data I can backup per day(I only keep my PC on 5hr per day due high energy consumption).\n\nMy question is: What's the most efficient(Or fastest) way to backup, TBs in size, HDDs? As a side note, while I can't have my PC on that long, I've a RPi 4 that is on 24/7, so if there is any software for it or a device that I can connect to it and do the trick, would be better.", "author_fullname": "t2_13y5jf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most efficient/fastest way to clone/backup data from HDDs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bpzww", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697740215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just recently 2 HDDs I had(1 4TB WD Elements and 1 3TB Seagate) stopped working suddenly, and since I can&amp;#39;t find a way to mount them on my PCs anymore, I had to consider their data fully lost. This made me realize the importance of having data backed up in at least one additional HDD, since years of my life were stolen from this event, and now I&amp;#39;m trying to back up a set of HDDs I have. My problem is that Copy/Pasting from Windows seems like an slow process, and also one that requires having my PC on, which limits the amount of data I can backup per day(I only keep my PC on 5hr per day due high energy consumption).&lt;/p&gt;\n\n&lt;p&gt;My question is: What&amp;#39;s the most efficient(Or fastest) way to backup, TBs in size, HDDs? As a side note, while I can&amp;#39;t have my PC on that long, I&amp;#39;ve a RPi 4 that is on 24/7, so if there is any software for it or a device that I can connect to it and do the trick, would be better.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bpzww", "is_robot_indexable": true, "report_reasons": null, "author": "NoirSkell", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bpzww/most_efficientfastest_way_to_clonebackup_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bpzww/most_efficientfastest_way_to_clonebackup_data/", "subreddit_subscribers": 707648, "created_utc": 1697740215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am new to BD, but I would like to archive some of my data. I am looking for a Disc that has a good quality / price ratio. I know M-DISC is the best, but that costs about 5x as much. \n\nWhat is the life expectancy of a disc like this (VERBATIM BD-R SL DataLife)?  \nTo me, if the disc works for a good 20-30 years I'd say it is good, but if it will lose data after a few years, it seems pointless for backup purposes. I'd like to know what to expect for this price range.", "author_fullname": "t2_2xftem1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How good/bad is VERBATIM BD-R SL DataLife 25GB ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c6tqt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697792862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to BD, but I would like to archive some of my data. I am looking for a Disc that has a good quality / price ratio. I know M-DISC is the best, but that costs about 5x as much. &lt;/p&gt;\n\n&lt;p&gt;What is the life expectancy of a disc like this (VERBATIM BD-R SL DataLife)?&lt;br/&gt;\nTo me, if the disc works for a good 20-30 years I&amp;#39;d say it is good, but if it will lose data after a few years, it seems pointless for backup purposes. I&amp;#39;d like to know what to expect for this price range.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c6tqt", "is_robot_indexable": true, "report_reasons": null, "author": "Leonhardt90", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c6tqt/how_goodbad_is_verbatim_bdr_sl_datalife_25gb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c6tqt/how_goodbad_is_verbatim_bdr_sl_datalife_25gb/", "subreddit_subscribers": 707648, "created_utc": 1697792862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "They say it costs $.006 per GB, so 200GB would be $1.20/month?   Is there a minimum?\n\nDo they have restrictions on what gets uploaded?\n\nAre my uploads private?  Can they see what is on their servers or just me?\n\nThanks.", "author_fullname": "t2_t44bb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BackBlaze B2 questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17brqrp", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697744717.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;They say it costs $.006 per GB, so 200GB would be $1.20/month?   Is there a minimum?&lt;/p&gt;\n\n&lt;p&gt;Do they have restrictions on what gets uploaded?&lt;/p&gt;\n\n&lt;p&gt;Are my uploads private?  Can they see what is on their servers or just me?&lt;/p&gt;\n\n&lt;p&gt;Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17brqrp", "is_robot_indexable": true, "report_reasons": null, "author": "818sfv", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17brqrp/backblaze_b2_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17brqrp/backblaze_b2_questions/", "subreddit_subscribers": 707648, "created_utc": 1697744717.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nI have around 200 to 300 GB of photos with multiple users. Most of data i have on 2 different pc and a decent copy on gdrive.\n\nOther problems are that users are not that tech savvy and they upload some data on gdrive some on pc, some on 15year old external drive and it became a mess. Plus i almost run out of space on gdrive.\n\nGoal is to have 2 full copies of data.\n\nBudget 2bay nas would be ideal for my need but i dont need it running 24/7, i would need it maybe once a month to drop photos and leave it there.\n\nIs this a good solution?\nBuy 2 external hard drives same size. Let users upload data to one drive and have a second drive as a copy. End of each month, run a file sync between two drives.\n\nBetter solutions are welcomed aswell.", "author_fullname": "t2_4yatpgfa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup solution for my needs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bm57l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697730104.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;I have around 200 to 300 GB of photos with multiple users. Most of data i have on 2 different pc and a decent copy on gdrive.&lt;/p&gt;\n\n&lt;p&gt;Other problems are that users are not that tech savvy and they upload some data on gdrive some on pc, some on 15year old external drive and it became a mess. Plus i almost run out of space on gdrive.&lt;/p&gt;\n\n&lt;p&gt;Goal is to have 2 full copies of data.&lt;/p&gt;\n\n&lt;p&gt;Budget 2bay nas would be ideal for my need but i dont need it running 24/7, i would need it maybe once a month to drop photos and leave it there.&lt;/p&gt;\n\n&lt;p&gt;Is this a good solution?\nBuy 2 external hard drives same size. Let users upload data to one drive and have a second drive as a copy. End of each month, run a file sync between two drives.&lt;/p&gt;\n\n&lt;p&gt;Better solutions are welcomed aswell.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bm57l", "is_robot_indexable": true, "report_reasons": null, "author": "lagerixx", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bm57l/backup_solution_for_my_needs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bm57l/backup_solution_for_my_needs/", "subreddit_subscribers": 707648, "created_utc": 1697730104.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi, I recently bought a 8Tb Seagate Irownolf (ST8000VN004) from amazon, and when it arrived, it didn't have any protections, it was freely moving in a cardboard envelope. Naturally the disk had reallocated sectors. I returned it and bought another one.  \n\n\nWhen the other one arrived yesterday, it was packaged the exact same way. I tried it anyway, and despite being packaged like shit, this one seems to be perfectly fine on CrystalDiskInfo. The current seek error rate is a little high but I just copied 4Tb of files on it so I imagine that's normal.  \n\n\nHowever, this is by far the loudest HDD I've ever heard. Not even drives from the 90's were this loud. Anytime I write or read stuff on there, it's like there is a popcorn machine in my computer, both in terms of the dB level and the kind of noise it makes. In comparison, I have two 4Tb Ironwolfs that are perfectly silent.  \n\n\nAfter searching a bit, I have read that this is apparently a common problem for 8Tb Ironwolf precisely. This reassures me a bit, but I'm still concerned since it was so poorly packaged. Could loud \"popcorn-like\" noises from a drive mean it could be damaged in a way that can't be picked up by CrystalDiskInfo ?", "author_fullname": "t2_7y182d9m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "New Ironwolf 8Tb is extremely loud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c9uzk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697804070.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I recently bought a 8Tb Seagate Irownolf (ST8000VN004) from amazon, and when it arrived, it didn&amp;#39;t have any protections, it was freely moving in a cardboard envelope. Naturally the disk had reallocated sectors. I returned it and bought another one.  &lt;/p&gt;\n\n&lt;p&gt;When the other one arrived yesterday, it was packaged the exact same way. I tried it anyway, and despite being packaged like shit, this one seems to be perfectly fine on CrystalDiskInfo. The current seek error rate is a little high but I just copied 4Tb of files on it so I imagine that&amp;#39;s normal.  &lt;/p&gt;\n\n&lt;p&gt;However, this is by far the loudest HDD I&amp;#39;ve ever heard. Not even drives from the 90&amp;#39;s were this loud. Anytime I write or read stuff on there, it&amp;#39;s like there is a popcorn machine in my computer, both in terms of the dB level and the kind of noise it makes. In comparison, I have two 4Tb Ironwolfs that are perfectly silent.  &lt;/p&gt;\n\n&lt;p&gt;After searching a bit, I have read that this is apparently a common problem for 8Tb Ironwolf precisely. This reassures me a bit, but I&amp;#39;m still concerned since it was so poorly packaged. Could loud &amp;quot;popcorn-like&amp;quot; noises from a drive mean it could be damaged in a way that can&amp;#39;t be picked up by CrystalDiskInfo ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c9uzk", "is_robot_indexable": true, "report_reasons": null, "author": "throwawayfuckthis01", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c9uzk/new_ironwolf_8tb_is_extremely_loud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c9uzk/new_ironwolf_8tb_is_extremely_loud/", "subreddit_subscribers": 707648, "created_utc": 1697804070.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\nWhat program is everyone using to generate checksums for their files?\nI have thousands of files in folders that I need to generate checksums for, but doing it individually is not realistic.\n\nIs there a windows program (preferably with a GUI for convenience) by any chance that can calculate checksums for entire folders of files and dump that to a text file (or something similar), then in the future be able to ingest that text file to verify all the checksums semi-automatically?\n\nThank you", "author_fullname": "t2_3j9dm7sj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best bulk/folder checksum utility for windows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c9esq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697802589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nWhat program is everyone using to generate checksums for their files?\nI have thousands of files in folders that I need to generate checksums for, but doing it individually is not realistic.&lt;/p&gt;\n\n&lt;p&gt;Is there a windows program (preferably with a GUI for convenience) by any chance that can calculate checksums for entire folders of files and dump that to a text file (or something similar), then in the future be able to ingest that text file to verify all the checksums semi-automatically?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c9esq", "is_robot_indexable": true, "report_reasons": null, "author": "NWSpitfire", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c9esq/best_bulkfolder_checksum_utility_for_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c9esq/best_bulkfolder_checksum_utility_for_windows/", "subreddit_subscribers": 707648, "created_utc": 1697802589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all, I'm in a bit of a pickle.  I currently have two 16TB HDD mirrored in TrueNAS and am almost at capacity.  I recently picked up two more 16TB but I'm not sure what RAID configuration I should use and how to set it up without losing data from my existing mirror.  \n\nI do also have a separate machine with a 16TB I use for backup, so i can copy everything over again if I had to lose my data on the mirror, just would prefer not to have to copy 16TB of data over my network.  \n\nAnybody have any good suggestions, can I expand my current pool with the new drives?  I assume I can't really since a mirror is usually two drives, it seems like I will have to create a new RAID and copy everything over, but I would love some opinions.  Thanks!", "author_fullname": "t2_b3tdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TrueNAS raid configuration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bu2ao", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697750592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I&amp;#39;m in a bit of a pickle.  I currently have two 16TB HDD mirrored in TrueNAS and am almost at capacity.  I recently picked up two more 16TB but I&amp;#39;m not sure what RAID configuration I should use and how to set it up without losing data from my existing mirror.  &lt;/p&gt;\n\n&lt;p&gt;I do also have a separate machine with a 16TB I use for backup, so i can copy everything over again if I had to lose my data on the mirror, just would prefer not to have to copy 16TB of data over my network.  &lt;/p&gt;\n\n&lt;p&gt;Anybody have any good suggestions, can I expand my current pool with the new drives?  I assume I can&amp;#39;t really since a mirror is usually two drives, it seems like I will have to create a new RAID and copy everything over, but I would love some opinions.  Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bu2ao", "is_robot_indexable": true, "report_reasons": null, "author": "slash65", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bu2ao/truenas_raid_configuration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bu2ao/truenas_raid_configuration/", "subreddit_subscribers": 707648, "created_utc": 1697750592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just installed a 9211-8i (Dell H310) in IT mode.\n\n It has tested fine however when shutting down Windows the one drive I had hooked up to it made the loud spin down whine my Exos drives make when performing a dreaded hard shutdown.\n\nIs there a spindown before shutdown setting I am missing for for drives attached via LSI HBA?", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LSI HBA hard shutting down drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17btp07", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697756956.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697749685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just installed a 9211-8i (Dell H310) in IT mode.&lt;/p&gt;\n\n&lt;p&gt;It has tested fine however when shutting down Windows the one drive I had hooked up to it made the loud spin down whine my Exos drives make when performing a dreaded hard shutdown.&lt;/p&gt;\n\n&lt;p&gt;Is there a spindown before shutdown setting I am missing for for drives attached via LSI HBA?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "74TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17btp07", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17btp07/lsi_hba_hard_shutting_down_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17btp07/lsi_hba_hard_shutting_down_drives/", "subreddit_subscribers": 707648, "created_utc": 1697749685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello,\n\nThis is my own program, I released this update to provide a couple of fixes.\n\n* Resolved an issue where files hashed directly  inside a volume root were stored with the drive letter, so the .lfhash file contained their full file path. This means that the files could not be verified if moved; or if copied, the old, still-existing version would be verified rather than the new one.\n* Disk type detection is now functional for disks containing multiple data volumes.\n* Resolved NaN progress reported when hashing empty files.\n\nAnyone who is currently using the program will see the update notification when they next run it.\n\nThe purpose of this program is to store checksums next to your files. This is most useful with backups. You can right-click files, folders, or volumes, and generate checksums for them. You can double-click the resulting checksum file to verify.\n\nOfficial website and Download: [https://www.liamfoot.com/lfh](https://www.liamfoot.com/lfh)\n\nDirect download link: [https://www.liamfoot.com/GetDownload/LiamFootHash/1.3.0.0](https://www.liamfoot.com/GetDownload/LiamFootHash/1.3.0.0)", "author_fullname": "t2_h62v4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LiamFootHash v1.3 - A functional and very fast checksumming program for Windows.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bor8y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697737033.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;/p&gt;\n\n&lt;p&gt;This is my own program, I released this update to provide a couple of fixes.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Resolved an issue where files hashed directly  inside a volume root were stored with the drive letter, so the .lfhash file contained their full file path. This means that the files could not be verified if moved; or if copied, the old, still-existing version would be verified rather than the new one.&lt;/li&gt;\n&lt;li&gt;Disk type detection is now functional for disks containing multiple data volumes.&lt;/li&gt;\n&lt;li&gt;Resolved NaN progress reported when hashing empty files.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Anyone who is currently using the program will see the update notification when they next run it.&lt;/p&gt;\n\n&lt;p&gt;The purpose of this program is to store checksums next to your files. This is most useful with backups. You can right-click files, folders, or volumes, and generate checksums for them. You can double-click the resulting checksum file to verify.&lt;/p&gt;\n\n&lt;p&gt;Official website and Download: &lt;a href=\"https://www.liamfoot.com/lfh\"&gt;https://www.liamfoot.com/lfh&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Direct download link: &lt;a href=\"https://www.liamfoot.com/GetDownload/LiamFootHash/1.3.0.0\"&gt;https://www.liamfoot.com/GetDownload/LiamFootHash/1.3.0.0&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bor8y", "is_robot_indexable": true, "report_reasons": null, "author": "Liam2349", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bor8y/liamfoothash_v13_a_functional_and_very_fast/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bor8y/liamfoothash_v13_a_functional_and_very_fast/", "subreddit_subscribers": 707648, "created_utc": 1697737033.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Sure bandwidth is limited, bit how are iops behaving?", "author_fullname": "t2_80r87i4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will a gen4 m.2 keep high iops inna gen3 slot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c78qq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697794574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sure bandwidth is limited, bit how are iops behaving?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c78qq", "is_robot_indexable": true, "report_reasons": null, "author": "PalmMallMars", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c78qq/will_a_gen4_m2_keep_high_iops_inna_gen3_slot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c78qq/will_a_gen4_m2_keep_high_iops_inna_gen3_slot/", "subreddit_subscribers": 707648, "created_utc": 1697794574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everybody, so I am re-organizing my data backup now and purchased a few drives for redundancy as well. What I was wondering is, how to you structure and build your backup? What would you do without buying a NAS or whatever :)   \nMy issue is: \n\nI now got around 7,5TB of Data, that I need to backup regularly. The data types are (very simple speaking)   \n\n\n* family stuff + personal documents (500GB (size is 1TB)) \n* music and audio files / recordings (2TB)\n* video files / recordings (4TB)\n* movie files / recordings (1TB)\n\nThis is also the current structure. Each \"type\" is on an external drive. Those are backed up onto a second hard drive the same size. And the most important personal files are also encrypted in a cloud. The personal stuff might also be burned on blu rays soon.   \n\n\nI bought myself a 8TB Seagate One Touch Hub now as well. My ideas would be:   \n\n\na) Use the Hub (connected to the computer) as extended space, give every data types their own space on there, work on that and then back up to smaller hard drives organized by the structure above.   \n\n\nOr...  \nb) Use external drives to work on, connected to the computer, and backup all on the HUB regularly.   \n\n\nLet me know what you think? What would be your ideas? ", "author_fullname": "t2_8mefawmx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organizing your data / backups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c4dds", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697782361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody, so I am re-organizing my data backup now and purchased a few drives for redundancy as well. What I was wondering is, how to you structure and build your backup? What would you do without buying a NAS or whatever :)&lt;br/&gt;\nMy issue is: &lt;/p&gt;\n\n&lt;p&gt;I now got around 7,5TB of Data, that I need to backup regularly. The data types are (very simple speaking)   &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;family stuff + personal documents (500GB (size is 1TB)) &lt;/li&gt;\n&lt;li&gt;music and audio files / recordings (2TB)&lt;/li&gt;\n&lt;li&gt;video files / recordings (4TB)&lt;/li&gt;\n&lt;li&gt;movie files / recordings (1TB)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This is also the current structure. Each &amp;quot;type&amp;quot; is on an external drive. Those are backed up onto a second hard drive the same size. And the most important personal files are also encrypted in a cloud. The personal stuff might also be burned on blu rays soon.   &lt;/p&gt;\n\n&lt;p&gt;I bought myself a 8TB Seagate One Touch Hub now as well. My ideas would be:   &lt;/p&gt;\n\n&lt;p&gt;a) Use the Hub (connected to the computer) as extended space, give every data types their own space on there, work on that and then back up to smaller hard drives organized by the structure above.   &lt;/p&gt;\n\n&lt;p&gt;Or...&lt;br/&gt;\nb) Use external drives to work on, connected to the computer, and backup all on the HUB regularly.   &lt;/p&gt;\n\n&lt;p&gt;Let me know what you think? What would be your ideas? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c4dds", "is_robot_indexable": true, "report_reasons": null, "author": "kollektivintim", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c4dds/organizing_your_data_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c4dds/organizing_your_data_backups/", "subreddit_subscribers": 707648, "created_utc": 1697782361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "doesnt wanna load profiles and so laggy ", "author_fullname": "t2_86tkmqsl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "anyone knows what happened to TT sver ? its not working for me anymore .. and apparently they lowered the max download from 1000 to 100", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bsdsq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697746335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;doesnt wanna load profiles and so laggy &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bsdsq", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable42", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bsdsq/anyone_knows_what_happened_to_tt_sver_its_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bsdsq/anyone_knows_what_happened_to_tt_sver_its_not/", "subreddit_subscribers": 707648, "created_utc": 1697746335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I'm upgrading my main machine hard drives.\n\nFor local backup I've been using external USBs. \n\nBut as I move my existing 4/8tb internal drives out of the server, I was thinking of using them as additional backup drives, but it seems usb/das enclosures are expensive, and it would actually be cheaper to just get rid of them.\n\n&amp;#x200B;\n\nDoes anyone know cheap ways to hook up a few old 4/8tb drives, or should I just admit they're not worth it and sell them off?", "author_fullname": "t2_2sr8ya35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup Pod", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17cass6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697807011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m upgrading my main machine hard drives.&lt;/p&gt;\n\n&lt;p&gt;For local backup I&amp;#39;ve been using external USBs. &lt;/p&gt;\n\n&lt;p&gt;But as I move my existing 4/8tb internal drives out of the server, I was thinking of using them as additional backup drives, but it seems usb/das enclosures are expensive, and it would actually be cheaper to just get rid of them.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does anyone know cheap ways to hook up a few old 4/8tb drives, or should I just admit they&amp;#39;re not worth it and sell them off?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17cass6", "is_robot_indexable": true, "report_reasons": null, "author": "Frewtti", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17cass6/backup_pod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17cass6/backup_pod/", "subreddit_subscribers": 707648, "created_utc": 1697807011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey, i\u2019ve got a smaller collection of around 16tb of data across 2x8tb drives &amp; a 3tb drive. \n\nAll external drives connected via USB to an old macbook. it\u2019s a bit jallopy but i\u2019ve been using it as a setup for some of my work &amp; my partners photography &amp; videography for about 4 years. \n\nI\u2019ve got backblaze as my \u201coh cr*p\u201d i\u2019ve had a drive failure recovery solution. \n\nI was wondering is there a compression method to save some space for files which are truly not in need of retrieval often?", "author_fullname": "t2_n0af3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Part time data hoarder questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bsg3q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697746507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, i\u2019ve got a smaller collection of around 16tb of data across 2x8tb drives &amp;amp; a 3tb drive. &lt;/p&gt;\n\n&lt;p&gt;All external drives connected via USB to an old macbook. it\u2019s a bit jallopy but i\u2019ve been using it as a setup for some of my work &amp;amp; my partners photography &amp;amp; videography for about 4 years. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got backblaze as my \u201coh cr*p\u201d i\u2019ve had a drive failure recovery solution. &lt;/p&gt;\n\n&lt;p&gt;I was wondering is there a compression method to save some space for files which are truly not in need of retrieval often?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bsg3q", "is_robot_indexable": true, "report_reasons": null, "author": "madragonn", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bsg3q/part_time_data_hoarder_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bsg3q/part_time_data_hoarder_questions/", "subreddit_subscribers": 707648, "created_utc": 1697746507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi guys,\n\nI am currently hosting a bunch of things on my Gigabyte brix  (jellyfin, vaultwarden, pihole, openHAB, paperless, Hyperion, \u2026)\n\nAdditionally in am storing all my pictures there.\n\nEverything is stored on an attached 4TB external HDD.\n\nNow as I start to get worried about data loss and I am missing a bit of power (to host Immich for example) I am considering updating my system to an Intel NUC or similar,\n\nHowever as HDD are pretty expensive I am unsure how to proceed with the storage. My first thought was to run everything as raidz2 but I quickly noticed that storage space is super expensive and 4x18TB HDD would set me back easily 1000\u20ac. As far as I understand I can\u2019t have a raidz and use different HDD sizes and can also not really add HDD on the go (as long as they have different sizes)\n\nNow I was thinking to have a solution that is scalable and buy additional storage when needed, so currently my idea is to run a raidz1 with 3x8tb (or 3x6tb) for the very important data like the paperless data and the pictures and additionally just start with one 18TB standalone HDD for the media for jellyfin and add more when needed.\n\nDoes anyone have any other smart ideas how to organize this? It would be great to have some kind of data protection for the media too, but I feel in doubt this is the stuff I could afford to loose cause I can reobtain it\n\nHow are you guys organizing your drives?\n\nEdit: to add and be clear, I am fully aware that a NAS is not a backup solution. I already have a 3-2-1 backup solution in place for the most important stuff, I just want even more reliability (and capacity) on the internal ones withouth breaking the bank\n\n\nEdit2 (in case someone else has the same question and wonders what I ended up deciding):\n\nWill go for a mixture of raidz and mergefs with SnapRAID.\n\nMost important data on 3 disks raidz1, less important data managed with mergefs and \u201eprotected\u201c wirh SnapRAID.\n\nThat way I only have to buy 3 identical sized HDD for my important data and can Start with 2HDD for the less important one and add on the go.", "author_fullname": "t2_61dr7f6z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "HDD setup for NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17brtch", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697798493.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697744901.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys,&lt;/p&gt;\n\n&lt;p&gt;I am currently hosting a bunch of things on my Gigabyte brix  (jellyfin, vaultwarden, pihole, openHAB, paperless, Hyperion, \u2026)&lt;/p&gt;\n\n&lt;p&gt;Additionally in am storing all my pictures there.&lt;/p&gt;\n\n&lt;p&gt;Everything is stored on an attached 4TB external HDD.&lt;/p&gt;\n\n&lt;p&gt;Now as I start to get worried about data loss and I am missing a bit of power (to host Immich for example) I am considering updating my system to an Intel NUC or similar,&lt;/p&gt;\n\n&lt;p&gt;However as HDD are pretty expensive I am unsure how to proceed with the storage. My first thought was to run everything as raidz2 but I quickly noticed that storage space is super expensive and 4x18TB HDD would set me back easily 1000\u20ac. As far as I understand I can\u2019t have a raidz and use different HDD sizes and can also not really add HDD on the go (as long as they have different sizes)&lt;/p&gt;\n\n&lt;p&gt;Now I was thinking to have a solution that is scalable and buy additional storage when needed, so currently my idea is to run a raidz1 with 3x8tb (or 3x6tb) for the very important data like the paperless data and the pictures and additionally just start with one 18TB standalone HDD for the media for jellyfin and add more when needed.&lt;/p&gt;\n\n&lt;p&gt;Does anyone have any other smart ideas how to organize this? It would be great to have some kind of data protection for the media too, but I feel in doubt this is the stuff I could afford to loose cause I can reobtain it&lt;/p&gt;\n\n&lt;p&gt;How are you guys organizing your drives?&lt;/p&gt;\n\n&lt;p&gt;Edit: to add and be clear, I am fully aware that a NAS is not a backup solution. I already have a 3-2-1 backup solution in place for the most important stuff, I just want even more reliability (and capacity) on the internal ones withouth breaking the bank&lt;/p&gt;\n\n&lt;p&gt;Edit2 (in case someone else has the same question and wonders what I ended up deciding):&lt;/p&gt;\n\n&lt;p&gt;Will go for a mixture of raidz and mergefs with SnapRAID.&lt;/p&gt;\n\n&lt;p&gt;Most important data on 3 disks raidz1, less important data managed with mergefs and \u201eprotected\u201c wirh SnapRAID.&lt;/p&gt;\n\n&lt;p&gt;That way I only have to buy 3 identical sized HDD for my important data and can Start with 2HDD for the less important one and add on the go.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17brtch", "is_robot_indexable": true, "report_reasons": null, "author": "Narrow_Smoke", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17brtch/hdd_setup_for_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17brtch/hdd_setup_for_nas/", "subreddit_subscribers": 707648, "created_utc": 1697744901.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "doesnt wanna load profiles and so laggy ", "author_fullname": "t2_86tkmqsl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "anyone knows what happened to TT sver ? its not working for me anymore .. and apparently they lowered the max download from 1000 to 100", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bsdsx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697746336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;doesnt wanna load profiles and so laggy &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bsdsx", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable42", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bsdsx/anyone_knows_what_happened_to_tt_sver_its_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bsdsx/anyone_knows_what_happened_to_tt_sver_its_not/", "subreddit_subscribers": 707648, "created_utc": 1697746336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi r/DataHoarder :)\n\nOk, I don't use NAS  and seeding torrents, just save/archive.\n\nAs in the title, can I buy a size of 20 TB or more but not NAS, and what is the right choice for me? As you know, I love to save movies, tv, games, books, etc. I want to stay without a network for a while (this is my belief that a regular storage is better, as if it were a new storage, just save and finish, unlike NAS who start it and maybe it crashes for years).\n\nOf course, backup copies must be made to a second disk of the same size or larger.\n\nI am worried that storage may not be in the future for a long time. There are new products. I don\u2019t know whether to buy it now or wait.\n\nIn short: I like to keep things and use them later.\n\nThis is a general discussion, you can share even if it is different, I am welcome any time.\n\nThank you very much!", "author_fullname": "t2_56zpr3td", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the new products for storage? What are the things to avoid?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c41ej", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697781055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/DataHoarder\"&gt;r/DataHoarder&lt;/a&gt; :)&lt;/p&gt;\n\n&lt;p&gt;Ok, I don&amp;#39;t use NAS  and seeding torrents, just save/archive.&lt;/p&gt;\n\n&lt;p&gt;As in the title, can I buy a size of 20 TB or more but not NAS, and what is the right choice for me? As you know, I love to save movies, tv, games, books, etc. I want to stay without a network for a while (this is my belief that a regular storage is better, as if it were a new storage, just save and finish, unlike NAS who start it and maybe it crashes for years).&lt;/p&gt;\n\n&lt;p&gt;Of course, backup copies must be made to a second disk of the same size or larger.&lt;/p&gt;\n\n&lt;p&gt;I am worried that storage may not be in the future for a long time. There are new products. I don\u2019t know whether to buy it now or wait.&lt;/p&gt;\n\n&lt;p&gt;In short: I like to keep things and use them later.&lt;/p&gt;\n\n&lt;p&gt;This is a general discussion, you can share even if it is different, I am welcome any time.&lt;/p&gt;\n\n&lt;p&gt;Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17c41ej", "is_robot_indexable": true, "report_reasons": null, "author": "DrEaMs0123", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c41ej/what_are_the_new_products_for_storage_what_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c41ej/what_are_the_new_products_for_storage_what_are/", "subreddit_subscribers": 707648, "created_utc": 1697781055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI run a couple of unraid servers and am running low on space on one of them so I've started having a look for another 12TB drive. I usually buy external a shuck them. I'm shocked at the prices of them\n\n3 years ago I bought 2 12TB WD Elements for \u00a3166 pounds each on amazon. Now the same is \u00a3214 used. I know there was a spike in prices during covid but it's crazy that a drive could be purchased 3 years ago much cheaper. Why have prices risen so much again? What have I missed?", "author_fullname": "t2_ecjd325v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hard Drives still so expensive", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bmb0s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697730546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I run a couple of unraid servers and am running low on space on one of them so I&amp;#39;ve started having a look for another 12TB drive. I usually buy external a shuck them. I&amp;#39;m shocked at the prices of them&lt;/p&gt;\n\n&lt;p&gt;3 years ago I bought 2 12TB WD Elements for \u00a3166 pounds each on amazon. Now the same is \u00a3214 used. I know there was a spike in prices during covid but it&amp;#39;s crazy that a drive could be purchased 3 years ago much cheaper. Why have prices risen so much again? What have I missed?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17bmb0s", "is_robot_indexable": true, "report_reasons": null, "author": "Upbeat_Platypus1833", "discussion_type": null, "num_comments": 27, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bmb0s/hard_drives_still_so_expensive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bmb0s/hard_drives_still_so_expensive/", "subreddit_subscribers": 707648, "created_utc": 1697730546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, as I said I just bought 4x20TB HDD to make a new RAID 5 array and I am wondering if I should write data unevenly on 3 of them before doing the RAID 5 to use a little bit of their lifespan so they will not die at the same time or while rebuilding the RAID 5.The data I would write isn't important, it's only to reduce their lifespan.\n\nOn the first I write nothing.On the second I write 40TB.On the third I write 80TB.And on the forth I write 120TB.And only then I erase the data I just wrote and I make the RAID 5.\n\nIt's not very sensitive data, but if I can save me from a complete data loss of this RAID 5 it's cool.btw it's 4 Seagate Exos X20 of 20TB. May not be the best but it's cheap.\n\nIs it meaningless to do so or can it increases my chances of a clean rebuild if one of them fail?", "author_fullname": "t2_c94mw03d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I bought 4x20TB HDD for my RAID 5. Will they die at the same time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bss87", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697768894.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697747380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, as I said I just bought 4x20TB HDD to make a new RAID 5 array and I am wondering if I should write data unevenly on 3 of them before doing the RAID 5 to use a little bit of their lifespan so they will not die at the same time or while rebuilding the RAID 5.The data I would write isn&amp;#39;t important, it&amp;#39;s only to reduce their lifespan.&lt;/p&gt;\n\n&lt;p&gt;On the first I write nothing.On the second I write 40TB.On the third I write 80TB.And on the forth I write 120TB.And only then I erase the data I just wrote and I make the RAID 5.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not very sensitive data, but if I can save me from a complete data loss of this RAID 5 it&amp;#39;s cool.btw it&amp;#39;s 4 Seagate Exos X20 of 20TB. May not be the best but it&amp;#39;s cheap.&lt;/p&gt;\n\n&lt;p&gt;Is it meaningless to do so or can it increases my chances of a clean rebuild if one of them fail?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bss87", "is_robot_indexable": true, "report_reasons": null, "author": "RAYTEKSO", "discussion_type": null, "num_comments": 30, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bss87/i_bought_4x20tb_hdd_for_my_raid_5_will_they_die/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bss87/i_bought_4x20tb_hdd_for_my_raid_5_will_they_die/", "subreddit_subscribers": 707648, "created_utc": 1697747380.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}