{"kind": "Listing", "data": {"after": null, "dist": 22, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Someone is selling these for 90 dollars each of FB and claims they are new but I feel off out about them, cant find much info on WD site for them.", "author_fullname": "t2_13gpto", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cant find any information on these drives, are they worth picking up or potentially fake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_17c2eia", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.87, "author_flair_background_color": null, "ups": 94, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 94, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/bAELPYOTJeHHLRoLz785Shccqqx5myOgR0t60iB7-8Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697774905.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Someone is selling these for 90 dollars each of FB and claims they are new but I feel off out about them, cant find much info on WD site for them.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/i6if9aig8avb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/i6if9aig8avb1.jpg?auto=webp&amp;s=11048feff708686b46549d1a1d6ab0eda6c24a4e", "width": 1440, "height": 3200}, "resolutions": [{"url": "https://preview.redd.it/i6if9aig8avb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=7818cd3f0c7e79bd31d1443f5103599fefca4743", "width": 108, "height": 216}, {"url": "https://preview.redd.it/i6if9aig8avb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=789c57714707ebf3bf771734655a509ae4de139e", "width": 216, "height": 432}, {"url": "https://preview.redd.it/i6if9aig8avb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f8a9cb40eb930277bf37df8399ca3d5d9233b749", "width": 320, "height": 640}, {"url": "https://preview.redd.it/i6if9aig8avb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6aa435e01af14ac9af68f439251e2c2c33aadfa7", "width": 640, "height": 1280}, {"url": "https://preview.redd.it/i6if9aig8avb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e5f7be24bda06855af1e17e68fa87c57404601e7", "width": 960, "height": 1920}, {"url": "https://preview.redd.it/i6if9aig8avb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7e2e814bd95e2a67247dfee313e2c3143d4bca2b", "width": 1080, "height": 2160}], "variants": {}, "id": "tgpCevzeVcwZCjFsFDGU9jGET0EwV6wU50HIPTFnz08"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c2eia", "is_robot_indexable": true, "report_reasons": null, "author": "nnhalo360nn", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c2eia/cant_find_any_information_on_these_drives_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/i6if9aig8avb1.jpg", "subreddit_subscribers": 707691, "created_utc": 1697774905.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Trying to build my library of audiobooks.  I found a free site that lets me play them on the site but I can't figure out how to download the files so I can play in a player (on my phone the site stops playing when I close browser and other times).  The site is tokybook.com\n\nCan anyone recommend a program or something that will get these audio files?  In bulk would be great but even one by one at least I'd have something to keep me busy.  I looked at the page source on the player but can't seem to find the full path to the media (I did find the file names with .mp3 extension) its in java so it's a bit foreign to me.", "author_fullname": "t2_fbbrfkqd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to scrape this site", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bulnk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697751934.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Trying to build my library of audiobooks.  I found a free site that lets me play them on the site but I can&amp;#39;t figure out how to download the files so I can play in a player (on my phone the site stops playing when I close browser and other times).  The site is tokybook.com&lt;/p&gt;\n\n&lt;p&gt;Can anyone recommend a program or something that will get these audio files?  In bulk would be great but even one by one at least I&amp;#39;d have something to keep me busy.  I looked at the page source on the player but can&amp;#39;t seem to find the full path to the media (I did find the file names with .mp3 extension) its in java so it&amp;#39;s a bit foreign to me.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bulnk", "is_robot_indexable": true, "report_reasons": null, "author": "CryGeneral9999", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bulnk/best_way_to_scrape_this_site/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bulnk/best_way_to_scrape_this_site/", "subreddit_subscribers": 707691, "created_utc": 1697751934.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I don't post here regularly on this topic because I don't like \"pushing\" my software.  I did post here years ago when I first launched Stacher, a hobby project started during the pandemic, looking for feedback.  Since then, I've taken your feedback and been working off and on to make it more stable and implement the features that were suggested.\n\nRecently, Subscriptions and \"Minimize to Tray\" were added which was something many of you in this subreddit had asked me about and the motivation for this post.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/173rsrot7evb1.png?width=2064&amp;format=png&amp;auto=webp&amp;s=83a309475f037270e4030262112d7d13765b7c4a\n\nFor those who don't know, Stacher is a frontend/GUI to the yt-dlp command line utility and provides the following features:\n\n* Clean UI for Mac and Windows\n* UI Controls for subtitles, different format selection, post processing options, playlists, etc\n* Because Stacher is essentially a CLI builder, you can use `ctrl`\\+`enter` after pasting a url to modify the command line directly which allows you to add any arguments that yt-dlp supports that aren't surfaced in Stacher.\n* Clip Cropping.  Admittedly a pretty basic tool, but provides little sliders to crop only a section of media *before* downloading\n* Clipboard listener that detects valid URL's and auto starts downloading (this has to manually be enabled each time you start Stacher - it will not save this setting)\n* Subscriptions allow you to automatically handle playlist or channel monitoring at regular intervals\n* Minimize to tray keeps stacher out of the way.  On Mac, you can drag links onto the tray icon\n\nStacher is available at [https://stacher.io](https://stacher.io) and there is a subreddit for it over at /r/stacherio.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\ninb4: some questions that I know will come up -\n\n**Does yt-dlp/ffmpeg come with it?**: Stacher will automatically setup yt-dlp.  There is a menu option to do this as well.  FFMPEG *does not* come with stacher, you have to set this up manually if you want it.  There is a wiki on it in the stacher subreddit but it's essentially the same process required for using yt-dlp\n\n**Is Stacher open source?**: It is not right now.  This project has always been a hobby project and the repo is a mess - cleaning it up is something I always push to the side.  I didn't intend to share it early on and wasn't really planning/thinking about it being open.  I totally get if you don't want to check it out for this reason.\n\n**Is it available on linux?** Every time I cut a release, I test mainly on mac and windows.  I do have unreleased 6.0.20 versions for debian that I still need to test.\n\n**Is there a Mac M1 version instead of just intel?** Similarly, I have the binary and it's better tested, but I need to apply the certs and go through the notarization  process for it.  On this topic, **I have not applied a cert for the windows binary**, so you'll probably get some kind of warning - this would happen with any binary that doesn't have a cert and the warning will be something about an \"unknown organization\" or something like that (I don't use windows)\n\n**Can it download {INSERT SOMETHING HERE}** I don't know, maybe?  Try it and see.  Being entirely a GUI, it can only do whatever yt-dlp can do.\n\n**Why should I use this vs something else?**: Maybe you shouldn't.  There's a ton of software like this out there, the /r/youtubedl subreddit has a wiki for GUI's that is rather extensive.  It's very possible that there's something else on that list that could better suit your needs and I 100% think you should check your options if you're looking for a tool like this.\n\nI hope you all are okay with me posting this here.  I really do not intend to be shilling software, but rather give an update and share it with anyone that may be interested.   My original post in this subrreddit is over at: [https://www.reddit.com/r/DataHoarder/comments/lmzgc8/stacher\\_a\\_modern\\_youtubedl\\_frontend/](https://www.reddit.com/r/DataHoarder/comments/lmzgc8/stacher_a_modern_youtubedl_frontend/)\n\n&amp;#x200B;\n\nReference links:\n\n* [https://stacher.io](https://stacher.io)\n* /r/stacherio\n* /r/youtubedl\n* [https://www.reddit.com/r/youtubedl/wiki/info-guis/](https://www.reddit.com/r/youtubedl/wiki/info-guis/). &lt;-- Other yt-dlp GUI's\n* [https://www.reddit.com/r/StacherIO/wiki/ffmpeg/](https://www.reddit.com/r/StacherIO/wiki/ffmpeg/)  &lt;-- Stacher/FFMPEG setup", "author_fullname": "t2_3zh4y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stacher version 6.0.20 (yt-dlp GUI)- Subscriptions and Minimize to Tray", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "media_metadata": {"173rsrot7evb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 67, "x": 108, "u": "https://preview.redd.it/173rsrot7evb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=afd5bbea1de23540e5241e8780841e7655cd3110"}, {"y": 135, "x": 216, "u": "https://preview.redd.it/173rsrot7evb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=dc419011e3205cbd3d601d69f883f62d62e8a3f0"}, {"y": 200, "x": 320, "u": "https://preview.redd.it/173rsrot7evb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=994cda4c927d721a4d2ac82721168ddcd057ccaa"}, {"y": 400, "x": 640, "u": "https://preview.redd.it/173rsrot7evb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=845290d228655ebb02777acccd6a09ae28c77d34"}, {"y": 600, "x": 960, "u": "https://preview.redd.it/173rsrot7evb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f302d0c356ee3e68cf4f9b64078494cdf6cca3bc"}, {"y": 675, "x": 1080, "u": "https://preview.redd.it/173rsrot7evb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8ec226506e75c48830b2caac0c70a11c70369744"}], "s": {"y": 1290, "x": 2064, "u": "https://preview.redd.it/173rsrot7evb1.png?width=2064&amp;format=png&amp;auto=webp&amp;s=83a309475f037270e4030262112d7d13765b7c4a"}, "id": "173rsrot7evb1"}}, "name": "t3_17ccw5m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Nm-9rOmVNljmpBL96Ff9n6hBiZhIotnV22aNUDyNK3M.jpg", "edited": 1697823175.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697812923.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I don&amp;#39;t post here regularly on this topic because I don&amp;#39;t like &amp;quot;pushing&amp;quot; my software.  I did post here years ago when I first launched Stacher, a hobby project started during the pandemic, looking for feedback.  Since then, I&amp;#39;ve taken your feedback and been working off and on to make it more stable and implement the features that were suggested.&lt;/p&gt;\n\n&lt;p&gt;Recently, Subscriptions and &amp;quot;Minimize to Tray&amp;quot; were added which was something many of you in this subreddit had asked me about and the motivation for this post.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/173rsrot7evb1.png?width=2064&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=83a309475f037270e4030262112d7d13765b7c4a\"&gt;https://preview.redd.it/173rsrot7evb1.png?width=2064&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=83a309475f037270e4030262112d7d13765b7c4a&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;For those who don&amp;#39;t know, Stacher is a frontend/GUI to the yt-dlp command line utility and provides the following features:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Clean UI for Mac and Windows&lt;/li&gt;\n&lt;li&gt;UI Controls for subtitles, different format selection, post processing options, playlists, etc&lt;/li&gt;\n&lt;li&gt;Because Stacher is essentially a CLI builder, you can use &lt;code&gt;ctrl&lt;/code&gt;+&lt;code&gt;enter&lt;/code&gt; after pasting a url to modify the command line directly which allows you to add any arguments that yt-dlp supports that aren&amp;#39;t surfaced in Stacher.&lt;/li&gt;\n&lt;li&gt;Clip Cropping.  Admittedly a pretty basic tool, but provides little sliders to crop only a section of media &lt;em&gt;before&lt;/em&gt; downloading&lt;/li&gt;\n&lt;li&gt;Clipboard listener that detects valid URL&amp;#39;s and auto starts downloading (this has to manually be enabled each time you start Stacher - it will not save this setting)&lt;/li&gt;\n&lt;li&gt;Subscriptions allow you to automatically handle playlist or channel monitoring at regular intervals&lt;/li&gt;\n&lt;li&gt;Minimize to tray keeps stacher out of the way.  On Mac, you can drag links onto the tray icon&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Stacher is available at &lt;a href=\"https://stacher.io\"&gt;https://stacher.io&lt;/a&gt; and there is a subreddit for it over at &lt;a href=\"/r/stacherio\"&gt;/r/stacherio&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;inb4: some questions that I know will come up -&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Does yt-dlp/ffmpeg come with it?&lt;/strong&gt;: Stacher will automatically setup yt-dlp.  There is a menu option to do this as well.  FFMPEG &lt;em&gt;does not&lt;/em&gt; come with stacher, you have to set this up manually if you want it.  There is a wiki on it in the stacher subreddit but it&amp;#39;s essentially the same process required for using yt-dlp&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is Stacher open source?&lt;/strong&gt;: It is not right now.  This project has always been a hobby project and the repo is a mess - cleaning it up is something I always push to the side.  I didn&amp;#39;t intend to share it early on and wasn&amp;#39;t really planning/thinking about it being open.  I totally get if you don&amp;#39;t want to check it out for this reason.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is it available on linux?&lt;/strong&gt; Every time I cut a release, I test mainly on mac and windows.  I do have unreleased 6.0.20 versions for debian that I still need to test.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Is there a Mac M1 version instead of just intel?&lt;/strong&gt; Similarly, I have the binary and it&amp;#39;s better tested, but I need to apply the certs and go through the notarization  process for it.  On this topic, &lt;strong&gt;I have not applied a cert for the windows binary&lt;/strong&gt;, so you&amp;#39;ll probably get some kind of warning - this would happen with any binary that doesn&amp;#39;t have a cert and the warning will be something about an &amp;quot;unknown organization&amp;quot; or something like that (I don&amp;#39;t use windows)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Can it download {INSERT SOMETHING HERE}&lt;/strong&gt; I don&amp;#39;t know, maybe?  Try it and see.  Being entirely a GUI, it can only do whatever yt-dlp can do.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why should I use this vs something else?&lt;/strong&gt;: Maybe you shouldn&amp;#39;t.  There&amp;#39;s a ton of software like this out there, the &lt;a href=\"/r/youtubedl\"&gt;/r/youtubedl&lt;/a&gt; subreddit has a wiki for GUI&amp;#39;s that is rather extensive.  It&amp;#39;s very possible that there&amp;#39;s something else on that list that could better suit your needs and I 100% think you should check your options if you&amp;#39;re looking for a tool like this.&lt;/p&gt;\n\n&lt;p&gt;I hope you all are okay with me posting this here.  I really do not intend to be shilling software, but rather give an update and share it with anyone that may be interested.   My original post in this subrreddit is over at: &lt;a href=\"https://www.reddit.com/r/DataHoarder/comments/lmzgc8/stacher_a_modern_youtubedl_frontend/\"&gt;https://www.reddit.com/r/DataHoarder/comments/lmzgc8/stacher_a_modern_youtubedl_frontend/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Reference links:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://stacher.io\"&gt;https://stacher.io&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"/r/stacherio\"&gt;/r/stacherio&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"/r/youtubedl\"&gt;/r/youtubedl&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.reddit.com/r/youtubedl/wiki/info-guis/\"&gt;https://www.reddit.com/r/youtubedl/wiki/info-guis/&lt;/a&gt;. &amp;lt;-- Other yt-dlp GUI&amp;#39;s&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://www.reddit.com/r/StacherIO/wiki/ffmpeg/\"&gt;https://www.reddit.com/r/StacherIO/wiki/ffmpeg/&lt;/a&gt;  &amp;lt;-- Stacher/FFMPEG setup&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ccw5m", "is_robot_indexable": true, "report_reasons": null, "author": "shiftysnowman", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ccw5m/stacher_version_6020_ytdlp_gui_subscriptions_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ccw5m/stacher_version_6020_ytdlp_gui_subscriptions_and/", "subreddit_subscribers": 707691, "created_utc": 1697812923.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everybody, so I am re-organizing my data backup now and purchased a few drives for redundancy as well. What I was wondering is, how to you structure and build your backup? What would you do without buying a NAS or whatever :)   \nMy issue is: \n\nI now got around 7,5TB of Data, that I need to backup regularly. The data types are (very simple speaking)   \n\n\n* family stuff + personal documents (500GB (size is 1TB)) \n* music and audio files / recordings (2TB)\n* video files / recordings (4TB)\n* movie files / recordings (1TB)\n\nThis is also the current structure. Each \"type\" is on an external drive. Those are backed up onto a second hard drive the same size. And the most important personal files are also encrypted in a cloud. The personal stuff might also be burned on blu rays soon.   \n\n\nI bought myself a 8TB Seagate One Touch Hub now as well. My ideas would be:   \n\n\na) Use the Hub (connected to the computer) as extended space, give every data types their own space on there, work on that and then back up to smaller hard drives organized by the structure above.   \n\n\nOr...  \nb) Use external drives to work on, connected to the computer, and backup all on the HUB regularly.   \n\n\nLet me know what you think? What would be your ideas? ", "author_fullname": "t2_8mefawmx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organizing your data / backups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c4ded", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697782364.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody, so I am re-organizing my data backup now and purchased a few drives for redundancy as well. What I was wondering is, how to you structure and build your backup? What would you do without buying a NAS or whatever :)&lt;br/&gt;\nMy issue is: &lt;/p&gt;\n\n&lt;p&gt;I now got around 7,5TB of Data, that I need to backup regularly. The data types are (very simple speaking)   &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;family stuff + personal documents (500GB (size is 1TB)) &lt;/li&gt;\n&lt;li&gt;music and audio files / recordings (2TB)&lt;/li&gt;\n&lt;li&gt;video files / recordings (4TB)&lt;/li&gt;\n&lt;li&gt;movie files / recordings (1TB)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This is also the current structure. Each &amp;quot;type&amp;quot; is on an external drive. Those are backed up onto a second hard drive the same size. And the most important personal files are also encrypted in a cloud. The personal stuff might also be burned on blu rays soon.   &lt;/p&gt;\n\n&lt;p&gt;I bought myself a 8TB Seagate One Touch Hub now as well. My ideas would be:   &lt;/p&gt;\n\n&lt;p&gt;a) Use the Hub (connected to the computer) as extended space, give every data types their own space on there, work on that and then back up to smaller hard drives organized by the structure above.   &lt;/p&gt;\n\n&lt;p&gt;Or...&lt;br/&gt;\nb) Use external drives to work on, connected to the computer, and backup all on the HUB regularly.   &lt;/p&gt;\n\n&lt;p&gt;Let me know what you think? What would be your ideas? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c4ded", "is_robot_indexable": true, "report_reasons": null, "author": "kollektivintim", "discussion_type": null, "num_comments": 11, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c4ded/organizing_your_data_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c4ded/organizing_your_data_backups/", "subreddit_subscribers": 707691, "created_utc": 1697782364.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\nWhat program is everyone using to generate checksums for their files?\nI have thousands of files in folders that I need to generate checksums for, but doing it individually is not realistic.\n\nIs there a windows program (preferably with a GUI for convenience) by any chance that can calculate checksums for entire folders of files and dump that to a text file (or something similar), then in the future be able to ingest that text file to verify all the checksums semi-automatically?\n\nThank you", "author_fullname": "t2_3j9dm7sj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best bulk/folder checksum utility for windows?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c9esq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697802589.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nWhat program is everyone using to generate checksums for their files?\nI have thousands of files in folders that I need to generate checksums for, but doing it individually is not realistic.&lt;/p&gt;\n\n&lt;p&gt;Is there a windows program (preferably with a GUI for convenience) by any chance that can calculate checksums for entire folders of files and dump that to a text file (or something similar), then in the future be able to ingest that text file to verify all the checksums semi-automatically?&lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c9esq", "is_robot_indexable": true, "report_reasons": null, "author": "NWSpitfire", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c9esq/best_bulkfolder_checksum_utility_for_windows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c9esq/best_bulkfolder_checksum_utility_for_windows/", "subreddit_subscribers": 707691, "created_utc": 1697802589.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I am new to BD, but I would like to archive some of my data. I am looking for a Disc that has a good quality / price ratio. I know M-DISC is the best, but that costs about 5x as much. \n\nWhat is the life expectancy of a disc like this (VERBATIM BD-R SL DataLife)?  \nTo me, if the disc works for a good 20-30 years I'd say it is good, but if it will lose data after a few years, it seems pointless for backup purposes. I'd like to know what to expect for this price range.", "author_fullname": "t2_2xftem1h", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How good/bad is VERBATIM BD-R SL DataLife 25GB ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c6tqt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697792862.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am new to BD, but I would like to archive some of my data. I am looking for a Disc that has a good quality / price ratio. I know M-DISC is the best, but that costs about 5x as much. &lt;/p&gt;\n\n&lt;p&gt;What is the life expectancy of a disc like this (VERBATIM BD-R SL DataLife)?&lt;br/&gt;\nTo me, if the disc works for a good 20-30 years I&amp;#39;d say it is good, but if it will lose data after a few years, it seems pointless for backup purposes. I&amp;#39;d like to know what to expect for this price range.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c6tqt", "is_robot_indexable": true, "report_reasons": null, "author": "Leonhardt90", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c6tqt/how_goodbad_is_verbatim_bdr_sl_datalife_25gb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c6tqt/how_goodbad_is_verbatim_bdr_sl_datalife_25gb/", "subreddit_subscribers": 707691, "created_utc": 1697792862.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello all, I'm in a bit of a pickle.  I currently have two 16TB HDD mirrored in TrueNAS and am almost at capacity.  I recently picked up two more 16TB but I'm not sure what RAID configuration I should use and how to set it up without losing data from my existing mirror.  \n\nI do also have a separate machine with a 16TB I use for backup, so i can copy everything over again if I had to lose my data on the mirror, just would prefer not to have to copy 16TB of data over my network.  \n\nAnybody have any good suggestions, can I expand my current pool with the new drives?  I assume I can't really since a mirror is usually two drives, it seems like I will have to create a new RAID and copy everything over, but I would love some opinions.  Thanks!", "author_fullname": "t2_b3tdw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TrueNAS raid configuration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bu2ao", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697750592.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, I&amp;#39;m in a bit of a pickle.  I currently have two 16TB HDD mirrored in TrueNAS and am almost at capacity.  I recently picked up two more 16TB but I&amp;#39;m not sure what RAID configuration I should use and how to set it up without losing data from my existing mirror.  &lt;/p&gt;\n\n&lt;p&gt;I do also have a separate machine with a 16TB I use for backup, so i can copy everything over again if I had to lose my data on the mirror, just would prefer not to have to copy 16TB of data over my network.  &lt;/p&gt;\n\n&lt;p&gt;Anybody have any good suggestions, can I expand my current pool with the new drives?  I assume I can&amp;#39;t really since a mirror is usually two drives, it seems like I will have to create a new RAID and copy everything over, but I would love some opinions.  Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bu2ao", "is_robot_indexable": true, "report_reasons": null, "author": "slash65", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bu2ao/truenas_raid_configuration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bu2ao/truenas_raid_configuration/", "subreddit_subscribers": 707691, "created_utc": 1697750592.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just installed a 9211-8i (Dell H310) in IT mode.\n\n It has tested fine however when shutting down Windows the one drive I had hooked up to it made the loud spin down whine my Exos drives make when performing a dreaded hard shutdown.\n\nIs there a spindown before shutdown setting I am missing for for drives attached via LSI HBA?", "author_fullname": "t2_vc6ecyv0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LSI HBA hard shutting down drives?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17btp07", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697756956.0, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697749685.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just installed a 9211-8i (Dell H310) in IT mode.&lt;/p&gt;\n\n&lt;p&gt;It has tested fine however when shutting down Windows the one drive I had hooked up to it made the loud spin down whine my Exos drives make when performing a dreaded hard shutdown.&lt;/p&gt;\n\n&lt;p&gt;Is there a spindown before shutdown setting I am missing for for drives attached via LSI HBA?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "74TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17btp07", "is_robot_indexable": true, "report_reasons": null, "author": "RileyKennels", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17btp07/lsi_hba_hard_shutting_down_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17btp07/lsi_hba_hard_shutting_down_drives/", "subreddit_subscribers": 707691, "created_utc": 1697749685.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve seen conflicting reports and can\u2019t find a definitive answer on this. Can anyone confirm that these HBA\u2019s work in IT mode with 4Kn-only SAS drives (ie., no 512e)?", "author_fullname": "t2_6kv2k2lv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "LSI 9211-8i with 4Kn", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17cjzwj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697831985.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve seen conflicting reports and can\u2019t find a definitive answer on this. Can anyone confirm that these HBA\u2019s work in IT mode with 4Kn-only SAS drives (ie., no 512e)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17cjzwj", "is_robot_indexable": true, "report_reasons": null, "author": "Lucretius_5102", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17cjzwj/lsi_92118i_with_4kn/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17cjzwj/lsi_92118i_with_4kn/", "subreddit_subscribers": 707691, "created_utc": 1697831985.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently bought sfp+ mellanox cards / cables / switch. I thought this was rare to get high tech stuff, turns out it's cheaper than RJ45 for 10g", "author_fullname": "t2_uk0ud", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "that felt nice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "setups", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": true, "name": "t3_17cjcz2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": "265b199a-b98c-11e2-8300-12313b0b21ae", "is_original_content": false, "user_reports": [], "secure_media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/ddlqtbhysevb1/DASH_1080.mp4?source=fallback", "height": 1920, "width": 1080, "scrubber_media_url": "https://v.redd.it/ddlqtbhysevb1/DASH_96.mp4", "dash_url": "https://v.redd.it/ddlqtbhysevb1/DASHPlaylist.mpd?a=1700426314%2CMjMwNDVhMjNmMjI4MTk4YTUzNjQxZDkzN2VkNzMzZDI0OWQ3MmJkM2IyMDc0Y2NhYTgxYzQwNDBmZWJiOGM0OA%3D%3D&amp;v=1&amp;f=sd", "duration": 2, "hls_url": "https://v.redd.it/ddlqtbhysevb1/HLSPlaylist.m3u8?a=1700426314%2CNzU4Zjc2ZWFmZmJmMjg3YjhlZDY4ZmRiMDc4MDA4NmMzYTVhMTZiZDgwNDc1NDk3ZmVlZTA4OTgzYzJiOTk1Nw%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Hoarder-Setups", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://external-preview.redd.it/dnMwaTVyOHlzZXZiMV8wPSqulmX-nCcjQLyAJhde-akY9QWaE5WxrMDIqPRY.png?width=140&amp;height=140&amp;crop=140:140,smart&amp;format=jpg&amp;v=enabled&amp;lthumb=true&amp;s=f8b13d3778bed1caade0b4e2efb83913d0821f23", "edited": false, "author_flair_css_class": "cloud", "author_flair_richtext": [], "gildings": {}, "post_hint": "hosted:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697830227.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "v.redd.it", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently bought sfp+ mellanox cards / cables / switch. I thought this was rare to get high tech stuff, turns out it&amp;#39;s cheaper than RJ45 for 10g&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://v.redd.it/ddlqtbhysevb1", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/dnMwaTVyOHlzZXZiMV8wPSqulmX-nCcjQLyAJhde-akY9QWaE5WxrMDIqPRY.png?format=pjpg&amp;auto=webp&amp;s=f2dff39a5047d94713f09994f227099032ca4904", "width": 954, "height": 1697}, "resolutions": [{"url": "https://external-preview.redd.it/dnMwaTVyOHlzZXZiMV8wPSqulmX-nCcjQLyAJhde-akY9QWaE5WxrMDIqPRY.png?width=108&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=fa4343d80df559243c21d23c389eaea23d9b0e9d", "width": 108, "height": 192}, {"url": "https://external-preview.redd.it/dnMwaTVyOHlzZXZiMV8wPSqulmX-nCcjQLyAJhde-akY9QWaE5WxrMDIqPRY.png?width=216&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=8979d2723bead3a105e0a3f1c72b12d0b199dcdf", "width": 216, "height": 384}, {"url": "https://external-preview.redd.it/dnMwaTVyOHlzZXZiMV8wPSqulmX-nCcjQLyAJhde-akY9QWaE5WxrMDIqPRY.png?width=320&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=b6acb87dd2c3b7ca0b3cf40b1fd99bc75622bf60", "width": 320, "height": 569}, {"url": "https://external-preview.redd.it/dnMwaTVyOHlzZXZiMV8wPSqulmX-nCcjQLyAJhde-akY9QWaE5WxrMDIqPRY.png?width=640&amp;crop=smart&amp;format=pjpg&amp;auto=webp&amp;s=9dba21db699d677e6468fbc914f207e40e0bbe64", "width": 640, "height": 1138}], "variants": {}, "id": "dnMwaTVyOHlzZXZiMV8wPSqulmX-nCcjQLyAJhde-akY9QWaE5WxrMDIqPRY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "d14a812c-b94e-11eb-b72a-0ee8a79b8cab", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "4x20T raid5 10g sfp+", "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17cjcz2", "is_robot_indexable": true, "report_reasons": null, "author": "Mabymaster", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/17cjcz2/that_felt_nice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://v.redd.it/ddlqtbhysevb1", "subreddit_subscribers": 707691, "created_utc": 1697830227.0, "num_crossposts": 0, "media": {"reddit_video": {"bitrate_kbps": 5000, "fallback_url": "https://v.redd.it/ddlqtbhysevb1/DASH_1080.mp4?source=fallback", "height": 1920, "width": 1080, "scrubber_media_url": "https://v.redd.it/ddlqtbhysevb1/DASH_96.mp4", "dash_url": "https://v.redd.it/ddlqtbhysevb1/DASHPlaylist.mpd?a=1700426314%2CMjMwNDVhMjNmMjI4MTk4YTUzNjQxZDkzN2VkNzMzZDI0OWQ3MmJkM2IyMDc0Y2NhYTgxYzQwNDBmZWJiOGM0OA%3D%3D&amp;v=1&amp;f=sd", "duration": 2, "hls_url": "https://v.redd.it/ddlqtbhysevb1/HLSPlaylist.m3u8?a=1700426314%2CNzU4Zjc2ZWFmZmJmMjg3YjhlZDY4ZmRiMDc4MDA4NmMzYTVhMTZiZDgwNDc1NDk3ZmVlZTA4OTgzYzJiOTk1Nw%3D%3D&amp;v=1&amp;f=sd", "is_gif": false, "transcoding_status": "completed"}}, "is_video": true}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I convert VHS from thrift stores, home movies and previous blanks with commercials etc, and more often than not the audio has static or hums. I\u2019ve tried to use Audacity or audio filters in video editing software, but each have their issues with dulling the audio in the process. \n\nDoes anyone have any recommendations for software they really like or perhaps specific settings they find works best?", "author_fullname": "t2_avxbriy4q", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cleaning poor VHS audio", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17cdnyh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697814959.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I convert VHS from thrift stores, home movies and previous blanks with commercials etc, and more often than not the audio has static or hums. I\u2019ve tried to use Audacity or audio filters in video editing software, but each have their issues with dulling the audio in the process. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any recommendations for software they really like or perhaps specific settings they find works best?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17cdnyh", "is_robot_indexable": true, "report_reasons": null, "author": "-Joby-", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17cdnyh/cleaning_poor_vhs_audio/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17cdnyh/cleaning_poor_vhs_audio/", "subreddit_subscribers": 707691, "created_utc": 1697814959.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking into compression formats right now, and while a lot of people swear by 7zip and Zstandard, I'm wondering if there are stronger options out there. I know ZPAQ Ultra from PeaZip can often provide higher compression ratios and it's an open format. Are there any other options I should be awawre of?", "author_fullname": "t2_6xot8zib", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What file compression format/algorithm has the best compression ratios (mainly for binary files of various types)? Compression and decompression time is irrelevant as this is for cold storage, and I have 36 GB of RAM.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17cdnsu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.53, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697814947.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking into compression formats right now, and while a lot of people swear by 7zip and Zstandard, I&amp;#39;m wondering if there are stronger options out there. I know ZPAQ Ultra from PeaZip can often provide higher compression ratios and it&amp;#39;s an open format. Are there any other options I should be awawre of?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17cdnsu", "is_robot_indexable": true, "report_reasons": null, "author": "ArcticCircleSystem", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17cdnsu/what_file_compression_formatalgorithm_has_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17cdnsu/what_file_compression_formatalgorithm_has_the/", "subreddit_subscribers": 707691, "created_utc": 1697814947.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "as in title   \ni searched this subreddit but those softs that i found dont work on livestreams ony videos  \ni have 650+ livestreams to download aaaand as it is possible to download it will take too much time   \nis there any way to speed things up ? ", "author_fullname": "t2_42smabc6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mass youtube livestreams downloading software", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ccyg4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697813108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;as in title&lt;br/&gt;\ni searched this subreddit but those softs that i found dont work on livestreams ony videos&lt;br/&gt;\ni have 650+ livestreams to download aaaand as it is possible to download it will take too much time&lt;br/&gt;\nis there any way to speed things up ? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17ccyg4", "is_robot_indexable": true, "report_reasons": null, "author": "ghostplx", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17ccyg4/mass_youtube_livestreams_downloading_software/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17ccyg4/mass_youtube_livestreams_downloading_software/", "subreddit_subscribers": 707691, "created_utc": 1697813108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey everybody, so I am re-organizing my data backup now and purchased a few drives for redundancy as well. What I was wondering is, how to you structure and build your backup? What would you do without buying a NAS or whatever :)   \nMy issue is: \n\nI now got around 7,5TB of Data, that I need to backup regularly. The data types are (very simple speaking)   \n\n\n* family stuff + personal documents (500GB (size is 1TB)) \n* music and audio files / recordings (2TB)\n* video files / recordings (4TB)\n* movie files / recordings (1TB)\n\nThis is also the current structure. Each \"type\" is on an external drive. Those are backed up onto a second hard drive the same size. And the most important personal files are also encrypted in a cloud. The personal stuff might also be burned on blu rays soon.   \n\n\nI bought myself a 8TB Seagate One Touch Hub now as well. My ideas would be:   \n\n\na) Use the Hub (connected to the computer) as extended space, give every data types their own space on there, work on that and then back up to smaller hard drives organized by the structure above.   \n\n\nOr...  \nb) Use external drives to work on, connected to the computer, and backup all on the HUB regularly.   \n\n\nLet me know what you think? What would be your ideas? ", "author_fullname": "t2_8mefawmx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organizing your data / backups", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "guide", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c4dds", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Guide/How-to", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697782361.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everybody, so I am re-organizing my data backup now and purchased a few drives for redundancy as well. What I was wondering is, how to you structure and build your backup? What would you do without buying a NAS or whatever :)&lt;br/&gt;\nMy issue is: &lt;/p&gt;\n\n&lt;p&gt;I now got around 7,5TB of Data, that I need to backup regularly. The data types are (very simple speaking)   &lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;family stuff + personal documents (500GB (size is 1TB)) &lt;/li&gt;\n&lt;li&gt;music and audio files / recordings (2TB)&lt;/li&gt;\n&lt;li&gt;video files / recordings (4TB)&lt;/li&gt;\n&lt;li&gt;movie files / recordings (1TB)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;This is also the current structure. Each &amp;quot;type&amp;quot; is on an external drive. Those are backed up onto a second hard drive the same size. And the most important personal files are also encrypted in a cloud. The personal stuff might also be burned on blu rays soon.   &lt;/p&gt;\n\n&lt;p&gt;I bought myself a 8TB Seagate One Touch Hub now as well. My ideas would be:   &lt;/p&gt;\n\n&lt;p&gt;a) Use the Hub (connected to the computer) as extended space, give every data types their own space on there, work on that and then back up to smaller hard drives organized by the structure above.   &lt;/p&gt;\n\n&lt;p&gt;Or...&lt;br/&gt;\nb) Use external drives to work on, connected to the computer, and backup all on the HUB regularly.   &lt;/p&gt;\n\n&lt;p&gt;Let me know what you think? What would be your ideas? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "69c7c050-b94e-11eb-9c9c-0eb6f39ede5f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c4dds", "is_robot_indexable": true, "report_reasons": null, "author": "kollektivintim", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c4dds/organizing_your_data_backups/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c4dds/organizing_your_data_backups/", "subreddit_subscribers": 707691, "created_utc": 1697782361.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "doesnt wanna load profiles and so laggy ", "author_fullname": "t2_86tkmqsl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "anyone knows what happened to TT sver ? its not working for me anymore .. and apparently they lowered the max download from 1000 to 100", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bsdsq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697746335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;doesnt wanna load profiles and so laggy &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bsdsq", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable42", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bsdsq/anyone_knows_what_happened_to_tt_sver_its_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bsdsq/anyone_knows_what_happened_to_tt_sver_its_not/", "subreddit_subscribers": 707691, "created_utc": 1697746335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Sure bandwidth is limited, bit how are iops behaving?", "author_fullname": "t2_80r87i4z", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Will a gen4 m.2 keep high iops inna gen3 slot?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c78qq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697794574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sure bandwidth is limited, bit how are iops behaving?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17c78qq", "is_robot_indexable": true, "report_reasons": null, "author": "PalmMallMars", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c78qq/will_a_gen4_m2_keep_high_iops_inna_gen3_slot/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c78qq/will_a_gen4_m2_keep_high_iops_inna_gen3_slot/", "subreddit_subscribers": 707691, "created_utc": 1697794574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey, i\u2019ve got a smaller collection of around 16tb of data across 2x8tb drives &amp; a 3tb drive. \n\nAll external drives connected via USB to an old macbook. it\u2019s a bit jallopy but i\u2019ve been using it as a setup for some of my work &amp; my partners photography &amp; videography for about 4 years. \n\nI\u2019ve got backblaze as my \u201coh cr*p\u201d i\u2019ve had a drive failure recovery solution. \n\nI was wondering is there a compression method to save some space for files which are truly not in need of retrieval often?", "author_fullname": "t2_n0af3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Part time data hoarder questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bsg3q", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697746507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey, i\u2019ve got a smaller collection of around 16tb of data across 2x8tb drives &amp;amp; a 3tb drive. &lt;/p&gt;\n\n&lt;p&gt;All external drives connected via USB to an old macbook. it\u2019s a bit jallopy but i\u2019ve been using it as a setup for some of my work &amp;amp; my partners photography &amp;amp; videography for about 4 years. &lt;/p&gt;\n\n&lt;p&gt;I\u2019ve got backblaze as my \u201coh cr*p\u201d i\u2019ve had a drive failure recovery solution. &lt;/p&gt;\n\n&lt;p&gt;I was wondering is there a compression method to save some space for files which are truly not in need of retrieval often?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bsg3q", "is_robot_indexable": true, "report_reasons": null, "author": "madragonn", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bsg3q/part_time_data_hoarder_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bsg3q/part_time_data_hoarder_questions/", "subreddit_subscribers": 707691, "created_utc": 1697746507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I'm upgrading my main machine hard drives.\n\nFor local backup I've been using external USBs. \n\nBut as I move my existing 4/8tb internal drives out of the server, I was thinking of using them as additional backup drives, but it seems usb/das enclosures are expensive, and it would actually be cheaper to just get rid of them.\n\n&amp;#x200B;\n\nDoes anyone know cheap ways to hook up a few old 4/8tb drives, or should I just admit they're not worth it and sell them off?", "author_fullname": "t2_2sr8ya35", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backup Pod", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17cass6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697807011.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;m upgrading my main machine hard drives.&lt;/p&gt;\n\n&lt;p&gt;For local backup I&amp;#39;ve been using external USBs. &lt;/p&gt;\n\n&lt;p&gt;But as I move my existing 4/8tb internal drives out of the server, I was thinking of using them as additional backup drives, but it seems usb/das enclosures are expensive, and it would actually be cheaper to just get rid of them.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Does anyone know cheap ways to hook up a few old 4/8tb drives, or should I just admit they&amp;#39;re not worth it and sell them off?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17cass6", "is_robot_indexable": true, "report_reasons": null, "author": "Frewtti", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17cass6/backup_pod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17cass6/backup_pod/", "subreddit_subscribers": 707691, "created_utc": 1697807011.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been putting off organizing and backing-up our family photos for a long, long time. Every time I try to create an organized system for storing photos, I just get discouraged because of all of the questions I have. Between my wife and I, we have 60,000+ photos and videos we would like organized and backed-up. It seems like everytime I look into this, my method generally boils down to saving and organizing all of our photos to an external HDD, then copying that to an additional HDD as well as backing it up in cloud storage (i.e. Google photos). Then I would repeat this process every 6 months by just adding the pictures taken since the last backup date. But the following questions always prevent me from getting started:\n\n1. **What format should I save my pictures in?** Aside from pictures taken professionally, all of our photos are from our phones and are JPG or HEIC, a lossy format. Most conversations on this topic recommend storing photos in a lossless format (TIFF or PNG), but I also see arguments being made to keep the file in its original, native format. Being as these are mostly from phone cameras, is it best to leave them as JPG/HEIC? Or will these lossy formats be less resilient and leave my family photos vulnerable to \u201cgeneration loss\u201d or \u201cbitrot\u201d? I believe a flipped bit on a compressed, lossy format is more likely to corrupt the entire image versus a lossless format that stores each pixel individually which only affects a single pixel.\n2. **Is there anything inherently wrong with using Google Drive as an integral part of my backup?** I see tons of people shitting on cloud storage on Google, but unsure why. Once I organize an HDD exactly how I want it, would it be out of the question to backup the HDD in its entirety to my Google Drive? Then at my next back-up date 6 months to 1 year later I can re-download the backup from Google to make updates to it? The rationale behind re-downloading is 1) it\u2019s difficult to edit/organize folders already saved into the cloud and 2) I justify using the backup on Google (as opposed to the physical HDDs) as the primary copy since it theoretically shouldn\u2019t succumb to bit rot or degradation. Once I add my newest photos and documents to the redownloaded backup, I would then save this overtop the old backups on the HDDs and re-upload the newest backup to Google.", "author_fullname": "t2_9z7s2rse", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What Format to Save Family Photos as for Long-term Storage? SO MANY QUESTIONS!!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17cadq6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697805723.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been putting off organizing and backing-up our family photos for a long, long time. Every time I try to create an organized system for storing photos, I just get discouraged because of all of the questions I have. Between my wife and I, we have 60,000+ photos and videos we would like organized and backed-up. It seems like everytime I look into this, my method generally boils down to saving and organizing all of our photos to an external HDD, then copying that to an additional HDD as well as backing it up in cloud storage (i.e. Google photos). Then I would repeat this process every 6 months by just adding the pictures taken since the last backup date. But the following questions always prevent me from getting started:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;strong&gt;What format should I save my pictures in?&lt;/strong&gt; Aside from pictures taken professionally, all of our photos are from our phones and are JPG or HEIC, a lossy format. Most conversations on this topic recommend storing photos in a lossless format (TIFF or PNG), but I also see arguments being made to keep the file in its original, native format. Being as these are mostly from phone cameras, is it best to leave them as JPG/HEIC? Or will these lossy formats be less resilient and leave my family photos vulnerable to \u201cgeneration loss\u201d or \u201cbitrot\u201d? I believe a flipped bit on a compressed, lossy format is more likely to corrupt the entire image versus a lossless format that stores each pixel individually which only affects a single pixel.&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;Is there anything inherently wrong with using Google Drive as an integral part of my backup?&lt;/strong&gt; I see tons of people shitting on cloud storage on Google, but unsure why. Once I organize an HDD exactly how I want it, would it be out of the question to backup the HDD in its entirety to my Google Drive? Then at my next back-up date 6 months to 1 year later I can re-download the backup from Google to make updates to it? The rationale behind re-downloading is 1) it\u2019s difficult to edit/organize folders already saved into the cloud and 2) I justify using the backup on Google (as opposed to the physical HDDs) as the primary copy since it theoretically shouldn\u2019t succumb to bit rot or degradation. Once I add my newest photos and documents to the redownloaded backup, I would then save this overtop the old backups on the HDDs and re-upload the newest backup to Google.&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17cadq6", "is_robot_indexable": true, "report_reasons": null, "author": "tgi-randy", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17cadq6/what_format_to_save_family_photos_as_for_longterm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17cadq6/what_format_to_save_family_photos_as_for_longterm/", "subreddit_subscribers": 707691, "created_utc": 1697805723.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "doesnt wanna load profiles and so laggy ", "author_fullname": "t2_86tkmqsl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "anyone knows what happened to TT sver ? its not working for me anymore .. and apparently they lowered the max download from 1000 to 100", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bsdsx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697746336.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;doesnt wanna load profiles and so laggy &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bsdsx", "is_robot_indexable": true, "report_reasons": null, "author": "Acceptable42", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bsdsx/anyone_knows_what_happened_to_tt_sver_its_not/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bsdsx/anyone_knows_what_happened_to_tt_sver_its_not/", "subreddit_subscribers": 707691, "created_utc": 1697746336.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi r/DataHoarder :)\n\nOk, I don't use NAS  and seeding torrents, just save/archive.\n\nAs in the title, can I buy a size of 20 TB or more but not NAS, and what is the right choice for me? As you know, I love to save movies, tv, games, books, etc. I want to stay without a network for a while (this is my belief that a regular storage is better, as if it were a new storage, just save and finish, unlike NAS who start it and maybe it crashes for years).\n\nOf course, backup copies must be made to a second disk of the same size or larger.\n\nI am worried that storage may not be in the future for a long time. There are new products. I don\u2019t know whether to buy it now or wait.\n\nIn short: I like to keep things and use them later.\n\nThis is a general discussion, you can share even if it is different, I am welcome any time.\n\nThank you very much!", "author_fullname": "t2_56zpr3td", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are the new products for storage? What are the things to avoid?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17c41ej", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697781055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;a href=\"/r/DataHoarder\"&gt;r/DataHoarder&lt;/a&gt; :)&lt;/p&gt;\n\n&lt;p&gt;Ok, I don&amp;#39;t use NAS  and seeding torrents, just save/archive.&lt;/p&gt;\n\n&lt;p&gt;As in the title, can I buy a size of 20 TB or more but not NAS, and what is the right choice for me? As you know, I love to save movies, tv, games, books, etc. I want to stay without a network for a while (this is my belief that a regular storage is better, as if it were a new storage, just save and finish, unlike NAS who start it and maybe it crashes for years).&lt;/p&gt;\n\n&lt;p&gt;Of course, backup copies must be made to a second disk of the same size or larger.&lt;/p&gt;\n\n&lt;p&gt;I am worried that storage may not be in the future for a long time. There are new products. I don\u2019t know whether to buy it now or wait.&lt;/p&gt;\n\n&lt;p&gt;In short: I like to keep things and use them later.&lt;/p&gt;\n\n&lt;p&gt;This is a general discussion, you can share even if it is different, I am welcome any time.&lt;/p&gt;\n\n&lt;p&gt;Thank you very much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "17c41ej", "is_robot_indexable": true, "report_reasons": null, "author": "DrEaMs0123", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17c41ej/what_are_the_new_products_for_storage_what_are/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17c41ej/what_are_the_new_products_for_storage_what_are/", "subreddit_subscribers": 707691, "created_utc": 1697781055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, as I said I just bought 4x20TB HDD to make a new RAID 5 array and I am wondering if I should write data unevenly on 3 of them before doing the RAID 5 to use a little bit of their lifespan so they will not die at the same time or while rebuilding the RAID 5.The data I would write isn't important, it's only to reduce their lifespan.\n\nOn the first I write nothing.On the second I write 40TB.On the third I write 80TB.And on the forth I write 120TB.And only then I erase the data I just wrote and I make the RAID 5.\n\nIt's not very sensitive data, but if I can save me from a complete data loss of this RAID 5 it's cool.btw it's 4 Seagate Exos X20 of 20TB. May not be the best but it's cheap.\n\nIs it meaningless to do so or can it increases my chances of a clean rebuild if one of them fail?", "author_fullname": "t2_c94mw03d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I bought 4x20TB HDD for my RAID 5. Will they die at the same time", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bss87", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697768894.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697747380.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, as I said I just bought 4x20TB HDD to make a new RAID 5 array and I am wondering if I should write data unevenly on 3 of them before doing the RAID 5 to use a little bit of their lifespan so they will not die at the same time or while rebuilding the RAID 5.The data I would write isn&amp;#39;t important, it&amp;#39;s only to reduce their lifespan.&lt;/p&gt;\n\n&lt;p&gt;On the first I write nothing.On the second I write 40TB.On the third I write 80TB.And on the forth I write 120TB.And only then I erase the data I just wrote and I make the RAID 5.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not very sensitive data, but if I can save me from a complete data loss of this RAID 5 it&amp;#39;s cool.btw it&amp;#39;s 4 Seagate Exos X20 of 20TB. May not be the best but it&amp;#39;s cheap.&lt;/p&gt;\n\n&lt;p&gt;Is it meaningless to do so or can it increases my chances of a clean rebuild if one of them fail?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17bss87", "is_robot_indexable": true, "report_reasons": null, "author": "RAYTEKSO", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17bss87/i_bought_4x20tb_hdd_for_my_raid_5_will_they_die/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17bss87/i_bought_4x20tb_hdd_for_my_raid_5_will_they_die/", "subreddit_subscribers": 707691, "created_utc": 1697747380.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}