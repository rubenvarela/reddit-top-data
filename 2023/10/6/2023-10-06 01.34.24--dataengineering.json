{"kind": "Listing", "data": {"after": "t3_170wvxc", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "So I've got a task to consolidate the 'database' at work, into a proper database.\n\nIssues:\n1) The current database is 2584 Excel files, all with different structures and information, though they all have a unique key within them.\n2) Information within the document is in the wrong columns in some of of the files.\n3) I am not allowed to use scripts, except for vba coded in Access.\n4) Some of the files only contain some of the information, others double the same information, some are missing fields.\n\nAnyone have any tips? Spent a few hours on a it today to work out where the data was as the previous people left.", "author_fullname": "t2_gam51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Oh god why, Help Consolidating \"Excel\" Database 2584 files in 246 folders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170azqv", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696488301.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve got a task to consolidate the &amp;#39;database&amp;#39; at work, into a proper database.&lt;/p&gt;\n\n&lt;p&gt;Issues:\n1) The current database is 2584 Excel files, all with different structures and information, though they all have a unique key within them.\n2) Information within the document is in the wrong columns in some of of the files.\n3) I am not allowed to use scripts, except for vba coded in Access.\n4) Some of the files only contain some of the information, others double the same information, some are missing fields.&lt;/p&gt;\n\n&lt;p&gt;Anyone have any tips? Spent a few hours on a it today to work out where the data was as the previous people left.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170azqv", "is_robot_indexable": true, "report_reasons": null, "author": "CYOA_With_Hitler", "discussion_type": null, "num_comments": 79, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170azqv/oh_god_why_help_consolidating_excel_database_2584/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170azqv/oh_god_why_help_consolidating_excel_database_2584/", "subreddit_subscribers": 132300, "created_utc": 1696488301.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Apologies as my background isn't in DE but come more from BI systems administration. In my career I've seen a lot but the craziest thing I've seen is business users using email heavily to send Excel and CSV data dumps using BI tools...at a huge scale. Of course there are also some secure file transfers out there, stuff you would see with MoveIT and IBM Sterling, etc. Both of these models beg the question to me which is -- why do we need this?\n\nIs it literally just because our system doesn't have a reliable REST API to pull the data easily? Is REST that insecure? So instead we rely on the other party generating a CSV and sending it to us in batch like it's 1995? Couldn't a REST API send a CSV over HTTPS anyway? Do we not trust it?\n\nIs data integration really that dirty? What can be done to eliminate these file transfer overhead monsters? Is progress with good REST APIs just moving that slow?\n\nI feel like there's something I'm fundamentally misunderstanding but not sure what it is...", "author_fullname": "t2_6c2aryt5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is the reason SFTP file transfer in banks, healthcare, etc is so ubiquitous just because they are using older systems without robust REST APIs...?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170rvz3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 31, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 31, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696536440.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Apologies as my background isn&amp;#39;t in DE but come more from BI systems administration. In my career I&amp;#39;ve seen a lot but the craziest thing I&amp;#39;ve seen is business users using email heavily to send Excel and CSV data dumps using BI tools...at a huge scale. Of course there are also some secure file transfers out there, stuff you would see with MoveIT and IBM Sterling, etc. Both of these models beg the question to me which is -- why do we need this?&lt;/p&gt;\n\n&lt;p&gt;Is it literally just because our system doesn&amp;#39;t have a reliable REST API to pull the data easily? Is REST that insecure? So instead we rely on the other party generating a CSV and sending it to us in batch like it&amp;#39;s 1995? Couldn&amp;#39;t a REST API send a CSV over HTTPS anyway? Do we not trust it?&lt;/p&gt;\n\n&lt;p&gt;Is data integration really that dirty? What can be done to eliminate these file transfer overhead monsters? Is progress with good REST APIs just moving that slow?&lt;/p&gt;\n\n&lt;p&gt;I feel like there&amp;#39;s something I&amp;#39;m fundamentally misunderstanding but not sure what it is...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "170rvz3", "is_robot_indexable": true, "report_reasons": null, "author": "TheWikiJedi", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170rvz3/is_the_reason_sftp_file_transfer_in_banks/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170rvz3/is_the_reason_sftp_file_transfer_in_banks/", "subreddit_subscribers": 132300, "created_utc": 1696536440.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_fb83g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Microsoft Fabric: Should Databricks be Worried?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 83, "top_awarded_type": null, "hide_score": false, "name": "t3_170otm0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/KqfXrZoRthY9_0rKj5OFsfqYtxhzW4XWdZseyT5_NcY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696529189.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "vantage.sh", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.vantage.sh/blog/databricks-vs-microsoft-fabric-pricing-analysis", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?auto=webp&amp;s=af663ae0121ce0a4793363094c1fec8259eefa84", "width": 1270, "height": 760}, "resolutions": [{"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=57e13db27e90db4e7152be7e631452a796c7297a", "width": 108, "height": 64}, {"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=deb5668b38d81175fea57b520a0c5c713c6d7ce9", "width": 216, "height": 129}, {"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6222d395bbc71108823edfc2628acb961c3bb0cf", "width": 320, "height": 191}, {"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0fe04e60e1c5b79f9154ec4a8193c93ba8b7c109", "width": 640, "height": 382}, {"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6f33a26035314d4789bc40760d8a6abb6837980b", "width": 960, "height": 574}, {"url": "https://external-preview.redd.it/fF1rTjn5aYUAQ1MqXyCQYpcmOelAg0OvRV-1i6o4ntg.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=394a654d23b5732bcba1b7573a3fc9a6da6897e6", "width": 1080, "height": 646}], "variants": {}, "id": "KJGb3So15RCrofadobr6rSw5w7wrNTNiPNLXDBWpF8o"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "170otm0", "is_robot_indexable": true, "report_reasons": null, "author": "include_stdio_h", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170otm0/microsoft_fabric_should_databricks_be_worried/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.vantage.sh/blog/databricks-vs-microsoft-fabric-pricing-analysis", "subreddit_subscribers": 132300, "created_utc": 1696529189.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI\u2019m at a crossroads in my career and could really use some insight. I\u2019ve previously worked as a Data Analyst, and have now been presented with an opportunity to train in either Data Engineering or DevOps from scratch, courtesy of a company I\u2019m considering joining. I\u2019m intrigued by both roles but also drawn by the attractive pay scales I\u2019ve seen in the DevOps field.\n\nShould I stick closer to my roots with Data Engineering, or explore the dynamic world of DevOps? I\u2019d love to hear your experiences and perspectives.\n\nThanks in advance!", "author_fullname": "t2_8fi5ln6j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer vs Devops?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1709g07", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.96, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696482683.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I\u2019m at a crossroads in my career and could really use some insight. I\u2019ve previously worked as a Data Analyst, and have now been presented with an opportunity to train in either Data Engineering or DevOps from scratch, courtesy of a company I\u2019m considering joining. I\u2019m intrigued by both roles but also drawn by the attractive pay scales I\u2019ve seen in the DevOps field.&lt;/p&gt;\n\n&lt;p&gt;Should I stick closer to my roots with Data Engineering, or explore the dynamic world of DevOps? I\u2019d love to hear your experiences and perspectives.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1709g07", "is_robot_indexable": true, "report_reasons": null, "author": "sailor_Moon_Pie", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1709g07/data_engineer_vs_devops/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1709g07/data_engineer_vs_devops/", "subreddit_subscribers": 132300, "created_utc": 1696482683.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have worked with Data in some capacity for the last 5-6 years of my career. I am self-taught and have experience with SQL, Python and Bash (as well as specific tools and database engines like MSSQL, MariaDB, Vertica etc).  \n\n\nI code a lot of custom ETL jobs for my work, and have begun to wonder - \\*how\\* can I evaluate performance, especially to identify room for improvement. It's one thing to benchmark script 1 vs script 2, but its more difficult to have a sense of how quickly a given amount of data should load. Are there ways to check network latency, the available computational resources etc to establish a baseline of performance to aim for? What are the best tools for feeling this out, especially ones easily available to me given what I know - ie SQL, Bash, Python? I'm out of my depth here but want to improve and feel answering or otherwise understanding this question is a necessary next step.  \n\n\nFor the sake of this exercise lets assume the data is fairly simple - floats, integers, char/varchar etc rather than more complex or larger formats like CLOB/BLOB.", "author_fullname": "t2_3v8tq4ba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I know the extent to which ETLs *could* be running faster?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170lxza", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696522323.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have worked with Data in some capacity for the last 5-6 years of my career. I am self-taught and have experience with SQL, Python and Bash (as well as specific tools and database engines like MSSQL, MariaDB, Vertica etc).  &lt;/p&gt;\n\n&lt;p&gt;I code a lot of custom ETL jobs for my work, and have begun to wonder - *how* can I evaluate performance, especially to identify room for improvement. It&amp;#39;s one thing to benchmark script 1 vs script 2, but its more difficult to have a sense of how quickly a given amount of data should load. Are there ways to check network latency, the available computational resources etc to establish a baseline of performance to aim for? What are the best tools for feeling this out, especially ones easily available to me given what I know - ie SQL, Bash, Python? I&amp;#39;m out of my depth here but want to improve and feel answering or otherwise understanding this question is a necessary next step.  &lt;/p&gt;\n\n&lt;p&gt;For the sake of this exercise lets assume the data is fairly simple - floats, integers, char/varchar etc rather than more complex or larger formats like CLOB/BLOB.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170lxza", "is_robot_indexable": true, "report_reasons": null, "author": "vonkraush1010", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170lxza/how_do_i_know_the_extent_to_which_etls_could_be/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170lxza/how_do_i_know_the_extent_to_which_etls_could_be/", "subreddit_subscribers": 132300, "created_utc": 1696522323.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_5puh1cdh2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Kestra is an open source data orchestration platform for complex workflows", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 107, "top_awarded_type": null, "hide_score": false, "name": "t3_170dilo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/4H_RhvBn6ZNfOhZz_b6iWFeIJOUOreJeKrhxxrURA9Q.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696498135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "techcrunch.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://techcrunch.com/2023/10/04/kestra-is-an-open-source-data-orchestration-platform-for-complex-workflows/", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?auto=webp&amp;s=68660ca9d2b2000fe79db81cb2ff27fcaf11d5d0", "width": 1200, "height": 924}, "resolutions": [{"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4cbf10b9426b1446ce397550d2bb99977cbd8686", "width": 108, "height": 83}, {"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f7d2266da09a1653f16549c3925b92e431913dad", "width": 216, "height": 166}, {"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e45b049021ce097e55829c0c0d1effef3beca9bc", "width": 320, "height": 246}, {"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=fe1a09047d7920c0e5cb584222749b96794faf54", "width": 640, "height": 492}, {"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=9279d0089cd1d4431f2ee15542f58a4e6a80848e", "width": 960, "height": 739}, {"url": "https://external-preview.redd.it/W7KoAnNMcF3Zf4PwoTK9-rUiJd88i1j8HGCCkbrB8RQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=032caf5ea23a96b8879417feaf4dd73d47de7a83", "width": 1080, "height": 831}], "variants": {}, "id": "02Q-33t-h3gAREC-TESqt8J99md2QiL7EA9XzOYgtWo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "170dilo", "is_robot_indexable": true, "report_reasons": null, "author": "Merlich_RSt", "discussion_type": null, "num_comments": 2, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170dilo/kestra_is_an_open_source_data_orchestration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://techcrunch.com/2023/10/04/kestra-is-an-open-source-data-orchestration-platform-for-complex-workflows/", "subreddit_subscribers": 132300, "created_utc": 1696498135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was wondering if anyone here transitioned from DA into DE can share what they enjoy or don\u2019t enjoy after changing careers. What advice you would give yourself looking back?\n\nI recently transitioned out of a decade of  teaching in a public high school into data analysis. I was so burned out, and it almost impossible to get any interviews, despite having a BS in Math from a top university, and finishing a Data Science boot camp with top marks. I finally got a job, but I\u2019m also hitting a ceiling with data analyst positions- currently, I\u2019m getting paid $75k in Los Angeles. \n\nI do feel underpaid for how quickly I pick up and complete work. My boss estimates that I saved them 10 hours of weekly manual labor in my first quarter,  because I taught myself JavaScript to write simple lines to automate some reports in their business analysis software.\n\nMost of my technical work entails Python to clean and format data, and graphs in Tableau. I found myself doing a lot of project management because my team is nice, but not very organized, and sitting in on calls to translate what someone wants into code or graphs. Now I\u2019m wondering if it\u2019s just hubris, and I should be happy with my salary for the type of work I do\u2026\n\nI am comfortable picking up code, since I learned C++ in college. I use Python and SQL for personal projects and certificates, but I do not fully understand the statistics behind data science projects, nor do I enjoy it, and these positions require a master\u2019s, so I feel uncomfortable continuing in the data science direction.\n\nThe most intimidating part of DE is all the tools listed, and unfamiliarity with the jargon. I signed up for a DE course, because the external motivation is helpful with the burnout, so I will share updates if it\u2019s helpful! I noticed a free DE bootcamp in this community in January, so I will keep an eye out for that as well.", "author_fullname": "t2_jzdhrzu2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for a Data Analyst", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1707z40", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696477885.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was wondering if anyone here transitioned from DA into DE can share what they enjoy or don\u2019t enjoy after changing careers. What advice you would give yourself looking back?&lt;/p&gt;\n\n&lt;p&gt;I recently transitioned out of a decade of  teaching in a public high school into data analysis. I was so burned out, and it almost impossible to get any interviews, despite having a BS in Math from a top university, and finishing a Data Science boot camp with top marks. I finally got a job, but I\u2019m also hitting a ceiling with data analyst positions- currently, I\u2019m getting paid $75k in Los Angeles. &lt;/p&gt;\n\n&lt;p&gt;I do feel underpaid for how quickly I pick up and complete work. My boss estimates that I saved them 10 hours of weekly manual labor in my first quarter,  because I taught myself JavaScript to write simple lines to automate some reports in their business analysis software.&lt;/p&gt;\n\n&lt;p&gt;Most of my technical work entails Python to clean and format data, and graphs in Tableau. I found myself doing a lot of project management because my team is nice, but not very organized, and sitting in on calls to translate what someone wants into code or graphs. Now I\u2019m wondering if it\u2019s just hubris, and I should be happy with my salary for the type of work I do\u2026&lt;/p&gt;\n\n&lt;p&gt;I am comfortable picking up code, since I learned C++ in college. I use Python and SQL for personal projects and certificates, but I do not fully understand the statistics behind data science projects, nor do I enjoy it, and these positions require a master\u2019s, so I feel uncomfortable continuing in the data science direction.&lt;/p&gt;\n\n&lt;p&gt;The most intimidating part of DE is all the tools listed, and unfamiliarity with the jargon. I signed up for a DE course, because the external motivation is helpful with the burnout, so I will share updates if it\u2019s helpful! I noticed a free DE bootcamp in this community in January, so I will keep an eye out for that as well.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1707z40", "is_robot_indexable": true, "report_reasons": null, "author": "blurry_forest", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1707z40/advice_for_a_data_analyst/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1707z40/advice_for_a_data_analyst/", "subreddit_subscribers": 132300, "created_utc": 1696477885.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all!\n\nI joined a team a few months ago as a senior from working at prior orgs, doing heavy DE infra work and Python &amp; Scala based coding in cloud first architectures, with a mix of modern data stack work &amp; Spark/Big Data work with Databricks &amp; the like.\n\nI was tasked with building a new data platform centered around best practices &amp; automation, and have delivered on a platform incorporating Dagster, templated SQL (no DBT yet\u2026), and Python work for a DSL based YAML workflow.\n\nI\u2019ve been able to compile YAML into orchestrated jobs, create CI/CD, build the application and publish containers, and provide monitoring &amp; reporting. Currently, it is being UAT\u2019d, but I\u2019m running into roadblocks because my team does not come from a OOP background at all. My boss is a heavy scripting-on prem healthcare environment experience, my juniors either come from Powershell scripting IT based automation or from no experience but SQL as DAs:\n\nThey\u2019ve built solid data infra so far, but there is a lot of risk for breakage and limits in scalability. Ingestion is mainly handled through Fivetran or through legacy orchestration  (think PS &amp; the like), git is somewhat used, but it has no affect on what\u2019s running in production, no testing, all jobs are run through Snowflake tasks, and everybody on the team has AccountAdmin access. \n\nI\u2019m worried my project won\u2019t get given a full green light because of these traditions. Any idea on how to get around it and fully show value, and teach the team quickly as we continue to scale?", "author_fullname": "t2_3ixkfqzx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to present and explain SWE DE practices to a green team", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1704smu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "fbc7d3e6-ac9c-11eb-adda-0e0b12e4a59b", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696468808.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all!&lt;/p&gt;\n\n&lt;p&gt;I joined a team a few months ago as a senior from working at prior orgs, doing heavy DE infra work and Python &amp;amp; Scala based coding in cloud first architectures, with a mix of modern data stack work &amp;amp; Spark/Big Data work with Databricks &amp;amp; the like.&lt;/p&gt;\n\n&lt;p&gt;I was tasked with building a new data platform centered around best practices &amp;amp; automation, and have delivered on a platform incorporating Dagster, templated SQL (no DBT yet\u2026), and Python work for a DSL based YAML workflow.&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve been able to compile YAML into orchestrated jobs, create CI/CD, build the application and publish containers, and provide monitoring &amp;amp; reporting. Currently, it is being UAT\u2019d, but I\u2019m running into roadblocks because my team does not come from a OOP background at all. My boss is a heavy scripting-on prem healthcare environment experience, my juniors either come from Powershell scripting IT based automation or from no experience but SQL as DAs:&lt;/p&gt;\n\n&lt;p&gt;They\u2019ve built solid data infra so far, but there is a lot of risk for breakage and limits in scalability. Ingestion is mainly handled through Fivetran or through legacy orchestration  (think PS &amp;amp; the like), git is somewhat used, but it has no affect on what\u2019s running in production, no testing, all jobs are run through Snowflake tasks, and everybody on the team has AccountAdmin access. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m worried my project won\u2019t get given a full green light because of these traditions. Any idea on how to get around it and fully show value, and teach the team quickly as we continue to scale?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1704smu", "is_robot_indexable": true, "report_reasons": null, "author": "kharigardner", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/1704smu/how_to_present_and_explain_swe_de_practices_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1704smu/how_to_present_and_explain_swe_de_practices_to_a/", "subreddit_subscribers": 132300, "created_utc": 1696468808.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m currently working on a hobby project and am hoping to continuously stream some data from a web API into my Apache Kafka producer. I am currently using the Confluent Kafka library for python to write my producer and consumer and thus also intend for my API data retrieval to be written in Python as well. \n\n&amp;nbsp;\n\nIn terms of getting the data from the API my current solution is to do the following in a loop: 1. Send a GET request to the API with the requests library 2. Send the requested data to the Kafka producer 3. Add a sleep statement to not overwhelm the web server. \n\n&amp;nbsp;\n\nI was just wondering if this is the best way to get the data from the API or if there is a more elegant solution that I may not have considered? For example, I\u2019ve seen some Kafka code written in Java that uses the EventHandler class. I\u2019ve also looked into Pythons asyncio module but it doesn\u2019t look like there would be much benefit to using it when just getting data from a single API?", "author_fullname": "t2_5bha3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "More elegant solution to constantly get data from a web API?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1708lhd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696479847.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m currently working on a hobby project and am hoping to continuously stream some data from a web API into my Apache Kafka producer. I am currently using the Confluent Kafka library for python to write my producer and consumer and thus also intend for my API data retrieval to be written in Python as well. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;In terms of getting the data from the API my current solution is to do the following in a loop: 1. Send a GET request to the API with the requests library 2. Send the requested data to the Kafka producer 3. Add a sleep statement to not overwhelm the web server. &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;I was just wondering if this is the best way to get the data from the API or if there is a more elegant solution that I may not have considered? For example, I\u2019ve seen some Kafka code written in Java that uses the EventHandler class. I\u2019ve also looked into Pythons asyncio module but it doesn\u2019t look like there would be much benefit to using it when just getting data from a single API?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1708lhd", "is_robot_indexable": true, "report_reasons": null, "author": "GreenSquid", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1708lhd/more_elegant_solution_to_constantly_get_data_from/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1708lhd/more_elegant_solution_to_constantly_get_data_from/", "subreddit_subscribers": 132300, "created_utc": 1696479847.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I need to know which tools is used to generate software architectures infographics like this?\n\ndespite the specific tool used for the below image, are there any other suggested tools to use to generate instagram posts for software architectures?\n\nhttps://preview.redd.it/rz6zkck1edsb1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=4081daef291deffb4f657364b56e0d1f6aeb831b\n\n&amp;#x200B;\n\nOr like those ones with moving arrows:\n\nhttps://preview.redd.it/i0bcjzo2edsb1.png?width=664&amp;format=png&amp;auto=webp&amp;s=052e1fa1e95bc0c888967550d408b38b7c8348bf", "author_fullname": "t2_i2h7dt11", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to generate DE architectures infographics like this?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "media_metadata": {"i0bcjzo2edsb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 136, "x": 108, "u": "https://preview.redd.it/i0bcjzo2edsb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=9ad274224d642a1f04d329d789ca17a690197bc9"}, {"y": 273, "x": 216, "u": "https://preview.redd.it/i0bcjzo2edsb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=a32dac75a8f7ddb40296d81014a7e1a0176fada6"}, {"y": 404, "x": 320, "u": "https://preview.redd.it/i0bcjzo2edsb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=161e2388a3e03b632397d342752453405bb8a97e"}, {"y": 809, "x": 640, "u": "https://preview.redd.it/i0bcjzo2edsb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=35684e0291acc7b160023f26bc160737ca949f9e"}], "s": {"y": 840, "x": 664, "u": "https://preview.redd.it/i0bcjzo2edsb1.png?width=664&amp;format=png&amp;auto=webp&amp;s=052e1fa1e95bc0c888967550d408b38b7c8348bf"}, "id": "i0bcjzo2edsb1"}, "rz6zkck1edsb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 54, "x": 108, "u": "https://preview.redd.it/rz6zkck1edsb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=59bb85de32473e01c960ab4d63b56d4e37e8fbad"}, {"y": 108, "x": 216, "u": "https://preview.redd.it/rz6zkck1edsb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=78572a7173b010602688524cad958967ea82d918"}, {"y": 160, "x": 320, "u": "https://preview.redd.it/rz6zkck1edsb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=c01b34199162918c507f104806825efb0076f840"}, {"y": 320, "x": 640, "u": "https://preview.redd.it/rz6zkck1edsb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=0b0a66fc6ba2985615048798d2139eeff4cd09bd"}, {"y": 480, "x": 960, "u": "https://preview.redd.it/rz6zkck1edsb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=9b604b64517feb8ab9290764b3a999c837bc38b3"}], "s": {"y": 501, "x": 1000, "u": "https://preview.redd.it/rz6zkck1edsb1.png?width=1000&amp;format=png&amp;auto=webp&amp;s=4081daef291deffb4f657364b56e0d1f6aeb831b"}, "id": "rz6zkck1edsb1"}}, "name": "t3_170fmce", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/n6lrokxk-_bD0N6_4fXZZdw9HFpIupAhulJLEc-O-To.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696505613.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I need to know which tools is used to generate software architectures infographics like this?&lt;/p&gt;\n\n&lt;p&gt;despite the specific tool used for the below image, are there any other suggested tools to use to generate instagram posts for software architectures?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rz6zkck1edsb1.png?width=1000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4081daef291deffb4f657364b56e0d1f6aeb831b\"&gt;https://preview.redd.it/rz6zkck1edsb1.png?width=1000&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=4081daef291deffb4f657364b56e0d1f6aeb831b&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Or like those ones with moving arrows:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/i0bcjzo2edsb1.png?width=664&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=052e1fa1e95bc0c888967550d408b38b7c8348bf\"&gt;https://preview.redd.it/i0bcjzo2edsb1.png?width=664&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=052e1fa1e95bc0c888967550d408b38b7c8348bf&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170fmce", "is_robot_indexable": true, "report_reasons": null, "author": "Omar-Tech", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170fmce/how_to_generate_de_architectures_infographics/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170fmce/how_to_generate_de_architectures_infographics/", "subreddit_subscribers": 132300, "created_utc": 1696505613.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Posted this over in /r/Azure , but wanted to get yawls perspective too. \n\n  \nI  am looking to migrate off of dedicated sql pool - it is too expensive. We are currently using  azure synapse studio + dedicated sql pool + adl. here is some workflows  we do:\n\n1) incremental data loads from transnational sql databases. we load this data pretty much straight into the dwh.\n\n2) about  5-6 external sources we pull data via an API or maybe a excel  spreadsheet/csv for adhoc data from my customer facing teams. we load  the data from the external sources into our data lake. I just use azure  batch to execute python code that does this for me. from there we create  external tables to load them into our dedicated sql pool.\n\n3) once  all the data is loaded into the sql pool, we then do various  transformations and aggregations on the data, and store the results in  sql, which are then loaded into our PBI data model. The refreshes happen  1x per day, typically around 4am.\n\nthis  all being said, dedicated sql pools are SUPER expensive. I do like  being able to load the external sources directly into sql, so i was  thinking about migrating off of dedicated sql pool and just using  serverless sql in synapse. We would just export data from our  transactional sql databases onto the lake in parquet format. One of my  concerns with this is everything would essentially be views, as i dont  think you can create/manage the transformations using CTAS statements.  This doesnt seem like it would scale well as we continue to get more  data.\n\nHonestly, were around 266gb  of data total, so i wouldnt be opposed to just using sql, i think  dedicated sql pool is overkill. BUT,  i dont think azure SQL has all of  the virtualisation tech like serverless or dedicated sql pool has, and  my aggregations might take longer, but i think i can fine tune  a lot to  make that work (and azure sql database is MUCHHHH cheaper). If i look  at the pricing of azure sql server managed instance (which from my  understanding does have the virtualisation tech) its around the same as  the dedicated sql pool, so doesnt seem worth to me.\n\nhow  are ya'll doing this in a cost effective way? There are so many  buzzwords and buzz tech out there, im not sure what i should be looking at. The term Synapse is super confusing because it seems interchangable with serverless or dedicated sql pool, when it also can act as an orchestration tool. I seem a lot of people saying databricks + adl + datafactory is the  way to go, but then there is the added expensive of databricks and learning databricks.. I am  also a 1 man team on the reporting and data side, and i am also managing  another separate team on top of this (lol the tech recession is real).  point is, i feel very lost, and i dont want to spend a bunch of time migrating to a solution that wont scale or isnt cost effective. I appreciate any direction and advice you  fellow data engineers can give.\n\nThanks!", "author_fullname": "t2_jrmn04", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Solutions to migrate off of dedicated SQL Pool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170ltz3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696522062.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Posted this over in &lt;a href=\"/r/Azure\"&gt;/r/Azure&lt;/a&gt; , but wanted to get yawls perspective too. &lt;/p&gt;\n\n&lt;p&gt;I  am looking to migrate off of dedicated sql pool - it is too expensive. We are currently using  azure synapse studio + dedicated sql pool + adl. here is some workflows  we do:&lt;/p&gt;\n\n&lt;p&gt;1) incremental data loads from transnational sql databases. we load this data pretty much straight into the dwh.&lt;/p&gt;\n\n&lt;p&gt;2) about  5-6 external sources we pull data via an API or maybe a excel  spreadsheet/csv for adhoc data from my customer facing teams. we load  the data from the external sources into our data lake. I just use azure  batch to execute python code that does this for me. from there we create  external tables to load them into our dedicated sql pool.&lt;/p&gt;\n\n&lt;p&gt;3) once  all the data is loaded into the sql pool, we then do various  transformations and aggregations on the data, and store the results in  sql, which are then loaded into our PBI data model. The refreshes happen  1x per day, typically around 4am.&lt;/p&gt;\n\n&lt;p&gt;this  all being said, dedicated sql pools are SUPER expensive. I do like  being able to load the external sources directly into sql, so i was  thinking about migrating off of dedicated sql pool and just using  serverless sql in synapse. We would just export data from our  transactional sql databases onto the lake in parquet format. One of my  concerns with this is everything would essentially be views, as i dont  think you can create/manage the transformations using CTAS statements.  This doesnt seem like it would scale well as we continue to get more  data.&lt;/p&gt;\n\n&lt;p&gt;Honestly, were around 266gb  of data total, so i wouldnt be opposed to just using sql, i think  dedicated sql pool is overkill. BUT,  i dont think azure SQL has all of  the virtualisation tech like serverless or dedicated sql pool has, and  my aggregations might take longer, but i think i can fine tune  a lot to  make that work (and azure sql database is MUCHHHH cheaper). If i look  at the pricing of azure sql server managed instance (which from my  understanding does have the virtualisation tech) its around the same as  the dedicated sql pool, so doesnt seem worth to me.&lt;/p&gt;\n\n&lt;p&gt;how  are ya&amp;#39;ll doing this in a cost effective way? There are so many  buzzwords and buzz tech out there, im not sure what i should be looking at. The term Synapse is super confusing because it seems interchangable with serverless or dedicated sql pool, when it also can act as an orchestration tool. I seem a lot of people saying databricks + adl + datafactory is the  way to go, but then there is the added expensive of databricks and learning databricks.. I am  also a 1 man team on the reporting and data side, and i am also managing  another separate team on top of this (lol the tech recession is real).  point is, i feel very lost, and i dont want to spend a bunch of time migrating to a solution that wont scale or isnt cost effective. I appreciate any direction and advice you  fellow data engineers can give.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170ltz3", "is_robot_indexable": true, "report_reasons": null, "author": "soricellia", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170ltz3/solutions_to_migrate_off_of_dedicated_sql_pool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170ltz3/solutions_to_migrate_off_of_dedicated_sql_pool/", "subreddit_subscribers": 132300, "created_utc": 1696522062.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cube integrates its semantic layer with dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170n9rf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1696525451.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/introducing-dbt-integration-with-cube", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "170n9rf", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170n9rf/cube_integrates_its_semantic_layer_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/introducing-dbt-integration-with-cube", "subreddit_subscribers": 132300, "created_utc": 1696525451.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Saw this post about how to get similar functionality to dbt Cloud using other OSS tools, wondering if anyone has done this and what your experience has been\n\n  \ntl;dr  \ndbt Cloud or dbt Core + vs code + airflow + cube.dev\n\nhttps://datacoves.com/post/dbt-core-vs-dbt-cloud-key-differences", "author_fullname": "t2_vx67of8l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt Cloud extra features worth it?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170l0nw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696520038.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Saw this post about how to get similar functionality to dbt Cloud using other OSS tools, wondering if anyone has done this and what your experience has been&lt;/p&gt;\n\n&lt;p&gt;tl;dr&lt;br/&gt;\ndbt Cloud or dbt Core + vs code + airflow + cube.dev&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://datacoves.com/post/dbt-core-vs-dbt-cloud-key-differences\"&gt;https://datacoves.com/post/dbt-core-vs-dbt-cloud-key-differences&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?auto=webp&amp;s=d3cc503fb34529b9e99c792a7117e5fc053ac06b", "width": 2400, "height": 1254}, "resolutions": [{"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=c6aedf9503b00fdb31f500fd840357bf700d9507", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=ec9a9837c66cb33c17898fd385442393eebb33b7", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=829d1b2e30c6aedbf56d477f7a8419d039d4be73", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a675320e601b25b36e1e6ac4f051e0b27f475414", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6a488a73fbc7d27fce74b0ca11a7b2c828a39519", "width": 960, "height": 501}, {"url": "https://external-preview.redd.it/AkrfqvlANIwcec3NIquBhmDv45PLZVpQy0VFN79knRM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=099e281cdfcfe53d01e3290cb938387eb3cee441", "width": 1080, "height": 564}], "variants": {}, "id": "xUIE53y-az5HrMPPgq4ndFAPYxY_HJJQd0C1S2OtT0E"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "170l0nw", "is_robot_indexable": true, "report_reasons": null, "author": "Hot_Map_7868", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170l0nw/dbt_cloud_extra_features_worth_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170l0nw/dbt_cloud_extra_features_worth_it/", "subreddit_subscribers": 132300, "created_utc": 1696520038.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a DE with 4+ YOE, I work mostly with SQL, python, typescript and sometimes pyspark, but the latter only at a superficial level.\n\nFor career purposes I wanna deepen my spark knowledge and was recommended the spark bundle course from rockthejvm. However, the course is in scala and not pyspark.\n\nDo you think it's possible to follow the course properly without any experience in scala, and just figure it out on the go?\n\nLet me know what you think!", "author_fullname": "t2_zwbba", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Think I can learn spark+scala at the same time?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170dfah", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696497745.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a DE with 4+ YOE, I work mostly with SQL, python, typescript and sometimes pyspark, but the latter only at a superficial level.&lt;/p&gt;\n\n&lt;p&gt;For career purposes I wanna deepen my spark knowledge and was recommended the spark bundle course from rockthejvm. However, the course is in scala and not pyspark.&lt;/p&gt;\n\n&lt;p&gt;Do you think it&amp;#39;s possible to follow the course properly without any experience in scala, and just figure it out on the go?&lt;/p&gt;\n\n&lt;p&gt;Let me know what you think!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "170dfah", "is_robot_indexable": true, "report_reasons": null, "author": "wtfzambo", "discussion_type": null, "num_comments": 26, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170dfah/think_i_can_learn_sparkscala_at_the_same_time/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170dfah/think_i_can_learn_sparkscala_at_the_same_time/", "subreddit_subscribers": 132300, "created_utc": 1696497745.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello future fellows , \n\nI\u2019m a data analyst with almost 2 years of exp , \n&amp; I want to pursue a career with data engineering..\n\nI\u2019ve used sql for extraction &amp; analyze data at my work , &amp; python for deep dive analysis ,\n\n&amp; recently I\u2019m studying DSA , reading DWH toolkit book , \n\nIs that enough for me for cracking DE interviews ?\n&amp; \nIf you could suggest me one ETL tool to study &amp; practice with , what would be it ? \n\nI\u2019m asking for your help as I don\u2019t have a network in DE , \n\nThanks helpers \ud83e\udd0d", "author_fullname": "t2_t3nz93za", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ETL tool", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1706dax", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.72, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696473160.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello future fellows , &lt;/p&gt;\n\n&lt;p&gt;I\u2019m a data analyst with almost 2 years of exp , \n&amp;amp; I want to pursue a career with data engineering..&lt;/p&gt;\n\n&lt;p&gt;I\u2019ve used sql for extraction &amp;amp; analyze data at my work , &amp;amp; python for deep dive analysis ,&lt;/p&gt;\n\n&lt;p&gt;&amp;amp; recently I\u2019m studying DSA , reading DWH toolkit book , &lt;/p&gt;\n\n&lt;p&gt;Is that enough for me for cracking DE interviews ?\n&amp;amp; \nIf you could suggest me one ETL tool to study &amp;amp; practice with , what would be it ? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m asking for your help as I don\u2019t have a network in DE , &lt;/p&gt;\n\n&lt;p&gt;Thanks helpers \ud83e\udd0d&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1706dax", "is_robot_indexable": true, "report_reasons": null, "author": "Repulsive-Ad7769", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1706dax/etl_tool/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1706dax/etl_tool/", "subreddit_subscribers": 132300, "created_utc": 1696473160.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! \ud83d\udc4b\n\nI hope you're all doing well. I'm a data engineer with 4 years of experience, and I'm contemplating a move to the United States from Australia as I'm looking for a change in environment and have been interested in experiencing living/working in the US.\n\nI have a few questions and would greatly appreciate any insights or recommendations from those who have experience in this field or have been in a similar situation:\n\n1. **Choosing a State/City:** First and foremost, I'm having a hard time deciding on the best state or city to settle in. Are there any particular areas in the US that are known for their strong data engineering job market or tech industry in general? What factors should I consider while making this decision, such as cost of living, job opportunities, or quality of life?\n\n2. **Job Hunting Process:** I'd like to know more about the process of looking for data engineering opportunities in the US. Which job boards, websites, or platforms are most effective for job searches in this field? Are there any specific resources tailored to international job seekers like me? \n\n3. **Typical Hiring Process:** What is the typical hiring process like for data engineering positions in the US? Any insights into the application, interview, and selection stages specifically for international applicants would be immensely helpful.\n\n4. **Relocation Experience:** If you've made a similar move from another country to the US, particularly in the tech industry, I'd love to hear about your experiences. What challenges did you face during the relocation process, and how did you overcome them? Any tips or lessons learned that you'd like to share?\n\nI'm excited about the potential opportunities in the US but want to ensure that I'm making an informed decision. Your input and advice would mean a lot to me as I embark on this journey! Thank you in advance for your time and help!", "author_fullname": "t2_itoec5nn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Guidance on Relocating to the US as a Data Engineer from Australia", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1704wfw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696469101.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! \ud83d\udc4b&lt;/p&gt;\n\n&lt;p&gt;I hope you&amp;#39;re all doing well. I&amp;#39;m a data engineer with 4 years of experience, and I&amp;#39;m contemplating a move to the United States from Australia as I&amp;#39;m looking for a change in environment and have been interested in experiencing living/working in the US.&lt;/p&gt;\n\n&lt;p&gt;I have a few questions and would greatly appreciate any insights or recommendations from those who have experience in this field or have been in a similar situation:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Choosing a State/City:&lt;/strong&gt; First and foremost, I&amp;#39;m having a hard time deciding on the best state or city to settle in. Are there any particular areas in the US that are known for their strong data engineering job market or tech industry in general? What factors should I consider while making this decision, such as cost of living, job opportunities, or quality of life?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Job Hunting Process:&lt;/strong&gt; I&amp;#39;d like to know more about the process of looking for data engineering opportunities in the US. Which job boards, websites, or platforms are most effective for job searches in this field? Are there any specific resources tailored to international job seekers like me? &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Typical Hiring Process:&lt;/strong&gt; What is the typical hiring process like for data engineering positions in the US? Any insights into the application, interview, and selection stages specifically for international applicants would be immensely helpful.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;&lt;strong&gt;Relocation Experience:&lt;/strong&gt; If you&amp;#39;ve made a similar move from another country to the US, particularly in the tech industry, I&amp;#39;d love to hear about your experiences. What challenges did you face during the relocation process, and how did you overcome them? Any tips or lessons learned that you&amp;#39;d like to share?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I&amp;#39;m excited about the potential opportunities in the US but want to ensure that I&amp;#39;m making an informed decision. Your input and advice would mean a lot to me as I embark on this journey! Thank you in advance for your time and help!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1704wfw", "is_robot_indexable": true, "report_reasons": null, "author": "CocoaDependent1664", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1704wfw/seeking_guidance_on_relocating_to_the_us_as_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1704wfw/seeking_guidance_on_relocating_to_the_us_as_a/", "subreddit_subscribers": 132300, "created_utc": 1696469101.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm taking an organization development course for my undergrad which requires me to ask a professional who currently works in your dream role about organization development at your company and your perspective. Preferably hop on a Zoom call so I can acquire a text transcript for notes. Please let me know!", "author_fullname": "t2_s47yjlr8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any Data Engineers available for a quick interview?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170vu6a", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696545799.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m taking an organization development course for my undergrad which requires me to ask a professional who currently works in your dream role about organization development at your company and your perspective. Preferably hop on a Zoom call so I can acquire a text transcript for notes. Please let me know!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170vu6a", "is_robot_indexable": true, "report_reasons": null, "author": "shouldawouldacoulda0", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170vu6a/any_data_engineers_available_for_a_quick_interview/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170vu6a/any_data_engineers_available_for_a_quick_interview/", "subreddit_subscribers": 132300, "created_utc": 1696545799.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear fellow Data Engineers\n\nYesterday, I had a Job Interview for a Senior Data Engieer Position at a local Healthcare Provider in Switzerland. I mastered almost all technical questions about Data Engineering in general (3NF, SCD2, Lakehouse vs DWH, Relational vs Star Schema, CDC, Batch processing etc.) as well as a technical case study how I would design a Warehouse + AI Solution regarding text analysis.\n\nThen a guy from another Department joined and asked question that were more backend related. E.g. What is REST, and how to design an api accordingly? What is OOP and its benefits? What are pros and cons of using Docker? etc.\n\nI stumbled across these questions and did not know how to answer them properly. I did not prepare for such questions as the job posting was not asking for backend related skills.\n\nToday, I got an email explaining that I would be a personal as well as a technical fit from a data engineering perspective. However, they are looking for a person that has more of an IT-background that can be used more flexible within their departments. Thus they declined.\n\nI do agree that I am not a perfect fit, if they are looking for such a person. But I am questioning if, in general, these backend related skills can be expected from someone that applies for a Data Engineering position. \n\nTo summarize: Should I study backend software engineering in order to increase my chances of finding a Job? Or, are backend related skills usually not asked for and I should not worry about it too much?\n\nI am curious to hear about your experience!", "author_fullname": "t2_ou2h13bx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Backend Skills for Data Engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170vj3u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696545043.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear fellow Data Engineers&lt;/p&gt;\n\n&lt;p&gt;Yesterday, I had a Job Interview for a Senior Data Engieer Position at a local Healthcare Provider in Switzerland. I mastered almost all technical questions about Data Engineering in general (3NF, SCD2, Lakehouse vs DWH, Relational vs Star Schema, CDC, Batch processing etc.) as well as a technical case study how I would design a Warehouse + AI Solution regarding text analysis.&lt;/p&gt;\n\n&lt;p&gt;Then a guy from another Department joined and asked question that were more backend related. E.g. What is REST, and how to design an api accordingly? What is OOP and its benefits? What are pros and cons of using Docker? etc.&lt;/p&gt;\n\n&lt;p&gt;I stumbled across these questions and did not know how to answer them properly. I did not prepare for such questions as the job posting was not asking for backend related skills.&lt;/p&gt;\n\n&lt;p&gt;Today, I got an email explaining that I would be a personal as well as a technical fit from a data engineering perspective. However, they are looking for a person that has more of an IT-background that can be used more flexible within their departments. Thus they declined.&lt;/p&gt;\n\n&lt;p&gt;I do agree that I am not a perfect fit, if they are looking for such a person. But I am questioning if, in general, these backend related skills can be expected from someone that applies for a Data Engineering position. &lt;/p&gt;\n\n&lt;p&gt;To summarize: Should I study backend software engineering in order to increase my chances of finding a Job? Or, are backend related skills usually not asked for and I should not worry about it too much?&lt;/p&gt;\n\n&lt;p&gt;I am curious to hear about your experience!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "170vj3u", "is_robot_indexable": true, "report_reasons": null, "author": "Present_Salt_1688", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170vj3u/backend_skills_for_data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170vj3u/backend_skills_for_data_engineers/", "subreddit_subscribers": 132300, "created_utc": 1696545043.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_y9qpd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I built an open-source scraping API that returns structured JSON data using GPT.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170m9lu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1696523115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/semanser/JsonGenius", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "170m9lu", "is_robot_indexable": true, "report_reasons": null, "author": "semanser", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170m9lu/i_built_an_opensource_scraping_api_that_returns/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/semanser/JsonGenius", "subreddit_subscribers": 132300, "created_utc": 1696523115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m trying to use shipyard to automate a bunch of PostgreSQL procedures. I\u2019m using shipyard as the data orchestrator. Their help desk support response is good, but it\u2019s taken 2 days for them so far not to come up with a solution. The problem \u2026it seems you can do all the pretty stuff like set up a connection to PostgreSQL\u2026and even when you grant execute on the user for PostgreSQL and for the specific procedures to run\u2026shipyard does not run the procedures!\n\nAm I missing something simple (probably!)?\n\nAre there any alternatives to use (airflow and prefect are a tad too involved for me right now\u2026a user interface for the main is what I\u2019m looking to use\u2026just to schedule and keep tabs on the jobs)\n\nCheers", "author_fullname": "t2_hg12i599c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shipyard - PostgreSQL fleet, not working", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170j5u8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696515444.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m trying to use shipyard to automate a bunch of PostgreSQL procedures. I\u2019m using shipyard as the data orchestrator. Their help desk support response is good, but it\u2019s taken 2 days for them so far not to come up with a solution. The problem \u2026it seems you can do all the pretty stuff like set up a connection to PostgreSQL\u2026and even when you grant execute on the user for PostgreSQL and for the specific procedures to run\u2026shipyard does not run the procedures!&lt;/p&gt;\n\n&lt;p&gt;Am I missing something simple (probably!)?&lt;/p&gt;\n\n&lt;p&gt;Are there any alternatives to use (airflow and prefect are a tad too involved for me right now\u2026a user interface for the main is what I\u2019m looking to use\u2026just to schedule and keep tabs on the jobs)&lt;/p&gt;\n\n&lt;p&gt;Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170j5u8", "is_robot_indexable": true, "report_reasons": null, "author": "BumblyWurzle", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170j5u8/shipyard_postgresql_fleet_not_working/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170j5u8/shipyard_postgresql_fleet_not_working/", "subreddit_subscribers": 132300, "created_utc": 1696515444.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am currently using Looker to display carbon offset data that is stored in BigQuery. I am planning to develop my own JavaScript-based dashboard, and I am considering using Memorystore with Redis as a cache layer. However, I am concerned that Redis may be too expensive for my needs.\n\nMy data volume is small (less than 300 MB) and will not increase much in the future. I want my JavaScript dashboard to be as flexible as Looker.\n\n**Questions:**\n\n1. Can using materialized views and query caching in BigQuery provide good performance for a JavaScript dashboard?\n2. Is Redis necessary in my case? Won't it be too expensive?\n3. Can you share any links to articles or tutorials on how to implement a Looker-like dashboard using BigQuery and JavaScript?", "author_fullname": "t2_brrw1jso", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Caching Layer and Replacing Looker", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170es90", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696502824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently using Looker to display carbon offset data that is stored in BigQuery. I am planning to develop my own JavaScript-based dashboard, and I am considering using Memorystore with Redis as a cache layer. However, I am concerned that Redis may be too expensive for my needs.&lt;/p&gt;\n\n&lt;p&gt;My data volume is small (less than 300 MB) and will not increase much in the future. I want my JavaScript dashboard to be as flexible as Looker.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Questions:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Can using materialized views and query caching in BigQuery provide good performance for a JavaScript dashboard?&lt;/li&gt;\n&lt;li&gt;Is Redis necessary in my case? Won&amp;#39;t it be too expensive?&lt;/li&gt;\n&lt;li&gt;Can you share any links to articles or tutorials on how to implement a Looker-like dashboard using BigQuery and JavaScript?&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170es90", "is_robot_indexable": true, "report_reasons": null, "author": "No-Reflection-3622", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170es90/caching_layer_and_replacing_looker/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170es90/caching_layer_and_replacing_looker/", "subreddit_subscribers": 132300, "created_utc": 1696502824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello Friends,\n\nI need some guidance on our data journey. We currently use GCP as our vendor and have been storing loads of data in BQ for reporting,  it hasn't been fun. I've used traditional warehouses before but seeing BQ amazes me in good ways yet I feel its just not the right step for us considering we have data quality issues upstream that needs proper oversight which a traditional warehouses can provide.\n\n1. BQ doesn't have a concept of pk fk in a way that we can enforce referential integrity when loading data. \n\n2. With above true, would a right approach for us be to add a traditional cloud sql server relational warehouses (kimball methodology) where data is stored and maintained outside of BQ, then exporting summary/ clean data back into BQ for analysis.\n\n\nThoughts", "author_fullname": "t2_efykxnpyj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "BigQuery warehouse VS Traditional", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170cyrb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696495962.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello Friends,&lt;/p&gt;\n\n&lt;p&gt;I need some guidance on our data journey. We currently use GCP as our vendor and have been storing loads of data in BQ for reporting,  it hasn&amp;#39;t been fun. I&amp;#39;ve used traditional warehouses before but seeing BQ amazes me in good ways yet I feel its just not the right step for us considering we have data quality issues upstream that needs proper oversight which a traditional warehouses can provide.&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;BQ doesn&amp;#39;t have a concept of pk fk in a way that we can enforce referential integrity when loading data. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;With above true, would a right approach for us be to add a traditional cloud sql server relational warehouses (kimball methodology) where data is stored and maintained outside of BQ, then exporting summary/ clean data back into BQ for analysis.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Thoughts&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170cyrb", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Accountant9334", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170cyrb/bigquery_warehouse_vs_traditional/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170cyrb/bigquery_warehouse_vs_traditional/", "subreddit_subscribers": 132300, "created_utc": 1696495962.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I need to integrate a data workload tool with my web app's API, which I know is a fairly non-standard thing to do... but the workloads can be expensive (in terms of $$, e.g. calling OpenAI), so I want to bring good data eng practices along.\n\nI've been playing around with Prefect and Benthos, and surprised to find that when you trigger a workflow that is set to cache results on a given input, there is no locking mechanism to ensure that concurrent requests for the same given input do not result in more than one computation. i.e. while the first request is being handled, subsequent requests should not trigger a new compute but rather wait for the result of the first one.\n\nThis is a problem primarily due to the tight integration with the web app API where users can trigger workloads that are set up to lazy-evaluate / lazy-compute certain data outputs\n\nDoes anyone know of any tools that do solve this cache stampede issue? And is a data eng tool what I should be using, or does it sound more like I am reaching for the wrong set of tooling?", "author_fullname": "t2_vep5j", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Caching workloads + concurrent requests", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_170ycyq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696552391.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I need to integrate a data workload tool with my web app&amp;#39;s API, which I know is a fairly non-standard thing to do... but the workloads can be expensive (in terms of $$, e.g. calling OpenAI), so I want to bring good data eng practices along.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been playing around with Prefect and Benthos, and surprised to find that when you trigger a workflow that is set to cache results on a given input, there is no locking mechanism to ensure that concurrent requests for the same given input do not result in more than one computation. i.e. while the first request is being handled, subsequent requests should not trigger a new compute but rather wait for the result of the first one.&lt;/p&gt;\n\n&lt;p&gt;This is a problem primarily due to the tight integration with the web app API where users can trigger workloads that are set up to lazy-evaluate / lazy-compute certain data outputs&lt;/p&gt;\n\n&lt;p&gt;Does anyone know of any tools that do solve this cache stampede issue? And is a data eng tool what I should be using, or does it sound more like I am reaching for the wrong set of tooling?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170ycyq", "is_robot_indexable": true, "report_reasons": null, "author": "matty_fu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170ycyq/caching_workloads_concurrent_requests/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170ycyq/caching_workloads_concurrent_requests/", "subreddit_subscribers": 132300, "created_utc": 1696552391.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My team has a ETL workload that runs on a daily batch of data from our S3 bucket. We have a contract to return back to the client by the end of the week.\n\nClient has their own S3 storage and wants to send us SNS message for every file they're ready to send. We use SQS to store those messages and later use Lambda ingest the S3 files to our S3 bucket.\n\nSome point down the line, we need to download all their data which may have been modified and is different than the first time we've downloaded it.\n\n\\----------------\n\nTo me, this seems over-engineered. I understand there's a lot of flexibility with this event-driven architecture and is necessary for real-time/low-latency ETL, but I can't help but think this should be as simple as syncing two S3 storages as needed (i.e., daily for us). If all the data is contain in one bucket, then we can use S3 replication or a sync feature.\n\nI understand syncing incurs more API calls. If the client's S3 files don't exist in a bucket/prefix, then they would need to send us a list of S3 paths. For example, we could still use SNS but the client will send us 1 message with the list of S3 paths. \n\nFor redownloading, a sync at the end is far easier than using all the S3 paths from all the SNS messages the client sent us.", "author_fullname": "t2_j08pz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Client wants to sync S3s with SNS, SQS, and Lambda for daily ETL. Isn't that too much?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_170y58t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696551787.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My team has a ETL workload that runs on a daily batch of data from our S3 bucket. We have a contract to return back to the client by the end of the week.&lt;/p&gt;\n\n&lt;p&gt;Client has their own S3 storage and wants to send us SNS message for every file they&amp;#39;re ready to send. We use SQS to store those messages and later use Lambda ingest the S3 files to our S3 bucket.&lt;/p&gt;\n\n&lt;p&gt;Some point down the line, we need to download all their data which may have been modified and is different than the first time we&amp;#39;ve downloaded it.&lt;/p&gt;\n\n&lt;p&gt;----------------&lt;/p&gt;\n\n&lt;p&gt;To me, this seems over-engineered. I understand there&amp;#39;s a lot of flexibility with this event-driven architecture and is necessary for real-time/low-latency ETL, but I can&amp;#39;t help but think this should be as simple as syncing two S3 storages as needed (i.e., daily for us). If all the data is contain in one bucket, then we can use S3 replication or a sync feature.&lt;/p&gt;\n\n&lt;p&gt;I understand syncing incurs more API calls. If the client&amp;#39;s S3 files don&amp;#39;t exist in a bucket/prefix, then they would need to send us a list of S3 paths. For example, we could still use SNS but the client will send us 1 message with the list of S3 paths. &lt;/p&gt;\n\n&lt;p&gt;For redownloading, a sync at the end is far easier than using all the S3 paths from all the SNS messages the client sent us.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "170y58t", "is_robot_indexable": true, "report_reasons": null, "author": "diamondketo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170y58t/client_wants_to_sync_s3s_with_sns_sqs_and_lambda/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170y58t/client_wants_to_sync_s3s_with_sns_sqs_and_lambda/", "subreddit_subscribers": 132300, "created_utc": 1696551787.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We have pipelines that run weekly and they're dependent on what clients send us. Some clients send us the same shit some can't seem to figure it out and their pipe fails. To what degree do you modify a pipeline? Is it just to get things moving or is there a way to gold-plate it and hope they don't find another way to fuck it up.\n\nThings that clients have fucked up in the last week,\nDifferent file format\nDifferent header\nDifferent data types", "author_fullname": "t2_vtm8z2o0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "At what point do you decide to modify a pipeline", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_170wvxc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696548419.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We have pipelines that run weekly and they&amp;#39;re dependent on what clients send us. Some clients send us the same shit some can&amp;#39;t seem to figure it out and their pipe fails. To what degree do you modify a pipeline? Is it just to get things moving or is there a way to gold-plate it and hope they don&amp;#39;t find another way to fuck it up.&lt;/p&gt;\n\n&lt;p&gt;Things that clients have fucked up in the last week,\nDifferent file format\nDifferent header\nDifferent data types&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "170wvxc", "is_robot_indexable": true, "report_reasons": null, "author": "Action_Maxim", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/170wvxc/at_what_point_do_you_decide_to_modify_a_pipeline/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/170wvxc/at_what_point_do_you_decide_to_modify_a_pipeline/", "subreddit_subscribers": 132300, "created_utc": 1696548419.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}