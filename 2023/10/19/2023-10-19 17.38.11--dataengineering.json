{"kind": "Listing", "data": {"after": "t3_17bhig4", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "PyGWalker is a python library that turns your dataframe (or a database connection) to an embeddable tableau-like user interface for visual analysis.\n\nIt can be used to explore and visualize your data in juypter notebook without switching between different tools. It can also be used with streamlit to host and share an interactive data app on web.\n\nPyGWalker Github: [https://github.com/Kanaries/pygwalker](https://github.com/Kanaries/pygwalker)\n\n[pygwalker in juypter lab](https://preview.redd.it/lor544wm82vb1.png?width=3002&amp;format=png&amp;auto=webp&amp;s=993a09ffb21075b1a4a213e3988c09b9a2be1bdd)\n\nA simple example of how to use pygwalker\n\n    import pygwalker as pyg\n    import pandas as pd\n    \n    df = pd.read_csv(\"you_data\")\n    \n    # then pass it to pygwalker\n    pyg.walk(df)", "author_fullname": "t2_dnzigfn3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PyGWalker: a Python library for data engineer that turns your dataframe into tableau-like data app.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 79, "top_awarded_type": null, "hide_score": false, "media_metadata": {"lor544wm82vb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 61, "x": 108, "u": "https://preview.redd.it/lor544wm82vb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ce7e7c2e461b8c5f8a62fa4fc0ec9dfd6ace2c3e"}, {"y": 122, "x": 216, "u": "https://preview.redd.it/lor544wm82vb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=eee7e80217d9179cba847be4f8db9894125b634c"}, {"y": 180, "x": 320, "u": "https://preview.redd.it/lor544wm82vb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=295a8a44847cbb4645e996e87ca86f66bf3cf360"}, {"y": 361, "x": 640, "u": "https://preview.redd.it/lor544wm82vb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=6c1a63ea82817d913b5141976ce8757419705c0c"}, {"y": 542, "x": 960, "u": "https://preview.redd.it/lor544wm82vb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=00a6472b88d633baf9f30cc48639ca51854b9463"}, {"y": 610, "x": 1080, "u": "https://preview.redd.it/lor544wm82vb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=38271e7d4e710122f24a3fc973486ac483cc23cc"}], "s": {"y": 1696, "x": 3002, "u": "https://preview.redd.it/lor544wm82vb1.png?width=3002&amp;format=png&amp;auto=webp&amp;s=993a09ffb21075b1a4a213e3988c09b9a2be1bdd"}, "id": "lor544wm82vb1"}}, "name": "t3_17b6wdl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 61, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 61, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/d1ctUbcbuJYjdb3IUb1F2qoxEKrfIsQL_tCBj6-pC_I.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697678204.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;PyGWalker is a python library that turns your dataframe (or a database connection) to an embeddable tableau-like user interface for visual analysis.&lt;/p&gt;\n\n&lt;p&gt;It can be used to explore and visualize your data in juypter notebook without switching between different tools. It can also be used with streamlit to host and share an interactive data app on web.&lt;/p&gt;\n\n&lt;p&gt;PyGWalker Github: &lt;a href=\"https://github.com/Kanaries/pygwalker\"&gt;https://github.com/Kanaries/pygwalker&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/lor544wm82vb1.png?width=3002&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=993a09ffb21075b1a4a213e3988c09b9a2be1bdd\"&gt;pygwalker in juypter lab&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;A simple example of how to use pygwalker&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;import pygwalker as pyg\nimport pandas as pd\n\ndf = pd.read_csv(&amp;quot;you_data&amp;quot;)\n\n# then pass it to pygwalker\npyg.walk(df)\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17b6wdl", "is_robot_indexable": true, "report_reasons": null, "author": "Sudden_Beginning_597", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17b6wdl/pygwalker_a_python_library_for_data_engineer_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17b6wdl/pygwalker_a_python_library_for_data_engineer_that/", "subreddit_subscribers": 134854, "created_utc": 1697678204.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a company with 200+ data engineers, and a new Head of HR was brought in a few months.\n\nThey announced last week that in the Q1, we will be measuring individual performance using stack ranking with the intention to \u201csupport equitable and diverse career growth.\u201d\n\nNot sure if I\u2019m crazy, but this is gonna be rough, right?  Everything I\u2019ve read about it suggests that stack ranking creates strong incentives that outright harm collaboration (which is a current strength at my company).", "author_fullname": "t2_nexbbb26", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "My company is implementing stack ranking", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17b1zaw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 43, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 43, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697664710.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a company with 200+ data engineers, and a new Head of HR was brought in a few months.&lt;/p&gt;\n\n&lt;p&gt;They announced last week that in the Q1, we will be measuring individual performance using stack ranking with the intention to \u201csupport equitable and diverse career growth.\u201d&lt;/p&gt;\n\n&lt;p&gt;Not sure if I\u2019m crazy, but this is gonna be rough, right?  Everything I\u2019ve read about it suggests that stack ranking creates strong incentives that outright harm collaboration (which is a current strength at my company).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17b1zaw", "is_robot_indexable": true, "report_reasons": null, "author": "keep_it_professional", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17b1zaw/my_company_is_implementing_stack_ranking/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17b1zaw/my_company_is_implementing_stack_ranking/", "subreddit_subscribers": 134854, "created_utc": 1697664710.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI have a DE coding interview at Apple, can someone please share some insights about the coding round. What type of questions I can expect?", "author_fullname": "t2_udkygwua", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DE Coding Round at Apple", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17b3nbo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 20, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 20, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697669053.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have a DE coding interview at Apple, can someone please share some insights about the coding round. What type of questions I can expect?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17b3nbo", "is_robot_indexable": true, "report_reasons": null, "author": "Anxious-Reality3258", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17b3nbo/de_coding_round_at_apple/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17b3nbo/de_coding_round_at_apple/", "subreddit_subscribers": 134854, "created_utc": 1697669053.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I want to learn more about data engineering (architecture, pipelines, etc.), but I don't just wan to spin up Python/SQL and solve problems for the sake of solving them. I want to potentially build something that I can passively make income from in the long term. \n\nI know there is a skill gap between data engineering and web app development, but is there any better thing to work on to develop my skills and potentially a steady income stream than a web app?\n\nI have an idea for a web app that would likely be very API heavy or might require a great amount of data scraping which would then need to be processed and organized.", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is creating a web app the best way to expand data engineering knowledge while possibly building the foundation of a sellable product?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17b730n", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697678757.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to learn more about data engineering (architecture, pipelines, etc.), but I don&amp;#39;t just wan to spin up Python/SQL and solve problems for the sake of solving them. I want to potentially build something that I can passively make income from in the long term. &lt;/p&gt;\n\n&lt;p&gt;I know there is a skill gap between data engineering and web app development, but is there any better thing to work on to develop my skills and potentially a steady income stream than a web app?&lt;/p&gt;\n\n&lt;p&gt;I have an idea for a web app that would likely be very API heavy or might require a great amount of data scraping which would then need to be processed and organized.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17b730n", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17b730n/is_creating_a_web_app_the_best_way_to_expand_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17b730n/is_creating_a_web_app_the_best_way_to_expand_data/", "subreddit_subscribers": 134854, "created_utc": 1697678757.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi folks,\n\nWe at [dlt](https://dlthub.com/) (the loading library before dbt) created 2 **dbt** **runners** to enable kicking off dbt jobs after loading. They are lightweight, and you can use them anywhere.\n\nThe **dbt core runner** features an optional venv creation for resolving library conflicts and accepts credentials from dlt (easier to pass, can pass in code too)\n\nThe **dbt cloud runner** supports starting and polling a job so you can run the transform after the load on a tight schedule for example.\n\nI wrote a blog post to describe the use cases why you would use them too.\n\nI hope they are useful to you, and that they might solve some of the issues with running dbt.\n\n**Feedback welcome!**\n\n**Article Link:** [dbt-runners-usage](https://dlthub.com/docs/blog/dbt-runners-usage)\n\n**And the docs&amp;links:** [**Cloud runner**](https://dlthub.com/docs/dlt-ecosystem/transformations/dbt/dbt_cloud)**,** [**Core runner**](https://dlthub.com/docs/dlt-ecosystem/transformations/dbt/), [Join dlt slack community for questions](https://join.slack.com/t/dlthub-community/shared_invite/zt-1slox199h-HAE7EQoXmstkP_bTqal65g)\u00a0\n\n**Examples:**\n\n**dbt Cloud** runner:\n\n    from dlt.helpers.dbt_cloud import run_dbt_cloud_job\n    \n    # Trigger a job run with additional data\n    additional_data = {\n        \"git_sha\": \"abcd1234\",\n        \"schema_override\": \"custom_schema\",\n        # ... other parameters\n    }\n    status = run_dbt_cloud_job(job_id=1234, data=additional_data, wait_for_outcome=True)\n    print(f\"Job run status: {status['status_humanized']}\")\n\n**dbt Core** runner:\n\n    pipeline = dlt.pipeline(\n        pipeline_name='pipedrive',\n        destination='bigquery',\n        dataset_name='pipedrive_dbt'\n    )\n    \n    # make or restore venv for dbt, using latest dbt version\n    venv = dlt.dbt.get_venv(pipeline)\n    \n    # get runner, optionally pass the venv\n    dbt = dlt.dbt.package(\n        pipeline,\n        \"pipedrive/dbt_pipedrive/pipedrive\",\n        venv=venv\n    )\n    \n    # run the models and collect any info\n    # If running fails, the error will be raised with full stack trace\n    models = dbt.run_all()", "author_fullname": "t2_uamr9xer", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT core and cloud runners and their use cases", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bb0fe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697691097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi folks,&lt;/p&gt;\n\n&lt;p&gt;We at &lt;a href=\"https://dlthub.com/\"&gt;dlt&lt;/a&gt; (the loading library before dbt) created 2 &lt;strong&gt;dbt&lt;/strong&gt; &lt;strong&gt;runners&lt;/strong&gt; to enable kicking off dbt jobs after loading. They are lightweight, and you can use them anywhere.&lt;/p&gt;\n\n&lt;p&gt;The &lt;strong&gt;dbt core runner&lt;/strong&gt; features an optional venv creation for resolving library conflicts and accepts credentials from dlt (easier to pass, can pass in code too)&lt;/p&gt;\n\n&lt;p&gt;The &lt;strong&gt;dbt cloud runner&lt;/strong&gt; supports starting and polling a job so you can run the transform after the load on a tight schedule for example.&lt;/p&gt;\n\n&lt;p&gt;I wrote a blog post to describe the use cases why you would use them too.&lt;/p&gt;\n\n&lt;p&gt;I hope they are useful to you, and that they might solve some of the issues with running dbt.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Feedback welcome!&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Article Link:&lt;/strong&gt; &lt;a href=\"https://dlthub.com/docs/blog/dbt-runners-usage\"&gt;dbt-runners-usage&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;And the docs&amp;amp;links:&lt;/strong&gt; &lt;a href=\"https://dlthub.com/docs/dlt-ecosystem/transformations/dbt/dbt_cloud\"&gt;&lt;strong&gt;Cloud runner&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;,&lt;/strong&gt; &lt;a href=\"https://dlthub.com/docs/dlt-ecosystem/transformations/dbt/\"&gt;&lt;strong&gt;Core runner&lt;/strong&gt;&lt;/a&gt;, &lt;a href=\"https://join.slack.com/t/dlthub-community/shared_invite/zt-1slox199h-HAE7EQoXmstkP_bTqal65g\"&gt;Join dlt slack community for questions&lt;/a&gt;\u00a0&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;dbt Cloud&lt;/strong&gt; runner:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from dlt.helpers.dbt_cloud import run_dbt_cloud_job\n\n# Trigger a job run with additional data\nadditional_data = {\n    &amp;quot;git_sha&amp;quot;: &amp;quot;abcd1234&amp;quot;,\n    &amp;quot;schema_override&amp;quot;: &amp;quot;custom_schema&amp;quot;,\n    # ... other parameters\n}\nstatus = run_dbt_cloud_job(job_id=1234, data=additional_data, wait_for_outcome=True)\nprint(f&amp;quot;Job run status: {status[&amp;#39;status_humanized&amp;#39;]}&amp;quot;)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;dbt Core&lt;/strong&gt; runner:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;pipeline = dlt.pipeline(\n    pipeline_name=&amp;#39;pipedrive&amp;#39;,\n    destination=&amp;#39;bigquery&amp;#39;,\n    dataset_name=&amp;#39;pipedrive_dbt&amp;#39;\n)\n\n# make or restore venv for dbt, using latest dbt version\nvenv = dlt.dbt.get_venv(pipeline)\n\n# get runner, optionally pass the venv\ndbt = dlt.dbt.package(\n    pipeline,\n    &amp;quot;pipedrive/dbt_pipedrive/pipedrive&amp;quot;,\n    venv=venv\n)\n\n# run the models and collect any info\n# If running fails, the error will be raised with full stack trace\nmodels = dbt.run_all()\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/WXmHsjH_hc03ysnjRGgpU0BpqPuyK4yoE4aetJevFcM.jpg?auto=webp&amp;s=1bd62d75d0936333c30fb69034c8c176429e93cf", "width": 1200, "height": 898}, "resolutions": [{"url": "https://external-preview.redd.it/WXmHsjH_hc03ysnjRGgpU0BpqPuyK4yoE4aetJevFcM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=8b7dfc5649e6aa2d1b7c128781fdc7fc6556ae07", "width": 108, "height": 80}, {"url": "https://external-preview.redd.it/WXmHsjH_hc03ysnjRGgpU0BpqPuyK4yoE4aetJevFcM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=f17115b9faa677c01bdf076bf97909b0f2194fd2", "width": 216, "height": 161}, {"url": "https://external-preview.redd.it/WXmHsjH_hc03ysnjRGgpU0BpqPuyK4yoE4aetJevFcM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=7957af9a90b452cb31fe0d69578baed68c7526fb", "width": 320, "height": 239}, {"url": "https://external-preview.redd.it/WXmHsjH_hc03ysnjRGgpU0BpqPuyK4yoE4aetJevFcM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a2009c85ad047390080ff6acbc319d96819eb885", "width": 640, "height": 478}, {"url": "https://external-preview.redd.it/WXmHsjH_hc03ysnjRGgpU0BpqPuyK4yoE4aetJevFcM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=394371b1ece2fdf65d23d108139c0f09980e3f42", "width": 960, "height": 718}, {"url": "https://external-preview.redd.it/WXmHsjH_hc03ysnjRGgpU0BpqPuyK4yoE4aetJevFcM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=02df7d26ef0ba37069425c8cd0e0d38e4aecc1f7", "width": 1080, "height": 808}], "variants": {}, "id": "cUuEsBHL5TMhrkQNJ9leYxFMOF6VgvTJ_EKHwExrn8Y"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "17bb0fe", "is_robot_indexable": true, "report_reasons": null, "author": "Thinker_Assignment", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bb0fe/dbt_core_and_cloud_runners_and_their_use_cases/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bb0fe/dbt_core_and_cloud_runners_and_their_use_cases/", "subreddit_subscribers": 134854, "created_utc": 1697691097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone obtained this? How was it for difficulty? I've never used GCP before but have just completed the *\"Preparing for your Professional Data Engineer Journey\"* course so not sure how much this will help.\n\nI'm fairly proficient is Python and SQL, I have some AWS experience. Looking to get certified as I'm trying to transition to the Data Engineering space rather than python/sql all rounder and it's better to have some GCP cert than nothing.\n\nAny advice is appreciated.", "author_fullname": "t2_5iincanh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Google Cloud Platform - Professional Data Engineer Certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17baklu", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697689485.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone obtained this? How was it for difficulty? I&amp;#39;ve never used GCP before but have just completed the &lt;em&gt;&amp;quot;Preparing for your Professional Data Engineer Journey&amp;quot;&lt;/em&gt; course so not sure how much this will help.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m fairly proficient is Python and SQL, I have some AWS experience. Looking to get certified as I&amp;#39;m trying to transition to the Data Engineering space rather than python/sql all rounder and it&amp;#39;s better to have some GCP cert than nothing.&lt;/p&gt;\n\n&lt;p&gt;Any advice is appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17baklu", "is_robot_indexable": true, "report_reasons": null, "author": "Willing_Excuse1652", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17baklu/google_cloud_platform_professional_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17baklu/google_cloud_platform_professional_data_engineer/", "subreddit_subscribers": 134854, "created_utc": 1697689485.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm looking into starting some certs to help my chances of breaking into a DE r\u00f4le. I have a year of experience as a SWE and I hope to switch to DE next year. Will Azure/GCP certifications actually add any value to my applications or do companies not really care?", "author_fullname": "t2_i30nbi2d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Certifications make or break?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17be4im", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697703427.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking into starting some certs to help my chances of breaking into a DE r\u00f4le. I have a year of experience as a SWE and I hope to switch to DE next year. Will Azure/GCP certifications actually add any value to my applications or do companies not really care?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17be4im", "is_robot_indexable": true, "report_reasons": null, "author": "iishadowsii_", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17be4im/certifications_make_or_break/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17be4im/certifications_make_or_break/", "subreddit_subscribers": 134854, "created_utc": 1697703427.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've released dbt-factory which enable you to write re-usable sql code blocks and compile to a dbt project through a yaml configuration\n\n**Benefits**\n\n* Construct pipeline without knowing SQL\n* Construct pipelines without learning dbt\n* Avoid duplicative code\n* Easier automation of pipeline creation, so your code can interact with yaml instead of sql (advanced users)\n\n&amp;#x200B;\n\nLet me know if anyone has any thoughts \ud83d\ude04", "author_fullname": "t2_9jvpz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt factory: re-usable sql, configured through YAML, compiled to dbt", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17b7nim", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697680425.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve released dbt-factory which enable you to write re-usable sql code blocks and compile to a dbt project through a yaml configuration&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Benefits&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Construct pipeline without knowing SQL&lt;/li&gt;\n&lt;li&gt;Construct pipelines without learning dbt&lt;/li&gt;\n&lt;li&gt;Avoid duplicative code&lt;/li&gt;\n&lt;li&gt;Easier automation of pipeline creation, so your code can interact with yaml instead of sql (advanced users)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Let me know if anyone has any thoughts \ud83d\ude04&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17b7nim", "is_robot_indexable": true, "report_reasons": null, "author": "conradbez", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17b7nim/dbt_factory_reusable_sql_configured_through_yaml/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17b7nim/dbt_factory_reusable_sql_configured_through_yaml/", "subreddit_subscribers": 134854, "created_utc": 1697680425.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone here use the change tracking feature of sql server? How do you usually stream the data to a datalake or dw if streaming will be coming from 30 sql servers and need atleast 10 tables per servers.\n\nIm seeing some hints for kafka but its mostly about debezium which is only capable for CDC.....spark streaming would be possible but changes will not be so many. It is like 10-30 changes every 5 minutes.\n\nMaybe there's more efficient way, hoping to hear some", "author_fullname": "t2_5g5u53hz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multiple sql server stream to datalake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bficq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697709507.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone here use the change tracking feature of sql server? How do you usually stream the data to a datalake or dw if streaming will be coming from 30 sql servers and need atleast 10 tables per servers.&lt;/p&gt;\n\n&lt;p&gt;Im seeing some hints for kafka but its mostly about debezium which is only capable for CDC.....spark streaming would be possible but changes will not be so many. It is like 10-30 changes every 5 minutes.&lt;/p&gt;\n\n&lt;p&gt;Maybe there&amp;#39;s more efficient way, hoping to hear some&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17bficq", "is_robot_indexable": true, "report_reasons": null, "author": "chanchan_delier", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bficq/multiple_sql_server_stream_to_datalake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bficq/multiple_sql_server_stream_to_datalake/", "subreddit_subscribers": 134854, "created_utc": 1697709507.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm new to Airflow and Docker and have a best practice question regarding a production deployment.\n\nI have Airflow with Docker installed on a remote linux host. I also currently have a pyenv virtual environment with python 3.11 on the same remote host and installed Airflow's modules into it via pip.  This is a dev environment. No issues in this setup, I can create and run simple DAG's in VS Code directing python to use the interpreter in the virtual environment.\n\nI have a nagging feeling this setup is not ideal for production as the virtual environment is maintained and dependent on the local host.\n\nQuestion:  For production, should I create another Docker container just for the Airflow modules so that everything (Airflow and the python interpreter) is running through Docker?\n\nOr should I keep the current setup for production?\n\nThere are many resources available on setting up Airflow on Docker but little in way of production guidance. (re where to put your python environments and use them) Your thoughts and ideas are appreciated, thank you.", "author_fullname": "t2_3amuxhl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow w/Python Best Practice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bf4bh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697708457.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697707817.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to Airflow and Docker and have a best practice question regarding a production deployment.&lt;/p&gt;\n\n&lt;p&gt;I have Airflow with Docker installed on a remote linux host. I also currently have a pyenv virtual environment with python 3.11 on the same remote host and installed Airflow&amp;#39;s modules into it via pip.  This is a dev environment. No issues in this setup, I can create and run simple DAG&amp;#39;s in VS Code directing python to use the interpreter in the virtual environment.&lt;/p&gt;\n\n&lt;p&gt;I have a nagging feeling this setup is not ideal for production as the virtual environment is maintained and dependent on the local host.&lt;/p&gt;\n\n&lt;p&gt;Question:  For production, should I create another Docker container just for the Airflow modules so that everything (Airflow and the python interpreter) is running through Docker?&lt;/p&gt;\n\n&lt;p&gt;Or should I keep the current setup for production?&lt;/p&gt;\n\n&lt;p&gt;There are many resources available on setting up Airflow on Docker but little in way of production guidance. (re where to put your python environments and use them) Your thoughts and ideas are appreciated, thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17bf4bh", "is_robot_indexable": true, "report_reasons": null, "author": "maxafrass", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bf4bh/airflow_wpython_best_practice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bf4bh/airflow_wpython_best_practice/", "subreddit_subscribers": 134854, "created_utc": 1697707817.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI am an experienced ETL developer with over 10 years and I am skilled in using tools like SSIS, Informatica and Python for ETL development.\n\nI am currently trying to Advance my career in the field and I was wondering which path to take. My major consideration is one that will still be in-demand for the 10 years or more and also one that has good pay grade as well as WFH opportunities.\n\nI am considering going into full blown career in data engineering (pipeline design, a good programming and server experience as well as  Containerization. **OR** one that focuses more on BIG DATA development.\n\nI know big data has been the buzz word since some years now but I am a bit concerned that its gradually not as loud as it used to be.\n\nI will appreciate your advise so much.", "author_fullname": "t2_dcnhwe2o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A career in Data Engineering or Big Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17blv3d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697729350.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I am an experienced ETL developer with over 10 years and I am skilled in using tools like SSIS, Informatica and Python for ETL development.&lt;/p&gt;\n\n&lt;p&gt;I am currently trying to Advance my career in the field and I was wondering which path to take. My major consideration is one that will still be in-demand for the 10 years or more and also one that has good pay grade as well as WFH opportunities.&lt;/p&gt;\n\n&lt;p&gt;I am considering going into full blown career in data engineering (pipeline design, a good programming and server experience as well as  Containerization. &lt;strong&gt;OR&lt;/strong&gt; one that focuses more on BIG DATA development.&lt;/p&gt;\n\n&lt;p&gt;I know big data has been the buzz word since some years now but I am a bit concerned that its gradually not as loud as it used to be.&lt;/p&gt;\n\n&lt;p&gt;I will appreciate your advise so much.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17blv3d", "is_robot_indexable": true, "report_reasons": null, "author": "MediumCat4064", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17blv3d/a_career_in_data_engineering_or_big_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17blv3d/a_career_in_data_engineering_or_big_data/", "subreddit_subscribers": 134854, "created_utc": 1697729350.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_uue07cnl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software engineering is about thinking, not typing", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bebep", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1697704285.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "jordankaye.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://jordankaye.dev/posts/thinking-not-typing//", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17bebep", "is_robot_indexable": true, "report_reasons": null, "author": "mowerr708", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bebep/software_engineering_is_about_thinking_not_typing/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://jordankaye.dev/posts/thinking-not-typing//", "subreddit_subscribers": 134854, "created_utc": 1697704285.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Anyone have good recommendations for sql (preferably postgres) servers that I can use for side projects I have? Want something that isn't pricey, since it's not something I make money off of lol. ", "author_fullname": "t2_k4oyb5z58", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SQL Servers for Personal Projects", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17azvdl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697659289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone have good recommendations for sql (preferably postgres) servers that I can use for side projects I have? Want something that isn&amp;#39;t pricey, since it&amp;#39;s not something I make money off of lol. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17azvdl", "is_robot_indexable": true, "report_reasons": null, "author": "SoccerFilmNerd", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17azvdl/sql_servers_for_personal_projects/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17azvdl/sql_servers_for_personal_projects/", "subreddit_subscribers": 134854, "created_utc": 1697659289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone,\n\nI've been assigned to support our Finance team and help them become a data-driven function.\n\nKeen to hear your stories if you've worked with a similar function before.\n\nMy observations so far:\n1- They are often left behind in terms of data changes upstream (eg: new revenue data)\n2- They constantly need data exports but won't/can't self-serve.\n3- Their needs seem quite simple though (bank reports in csv, accounting data from Xero, product and subscription data from our OLTP) - I might be oversimplifying/just see the tip of the iceberg here.\n\nI've also been trying to get them to use new BI tools (trialling Metabase atm) but so far not been very successfull in getting them to self-serve (it seems they mostly want to export to Excel/Sheets).", "author_fullname": "t2_ilw3j5ci", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Finance Team DE", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17beb0r", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697704242.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been assigned to support our Finance team and help them become a data-driven function.&lt;/p&gt;\n\n&lt;p&gt;Keen to hear your stories if you&amp;#39;ve worked with a similar function before.&lt;/p&gt;\n\n&lt;p&gt;My observations so far:\n1- They are often left behind in terms of data changes upstream (eg: new revenue data)\n2- They constantly need data exports but won&amp;#39;t/can&amp;#39;t self-serve.\n3- Their needs seem quite simple though (bank reports in csv, accounting data from Xero, product and subscription data from our OLTP) - I might be oversimplifying/just see the tip of the iceberg here.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve also been trying to get them to use new BI tools (trialling Metabase atm) but so far not been very successfull in getting them to self-serve (it seems they mostly want to export to Excel/Sheets).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17beb0r", "is_robot_indexable": true, "report_reasons": null, "author": "GiacomoLeopardi6", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17beb0r/finance_team_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17beb0r/finance_team_de/", "subreddit_subscribers": 134854, "created_utc": 1697704242.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are there any data engineering project courses available? I come from a different background than data engineering and have completed a diploma program and Zoomcamp in DE. I'm still actively searching for data engineering jobs and could use a mentor's guidance for improving my LinkedIn profile and resume. Simultaneously, I'm eager to embark on new projects that involve the community and help me gain more experience.", "author_fullname": "t2_71nzg158", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineering Project Course", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17b83bd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697681709.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any data engineering project courses available? I come from a different background than data engineering and have completed a diploma program and Zoomcamp in DE. I&amp;#39;m still actively searching for data engineering jobs and could use a mentor&amp;#39;s guidance for improving my LinkedIn profile and resume. Simultaneously, I&amp;#39;m eager to embark on new projects that involve the community and help me gain more experience.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17b83bd", "is_robot_indexable": true, "report_reasons": null, "author": "BeltUsual3130", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17b83bd/data_engineering_project_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17b83bd/data_engineering_project_course/", "subreddit_subscribers": 134854, "created_utc": 1697681709.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have some money I can use for a short outsourced project (~$180k)\n\nCompany profile: pharma manufacturing; ~800 people across a few sites, most people rely on data of some sort, mainly SAP. ~200 people have office roles and as such drill into data lot more. Our team is 3 people; me (~ 10 years data science + little bit of engineering background), 2 very junior (but good) others. No scope for more headcount now\n\nI started the team in the company 2 years ago. Since then, we have done a lot of quick win analyses/apps (source data -&gt; target outcome), without tackling any of the data integration, data governance, reporting challenges. I now feel it's time we begin building out our data pipelines, and in particular, pulling data from our most important platforms (CRM; ERP - SAP, time series sensor data), and the various set of \"important spreadsheets\" scattered around the place. Once we have the core data stack in place, I hope we'll be able to manage better and deliver more as a very small team\n\nSAP (onprem S/4HANA) is the most important data source. We have a bit of SAP experience (relevant data objects and tables), and quite a bit of business domain understanding (what reports and analysis people want). Given some of my experience with SAP, I am very averse to wanting to go down the path of building more in SAP: BW4/HANA, SAC, ...\n\nWhat I'm thinking is that we build a short 3-5 page request for proposal (RFP) to \"build our data stack\" without actually specifying the tech stack we want, with some high level requirements of\n\n* Enable iterative building of data integrations from System X, Y, Z into a cloud platform staging area (e.g. data lake). These data integrations will only very rarely be required to be faster than daily batch jobs. We have a preference for Azure\n* Enable data transformations from staging area to build views/marts suitable for business reports. We have a preference for SQL, Python, R for transformation and PowerBI for reporting \n* Enable data analysis suitable for detailed investigations. We have a preference for R, but Python is desirable too\n* We have a preference for popular and open tools with minimal maintenance\n\nAnother direction to go down would be data governance, but I feel that we can only really get started on that once we have a data stack\n\nThe main challenges we have are (a) compliance - we need to prove data landing in reports is the same (conditional on transformation) as in the source system, (b) low experience/skill IT team - we ask for X and they don't know what it is\n\nWe've just signed up for Microsoft Fabric - which looks like we might be able to get started quickly - but I feel it's not a full enough platform yet, so it's a risk for us to dive into that\n\nThoughts? Anything I can add that would be helpful?\n\nThanks very much", "author_fullname": "t2_4t8zz1xo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you spend $180k on?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17b0jhs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.73, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697661031.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have some money I can use for a short outsourced project (~$180k)&lt;/p&gt;\n\n&lt;p&gt;Company profile: pharma manufacturing; ~800 people across a few sites, most people rely on data of some sort, mainly SAP. ~200 people have office roles and as such drill into data lot more. Our team is 3 people; me (~ 10 years data science + little bit of engineering background), 2 very junior (but good) others. No scope for more headcount now&lt;/p&gt;\n\n&lt;p&gt;I started the team in the company 2 years ago. Since then, we have done a lot of quick win analyses/apps (source data -&amp;gt; target outcome), without tackling any of the data integration, data governance, reporting challenges. I now feel it&amp;#39;s time we begin building out our data pipelines, and in particular, pulling data from our most important platforms (CRM; ERP - SAP, time series sensor data), and the various set of &amp;quot;important spreadsheets&amp;quot; scattered around the place. Once we have the core data stack in place, I hope we&amp;#39;ll be able to manage better and deliver more as a very small team&lt;/p&gt;\n\n&lt;p&gt;SAP (onprem S/4HANA) is the most important data source. We have a bit of SAP experience (relevant data objects and tables), and quite a bit of business domain understanding (what reports and analysis people want). Given some of my experience with SAP, I am very averse to wanting to go down the path of building more in SAP: BW4/HANA, SAC, ...&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m thinking is that we build a short 3-5 page request for proposal (RFP) to &amp;quot;build our data stack&amp;quot; without actually specifying the tech stack we want, with some high level requirements of&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Enable iterative building of data integrations from System X, Y, Z into a cloud platform staging area (e.g. data lake). These data integrations will only very rarely be required to be faster than daily batch jobs. We have a preference for Azure&lt;/li&gt;\n&lt;li&gt;Enable data transformations from staging area to build views/marts suitable for business reports. We have a preference for SQL, Python, R for transformation and PowerBI for reporting &lt;/li&gt;\n&lt;li&gt;Enable data analysis suitable for detailed investigations. We have a preference for R, but Python is desirable too&lt;/li&gt;\n&lt;li&gt;We have a preference for popular and open tools with minimal maintenance&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Another direction to go down would be data governance, but I feel that we can only really get started on that once we have a data stack&lt;/p&gt;\n\n&lt;p&gt;The main challenges we have are (a) compliance - we need to prove data landing in reports is the same (conditional on transformation) as in the source system, (b) low experience/skill IT team - we ask for X and they don&amp;#39;t know what it is&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve just signed up for Microsoft Fabric - which looks like we might be able to get started quickly - but I feel it&amp;#39;s not a full enough platform yet, so it&amp;#39;s a risk for us to dive into that&lt;/p&gt;\n\n&lt;p&gt;Thoughts? Anything I can add that would be helpful?&lt;/p&gt;\n\n&lt;p&gt;Thanks very much&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17b0jhs", "is_robot_indexable": true, "report_reasons": null, "author": "c3f7", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17b0jhs/what_would_you_spend_180k_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17b0jhs/what_would_you_spend_180k_on/", "subreddit_subscribers": 134854, "created_utc": 1697661031.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone!\n\nI\u2019m currently a Senior Data Engineer working with  AWS and I would like to know your opinion if the AWS SAA cert is worth it?\n\nI already have the knowledge, just thinking if having the certification will help somehow for new roles in the future.\n\nAnd also, if going for any cert, should just skip SAA and go for the Data Analytics Specialty?", "author_fullname": "t2_3ng50ktz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is AWS Solutions Architect useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17be0d0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "02917a1a-ac9d-11eb-beee-0ed0a94b470d", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697702912.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone!&lt;/p&gt;\n\n&lt;p&gt;I\u2019m currently a Senior Data Engineer working with  AWS and I would like to know your opinion if the AWS SAA cert is worth it?&lt;/p&gt;\n\n&lt;p&gt;I already have the knowledge, just thinking if having the certification will help somehow for new roles in the future.&lt;/p&gt;\n\n&lt;p&gt;And also, if going for any cert, should just skip SAA and go for the Data Analytics Specialty?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Senior Data Engineer", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "17be0d0", "is_robot_indexable": true, "report_reasons": null, "author": "BramosR", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/17be0d0/is_aws_solutions_architect_useful/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17be0d0/is_aws_solutions_architect_useful/", "subreddit_subscribers": 134854, "created_utc": 1697702912.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all - I\u2019m an experienced DE but I have never gotten the opportunity to work with real-time/event data as it\u2019s generated and stored. An example could be Instagram. Millions of people are clicking, searching, liking stuff every minute. I understand the need for a streaming pipeline that gets this data from APIs via Kafka Connect or something and potentially loads into a NoSQL database like Cassandra or MongoDB. This is all OLTP until now.\n\nMy primary question is how is this data stored in a data warehouse like Snowflake or BigQuery. More specifically, the  number of metrics to store (like/comment/share/search) are pretty big. So do each of these metrics become a 1/0 metric in the same fact table. Example, is_like, is_comment etc. Columnar databases can handle a lottttt of columns, so is this how data is actually stored for massive companies? Or am I thinking about it completely wrong? \n\nAppreciate any insight.", "author_fullname": "t2_3auynywj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Guidance on how event data is stored in a DWH", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17b2d47", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697665706.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all - I\u2019m an experienced DE but I have never gotten the opportunity to work with real-time/event data as it\u2019s generated and stored. An example could be Instagram. Millions of people are clicking, searching, liking stuff every minute. I understand the need for a streaming pipeline that gets this data from APIs via Kafka Connect or something and potentially loads into a NoSQL database like Cassandra or MongoDB. This is all OLTP until now.&lt;/p&gt;\n\n&lt;p&gt;My primary question is how is this data stored in a data warehouse like Snowflake or BigQuery. More specifically, the  number of metrics to store (like/comment/share/search) are pretty big. So do each of these metrics become a 1/0 metric in the same fact table. Example, is_like, is_comment etc. Columnar databases can handle a lottttt of columns, so is this how data is actually stored for massive companies? Or am I thinking about it completely wrong? &lt;/p&gt;\n\n&lt;p&gt;Appreciate any insight.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17b2d47", "is_robot_indexable": true, "report_reasons": null, "author": "currentlyreadingit", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17b2d47/guidance_on_how_event_data_is_stored_in_a_dwh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17b2d47/guidance_on_how_event_data_is_stored_in_a_dwh/", "subreddit_subscribers": 134854, "created_utc": 1697665706.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've recently had the chance to explore e-commerce APIs (helping a friend out with their startup), and I'm looking for help on a seemingly simple task that has me confused.\n\nThe vendor APIs will provide info on various conversions by users. Fields of interest to us would be the conversion_id, and the conversion_status. We want to capture changes in the status and forward those conversions to another database. I.e. if a conversions status during the last update was different to its status today, we want to capture it.\n\nWe would hit the APIs about once a day to get updates on these conversions. Here's my idea so far:\n\n1. Our data isn't massive, so I'm ok with sticking with python+postgres and cron.\n\n2. Python to hit the API, go through all pages in the response, concat those into one long JSON and dump it into a jsonb column.\n\n3. I would use a table specifically as a data dump, with three columns: run_date, api_name, json_data.\n\n4. Create views for each API, extracting out the fields specific to that vendor. These would generally include the conversion Id, run date and the status.\n\n5. Use the LAG function to compare the status on this run to the status from the last run.\n\n6. If the status change is relevant to us, capture that conversion and forward it.\n\nThis seems like it would work, but it does seem a little hacky to me. Also not sure if it would scale with multiple vendors.\n\nIs there a better way to do this that is standard practice?", "author_fullname": "t2_d8wq0wkd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice for capturing changes in column values", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17avpdg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697648615.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve recently had the chance to explore e-commerce APIs (helping a friend out with their startup), and I&amp;#39;m looking for help on a seemingly simple task that has me confused.&lt;/p&gt;\n\n&lt;p&gt;The vendor APIs will provide info on various conversions by users. Fields of interest to us would be the conversion_id, and the conversion_status. We want to capture changes in the status and forward those conversions to another database. I.e. if a conversions status during the last update was different to its status today, we want to capture it.&lt;/p&gt;\n\n&lt;p&gt;We would hit the APIs about once a day to get updates on these conversions. Here&amp;#39;s my idea so far:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Our data isn&amp;#39;t massive, so I&amp;#39;m ok with sticking with python+postgres and cron.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Python to hit the API, go through all pages in the response, concat those into one long JSON and dump it into a jsonb column.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I would use a table specifically as a data dump, with three columns: run_date, api_name, json_data.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Create views for each API, extracting out the fields specific to that vendor. These would generally include the conversion Id, run date and the status.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Use the LAG function to compare the status on this run to the status from the last run.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;If the status change is relevant to us, capture that conversion and forward it.&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This seems like it would work, but it does seem a little hacky to me. Also not sure if it would scale with multiple vendors.&lt;/p&gt;\n\n&lt;p&gt;Is there a better way to do this that is standard practice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17avpdg", "is_robot_indexable": true, "report_reasons": null, "author": "fabricmoo", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17avpdg/advice_for_capturing_changes_in_column_values/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17avpdg/advice_for_capturing_changes_in_column_values/", "subreddit_subscribers": 134854, "created_utc": 1697648615.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " The  data is being made available as SQL Server Analysis Services Cubes. I  know I can use a program like Microsoft Power BI to connect directly to  these, but if I have a PHP site, how can I either connect to these to  query them (even if I have to do MDX query or likewise), or, how can I  convert the output from these Cubes back into a regular database so I  can query it using regular SQL?\n\nI  just need some way to get the data I need out of these cubes to use on a  website which uses php. whether its directly or by snapshotting the  data into a DB periodically to run queries against.\n\nThanks", "author_fullname": "t2_9lf6bs4dn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Query SSAS OLAP/MOLAP Cube with PHP?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17bngc2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697733588.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The  data is being made available as SQL Server Analysis Services Cubes. I  know I can use a program like Microsoft Power BI to connect directly to  these, but if I have a PHP site, how can I either connect to these to  query them (even if I have to do MDX query or likewise), or, how can I  convert the output from these Cubes back into a regular database so I  can query it using regular SQL?&lt;/p&gt;\n\n&lt;p&gt;I  just need some way to get the data I need out of these cubes to use on a  website which uses php. whether its directly or by snapshotting the  data into a DB periodically to run queries against.&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17bngc2", "is_robot_indexable": true, "report_reasons": null, "author": "Intense_011", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bngc2/query_ssas_olapmolap_cube_with_php/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bngc2/query_ssas_olapmolap_cube_with_php/", "subreddit_subscribers": 134854, "created_utc": 1697733588.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, someone of you know how to do that?\nI'm looking in internet about bulk copy but if i have a dagster/mage orchestration how can i do that?", "author_fullname": "t2_bvpnqeta", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can copy data bethween csv in S3/GCS to SQL server DB?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17bnfsc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697733545.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, someone of you know how to do that?\nI&amp;#39;m looking in internet about bulk copy but if i have a dagster/mage orchestration how can i do that?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "17bnfsc", "is_robot_indexable": true, "report_reasons": null, "author": "aaaasd12", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bnfsc/how_can_copy_data_bethween_csv_in_s3gcs_to_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bnfsc/how_can_copy_data_bethween_csv_in_s3gcs_to_sql/", "subreddit_subscribers": 134854, "created_utc": 1697733545.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi\nI have a spark application which requires a token to access a certain sysyem. The lib I am using to connect the said sysyem requires token in application.conf file. How can I make sure that my spark scala job have the conf file at runtime. As of now I am manually copying the file to hdfs directory. But if I put it in src/main/resources directory workers are not able to find it. As its a access token I cannot commit the application.conf to git repo. It will fail security check.  What options I have to make a resource available to all workers at runtime?", "author_fullname": "t2_gzyg3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cannot find application.conf issue", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17bmk9x", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697731230.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi\nI have a spark application which requires a token to access a certain sysyem. The lib I am using to connect the said sysyem requires token in application.conf file. How can I make sure that my spark scala job have the conf file at runtime. As of now I am manually copying the file to hdfs directory. But if I put it in src/main/resources directory workers are not able to find it. As its a access token I cannot commit the application.conf to git repo. It will fail security check.  What options I have to make a resource available to all workers at runtime?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17bmk9x", "is_robot_indexable": true, "report_reasons": null, "author": "ps2931", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bmk9x/cannot_find_applicationconf_issue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bmk9x/cannot_find_applicationconf_issue/", "subreddit_subscribers": 134854, "created_utc": 1697731230.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "At the moment, when we \"run\" a dbt project, we are more or less running every model in the project. Our largest project has ~450 models and takes under an hour to complete. We have a cron schedule that invokes the run and a step function that defines the flow between states (projects and their various dbt operations).\n\nDo folks who use airflow run smaller batches at a time? This seems hard to manage, also seems like you would end up duplicating steps as you build a shared dependency multiple times.", "author_fullname": "t2_6nf2i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How exactly are you using airflow with dbt?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17bmbov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697730598.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At the moment, when we &amp;quot;run&amp;quot; a dbt project, we are more or less running every model in the project. Our largest project has ~450 models and takes under an hour to complete. We have a cron schedule that invokes the run and a step function that defines the flow between states (projects and their various dbt operations).&lt;/p&gt;\n\n&lt;p&gt;Do folks who use airflow run smaller batches at a time? This seems hard to manage, also seems like you would end up duplicating steps as you build a shared dependency multiple times.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17bmbov", "is_robot_indexable": true, "report_reasons": null, "author": "radil", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bmbov/how_exactly_are_you_using_airflow_with_dbt/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bmbov/how_exactly_are_you_using_airflow_with_dbt/", "subreddit_subscribers": 134854, "created_utc": 1697730598.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m looking to switch into data engineering and am wondering if getting certs are worth it and which ones. For context, I have a data science MS and stats undergrad and 2 deep learning internships, but just want to transition away from deep learning right now. I am currently learning some data engineering basics off the resources on the dataengineering wiki and was wondering if picking up some certs would be worth it.", "author_fullname": "t2_1vuo9y61", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Certs useful?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17bkc9q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697725322.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to switch into data engineering and am wondering if getting certs are worth it and which ones. For context, I have a data science MS and stats undergrad and 2 deep learning internships, but just want to transition away from deep learning right now. I am currently learning some data engineering basics off the resources on the dataengineering wiki and was wondering if picking up some certs would be worth it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17bkc9q", "is_robot_indexable": true, "report_reasons": null, "author": "bobp25", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bkc9q/certs_useful/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17bkc9q/certs_useful/", "subreddit_subscribers": 134854, "created_utc": 1697725322.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_llltp0a4r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multi-Cloud Migration: Harnessing the Power of Multiple Cloud Providers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": false, "name": "t3_17bhig4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/9hw6gXTcDzOBkFv0ZVRbiUBStJeOOKwAgGzJNI5KOVM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697716956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "nallas.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://nallas.com/multi-cloud-migration-harnessing-the-power-of-multiple-cloud-providers/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nvG0dGBXBpSJsYZzvsByXm3J_FjQSFdf6CbL45IRFQw.jpg?auto=webp&amp;s=c11933f1af26e3add60f428492e18039805b02de", "width": 1920, "height": 1080}, "resolutions": [{"url": "https://external-preview.redd.it/nvG0dGBXBpSJsYZzvsByXm3J_FjQSFdf6CbL45IRFQw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=69b9c355e840a8fab7746dd10b021e305905e9ac", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/nvG0dGBXBpSJsYZzvsByXm3J_FjQSFdf6CbL45IRFQw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=266004acbd6b8130c8d13f0b3d00abe02e2d3c2b", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/nvG0dGBXBpSJsYZzvsByXm3J_FjQSFdf6CbL45IRFQw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=eb1b9de0984719a89290040fa9e9aabab7aeadc7", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/nvG0dGBXBpSJsYZzvsByXm3J_FjQSFdf6CbL45IRFQw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b47b38d3f6518feb3ba5373567ccca18b7a37317", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/nvG0dGBXBpSJsYZzvsByXm3J_FjQSFdf6CbL45IRFQw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8415a7d5013da02d9d30ec2c16ab83cd8be0ddfb", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/nvG0dGBXBpSJsYZzvsByXm3J_FjQSFdf6CbL45IRFQw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1c63c7d2fa4d4e09fdb48cccb65bd7c85a302296", "width": 1080, "height": 607}], "variants": {}, "id": "vYFXNiuP1JBmetpGcn3zJMkxjHtw1nlqh_Ii70RdfB8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17bhig4", "is_robot_indexable": true, "report_reasons": null, "author": "Nallas_Corporation", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17bhig4/multicloud_migration_harnessing_the_power_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://nallas.com/multi-cloud-migration-harnessing-the-power-of-multiple-cloud-providers/", "subreddit_subscribers": 134854, "created_utc": 1697716956.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}