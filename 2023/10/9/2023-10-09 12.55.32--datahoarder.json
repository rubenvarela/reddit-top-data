{"kind": "Listing", "data": {"after": "t3_173mvmb", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A while back me and an acquaintance downloaded 50gb of print ad listings from an eBay account. I had discovered that the seller was selling pages from rare toy magazines that haven't been digitized. Theoretically, a large portion of these magazines could be saved by sorting the listings into their respective publications and issues. The problem is, we have all of these pages but no way to sort them automatically. The listings were not named by publication, but by content, so unfortunately we can't just use the titles.\n\nThe only idea I could come up with was using an OCR algorithm to read every page and sort them based on the footers reading the publication and issue month. I just don't know how to do that or how easy it would be to set up.\n\nThis would be a great research resource for others, I don't think even The Strong has some of these toy magazines. If anyone can come up with an idea or is open to writing a program that can automatically sort it all, that would be fantastic.", "author_fullname": "t2_b8qqcytr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sorting over 60k pages of toy ads spanning a century", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173gdqa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 50, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 50, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696816982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A while back me and an acquaintance downloaded 50gb of print ad listings from an eBay account. I had discovered that the seller was selling pages from rare toy magazines that haven&amp;#39;t been digitized. Theoretically, a large portion of these magazines could be saved by sorting the listings into their respective publications and issues. The problem is, we have all of these pages but no way to sort them automatically. The listings were not named by publication, but by content, so unfortunately we can&amp;#39;t just use the titles.&lt;/p&gt;\n\n&lt;p&gt;The only idea I could come up with was using an OCR algorithm to read every page and sort them based on the footers reading the publication and issue month. I just don&amp;#39;t know how to do that or how easy it would be to set up.&lt;/p&gt;\n\n&lt;p&gt;This would be a great research resource for others, I don&amp;#39;t think even The Strong has some of these toy magazines. If anyone can come up with an idea or is open to writing a program that can automatically sort it all, that would be fantastic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173gdqa", "is_robot_indexable": true, "report_reasons": null, "author": "doodlebuuggg", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173gdqa/sorting_over_60k_pages_of_toy_ads_spanning_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173gdqa/sorting_over_60k_pages_of_toy_ads_spanning_a/", "subreddit_subscribers": 705761, "created_utc": 1696816982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I ran a SMART test in TrueNAS for an old 6TB Western Digital Green drive (model WD60EZRX), and although TureNAS is telling me that the drive has failed the test, `smartctl` gives a status of \"SMART overall-health self-assessment test result: PASSED\" and all of my actual values look okay.  I'm trying to figure out what's going on.\n\nFrom what I can tell, the issue is that the test isn't completing.  I'm seeing this in the `General SMART Values:` section:\n\n    \tSelf-test execution status:      (  57) A fatal error or unknown test error\n    \t                                        occurred while the device was executing\n    \t                                        its self-test routine and the device \n    \t                                        was unable to complete the self-test \n    \t                                        routine.\n\nAnd under `SMART Self-test log structure` I'm seeing this:\n\n    \tSMART Self-test log structure revision number 1\n    \tNum  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error\n    \t# 1  Short offline       Fatal or unknown error        90%     43903         -\n    \t# 2  Extended offline    Fatal or unknown error        90%     43881         -\n    \t# 3  Short offline       Fatal or unknown error        90%     43879         -\n\n\n\n#**HOWEVER**! \nIt does look like it's updating the disk values in the `Vendor Specific SMART Attributes with Thresholds` section.  Here's the output of the first and second SMART tests for comparison:\n\n    \tSMART Attributes Data Structure revision number: 16\n    \tVendor Specific SMART Attributes with Thresholds:\n    \tID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n    \t  1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n    \t  3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n    \t  4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n    \t  5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n    \t  7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n    \t  9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43890\n    \t 10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n    \t 11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n    \t 12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    \t192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    \t193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123623\n    \t194 Temperature_Celsius     0x0022   123   103   000    Old_age   Always       -       29\n    \t196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    \t197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    \t198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    \t199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    \t200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n    \t\n    \tSMART Error Log Version: 1\n    \tNo Errors Logged\n\nAnd the second test:\n\n    SMART Attributes Data Structure revision number: 16\n    \tVendor Specific SMART Attributes with Thresholds:\n    \tID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n    \t  1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n    \t  3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n    \t  4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n    \t  5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n    \t  7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n    \t  9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43903\n    \t 10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n    \t 11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n    \t 12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    \t192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    \t193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123650\n    \t194 Temperature_Celsius     0x0022   119   103   000    Old_age   Always       -       33\n    \t196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    \t197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    \t198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    \t199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    \t200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n    \t\n    \tSMART Error Log Version: 1\n    \tNo Errors Logged\n\nBetween the first and second test, I filled the drive with random data overnight, but it didn't seem to make any difference.\n\nI have no clue what to make of this.  Everything tests well within tolerances, but the testing isn't completing properly?  No idea what to do with this.\n\nAny suggestions for next steps?  I have a Windows box I can plug this drive into for further testing, but is there any reason to think I'd get a different result?  I'm pretty stumped on this one.  Full logs in the comments in case it's helpful.", "author_fullname": "t2_vqak2uq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TrueNAS Scale shows that my drive's SMART test failed, but `smartctl` says it passed. Do I really have a problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1732na8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696781061.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696780669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ran a SMART test in TrueNAS for an old 6TB Western Digital Green drive (model WD60EZRX), and although TureNAS is telling me that the drive has failed the test, &lt;code&gt;smartctl&lt;/code&gt; gives a status of &amp;quot;SMART overall-health self-assessment test result: PASSED&amp;quot; and all of my actual values look okay.  I&amp;#39;m trying to figure out what&amp;#39;s going on.&lt;/p&gt;\n\n&lt;p&gt;From what I can tell, the issue is that the test isn&amp;#39;t completing.  I&amp;#39;m seeing this in the &lt;code&gt;General SMART Values:&lt;/code&gt; section:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    Self-test execution status:      (  57) A fatal error or unknown test error\n                                            occurred while the device was executing\n                                            its self-test routine and the device \n                                            was unable to complete the self-test \n                                            routine.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And under &lt;code&gt;SMART Self-test log structure&lt;/code&gt; I&amp;#39;m seeing this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    SMART Self-test log structure revision number 1\n    Num  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error\n    # 1  Short offline       Fatal or unknown error        90%     43903         -\n    # 2  Extended offline    Fatal or unknown error        90%     43881         -\n    # 3  Short offline       Fatal or unknown error        90%     43879         -\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h1&gt;&lt;strong&gt;HOWEVER&lt;/strong&gt;!&lt;/h1&gt;\n\n&lt;p&gt;It does look like it&amp;#39;s updating the disk values in the &lt;code&gt;Vendor Specific SMART Attributes with Thresholds&lt;/code&gt; section.  Here&amp;#39;s the output of the first and second SMART tests for comparison:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    SMART Attributes Data Structure revision number: 16\n    Vendor Specific SMART Attributes with Thresholds:\n    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n      1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n      3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n      4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n      5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n      7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n      9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43890\n     10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n     11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n     12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123623\n    194 Temperature_Celsius     0x0022   123   103   000    Old_age   Always       -       29\n    196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n\n    SMART Error Log Version: 1\n    No Errors Logged\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And the second test:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SMART Attributes Data Structure revision number: 16\n    Vendor Specific SMART Attributes with Thresholds:\n    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n      1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n      3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n      4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n      5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n      7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n      9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43903\n     10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n     11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n     12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123650\n    194 Temperature_Celsius     0x0022   119   103   000    Old_age   Always       -       33\n    196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n\n    SMART Error Log Version: 1\n    No Errors Logged\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Between the first and second test, I filled the drive with random data overnight, but it didn&amp;#39;t seem to make any difference.&lt;/p&gt;\n\n&lt;p&gt;I have no clue what to make of this.  Everything tests well within tolerances, but the testing isn&amp;#39;t completing properly?  No idea what to do with this.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for next steps?  I have a Windows box I can plug this drive into for further testing, but is there any reason to think I&amp;#39;d get a different result?  I&amp;#39;m pretty stumped on this one.  Full logs in the comments in case it&amp;#39;s helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1732na8", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyForSomeThings", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1732na8/truenas_scale_shows_that_my_drives_smart_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1732na8/truenas_scale_shows_that_my_drives_smart_test/", "subreddit_subscribers": 705761, "created_utc": 1696780669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been writing BD-REs with CDBurnerXP, and every single time I used \"verify data after burning\".\n\nI am using an external Blu-ray recorder. The ASUS SBW-06D5H-U. Connected with a 2 meter USB-C cable (+ 3.2 Micro-B for the device).\n\nIt came with a 0.5 m cable, not enough for me, so I got this other one.\n\n\\+++++++\n\nI noticed that on my i5 11400 (now 32 GB of DDR-4 RAM, MB is Z590-A Pro, from MSI), using two SSDs, one for C: is a 2 TB NVME from Western Digital, the other 870 EVO 4 TB from Samsung (regular):\n\n\\- It takes 40-45 minutes to burn a rewritable 25 GB disc; I tried in 2x, Ritek media;\n\n\\- I always use CDBurnerXP, and \"verify data after burning\".\n\nIn the past I used an old internal drive, the GGW-H20L from LG;\n\nI once bought 50 discs and noticed all 49 were recorded OK;\n\nIt takes additional 40-45 minutes to verify data after burning. I always let this enabled, to check if there isn't any data corruption. Is this a good idea?\n\nThe 50th disc which was not OK, I think I only spotted a problem with the \"verify after burning\". Most of the contents were fine; some were not, and could not be played (all my discs are backups, data only).\n\nThen I inspected the disc and noticed a very small scratch in the surface. Which accounts for the errors, that blank disc was already flawed.\n\n\\+++++\n\nA few more things I want to point out:\n\n\\- If I simply copy (control + C and control + V) the entire 25 GB disc (or 23 = real size) to my NVME SSD, it will take 25 minutes. But if I do the same for the Samsung regular SSD, it will take 35-40 minutes. I didn't know it was going to be slower depending on the SSD, I thought this was limited by the reader/disc speeds, regardless of the SSD used.\n\n\\++++  \nSome users on this sub and on the internet suggested IMGBURN instead, There's just one problem - CDBURNERXP is updated, while IMGBURN is no longer developed, the last version is [2.5.8.0](https://2.5.8.0), from 10 years ago. Even if you say it doesn't matter how old it is (for the purpose of burning and checking), are there any reasons to use IMGBURN instead, or it doesn't matter which one we choose?", "author_fullname": "t2_1utoiwm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Verifying a disc after burning, copying files back, and ImgBurn vs. CDBurnerXP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1733bf0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.74, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696782383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been writing BD-REs with CDBurnerXP, and every single time I used &amp;quot;verify data after burning&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I am using an external Blu-ray recorder. The ASUS SBW-06D5H-U. Connected with a 2 meter USB-C cable (+ 3.2 Micro-B for the device).&lt;/p&gt;\n\n&lt;p&gt;It came with a 0.5 m cable, not enough for me, so I got this other one.&lt;/p&gt;\n\n&lt;p&gt;+++++++&lt;/p&gt;\n\n&lt;p&gt;I noticed that on my i5 11400 (now 32 GB of DDR-4 RAM, MB is Z590-A Pro, from MSI), using two SSDs, one for C: is a 2 TB NVME from Western Digital, the other 870 EVO 4 TB from Samsung (regular):&lt;/p&gt;\n\n&lt;p&gt;- It takes 40-45 minutes to burn a rewritable 25 GB disc; I tried in 2x, Ritek media;&lt;/p&gt;\n\n&lt;p&gt;- I always use CDBurnerXP, and &amp;quot;verify data after burning&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;In the past I used an old internal drive, the GGW-H20L from LG;&lt;/p&gt;\n\n&lt;p&gt;I once bought 50 discs and noticed all 49 were recorded OK;&lt;/p&gt;\n\n&lt;p&gt;It takes additional 40-45 minutes to verify data after burning. I always let this enabled, to check if there isn&amp;#39;t any data corruption. Is this a good idea?&lt;/p&gt;\n\n&lt;p&gt;The 50th disc which was not OK, I think I only spotted a problem with the &amp;quot;verify after burning&amp;quot;. Most of the contents were fine; some were not, and could not be played (all my discs are backups, data only).&lt;/p&gt;\n\n&lt;p&gt;Then I inspected the disc and noticed a very small scratch in the surface. Which accounts for the errors, that blank disc was already flawed.&lt;/p&gt;\n\n&lt;p&gt;+++++&lt;/p&gt;\n\n&lt;p&gt;A few more things I want to point out:&lt;/p&gt;\n\n&lt;p&gt;- If I simply copy (control + C and control + V) the entire 25 GB disc (or 23 = real size) to my NVME SSD, it will take 25 minutes. But if I do the same for the Samsung regular SSD, it will take 35-40 minutes. I didn&amp;#39;t know it was going to be slower depending on the SSD, I thought this was limited by the reader/disc speeds, regardless of the SSD used.&lt;/p&gt;\n\n&lt;p&gt;++++&lt;br/&gt;\nSome users on this sub and on the internet suggested IMGBURN instead, There&amp;#39;s just one problem - CDBURNERXP is updated, while IMGBURN is no longer developed, the last version is &lt;a href=\"https://2.5.8.0\"&gt;2.5.8.0&lt;/a&gt;, from 10 years ago. Even if you say it doesn&amp;#39;t matter how old it is (for the purpose of burning and checking), are there any reasons to use IMGBURN instead, or it doesn&amp;#39;t matter which one we choose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1733bf0", "is_robot_indexable": true, "report_reasons": null, "author": "Maratocarde", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1733bf0/verifying_a_disc_after_burning_copying_files_back/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1733bf0/verifying_a_disc_after_burning_copying_files_back/", "subreddit_subscribers": 705761, "created_utc": 1696782383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there datahoarders, I was searching for a lot of time for solutions for bulk download from zlib. Sadly I wasn't able to find any real solutions. There was a post about this topic 3 years ago but there was no real solution.   \n\n\nDoes any one of you know about a solution for this? I am a bit skeptical and would love to have a database of books for personal use and would love to download non fiction books. ", "author_fullname": "t2_jvrt4662", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zlibrary Book Download", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17302gj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696774191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there datahoarders, I was searching for a lot of time for solutions for bulk download from zlib. Sadly I wasn&amp;#39;t able to find any real solutions. There was a post about this topic 3 years ago but there was no real solution.   &lt;/p&gt;\n\n&lt;p&gt;Does any one of you know about a solution for this? I am a bit skeptical and would love to have a database of books for personal use and would love to download non fiction books. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17302gj", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic-Patient56", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17302gj/zlibrary_book_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17302gj/zlibrary_book_download/", "subreddit_subscribers": 705761, "created_utc": 1696774191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://github.com/HybridWare/hybrid-browser](https://github.com/HybridWare/hybrid-browser/releases/tag/2.0.0)\n\n[https://github.com/HybridWare/hybrid-browser/releases/tag/2.0.0](https://github.com/HybridWare/hybrid-browser/releases/tag/2.0.0)\n\nthis is a web browser that directly supports bittorrent, ipfs, hyper and other networks\n\ni see a lot of archives being uploaded to bittorrent and ipfs, using this you can view all of that data in one app\n\nyou can also create and host websites in p2p networks and then you can interact with data from muleiple networks in a single webpage\n\nexample\n\n&lt;img src=\"http://somesite.com/file.jpeg\" width=\"500\" height=\"600\"&gt; \n\nnow you can\n\n&lt;img src=\"http://somesite.com/file.jpeg\" width=\"500\" height=\"600\"&gt; \n\n&lt;img src=\"bt://bittorrenturl/file.jpeg\" width=\"500\" height=\"600\"&gt; \n\n&lt;img src=\"ipfs://ipfsurl/file.jpeg\" width=\"500\" height=\"600\"&gt; \n\n&lt;img src=\"hyper://hyper/file.jpeg\" width=\"500\" height=\"600\"&gt; ", "author_fullname": "t2_12l7zu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "peer to peer web browser, great for archives and datahoarders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173du89", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696809402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/HybridWare/hybrid-browser/releases/tag/2.0.0\"&gt;https://github.com/HybridWare/hybrid-browser&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/HybridWare/hybrid-browser/releases/tag/2.0.0\"&gt;https://github.com/HybridWare/hybrid-browser/releases/tag/2.0.0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;this is a web browser that directly supports bittorrent, ipfs, hyper and other networks&lt;/p&gt;\n\n&lt;p&gt;i see a lot of archives being uploaded to bittorrent and ipfs, using this you can view all of that data in one app&lt;/p&gt;\n\n&lt;p&gt;you can also create and host websites in p2p networks and then you can interact with data from muleiple networks in a single webpage&lt;/p&gt;\n\n&lt;p&gt;example&lt;/p&gt;\n\n&lt;p&gt;&amp;lt;img src=&amp;quot;http://somesite.com/file.jpeg&amp;quot; width=&amp;quot;500&amp;quot; height=&amp;quot;600&amp;quot;&amp;gt; &lt;/p&gt;\n\n&lt;p&gt;now you can&lt;/p&gt;\n\n&lt;p&gt;&amp;lt;img src=&amp;quot;http://somesite.com/file.jpeg&amp;quot; width=&amp;quot;500&amp;quot; height=&amp;quot;600&amp;quot;&amp;gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;lt;img src=&amp;quot;bt://bittorrenturl/file.jpeg&amp;quot; width=&amp;quot;500&amp;quot; height=&amp;quot;600&amp;quot;&amp;gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;lt;img src=&amp;quot;ipfs://ipfsurl/file.jpeg&amp;quot; width=&amp;quot;500&amp;quot; height=&amp;quot;600&amp;quot;&amp;gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;lt;img src=&amp;quot;hyper://hyper/file.jpeg&amp;quot; width=&amp;quot;500&amp;quot; height=&amp;quot;600&amp;quot;&amp;gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?auto=webp&amp;s=da30c2db275f032ba21561e417fde8d81966ae96", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=280e6c0c842278c9c95c8acc38519134c3821971", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2584882816994000b863e86b910b750e22592270", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=481e194766cd98338750824a86e9e512396201bc", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ee08f301b11e082ab9d7377102da021a0f54d2f4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7b445b5e6139f8093328af7ffd921d28b2c566d4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=61666c59706a2f367873edbd0c760f0353767602", "width": 1080, "height": 540}], "variants": {}, "id": "YbOh1oig7LG7CocA_S5d0gG5JEKp9lDgV4VrvynNN7M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173du89", "is_robot_indexable": true, "report_reasons": null, "author": "thezzeds", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173du89/peer_to_peer_web_browser_great_for_archives_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173du89/peer_to_peer_web_browser_great_for_archives_and/", "subreddit_subscribers": 705761, "created_utc": 1696809402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a 2 TB SanDisk SSD on Amazon, and let it sit around for couple weeks before I got around to trying it out on my iMac. I struggled to get the thing recognized by the Mac, and then when it did show up, I couldn't format the drive to anything but MAC OS (attempts at APFS failed every time). Once it was formatted, file transfers were slow, and then the files I copied on there as a test just disappeared. Now the thing doesn't function at all, either on the Mac or on a Win 11 laptop. The thing is dead.\n\n&amp;#x200B;\n\nAm I just out the money I spent on it? I waited too long and I can't return it to Amazon, and SanDisk won't take it either. Also, what is a decent 2-4 TB SSD I could trust? The SanDisk looked really cool, but I certainly don't trust it to buy another one.", "author_fullname": "t2_4vnjyete", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SanDisk Extreme SSD bricked. What now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173a11c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696799368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a 2 TB SanDisk SSD on Amazon, and let it sit around for couple weeks before I got around to trying it out on my iMac. I struggled to get the thing recognized by the Mac, and then when it did show up, I couldn&amp;#39;t format the drive to anything but MAC OS (attempts at APFS failed every time). Once it was formatted, file transfers were slow, and then the files I copied on there as a test just disappeared. Now the thing doesn&amp;#39;t function at all, either on the Mac or on a Win 11 laptop. The thing is dead.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Am I just out the money I spent on it? I waited too long and I can&amp;#39;t return it to Amazon, and SanDisk won&amp;#39;t take it either. Also, what is a decent 2-4 TB SSD I could trust? The SanDisk looked really cool, but I certainly don&amp;#39;t trust it to buy another one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173a11c", "is_robot_indexable": true, "report_reasons": null, "author": "tedlyri", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173a11c/sandisk_extreme_ssd_bricked_what_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173a11c/sandisk_extreme_ssd_bricked_what_now/", "subreddit_subscribers": 705761, "created_utc": 1696799368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've bought plenty of \"normal\" HDDs and SSDs for my desktop PC, highest size being a WD Blue 6TB. Well, it's maxed out on space, and instead of wasting SATA space with another 6TB, I want to turn to NAS drives. I know literally next to nothing about them and what to look for if I intend to use one for simple image/file storage in my desktop (so not in a dedicated NAS setup). I really just want a high capacity with a decent value. Speed would be nice, too, but since the use case will probably include upwards of accessing images or simple files, speed isn't a priority, just a luxury.\n\nI've found a couple on Amazon, but again, I have no idea what I'm looking at to compare them to each other with their relative prices:\n\nLike this Seagate Exos X18 18TB @ $279 USD, or Seagate Ironwolf Pro 16TB @ $285 USD\n\nI figure the Ironwolf Pro just adds some markup for features I don't need, so I suppose I should disqualify that one. But what about other choices similar to the Exos at a similar price range? Most of these seem to be CRM 7200rpm in this class. And is that even a good price? \n\nNote, my max budget ideally is less than $250, but there seems to be only a $20 difference in price in the 14-18TB options.\n\nAlso, I haven't stalked these before - do these products ever take part in Prime Day deals? There's some deal days coming up this week, if I recall correctly.", "author_fullname": "t2_7damr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good bang-for-your-buck NAS drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173bp11", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696803552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve bought plenty of &amp;quot;normal&amp;quot; HDDs and SSDs for my desktop PC, highest size being a WD Blue 6TB. Well, it&amp;#39;s maxed out on space, and instead of wasting SATA space with another 6TB, I want to turn to NAS drives. I know literally next to nothing about them and what to look for if I intend to use one for simple image/file storage in my desktop (so not in a dedicated NAS setup). I really just want a high capacity with a decent value. Speed would be nice, too, but since the use case will probably include upwards of accessing images or simple files, speed isn&amp;#39;t a priority, just a luxury.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve found a couple on Amazon, but again, I have no idea what I&amp;#39;m looking at to compare them to each other with their relative prices:&lt;/p&gt;\n\n&lt;p&gt;Like this Seagate Exos X18 18TB @ $279 USD, or Seagate Ironwolf Pro 16TB @ $285 USD&lt;/p&gt;\n\n&lt;p&gt;I figure the Ironwolf Pro just adds some markup for features I don&amp;#39;t need, so I suppose I should disqualify that one. But what about other choices similar to the Exos at a similar price range? Most of these seem to be CRM 7200rpm in this class. And is that even a good price? &lt;/p&gt;\n\n&lt;p&gt;Note, my max budget ideally is less than $250, but there seems to be only a $20 difference in price in the 14-18TB options.&lt;/p&gt;\n\n&lt;p&gt;Also, I haven&amp;#39;t stalked these before - do these products ever take part in Prime Day deals? There&amp;#39;s some deal days coming up this week, if I recall correctly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173bp11", "is_robot_indexable": true, "report_reasons": null, "author": "PhotonWolfsky", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173bp11/good_bangforyourbuck_nas_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173bp11/good_bangforyourbuck_nas_drive/", "subreddit_subscribers": 705761, "created_utc": 1696803552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a functioning tool to download the saved posts / upvotes that you do on reddit? This tool: [https://github.com/shadowmoose/RedditDownloader](https://github.com/shadowmoose/RedditDownloader) was perfect, but it got rekt by the API changes and has been discontinued.", "author_fullname": "t2_16hsu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit downloader that works after API upgrade", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17304ho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696774341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a functioning tool to download the saved posts / upvotes that you do on reddit? This tool: &lt;a href=\"https://github.com/shadowmoose/RedditDownloader\"&gt;https://github.com/shadowmoose/RedditDownloader&lt;/a&gt; was perfect, but it got rekt by the API changes and has been discontinued.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17304ho", "is_robot_indexable": true, "report_reasons": null, "author": "TheSaltyJ", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17304ho/reddit_downloader_that_works_after_api_upgrade/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17304ho/reddit_downloader_that_works_after_api_upgrade/", "subreddit_subscribers": 705761, "created_utc": 1696774341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have about 5 hard drives I use to back stuff up.\n\nI currently have a little 2-HDD dock that I connect to my PC via USB and manually drag stuff over.  But this means I have to keep swapping the drives.\n\nIs there some sort of hardware that will allow me to plug 5 or 6 hard drives in and they all be connected as a bunch of disks to my PC?\n\nNot sure if I need a full blown NAS or if there's some sort of case/board combo I could use?\n\nLooking for something a little more permanent than moving the drives around.", "author_fullname": "t2_mre85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I need a NAS or is there a dock I can use?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173oh8y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.7, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696847316.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have about 5 hard drives I use to back stuff up.&lt;/p&gt;\n\n&lt;p&gt;I currently have a little 2-HDD dock that I connect to my PC via USB and manually drag stuff over.  But this means I have to keep swapping the drives.&lt;/p&gt;\n\n&lt;p&gt;Is there some sort of hardware that will allow me to plug 5 or 6 hard drives in and they all be connected as a bunch of disks to my PC?&lt;/p&gt;\n\n&lt;p&gt;Not sure if I need a full blown NAS or if there&amp;#39;s some sort of case/board combo I could use?&lt;/p&gt;\n\n&lt;p&gt;Looking for something a little more permanent than moving the drives around.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173oh8y", "is_robot_indexable": true, "report_reasons": null, "author": "banisheduser", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173oh8y/do_i_need_a_nas_or_is_there_a_dock_i_can_use/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173oh8y/do_i_need_a_nas_or_is_there_a_dock_i_can_use/", "subreddit_subscribers": 705761, "created_utc": 1696847316.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The title pretty much says it  all. I have tried the wayback-machine-downloader but it downloads .HTML files and archivarix does not help much either (have not heard back from them after submitting a download request). Is there any other alternatives that actually work and able to grab all the files from website using the internet archive from Wayback machine? Thanks. ", "author_fullname": "t2_9oo3ftmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you bulk download all the resources (i.e., pdf, jpg) from a website using the Wyabck machine archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173g19v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696815991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title pretty much says it  all. I have tried the wayback-machine-downloader but it downloads .HTML files and archivarix does not help much either (have not heard back from them after submitting a download request). Is there any other alternatives that actually work and able to grab all the files from website using the internet archive from Wayback machine? Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173g19v", "is_robot_indexable": true, "report_reasons": null, "author": "non-linear94", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173g19v/can_you_bulk_download_all_the_resources_ie_pdf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173g19v/can_you_bulk_download_all_the_resources_ie_pdf/", "subreddit_subscribers": 705761, "created_utc": 1696815991.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I'm currently new to this topic so I would like some clarification between cloning and imaging. I've done some research, but most of the articles aren't doing a very good job of clarifying the differences between the two and which is most effective for what.  \n\n\nSo here are some of the scenarios that I will create a backup for:\n\n1. Restoring windows and my data in case of a software issue (bad update or malware, but hardware is fine)\n2. Replacing a failing hard drive. If my hard drive stops working the very next day, I would like to use my backup to restore all my files to a new drive\n3. Transferring all of my data from an old computer to a new computer.\n\nIn which of these scenarios would imaging or cloning make the most sense? \n\nThank you in advance.  \n\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_25235vtr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use imaging or cloning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1733ztz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696784110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I&amp;#39;m currently new to this topic so I would like some clarification between cloning and imaging. I&amp;#39;ve done some research, but most of the articles aren&amp;#39;t doing a very good job of clarifying the differences between the two and which is most effective for what.  &lt;/p&gt;\n\n&lt;p&gt;So here are some of the scenarios that I will create a backup for:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Restoring windows and my data in case of a software issue (bad update or malware, but hardware is fine)&lt;/li&gt;\n&lt;li&gt;Replacing a failing hard drive. If my hard drive stops working the very next day, I would like to use my backup to restore all my files to a new drive&lt;/li&gt;\n&lt;li&gt;Transferring all of my data from an old computer to a new computer.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;In which of these scenarios would imaging or cloning make the most sense? &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1733ztz", "is_robot_indexable": true, "report_reasons": null, "author": "iSpazm", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1733ztz/should_i_use_imaging_or_cloning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1733ztz/should_i_use_imaging_or_cloning/", "subreddit_subscribers": 705761, "created_utc": 1696784110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hoping someone can help here as they are of huge sentimental value. \n\nI just want ask now if there\u2019s any major things to avoid doing or thing to do when plugging them in and trying to transfer the contents to my computer?  \n\nI guess things like do I need to prioritise getting files off steadily as opposed to one large file transfer? Or do I just go straight to a professional? \n\nI\u2019m not getting my hopes up that it\u2019ll work but any advice to give it the best possible chance I\u2019d be so grateful for. \n\nThere are two hard drives, both containing the same backup, both compatible with Macs and containing files off a Mac. I\u2019ll be transferring back onto my Mac. \n\nPlease be kind about this, I know it\u2019s a slim chance it\u2019ll work and I know that hard drives should not be left this long. \n\nThey belonged to my dad who we lost in April this year, and he got back into photography later in life. About 10 years ago I helped him back up his photos (many of which are photos of the family and my late mum) onto 2 hard drives. The transfers were successful and the hard drives were stored in their original packaging/box and then stored in another box. \n\nMy dad developed dementia and couldn\u2019t remember where he\u2019d put them &amp; I honestly thought they\u2019d been lost. But I recently found them clearing my dad\u2019s house, still in the same box. \n\nThey are quite well protected and there doesn\u2019t appear to be any damage to the box, no mould or damp on anything. My dad hasn\u2019t had a computer since we backed up everything, so I know they haven\u2019t been accessed in just under 10 years. \n\nI\u2019d love to see the photos of my mum through my dads eyes, so any advice would be really appreciated", "author_fullname": "t2_70cgp9a4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019d like to save my late dad\u2019s hard drives that haven\u2019t been used for 10 years - any advice to give them the best chance?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173py3m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696852655.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hoping someone can help here as they are of huge sentimental value. &lt;/p&gt;\n\n&lt;p&gt;I just want ask now if there\u2019s any major things to avoid doing or thing to do when plugging them in and trying to transfer the contents to my computer?  &lt;/p&gt;\n\n&lt;p&gt;I guess things like do I need to prioritise getting files off steadily as opposed to one large file transfer? Or do I just go straight to a professional? &lt;/p&gt;\n\n&lt;p&gt;I\u2019m not getting my hopes up that it\u2019ll work but any advice to give it the best possible chance I\u2019d be so grateful for. &lt;/p&gt;\n\n&lt;p&gt;There are two hard drives, both containing the same backup, both compatible with Macs and containing files off a Mac. I\u2019ll be transferring back onto my Mac. &lt;/p&gt;\n\n&lt;p&gt;Please be kind about this, I know it\u2019s a slim chance it\u2019ll work and I know that hard drives should not be left this long. &lt;/p&gt;\n\n&lt;p&gt;They belonged to my dad who we lost in April this year, and he got back into photography later in life. About 10 years ago I helped him back up his photos (many of which are photos of the family and my late mum) onto 2 hard drives. The transfers were successful and the hard drives were stored in their original packaging/box and then stored in another box. &lt;/p&gt;\n\n&lt;p&gt;My dad developed dementia and couldn\u2019t remember where he\u2019d put them &amp;amp; I honestly thought they\u2019d been lost. But I recently found them clearing my dad\u2019s house, still in the same box. &lt;/p&gt;\n\n&lt;p&gt;They are quite well protected and there doesn\u2019t appear to be any damage to the box, no mould or damp on anything. My dad hasn\u2019t had a computer since we backed up everything, so I know they haven\u2019t been accessed in just under 10 years. &lt;/p&gt;\n\n&lt;p&gt;I\u2019d love to see the photos of my mum through my dads eyes, so any advice would be really appreciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173py3m", "is_robot_indexable": true, "report_reasons": null, "author": "thirstylearning", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173py3m/id_like_to_save_my_late_dads_hard_drives_that/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173py3m/id_like_to_save_my_late_dads_hard_drives_that/", "subreddit_subscribers": 705761, "created_utc": 1696852655.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Does anyone have any links to a copy of the installation for COD Online? All the links for it are dead now. It had so many unique features, campaign, its own zombies, unique maps and weapons.\n\nThe game was online only and Chinese exclusive and shutdown, so there's currently no way to play it.  Would love to get a project going to revive it and run private servers for it.", "author_fullname": "t2_jm3rzwzs1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Call of Duty Online preservation? Chinese COD", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173p0co", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696849342.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Does anyone have any links to a copy of the installation for COD Online? All the links for it are dead now. It had so many unique features, campaign, its own zombies, unique maps and weapons.&lt;/p&gt;\n\n&lt;p&gt;The game was online only and Chinese exclusive and shutdown, so there&amp;#39;s currently no way to play it.  Would love to get a project going to revive it and run private servers for it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "173p0co", "is_robot_indexable": true, "report_reasons": null, "author": "PaprikaRainbow", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173p0co/call_of_duty_online_preservation_chinese_cod/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173p0co/call_of_duty_online_preservation_chinese_cod/", "subreddit_subscribers": 705761, "created_utc": 1696849342.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi to everyone, I apologize for the question that may be a little bit out of topic, but I am setting up my first home server, and I chose these two software for HDD management.\n\nI am planning to use ubuntu server, and I would like to ask an advice: according to [snapraid](https://www.snapraid.it/download)'s download page and  [mergerfs](https://github.com/trapexit/mergerfs)' github page, it seems to be suggested to download directly their source instead of using ubuntu's package manager.\n\nCan you suggest me a way to update automatically somehow these two software, since I am planning building from source? Or, if there it is not an automatic way, which is the fastest way to update them when installed from source and not from the package manager?\n\nThanks a lot in advance to everyone, and sorry again if the question may be a little bit out of topic.", "author_fullname": "t2_3hwuhm84", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mergerfs and Snapraid installation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173nkyk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696843715.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi to everyone, I apologize for the question that may be a little bit out of topic, but I am setting up my first home server, and I chose these two software for HDD management.&lt;/p&gt;\n\n&lt;p&gt;I am planning to use ubuntu server, and I would like to ask an advice: according to &lt;a href=\"https://www.snapraid.it/download\"&gt;snapraid&lt;/a&gt;&amp;#39;s download page and  &lt;a href=\"https://github.com/trapexit/mergerfs\"&gt;mergerfs&lt;/a&gt;&amp;#39; github page, it seems to be suggested to download directly their source instead of using ubuntu&amp;#39;s package manager.&lt;/p&gt;\n\n&lt;p&gt;Can you suggest me a way to update automatically somehow these two software, since I am planning building from source? Or, if there it is not an automatic way, which is the fastest way to update them when installed from source and not from the package manager?&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot in advance to everyone, and sorry again if the question may be a little bit out of topic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173nkyk", "is_robot_indexable": true, "report_reasons": null, "author": "Landomix", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173nkyk/mergerfs_and_snapraid_installation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173nkyk/mergerfs_and_snapraid_installation/", "subreddit_subscribers": 705761, "created_utc": 1696843715.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was trying to save an online stream for editing and archival purposes and tried 3 different software:\n\n1. YT-DLP : 994MB (best format already selected 720P)\n2. VDHelper: 996MB\n3. Stream HLS Recorder: 993MB \n\nWhy is this the case? \n\nI retried their downloads and it consistently downloaded the same file sizes respectively \n\nAll 3 video files are 720p and have very similar meta data, if not exactly the same. \n\nI'm watching all three of them manually and there are no noticeable differences.\n\n&amp;#x200B;", "author_fullname": "t2_7qbkalan", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why? Converting hls streaming to mp4 with 3 different methods results in 3 different file sizes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173kzbd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696832928.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was trying to save an online stream for editing and archival purposes and tried 3 different software:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;YT-DLP : 994MB (best format already selected 720P)&lt;/li&gt;\n&lt;li&gt;VDHelper: 996MB&lt;/li&gt;\n&lt;li&gt;Stream HLS Recorder: 993MB &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Why is this the case? &lt;/p&gt;\n\n&lt;p&gt;I retried their downloads and it consistently downloaded the same file sizes respectively &lt;/p&gt;\n\n&lt;p&gt;All 3 video files are 720p and have very similar meta data, if not exactly the same. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m watching all three of them manually and there are no noticeable differences.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173kzbd", "is_robot_indexable": true, "report_reasons": null, "author": "SherbetTiger", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173kzbd/why_converting_hls_streaming_to_mp4_with_3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173kzbd/why_converting_hls_streaming_to_mp4_with_3/", "subreddit_subscribers": 705761, "created_utc": 1696832928.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for one that can swap drives with ease, not the kind you have to screw and unscrew to change drives. I have one that's basically just a plastic box, but it gets HOT! Have you guys come across any you really like?", "author_fullname": "t2_4y11jk7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have an external 3.5\" enclosure you recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173ha3m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696819729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for one that can swap drives with ease, not the kind you have to screw and unscrew to change drives. I have one that&amp;#39;s basically just a plastic box, but it gets HOT! Have you guys come across any you really like?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173ha3m", "is_robot_indexable": true, "report_reasons": null, "author": "grief_and_confusion", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173ha3m/do_you_have_an_external_35_enclosure_you_recommend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173ha3m/do_you_have_an_external_35_enclosure_you_recommend/", "subreddit_subscribers": 705761, "created_utc": 1696819729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi \n\nI currently have a LSI 9305-24i in my server with 24 drives connected up. This card has the AVAGO bios on the card.\n\nMy question, if i purchase another card for example a LSI 9300-8i would I be able to see that AVAGO bios also during the post?\n\nSorry if this question is pretty dumb but I am pretty new to this.\n\nReason being I want to test if my current card is playing up as one the drives is negotiating at 3Gbps instead of 6Gbps.\n\nThe server is a Truenas build.\n\nOnce again sorry if this is stupid", "author_fullname": "t2_4kl3s1e1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I use 2 different SAS cards in my server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1739mhx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696798344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;/p&gt;\n\n&lt;p&gt;I currently have a LSI 9305-24i in my server with 24 drives connected up. This card has the AVAGO bios on the card.&lt;/p&gt;\n\n&lt;p&gt;My question, if i purchase another card for example a LSI 9300-8i would I be able to see that AVAGO bios also during the post?&lt;/p&gt;\n\n&lt;p&gt;Sorry if this question is pretty dumb but I am pretty new to this.&lt;/p&gt;\n\n&lt;p&gt;Reason being I want to test if my current card is playing up as one the drives is negotiating at 3Gbps instead of 6Gbps.&lt;/p&gt;\n\n&lt;p&gt;The server is a Truenas build.&lt;/p&gt;\n\n&lt;p&gt;Once again sorry if this is stupid&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1739mhx", "is_robot_indexable": true, "report_reasons": null, "author": "AJBOJACK", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1739mhx/can_i_use_2_different_sas_cards_in_my_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1739mhx/can_i_use_2_different_sas_cards_in_my_server/", "subreddit_subscribers": 705761, "created_utc": 1696798344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Did people save Imgur content before Imgur deleted a lot of stuff according to their new policy?\n\nBtw, few years ago some website crawler apps were able to get deleted content from Imgur servers, despite being deleted and not accessible through web browsers.\n\nBut I don't remember the specific crawler app name anymore. It was Windows version, was it on Github or some other site, can't remember anymore.", "author_fullname": "t2_fl12kooxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imgur deleted content?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1730pwh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.54, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696775867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did people save Imgur content before Imgur deleted a lot of stuff according to their new policy?&lt;/p&gt;\n\n&lt;p&gt;Btw, few years ago some website crawler apps were able to get deleted content from Imgur servers, despite being deleted and not accessible through web browsers.&lt;/p&gt;\n\n&lt;p&gt;But I don&amp;#39;t remember the specific crawler app name anymore. It was Windows version, was it on Github or some other site, can&amp;#39;t remember anymore.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1730pwh", "is_robot_indexable": true, "report_reasons": null, "author": "Confident-Dingo-99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1730pwh/imgur_deleted_content/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1730pwh/imgur_deleted_content/", "subreddit_subscribers": 705761, "created_utc": 1696775867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What is the best way to upgrade RAID1 pool with 2 WD 500gb drives? I bought 2x4 TB drives but my truenas server only has 3 sata ports. What should i do?", "author_fullname": "t2_adfbrmlw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expanding NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172zvdn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696773671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the best way to upgrade RAID1 pool with 2 WD 500gb drives? I bought 2x4 TB drives but my truenas server only has 3 sata ports. What should i do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172zvdn", "is_robot_indexable": true, "report_reasons": null, "author": "picua_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172zvdn/expanding_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172zvdn/expanding_nas/", "subreddit_subscribers": 705761, "created_utc": 1696773671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i have a few thousand videos that i need to crop and can't find any good software for pc, any suggestions? (would be better if it allows for custom crop ratio and not just 1:1 or 16:9 ect...)", "author_fullname": "t2_dfdoc6ab", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A good free video cropping software for lots of video?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172y71e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696768842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have a few thousand videos that i need to crop and can&amp;#39;t find any good software for pc, any suggestions? (would be better if it allows for custom crop ratio and not just 1:1 or 16:9 ect...)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "5,5TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172y71e", "is_robot_indexable": true, "report_reasons": null, "author": "Key-Wait-3098", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/172y71e/a_good_free_video_cropping_software_for_lots_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172y71e/a_good_free_video_cropping_software_for_lots_of/", "subreddit_subscribers": 705761, "created_utc": 1696768842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I want to download a video on YouTube and came across flixmate but scared it\u2019s a virus. Has anyone downloaded it before?", "author_fullname": "t2_f3ogytw9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How safe is flixmate.net?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173pexh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696850834.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I want to download a video on YouTube and came across flixmate but scared it\u2019s a virus. Has anyone downloaded it before?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173pexh", "is_robot_indexable": true, "report_reasons": null, "author": "patricknails", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173pexh/how_safe_is_flixmatenet/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173pexh/how_safe_is_flixmatenet/", "subreddit_subscribers": 705761, "created_utc": 1696850834.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all,\n\nClear  novice in this area. I've just set up my first NAS - a DS224+ with 24TB  - configured in Raid 1. It leaves me with around 10TB or so usable  space. I'm now looking at backing this up to a USB drive - possibly  something like a WD MyBook Duo. My question is this... well, it's two  fold actually:\n\n\\- To back up a 24TB  Synology configured in RAID, do you need something that covers the full  24TB (ie. a 28TB WD MyBook), or do you need one sufficiently sized to  cover the 'halved' storage amount - ie. a 14TB WD MyBook to comfortably  fit the 10TB or so 'usable' space? Logically, I would assume it would  only need to backup the 10TB of data on one of the drives, rather than the mirrored one too, but as I say... novice!\n\nMy  second question is how long it might roughly take to backup 10TB over  USB if I got the WD MyBook. It's just for backing up family photos  primarily - so probably wouldn't need to do it more than 1-2 times a  month.\n\nThanks in advance!", "author_fullname": "t2_6swpz6de6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How much storage do you need in a USB enclosure/drives to back up a NAS? *novice*", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173n9ws", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696842414.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;Clear  novice in this area. I&amp;#39;ve just set up my first NAS - a DS224+ with 24TB  - configured in Raid 1. It leaves me with around 10TB or so usable  space. I&amp;#39;m now looking at backing this up to a USB drive - possibly  something like a WD MyBook Duo. My question is this... well, it&amp;#39;s two  fold actually:&lt;/p&gt;\n\n&lt;p&gt;- To back up a 24TB  Synology configured in RAID, do you need something that covers the full  24TB (ie. a 28TB WD MyBook), or do you need one sufficiently sized to  cover the &amp;#39;halved&amp;#39; storage amount - ie. a 14TB WD MyBook to comfortably  fit the 10TB or so &amp;#39;usable&amp;#39; space? Logically, I would assume it would  only need to backup the 10TB of data on one of the drives, rather than the mirrored one too, but as I say... novice!&lt;/p&gt;\n\n&lt;p&gt;My  second question is how long it might roughly take to backup 10TB over  USB if I got the WD MyBook. It&amp;#39;s just for backing up family photos  primarily - so probably wouldn&amp;#39;t need to do it more than 1-2 times a  month.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173n9ws", "is_robot_indexable": true, "report_reasons": null, "author": "kfc_not_the_chicken", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173n9ws/how_much_storage_do_you_need_in_a_usb/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173n9ws/how_much_storage_do_you_need_in_a_usb/", "subreddit_subscribers": 705761, "created_utc": 1696842414.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a LSI SAS3041E pci card to add more sata ports on my computer, I'm running truenas scale, I was expecting to have to flash it but thought let me try it as it's a used part. It recognized the drive. Has this card already been flashed to IT mode? How can I tell?", "author_fullname": "t2_31uwvm4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flashing SAS card to IT mode.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1739adk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696797490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a LSI SAS3041E pci card to add more sata ports on my computer, I&amp;#39;m running truenas scale, I was expecting to have to flash it but thought let me try it as it&amp;#39;s a used part. It recognized the drive. Has this card already been flashed to IT mode? How can I tell?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1739adk", "is_robot_indexable": true, "report_reasons": null, "author": "arun2118", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1739adk/flashing_sas_card_to_it_mode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1739adk/flashing_sas_card_to_it_mode/", "subreddit_subscribers": 705761, "created_utc": 1696797490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Not sure if this is the correct sub for this but I'm not sure where else to ask. \n\nI have folders of very long screenshots of fanfics from tumblr and fanfiction.net saved on my phone and I want to convert them as word/text files so i can use text to speech to read. I didn't know to use the wayback machine back then, i just use Longshot to screenshot everything I couldn't download. \n\nRight now my only recourse is use something like google lens but using that, I can only convert the length of my screen at a time and that's gonna take so long because like one pic is like, 30 stitched screenshots and I have a couple of folders. \n\nIs there software for this?", "author_fullname": "t2_5lnt8f8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OCR or image-to-text for very long screenshots", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1733zxj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696784117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if this is the correct sub for this but I&amp;#39;m not sure where else to ask. &lt;/p&gt;\n\n&lt;p&gt;I have folders of very long screenshots of fanfics from tumblr and fanfiction.net saved on my phone and I want to convert them as word/text files so i can use text to speech to read. I didn&amp;#39;t know to use the wayback machine back then, i just use Longshot to screenshot everything I couldn&amp;#39;t download. &lt;/p&gt;\n\n&lt;p&gt;Right now my only recourse is use something like google lens but using that, I can only convert the length of my screen at a time and that&amp;#39;s gonna take so long because like one pic is like, 30 stitched screenshots and I have a couple of folders. &lt;/p&gt;\n\n&lt;p&gt;Is there software for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1733zxj", "is_robot_indexable": true, "report_reasons": null, "author": "ac-2223", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1733zxj/ocr_or_imagetotext_for_very_long_screenshots/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1733zxj/ocr_or_imagetotext_for_very_long_screenshots/", "subreddit_subscribers": 705761, "created_utc": 1696784117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I used to download from open directories pretty frequently and have a bunch of ebooks. I was wondering if there was a way I could have a script/program scan the folder and automatically rename and sort the files. Is this possible?", "author_fullname": "t2_f2z4g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I auto-tag a folder full of ebooks in order to separate them into categories (like science, math, language, etc.)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173mvmb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.25, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696840789.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I used to download from open directories pretty frequently and have a bunch of ebooks. I was wondering if there was a way I could have a script/program scan the folder and automatically rename and sort the files. Is this possible?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173mvmb", "is_robot_indexable": true, "report_reasons": null, "author": "aproposquidproquo", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173mvmb/how_do_i_autotag_a_folder_full_of_ebooks_in_order/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173mvmb/how_do_i_autotag_a_folder_full_of_ebooks_in_order/", "subreddit_subscribers": 705761, "created_utc": 1696840789.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}