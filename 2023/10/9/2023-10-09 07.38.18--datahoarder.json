{"kind": "Listing", "data": {"after": "t3_1733zxj", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I ran a SMART test in TrueNAS for an old 6TB Western Digital Green drive (model WD60EZRX), and although TureNAS is telling me that the drive has failed the test, `smartctl` gives a status of \"SMART overall-health self-assessment test result: PASSED\" and all of my actual values look okay.  I'm trying to figure out what's going on.\n\nFrom what I can tell, the issue is that the test isn't completing.  I'm seeing this in the `General SMART Values:` section:\n\n    \tSelf-test execution status:      (  57) A fatal error or unknown test error\n    \t                                        occurred while the device was executing\n    \t                                        its self-test routine and the device \n    \t                                        was unable to complete the self-test \n    \t                                        routine.\n\nAnd under `SMART Self-test log structure` I'm seeing this:\n\n    \tSMART Self-test log structure revision number 1\n    \tNum  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error\n    \t# 1  Short offline       Fatal or unknown error        90%     43903         -\n    \t# 2  Extended offline    Fatal or unknown error        90%     43881         -\n    \t# 3  Short offline       Fatal or unknown error        90%     43879         -\n\n\n\n#**HOWEVER**! \nIt does look like it's updating the disk values in the `Vendor Specific SMART Attributes with Thresholds` section.  Here's the output of the first and second SMART tests for comparison:\n\n    \tSMART Attributes Data Structure revision number: 16\n    \tVendor Specific SMART Attributes with Thresholds:\n    \tID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n    \t  1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n    \t  3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n    \t  4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n    \t  5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n    \t  7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n    \t  9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43890\n    \t 10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n    \t 11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n    \t 12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    \t192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    \t193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123623\n    \t194 Temperature_Celsius     0x0022   123   103   000    Old_age   Always       -       29\n    \t196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    \t197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    \t198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    \t199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    \t200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n    \t\n    \tSMART Error Log Version: 1\n    \tNo Errors Logged\n\nAnd the second test:\n\n    SMART Attributes Data Structure revision number: 16\n    \tVendor Specific SMART Attributes with Thresholds:\n    \tID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n    \t  1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n    \t  3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n    \t  4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n    \t  5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n    \t  7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n    \t  9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43903\n    \t 10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n    \t 11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n    \t 12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    \t192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    \t193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123650\n    \t194 Temperature_Celsius     0x0022   119   103   000    Old_age   Always       -       33\n    \t196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    \t197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    \t198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    \t199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    \t200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n    \t\n    \tSMART Error Log Version: 1\n    \tNo Errors Logged\n\nBetween the first and second test, I filled the drive with random data overnight, but it didn't seem to make any difference.\n\nI have no clue what to make of this.  Everything tests well within tolerances, but the testing isn't completing properly?  No idea what to do with this.\n\nAny suggestions for next steps?  I have a Windows box I can plug this drive into for further testing, but is there any reason to think I'd get a different result?  I'm pretty stumped on this one.  Full logs in the comments in case it's helpful.", "author_fullname": "t2_vqak2uq7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "TrueNAS Scale shows that my drive's SMART test failed, but `smartctl` says it passed. Do I really have a problem?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1732na8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696781061.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696780669.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I ran a SMART test in TrueNAS for an old 6TB Western Digital Green drive (model WD60EZRX), and although TureNAS is telling me that the drive has failed the test, &lt;code&gt;smartctl&lt;/code&gt; gives a status of &amp;quot;SMART overall-health self-assessment test result: PASSED&amp;quot; and all of my actual values look okay.  I&amp;#39;m trying to figure out what&amp;#39;s going on.&lt;/p&gt;\n\n&lt;p&gt;From what I can tell, the issue is that the test isn&amp;#39;t completing.  I&amp;#39;m seeing this in the &lt;code&gt;General SMART Values:&lt;/code&gt; section:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    Self-test execution status:      (  57) A fatal error or unknown test error\n                                            occurred while the device was executing\n                                            its self-test routine and the device \n                                            was unable to complete the self-test \n                                            routine.\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And under &lt;code&gt;SMART Self-test log structure&lt;/code&gt; I&amp;#39;m seeing this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    SMART Self-test log structure revision number 1\n    Num  Test_Description    Status                  Remaining  LifeTime(hours)  LBA_of_first_error\n    # 1  Short offline       Fatal or unknown error        90%     43903         -\n    # 2  Extended offline    Fatal or unknown error        90%     43881         -\n    # 3  Short offline       Fatal or unknown error        90%     43879         -\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;h1&gt;&lt;strong&gt;HOWEVER&lt;/strong&gt;!&lt;/h1&gt;\n\n&lt;p&gt;It does look like it&amp;#39;s updating the disk values in the &lt;code&gt;Vendor Specific SMART Attributes with Thresholds&lt;/code&gt; section.  Here&amp;#39;s the output of the first and second SMART tests for comparison:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;    SMART Attributes Data Structure revision number: 16\n    Vendor Specific SMART Attributes with Thresholds:\n    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n      1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n      3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n      4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n      5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n      7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n      9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43890\n     10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n     11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n     12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123623\n    194 Temperature_Celsius     0x0022   123   103   000    Old_age   Always       -       29\n    196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n\n    SMART Error Log Version: 1\n    No Errors Logged\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;And the second test:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SMART Attributes Data Structure revision number: 16\n    Vendor Specific SMART Attributes with Thresholds:\n    ID# ATTRIBUTE_NAME          FLAG     VALUE WORST THRESH TYPE      UPDATED  WHEN_FAILED RAW_VALUE\n      1 Raw_Read_Error_Rate     0x002f   200   200   051    Pre-fail  Always       -       4\n      3 Spin_Up_Time            0x0027   199   196   021    Pre-fail  Always       -       9025\n      4 Start_Stop_Count        0x0032   097   097   000    Old_age   Always       -       3385\n      5 Reallocated_Sector_Ct   0x0033   200   200   140    Pre-fail  Always       -       0\n      7 Seek_Error_Rate         0x002e   200   200   000    Old_age   Always       -       0\n      9 Power_On_Hours          0x0032   040   040   000    Old_age   Always       -       43903\n     10 Spin_Retry_Count        0x0032   100   100   000    Old_age   Always       -       0\n     11 Calibration_Retry_Count 0x0032   100   100   000    Old_age   Always       -       0\n     12 Power_Cycle_Count       0x0032   098   098   000    Old_age   Always       -       2533\n    192 Power-Off_Retract_Count 0x0032   200   200   000    Old_age   Always       -       109\n    193 Load_Cycle_Count        0x0032   159   159   000    Old_age   Always       -       123650\n    194 Temperature_Celsius     0x0022   119   103   000    Old_age   Always       -       33\n    196 Reallocated_Event_Count 0x0032   200   200   000    Old_age   Always       -       0\n    197 Current_Pending_Sector  0x0032   200   200   000    Old_age   Always       -       0\n    198 Offline_Uncorrectable   0x0030   200   200   000    Old_age   Offline      -       0\n    199 UDMA_CRC_Error_Count    0x0032   200   200   000    Old_age   Always       -       0\n    200 Multi_Zone_Error_Rate   0x0008   200   200   000    Old_age   Offline      -       0\n\n    SMART Error Log Version: 1\n    No Errors Logged\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Between the first and second test, I filled the drive with random data overnight, but it didn&amp;#39;t seem to make any difference.&lt;/p&gt;\n\n&lt;p&gt;I have no clue what to make of this.  Everything tests well within tolerances, but the testing isn&amp;#39;t completing properly?  No idea what to do with this.&lt;/p&gt;\n\n&lt;p&gt;Any suggestions for next steps?  I have a Windows box I can plug this drive into for further testing, but is there any reason to think I&amp;#39;d get a different result?  I&amp;#39;m pretty stumped on this one.  Full logs in the comments in case it&amp;#39;s helpful.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1732na8", "is_robot_indexable": true, "report_reasons": null, "author": "OnlyForSomeThings", "discussion_type": null, "num_comments": 16, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1732na8/truenas_scale_shows_that_my_drives_smart_test/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1732na8/truenas_scale_shows_that_my_drives_smart_test/", "subreddit_subscribers": 705723, "created_utc": 1696780669.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "A while back me and an acquaintance downloaded 50gb of print ad listings from an eBay account. I had discovered that the seller was selling pages from rare toy magazines that haven't been digitized. Theoretically, a large portion of these magazines could be saved by sorting the listings into their respective publications and issues. The problem is, we have all of these pages but no way to sort them automatically. The listings were not named by publication, but by content, so unfortunately we can't just use the titles.\n\nThe only idea I could come up with was using an OCR algorithm to read every page and sort them based on the footers reading the publication and issue month. I just don't know how to do that or how easy it would be to set up.\n\nThis would be a great research resource for others, I don't think even The Strong has some of these toy magazines. If anyone can come up with an idea or is open to writing a program that can automatically sort it all, that would be fantastic.", "author_fullname": "t2_b8qqcytr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Sorting over 60k pages of toy ads spanning a century", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173gdqa", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696816982.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A while back me and an acquaintance downloaded 50gb of print ad listings from an eBay account. I had discovered that the seller was selling pages from rare toy magazines that haven&amp;#39;t been digitized. Theoretically, a large portion of these magazines could be saved by sorting the listings into their respective publications and issues. The problem is, we have all of these pages but no way to sort them automatically. The listings were not named by publication, but by content, so unfortunately we can&amp;#39;t just use the titles.&lt;/p&gt;\n\n&lt;p&gt;The only idea I could come up with was using an OCR algorithm to read every page and sort them based on the footers reading the publication and issue month. I just don&amp;#39;t know how to do that or how easy it would be to set up.&lt;/p&gt;\n\n&lt;p&gt;This would be a great research resource for others, I don&amp;#39;t think even The Strong has some of these toy magazines. If anyone can come up with an idea or is open to writing a program that can automatically sort it all, that would be fantastic.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173gdqa", "is_robot_indexable": true, "report_reasons": null, "author": "doodlebuuggg", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173gdqa/sorting_over_60k_pages_of_toy_ads_spanning_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173gdqa/sorting_over_60k_pages_of_toy_ads_spanning_a/", "subreddit_subscribers": 705723, "created_utc": 1696816982.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've found the following deal: [Seagate IronWolf Pro 16TB](https://www.jb-computer.de/komponenten-zubehoer/speicher/hdd/9078/seagate-ironwolf-pro-16tb-hdd-3.5-zoll-nas-festplatte-sata-6gb/s-7200rpm-recertified-new-st16000ne0?number=MJB991970)\n\nThey're \"Recertified new\", so they should be as good as new, but I'm still wondering about the price, since it's about 100\u20ac cheaper than everywhere else I could find.\n\nIs there anything that I should worry about / that I'm missing?", "author_fullname": "t2_clqfxwwh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this deal too good to be true? [IronWolf Pro 16TB for 240\u20ac]", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172w1r5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 30, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 30, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696761516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve found the following deal: &lt;a href=\"https://www.jb-computer.de/komponenten-zubehoer/speicher/hdd/9078/seagate-ironwolf-pro-16tb-hdd-3.5-zoll-nas-festplatte-sata-6gb/s-7200rpm-recertified-new-st16000ne0?number=MJB991970\"&gt;Seagate IronWolf Pro 16TB&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;re &amp;quot;Recertified new&amp;quot;, so they should be as good as new, but I&amp;#39;m still wondering about the price, since it&amp;#39;s about 100\u20ac cheaper than everywhere else I could find.&lt;/p&gt;\n\n&lt;p&gt;Is there anything that I should worry about / that I&amp;#39;m missing?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?auto=webp&amp;s=56b69a3282cb2b793518b93e5713fc05ca97b3a3", "width": 1021, "height": 1500}, "resolutions": [{"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=6898dba29c225dfd92ade0f094b1bbc543b719a3", "width": 108, "height": 158}, {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a4b1c16bc0482411036a8bc1a55652efc557a52f", "width": 216, "height": 317}, {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=3024895cf2dfea54a338522a6bc78b40b887c476", "width": 320, "height": 470}, {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=6cdd1ca290de37f8d622429d54dceef9789eb559", "width": 640, "height": 940}, {"url": "https://external-preview.redd.it/36Uvm5Lts0IeWDRMeWvxQ85xleFSiq-i3FDjz0tR7Fg.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=eb5eac25e419fcfd5b6110cb0299daba31487979", "width": 960, "height": 1410}], "variants": {}, "id": "_I8KRd5bw-DkkX0QsAwG4hMeOwGXhPN3hpap37_8jGY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172w1r5", "is_robot_indexable": true, "report_reasons": null, "author": "SeltsamerMagnet", "discussion_type": null, "num_comments": 34, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172w1r5/is_this_deal_too_good_to_be_true_ironwolf_pro/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172w1r5/is_this_deal_too_good_to_be_true_ironwolf_pro/", "subreddit_subscribers": 705723, "created_utc": 1696761516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have been writing BD-REs with CDBurnerXP, and every single time I used \"verify data after burning\".\n\nI am using an external Blu-ray recorder. The ASUS SBW-06D5H-U. Connected with a 2 meter USB-C cable (+ 3.2 Micro-B for the device).\n\nIt came with a 0.5 m cable, not enough for me, so I got this other one.\n\n\\+++++++\n\nI noticed that on my i5 11400 (now 32 GB of DDR-4 RAM, MB is Z590-A Pro, from MSI), using two SSDs, one for C: is a 2 TB NVME from Western Digital, the other 870 EVO 4 TB from Samsung (regular):\n\n\\- It takes 40-45 minutes to burn a rewritable 25 GB disc; I tried in 2x, Ritek media;\n\n\\- I always use CDBurnerXP, and \"verify data after burning\".\n\nIn the past I used an old internal drive, the GGW-H20L from LG;\n\nI once bought 50 discs and noticed all 49 were recorded OK;\n\nIt takes additional 40-45 minutes to verify data after burning. I always let this enabled, to check if there isn't any data corruption. Is this a good idea?\n\nThe 50th disc which was not OK, I think I only spotted a problem with the \"verify after burning\". Most of the contents were fine; some were not, and could not be played (all my discs are backups, data only).\n\nThen I inspected the disc and noticed a very small scratch in the surface. Which accounts for the errors, that blank disc was already flawed.\n\n\\+++++\n\nA few more things I want to point out:\n\n\\- If I simply copy (control + C and control + V) the entire 25 GB disc (or 23 = real size) to my NVME SSD, it will take 25 minutes. But if I do the same for the Samsung regular SSD, it will take 35-40 minutes. I didn't know it was going to be slower depending on the SSD, I thought this was limited by the reader/disc speeds, regardless of the SSD used.\n\n\\++++  \nSome users on this sub and on the internet suggested IMGBURN instead, There's just one problem - CDBURNERXP is updated, while IMGBURN is no longer developed, the last version is [2.5.8.0](https://2.5.8.0), from 10 years ago. Even if you say it doesn't matter how old it is (for the purpose of burning and checking), are there any reasons to use IMGBURN instead, or it doesn't matter which one we choose?", "author_fullname": "t2_1utoiwm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Verifying a disc after burning, copying files back, and ImgBurn vs. CDBurnerXP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1733bf0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.78, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696782383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been writing BD-REs with CDBurnerXP, and every single time I used &amp;quot;verify data after burning&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;I am using an external Blu-ray recorder. The ASUS SBW-06D5H-U. Connected with a 2 meter USB-C cable (+ 3.2 Micro-B for the device).&lt;/p&gt;\n\n&lt;p&gt;It came with a 0.5 m cable, not enough for me, so I got this other one.&lt;/p&gt;\n\n&lt;p&gt;+++++++&lt;/p&gt;\n\n&lt;p&gt;I noticed that on my i5 11400 (now 32 GB of DDR-4 RAM, MB is Z590-A Pro, from MSI), using two SSDs, one for C: is a 2 TB NVME from Western Digital, the other 870 EVO 4 TB from Samsung (regular):&lt;/p&gt;\n\n&lt;p&gt;- It takes 40-45 minutes to burn a rewritable 25 GB disc; I tried in 2x, Ritek media;&lt;/p&gt;\n\n&lt;p&gt;- I always use CDBurnerXP, and &amp;quot;verify data after burning&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;In the past I used an old internal drive, the GGW-H20L from LG;&lt;/p&gt;\n\n&lt;p&gt;I once bought 50 discs and noticed all 49 were recorded OK;&lt;/p&gt;\n\n&lt;p&gt;It takes additional 40-45 minutes to verify data after burning. I always let this enabled, to check if there isn&amp;#39;t any data corruption. Is this a good idea?&lt;/p&gt;\n\n&lt;p&gt;The 50th disc which was not OK, I think I only spotted a problem with the &amp;quot;verify after burning&amp;quot;. Most of the contents were fine; some were not, and could not be played (all my discs are backups, data only).&lt;/p&gt;\n\n&lt;p&gt;Then I inspected the disc and noticed a very small scratch in the surface. Which accounts for the errors, that blank disc was already flawed.&lt;/p&gt;\n\n&lt;p&gt;+++++&lt;/p&gt;\n\n&lt;p&gt;A few more things I want to point out:&lt;/p&gt;\n\n&lt;p&gt;- If I simply copy (control + C and control + V) the entire 25 GB disc (or 23 = real size) to my NVME SSD, it will take 25 minutes. But if I do the same for the Samsung regular SSD, it will take 35-40 minutes. I didn&amp;#39;t know it was going to be slower depending on the SSD, I thought this was limited by the reader/disc speeds, regardless of the SSD used.&lt;/p&gt;\n\n&lt;p&gt;++++&lt;br/&gt;\nSome users on this sub and on the internet suggested IMGBURN instead, There&amp;#39;s just one problem - CDBURNERXP is updated, while IMGBURN is no longer developed, the last version is &lt;a href=\"https://2.5.8.0\"&gt;2.5.8.0&lt;/a&gt;, from 10 years ago. Even if you say it doesn&amp;#39;t matter how old it is (for the purpose of burning and checking), are there any reasons to use IMGBURN instead, or it doesn&amp;#39;t matter which one we choose?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1733bf0", "is_robot_indexable": true, "report_reasons": null, "author": "Maratocarde", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1733bf0/verifying_a_disc_after_burning_copying_files_back/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1733bf0/verifying_a_disc_after_burning_copying_files_back/", "subreddit_subscribers": 705723, "created_utc": 1696782383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey there datahoarders, I was searching for a lot of time for solutions for bulk download from zlib. Sadly I wasn't able to find any real solutions. There was a post about this topic 3 years ago but there was no real solution.   \n\n\nDoes any one of you know about a solution for this? I am a bit skeptical and would love to have a database of books for personal use and would love to download non fiction books. ", "author_fullname": "t2_jvrt4662", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Zlibrary Book Download", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17302gj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696774191.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey there datahoarders, I was searching for a lot of time for solutions for bulk download from zlib. Sadly I wasn&amp;#39;t able to find any real solutions. There was a post about this topic 3 years ago but there was no real solution.   &lt;/p&gt;\n\n&lt;p&gt;Does any one of you know about a solution for this? I am a bit skeptical and would love to have a database of books for personal use and would love to download non fiction books. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17302gj", "is_robot_indexable": true, "report_reasons": null, "author": "Altruistic-Patient56", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17302gj/zlibrary_book_download/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17302gj/zlibrary_book_download/", "subreddit_subscribers": 705723, "created_utc": 1696774191.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "[https://github.com/HybridWare/hybrid-browser](https://github.com/HybridWare/hybrid-browser/releases/tag/2.0.0)\n\n[https://github.com/HybridWare/hybrid-browser/releases/tag/2.0.0](https://github.com/HybridWare/hybrid-browser/releases/tag/2.0.0)\n\nthis is a web browser that directly supports bittorrent, ipfs, hyper and other networks\n\ni see a lot of archives being uploaded to bittorrent and ipfs, using this you can view all of that data in one app\n\nyou can also create and host websites in p2p networks and then you can interact with data from muleiple networks in a single webpage\n\nexample\n\n&lt;img src=\"http://somesite.com/file.jpeg\" width=\"500\" height=\"600\"&gt; \n\nnow you can\n\n&lt;img src=\"http://somesite.com/file.jpeg\" width=\"500\" height=\"600\"&gt; \n\n&lt;img src=\"bt://bittorrenturl/file.jpeg\" width=\"500\" height=\"600\"&gt; \n\n&lt;img src=\"ipfs://ipfsurl/file.jpeg\" width=\"500\" height=\"600\"&gt; \n\n&lt;img src=\"hyper://hyper/file.jpeg\" width=\"500\" height=\"600\"&gt; ", "author_fullname": "t2_12l7zu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "peer to peer web browser, great for archives and datahoarders", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173du89", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696809402.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://github.com/HybridWare/hybrid-browser/releases/tag/2.0.0\"&gt;https://github.com/HybridWare/hybrid-browser&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/HybridWare/hybrid-browser/releases/tag/2.0.0\"&gt;https://github.com/HybridWare/hybrid-browser/releases/tag/2.0.0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;this is a web browser that directly supports bittorrent, ipfs, hyper and other networks&lt;/p&gt;\n\n&lt;p&gt;i see a lot of archives being uploaded to bittorrent and ipfs, using this you can view all of that data in one app&lt;/p&gt;\n\n&lt;p&gt;you can also create and host websites in p2p networks and then you can interact with data from muleiple networks in a single webpage&lt;/p&gt;\n\n&lt;p&gt;example&lt;/p&gt;\n\n&lt;p&gt;&amp;lt;img src=&amp;quot;http://somesite.com/file.jpeg&amp;quot; width=&amp;quot;500&amp;quot; height=&amp;quot;600&amp;quot;&amp;gt; &lt;/p&gt;\n\n&lt;p&gt;now you can&lt;/p&gt;\n\n&lt;p&gt;&amp;lt;img src=&amp;quot;http://somesite.com/file.jpeg&amp;quot; width=&amp;quot;500&amp;quot; height=&amp;quot;600&amp;quot;&amp;gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;lt;img src=&amp;quot;bt://bittorrenturl/file.jpeg&amp;quot; width=&amp;quot;500&amp;quot; height=&amp;quot;600&amp;quot;&amp;gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;lt;img src=&amp;quot;ipfs://ipfsurl/file.jpeg&amp;quot; width=&amp;quot;500&amp;quot; height=&amp;quot;600&amp;quot;&amp;gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;lt;img src=&amp;quot;hyper://hyper/file.jpeg&amp;quot; width=&amp;quot;500&amp;quot; height=&amp;quot;600&amp;quot;&amp;gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?auto=webp&amp;s=da30c2db275f032ba21561e417fde8d81966ae96", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=280e6c0c842278c9c95c8acc38519134c3821971", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2584882816994000b863e86b910b750e22592270", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=481e194766cd98338750824a86e9e512396201bc", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=ee08f301b11e082ab9d7377102da021a0f54d2f4", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7b445b5e6139f8093328af7ffd921d28b2c566d4", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/1kn3QvM0UNb4-zzjNg7ZImvDYI2b2TyubxWYFLPKJt0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=61666c59706a2f367873edbd0c760f0353767602", "width": 1080, "height": 540}], "variants": {}, "id": "YbOh1oig7LG7CocA_S5d0gG5JEKp9lDgV4VrvynNN7M"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173du89", "is_robot_indexable": true, "report_reasons": null, "author": "thezzeds", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173du89/peer_to_peer_web_browser_great_for_archives_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173du89/peer_to_peer_web_browser_great_for_archives_and/", "subreddit_subscribers": 705723, "created_utc": 1696809402.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a 2 TB SanDisk SSD on Amazon, and let it sit around for couple weeks before I got around to trying it out on my iMac. I struggled to get the thing recognized by the Mac, and then when it did show up, I couldn't format the drive to anything but MAC OS (attempts at APFS failed every time). Once it was formatted, file transfers were slow, and then the files I copied on there as a test just disappeared. Now the thing doesn't function at all, either on the Mac or on a Win 11 laptop. The thing is dead.\n\n&amp;#x200B;\n\nAm I just out the money I spent on it? I waited too long and I can't return it to Amazon, and SanDisk won't take it either. Also, what is a decent 2-4 TB SSD I could trust? The SanDisk looked really cool, but I certainly don't trust it to buy another one.", "author_fullname": "t2_4vnjyete", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "SanDisk Extreme SSD bricked. What now?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173a11c", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696799368.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a 2 TB SanDisk SSD on Amazon, and let it sit around for couple weeks before I got around to trying it out on my iMac. I struggled to get the thing recognized by the Mac, and then when it did show up, I couldn&amp;#39;t format the drive to anything but MAC OS (attempts at APFS failed every time). Once it was formatted, file transfers were slow, and then the files I copied on there as a test just disappeared. Now the thing doesn&amp;#39;t function at all, either on the Mac or on a Win 11 laptop. The thing is dead.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Am I just out the money I spent on it? I waited too long and I can&amp;#39;t return it to Amazon, and SanDisk won&amp;#39;t take it either. Also, what is a decent 2-4 TB SSD I could trust? The SanDisk looked really cool, but I certainly don&amp;#39;t trust it to buy another one.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173a11c", "is_robot_indexable": true, "report_reasons": null, "author": "tedlyri", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173a11c/sandisk_extreme_ssd_bricked_what_now/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173a11c/sandisk_extreme_ssd_bricked_what_now/", "subreddit_subscribers": 705723, "created_utc": 1696799368.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I've bought plenty of \"normal\" HDDs and SSDs for my desktop PC, highest size being a WD Blue 6TB. Well, it's maxed out on space, and instead of wasting SATA space with another 6TB, I want to turn to NAS drives. I know literally next to nothing about them and what to look for if I intend to use one for simple image/file storage in my desktop (so not in a dedicated NAS setup). I really just want a high capacity with a decent value. Speed would be nice, too, but since the use case will probably include upwards of accessing images or simple files, speed isn't a priority, just a luxury.\n\nI've found a couple on Amazon, but again, I have no idea what I'm looking at to compare them to each other with their relative prices:\n\nLike this Seagate Exos X18 18TB @ $279 USD, or Seagate Ironwolf Pro 16TB @ $285 USD\n\nI figure the Ironwolf Pro just adds some markup for features I don't need, so I suppose I should disqualify that one. But what about other choices similar to the Exos at a similar price range? Most of these seem to be CRM 7200rpm in this class. And is that even a good price? \n\nNote, my max budget ideally is less than $250, but there seems to be only a $20 difference in price in the 14-18TB options.\n\nAlso, I haven't stalked these before - do these products ever take part in Prime Day deals? There's some deal days coming up this week, if I recall correctly.", "author_fullname": "t2_7damr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Good bang-for-your-buck NAS drive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173bp11", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.61, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696803552.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve bought plenty of &amp;quot;normal&amp;quot; HDDs and SSDs for my desktop PC, highest size being a WD Blue 6TB. Well, it&amp;#39;s maxed out on space, and instead of wasting SATA space with another 6TB, I want to turn to NAS drives. I know literally next to nothing about them and what to look for if I intend to use one for simple image/file storage in my desktop (so not in a dedicated NAS setup). I really just want a high capacity with a decent value. Speed would be nice, too, but since the use case will probably include upwards of accessing images or simple files, speed isn&amp;#39;t a priority, just a luxury.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve found a couple on Amazon, but again, I have no idea what I&amp;#39;m looking at to compare them to each other with their relative prices:&lt;/p&gt;\n\n&lt;p&gt;Like this Seagate Exos X18 18TB @ $279 USD, or Seagate Ironwolf Pro 16TB @ $285 USD&lt;/p&gt;\n\n&lt;p&gt;I figure the Ironwolf Pro just adds some markup for features I don&amp;#39;t need, so I suppose I should disqualify that one. But what about other choices similar to the Exos at a similar price range? Most of these seem to be CRM 7200rpm in this class. And is that even a good price? &lt;/p&gt;\n\n&lt;p&gt;Note, my max budget ideally is less than $250, but there seems to be only a $20 difference in price in the 14-18TB options.&lt;/p&gt;\n\n&lt;p&gt;Also, I haven&amp;#39;t stalked these before - do these products ever take part in Prime Day deals? There&amp;#39;s some deal days coming up this week, if I recall correctly.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173bp11", "is_robot_indexable": true, "report_reasons": null, "author": "PhotonWolfsky", "discussion_type": null, "num_comments": 17, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173bp11/good_bangforyourbuck_nas_drive/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173bp11/good_bangforyourbuck_nas_drive/", "subreddit_subscribers": 705723, "created_utc": 1696803552.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The title pretty much says it  all. I have tried the wayback-machine-downloader but it downloads .HTML files and archivarix does not help much either (have not heard back from them after submitting a download request). Is there any other alternatives that actually work and able to grab all the files from website using the internet archive from Wayback machine? Thanks. ", "author_fullname": "t2_9oo3ftmu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can you bulk download all the resources (i.e., pdf, jpg) from a website using the Wyabck machine archive?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173g19v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696815991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The title pretty much says it  all. I have tried the wayback-machine-downloader but it downloads .HTML files and archivarix does not help much either (have not heard back from them after submitting a download request). Is there any other alternatives that actually work and able to grab all the files from website using the internet archive from Wayback machine? Thanks. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173g19v", "is_robot_indexable": true, "report_reasons": null, "author": "non-linear94", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173g19v/can_you_bulk_download_all_the_resources_ie_pdf/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173g19v/can_you_bulk_download_all_the_resources_ie_pdf/", "subreddit_subscribers": 705723, "created_utc": 1696815991.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey guys, I'm currently new to this topic so I would like some clarification between cloning and imaging. I've done some research, but most of the articles aren't doing a very good job of clarifying the differences between the two and which is most effective for what.  \n\n\nSo here are some of the scenarios that I will create a backup for:\n\n1. Restoring windows and my data in case of a software issue (bad update or malware, but hardware is fine)\n2. Replacing a failing hard drive. If my hard drive stops working the very next day, I would like to use my backup to restore all my files to a new drive\n3. Transferring all of my data from an old computer to a new computer.\n\nIn which of these scenarios would imaging or cloning make the most sense? \n\nThank you in advance.  \n\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_25235vtr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should I use imaging or cloning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1733ztz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.64, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696784110.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, I&amp;#39;m currently new to this topic so I would like some clarification between cloning and imaging. I&amp;#39;ve done some research, but most of the articles aren&amp;#39;t doing a very good job of clarifying the differences between the two and which is most effective for what.  &lt;/p&gt;\n\n&lt;p&gt;So here are some of the scenarios that I will create a backup for:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Restoring windows and my data in case of a software issue (bad update or malware, but hardware is fine)&lt;/li&gt;\n&lt;li&gt;Replacing a failing hard drive. If my hard drive stops working the very next day, I would like to use my backup to restore all my files to a new drive&lt;/li&gt;\n&lt;li&gt;Transferring all of my data from an old computer to a new computer.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;In which of these scenarios would imaging or cloning make the most sense? &lt;/p&gt;\n\n&lt;p&gt;Thank you in advance.  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1733ztz", "is_robot_indexable": true, "report_reasons": null, "author": "iSpazm", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1733ztz/should_i_use_imaging_or_cloning/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1733ztz/should_i_use_imaging_or_cloning/", "subreddit_subscribers": 705723, "created_utc": 1696784110.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Did people save Imgur content before Imgur deleted a lot of stuff according to their new policy?\n\nBtw, few years ago some website crawler apps were able to get deleted content from Imgur servers, despite being deleted and not accessible through web browsers.\n\nBut I don't remember the specific crawler app name anymore. It was Windows version, was it on Github or some other site, can't remember anymore.", "author_fullname": "t2_fl12kooxb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Imgur deleted content?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1730pwh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696775867.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Did people save Imgur content before Imgur deleted a lot of stuff according to their new policy?&lt;/p&gt;\n\n&lt;p&gt;Btw, few years ago some website crawler apps were able to get deleted content from Imgur servers, despite being deleted and not accessible through web browsers.&lt;/p&gt;\n\n&lt;p&gt;But I don&amp;#39;t remember the specific crawler app name anymore. It was Windows version, was it on Github or some other site, can&amp;#39;t remember anymore.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1730pwh", "is_robot_indexable": true, "report_reasons": null, "author": "Confident-Dingo-99", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1730pwh/imgur_deleted_content/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1730pwh/imgur_deleted_content/", "subreddit_subscribers": 705723, "created_utc": 1696775867.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Is there a functioning tool to download the saved posts / upvotes that you do on reddit? This tool: [https://github.com/shadowmoose/RedditDownloader](https://github.com/shadowmoose/RedditDownloader) was perfect, but it got rekt by the API changes and has been discontinued.", "author_fullname": "t2_16hsu9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Reddit downloader that works after API upgrade", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17304ho", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.58, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696774341.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there a functioning tool to download the saved posts / upvotes that you do on reddit? This tool: &lt;a href=\"https://github.com/shadowmoose/RedditDownloader\"&gt;https://github.com/shadowmoose/RedditDownloader&lt;/a&gt; was perfect, but it got rekt by the API changes and has been discontinued.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17304ho", "is_robot_indexable": true, "report_reasons": null, "author": "TheSaltyJ", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17304ho/reddit_downloader_that_works_after_api_upgrade/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/17304ho/reddit_downloader_that_works_after_api_upgrade/", "subreddit_subscribers": 705723, "created_utc": 1696774341.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I was trying to save an online stream for editing and archival purposes and tried 3 different software:\n\n1. YT-DLP : 994MB (best format already selected 720P)\n2. VDHelper: 996MB\n3. Stream HLS Recorder: 993MB \n\nWhy is this the case? \n\nI retried their downloads and it consistently downloaded the same file sizes respectively \n\nAll 3 video files are 720p and have very similar meta data, if not exactly the same. \n\nI'm watching all three of them manually and there are no noticeable differences.\n\n&amp;#x200B;", "author_fullname": "t2_7qbkalan", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why? Converting hls streaming to mp4 with 3 different methods results in 3 different file sizes?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173kzbd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696832928.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was trying to save an online stream for editing and archival purposes and tried 3 different software:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;YT-DLP : 994MB (best format already selected 720P)&lt;/li&gt;\n&lt;li&gt;VDHelper: 996MB&lt;/li&gt;\n&lt;li&gt;Stream HLS Recorder: 993MB &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Why is this the case? &lt;/p&gt;\n\n&lt;p&gt;I retried their downloads and it consistently downloaded the same file sizes respectively &lt;/p&gt;\n\n&lt;p&gt;All 3 video files are 720p and have very similar meta data, if not exactly the same. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m watching all three of them manually and there are no noticeable differences.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173kzbd", "is_robot_indexable": true, "report_reasons": null, "author": "SherbetTiger", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173kzbd/why_converting_hls_streaming_to_mp4_with_3/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173kzbd/why_converting_hls_streaming_to_mp4_with_3/", "subreddit_subscribers": 705723, "created_utc": 1696832928.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm looking for one that can swap drives with ease, not the kind you have to screw and unscrew to change drives. I have one that's basically just a plastic box, but it gets HOT! Have you guys come across any you really like?", "author_fullname": "t2_4y11jk7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do you have an external 3.5\" enclosure you recommend?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173ha3m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696819729.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m looking for one that can swap drives with ease, not the kind you have to screw and unscrew to change drives. I have one that&amp;#39;s basically just a plastic box, but it gets HOT! Have you guys come across any you really like?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173ha3m", "is_robot_indexable": true, "report_reasons": null, "author": "grief_and_confusion", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173ha3m/do_you_have_an_external_35_enclosure_you_recommend/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173ha3m/do_you_have_an_external_35_enclosure_you_recommend/", "subreddit_subscribers": 705723, "created_utc": 1696819729.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I\u2019ve just about wrapped up my network setup and am considering adding a NAS next, specifically eyeing the Synology DS1522+. In the interim, I'd like some suggestions for an SSD and case to use with a Raspberry Pi for running a Bitcoin node. It would be a bonus if this SSD is also compatible with my future NAS. \n\nAppreciate any insights!", "author_fullname": "t2_jk4yxeos", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking SSD and Case Recommendations for Raspberry Pi Bitcoin Node &amp; Future NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173cwkd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696806780.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019ve just about wrapped up my network setup and am considering adding a NAS next, specifically eyeing the Synology DS1522+. In the interim, I&amp;#39;d like some suggestions for an SSD and case to use with a Raspberry Pi for running a Bitcoin node. It would be a bonus if this SSD is also compatible with my future NAS. &lt;/p&gt;\n\n&lt;p&gt;Appreciate any insights!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173cwkd", "is_robot_indexable": true, "report_reasons": null, "author": "SecondMars", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173cwkd/seeking_ssd_and_case_recommendations_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173cwkd/seeking_ssd_and_case_recommendations_for/", "subreddit_subscribers": 705723, "created_utc": 1696806780.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi \n\nI currently have a LSI 9305-24i in my server with 24 drives connected up. This card has the AVAGO bios on the card.\n\nMy question, if i purchase another card for example a LSI 9300-8i would I be able to see that AVAGO bios also during the post?\n\nSorry if this question is pretty dumb but I am pretty new to this.\n\nReason being I want to test if my current card is playing up as one the drives is negotiating at 3Gbps instead of 6Gbps.\n\nThe server is a Truenas build.\n\nOnce again sorry if this is stupid", "author_fullname": "t2_4kl3s1e1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can I use 2 different SAS cards in my server", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1739mhx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696798344.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi &lt;/p&gt;\n\n&lt;p&gt;I currently have a LSI 9305-24i in my server with 24 drives connected up. This card has the AVAGO bios on the card.&lt;/p&gt;\n\n&lt;p&gt;My question, if i purchase another card for example a LSI 9300-8i would I be able to see that AVAGO bios also during the post?&lt;/p&gt;\n\n&lt;p&gt;Sorry if this question is pretty dumb but I am pretty new to this.&lt;/p&gt;\n\n&lt;p&gt;Reason being I want to test if my current card is playing up as one the drives is negotiating at 3Gbps instead of 6Gbps.&lt;/p&gt;\n\n&lt;p&gt;The server is a Truenas build.&lt;/p&gt;\n\n&lt;p&gt;Once again sorry if this is stupid&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1739mhx", "is_robot_indexable": true, "report_reasons": null, "author": "AJBOJACK", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1739mhx/can_i_use_2_different_sas_cards_in_my_server/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1739mhx/can_i_use_2_different_sas_cards_in_my_server/", "subreddit_subscribers": 705723, "created_utc": 1696798344.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What is the best way to upgrade RAID1 pool with 2 WD 500gb drives? I bought 2x4 TB drives but my truenas server only has 3 sata ports. What should i do?", "author_fullname": "t2_adfbrmlw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Expanding NAS", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172zvdn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.66, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696773671.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What is the best way to upgrade RAID1 pool with 2 WD 500gb drives? I bought 2x4 TB drives but my truenas server only has 3 sata ports. What should i do?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172zvdn", "is_robot_indexable": true, "report_reasons": null, "author": "picua_", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172zvdn/expanding_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172zvdn/expanding_nas/", "subreddit_subscribers": 705723, "created_utc": 1696773671.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "i have a few thousand videos that i need to crop and can't find any good software for pc, any suggestions? (would be better if it allows for custom crop ratio and not just 1:1 or 16:9 ect...)", "author_fullname": "t2_dfdoc6ab", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "A good free video cropping software for lots of video?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172y71e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696768842.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;i have a few thousand videos that i need to crop and can&amp;#39;t find any good software for pc, any suggestions? (would be better if it allows for custom crop ratio and not just 1:1 or 16:9 ect...)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "5,5TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172y71e", "is_robot_indexable": true, "report_reasons": null, "author": "Key-Wait-3098", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/172y71e/a_good_free_video_cropping_software_for_lots_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172y71e/a_good_free_video_cropping_software_for_lots_of/", "subreddit_subscribers": 705723, "created_utc": 1696768842.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "What can archive downloaders are safe to use, I was about to use camsweb but I\u2019m unsure of its safety, other places charge payment are there any other free sites that are confirmed safe to use?", "author_fullname": "t2_81aol1r9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Archive safety", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172x5xg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696765516.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What can archive downloaders are safe to use, I was about to use camsweb but I\u2019m unsure of its safety, other places charge payment are there any other free sites that are confirmed safe to use?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172x5xg", "is_robot_indexable": true, "report_reasons": null, "author": "Revolutionary-Group7", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/172x5xg/archive_safety/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172x5xg/archive_safety/", "subreddit_subscribers": 705723, "created_utc": 1696765516.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "The account in question is set to private but I'm a subscriber.\n\nWould be great if I could also archive comments to that account's posts.\nThank you.", "author_fullname": "t2_114rdj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I mass-archive caption text from an Instagram account's posts?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172w4pu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.57, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "e34ee8aa-b988-11e2-9fc1-12313d18884c", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "hd", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696761826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;The account in question is set to private but I&amp;#39;m a subscriber.&lt;/p&gt;\n\n&lt;p&gt;Would be great if I could also archive comments to that account&amp;#39;s posts.\nThank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "16TB", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "172w4pu", "is_robot_indexable": true, "report_reasons": null, "author": "KitezhGrad", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/172w4pu/how_do_i_massarchive_caption_text_from_an/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/172w4pu/how_do_i_massarchive_caption_text_from_an/", "subreddit_subscribers": 705723, "created_utc": 1696761826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm new to all this but wanted to take a crack at recovering deleted data on my personal devices just to see what can be dug up and how much space you lose over time to residual files that just never actually go away. As I expected from what I've learned, it was pretty easy to do on an HDD using Recuva, but I wanted to know how possible it is on an SSD. I hear mixed things about TRIM-enabled SSDs though, with some saying that you can easily recover deleted stuff, and that like HDDs things are only gone when overwritten, while others say that the moment TRIM is run it's as good as gone, and others say it's somewhere in the middle where within a week or two it'll be gone.  \n\nI figured I'd ask here seeing as there are people with far more knowledge than me on this - is it worth trying to recover something from a TRIM-enabled SSD? I have a handful of devices - one with a 500GB NVME SSD, another with a 500GB SATA SSD, both on computers running Windows 11, and a Google Pixel 6 running the latest version of its OS and software with 128gb of storage. I'm not 100% sure if it's an SSD but I always figured phones made within the past 10-ish years used SSDs. Say after a month or two of continued use of a device with TRIM enabled, (so new things are being written like cache from apps and browsing the internet) what deleted files could be recovered from these? If you deleted an important file on a TRIM-enabled drive, how much time on average would you have to recover it before garbage collection occurs and the file is lost for good?  \n\nAnother question I have is that while I obviously don't have the equipment or expertise to do this, I've also read that data recovery companies can actually remove the chips from an SSD and recover data directly from them that way. Can this be used to circumvent TRIM deleted files if you really need to recover what you deleted?", "author_fullname": "t2_j52b70pj5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recovering data from TRIM-enabled drives - is it worth trying?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173fl1d", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696814649.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m new to all this but wanted to take a crack at recovering deleted data on my personal devices just to see what can be dug up and how much space you lose over time to residual files that just never actually go away. As I expected from what I&amp;#39;ve learned, it was pretty easy to do on an HDD using Recuva, but I wanted to know how possible it is on an SSD. I hear mixed things about TRIM-enabled SSDs though, with some saying that you can easily recover deleted stuff, and that like HDDs things are only gone when overwritten, while others say that the moment TRIM is run it&amp;#39;s as good as gone, and others say it&amp;#39;s somewhere in the middle where within a week or two it&amp;#39;ll be gone.  &lt;/p&gt;\n\n&lt;p&gt;I figured I&amp;#39;d ask here seeing as there are people with far more knowledge than me on this - is it worth trying to recover something from a TRIM-enabled SSD? I have a handful of devices - one with a 500GB NVME SSD, another with a 500GB SATA SSD, both on computers running Windows 11, and a Google Pixel 6 running the latest version of its OS and software with 128gb of storage. I&amp;#39;m not 100% sure if it&amp;#39;s an SSD but I always figured phones made within the past 10-ish years used SSDs. Say after a month or two of continued use of a device with TRIM enabled, (so new things are being written like cache from apps and browsing the internet) what deleted files could be recovered from these? If you deleted an important file on a TRIM-enabled drive, how much time on average would you have to recover it before garbage collection occurs and the file is lost for good?  &lt;/p&gt;\n\n&lt;p&gt;Another question I have is that while I obviously don&amp;#39;t have the equipment or expertise to do this, I&amp;#39;ve also read that data recovery companies can actually remove the chips from an SSD and recover data directly from them that way. Can this be used to circumvent TRIM deleted files if you really need to recover what you deleted?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173fl1d", "is_robot_indexable": true, "report_reasons": null, "author": "stellerman7", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173fl1d/recovering_data_from_trimenabled_drives_is_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173fl1d/recovering_data_from_trimenabled_drives_is_it/", "subreddit_subscribers": 705723, "created_utc": 1696814649.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "with out modifying the case, can I use 2 Rosewill RSV-L4500U cases and get 30 drives in 1 setup?\n\nMy idea was a 8e HBA card connected to some pci pass-through bracket then breaks out to the drives. I am concerned mostly about the length of cable from card to HDD", "author_fullname": "t2_bzyt92hp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "will this work 2xRosewill RSV-L4500U acting as 1 30 drive setup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173e9vk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696810686.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;with out modifying the case, can I use 2 Rosewill RSV-L4500U cases and get 30 drives in 1 setup?&lt;/p&gt;\n\n&lt;p&gt;My idea was a 8e HBA card connected to some pci pass-through bracket then breaks out to the drives. I am concerned mostly about the length of cable from card to HDD&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173e9vk", "is_robot_indexable": true, "report_reasons": null, "author": "Think_Ad_9915", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173e9vk/will_this_work_2xrosewill_rsvl4500u_acting_as_1/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173e9vk/will_this_work_2xrosewill_rsvl4500u_acting_as_1/", "subreddit_subscribers": 705723, "created_utc": 1696810686.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "There were tons of downloader scripts that would download saved posts for reddit. But what about lemmy... do you know of any such scripts. I searched but couldn't find any...\n\n Or do you know of a way of downloading saved posts (pictures, videos) on Lemmy?", "author_fullname": "t2_caaja", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a lemmy downloader?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "scripts", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173bzu0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Scripts/Software", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696804324.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There were tons of downloader scripts that would download saved posts for reddit. But what about lemmy... do you know of any such scripts. I searched but couldn&amp;#39;t find any...&lt;/p&gt;\n\n&lt;p&gt;Or do you know of a way of downloading saved posts (pictures, videos) on Lemmy?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "70ae6ea0-b94e-11eb-af00-0ec434816a2f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "173bzu0", "is_robot_indexable": true, "report_reasons": null, "author": "ideas_r_bulletproof", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/173bzu0/is_there_a_lemmy_downloader/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/173bzu0/is_there_a_lemmy_downloader/", "subreddit_subscribers": 705723, "created_utc": 1696804324.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I bought a LSI SAS3041E pci card to add more sata ports on my computer, I'm running truenas scale, I was expecting to have to flash it but thought let me try it as it's a used part. It recognized the drive. Has this card already been flashed to IT mode? How can I tell?", "author_fullname": "t2_31uwvm4t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Flashing SAS card to IT mode.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1739adk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696797490.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I bought a LSI SAS3041E pci card to add more sata ports on my computer, I&amp;#39;m running truenas scale, I was expecting to have to flash it but thought let me try it as it&amp;#39;s a used part. It recognized the drive. Has this card already been flashed to IT mode? How can I tell?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1739adk", "is_robot_indexable": true, "report_reasons": null, "author": "arun2118", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1739adk/flashing_sas_card_to_it_mode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1739adk/flashing_sas_card_to_it_mode/", "subreddit_subscribers": 705723, "created_utc": 1696797490.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Not sure if this is the correct sub for this but I'm not sure where else to ask. \n\nI have folders of very long screenshots of fanfics from tumblr and fanfiction.net saved on my phone and I want to convert them as word/text files so i can use text to speech to read. I didn't know to use the wayback machine back then, i just use Longshot to screenshot everything I couldn't download. \n\nRight now my only recourse is use something like google lens but using that, I can only convert the length of my screen at a time and that's gonna take so long because like one pic is like, 30 stitched screenshots and I have a couple of folders. \n\nIs there software for this?", "author_fullname": "t2_5lnt8f8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "OCR or image-to-text for very long screenshots", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1733zxj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696784117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Not sure if this is the correct sub for this but I&amp;#39;m not sure where else to ask. &lt;/p&gt;\n\n&lt;p&gt;I have folders of very long screenshots of fanfics from tumblr and fanfiction.net saved on my phone and I want to convert them as word/text files so i can use text to speech to read. I didn&amp;#39;t know to use the wayback machine back then, i just use Longshot to screenshot everything I couldn&amp;#39;t download. &lt;/p&gt;\n\n&lt;p&gt;Right now my only recourse is use something like google lens but using that, I can only convert the length of my screen at a time and that&amp;#39;s gonna take so long because like one pic is like, 30 stitched screenshots and I have a couple of folders. &lt;/p&gt;\n\n&lt;p&gt;Is there software for this?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1733zxj", "is_robot_indexable": true, "report_reasons": null, "author": "ac-2223", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1733zxj/ocr_or_imagetotext_for_very_long_screenshots/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1733zxj/ocr_or_imagetotext_for_very_long_screenshots/", "subreddit_subscribers": 705723, "created_utc": 1696784117.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}