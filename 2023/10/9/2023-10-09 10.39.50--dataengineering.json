{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Had to leav my $130K remote job in August after 6 toxic months.  Had to take a 100% on site gig for $110K last month at a bad company to keep food on the table. Been still interviewing heavily to find something better. \n\nWhen I was casually looking around late last year, jobs were around $140K - $160K at my experience level, but I couldn\u2019t land anything. \n\n Even though I make $110K now, I tell recruiters I make $150K in my new role. Most refute and say that their max budget is $120Kish and full on site. \n\nThis is ~20% lower pay than what was being thrown around late last year, and on site. Anyone experiencing similiar?\n\nI\u2019m also might just be in a bad spot since I had to take this new gig, and people see my 2 short tenures in a row as a red flag. Advice?", "author_fullname": "t2_dbas4m3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone Else Seeing Salaries Collapse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173fj4h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.82, "author_flair_background_color": null, "subreddit_type": "public", "ups": 44, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 44, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696814480.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Had to leav my $130K remote job in August after 6 toxic months.  Had to take a 100% on site gig for $110K last month at a bad company to keep food on the table. Been still interviewing heavily to find something better. &lt;/p&gt;\n\n&lt;p&gt;When I was casually looking around late last year, jobs were around $140K - $160K at my experience level, but I couldn\u2019t land anything. &lt;/p&gt;\n\n&lt;p&gt;Even though I make $110K now, I tell recruiters I make $150K in my new role. Most refute and say that their max budget is $120Kish and full on site. &lt;/p&gt;\n\n&lt;p&gt;This is ~20% lower pay than what was being thrown around late last year, and on site. Anyone experiencing similiar?&lt;/p&gt;\n\n&lt;p&gt;I\u2019m also might just be in a bad spot since I had to take this new gig, and people see my 2 short tenures in a row as a red flag. Advice?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "173fj4h", "is_robot_indexable": true, "report_reasons": null, "author": "Proof_Hyena4223", "discussion_type": null, "num_comments": 41, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173fj4h/anyone_else_seeing_salaries_collapse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/173fj4h/anyone_else_seeing_salaries_collapse/", "subreddit_subscribers": 132838, "created_utc": 1696814480.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\nThere is this post a few years back summarising what they are. With the conclusion being they aren't really needed anymore if you rely on a modern cloud OLAP data warehouse. Especially when coupled with a metric semantic layer. \n\nhttps://analyticsengineers.club/whats-an-olap-cube/\n\nBut I was curious if this is indeed the case from other people's experiences? Or was this article an artifact of the ZIRP modern data tech stack hype era. \n\nI believe certain concepts are still relevant to understand since they can be applied outside of the actual OLAP cube(slice, dice, drill down, pivot the cube, cube design for handling non additive facts).\n\nBut are we in a place in time with technology where the computation and cost savings of storing preaggregated results in OLAP cubes are trivial and not worth the effort?", "author_fullname": "t2_5vqn2nya", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Are OLAP Cubes irrelevant in the present day?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172x3p9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 37, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 37, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696766686.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696765289.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is this post a few years back summarising what they are. With the conclusion being they aren&amp;#39;t really needed anymore if you rely on a modern cloud OLAP data warehouse. Especially when coupled with a metric semantic layer. &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://analyticsengineers.club/whats-an-olap-cube/\"&gt;https://analyticsengineers.club/whats-an-olap-cube/&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But I was curious if this is indeed the case from other people&amp;#39;s experiences? Or was this article an artifact of the ZIRP modern data tech stack hype era. &lt;/p&gt;\n\n&lt;p&gt;I believe certain concepts are still relevant to understand since they can be applied outside of the actual OLAP cube(slice, dice, drill down, pivot the cube, cube design for handling non additive facts).&lt;/p&gt;\n\n&lt;p&gt;But are we in a place in time with technology where the computation and cost savings of storing preaggregated results in OLAP cubes are trivial and not worth the effort?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QjrvxUmpd-ZW4ifQD-Whrz978V6hDwKH5fevn7PFWz0.jpg?auto=webp&amp;s=408d5bca1765ff2e84ac52c8e3333778de3ca2a3", "width": 2560, "height": 1740}, "resolutions": [{"url": "https://external-preview.redd.it/QjrvxUmpd-ZW4ifQD-Whrz978V6hDwKH5fevn7PFWz0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=633c539fc687303acb2ca5480328e48e21102da8", "width": 108, "height": 73}, {"url": "https://external-preview.redd.it/QjrvxUmpd-ZW4ifQD-Whrz978V6hDwKH5fevn7PFWz0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=32022a77efd303f2f8e7f6d8a86adedb6c64e783", "width": 216, "height": 146}, {"url": "https://external-preview.redd.it/QjrvxUmpd-ZW4ifQD-Whrz978V6hDwKH5fevn7PFWz0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6977356c24997a9044fd257642b4c05bdcf399c4", "width": 320, "height": 217}, {"url": "https://external-preview.redd.it/QjrvxUmpd-ZW4ifQD-Whrz978V6hDwKH5fevn7PFWz0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=25b6bac2a303913ddd97a5f3ef83a6bb5f979967", "width": 640, "height": 435}, {"url": "https://external-preview.redd.it/QjrvxUmpd-ZW4ifQD-Whrz978V6hDwKH5fevn7PFWz0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=0f822fbed26745507b6023ea72b73f76b8962ac6", "width": 960, "height": 652}, {"url": "https://external-preview.redd.it/QjrvxUmpd-ZW4ifQD-Whrz978V6hDwKH5fevn7PFWz0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c443f2f6707a695e6afb3fb6c6511c9d6f89eacb", "width": 1080, "height": 734}], "variants": {}, "id": "bfJ0QVkvsHrOs2-GmyFUiqiDbgiKrwkAx8UwCxgh2-4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "172x3p9", "is_robot_indexable": true, "report_reasons": null, "author": "recentcurrency", "discussion_type": null, "num_comments": 37, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/172x3p9/are_olap_cubes_irrelevant_in_the_present_day/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/172x3p9/are_olap_cubes_irrelevant_in_the_present_day/", "subreddit_subscribers": 132838, "created_utc": 1696765289.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Do you do freelance work or consultancy in data engineering/analytics? I have some questions:\n\n* How do you deliver the work to customers, for example an ETL pipeline? (do they assemble everything on the client including orchestrator, python, database, etc?) - this really worry me because I think that i will need to setup all the environment in their side and this could be really complex to do.\n* What services do you do?\n* What are the most requested services?\n* Which ones would you like to do, but don't have time to learn/pratice?\n* Which ones you don't do because you don't want to and it doesn't pay well?\n* Can you describe an example of a project you have done?\n* Can you share the areas/niches (size of companies) that you usually work with?\n\n&amp;#x200B;\n\nContext: i did some freelancing projects in the past but were more related to data cleaning and data transformations. And now I want to start something from zero and offer more and create internet presence to share my projects. I have a few years of experience too.", "author_fullname": "t2_6ip8cun1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Engineers", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1737dp9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696793122.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696792618.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Do you do freelance work or consultancy in data engineering/analytics? I have some questions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;How do you deliver the work to customers, for example an ETL pipeline? (do they assemble everything on the client including orchestrator, python, database, etc?) - this really worry me because I think that i will need to setup all the environment in their side and this could be really complex to do.&lt;/li&gt;\n&lt;li&gt;What services do you do?&lt;/li&gt;\n&lt;li&gt;What are the most requested services?&lt;/li&gt;\n&lt;li&gt;Which ones would you like to do, but don&amp;#39;t have time to learn/pratice?&lt;/li&gt;\n&lt;li&gt;Which ones you don&amp;#39;t do because you don&amp;#39;t want to and it doesn&amp;#39;t pay well?&lt;/li&gt;\n&lt;li&gt;Can you describe an example of a project you have done?&lt;/li&gt;\n&lt;li&gt;Can you share the areas/niches (size of companies) that you usually work with?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Context: i did some freelancing projects in the past but were more related to data cleaning and data transformations. And now I want to start something from zero and offer more and create internet presence to share my projects. I have a few years of experience too.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1737dp9", "is_robot_indexable": true, "report_reasons": null, "author": "23am50", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1737dp9/data_engineers/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1737dp9/data_engineers/", "subreddit_subscribers": 132838, "created_utc": 1696792618.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Umm so I am kind of stuck  at where I am as a Data Engineer or Data Platform Engineer or whether those two should even be seperate roles. \n\nMy current employer is a IT service provider and I joined as a Data Engineer associate straight outta college (not even CS background, got lucky I guess). They trained us in the basics SQL/Python and then I got onboarded on a project focusing on AWS EMR and Databricks and the complete AWS stack. To my luck I was onboarded on the platform team so I learnt quite a bit of DevOps on the fly. \n\n3 years later, I set up the entire Databricks infrastructure here, and created the SOPs for development teams to follow. But I haven't written a single line of code myself. Worked purely on architecture and benchmarkings (like what's better, what's cheaper etc, which has more security protocols) \n\nHere comes the question I realised I am severely underpaid, but no where I go I can say my experience matches apples to apples. \n\nI don't even know what my role classifies as and how should I be preparing for the next role. Any help? any ideas? Kinda fried my brains rn.", "author_fullname": "t2_4c9picnu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's like a realistic amount of time when you are considered as an experienced / senior Data Engineer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173dp8t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696808994.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Umm so I am kind of stuck  at where I am as a Data Engineer or Data Platform Engineer or whether those two should even be seperate roles. &lt;/p&gt;\n\n&lt;p&gt;My current employer is a IT service provider and I joined as a Data Engineer associate straight outta college (not even CS background, got lucky I guess). They trained us in the basics SQL/Python and then I got onboarded on a project focusing on AWS EMR and Databricks and the complete AWS stack. To my luck I was onboarded on the platform team so I learnt quite a bit of DevOps on the fly. &lt;/p&gt;\n\n&lt;p&gt;3 years later, I set up the entire Databricks infrastructure here, and created the SOPs for development teams to follow. But I haven&amp;#39;t written a single line of code myself. Worked purely on architecture and benchmarkings (like what&amp;#39;s better, what&amp;#39;s cheaper etc, which has more security protocols) &lt;/p&gt;\n\n&lt;p&gt;Here comes the question I realised I am severely underpaid, but no where I go I can say my experience matches apples to apples. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t even know what my role classifies as and how should I be preparing for the next role. Any help? any ideas? Kinda fried my brains rn.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "173dp8t", "is_robot_indexable": true, "report_reasons": null, "author": "Gora_HabshiYoYo", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173dp8t/whats_like_a_realistic_amount_of_time_when_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/173dp8t/whats_like_a_realistic_amount_of_time_when_you/", "subreddit_subscribers": 132838, "created_utc": 1696808994.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone, I uploaded a PySpark course to my YouTube channel. I tried to cover wide range of topics including SparkContext and SparkSession, Resilient Distributed Datasets (RDDs), DataFrame and Dataset APIs, Data Cleaning and Preprocessing, Exploratory Data Analysis, Data Transformation and Manipulation, Group By and Window ,User Defined Functions and Machine Learning with Spark MLlib. I am adding the link below, have a great day! \n\n[https://www.youtube.com/watch?v=jWZ9K1agm5Y](https://www.youtube.com/watch?v=jWZ9K1agm5Y)", "author_fullname": "t2_me12im5a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I recorded a PySpark Big Data Course (1+ Hour) and uploaded it on YouTube", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1731ksb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696777956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I uploaded a PySpark course to my YouTube channel. I tried to cover wide range of topics including SparkContext and SparkSession, Resilient Distributed Datasets (RDDs), DataFrame and Dataset APIs, Data Cleaning and Preprocessing, Exploratory Data Analysis, Data Transformation and Manipulation, Group By and Window ,User Defined Functions and Machine Learning with Spark MLlib. I am adding the link below, have a great day! &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.youtube.com/watch?v=jWZ9K1agm5Y\"&gt;https://www.youtube.com/watch?v=jWZ9K1agm5Y&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/jqoodiekrnULXjPZtvF9eEpIUXsnwoG-ER8FIh-yeUo.jpg?auto=webp&amp;s=7b0166bc5867a7ce4385d67dcd3f4fa50683d4e7", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/jqoodiekrnULXjPZtvF9eEpIUXsnwoG-ER8FIh-yeUo.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=3274ea7312a04e8647f5f09e239e3f683673b5d4", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/jqoodiekrnULXjPZtvF9eEpIUXsnwoG-ER8FIh-yeUo.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b64d29a1fcbb01247ec43c00bac15338baed0ad7", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/jqoodiekrnULXjPZtvF9eEpIUXsnwoG-ER8FIh-yeUo.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=552a93dafd66279606f2612ed030dabdce4eaf26", "width": 320, "height": 240}], "variants": {}, "id": "BSXYISB8lzOgeFswenJST8Pji3lho2I6izN4zeF7t9g"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "1731ksb", "is_robot_indexable": true, "report_reasons": null, "author": "onurbaltaci", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1731ksb/i_recorded_a_pyspark_big_data_course_1_hour_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1731ksb/i_recorded_a_pyspark_big_data_course_1_hour_and/", "subreddit_subscribers": 132838, "created_utc": 1696777956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am defining data validation standards for our data pipelines  on ingestion. I am planning that checks should be done in the pipeline itself. So far I have this list:\n\n1. Check for schema changes\n2. Check if received data matches the agreed schema\n3. Nulls, Unique, where applicable\n4. Check for integrity by comparing to other datasets (like that FK and master tables\n5. Maybe check counts vs some periodic averages\n\n&amp;#x200B;\n\nAny other recommendations? Even if we aim to ingest raw data, we will want to check its validity before storing. These are for structured data from structured sources that will be stored in a columnar database.\n\nAlso, maybe those would be an overkill? I am not a DE, but I am responsible for Data Quality. So looking for some practical suggestions that would not seem too crazy for the team.\n\n&amp;#x200B;\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_49dbxejy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ideas for data validation on data ingestion?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173kp9o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696831831.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am defining data validation standards for our data pipelines  on ingestion. I am planning that checks should be done in the pipeline itself. So far I have this list:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Check for schema changes&lt;/li&gt;\n&lt;li&gt;Check if received data matches the agreed schema&lt;/li&gt;\n&lt;li&gt;Nulls, Unique, where applicable&lt;/li&gt;\n&lt;li&gt;Check for integrity by comparing to other datasets (like that FK and master tables&lt;/li&gt;\n&lt;li&gt;Maybe check counts vs some periodic averages&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any other recommendations? Even if we aim to ingest raw data, we will want to check its validity before storing. These are for structured data from structured sources that will be stored in a columnar database.&lt;/p&gt;\n\n&lt;p&gt;Also, maybe those would be an overkill? I am not a DE, but I am responsible for Data Quality. So looking for some practical suggestions that would not seem too crazy for the team.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "173kp9o", "is_robot_indexable": true, "report_reasons": null, "author": "HereJustForAnswers", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173kp9o/ideas_for_data_validation_on_data_ingestion/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/173kp9o/ideas_for_data_validation_on_data_ingestion/", "subreddit_subscribers": 132838, "created_utc": 1696831831.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\ud83d\ude80 Exciting News! Just released my latest YouTube video - \"PySpark Tutorial for Beginners: 1-Hour Full Course\" \ud83d\udc0d\ud83d\udca1\n\nAre you ready to dive into the world of PySpark and harness the power of distributed data processing with ease? In this comprehensive 1-hour tutorial, I'll guide you through the fundamentals of PySpark, from installation to hands-on coding examples.\n\n\ud83d\udd25 What You'll Learn:\n\u2705 Spark Introduction\n\u2705 Spark Installation\n\u2705 Setting Up Your PySpark Environment\n\u2705 Spark RDD\n\u2705 DataFrame Operations\n\u2705 Spark SQL\n\u2705 And much more!\n\nWhether you're a beginner looking to kickstart your journey into big data or an experienced data engineer aiming to refresh your skills, this video has something for you!\n\nWatch it now \ud83d\udc49 https://youtu.be/EB8lfdxpirM\nGitHub Repo \ud83d\udc49 https://github.com/coder2j/pyspark-tutorial\n\nDon't forget to like, subscribe, and share with your network. Let's spread the knowledge together! \ud83d\udcda\ud83d\udcaa\n#PySpark #DataScience #BigData #Tutorial #LinkedInLearning #YouTubeTutorial", "author_fullname": "t2_h4j43yry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark Tutorial for Beginners: 1-Hour Full Course", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_173lca6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/EB8lfdxpirM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"PySpark Tutorial for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "PySpark Tutorial for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/EB8lfdxpirM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"PySpark Tutorial for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "coder2j", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/EB8lfdxpirM/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@coder2j"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/EB8lfdxpirM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"PySpark Tutorial for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/173lca6", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nyeAsJ_Iyn208srWSK-sRJw_-S14SsgknHSuV_YPKCM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696834356.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\ud83d\ude80 Exciting News! Just released my latest YouTube video - &amp;quot;PySpark Tutorial for Beginners: 1-Hour Full Course&amp;quot; \ud83d\udc0d\ud83d\udca1&lt;/p&gt;\n\n&lt;p&gt;Are you ready to dive into the world of PySpark and harness the power of distributed data processing with ease? In this comprehensive 1-hour tutorial, I&amp;#39;ll guide you through the fundamentals of PySpark, from installation to hands-on coding examples.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd25 What You&amp;#39;ll Learn:\n\u2705 Spark Introduction\n\u2705 Spark Installation\n\u2705 Setting Up Your PySpark Environment\n\u2705 Spark RDD\n\u2705 DataFrame Operations\n\u2705 Spark SQL\n\u2705 And much more!&lt;/p&gt;\n\n&lt;p&gt;Whether you&amp;#39;re a beginner looking to kickstart your journey into big data or an experienced data engineer aiming to refresh your skills, this video has something for you!&lt;/p&gt;\n\n&lt;p&gt;Watch it now \ud83d\udc49 &lt;a href=\"https://youtu.be/EB8lfdxpirM\"&gt;https://youtu.be/EB8lfdxpirM&lt;/a&gt;\nGitHub Repo \ud83d\udc49 &lt;a href=\"https://github.com/coder2j/pyspark-tutorial\"&gt;https://github.com/coder2j/pyspark-tutorial&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t forget to like, subscribe, and share with your network. Let&amp;#39;s spread the knowledge together! \ud83d\udcda\ud83d\udcaa&lt;/p&gt;\n\n&lt;h1&gt;PySpark #DataScience #BigData #Tutorial #LinkedInLearning #YouTubeTutorial&lt;/h1&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/EB8lfdxpirM", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/82Ln0Z8hZhrRQ6_8TIvFLpE_UPEKESS_TxaZOyjr6Ig.jpg?auto=webp&amp;s=721ceed222baa9b21597759f40ad168578d0ee74", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/82Ln0Z8hZhrRQ6_8TIvFLpE_UPEKESS_TxaZOyjr6Ig.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9318f73383bcd738f86d14479864d192ae47b270", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/82Ln0Z8hZhrRQ6_8TIvFLpE_UPEKESS_TxaZOyjr6Ig.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6616b558982a89e258beb94901e9d212ce6bf76a", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/82Ln0Z8hZhrRQ6_8TIvFLpE_UPEKESS_TxaZOyjr6Ig.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b465b2e80a183e03df5ef8d4f758d78f53dd3454", "width": 320, "height": 240}], "variants": {}, "id": "wp5OUtzYt-eYRgOkWVPGa-zaQJ8PGPB2r-t4qza7MPs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "173lca6", "is_robot_indexable": true, "report_reasons": null, "author": "Coder2j", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173lca6/pyspark_tutorial_for_beginners_1hour_full_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/EB8lfdxpirM", "subreddit_subscribers": 132838, "created_utc": 1696834356.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "PySpark Tutorial for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/EB8lfdxpirM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"PySpark Tutorial for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "coder2j", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/EB8lfdxpirM/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@coder2j"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am working on a simple data pipeline that reads data from an API every minute and sends it through Kafka to AWS S3 and DynamoDB for some analytics. The goal is to showcase this project in my resume in a month or two. \n\nThe throughput is quite low (basically 5-6 records per minute), I know that Kafka might be overhead but I just want to showcase my skills with it. Which option would be the most affordable to deploy the Kafka server/cluster (although a single instance would be enough) and run it for 6 months : \n\n\\- Confluent Cloud (they have a free option, but you still pay for the infrastructure which is more than what's required for this simple use case).\n\n\\- A single EC2 instance running Kafka\n\n\\- A Kafka docker container in AWS ECS. \n\n&amp;#x200B;", "author_fullname": "t2_nq65wse7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best affordable way to deploy host a Kafka setup for a toy project", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1739kqr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696798220.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a simple data pipeline that reads data from an API every minute and sends it through Kafka to AWS S3 and DynamoDB for some analytics. The goal is to showcase this project in my resume in a month or two. &lt;/p&gt;\n\n&lt;p&gt;The throughput is quite low (basically 5-6 records per minute), I know that Kafka might be overhead but I just want to showcase my skills with it. Which option would be the most affordable to deploy the Kafka server/cluster (although a single instance would be enough) and run it for 6 months : &lt;/p&gt;\n\n&lt;p&gt;- Confluent Cloud (they have a free option, but you still pay for the infrastructure which is more than what&amp;#39;s required for this simple use case).&lt;/p&gt;\n\n&lt;p&gt;- A single EC2 instance running Kafka&lt;/p&gt;\n\n&lt;p&gt;- A Kafka docker container in AWS ECS. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1739kqr", "is_robot_indexable": true, "report_reasons": null, "author": "lancelot_of_camelot", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1739kqr/best_affordable_way_to_deploy_host_a_kafka_setup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1739kqr/best_affordable_way_to_deploy_host_a_kafka_setup/", "subreddit_subscribers": 132838, "created_utc": 1696798220.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Sup guys,\n\nI was scrolling through some of your posts and found that well, half of the time I have no idea what you guys are talking about haha. Well, I work at a SaaS startup. My day consists on developing and troubleshooting data integrations into our product.\n\n For example, I might need to go to AWS Api Gateway, set up a new connection with the client, do the testing, receive the data, send it to one of our buckets (the backend is outside of my scope, I just use the Django front that the backend created and send the instruction to AWS batch), then I meet with the client again, parse the data to their liking (Python) and then set up the jobs and stuff. Then I might solve some tickets (hey this file didn't go through because the SFTP creds changed) and then build some webscrappers, DB extractions, API scripts, etc. My official title is Integrations Engineer, what are your thoughts?\n\nCheers!", "author_fullname": "t2_171ccp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Am I a data engineer?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173kzcg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696832931.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Sup guys,&lt;/p&gt;\n\n&lt;p&gt;I was scrolling through some of your posts and found that well, half of the time I have no idea what you guys are talking about haha. Well, I work at a SaaS startup. My day consists on developing and troubleshooting data integrations into our product.&lt;/p&gt;\n\n&lt;p&gt;For example, I might need to go to AWS Api Gateway, set up a new connection with the client, do the testing, receive the data, send it to one of our buckets (the backend is outside of my scope, I just use the Django front that the backend created and send the instruction to AWS batch), then I meet with the client again, parse the data to their liking (Python) and then set up the jobs and stuff. Then I might solve some tickets (hey this file didn&amp;#39;t go through because the SFTP creds changed) and then build some webscrappers, DB extractions, API scripts, etc. My official title is Integrations Engineer, what are your thoughts?&lt;/p&gt;\n\n&lt;p&gt;Cheers!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "173kzcg", "is_robot_indexable": true, "report_reasons": null, "author": "Mr_Nicotine", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173kzcg/am_i_a_data_engineer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/173kzcg/am_i_a_data_engineer/", "subreddit_subscribers": 132838, "created_utc": 1696832931.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all,\n\nI took a two year break to help my dad with his business. I was working at T-mobile as a data engineer dealing with traditional SQL framework (Cubes, ETL, Warehousing). \n\nNow I feel like the game has changed completely and my skill sets are obsolete. \n\nIf my aim to get a job at FAANG, can you guys point me to some reading materials/certification/technology stack I should upgrade my self with? \n\nI know my way around SQL, Python (scripting).", "author_fullname": "t2_532r23kf", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Prepping for Data Engineering interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173i7qa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696822714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I took a two year break to help my dad with his business. I was working at T-mobile as a data engineer dealing with traditional SQL framework (Cubes, ETL, Warehousing). &lt;/p&gt;\n\n&lt;p&gt;Now I feel like the game has changed completely and my skill sets are obsolete. &lt;/p&gt;\n\n&lt;p&gt;If my aim to get a job at FAANG, can you guys point me to some reading materials/certification/technology stack I should upgrade my self with? &lt;/p&gt;\n\n&lt;p&gt;I know my way around SQL, Python (scripting).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "173i7qa", "is_robot_indexable": true, "report_reasons": null, "author": "Dunklerverfaast", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173i7qa/prepping_for_data_engineering_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/173i7qa/prepping_for_data_engineering_interviews/", "subreddit_subscribers": 132838, "created_utc": 1696822714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have around 3 years of developing experience, I started as a ML engineer + computer vision softare engineering projects, and have worked as a DE for 1.4 years now. I work at a pretty big retail SaaS where our group is growing and I have more of an important role now as I'm involved in many services and solutions. \n\nI will soon be promoted from junior to mid-level Data Engineer.\n\nWhat kind of salary bump can I expect? My current salary is  around 42 000 Sek a month = 3650 euro per month", "author_fullname": "t2_128ob4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Promotion from junior to mid-level DE Sweden Salary Increase", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172wvef", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696764497.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have around 3 years of developing experience, I started as a ML engineer + computer vision softare engineering projects, and have worked as a DE for 1.4 years now. I work at a pretty big retail SaaS where our group is growing and I have more of an important role now as I&amp;#39;m involved in many services and solutions. &lt;/p&gt;\n\n&lt;p&gt;I will soon be promoted from junior to mid-level Data Engineer.&lt;/p&gt;\n\n&lt;p&gt;What kind of salary bump can I expect? My current salary is  around 42 000 Sek a month = 3650 euro per month&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "172wvef", "is_robot_indexable": true, "report_reasons": null, "author": "darvidas", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/172wvef/promotion_from_junior_to_midlevel_de_sweden/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/172wvef/promotion_from_junior_to_midlevel_de_sweden/", "subreddit_subscribers": 132838, "created_utc": 1696764497.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey everyone,\n\nI've been working as an MLE for some time now and realized that there's a lack of a scalable framework that can create API endpoints with dynamic queries. And found that a lot of existing solutions just didn't hit the sweet spot in terms of flexibility and ease of use.\n\nSo... I ended up creating one from scratch! It's called **Squirrels**. I've integrated some neat features like dynamic SQL &amp; Python query generation with Jinja templating, cascading parameters, and in-memory caching.\n\nTogether with my college, we recently published it on PyPI with a corresponding documentation page, and we're aiming to make it into a full-fledged solution so would genuinely love to have some of you try it out. Please let us know if you have any feedback, good or bad. I'm curious to see how it might fit into some of your workflows or where we can improve.\n\n&amp;#x200B;\n\nHere's the link to the GitHub page:\n\n[squirrels-nest/squirrels (github.com)](https://github.com/squirrels-nest/squirrels)\n\nAnd the documentation page:\n\n[Squirrels Documentation (squirrels-nest.github.io)](https://squirrels-nest.github.io/squirrels-docs/)\n\nWe even made a YouTube channel to house some tutorials if y'all are interested:   \n [Squirrels - YouTube](https://www.youtube.com/@Squirrels-hk7rj/featured) \n\n&amp;#x200B;\n\nThanks in advance for giving it a whirl! \ud83c\udf7b\ud83d\udc3f\ufe0f\n\n&amp;#x200B;\n\n(Disclaimer for rule no.8: we're not an entity of any sort, as Squirrels is only a side project that we're working on)", "author_fullname": "t2_kjvfum79o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Made a Python package for creating API endpoints with dynamic queries.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173k91u", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696830117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey everyone,&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been working as an MLE for some time now and realized that there&amp;#39;s a lack of a scalable framework that can create API endpoints with dynamic queries. And found that a lot of existing solutions just didn&amp;#39;t hit the sweet spot in terms of flexibility and ease of use.&lt;/p&gt;\n\n&lt;p&gt;So... I ended up creating one from scratch! It&amp;#39;s called &lt;strong&gt;Squirrels&lt;/strong&gt;. I&amp;#39;ve integrated some neat features like dynamic SQL &amp;amp; Python query generation with Jinja templating, cascading parameters, and in-memory caching.&lt;/p&gt;\n\n&lt;p&gt;Together with my college, we recently published it on PyPI with a corresponding documentation page, and we&amp;#39;re aiming to make it into a full-fledged solution so would genuinely love to have some of you try it out. Please let us know if you have any feedback, good or bad. I&amp;#39;m curious to see how it might fit into some of your workflows or where we can improve.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s the link to the GitHub page:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/squirrels-nest/squirrels\"&gt;squirrels-nest/squirrels (github.com)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And the documentation page:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://squirrels-nest.github.io/squirrels-docs/\"&gt;Squirrels Documentation (squirrels-nest.github.io)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;We even made a YouTube channel to house some tutorials if y&amp;#39;all are interested:&lt;br/&gt;\n &lt;a href=\"https://www.youtube.com/@Squirrels-hk7rj/featured\"&gt;Squirrels - YouTube&lt;/a&gt; &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for giving it a whirl! \ud83c\udf7b\ud83d\udc3f\ufe0f&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;(Disclaimer for rule no.8: we&amp;#39;re not an entity of any sort, as Squirrels is only a side project that we&amp;#39;re working on)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "173k91u", "is_robot_indexable": true, "report_reasons": null, "author": "squirrels-api", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173k91u/made_a_python_package_for_creating_api_endpoints/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/173k91u/made_a_python_package_for_creating_api_endpoints/", "subreddit_subscribers": 132838, "created_utc": 1696830117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Created an account a month or so ago. I get passed the login/creds page and land into an infinite loop of url calls at \n\nhttps://cloud.getdbt.com/api/auth/auth-login/?next=\n\nTheir outage page shows all-clear. Tried multiple browsers/devices/networks.\n\nBummed. I had an afternoon to start learning and looks like they might be ?down?", "author_fullname": "t2_f1kbimm96", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "anyone having trouble logging into DBT cloud?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173dcpc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696808025.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Created an account a month or so ago. I get passed the login/creds page and land into an infinite loop of url calls at &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://cloud.getdbt.com/api/auth/auth-login/?next=\"&gt;https://cloud.getdbt.com/api/auth/auth-login/?next=&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Their outage page shows all-clear. Tried multiple browsers/devices/networks.&lt;/p&gt;\n\n&lt;p&gt;Bummed. I had an afternoon to start learning and looks like they might be ?down?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "173dcpc", "is_robot_indexable": true, "report_reasons": null, "author": "No-Database2068", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173dcpc/anyone_having_trouble_logging_into_dbt_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/173dcpc/anyone_having_trouble_logging_into_dbt_cloud/", "subreddit_subscribers": 132838, "created_utc": 1696808025.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey I would love to hear suggestions from your experience. \n\nWe are redesigning out architecture, and we need a messaging technology to distribute tasks to our microservices. \n\nOur use case is:\n\n\\- Low throughput. we're talking around a few hundreds tasks to distribute every few minutes or so.\n\n\\- Reliability. I want to have exactly once delivery or the closest thing to it.\n\n\\- We have A few hundred microservices that read and execute the tasks. A task can take from a few seconds to several minutes to execute. We want the task to persist in the message broker in the time span of the execution.\n\n\\- Maximum availability. What I mean by this is simply when a task is being produced, it would be pushed to an idle consuming microservice ASAP. (not the case with Kafka consumer groups)\n\n\\- Feasible to deploy in Kubernetes.\n\n\\- Order matters. Conceptually we want a Queue(FIFO).\n\nI have looked into Apache Kafka, NATS, RabbitMQ and Apache RocketMQ.\n\nSeems like the best options are Rabbit and Rocket.\n\nWhat can you recommend for me?\n\nThanks ahead :)", "author_fullname": "t2_gik0k1m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need a messaging technology to maximize reliability and availability on low throughput - help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1731ynq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696778904.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey I would love to hear suggestions from your experience. &lt;/p&gt;\n\n&lt;p&gt;We are redesigning out architecture, and we need a messaging technology to distribute tasks to our microservices. &lt;/p&gt;\n\n&lt;p&gt;Our use case is:&lt;/p&gt;\n\n&lt;p&gt;- Low throughput. we&amp;#39;re talking around a few hundreds tasks to distribute every few minutes or so.&lt;/p&gt;\n\n&lt;p&gt;- Reliability. I want to have exactly once delivery or the closest thing to it.&lt;/p&gt;\n\n&lt;p&gt;- We have A few hundred microservices that read and execute the tasks. A task can take from a few seconds to several minutes to execute. We want the task to persist in the message broker in the time span of the execution.&lt;/p&gt;\n\n&lt;p&gt;- Maximum availability. What I mean by this is simply when a task is being produced, it would be pushed to an idle consuming microservice ASAP. (not the case with Kafka consumer groups)&lt;/p&gt;\n\n&lt;p&gt;- Feasible to deploy in Kubernetes.&lt;/p&gt;\n\n&lt;p&gt;- Order matters. Conceptually we want a Queue(FIFO).&lt;/p&gt;\n\n&lt;p&gt;I have looked into Apache Kafka, NATS, RabbitMQ and Apache RocketMQ.&lt;/p&gt;\n\n&lt;p&gt;Seems like the best options are Rabbit and Rocket.&lt;/p&gt;\n\n&lt;p&gt;What can you recommend for me?&lt;/p&gt;\n\n&lt;p&gt;Thanks ahead :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1731ynq", "is_robot_indexable": true, "report_reasons": null, "author": "eitanski", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1731ynq/need_a_messaging_technology_to_maximize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1731ynq/need_a_messaging_technology_to_maximize/", "subreddit_subscribers": 132838, "created_utc": 1696778904.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\nI would like to ask for career advice.\nI have been working as a Power Bi programmer in a large international consulting firm for the past year.\nMy goal for the future is to work in the Business Intelligence area on the backend / data engineer side.\n\nHowever, I recently received a job offer from a bank for a Business Analyst/Reporting Specialist position. In this role, I would be responsible for creating and enhancing reports using Power BI, delving into Oracle, MSSQL and Hadoop. The offer also includes the opportunity to learn Python for data processing and visualization (but this was an add-on option in the offer, so they probably don't use it much). The only downside is that the bank doesn't work with cloud solutions, and I'm not sure how much of my work will be related to data processing, and how much will be related to visualization and working with Power Bi and (probably sometimes) Excel reports.\n\nOn the other hand, my current company has made a counter-proposal, suggesting that I stay and learn new skills. They are proposing that I become a Big Query programmer at GCP (probably 50/50 with my role as a powerbi programmer, which is good because I don't want to give up that part of my job), and are willing to provide the necessary training.\n\nThe salaries for both positions are the same, as the company will also give me a raise.\n\nHere's my question. Which role is most suitable for a future BI backend dev / data engineer role? I want to learn how to work with advanced sql and etl processes, and in my company everything revolves around the cloud, so in my mind moving to the cloud is the only option, but maybe that's not true and starting with an on prem solution will be better. What do you think about this?\n\nThanks for all the advice!", "author_fullname": "t2_7jc8db23", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Job advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172vr9e", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696781863.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696760406.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,\nI would like to ask for career advice.\nI have been working as a Power Bi programmer in a large international consulting firm for the past year.\nMy goal for the future is to work in the Business Intelligence area on the backend / data engineer side.&lt;/p&gt;\n\n&lt;p&gt;However, I recently received a job offer from a bank for a Business Analyst/Reporting Specialist position. In this role, I would be responsible for creating and enhancing reports using Power BI, delving into Oracle, MSSQL and Hadoop. The offer also includes the opportunity to learn Python for data processing and visualization (but this was an add-on option in the offer, so they probably don&amp;#39;t use it much). The only downside is that the bank doesn&amp;#39;t work with cloud solutions, and I&amp;#39;m not sure how much of my work will be related to data processing, and how much will be related to visualization and working with Power Bi and (probably sometimes) Excel reports.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, my current company has made a counter-proposal, suggesting that I stay and learn new skills. They are proposing that I become a Big Query programmer at GCP (probably 50/50 with my role as a powerbi programmer, which is good because I don&amp;#39;t want to give up that part of my job), and are willing to provide the necessary training.&lt;/p&gt;\n\n&lt;p&gt;The salaries for both positions are the same, as the company will also give me a raise.&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s my question. Which role is most suitable for a future BI backend dev / data engineer role? I want to learn how to work with advanced sql and etl processes, and in my company everything revolves around the cloud, so in my mind moving to the cloud is the only option, but maybe that&amp;#39;s not true and starting with an on prem solution will be better. What do you think about this?&lt;/p&gt;\n\n&lt;p&gt;Thanks for all the advice!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "172vr9e", "is_robot_indexable": true, "report_reasons": null, "author": "eqwlknam", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/172vr9e/job_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/172vr9e/job_advice/", "subreddit_subscribers": 132838, "created_utc": 1696760406.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a multi-database project, which among other databases, supports both Postgres AND TimescaleDB. For the time being, the queries for timescaledb and postgres are exactly identical. \n\nSo I wonder - when using timescaledb, in contrast with postgres, are there some query optimisations that I could already do to improve performance, or gain some efficiency of some of the \"read\" queries?\n\nDisclaimer before I go further - this is the first time I'm attempting to use TimescaleDB, so this is definitely a skill gap on my end. \n\nConsider this following table structure:\n\n[https://github.com/dotmethodme/storywise/blob/main/api/src/migrations/timescale/001\\_basic\\_schema.ts](https://github.com/dotmethodme/storywise/blob/main/api/src/migrations/timescale/001_basic_schema.ts) (essentially a table containing pageview events for a website)\n\nCan you recommend any query optimisations specific to TimescaleDB that could help with queries such as this for example:\n\n[https://github.com/dotmethodme/storywise/blob/main/api/src/repository/postgres.ts#L71](https://github.com/dotmethodme/storywise/blob/main/api/src/repository/postgres.ts#L71)\n\nThe same question could apply for some of the other read queries in the same file too.\n\nMore generally - do you have pointers for someone trying to \"translate\" from vanilla postgres to timescaledb?", "author_fullname": "t2_tup5ajb4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Migrate from postgres to timescaledb and optimize queries", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1739v1o", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696798956.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a multi-database project, which among other databases, supports both Postgres AND TimescaleDB. For the time being, the queries for timescaledb and postgres are exactly identical. &lt;/p&gt;\n\n&lt;p&gt;So I wonder - when using timescaledb, in contrast with postgres, are there some query optimisations that I could already do to improve performance, or gain some efficiency of some of the &amp;quot;read&amp;quot; queries?&lt;/p&gt;\n\n&lt;p&gt;Disclaimer before I go further - this is the first time I&amp;#39;m attempting to use TimescaleDB, so this is definitely a skill gap on my end. &lt;/p&gt;\n\n&lt;p&gt;Consider this following table structure:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/dotmethodme/storywise/blob/main/api/src/migrations/timescale/001_basic_schema.ts\"&gt;https://github.com/dotmethodme/storywise/blob/main/api/src/migrations/timescale/001_basic_schema.ts&lt;/a&gt; (essentially a table containing pageview events for a website)&lt;/p&gt;\n\n&lt;p&gt;Can you recommend any query optimisations specific to TimescaleDB that could help with queries such as this for example:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/dotmethodme/storywise/blob/main/api/src/repository/postgres.ts#L71\"&gt;https://github.com/dotmethodme/storywise/blob/main/api/src/repository/postgres.ts#L71&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The same question could apply for some of the other read queries in the same file too.&lt;/p&gt;\n\n&lt;p&gt;More generally - do you have pointers for someone trying to &amp;quot;translate&amp;quot; from vanilla postgres to timescaledb?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Hz7jfFbQVTpFB0UVG8ao-YzaeUK9BBOKfEibweBkpMw.jpg?auto=webp&amp;s=32330b47ef85935bb7741eab49d9bc253dc582a9", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/Hz7jfFbQVTpFB0UVG8ao-YzaeUK9BBOKfEibweBkpMw.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=1933c3c7eb6fc14679199ac7f44cba030fbc5f34", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/Hz7jfFbQVTpFB0UVG8ao-YzaeUK9BBOKfEibweBkpMw.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=55b20698677b6210d94a4afcf1b97498baa3abef", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/Hz7jfFbQVTpFB0UVG8ao-YzaeUK9BBOKfEibweBkpMw.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=0e5d0c23d501722a27b25e91228494d1a2211934", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/Hz7jfFbQVTpFB0UVG8ao-YzaeUK9BBOKfEibweBkpMw.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=13d1d5ba52be7df4785e508a54b10295c8dd0a9a", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/Hz7jfFbQVTpFB0UVG8ao-YzaeUK9BBOKfEibweBkpMw.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=4ba2c2e1fc88998100df0af08c92f4ffd1f0f05c", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/Hz7jfFbQVTpFB0UVG8ao-YzaeUK9BBOKfEibweBkpMw.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=02e6ec8ae5ef84572b83a9889e9f482be8302c7c", "width": 1080, "height": 540}], "variants": {}, "id": "taBimoUKzm8zcgt4RSSA4pCZWsln9ySPLztN1LqtGcs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1739v1o", "is_robot_indexable": true, "report_reasons": null, "author": "dotmethod_me", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1739v1o/migrate_from_postgres_to_timescaledb_and_optimize/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1739v1o/migrate_from_postgres_to_timescaledb_and_optimize/", "subreddit_subscribers": 132838, "created_utc": 1696798956.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Working towards a job in Data Analysis, my pathway is DA-DE, please rate my github projects so i know how close/far i am from a junior da job, (i have a non cs degree and masters)\n\ngithub:[https://github.com/khorne182](https://github.com/khorne182)\n\nthank you", "author_fullname": "t2_5466c8m7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Please Rate My Portfolio Projects (Data Analysis)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1733cnc", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696782472.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Working towards a job in Data Analysis, my pathway is DA-DE, please rate my github projects so i know how close/far i am from a junior da job, (i have a non cs degree and masters)&lt;/p&gt;\n\n&lt;p&gt;github:&lt;a href=\"https://github.com/khorne182\"&gt;https://github.com/khorne182&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/_JP0h6CZLbbqD-yhTXY8XLDC70mXB8LGs6ZdD9gfe3Y.jpg?auto=webp&amp;s=2db572d484141700b80685f5fa7fc80a53b860b1", "width": 420, "height": 420}, "resolutions": [{"url": "https://external-preview.redd.it/_JP0h6CZLbbqD-yhTXY8XLDC70mXB8LGs6ZdD9gfe3Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=12f0da57b0bd50320cd50c11efb43ede4d148ab1", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/_JP0h6CZLbbqD-yhTXY8XLDC70mXB8LGs6ZdD9gfe3Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=955d74aa2e811c9d5f46c08d145e185b27f4b7c2", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/_JP0h6CZLbbqD-yhTXY8XLDC70mXB8LGs6ZdD9gfe3Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b2431a5014ced6ea10078408be4753fc636cefb2", "width": 320, "height": 320}], "variants": {}, "id": "Zdv2L8vDMZBOia6vZR3chtNVQhUeXESnOzRdlMFY3Ig"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1733cnc", "is_robot_indexable": true, "report_reasons": null, "author": "EmotionalResolve9", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1733cnc/please_rate_my_portfolio_projects_data_analysis/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1733cnc/please_rate_my_portfolio_projects_data_analysis/", "subreddit_subscribers": 132838, "created_utc": 1696782472.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I once worked in a medium sized company where there's no data or BI platform to store sql related things. And there's only 2 data+BI people so we work pretty freestyle. I processed about 10-20 queries each day and ended up copy-pasting everything from my sql client to notion ( to store some context about the task and sometimes the screenshot of the visualization)\n\nBut once the modifications of the same requirement comes back I needed to copy paste things back from the notepad into the sql client. Not to mention I need to make visualizations and share them using Google sheet.\n\nIt still kinda bugs me today. I wonder how do you guys manage those workflows when you don't have a good infra?", "author_fullname": "t2_cr04g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "where do you store your sql queries?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173nrq2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696847732.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696844494.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I once worked in a medium sized company where there&amp;#39;s no data or BI platform to store sql related things. And there&amp;#39;s only 2 data+BI people so we work pretty freestyle. I processed about 10-20 queries each day and ended up copy-pasting everything from my sql client to notion ( to store some context about the task and sometimes the screenshot of the visualization)&lt;/p&gt;\n\n&lt;p&gt;But once the modifications of the same requirement comes back I needed to copy paste things back from the notepad into the sql client. Not to mention I need to make visualizations and share them using Google sheet.&lt;/p&gt;\n\n&lt;p&gt;It still kinda bugs me today. I wonder how do you guys manage those workflows when you don&amp;#39;t have a good infra?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "173nrq2", "is_robot_indexable": true, "report_reasons": null, "author": "jchnxu", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173nrq2/where_do_you_store_your_sql_queries/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/173nrq2/where_do_you_store_your_sql_queries/", "subreddit_subscribers": 132838, "created_utc": 1696844494.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi all, my co-worker has written an article about alerting in our platform (GoodData). As you might suspect, the article promotes our product, but on the other hand, I think it can provide you with some new perspectives on how to deal with alerts in data/BI tools.\n\nPlease check it out and let us know if you find it valuable! We are eager to discuss it.  \n\n\n[https://medium.com/gooddata-developers/alerts-are-dead-long-live-data-driven-actions-486998b58dca](https://medium.com/gooddata-developers/alerts-are-dead-long-live-data-driven-actions-486998b58dca)", "author_fullname": "t2_kyoi486i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "\u270d\ufe0f Article: Alerts Are Dead", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173nqqz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696844394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, my co-worker has written an article about alerting in our platform (GoodData). As you might suspect, the article promotes our product, but on the other hand, I think it can provide you with some new perspectives on how to deal with alerts in data/BI tools.&lt;/p&gt;\n\n&lt;p&gt;Please check it out and let us know if you find it valuable! We are eager to discuss it.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://medium.com/gooddata-developers/alerts-are-dead-long-live-data-driven-actions-486998b58dca\"&gt;https://medium.com/gooddata-developers/alerts-are-dead-long-live-data-driven-actions-486998b58dca&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/C_nlrFinIxZmtc33ifX-0JpeH0s3E2g5N0786MRP7IA.jpg?auto=webp&amp;s=9dad9baf3c1012766177702d394293ae8dd13622", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/C_nlrFinIxZmtc33ifX-0JpeH0s3E2g5N0786MRP7IA.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e053ab0c60a7e30ba581a27e9c42035aee5b4643", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/C_nlrFinIxZmtc33ifX-0JpeH0s3E2g5N0786MRP7IA.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a84b6f48123ec2298872e4a3d7f58ded64815fde", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/C_nlrFinIxZmtc33ifX-0JpeH0s3E2g5N0786MRP7IA.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=ef7aa2cbc6bf0216e1afd7d5ac616d208a2a9e56", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/C_nlrFinIxZmtc33ifX-0JpeH0s3E2g5N0786MRP7IA.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a45b9b0856995d9edeb136424aa130035d5436a6", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/C_nlrFinIxZmtc33ifX-0JpeH0s3E2g5N0786MRP7IA.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=6aa73517955d527d03a97c03d342abaa1bcbde05", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/C_nlrFinIxZmtc33ifX-0JpeH0s3E2g5N0786MRP7IA.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=87ad79b7690b4e1626609421852ab6eb18d9d7be", "width": 1080, "height": 567}], "variants": {}, "id": "vsg3D5DApgZiwi1CyIlPbeQyyWP73HkihJneJ7hmGnI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "173nqqz", "is_robot_indexable": true, "report_reasons": null, "author": "AmphibianInfamous574", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173nqqz/article_alerts_are_dead/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/173nqqz/article_alerts_are_dead/", "subreddit_subscribers": 132838, "created_utc": 1696844394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am planning to re-factor/re-design the management of database connections of some part of old business logic code.\n\nTo date, the code works as follows: there are multiple databases (e.g. db1, db2, ... dbN) and each has multiple \"tasks\" (i.e. generic business logic work) that reads from the associated database, (e.g. t11, t12, ... , t1N, ..., tM1, tM2, ..., tMN). The queries are written directly in SQL dialect, i.e. no \"ORM\" framework. We are mantaining both posgresql and mssql to date, duplicating the queries when needed. We plan to be non-agnognic and pick only one dialect, I think posgressql being free.\n\nThe logic open all the database connections at the start, then iterate over the tasks and exploits the open connections. If between tasks a timeout is reached, the connection is checked again and re-opened. Sometimes the connections are not closed properly and the connections are managed at low level directly with the available python drivers.\n\nAfter some thinking, I came with the following steps for the re-design:\n\n1. Order the (database, task) pairs in order to group by database and run the associated tasks in order, i.e. sequentially.\n2. Open and closing the database connection inside the \"group by for loop\" so that the logic to manage the connection is somehow limited to the loop iteration, this should help the transition and re-design by having more control.\n3. Switch from using the low-level driver to a production-ready library already optimized for the maganement of pools of connections in a threaded/async way. I was thinking about SQL Alchemy for this task.\n4. Re-designing the writing queries to be indipedent of each other. To date, some queries need to know the ID generated by a previous query, so they are runned in a non-atomic way (i.e. with autocommit set to true). I would like to set autocommit to false and commit only at the end of each task so to avoid corruping the database in the case if the task is stopped while running (to date we do not have control of this and sometimes  we find corruped data). How can I solve this problem?\n\nI would like to have your ideas on this refactoring process, if you need to ask me more questions or have more information, feel free to ask me: I wish to brainstorm here and collect some experience from senior data engineers as I am learning the role and I would like to re-design this in a robust way.\n\n&amp;#x200B;", "author_fullname": "t2_vlk568vv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Refactoring database connection management with SQL Alchemy", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173nluq", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696843819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am planning to re-factor/re-design the management of database connections of some part of old business logic code.&lt;/p&gt;\n\n&lt;p&gt;To date, the code works as follows: there are multiple databases (e.g. db1, db2, ... dbN) and each has multiple &amp;quot;tasks&amp;quot; (i.e. generic business logic work) that reads from the associated database, (e.g. t11, t12, ... , t1N, ..., tM1, tM2, ..., tMN). The queries are written directly in SQL dialect, i.e. no &amp;quot;ORM&amp;quot; framework. We are mantaining both posgresql and mssql to date, duplicating the queries when needed. We plan to be non-agnognic and pick only one dialect, I think posgressql being free.&lt;/p&gt;\n\n&lt;p&gt;The logic open all the database connections at the start, then iterate over the tasks and exploits the open connections. If between tasks a timeout is reached, the connection is checked again and re-opened. Sometimes the connections are not closed properly and the connections are managed at low level directly with the available python drivers.&lt;/p&gt;\n\n&lt;p&gt;After some thinking, I came with the following steps for the re-design:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Order the (database, task) pairs in order to group by database and run the associated tasks in order, i.e. sequentially.&lt;/li&gt;\n&lt;li&gt;Open and closing the database connection inside the &amp;quot;group by for loop&amp;quot; so that the logic to manage the connection is somehow limited to the loop iteration, this should help the transition and re-design by having more control.&lt;/li&gt;\n&lt;li&gt;Switch from using the low-level driver to a production-ready library already optimized for the maganement of pools of connections in a threaded/async way. I was thinking about SQL Alchemy for this task.&lt;/li&gt;\n&lt;li&gt;Re-designing the writing queries to be indipedent of each other. To date, some queries need to know the ID generated by a previous query, so they are runned in a non-atomic way (i.e. with autocommit set to true). I would like to set autocommit to false and commit only at the end of each task so to avoid corruping the database in the case if the task is stopped while running (to date we do not have control of this and sometimes  we find corruped data). How can I solve this problem?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I would like to have your ideas on this refactoring process, if you need to ask me more questions or have more information, feel free to ask me: I wish to brainstorm here and collect some experience from senior data engineers as I am learning the role and I would like to re-design this in a robust way.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "173nluq", "is_robot_indexable": true, "report_reasons": null, "author": "Plenty-Button8465", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173nluq/refactoring_database_connection_management_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/173nluq/refactoring_database_connection_management_with/", "subreddit_subscribers": 132838, "created_utc": 1696843819.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Dear all. \n\n&amp;#x200B;\n\nHope you are OK.\n\n&amp;#x200B;\n\nI was told by my boss, that if I see a course I need, there is a budget for it. It has to be kind of short, and specific. What I am using at work is Redshift, DBT, Qlik, and QuickSight. I don\u00b4t have a clue abour kafka, lambda, or arquitecture. My background is a data science(analytics bootcamp, and I am a DE junior improving a lot and already understanding more and more our data and making visualizations transforming data via DBT.\n\n&amp;#x200B;\n\nAny good place to look for a paid course? Any specific course which you recommend?\n\n&amp;#x200B;\n\nMany thanks :)", "author_fullname": "t2_s92yqnfm", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice course to improve in my job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173k36c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696829484.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Dear all. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Hope you are OK.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I was told by my boss, that if I see a course I need, there is a budget for it. It has to be kind of short, and specific. What I am using at work is Redshift, DBT, Qlik, and QuickSight. I don\u00b4t have a clue abour kafka, lambda, or arquitecture. My background is a data science(analytics bootcamp, and I am a DE junior improving a lot and already understanding more and more our data and making visualizations transforming data via DBT.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any good place to look for a paid course? Any specific course which you recommend?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Many thanks :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "173k36c", "is_robot_indexable": true, "report_reasons": null, "author": "Illustrious_Savior", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173k36c/advice_course_to_improve_in_my_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/173k36c/advice_course_to_improve_in_my_job/", "subreddit_subscribers": 132838, "created_utc": 1696829484.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I have recently tried snowflake in my new company after using spark for several years.\n\nPersonally, I really like that it delivers what it promises, but I don't like lack of customization and the fact their support/sales have a know-it-all attitude and they ask you to trust everything works automagically.\n\nI am also concerned that in the long term this very strong lock-in in pair with a revamp of billing policies (think about dbt cloud) will cause many troubles to data teams. I already don't like the pricing of warehouses where you can only double the amount of spent credits to improve query performance...\n\nIs this a legitimate concern? With databricks you can always opt out and migrate your spark/delta codebase somewhere else. With snowflake I don't see this option.", "author_fullname": "t2_jni6yu7mo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are your thoughts on Snowflake?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173nkx2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696843711.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I have recently tried snowflake in my new company after using spark for several years.&lt;/p&gt;\n\n&lt;p&gt;Personally, I really like that it delivers what it promises, but I don&amp;#39;t like lack of customization and the fact their support/sales have a know-it-all attitude and they ask you to trust everything works automagically.&lt;/p&gt;\n\n&lt;p&gt;I am also concerned that in the long term this very strong lock-in in pair with a revamp of billing policies (think about dbt cloud) will cause many troubles to data teams. I already don&amp;#39;t like the pricing of warehouses where you can only double the amount of spent credits to improve query performance...&lt;/p&gt;\n\n&lt;p&gt;Is this a legitimate concern? With databricks you can always opt out and migrate your spark/delta codebase somewhere else. With snowflake I don&amp;#39;t see this option.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "173nkx2", "is_robot_indexable": true, "report_reasons": null, "author": "Ok-Data-810", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/173nkx2/what_are_your_thoughts_on_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/173nkx2/what_are_your_thoughts_on_snowflake/", "subreddit_subscribers": 132838, "created_utc": 1696843711.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey guys,\n\nI wanna upgrade to an Western Digital SN850X 1TB and I wonder if 1TB is enough or should I go for 2TB?  \nI wonder if big SSD's are needed these days since everything is cloud now?  \n", "author_fullname": "t2_b7p5seze", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1TB enough space for Data Engineering/Machine Learning?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17318vx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.38, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696777217.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys,&lt;/p&gt;\n\n&lt;p&gt;I wanna upgrade to an Western Digital SN850X 1TB and I wonder if 1TB is enough or should I go for 2TB?&lt;br/&gt;\nI wonder if big SSD&amp;#39;s are needed these days since everything is cloud now?  &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17318vx", "is_robot_indexable": true, "report_reasons": null, "author": "DentistSecure6543", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17318vx/1tb_enough_space_for_data_engineeringmachine/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17318vx/1tb_enough_space_for_data_engineeringmachine/", "subreddit_subscribers": 132838, "created_utc": 1696777217.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}