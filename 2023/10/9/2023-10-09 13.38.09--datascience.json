{"kind": "Listing", "data": {"after": null, "dist": 23, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "As a data science manager how do you manage your team? Specifically how do you manage your DSs career growth and promotion opportunities? Imagine you have a team of 5 DSs: 2 DS1, 2 DS2, and 1 DS3, where DSX is a Data Scientist 1-4. What is your measure of success - promotions, completed projects, revenue contribution,etc? How do DSX become DSX+1?\n\nSome of my thoughts:\n\n1. As a manager, I can support my DSs by **NOT** micromanaging.  I will track your project and encourage model reviews, code reviews and present final outputs to the team. All necessary skills of a DS.\n\n2. I can ensure my DSs have the skills to mange a project. A DS1 would see many touch points with the manager(me) or a DS3-4 on projects to ensure success, a DS2 less, and DS3 probably none. This in fact is my basis for promotion - shows level of competency on managing projects and deliverables. \n\n3. There can also be project based performance promotion, that is, DS possibly lacking project managing skills but tackles difficult projects and delivers top notch work consistently. \n\n4. The bigger issue is about personal development(PD).  How do managers balance PD against available projects? The DSs may want to gain experience in applying AI or unstructured learning , GPGPU models, specific toolsets like Vertex AI, NLP etc. Your team\u2019s project assignments  may not see this diverse a set of projects. When a project becomes available I balance availability against skill set in order to complete the projects based on delivery times and quarterly goals because these are the measures of success for my team. Typically I fill the void with targeted training courses and allocate time to PD. \n\n5. Some managers think PD is solely the DS\u2019s responsibility. Thoughts?\n\n6. How do you deal with HR when there are no clear DS role descriptions?\n\nNot a simple optimization problem!", "author_fullname": "t2_7ilx2oko", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do data scientist managers manage data scientists?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_172zdgx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.94, "author_flair_background_color": null, "subreddit_type": "public", "ups": 106, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 106, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696772308.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;As a data science manager how do you manage your team? Specifically how do you manage your DSs career growth and promotion opportunities? Imagine you have a team of 5 DSs: 2 DS1, 2 DS2, and 1 DS3, where DSX is a Data Scientist 1-4. What is your measure of success - promotions, completed projects, revenue contribution,etc? How do DSX become DSX+1?&lt;/p&gt;\n\n&lt;p&gt;Some of my thoughts:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;As a manager, I can support my DSs by &lt;strong&gt;NOT&lt;/strong&gt; micromanaging.  I will track your project and encourage model reviews, code reviews and present final outputs to the team. All necessary skills of a DS.&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;I can ensure my DSs have the skills to mange a project. A DS1 would see many touch points with the manager(me) or a DS3-4 on projects to ensure success, a DS2 less, and DS3 probably none. This in fact is my basis for promotion - shows level of competency on managing projects and deliverables. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;There can also be project based performance promotion, that is, DS possibly lacking project managing skills but tackles difficult projects and delivers top notch work consistently. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The bigger issue is about personal development(PD).  How do managers balance PD against available projects? The DSs may want to gain experience in applying AI or unstructured learning , GPGPU models, specific toolsets like Vertex AI, NLP etc. Your team\u2019s project assignments  may not see this diverse a set of projects. When a project becomes available I balance availability against skill set in order to complete the projects based on delivery times and quarterly goals because these are the measures of success for my team. Typically I fill the void with targeted training courses and allocate time to PD. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Some managers think PD is solely the DS\u2019s responsibility. Thoughts?&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;How do you deal with HR when there are no clear DS role descriptions?&lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Not a simple optimization problem!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "172zdgx", "is_robot_indexable": true, "report_reasons": null, "author": "cazzobomba", "discussion_type": null, "num_comments": 53, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/172zdgx/how_do_data_scientist_managers_manage_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/172zdgx/how_do_data_scientist_managers_manage_data/", "subreddit_subscribers": 1077836, "created_utc": 1696772308.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm an SWE (**not a data scientist**) and trying to build a generic data validation tool (or find appropriate tools to adopt) for my company.\n\nI started looking into libraries such as Great Expectations, Pydantic, etc.. And they all seem promising, but I don't think they solve the issue of validating *changes in data* (as far as I can tell). They seem to be good at validating that data is within an expected range, of an expected type, etc., but I need a little more.\n\nWhat I'm looking for is a tool that validates changes in data by comparing the previous value with the new value.\n\nIn some of our applications, new data is first pumped into a staging table. We then calculate relative change % between the staging and target table (for each field), and if the change is higher than some threshold, validation fails. But there's obviously a lot of issues with this (like in cases where a change from 1 to 18 is normal but produces a percent change of 1700).\n\nThis is just an example, but it would be helpful if we can call an API to do this sort of validation for us.\n\nAnd instead of using absolute change, relative change, etc... is there perhaps a tool that can validate based on historical changes? Perhaps by capturing changes for some set time and using that information to validate future changes? I'm just brainstorming here.\n\nWould highly appreciate some recommendations/tips for tackling this problem. Thank you!", "author_fullname": "t2_mxg44sgb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to validate data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173broc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 41, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 41, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696808736.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696803736.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m an SWE (&lt;strong&gt;not a data scientist&lt;/strong&gt;) and trying to build a generic data validation tool (or find appropriate tools to adopt) for my company.&lt;/p&gt;\n\n&lt;p&gt;I started looking into libraries such as Great Expectations, Pydantic, etc.. And they all seem promising, but I don&amp;#39;t think they solve the issue of validating &lt;em&gt;changes in data&lt;/em&gt; (as far as I can tell). They seem to be good at validating that data is within an expected range, of an expected type, etc., but I need a little more.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m looking for is a tool that validates changes in data by comparing the previous value with the new value.&lt;/p&gt;\n\n&lt;p&gt;In some of our applications, new data is first pumped into a staging table. We then calculate relative change % between the staging and target table (for each field), and if the change is higher than some threshold, validation fails. But there&amp;#39;s obviously a lot of issues with this (like in cases where a change from 1 to 18 is normal but produces a percent change of 1700).&lt;/p&gt;\n\n&lt;p&gt;This is just an example, but it would be helpful if we can call an API to do this sort of validation for us.&lt;/p&gt;\n\n&lt;p&gt;And instead of using absolute change, relative change, etc... is there perhaps a tool that can validate based on historical changes? Perhaps by capturing changes for some set time and using that information to validate future changes? I&amp;#39;m just brainstorming here.&lt;/p&gt;\n\n&lt;p&gt;Would highly appreciate some recommendations/tips for tackling this problem. Thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173broc", "is_robot_indexable": true, "report_reasons": null, "author": "Sensitive-Main-6700", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173broc/how_to_validate_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173broc/how_to_validate_data/", "subreddit_subscribers": 1077836, "created_utc": 1696803736.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "(Previous post was removed for unclear reason)\n\nI'm curious to hear about the impactful data science projects you've had the opportunity to work on in the corporate world. Whether it's in healthcare, finance, e-commerce, or any other industry, I'd love to know about the projects that made a significant difference.\n\nI understand it may not be possible to go into details, but please share your experiences:\n\n1. The industry or sector you were working in.\n2. A brief description of the project.\n3. The impact or results the project had on the company. \n\nJust to clarify, when I say \u201cvaluable\u201d I mean from the company\u2019s perspective.", "author_fullname": "t2_e2jh8y8b", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most valuable data science project you've worked on for a company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173l7aj", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696833786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;(Previous post was removed for unclear reason)&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m curious to hear about the impactful data science projects you&amp;#39;ve had the opportunity to work on in the corporate world. Whether it&amp;#39;s in healthcare, finance, e-commerce, or any other industry, I&amp;#39;d love to know about the projects that made a significant difference.&lt;/p&gt;\n\n&lt;p&gt;I understand it may not be possible to go into details, but please share your experiences:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;The industry or sector you were working in.&lt;/li&gt;\n&lt;li&gt;A brief description of the project.&lt;/li&gt;\n&lt;li&gt;The impact or results the project had on the company. &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Just to clarify, when I say \u201cvaluable\u201d I mean from the company\u2019s perspective.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173l7aj", "is_robot_indexable": true, "report_reasons": null, "author": "foreignparent", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173l7aj/most_valuable_data_science_project_youve_worked/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173l7aj/most_valuable_data_science_project_youve_worked/", "subreddit_subscribers": 1077836, "created_utc": 1696833786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Currently a medical student, but have been reading into clinical informatics. Literature seems to suggest that simple algorithms can out perform doctors in regards to differential diagnosing. Why hasn't there been more implementation to create decision support software to augment decision manage in regards to diagnosis and treatment?\n\nShit, like I'm playing around ChatGPT with a lot of my cases and its really good at differential diagnosis. Which would make me think that mapping a constellation of symptoms to specific diseases shouldn't be that hard for a machine to do right? I can't imagine how much better it could get within the black box of ML where local prevalence and what not of diseases could be taken into account ", "author_fullname": "t2_vkzi7izo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why aren't there more decision support algos for doctors for differential diagnosing?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173hj19", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696820501.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Currently a medical student, but have been reading into clinical informatics. Literature seems to suggest that simple algorithms can out perform doctors in regards to differential diagnosing. Why hasn&amp;#39;t there been more implementation to create decision support software to augment decision manage in regards to diagnosis and treatment?&lt;/p&gt;\n\n&lt;p&gt;Shit, like I&amp;#39;m playing around ChatGPT with a lot of my cases and its really good at differential diagnosis. Which would make me think that mapping a constellation of symptoms to specific diseases shouldn&amp;#39;t be that hard for a machine to do right? I can&amp;#39;t imagine how much better it could get within the black box of ML where local prevalence and what not of diseases could be taken into account &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173hj19", "is_robot_indexable": true, "report_reasons": null, "author": "derpgod123", "discussion_type": null, "num_comments": 33, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173hj19/why_arent_there_more_decision_support_algos_for/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173hj19/why_arent_there_more_decision_support_algos_for/", "subreddit_subscribers": 1077836, "created_utc": 1696820501.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Data Science community, I've got a question for you:\n\nWhich data science tools do you find most user-friendly?\n\nI just went live with a project I've been working on. I feel like the configuration process is easy but would love to compare it with some of your favorite data science tools. The project I'm working on is a simple cluster compute tool. All you do is add a single line of code to your python script and then you're able to run your code on thousands of separate VMs in the cloud. I built this tool so I could stop relying on DevOps for batch inference and hyperparameter tuning. At the moment we are managing the cluster but in the future I plan to allow users to deploy on their own private cloud. If you are interested I can give you 1k GPU hours for testing it :). I honestly wouldn't mind a few people ripping everything that sucks with the user experience.\n\nAnyways, I'd love to learn about everyone's favorite data science tools (specifically python ones). Ideally I can incorporate a config process that everyone is familiar with and zero friction.\n\nProject link: [https://www.burla.dev/](https://www.burla.dev/)", "author_fullname": "t2_7iyeps3c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What data science tools have the best user experience?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173hmq4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.77, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696822436.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696820819.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Data Science community, I&amp;#39;ve got a question for you:&lt;/p&gt;\n\n&lt;p&gt;Which data science tools do you find most user-friendly?&lt;/p&gt;\n\n&lt;p&gt;I just went live with a project I&amp;#39;ve been working on. I feel like the configuration process is easy but would love to compare it with some of your favorite data science tools. The project I&amp;#39;m working on is a simple cluster compute tool. All you do is add a single line of code to your python script and then you&amp;#39;re able to run your code on thousands of separate VMs in the cloud. I built this tool so I could stop relying on DevOps for batch inference and hyperparameter tuning. At the moment we are managing the cluster but in the future I plan to allow users to deploy on their own private cloud. If you are interested I can give you 1k GPU hours for testing it :). I honestly wouldn&amp;#39;t mind a few people ripping everything that sucks with the user experience.&lt;/p&gt;\n\n&lt;p&gt;Anyways, I&amp;#39;d love to learn about everyone&amp;#39;s favorite data science tools (specifically python ones). Ideally I can incorporate a config process that everyone is familiar with and zero friction.&lt;/p&gt;\n\n&lt;p&gt;Project link: &lt;a href=\"https://www.burla.dev/\"&gt;https://www.burla.dev/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?auto=webp&amp;s=dc8c6771b845e644cd666eb595201de88230f142", "width": 1709, "height": 1121}, "resolutions": [{"url": "https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=496107537c7f02d11ba32280e55d89e56a5848d8", "width": 108, "height": 70}, {"url": "https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5ea8dc399ca823ce42caad20fe9c4f25f2be15cd", "width": 216, "height": 141}, {"url": "https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a3b10d6ba51982b5f955f301a6d0e6b2db776f20", "width": 320, "height": 209}, {"url": "https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=e99df4cf576fa238ed3e8c93013053c3dfa877d4", "width": 640, "height": 419}, {"url": "https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1082634e72898dc2bea9d09182c55d9fd9fa9778", "width": 960, "height": 629}, {"url": "https://external-preview.redd.it/u4ClAZ8St8TzahW1K9x9EYxv7SBJVWxsrbP4poyqyMQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=9e2dd0e6cd4a758bad26ffe4422e54719d529be1", "width": 1080, "height": 708}], "variants": {}, "id": "87w8QKwoshM83mfexlzDzg8Xw1B52-C16nqklM-GBsc"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173hmq4", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Post_149", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173hmq4/what_data_science_tools_have_the_best_user/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173hmq4/what_data_science_tools_have_the_best_user/", "subreddit_subscribers": 1077836, "created_utc": 1696820819.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I'm starting out on a team that is very collaborative and I've realized that while I've worked with other people before, I'm not used to doing it the way they do, where a project could be divided up into lots of smaller parts and it might not be me on every one of those parts. \n\nDoes anyone have advice for dealing with what almost feels like getting territorial over a model? It's nothing against the people on my team - they've all been there for longer than me and are much smarter than me. I just am used to seeing things 100% of the way and I took a lot of pride in being able to look at a finished thing and be like \"I built that.\" It also almost feels like it's my fault for not being able to do all of the work myself, like if I was a better worker I'd be able to get more of the work done and people wouldn't have to pick up my slack.\n\nIs this something that just goes away with time if you continue working on a team that works in this way? I didn't expect there to be an emotional challenge component to this and I'm struggling to know what to do and how to adapt, especially because this doesn't feel like the kind of thing you can really share/get support from coworkers on, because they're the ones working on it with me if that makes sense.", "author_fullname": "t2_m3zm5vg6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What advice would you give someone starting out on learning to collaborate on large projects and not be the sole person responsible for a model build?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173dd6h", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696808065.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m starting out on a team that is very collaborative and I&amp;#39;ve realized that while I&amp;#39;ve worked with other people before, I&amp;#39;m not used to doing it the way they do, where a project could be divided up into lots of smaller parts and it might not be me on every one of those parts. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have advice for dealing with what almost feels like getting territorial over a model? It&amp;#39;s nothing against the people on my team - they&amp;#39;ve all been there for longer than me and are much smarter than me. I just am used to seeing things 100% of the way and I took a lot of pride in being able to look at a finished thing and be like &amp;quot;I built that.&amp;quot; It also almost feels like it&amp;#39;s my fault for not being able to do all of the work myself, like if I was a better worker I&amp;#39;d be able to get more of the work done and people wouldn&amp;#39;t have to pick up my slack.&lt;/p&gt;\n\n&lt;p&gt;Is this something that just goes away with time if you continue working on a team that works in this way? I didn&amp;#39;t expect there to be an emotional challenge component to this and I&amp;#39;m struggling to know what to do and how to adapt, especially because this doesn&amp;#39;t feel like the kind of thing you can really share/get support from coworkers on, because they&amp;#39;re the ones working on it with me if that makes sense.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173dd6h", "is_robot_indexable": true, "report_reasons": null, "author": "Champaign__Supernova", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173dd6h/what_advice_would_you_give_someone_starting_out/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173dd6h/what_advice_would_you_give_someone_starting_out/", "subreddit_subscribers": 1077836, "created_utc": 1696808065.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "A friend of mine asked me to see if there was a way to automatically add labels to customer complaints based on the text in the complaint. Presently, on a monthly basis they read every customer complaint and manually apply a label based on their judgement of what it is. There is a specific set of labels they use to classify their complaints.\n\nThis seems like a problem for NLP but I'm unsure of where to start or just not confident. It's been at least 7 years since I've done any real 'data science' stuff. The data is tidy, I can read it into a data frame. I know there are a number of tutorials online that discuss stemming, lemmatization, and other factors so I think I can get some of those basic steps down. But I would be happy if you had a specific guidebook that you've used that you like and could share.\n\nAm I oversimplifying this or overly confident? I should be able to build a model that tries to applies the same labels they previously applied manually but automatically with this program. Am I thinking about this correctly?\n\nI'm really not certain what the best tools in R to use for this are. Back when I did I used caret, keras, SnowballRC and some other things like dplyr. I'm not certain what models or validation approaches to use either. Are there any good guides that a simpleton like me could use to build a relatively confident validation stage?\n\nThanks for your thoughtfulness on this :)", "author_fullname": "t2_viztxm6i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is it possible to automate the labeling of strings of text?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173cl4s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 11, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 11, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696805952.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;A friend of mine asked me to see if there was a way to automatically add labels to customer complaints based on the text in the complaint. Presently, on a monthly basis they read every customer complaint and manually apply a label based on their judgement of what it is. There is a specific set of labels they use to classify their complaints.&lt;/p&gt;\n\n&lt;p&gt;This seems like a problem for NLP but I&amp;#39;m unsure of where to start or just not confident. It&amp;#39;s been at least 7 years since I&amp;#39;ve done any real &amp;#39;data science&amp;#39; stuff. The data is tidy, I can read it into a data frame. I know there are a number of tutorials online that discuss stemming, lemmatization, and other factors so I think I can get some of those basic steps down. But I would be happy if you had a specific guidebook that you&amp;#39;ve used that you like and could share.&lt;/p&gt;\n\n&lt;p&gt;Am I oversimplifying this or overly confident? I should be able to build a model that tries to applies the same labels they previously applied manually but automatically with this program. Am I thinking about this correctly?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m really not certain what the best tools in R to use for this are. Back when I did I used caret, keras, SnowballRC and some other things like dplyr. I&amp;#39;m not certain what models or validation approaches to use either. Are there any good guides that a simpleton like me could use to build a relatively confident validation stage?&lt;/p&gt;\n\n&lt;p&gt;Thanks for your thoughtfulness on this :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173cl4s", "is_robot_indexable": true, "report_reasons": null, "author": "rationally_speaking", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173cl4s/is_it_possible_to_automate_the_labeling_of/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173cl4s/is_it_possible_to_automate_the_labeling_of/", "subreddit_subscribers": 1077836, "created_utc": 1696805952.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_p59o0l5l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is currently the most in demand Analytics/DS by Healthcare institutions (hospitals, clinics, big pharma, government, etc.)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173cxz4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696806888.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173cxz4", "is_robot_indexable": true, "report_reasons": null, "author": "EcstaticStructure830", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173cxz4/what_is_currently_the_most_in_demand_analyticsds/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173cxz4/what_is_currently_the_most_in_demand_analyticsds/", "subreddit_subscribers": 1077836, "created_utc": 1696806888.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "\ud83d\ude80 Exciting News! Just released my latest YouTube video - \"PySpark Tutorial for Beginners: 1-Hour Full Course\" \ud83d\udc0d\ud83d\udca1\n\nAre you ready to dive into the world of PySpark and harness the power of distributed data processing with ease? In this comprehensive 1-hour tutorial, I'll guide you through the fundamentals of PySpark, from installation to hands-on coding examples.\n\n\ud83d\udd25 What You'll Learn:\n\u2705 Spark Introduction\n\u2705 Spark Installation\n\u2705 Setting Up Your PySpark Environment\n\u2705 Spark RDD\n\u2705 DataFrame Operations\n\u2705 Spark SQL\n\u2705 And much more!\n\nWhether you're a beginner looking to kickstart your journey into big data or an experienced data engineer aiming to refresh your skills, this video has something for you!\n\nWatch it now \ud83d\udc49 https://youtu.be/EB8lfdxpirM\nGitHub Repo \ud83d\udc49 https://github.com/coder2j/pyspark-tutorial\n\nDon't forget to like, subscribe, and share with your network. Let's spread the knowledge together! \ud83d\udcda\ud83d\udcaa\n\n#PySpark #DataScience #BigData #Tutorial #LinkedInLearning #YouTubeTutorial", "author_fullname": "t2_h4j43yry", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark Tutorial for Beginners: 1-Hour Full Course", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_173ldbg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "ups": 4, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/EB8lfdxpirM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"PySpark Tutorial for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "PySpark Tutorial for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/EB8lfdxpirM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"PySpark Tutorial for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "coder2j", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/EB8lfdxpirM/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@coder2j"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/EB8lfdxpirM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"PySpark Tutorial for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/173ldbg", "height": 200}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/nyeAsJ_Iyn208srWSK-sRJw_-S14SsgknHSuV_YPKCM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696834479.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;\ud83d\ude80 Exciting News! Just released my latest YouTube video - &amp;quot;PySpark Tutorial for Beginners: 1-Hour Full Course&amp;quot; \ud83d\udc0d\ud83d\udca1&lt;/p&gt;\n\n&lt;p&gt;Are you ready to dive into the world of PySpark and harness the power of distributed data processing with ease? In this comprehensive 1-hour tutorial, I&amp;#39;ll guide you through the fundamentals of PySpark, from installation to hands-on coding examples.&lt;/p&gt;\n\n&lt;p&gt;\ud83d\udd25 What You&amp;#39;ll Learn:\n\u2705 Spark Introduction\n\u2705 Spark Installation\n\u2705 Setting Up Your PySpark Environment\n\u2705 Spark RDD\n\u2705 DataFrame Operations\n\u2705 Spark SQL\n\u2705 And much more!&lt;/p&gt;\n\n&lt;p&gt;Whether you&amp;#39;re a beginner looking to kickstart your journey into big data or an experienced data engineer aiming to refresh your skills, this video has something for you!&lt;/p&gt;\n\n&lt;p&gt;Watch it now \ud83d\udc49 &lt;a href=\"https://youtu.be/EB8lfdxpirM\"&gt;https://youtu.be/EB8lfdxpirM&lt;/a&gt;\nGitHub Repo \ud83d\udc49 &lt;a href=\"https://github.com/coder2j/pyspark-tutorial\"&gt;https://github.com/coder2j/pyspark-tutorial&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t forget to like, subscribe, and share with your network. Let&amp;#39;s spread the knowledge together! \ud83d\udcda\ud83d\udcaa&lt;/p&gt;\n\n&lt;h1&gt;PySpark #DataScience #BigData #Tutorial #LinkedInLearning #YouTubeTutorial&lt;/h1&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/EB8lfdxpirM", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/82Ln0Z8hZhrRQ6_8TIvFLpE_UPEKESS_TxaZOyjr6Ig.jpg?auto=webp&amp;s=721ceed222baa9b21597759f40ad168578d0ee74", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/82Ln0Z8hZhrRQ6_8TIvFLpE_UPEKESS_TxaZOyjr6Ig.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9318f73383bcd738f86d14479864d192ae47b270", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/82Ln0Z8hZhrRQ6_8TIvFLpE_UPEKESS_TxaZOyjr6Ig.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6616b558982a89e258beb94901e9d212ce6bf76a", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/82Ln0Z8hZhrRQ6_8TIvFLpE_UPEKESS_TxaZOyjr6Ig.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=b465b2e80a183e03df5ef8d4f758d78f53dd3454", "width": 320, "height": 240}], "variants": {}, "id": "wp5OUtzYt-eYRgOkWVPGa-zaQJ8PGPB2r-t4qza7MPs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "173ldbg", "is_robot_indexable": true, "report_reasons": null, "author": "Coder2j", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173ldbg/pyspark_tutorial_for_beginners_1hour_full_course/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/EB8lfdxpirM", "subreddit_subscribers": 1077836, "created_utc": 1696834479.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "PySpark Tutorial for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/EB8lfdxpirM?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"PySpark Tutorial for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "coder2j", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/EB8lfdxpirM/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@coder2j"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am trying to match company names in all languages and have been using rapidfuzz package with partial ratio distance metric which works fine for English names. I have tried levenshtein, jaccard and others as well but wondering what is the best approach? Also what do u use for non English text matching?", "author_fullname": "t2_96pe53q5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the best package /approach for matching text in python?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173izkk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696825392.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am trying to match company names in all languages and have been using rapidfuzz package with partial ratio distance metric which works fine for English names. I have tried levenshtein, jaccard and others as well but wondering what is the best approach? Also what do u use for non English text matching?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173izkk", "is_robot_indexable": true, "report_reasons": null, "author": "Ok_Waltz_5145", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173izkk/what_is_the_best_package_approach_for_matching/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173izkk/what_is_the_best_package_approach_for_matching/", "subreddit_subscribers": 1077836, "created_utc": 1696825392.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Where is the best place to run an ARIMA model? I have done all the work in python to determine the best parameters but it is so confusing to actually fit the model correctly. Thanks!", "author_fullname": "t2_cjm93tal", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Running ARIMA Models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17369yn", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696789910.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Where is the best place to run an ARIMA model? I have done all the work in python to determine the best parameters but it is so confusing to actually fit the model correctly. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17369yn", "is_robot_indexable": true, "report_reasons": null, "author": "fhckgkgkgjdh", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17369yn/running_arima_models/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17369yn/running_arima_models/", "subreddit_subscribers": 1077836, "created_utc": 1696789910.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_dbzc83zts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Complete Excel, Python and Machine Learning Mega Software Bundle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "meta", "downs": 0, "thumbnail_height": 78, "top_awarded_type": null, "hide_score": true, "name": "t3_173qcao", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Meta", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://a.thumbs.redditmedia.com/zBmW-UTZYibiVBYOFW1rQAE4M15p9F9F7veuqcvAdl4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696853850.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/@Humble_Bundle_Partner_Blog/the-complete-excel-python-and-machine-learning-mega-software-bundle-dddf5277bf39?3", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/nxijwBWcx7LmwVpb3mzkMeKgAcv55udyMAPhT8DznY0.jpg?auto=webp&amp;s=12dcaf638e08ca0222aeae619417ce9c0d9316fd", "width": 1200, "height": 675}, "resolutions": [{"url": "https://external-preview.redd.it/nxijwBWcx7LmwVpb3mzkMeKgAcv55udyMAPhT8DznY0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=79333e70ce8b8fcc22d82ec27f25e3eb700b56b1", "width": 108, "height": 60}, {"url": "https://external-preview.redd.it/nxijwBWcx7LmwVpb3mzkMeKgAcv55udyMAPhT8DznY0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=14be50de4fa23b68558106dbb8df91c34d1bc6d7", "width": 216, "height": 121}, {"url": "https://external-preview.redd.it/nxijwBWcx7LmwVpb3mzkMeKgAcv55udyMAPhT8DznY0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=9783e9905b9fe959ebaafa7929806230616f1bb2", "width": 320, "height": 180}, {"url": "https://external-preview.redd.it/nxijwBWcx7LmwVpb3mzkMeKgAcv55udyMAPhT8DznY0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a405dd01a8709615c7d4db069f7536ac4dc2276c", "width": 640, "height": 360}, {"url": "https://external-preview.redd.it/nxijwBWcx7LmwVpb3mzkMeKgAcv55udyMAPhT8DznY0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=1cd68c99426a3504ce5810bf5a117f5241b283de", "width": 960, "height": 540}, {"url": "https://external-preview.redd.it/nxijwBWcx7LmwVpb3mzkMeKgAcv55udyMAPhT8DznY0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5442cd2718ae2a4903f63c27b8fcdd32457d37d5", "width": 1080, "height": 607}], "variants": {}, "id": "Q2xWXEnMbgUVOU1cWq0z2MOmudY903vj0_G0tSqZmDY"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "481ee318-d77d-11e7-a4a3-0e8624d7129a", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "173qcao", "is_robot_indexable": true, "report_reasons": null, "author": "brand_momentum", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173qcao/complete_excel_python_and_machine_learning_mega/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/@Humble_Bundle_Partner_Blog/the-complete-excel-python-and-machine-learning-mega-software-bundle-dddf5277bf39?3", "subreddit_subscribers": 1077836, "created_utc": 1696853850.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi all,\n\nI need to take a home assessment for a potential hiring at a retail company.\n\nThey asked me to make a simple time series prediction on unit sales and write a \"brief report\" with the main findings.\n\nHowever, since I lack experience in translating outcomes of time series forecasting into actionable insights for the business, I don't know what aspects I should focus on nor how long this report should be.\n\nIn the assignment they specified that the goal is to develop a POC, therefore how would you guys approach this and how many pages would you write? \nI am a bit lost...", "author_fullname": "t2_6la2x6qi", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What to explain in a \"brief report\" for time series forecasting?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173q3r6", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696853117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all,&lt;/p&gt;\n\n&lt;p&gt;I need to take a home assessment for a potential hiring at a retail company.&lt;/p&gt;\n\n&lt;p&gt;They asked me to make a simple time series prediction on unit sales and write a &amp;quot;brief report&amp;quot; with the main findings.&lt;/p&gt;\n\n&lt;p&gt;However, since I lack experience in translating outcomes of time series forecasting into actionable insights for the business, I don&amp;#39;t know what aspects I should focus on nor how long this report should be.&lt;/p&gt;\n\n&lt;p&gt;In the assignment they specified that the goal is to develop a POC, therefore how would you guys approach this and how many pages would you write? \nI am a bit lost...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173q3r6", "is_robot_indexable": true, "report_reasons": null, "author": "Stedua", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173q3r6/what_to_explain_in_a_brief_report_for_time_series/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173q3r6/what_to_explain_in_a_brief_report_for_time_series/", "subreddit_subscribers": 1077836, "created_utc": 1696853117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello, my deep learning class professor assigned us some projects, my group mates we want to do something from our own. \n\nIf you have any suggestions on projects that are new, interesting, and relatively difficult, please suggest them to me. Thanks.", "author_fullname": "t2_c2vnieg4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Looking for project ideas (related to LLMs or Generative AI)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173q025", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696852826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, my deep learning class professor assigned us some projects, my group mates we want to do something from our own. &lt;/p&gt;\n\n&lt;p&gt;If you have any suggestions on projects that are new, interesting, and relatively difficult, please suggest them to me. Thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173q025", "is_robot_indexable": true, "report_reasons": null, "author": "Evening_Pitch5398", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173q025/looking_for_project_ideas_related_to_llms_or/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173q025/looking_for_project_ideas_related_to_llms_or/", "subreddit_subscribers": 1077836, "created_utc": 1696852826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I've been given this task to create clustering on users dataset. The model itself performs well but the management wants me to somehow automate the output/insights so it can be translated to other datasets too. I expressed my worries for them as I don't think that it is possible but I was trying my luck here to see maybe there is a method/idea which I am not aware of?\n\nThe only thing I could come up with is looping for each cluster and finding if there is a feature which has a value count of more than 90% (or any threshold) and just saving the cluster-feature-value trio that is answering this condition. I don't know how much I'm up for that method because its very technical and automatic and might miss valuable (for example - If I have a country feature, and let's say if I have 50 countries in a cluster. Maybe the prevelance of all countries is equal to 2% but because 49 of the 50 countries are from Asia so it means 98% of them are from Asia which is a valuable information I am missing).\n\nIs there even any method to do that? Or should I just insist that it is not feasible?  \nThanks", "author_fullname": "t2_3hqmko1r", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Automation of insights extraction from Clustering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1731r1r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.76, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696778383.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I&amp;#39;ve been given this task to create clustering on users dataset. The model itself performs well but the management wants me to somehow automate the output/insights so it can be translated to other datasets too. I expressed my worries for them as I don&amp;#39;t think that it is possible but I was trying my luck here to see maybe there is a method/idea which I am not aware of?&lt;/p&gt;\n\n&lt;p&gt;The only thing I could come up with is looping for each cluster and finding if there is a feature which has a value count of more than 90% (or any threshold) and just saving the cluster-feature-value trio that is answering this condition. I don&amp;#39;t know how much I&amp;#39;m up for that method because its very technical and automatic and might miss valuable (for example - If I have a country feature, and let&amp;#39;s say if I have 50 countries in a cluster. Maybe the prevelance of all countries is equal to 2% but because 49 of the 50 countries are from Asia so it means 98% of them are from Asia which is a valuable information I am missing).&lt;/p&gt;\n\n&lt;p&gt;Is there even any method to do that? Or should I just insist that it is not feasible?&lt;br/&gt;\nThanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "1731r1r", "is_robot_indexable": true, "report_reasons": null, "author": "nuriel8833", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/1731r1r/automation_of_insights_extraction_from_clustering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/1731r1r/automation_of_insights_extraction_from_clustering/", "subreddit_subscribers": 1077836, "created_utc": 1696778383.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a beginner trying to create a Model with Image detection using Convolutional Neural Network. I have a project in mind where I would detect the type of banknotes. I have already collected some images to be used but as far as i know. I need to annotate it and then train it. \n\nI don't know how will i link the annotated JSON file of the images when training. Does anyone know how?", "author_fullname": "t2_okaww79i", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Image Detection with CNN Model", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17316vc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696777078.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a beginner trying to create a Model with Image detection using Convolutional Neural Network. I have a project in mind where I would detect the type of banknotes. I have already collected some images to be used but as far as i know. I need to annotate it and then train it. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know how will i link the annotated JSON file of the images when training. Does anyone know how?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17316vc", "is_robot_indexable": true, "report_reasons": null, "author": "AutomaticResearch337", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17316vc/image_detection_with_cnn_model/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17316vc/image_detection_with_cnn_model/", "subreddit_subscribers": 1077836, "created_utc": 1696777078.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am a mechanical engineering graduate from India. I have about three years of experience in data driven product development (using computational models and statistics) and python programming. I will be moving to the USA in January 2024 to pursue my masters in data science. I quit my job recently and am hoping to utilize the rest of 2023 to cover knowledge gaps and eventually ease up my academic journey. \n\nPlan of action:  \n**1. Brush up my C language and Python skills:** I will be relying on previous notes, youtube tutorials and leetcode.\n\n**2. Learn MySQL and Power BI:** Here are my [MySQL](https://youtu.be/hlGoQC332VM) and [Power BI](https://www.linkedin.com/pulse/i-dont-know-lot-simply-read-0-dimes-power-bi-resource-alex-powers/) learning resources. Kindly suggest me better resources, that you know of.\n\n**3. Build a project:** A beginner's level project utilizing the above skills would give me some practical experience. If you happen to be working on any personal or open source projects, count me in.\n\n**4. Machine learning:** I am planning to utilize these three months to gain strong foundation on all the mathematical  concepts required. I don't think I can explore ML in depth in these three months.\n\nSo....Does this POA make sense to you? Should I be concentrating on any other concepts to better prepare for my master's? Any general advice on DS  is also welcome.  \n\n\nThanks in advance!  \n\n\n&amp;#x200B;", "author_fullname": "t2_9f9a0pcq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help me build a plan of action for my MS in Data Science program.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173qc0r", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696853826.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am a mechanical engineering graduate from India. I have about three years of experience in data driven product development (using computational models and statistics) and python programming. I will be moving to the USA in January 2024 to pursue my masters in data science. I quit my job recently and am hoping to utilize the rest of 2023 to cover knowledge gaps and eventually ease up my academic journey. &lt;/p&gt;\n\n&lt;p&gt;Plan of action:&lt;br/&gt;\n&lt;strong&gt;1. Brush up my C language and Python skills:&lt;/strong&gt; I will be relying on previous notes, youtube tutorials and leetcode.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;2. Learn MySQL and Power BI:&lt;/strong&gt; Here are my &lt;a href=\"https://youtu.be/hlGoQC332VM\"&gt;MySQL&lt;/a&gt; and &lt;a href=\"https://www.linkedin.com/pulse/i-dont-know-lot-simply-read-0-dimes-power-bi-resource-alex-powers/\"&gt;Power BI&lt;/a&gt; learning resources. Kindly suggest me better resources, that you know of.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;3. Build a project:&lt;/strong&gt; A beginner&amp;#39;s level project utilizing the above skills would give me some practical experience. If you happen to be working on any personal or open source projects, count me in.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;4. Machine learning:&lt;/strong&gt; I am planning to utilize these three months to gain strong foundation on all the mathematical  concepts required. I don&amp;#39;t think I can explore ML in depth in these three months.&lt;/p&gt;\n\n&lt;p&gt;So....Does this POA make sense to you? Should I be concentrating on any other concepts to better prepare for my master&amp;#39;s? Any general advice on DS  is also welcome.  &lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!  &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QSIGYJdVtRWudxAUudXIkQ1r2Odq_A66pd8bi9RdMpc.jpg?auto=webp&amp;s=ca6700a7eddbddc3030cc8494e937e1f5309cda9", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/QSIGYJdVtRWudxAUudXIkQ1r2Odq_A66pd8bi9RdMpc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f2517ff41a078de46aa05f76678e09c47eeb7350", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/QSIGYJdVtRWudxAUudXIkQ1r2Odq_A66pd8bi9RdMpc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=2ac6e31de067c3bc5eb1ea7a461b1f428ed8d821", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/QSIGYJdVtRWudxAUudXIkQ1r2Odq_A66pd8bi9RdMpc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5661cd02b1b506ebbb013fd81acc4239a22afe3c", "width": 320, "height": 240}], "variants": {}, "id": "ycWdsPxHkU_2YN902oc0w9OjGDg25zTexr5ZTMv7CXE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173qc0r", "is_robot_indexable": true, "report_reasons": null, "author": "AppropriateMix3928", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173qc0r/help_me_build_a_plan_of_action_for_my_ms_in_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173qc0r/help_me_build_a_plan_of_action_for_my_ms_in_data/", "subreddit_subscribers": 1077836, "created_utc": 1696853826.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anyone interested? Also could anyone help with some tips on how to format a blog?", "author_fullname": "t2_al2yxww8e", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I\u2019m starting a Level 7 AI Data Specialist Apprenticeship in 4 weeks. I was thinking about creating a blog alongside learning, would anyone be interested in this at all?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173q2aw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696852996.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone interested? Also could anyone help with some tips on how to format a blog?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173q2aw", "is_robot_indexable": true, "report_reasons": null, "author": "The-Engineer-93", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173q2aw/im_starting_a_level_7_ai_data_specialist/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173q2aw/im_starting_a_level_7_ai_data_specialist/", "subreddit_subscribers": 1077836, "created_utc": 1696852996.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "What are the best resources to use when preparing for an interview for a Data Scientist position? What are the key things to focus on? \nI have 2.5 YoE as a researcher (energy sector, mostly time series forecasting) in an academic institution but have worked on projects for the industry during my time here.", "author_fullname": "t2_7nyuf0y3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview preparation", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_173pqdk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696851926.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;What are the best resources to use when preparing for an interview for a Data Scientist position? What are the key things to focus on? \nI have 2.5 YoE as a researcher (energy sector, mostly time series forecasting) in an academic institution but have worked on projects for the industry during my time here.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173pqdk", "is_robot_indexable": true, "report_reasons": null, "author": "fxsta33", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173pqdk/interview_preparation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173pqdk/interview_preparation/", "subreddit_subscribers": 1077836, "created_utc": 1696851926.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi Guys\n\nI am embarking on a new project where I would like to train a GAN to create Islamic patterns for doors, roofs, and other furniture. I've attached a few examples of what I have in mind as I am looking for a dataset I can use for training. \n\n&amp;#x200B;\n\nAny directions or recommendations will be appreciated, and advise on the model are welcome as well. ", "author_fullname": "t2_8o2bbpliq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Islamic Patterns and Designs Data Set", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173mu8v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696840614.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys&lt;/p&gt;\n\n&lt;p&gt;I am embarking on a new project where I would like to train a GAN to create Islamic patterns for doors, roofs, and other furniture. I&amp;#39;ve attached a few examples of what I have in mind as I am looking for a dataset I can use for training. &lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Any directions or recommendations will be appreciated, and advise on the model are welcome as well. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173mu8v", "is_robot_indexable": true, "report_reasons": null, "author": "Prestigious_Virus_33", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173mu8v/islamic_patterns_and_designs_data_set/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173mu8v/islamic_patterns_and_designs_data_set/", "subreddit_subscribers": 1077836, "created_utc": 1696840614.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nWelcome to this week's entering &amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:\n\n* Learning resources (e.g. books, tutorials, videos)\n* Traditional education (e.g. schools, degrees, electives)\n* Alternative education (e.g. online courses, bootcamps)\n* Job search questions (e.g. resumes, applying, career prospects)\n* Elementary questions (e.g. where to start, what next)\n\nWhile you wait for answers from the community, check out the [FAQ](https://www.reddit.com/r/datascience/wiki/frequently-asked-questions) and Resources pages on our wiki. You can also search for answers in [past weekly threads](https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;restrict_sr=1&amp;sort=new).", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Weekly Entering &amp; Transitioning - Thread 09 Oct, 2023 - 16 Oct, 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": null, "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173im0f", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": null, "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696824085.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Welcome to this week&amp;#39;s entering &amp;amp; transitioning thread! This thread is for any questions about getting started, studying, or transitioning into the data science field. Topics include:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Learning resources (e.g. books, tutorials, videos)&lt;/li&gt;\n&lt;li&gt;Traditional education (e.g. schools, degrees, electives)&lt;/li&gt;\n&lt;li&gt;Alternative education (e.g. online courses, bootcamps)&lt;/li&gt;\n&lt;li&gt;Job search questions (e.g. resumes, applying, career prospects)&lt;/li&gt;\n&lt;li&gt;Elementary questions (e.g. where to start, what next)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;While you wait for answers from the community, check out the &lt;a href=\"https://www.reddit.com/r/datascience/wiki/frequently-asked-questions\"&gt;FAQ&lt;/a&gt; and Resources pages on our wiki. You can also search for answers in &lt;a href=\"https://www.reddit.com/r/datascience/search?q=weekly%20thread&amp;amp;restrict_sr=1&amp;amp;sort=new\"&gt;past weekly threads&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "new", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173im0f", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 1, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173im0f/weekly_entering_transitioning_thread_09_oct_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/datascience/comments/173im0f/weekly_entering_transitioning_thread_09_oct_2023/", "subreddit_subscribers": 1077836, "created_utc": 1696824085.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_laai6zvho", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Unlimited Karma: Setting AI Agents Free in the Reddit jungle", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 137, "top_awarded_type": null, "hide_score": true, "name": "t3_173q8m8", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.29, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/rcz-30IFefQxTxzm6DDGwH33Z4UGRiW9LdN28pGEJzQ.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696853522.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/ggmubb0p46tb1.png", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/ggmubb0p46tb1.png?auto=webp&amp;s=2ba52bdb6649a3c8b38b0f0385f05ddf0fe5e65f", "width": 664, "height": 652}, "resolutions": [{"url": "https://preview.redd.it/ggmubb0p46tb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa451f4189d2a9afe1b371a9642547d77e4ecc5d", "width": 108, "height": 106}, {"url": "https://preview.redd.it/ggmubb0p46tb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=95dc630227e9ef90abf3a6e680b5d9b9127ccef8", "width": 216, "height": 212}, {"url": "https://preview.redd.it/ggmubb0p46tb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=6acb72a0654a6448cee6ccc7c45e3b8b41bab962", "width": 320, "height": 314}, {"url": "https://preview.redd.it/ggmubb0p46tb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=2ec58634d5b931706b13132e5ac926eab71d8243", "width": 640, "height": 628}], "variants": {}, "id": "gMgbHDrcA82cpetpIpw5_72zxYfAdaXSX3A8LpB_3ss"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "173q8m8", "is_robot_indexable": true, "report_reasons": null, "author": "Significant_Hat_3389", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173q8m8/unlimited_karma_setting_ai_agents_free_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/ggmubb0p46tb1.png", "subreddit_subscribers": 1077836, "created_utc": 1696853522.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "so I am second year student and I have knowledge of numpy panda and python oops and I have a data science hackathon in 10 days so what all should I prepare with and from where", "author_fullname": "t2_8b1cay56", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help !!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_173m9qh", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696838166.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;so I am second year student and I have knowledge of numpy panda and python oops and I have a data science hackathon in 10 days so what all should I prepare with and from where&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "173m9qh", "is_robot_indexable": true, "report_reasons": null, "author": "SevereMasterpiece806", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/173m9qh/help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/173m9qh/help/", "subreddit_subscribers": 1077836, "created_utc": 1696838166.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}