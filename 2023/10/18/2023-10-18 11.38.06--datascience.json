{"kind": "Listing", "data": {"after": "t3_17aba8j", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Just recently graduated in May with a BS statistics from texas a&amp;m with a specialization in GIS. I have a good knowledge of statistics, not a slacker in the academic sense. 3.5 gpa. One semester of research, no internship experience Edit: Passed two preliminary actuarial exams P and FM early on in university. Since then, I got a contracting gig at apple as GIS editor/mapper, maybe I can market it off as an analyst), I was training there for a month and got laid off, can def get a good ref letter though. I have a decent capstone project from university, shiny app utilizing exploratory methods for points patterns. I'm almost done with the meta coursera front-end prof certificate and I'm gonna do the back-end version, because I want to know how to deploy a shiny app with all the bells and whistles using the rhino framework, connected to a database, testing, user feedback, hosted on the cloud. Maybe then if can have a little web app on my resume that also makes peoples lives a little easier. I've thought about it, looks like I have a lot to learn, ux/ui design, marketing the web-app somewhere, even if it doesn't get any traffic, maybe it'll look good on a resume.\n\nI'm disenchanted with it all, I'm hearing a person with a PhD in a quantitative field hardly ever needs PhD level knowledge in their work, unless they are in academia or industry doing research, do you even need a masters? I mean, doesn't a bachelors in statistics, especially coupled with a few graduate level stacked courses in statistics, basically qualify you, as \"pretty much as knowledgeable as a masters in statistics with no undergrad statistics related coursework, in terms of theoretical knowledge of probability, regression, inference\", I'm not asking any questions. It's just that a person with connections and a bachelors in english, can get a job in analytics, and I am having trouble. I call it how I see it, my knowledge of statistics is not nearly as important, as having something tangible, that says \"I'm of value\" and \"people can rely on me\", and knowing people. Especially when employers aren't going to ask my professors how I was like,  I imagine I'll have a better chance getting into a PhD program. Even if you get a PhD, you still need to fight for job, learn new skills, deal with layoffs, and probably, continue the wage-slave life like most people in America (which is a good life I admit for most people). No question here, I'm just saying how I feel at the moment, making no implicit claims. I can get good rec letters from my professors, I'm pretty sure, lol, ya think I can get it at places like texas tech, iowa state, or kansas state?  Open to conversation about anything. So plan is, get a PhD, because I can't get a job now, maybe yeet out with a masters, but honestly, I like teaching, I like learning, I don't mind taking tests, and I know how to live with a low overhead (I don't buy stuff I don't need). I know what really matters, your basic needs, family, a few good friends. Ok, that's not all that matters, there have been many people who have excelled in their fields, sacrificing their time with their family and friends, in order to do things that everybody would agree matters. Some I know regret it, others don't.", "author_fullname": "t2_qorbr809", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I'm giving up finding a job. I feel like I'll have better luck applying to PhD programs. This is a rant.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17aba8a", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 77, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 77, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697588397.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697583329.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just recently graduated in May with a BS statistics from texas a&amp;amp;m with a specialization in GIS. I have a good knowledge of statistics, not a slacker in the academic sense. 3.5 gpa. One semester of research, no internship experience Edit: Passed two preliminary actuarial exams P and FM early on in university. Since then, I got a contracting gig at apple as GIS editor/mapper, maybe I can market it off as an analyst), I was training there for a month and got laid off, can def get a good ref letter though. I have a decent capstone project from university, shiny app utilizing exploratory methods for points patterns. I&amp;#39;m almost done with the meta coursera front-end prof certificate and I&amp;#39;m gonna do the back-end version, because I want to know how to deploy a shiny app with all the bells and whistles using the rhino framework, connected to a database, testing, user feedback, hosted on the cloud. Maybe then if can have a little web app on my resume that also makes peoples lives a little easier. I&amp;#39;ve thought about it, looks like I have a lot to learn, ux/ui design, marketing the web-app somewhere, even if it doesn&amp;#39;t get any traffic, maybe it&amp;#39;ll look good on a resume.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m disenchanted with it all, I&amp;#39;m hearing a person with a PhD in a quantitative field hardly ever needs PhD level knowledge in their work, unless they are in academia or industry doing research, do you even need a masters? I mean, doesn&amp;#39;t a bachelors in statistics, especially coupled with a few graduate level stacked courses in statistics, basically qualify you, as &amp;quot;pretty much as knowledgeable as a masters in statistics with no undergrad statistics related coursework, in terms of theoretical knowledge of probability, regression, inference&amp;quot;, I&amp;#39;m not asking any questions. It&amp;#39;s just that a person with connections and a bachelors in english, can get a job in analytics, and I am having trouble. I call it how I see it, my knowledge of statistics is not nearly as important, as having something tangible, that says &amp;quot;I&amp;#39;m of value&amp;quot; and &amp;quot;people can rely on me&amp;quot;, and knowing people. Especially when employers aren&amp;#39;t going to ask my professors how I was like,  I imagine I&amp;#39;ll have a better chance getting into a PhD program. Even if you get a PhD, you still need to fight for job, learn new skills, deal with layoffs, and probably, continue the wage-slave life like most people in America (which is a good life I admit for most people). No question here, I&amp;#39;m just saying how I feel at the moment, making no implicit claims. I can get good rec letters from my professors, I&amp;#39;m pretty sure, lol, ya think I can get it at places like texas tech, iowa state, or kansas state?  Open to conversation about anything. So plan is, get a PhD, because I can&amp;#39;t get a job now, maybe yeet out with a masters, but honestly, I like teaching, I like learning, I don&amp;#39;t mind taking tests, and I know how to live with a low overhead (I don&amp;#39;t buy stuff I don&amp;#39;t need). I know what really matters, your basic needs, family, a few good friends. Ok, that&amp;#39;s not all that matters, there have been many people who have excelled in their fields, sacrificing their time with their family and friends, in order to do things that everybody would agree matters. Some I know regret it, others don&amp;#39;t.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17aba8a", "is_robot_indexable": true, "report_reasons": null, "author": "Sea-Bodybuilder-1277", "discussion_type": null, "num_comments": 85, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17aba8a/im_giving_up_finding_a_job_i_feel_like_ill_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17aba8a/im_giving_up_finding_a_job_i_feel_like_ill_have/", "subreddit_subscribers": 1089222, "created_utc": 1697583329.0, "num_crossposts": 1, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am finishing my my masters degree in data analytics. Previously I've worked as a business analyst for three years. I just had an interview for a data analyst position and I was asked to complete a take home assignment with two parts: a written analysis, and an R project that included a business report with a summary and discussion for recommendations on improving the data reporting. I had 24 from after my interview to return the assignment. I got the exam at 2pm yesterday, so I had until 2pm today. \n\nI got home at 3pm and got the first written portion done yesterday. It involved some simple excel manipulations. Then I had to go to class at 5. Didn't get home till 10pm.\n\nFast forward this morning. I wake up at 8.i get started on the R project at 9am.\n\nThe data was some of the messiness I've seen, and cleaning and transforming the data took four hours. The analysis and visualizations took about one. I know there were some mistakes, and I got the written summary done. But I could not submit the discussion on recommendations. \n\nI'm not here to ask about my likelihood of getting the job. But this task seemed monumental for just 24 hours (i have other obligations like class and a family). Even my worst professors haven't asked me to do anything like that in such a short time. Is this to be expected going forward?", "author_fullname": "t2_fypd1w6xt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Interview Take Home task seemed unreasonable", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a79kw", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 77, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 77, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697572997.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am finishing my my masters degree in data analytics. Previously I&amp;#39;ve worked as a business analyst for three years. I just had an interview for a data analyst position and I was asked to complete a take home assignment with two parts: a written analysis, and an R project that included a business report with a summary and discussion for recommendations on improving the data reporting. I had 24 from after my interview to return the assignment. I got the exam at 2pm yesterday, so I had until 2pm today. &lt;/p&gt;\n\n&lt;p&gt;I got home at 3pm and got the first written portion done yesterday. It involved some simple excel manipulations. Then I had to go to class at 5. Didn&amp;#39;t get home till 10pm.&lt;/p&gt;\n\n&lt;p&gt;Fast forward this morning. I wake up at 8.i get started on the R project at 9am.&lt;/p&gt;\n\n&lt;p&gt;The data was some of the messiness I&amp;#39;ve seen, and cleaning and transforming the data took four hours. The analysis and visualizations took about one. I know there were some mistakes, and I got the written summary done. But I could not submit the discussion on recommendations. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not here to ask about my likelihood of getting the job. But this task seemed monumental for just 24 hours (i have other obligations like class and a family). Even my worst professors haven&amp;#39;t asked me to do anything like that in such a short time. Is this to be expected going forward?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a79kw", "is_robot_indexable": true, "report_reasons": null, "author": "wildwildwildebeast", "discussion_type": null, "num_comments": 50, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a79kw/interview_take_home_task_seemed_unreasonable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a79kw/interview_take_home_task_seemed_unreasonable/", "subreddit_subscribers": 1089222, "created_utc": 1697572997.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am aware of a few tools that aid in converting XGBoost decision trees to \"if-then\" statements. I'm curious if anyone has experience with this approach, and how feasible/successful was the outcome?", "author_fullname": "t2_8qqebrm9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Converting XGBoost decision models to \"if-then\" statements", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a6ken", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.89, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697571198.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am aware of a few tools that aid in converting XGBoost decision trees to &amp;quot;if-then&amp;quot; statements. I&amp;#39;m curious if anyone has experience with this approach, and how feasible/successful was the outcome?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a6ken", "is_robot_indexable": true, "report_reasons": null, "author": "MultiPass10", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a6ken/converting_xgboost_decision_models_to_ifthen/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a6ken/converting_xgboost_decision_models_to_ifthen/", "subreddit_subscribers": 1089222, "created_utc": 1697571198.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am currently a CS grad major and I really love this field! I have a major interest, work experience and projects in Data Science(majorly Deep Learning and Machine Learning). I am currently looking for summer internships in Data Science, ML, AI etc. I am being told that you'll probably be asked leetcode questions in your technical interviews and I am shit scared of it. I can't do anything beyond Leetcode easy, my mind just doesn't accept unseen medium questions. If I remember a solution to one of the medium problem, I might be able to solve it but that also fades away if I don't practice that problem in every few days. \n\nSomeone please shed light on whether my targeted jobs require Leetcode or not, and if they do then what level of questions?", "author_fullname": "t2_7tvt0u4s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shit scared of Leetcode!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ajqwd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697609542.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am currently a CS grad major and I really love this field! I have a major interest, work experience and projects in Data Science(majorly Deep Learning and Machine Learning). I am currently looking for summer internships in Data Science, ML, AI etc. I am being told that you&amp;#39;ll probably be asked leetcode questions in your technical interviews and I am shit scared of it. I can&amp;#39;t do anything beyond Leetcode easy, my mind just doesn&amp;#39;t accept unseen medium questions. If I remember a solution to one of the medium problem, I might be able to solve it but that also fades away if I don&amp;#39;t practice that problem in every few days. &lt;/p&gt;\n\n&lt;p&gt;Someone please shed light on whether my targeted jobs require Leetcode or not, and if they do then what level of questions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17ajqwd", "is_robot_indexable": true, "report_reasons": null, "author": "treaty_tonvis", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ajqwd/shit_scared_of_leetcode/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ajqwd/shit_scared_of_leetcode/", "subreddit_subscribers": 1089222, "created_utc": 1697609542.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I cant make heads and tails of theory papers that have  mathematical notations and equation. Where do you start? Is there an ebook/primer that can help? I dont have an economics background but I did study advanced math in high school. I am in accounting if it matters", "author_fullname": "t2_8xfzxrs0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Where do you start if you are new to mathematical models", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ad4og", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697588385.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I cant make heads and tails of theory papers that have  mathematical notations and equation. Where do you start? Is there an ebook/primer that can help? I dont have an economics background but I did study advanced math in high school. I am in accounting if it matters&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17ad4og", "is_robot_indexable": true, "report_reasons": null, "author": "relativefluffy", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ad4og/where_do_you_start_if_you_are_new_to_mathematical/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ad4og/where_do_you_start_if_you_are_new_to_mathematical/", "subreddit_subscribers": 1089222, "created_utc": 1697588385.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I am in process of switching jobs, and preferably domains as well. I am currently in the banking domain (Consulting) and would like to move to a B2C/Product based company. \n\nThe topics often mentioned in JDs are like price optimization, Cohort Analysis, Funnel Analysis, Forecasting etc.  I have no experience in such topics due to the nature of my work, but I have started doing small projects for the same.\n\nMy problem is how can I show this in my recruiters such that they don't just ignore my personal projects section. ", "author_fullname": "t2_736ioria", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How can I show knowledge in topics I haven't worked on professionally?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17alvvb", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697618520.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am in process of switching jobs, and preferably domains as well. I am currently in the banking domain (Consulting) and would like to move to a B2C/Product based company. &lt;/p&gt;\n\n&lt;p&gt;The topics often mentioned in JDs are like price optimization, Cohort Analysis, Funnel Analysis, Forecasting etc.  I have no experience in such topics due to the nature of my work, but I have started doing small projects for the same.&lt;/p&gt;\n\n&lt;p&gt;My problem is how can I show this in my recruiters such that they don&amp;#39;t just ignore my personal projects section. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17alvvb", "is_robot_indexable": true, "report_reasons": null, "author": "jaegarbong", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17alvvb/how_can_i_show_knowledge_in_topics_i_havent/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17alvvb/how_can_i_show_knowledge_in_topics_i_havent/", "subreddit_subscribers": 1089222, "created_utc": 1697618520.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "This has happened to me twice now, dunno if it\u2019s a new trend in recruitment processes. I\u2019m fine with it, to be honest, because it lets me show that I have the skills necessary for the job. I\u2019m not currently working in DS but in finance with some data analysis, but not much modeling work to show for (even though I have my master\u2019s in a computational quantitative field and so know the stats/theory behind most models).\n\n I didn\u2019t get the first job that required a live-coding exercise because they could only schedule it while I was on vacation and I didn\u2019t feel like I could really prepare, but now with this second position I passed the assignment and I have a 45 minute behavioral interview tomorrow. \n\nJust wondering for anyone who has had a similar recruitment process, does this mean that this recruitment process should be relatively quick? Just this interview and maybe one more technical one? (Am a bit desperate to switch jobs as my current job has a crazy high tempo and it\u2019s hard to find time to interview, which is the main reason I don\u2019t want a super dragged out process)", "author_fullname": "t2_ls91v62g", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What does it mean to get a take-home assignment before screening call?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179yve1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697551029.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697550765.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This has happened to me twice now, dunno if it\u2019s a new trend in recruitment processes. I\u2019m fine with it, to be honest, because it lets me show that I have the skills necessary for the job. I\u2019m not currently working in DS but in finance with some data analysis, but not much modeling work to show for (even though I have my master\u2019s in a computational quantitative field and so know the stats/theory behind most models).&lt;/p&gt;\n\n&lt;p&gt;I didn\u2019t get the first job that required a live-coding exercise because they could only schedule it while I was on vacation and I didn\u2019t feel like I could really prepare, but now with this second position I passed the assignment and I have a 45 minute behavioral interview tomorrow. &lt;/p&gt;\n\n&lt;p&gt;Just wondering for anyone who has had a similar recruitment process, does this mean that this recruitment process should be relatively quick? Just this interview and maybe one more technical one? (Am a bit desperate to switch jobs as my current job has a crazy high tempo and it\u2019s hard to find time to interview, which is the main reason I don\u2019t want a super dragged out process)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179yve1", "is_robot_indexable": true, "report_reasons": null, "author": "Whole-Ad-8370", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179yve1/what_does_it_mean_to_get_a_takehome_assignment/", "subreddit_subscribers": 1089222, "created_utc": 1697550765.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_65r4fi3o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone here that knows where to find scientific papers about regression models for Sports results?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ag1pr", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697596666.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17ag1pr", "is_robot_indexable": true, "report_reasons": null, "author": "DanRobin1r", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ag1pr/anyone_here_that_knows_where_to_find_scientific/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ag1pr/anyone_here_that_knows_where_to_find_scientific/", "subreddit_subscribers": 1089222, "created_utc": 1697596666.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hi,   \n\n\nWe just hired a data analyst to analyse a time series representing a certain commodity value over time, we offered them the possibility to take the price data from a source of their choice, but they insisted that we provide it ourselves. Is this good or bad practice? Could someone give pros and cons of letting the analyst find their own publicly available data vs. the company providing them the data set?   \n\n\nThank you", "author_fullname": "t2_97o8m0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Should data-scientists look for their own datasets or be provided by the hiring company?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179ztob", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697553394.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,   &lt;/p&gt;\n\n&lt;p&gt;We just hired a data analyst to analyse a time series representing a certain commodity value over time, we offered them the possibility to take the price data from a source of their choice, but they insisted that we provide it ourselves. Is this good or bad practice? Could someone give pros and cons of letting the analyst find their own publicly available data vs. the company providing them the data set?   &lt;/p&gt;\n\n&lt;p&gt;Thank you&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179ztob", "is_robot_indexable": true, "report_reasons": null, "author": "Cryptocheets", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179ztob/should_datascientists_look_for_their_own_datasets/", "subreddit_subscribers": 1089222, "created_utc": 1697553394.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Why does the DAGitty \"Testable Dependencies\" function only describe independencies, but not spurious correlations?\n\n&amp;#x200B;\n\nE.g, if I have B-&gt;A&lt;-C,\n\nDAGitty just tells me that\n\nB \u22a5 C is the only testable (in)dependency\n\nWhy shouldn't we expect also\n\nB\u22a5\u0338C|A\n\n(i.e, B and C have a spurious correlation given A)?", "author_fullname": "t2_8nq7249f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DAGitty Question: Testable Implications only describes independencies, but not dependencies", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17alwcz", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697628721.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697618580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Why does the DAGitty &amp;quot;Testable Dependencies&amp;quot; function only describe independencies, but not spurious correlations?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;E.g, if I have B-&amp;gt;A&amp;lt;-C,&lt;/p&gt;\n\n&lt;p&gt;DAGitty just tells me that&lt;/p&gt;\n\n&lt;p&gt;B \u22a5 C is the only testable (in)dependency&lt;/p&gt;\n\n&lt;p&gt;Why shouldn&amp;#39;t we expect also&lt;/p&gt;\n\n&lt;p&gt;B\u22a5\u0338C|A&lt;/p&gt;\n\n&lt;p&gt;(i.e, B and C have a spurious correlation given A)?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17alwcz", "is_robot_indexable": true, "report_reasons": null, "author": "zurdosios", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17alwcz/dagitty_question_testable_implications_only/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17alwcz/dagitty_question_testable_implications_only/", "subreddit_subscribers": 1089222, "created_utc": 1697618580.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So i\u2019m working on a project that forecasts sales of products in a series. Curious to know the best approach to model \u201ccascaded\u201d products i.e old version of the series when the new one launches.\nUsing a Recursive multistep regression approach to forecast with some features\n\nAppreciate the help, thanks \ud83d\ude4f\ud83c\udffc", "author_fullname": "t2_7xxtza3n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Forecasting sales", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17al968", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697615792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So i\u2019m working on a project that forecasts sales of products in a series. Curious to know the best approach to model \u201ccascaded\u201d products i.e old version of the series when the new one launches.\nUsing a Recursive multistep regression approach to forecast with some features&lt;/p&gt;\n\n&lt;p&gt;Appreciate the help, thanks \ud83d\ude4f\ud83c\udffc&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17al968", "is_robot_indexable": true, "report_reasons": null, "author": "Asleep-Fun-6508", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17al968/forecasting_sales/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17al968/forecasting_sales/", "subreddit_subscribers": 1089222, "created_utc": 1697615792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Getting around to expanding the team and wanted to implement some sort of coding portion. Does anyone have good experiences with a take home that is respectful of a candidate\u2019s time but also will give you a good idea of their skills? Not a copy/paste LeetCode either.", "author_fullname": "t2_ajfuo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What makes a good take home?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ai9df", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697603857.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Getting around to expanding the team and wanted to implement some sort of coding portion. Does anyone have good experiences with a take home that is respectful of a candidate\u2019s time but also will give you a good idea of their skills? Not a copy/paste LeetCode either.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17ai9df", "is_robot_indexable": true, "report_reasons": null, "author": "Rcpiv", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ai9df/what_makes_a_good_take_home/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ai9df/what_makes_a_good_take_home/", "subreddit_subscribers": 1089222, "created_utc": 1697603857.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_6dgjvkmye", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "We built An Open-Source platform to process relational and Graph Query simultaneously", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_17aaayg", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/DhqpOvMyl_Iv_YtjtsxBAh9z9GgMdAorxuuioN0Q2Gs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697580766.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "github.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://github.com/apache/age", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/TRZymqGBMrpaHYPwm_ZcmXsUZbnGZyQguPSYhSihziU.jpg?auto=webp&amp;s=58a7d69efd2e23844b4e7f1535954b1621778b3f", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/TRZymqGBMrpaHYPwm_ZcmXsUZbnGZyQguPSYhSihziU.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f316a1202f5fa74b0e5f2fbf498b856c9f62215f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/TRZymqGBMrpaHYPwm_ZcmXsUZbnGZyQguPSYhSihziU.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=d5c3f7954f6f80e9189469fca4c02f9e1d64bd86", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/TRZymqGBMrpaHYPwm_ZcmXsUZbnGZyQguPSYhSihziU.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e99420e05d9a57934fcc0d938a675bbddc2fad0d", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/TRZymqGBMrpaHYPwm_ZcmXsUZbnGZyQguPSYhSihziU.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=674177fcbce104b5850c187b74bafb6bfa3a59a6", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/TRZymqGBMrpaHYPwm_ZcmXsUZbnGZyQguPSYhSihziU.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5e5e2c41106d7223ffd0a647c8dcd9e9be77fef0", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/TRZymqGBMrpaHYPwm_ZcmXsUZbnGZyQguPSYhSihziU.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=d4f518d28fcadfd0903c06acb87db698283bda6c", "width": 1080, "height": 540}], "variants": {}, "id": "OogeLufs8cl2yF7lU6HHhIEI9KAKQD2BU74UX-T7Kig"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "17aaayg", "is_robot_indexable": true, "report_reasons": null, "author": "SpecialEngineer7951", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17aaayg/we_built_an_opensource_platform_to_process/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://github.com/apache/age", "subreddit_subscribers": 1089222, "created_utc": 1697580766.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hello all,\n\n I work at one of the big 4 consulting companies as a data scientist on their public sector accounts( with security clearance). I was a campus hire who started this year but I had a solid year of experience as a data science intern at a small tech company.  My bachelor degree was in statistics.\n\nI want to move to a data science or data analyst positions at big tech companies. I mainly want to work in analytics and data engineering. How many years of experience would I need to have a decent change?what would you recommend to increase my odds? Should I get a master degree? Where can I go to network other than cold email? Do certifications help?", "author_fullname": "t2_6cbsdgdj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Moving to Big Tech from big government contractor", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a9bma", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697578283.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all,&lt;/p&gt;\n\n&lt;p&gt;I work at one of the big 4 consulting companies as a data scientist on their public sector accounts( with security clearance). I was a campus hire who started this year but I had a solid year of experience as a data science intern at a small tech company.  My bachelor degree was in statistics.&lt;/p&gt;\n\n&lt;p&gt;I want to move to a data science or data analyst positions at big tech companies. I mainly want to work in analytics and data engineering. How many years of experience would I need to have a decent change?what would you recommend to increase my odds? Should I get a master degree? Where can I go to network other than cold email? Do certifications help?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a9bma", "is_robot_indexable": true, "report_reasons": null, "author": "Administrative_Bar46", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a9bma/moving_to_big_tech_from_big_government_contractor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a9bma/moving_to_big_tech_from_big_government_contractor/", "subreddit_subscribers": 1089222, "created_utc": 1697578283.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHello, fellow data science enthusiasts! I'm participating in some machine learning competitions and I'm looking for insights on the strengths and weaknesses of various ML algorithms, along with their ideal use cases. This will help me choose the most suitable model for my competition tasks. Your expert opinions would be highly valuable!\n\n1. Could you please share your thoughts on the strengths and weaknesses of different ML algorithms, considering factors like accuracy, interpretability, computational requirements, etc.?\n2. What are some specific use cases or scenarios where certain ML algorithms excel? For example, which algorithms are best for image classification, natural language processing, or time series forecasting?\n3. Are there any resources, articles, or books that you would recommend for a deeper understanding of ML algorithm selection?\n\nYour insights will be greatly appreciated and will aid me in making more informed decisions for my competition endeavors. Thanks in advance!\"", "author_fullname": "t2_hhycptpk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Seeking Advice on Machine Learning Algorithm Selection for Competitions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a6t46", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697571824.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, fellow data science enthusiasts! I&amp;#39;m participating in some machine learning competitions and I&amp;#39;m looking for insights on the strengths and weaknesses of various ML algorithms, along with their ideal use cases. This will help me choose the most suitable model for my competition tasks. Your expert opinions would be highly valuable!&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Could you please share your thoughts on the strengths and weaknesses of different ML algorithms, considering factors like accuracy, interpretability, computational requirements, etc.?&lt;/li&gt;\n&lt;li&gt;What are some specific use cases or scenarios where certain ML algorithms excel? For example, which algorithms are best for image classification, natural language processing, or time series forecasting?&lt;/li&gt;\n&lt;li&gt;Are there any resources, articles, or books that you would recommend for a deeper understanding of ML algorithm selection?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Your insights will be greatly appreciated and will aid me in making more informed decisions for my competition endeavors. Thanks in advance!&amp;quot;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a6t46", "is_robot_indexable": true, "report_reasons": null, "author": "After_Reception1696", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a6t46/seeking_advice_on_machine_learning_algorithm/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a6t46/seeking_advice_on_machine_learning_algorithm/", "subreddit_subscribers": 1089222, "created_utc": 1697571824.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "**TL;DR:**\n\nBelow, I describe the info I'm tracking, and an algorithm I want to follow to produce a model that shows which factors matter and which don't. **My question is, does this algorithm already exist in some code library?** Or do I have to code it myself?\n\n**Background:**\n\nI've been keeping a spreadsheet of my sleep habits and energy levels for the last 60 days. I have looked a bit at simple correlations -- the highest correlation so far is (no surprise) the correlation between the number of hours a night I have been sleeping recently, and the energy level I feel in the morning. Other correlations, like drinks of alcohol or caffeine, are lower, but I wonder if they would show a stronger effect if I controlled for other factors.\n\n**Regression algorithm:**\n\nI used to work at a data science company where we would run studies we called \"regression hill climbs\", where we would iterate like this:\n\n1. identify the output factor (AKA \"dependent variable\"); in this case, it would be energy level on a given day\n2. for every input factor (AKA \"independent variable\", e.g. whether I taped my mouth shut the night before), calculate the correlations between it and each other input factor\n3. start with an empty \"model\", a set of independent variables\n4. start with a correlation between model and dependent variable of 0\n5. repeat until no more variables are selected to add to the model:\n   1. filter all candidate independent variables, omitting any with too high a correlation to any of the already selected variables in the model (e.g., must be under a threshold of 0.3; this avoids over-fitting) \n   2. of all remaining candidate independent variables, try adding each to the model, and running a new regression on the model's variables (to best predict the dependent variable)\n   3. select the candidate independent variable that most increased the resulting correlation between model and dependent variable, if and only if the increase is above some threshold (e.g., .02 improvement in correlation)\n\nThis results in a model whose total number of independent variables is small, where each is not influenced too much by the others, and where you can see how significant it is (and whether it is positive or negative!). \n\n**Why it matters:**\n\nFor instance, if I have nights where I'm more disciplined overall -- say, when I don't drink, I go to bed early, I set up my CPAP machine and use it all night, etc. -- it might turn out that there's a high (negative) correlation between drinking and sleep quality, but the model may omit alcohol as a variable because its value is really just captured entirely in hours of sleep and in CPAP compliance.\n\nOr, maybe, even taking these things into account, drinking alcohol does consistently disturb my sleep quality, and I should stop. Or maybe it has a slight positive effect! The point is, it's very hard to isolate it as a factor; this algorithm helps.\n\n**What I'm looking for:**\n\nA code library -- presumably in python -- that is built to perform such a \"regression hill climb\", and allow for the various thresholds and other settings to be specified.\n\nDoes anyone know of such a library? Or, is there something different I should do, or some way I'm misunderstanding the problem?\n\nThanks!", "author_fullname": "t2_1why", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Q: How to extract learnings from my spreadsheets, beyond simple correlations?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17a2wb4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697561640.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;Below, I describe the info I&amp;#39;m tracking, and an algorithm I want to follow to produce a model that shows which factors matter and which don&amp;#39;t. &lt;strong&gt;My question is, does this algorithm already exist in some code library?&lt;/strong&gt; Or do I have to code it myself?&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve been keeping a spreadsheet of my sleep habits and energy levels for the last 60 days. I have looked a bit at simple correlations -- the highest correlation so far is (no surprise) the correlation between the number of hours a night I have been sleeping recently, and the energy level I feel in the morning. Other correlations, like drinks of alcohol or caffeine, are lower, but I wonder if they would show a stronger effect if I controlled for other factors.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Regression algorithm:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;I used to work at a data science company where we would run studies we called &amp;quot;regression hill climbs&amp;quot;, where we would iterate like this:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;identify the output factor (AKA &amp;quot;dependent variable&amp;quot;); in this case, it would be energy level on a given day&lt;/li&gt;\n&lt;li&gt;for every input factor (AKA &amp;quot;independent variable&amp;quot;, e.g. whether I taped my mouth shut the night before), calculate the correlations between it and each other input factor&lt;/li&gt;\n&lt;li&gt;start with an empty &amp;quot;model&amp;quot;, a set of independent variables&lt;/li&gt;\n&lt;li&gt;start with a correlation between model and dependent variable of 0&lt;/li&gt;\n&lt;li&gt;repeat until no more variables are selected to add to the model:\n\n&lt;ol&gt;\n&lt;li&gt;filter all candidate independent variables, omitting any with too high a correlation to any of the already selected variables in the model (e.g., must be under a threshold of 0.3; this avoids over-fitting) &lt;/li&gt;\n&lt;li&gt;of all remaining candidate independent variables, try adding each to the model, and running a new regression on the model&amp;#39;s variables (to best predict the dependent variable)&lt;/li&gt;\n&lt;li&gt;select the candidate independent variable that most increased the resulting correlation between model and dependent variable, if and only if the increase is above some threshold (e.g., .02 improvement in correlation)&lt;/li&gt;\n&lt;/ol&gt;&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;This results in a model whose total number of independent variables is small, where each is not influenced too much by the others, and where you can see how significant it is (and whether it is positive or negative!). &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Why it matters:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;For instance, if I have nights where I&amp;#39;m more disciplined overall -- say, when I don&amp;#39;t drink, I go to bed early, I set up my CPAP machine and use it all night, etc. -- it might turn out that there&amp;#39;s a high (negative) correlation between drinking and sleep quality, but the model may omit alcohol as a variable because its value is really just captured entirely in hours of sleep and in CPAP compliance.&lt;/p&gt;\n\n&lt;p&gt;Or, maybe, even taking these things into account, drinking alcohol does consistently disturb my sleep quality, and I should stop. Or maybe it has a slight positive effect! The point is, it&amp;#39;s very hard to isolate it as a factor; this algorithm helps.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;What I&amp;#39;m looking for:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;A code library -- presumably in python -- that is built to perform such a &amp;quot;regression hill climb&amp;quot;, and allow for the various thresholds and other settings to be specified.&lt;/p&gt;\n\n&lt;p&gt;Does anyone know of such a library? Or, is there something different I should do, or some way I&amp;#39;m misunderstanding the problem?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17a2wb4", "is_robot_indexable": true, "report_reasons": null, "author": "brw12", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17a2wb4/q_how_to_extract_learnings_from_my_spreadsheets/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17a2wb4/q_how_to_extract_learnings_from_my_spreadsheets/", "subreddit_subscribers": 1089222, "created_utc": 1697561640.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey Guys,  \nIt seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo'd vector dbs.   \n\n\nDo you guys think there's any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone's raving about today)  \n\n\n\\-  \n\n\nFor context, I'm building a social media product we're users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche's classification string. Essentially we're aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. ", "author_fullname": "t2_13im86", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Shared Public Contextual Database for RAG", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_179z4yq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697551500.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey Guys,&lt;br/&gt;\nIt seems RAG is really taking off as an increasingly popular use case for LLMs to leverage contextual data. However, everybody is building their own contextual data sets and embedding them in their own silo&amp;#39;d vector dbs.   &lt;/p&gt;\n\n&lt;p&gt;Do you guys think there&amp;#39;s any utility in having a shared public vector db that anyone can tap into their API, without having to self-host, worry about the embedding pipelines and filling the vector db with enough data in the first place for their use cases? Would this save devs alot of time in quickly testing testing product ideas? (albeit it does seem that propriety data is what everyone&amp;#39;s raving about today)  &lt;/p&gt;\n\n&lt;p&gt;-  &lt;/p&gt;\n\n&lt;p&gt;For context, I&amp;#39;m building a social media product we&amp;#39;re users can upload a few pieces (approx 10) of content (social media posts, websites, videos to start with), which becomes the verified human-curated list/Niche. We then classify and embed this into a vector db. From this, we have set up a data pipeline to scrape the web and find new content that is most similar which we suggest to users to add to the Niche (upvote, downvote style). When a piece of content is upvoted on its added to the verified list updating the Niche&amp;#39;s classification string. Essentially we&amp;#39;re aiming to construct an ever-growing, user-curated, contextually classified vector database from a relatively small set of sample data. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "179z4yq", "is_robot_indexable": true, "report_reasons": null, "author": "niksteel123", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/179z4yq/shared_public_contextual_database_for_rag/", "subreddit_subscribers": 1089222, "created_utc": 1697551500.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_baajg5kk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to Build Data Products? Deploy: Part 3/4 - Doubling down on the power of Unified Experiences", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "tooling", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_179ykfd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Tooling", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/fIAPxsCawPBu-N75Vvoyg_keOmRvMjS4W4feJpzH2AE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697549881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "moderndata101.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://moderndata101.substack.com/p/how-to-build-data-products-deploy", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?auto=webp&amp;s=ea619a7c524f8c5536cc06f8b13ba792caddd5b5", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=66add8fac528d26de7feccdd0c5022d39fd89850", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=85446cd271d715b3865f735be872ce747366b093", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=929b190abb183f4784a7d725a150dbb2083ba894", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e4c400d8251d52d7421fc6640499a17ea524db3", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=5e716ed51284478d9d2a2569fdf859fe895fdf91", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/XZbtq-aQh02nKdrMzpZYd3-viI17NIEpazgIpUJ0liI.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5219b40b806ce0099e4650da1d92ec438c0e19d8", "width": 1080, "height": 540}], "variants": {}, "id": "_WJ_OVW7dv_Q8Y2muH3UxiO88vjiOO6xTcwW1zV8-tA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "aaf5d8cc-d780-11e7-a4a5-0e68d01eab56", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "179ykfd", "is_robot_indexable": true, "report_reasons": null, "author": "growth_man", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/179ykfd/how_to_build_data_products_deploy_part_34/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://moderndata101.substack.com/p/how-to-build-data-products-deploy", "subreddit_subscribers": 1089222, "created_utc": 1697549881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "", "author_fullname": "t2_8bcezw1t6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's happened to global aviation over the last 30 years? \u27a1\ufe0fPassenger demand quadrupled (until COVID) \u27a1\ufe0fNo change in carbon intensity of fuel (still using jet fuel) \u27a1\ufe0f Energy intensity halved \u27a1\ufe0f This means emissions approx. doubhttps://www.sustainabilitybynumbers.com/p/aviation-climate-part-one", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "network", "downs": 0, "thumbnail_height": 102, "top_awarded_type": null, "hide_score": true, "name": "t3_17ao0hq", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Networking", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/eCLB1p-5omAyQy2osaSPD12WrW9dV8hF7TrmlLb2q20.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697626991.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/y451stbm0yub1.jpg", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/y451stbm0yub1.jpg?auto=webp&amp;s=38da725428d67ea30551859e9c958be2bf5049d2", "width": 1044, "height": 768}, "resolutions": [{"url": "https://preview.redd.it/y451stbm0yub1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=43bef6edc711f4be462ddaad094f74a0fac8a43e", "width": 108, "height": 79}, {"url": "https://preview.redd.it/y451stbm0yub1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=143aa751c882350b350f5d449cc9cef2d4ef005a", "width": 216, "height": 158}, {"url": "https://preview.redd.it/y451stbm0yub1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f12483a7729cd4df7e96545ab544e6ab206bd986", "width": 320, "height": 235}, {"url": "https://preview.redd.it/y451stbm0yub1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=02f7fc90a8c24211112c17916e7aeaa90109c13e", "width": 640, "height": 470}, {"url": "https://preview.redd.it/y451stbm0yub1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b1bb3a2c75f568b940576ea68bc166cf503f6382", "width": 960, "height": 706}], "variants": {}, "id": "fJ4TbtIICnIpUxPruN8aVaVE_isvolIPVhNbd60-aDs"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "8addf236-d780-11e7-932d-0e90af9dfe6e", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "", "id": "17ao0hq", "is_robot_indexable": true, "report_reasons": null, "author": "neboair", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ao0hq/whats_happened_to_global_aviation_over_the_last/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/y451stbm0yub1.jpg", "subreddit_subscribers": 1089222, "created_utc": 1697626991.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " I'm about to graduate with a Master of Data Science from one of the top 5 universities in Australia. I am in my final few units with a 4.00 GPA - High Distinctions in every unit. Additionally, I have 2 years of experience as a Data Analyst in the supply chain domain.\n\nI'm currently exploring career opportunities in the US and other international locations. I'm curious if there are well-known companies that frequently interview international candidates who are willing to relocate for the role. Any advice or recommendations would be greatly appreciated!\n\nThank you in advance!", "author_fullname": "t2_cvvcrwpx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Graduate US/International Career Opportunities", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_17amx3l", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697622838.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m about to graduate with a Master of Data Science from one of the top 5 universities in Australia. I am in my final few units with a 4.00 GPA - High Distinctions in every unit. Additionally, I have 2 years of experience as a Data Analyst in the supply chain domain.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m currently exploring career opportunities in the US and other international locations. I&amp;#39;m curious if there are well-known companies that frequently interview international candidates who are willing to relocate for the role. Any advice or recommendations would be greatly appreciated!&lt;/p&gt;\n\n&lt;p&gt;Thank you in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17amx3l", "is_robot_indexable": true, "report_reasons": null, "author": "CanberraMogul", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17amx3l/graduate_usinternational_career_opportunities/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17amx3l/graduate_usinternational_career_opportunities/", "subreddit_subscribers": 1089222, "created_utc": 1697622838.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Hey guys, what are some of the best library or libraries to use to make a voice conservational AI chatbot? \n\nI googled around and found Vocode. They look pretty good. However Vocode rely on several other (paid) closed sourced libraries such as Deepgram (for transcribing) and Azure AI Speech (for synthesising). Are there any other libraries/frameworks available out there which are completely or more open sourced?", "author_fullname": "t2_f1x3eywqz", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some of the best library frameworks to use for speech2text and text2speech AI chatbot", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17al56s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697615321.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey guys, what are some of the best library or libraries to use to make a voice conservational AI chatbot? &lt;/p&gt;\n\n&lt;p&gt;I googled around and found Vocode. They look pretty good. However Vocode rely on several other (paid) closed sourced libraries such as Deepgram (for transcribing) and Azure AI Speech (for synthesising). Are there any other libraries/frameworks available out there which are completely or more open sourced?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17al56s", "is_robot_indexable": true, "report_reasons": null, "author": "redd-dev", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17al56s/what_are_some_of_the_best_library_frameworks_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17al56s/what_are_some_of_the_best_library_frameworks_to/", "subreddit_subscribers": 1089222, "created_utc": 1697615321.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "Anyone done something on XAI where you use SHAP and Anchor model to explain your model?\n\nI implementes Shap to predict the next day event but find it a bit confusing using Anchor or Lime to do so", "author_fullname": "t2_l6htd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What's the best way to implement Shaq and Anchor (XAI) techniques", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ajf0e", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697608224.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Anyone done something on XAI where you use SHAP and Anchor model to explain your model?&lt;/p&gt;\n\n&lt;p&gt;I implementes Shap to predict the next day event but find it a bit confusing using Anchor or Lime to do so&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17ajf0e", "is_robot_indexable": true, "report_reasons": null, "author": "IamFromNigeria", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ajf0e/whats_the_best_way_to_implement_shaq_and_anchor/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ajf0e/whats_the_best_way_to_implement_shaq_and_anchor/", "subreddit_subscribers": 1089222, "created_utc": 1697608224.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "So I am a new grad that graduated from my bachelors in May 2023. I just started a data analyst/consultant position at a company in August. However, I really don't get along with the work culture here. My question is, if I am applying for jobs (entry level/ new grad) now, should I include my current job on my resume?\n\nI see there are 3 different options:\n\n1. Apply for jobs without my current job on resume (so that interviewer doesn't know I am leaving this job so soon)\n2. Apply with my current job and hope to have a chance to explain why I am leaving so soon\n3. Tough it out for some more time before applying for new jobs (ideally I would not like to take this option)\n\nWhich option would you all recommend?", "author_fullname": "t2_23wcaiel", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "job switch advice", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17ahr58", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697602077.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I am a new grad that graduated from my bachelors in May 2023. I just started a data analyst/consultant position at a company in August. However, I really don&amp;#39;t get along with the work culture here. My question is, if I am applying for jobs (entry level/ new grad) now, should I include my current job on my resume?&lt;/p&gt;\n\n&lt;p&gt;I see there are 3 different options:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Apply for jobs without my current job on resume (so that interviewer doesn&amp;#39;t know I am leaving this job so soon)&lt;/li&gt;\n&lt;li&gt;Apply with my current job and hope to have a chance to explain why I am leaving so soon&lt;/li&gt;\n&lt;li&gt;Tough it out for some more time before applying for new jobs (ideally I would not like to take this option)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Which option would you all recommend?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17ahr58", "is_robot_indexable": true, "report_reasons": null, "author": "confused_student2019", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17ahr58/job_switch_advice/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17ahr58/job_switch_advice/", "subreddit_subscribers": 1089222, "created_utc": 1697602077.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": "I\u2019m looking to clustering on a dimensionally reduced dataset of 3D vectors. I\u2019ve tried using kmeans mini batches but the problem is that the visualization of the labelled data is not what I\u2019m looking for. I also tried using dbscan but I\u2019ve ran into performance issues where I run out of memory. For reference the dataset is over 100k rows and in the future I\u2019d like to use a similar clustering approach for gigabytes worth of data. Any alternatives or advice will be greatly appreciated.", "author_fullname": "t2_2pxniisp", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Performance issues with dbscan", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17adx4s", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697590581.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m looking to clustering on a dimensionally reduced dataset of 3D vectors. I\u2019ve tried using kmeans mini batches but the problem is that the visualization of the labelled data is not what I\u2019m looking for. I also tried using dbscan but I\u2019ve ran into performance issues where I run out of memory. For reference the dataset is over 100k rows and in the future I\u2019d like to use a similar clustering approach for gigabytes worth of data. Any alternatives or advice will be greatly appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4fad7108-d77d-11e7-b0c6-0ee69f155af2", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17adx4s", "is_robot_indexable": true, "report_reasons": null, "author": "spx416", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17adx4s/performance_issues_with_dbscan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17adx4s/performance_issues_with_dbscan/", "subreddit_subscribers": 1089222, "created_utc": 1697590581.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "datascience", "selftext": " \n\nHey!\n\n**Startup:**\n\n\\- Apply Script dot com \"Connect business and data professionals via pre-recorded standardized video interviews.\"\n\n**More details:**\n\n**Problems with Traditional Hiring**\n\n\\- Outdated: The current method of conducting interviews has become overly complex and outdated.\n\n\\- Time-Wasting: The process involves too many appointments, meetings, and stages, leading to communication errors.\n\n\\- Expensive: The man-hours invested by HR and engineering teams are costly.\n\n\\- Constraining: Interviews are fixed to specific times and locations.\n\n\\- Cumbersome: The experience is challenging for both businesses and professionals.\n\n**Our Solution**\n\n\\+ Talent Identification: We find top talent that matches your job post.\n\n\\+ Standardized Interviews: Professionals standardized pre-record their interviews (apples to apples comparison), covering areas such as CV, personality questions, project presentations, theory questions, coding tests, and hobbies.\n\n\\+ Efficiency: Businesses receive a pre-filtered batch of top applicants with their interviews ready for viewing.\n\n\\+ Time-Saving: Professionals can apply and businesses can employ candidates more quickly than with traditional methods.\n\n\\+ Reduced Workload: Minimize time spent reviewing applications; all interviews are pre-recorded.\n\n\\+ Flexibility: Managers can watch, speed up, or rewind interviews at their convenience.\n\n\\+ Transparency: Applicants receive immediate feedback on their applications to avoid being \"ghosted.\"\n\n**Life cycle stage:**\n\n\\- Validation: Currently looking to run our\u00a0***#1st pilot B2B***\u00a0with our first client.\n\n**My role:**\n\n\\- Founder\n\n**Goals for this month:**\n\n\\- Secure my first client for the pilot.\n\n\\- Obtain feedback from both the employee and business sides.\n\n\\- Optimize the product based on the feedback received.\n\n**How can I** **help?**\n\n\\- I am searching for a business, that wants to streamline and accelerate the hiring of top data professionals (ex.: Data Scientist, Machine Learning Engineer, Data Engineer, Data Analyst) in the USA.\n\n\\- in the USA.\n\nThx for the feedback ;)", "author_fullname": "t2_qrm5o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feedback on my MVP project - Pre-Recorded Standardized Video Interviews Job Site for Data Professionals", "link_flair_richtext": [], "subreddit_name_prefixed": "r/datascience", "hidden": false, "pwls": 6, "link_flair_css_class": "projects", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17aba8j", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Projects", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697583330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.datascience", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey!&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Startup:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- Apply Script dot com &amp;quot;Connect business and data professionals via pre-recorded standardized video interviews.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;More details:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Problems with Traditional Hiring&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- Outdated: The current method of conducting interviews has become overly complex and outdated.&lt;/p&gt;\n\n&lt;p&gt;- Time-Wasting: The process involves too many appointments, meetings, and stages, leading to communication errors.&lt;/p&gt;\n\n&lt;p&gt;- Expensive: The man-hours invested by HR and engineering teams are costly.&lt;/p&gt;\n\n&lt;p&gt;- Constraining: Interviews are fixed to specific times and locations.&lt;/p&gt;\n\n&lt;p&gt;- Cumbersome: The experience is challenging for both businesses and professionals.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Our Solution&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;+ Talent Identification: We find top talent that matches your job post.&lt;/p&gt;\n\n&lt;p&gt;+ Standardized Interviews: Professionals standardized pre-record their interviews (apples to apples comparison), covering areas such as CV, personality questions, project presentations, theory questions, coding tests, and hobbies.&lt;/p&gt;\n\n&lt;p&gt;+ Efficiency: Businesses receive a pre-filtered batch of top applicants with their interviews ready for viewing.&lt;/p&gt;\n\n&lt;p&gt;+ Time-Saving: Professionals can apply and businesses can employ candidates more quickly than with traditional methods.&lt;/p&gt;\n\n&lt;p&gt;+ Reduced Workload: Minimize time spent reviewing applications; all interviews are pre-recorded.&lt;/p&gt;\n\n&lt;p&gt;+ Flexibility: Managers can watch, speed up, or rewind interviews at their convenience.&lt;/p&gt;\n\n&lt;p&gt;+ Transparency: Applicants receive immediate feedback on their applications to avoid being &amp;quot;ghosted.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Life cycle stage:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- Validation: Currently looking to run our\u00a0&lt;strong&gt;&lt;em&gt;#1st pilot B2B&lt;/em&gt;&lt;/strong&gt;\u00a0with our first client.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;My role:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- Founder&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Goals for this month:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- Secure my first client for the pilot.&lt;/p&gt;\n\n&lt;p&gt;- Obtain feedback from both the employee and business sides.&lt;/p&gt;\n\n&lt;p&gt;- Optimize the product based on the feedback received.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;How can I&lt;/strong&gt; &lt;strong&gt;help?&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;- I am searching for a business, that wants to streamline and accelerate the hiring of top data professionals (ex.: Data Scientist, Machine Learning Engineer, Data Engineer, Data Analyst) in the USA.&lt;/p&gt;\n\n&lt;p&gt;- in the USA.&lt;/p&gt;\n\n&lt;p&gt;Thx for the feedback ;)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": "confidence", "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "937a6f50-d780-11e7-826d-0ed1beddcc82", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2sptq", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "", "id": "17aba8j", "is_robot_indexable": true, "report_reasons": null, "author": "glassAlloy", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/datascience/comments/17aba8j/feedback_on_my_mvp_project_prerecorded/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/datascience/comments/17aba8j/feedback_on_my_mvp_project_prerecorded/", "subreddit_subscribers": 1089222, "created_utc": 1697583330.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}