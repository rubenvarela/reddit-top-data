{"kind": "Listing", "data": {"after": "t3_177sl07", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently had a failure on my working drive (an external hard drive... yeah I know) which led me to *almost* lose important data if weren't for very good data recovery.  \n\n\nI'm now here looking for advice on setting up a storage solution that is more resilient for my data. I occasionally work with large video/audio projects so whatever solution would need to be quick enough to edit from. I have a mac mini with a 10gb ethernet connection. Realistically I only need to access like 8GB of storage, and everything else could be moved to long term backups.\n\nThank you guys so much!\n\n&amp;#x200B;", "author_fullname": "t2_2z5oulej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Had my first data loss scare, and now I'm here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177b9j0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 24, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 24, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697238004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently had a failure on my working drive (an external hard drive... yeah I know) which led me to &lt;em&gt;almost&lt;/em&gt; lose important data if weren&amp;#39;t for very good data recovery.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m now here looking for advice on setting up a storage solution that is more resilient for my data. I occasionally work with large video/audio projects so whatever solution would need to be quick enough to edit from. I have a mac mini with a 10gb ethernet connection. Realistically I only need to access like 8GB of storage, and everything else could be moved to long term backups.&lt;/p&gt;\n\n&lt;p&gt;Thank you guys so much!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177b9j0", "is_robot_indexable": true, "report_reasons": null, "author": "Sttql", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177b9j0/had_my_first_data_loss_scare_and_now_im_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177b9j0/had_my_first_data_loss_scare_and_now_im_here/", "subreddit_subscribers": 706698, "created_utc": 1697238004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "This may not be applicable to all, but the scenario is: you die tomorrow, what are the chances that your wife / significant other will have the slightest clue what is even on your devices / external drives? Or how to get access to important things such as family photos or important documents?\n\n Or, are they all just getting lumped in a box and sold off at an estate sale eventually?\n\nI had the realisation the other day, that if i was hit by a car tomorrow - My Wife, who isn\u2019t technically minded at all, (e.g. her phone runs out of space regularly, i get handed the phone, i back everything up, she gets it back an hour later), i don\u2019t think she would just get all my harddrives and chuck them out or sell them instantly, but everything is \u2018organised\u2019 (if you can even call it that) in such a mish-mash way that she\u2019d have one hell of a problem trying to get family photos or whatever with my prior data storage setup.\n\n So i decided to change things around a bit in the hopes that she\u2019ll have a fighting chance of knowing how the hell to work things. Now i have things organised properly, individual harddrive codename identifiers, copies of spreadsheets and \u2018read-me\u2019 files on every drives top-level folder explaining the organisation process and how to access things with certain programs, multiple backup copes, and a master-backup copy kept safe in an off-site location, all explained in files present on every single drive, along with print outs kept with the drives. We\u2019ve also had a talk and i\u2019ve basically said \u201cif anything happens, just plug one of them in and read the files/print outs, to know where everything is kept.\n\nHave any of you ever had this thought and how have you gone about handling the issue?", "author_fullname": "t2_5blmseag", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is your \u2018I\u2019m dead\u2019 plan?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_177s5fs", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697297553.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This may not be applicable to all, but the scenario is: you die tomorrow, what are the chances that your wife / significant other will have the slightest clue what is even on your devices / external drives? Or how to get access to important things such as family photos or important documents?&lt;/p&gt;\n\n&lt;p&gt;Or, are they all just getting lumped in a box and sold off at an estate sale eventually?&lt;/p&gt;\n\n&lt;p&gt;I had the realisation the other day, that if i was hit by a car tomorrow - My Wife, who isn\u2019t technically minded at all, (e.g. her phone runs out of space regularly, i get handed the phone, i back everything up, she gets it back an hour later), i don\u2019t think she would just get all my harddrives and chuck them out or sell them instantly, but everything is \u2018organised\u2019 (if you can even call it that) in such a mish-mash way that she\u2019d have one hell of a problem trying to get family photos or whatever with my prior data storage setup.&lt;/p&gt;\n\n&lt;p&gt;So i decided to change things around a bit in the hopes that she\u2019ll have a fighting chance of knowing how the hell to work things. Now i have things organised properly, individual harddrive codename identifiers, copies of spreadsheets and \u2018read-me\u2019 files on every drives top-level folder explaining the organisation process and how to access things with certain programs, multiple backup copes, and a master-backup copy kept safe in an off-site location, all explained in files present on every single drive, along with print outs kept with the drives. We\u2019ve also had a talk and i\u2019ve basically said \u201cif anything happens, just plug one of them in and read the files/print outs, to know where everything is kept.&lt;/p&gt;\n\n&lt;p&gt;Have any of you ever had this thought and how have you gone about handling the issue?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177s5fs", "is_robot_indexable": true, "report_reasons": null, "author": "jacspe", "discussion_type": null, "num_comments": 28, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177s5fs/what_is_your_im_dead_plan/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177s5fs/what_is_your_im_dead_plan/", "subreddit_subscribers": 706698, "created_utc": 1697297553.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I put this old disk into my PC thinking I could copy the data from it onto the PC. it then prompted \"How do you want to use this disk?\" It didnt say anything about reformatting the disk and I realized too late, it started the formatting process. I stopped it a few seconds after it began but now the dvd isnt even playing on my dvd player.\n\nis there anything I can do to recover the home movies? And I have other disks of the same format, how do I go about saving them digitally?", "author_fullname": "t2_4chk9t7t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recovering old home movies from DVD+r", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177261i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697213097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I put this old disk into my PC thinking I could copy the data from it onto the PC. it then prompted &amp;quot;How do you want to use this disk?&amp;quot; It didnt say anything about reformatting the disk and I realized too late, it started the formatting process. I stopped it a few seconds after it began but now the dvd isnt even playing on my dvd player.&lt;/p&gt;\n\n&lt;p&gt;is there anything I can do to recover the home movies? And I have other disks of the same format, how do I go about saving them digitally?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177261i", "is_robot_indexable": true, "report_reasons": null, "author": "s-atch", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177261i/recovering_old_home_movies_from_dvdr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177261i/recovering_old_home_movies_from_dvdr/", "subreddit_subscribers": 706698, "created_utc": 1697213097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hey all, i'm looking into a way to switch from regular zip/7z archives to something more robust and reliable. Some years ago i accidentally shifted one of my drives that caused a lot of the media files inside of it get garbled but somehow still able to play back. I'm looking into a way to recover my archives in case something like this ever happens again.  \n\n\nThe idea comes from Nero's secure disk feature where you can keep a bit of space for this feature and it will save some data in the CD/DVD/BD so in case your medium gets scratched, it can recover it from this area you allocated beforehand (up to a point of course).  \n\n\nI have looked online for something similar like this but no luck so far. This is something a CRC/SHA can't fix as those are for ensuring data integrity, not recovering it after a corruption as far as i know. ", "author_fullname": "t2_w272e6l5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there a way to make self-healing file archives that can recover themselves in case of a corruption?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177qr4m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697293541.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, i&amp;#39;m looking into a way to switch from regular zip/7z archives to something more robust and reliable. Some years ago i accidentally shifted one of my drives that caused a lot of the media files inside of it get garbled but somehow still able to play back. I&amp;#39;m looking into a way to recover my archives in case something like this ever happens again.  &lt;/p&gt;\n\n&lt;p&gt;The idea comes from Nero&amp;#39;s secure disk feature where you can keep a bit of space for this feature and it will save some data in the CD/DVD/BD so in case your medium gets scratched, it can recover it from this area you allocated beforehand (up to a point of course).  &lt;/p&gt;\n\n&lt;p&gt;I have looked online for something similar like this but no luck so far. This is something a CRC/SHA can&amp;#39;t fix as those are for ensuring data integrity, not recovering it after a corruption as far as i know. &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177qr4m", "is_robot_indexable": true, "report_reasons": null, "author": "notrktfier", "discussion_type": null, "num_comments": 31, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177qr4m/is_there_a_way_to_make_selfhealing_file_archives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177qr4m/is_there_a_way_to_make_selfhealing_file_archives/", "subreddit_subscribers": 706698, "created_utc": 1697293541.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! Is there an easy way to recover data from HDD that was installed in a single bay TS-133 NAS? I have a Windows, Ubuntu and a Mac computer. They all see my HDD but cannot access the data. Ubuntu sees data partition as RAID and is also unable to access\n\nAnd a bonus question: is there way to disable RAID completely (since I have only a one bay NAS) so I don\u2019t run into this issue in the future?", "author_fullname": "t2_2or3zqpu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get data off a HDD that was in a Qnap NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177oxk5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697288106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! Is there an easy way to recover data from HDD that was installed in a single bay TS-133 NAS? I have a Windows, Ubuntu and a Mac computer. They all see my HDD but cannot access the data. Ubuntu sees data partition as RAID and is also unable to access&lt;/p&gt;\n\n&lt;p&gt;And a bonus question: is there way to disable RAID completely (since I have only a one bay NAS) so I don\u2019t run into this issue in the future?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177oxk5", "is_robot_indexable": true, "report_reasons": null, "author": "Karmacosmik", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177oxk5/how_to_get_data_off_a_hdd_that_was_in_a_qnap_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177oxk5/how_to_get_data_off_a_hdd_that_was_in_a_qnap_nas/", "subreddit_subscribers": 706698, "created_utc": 1697288106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI have no experience with data backup (better said with huge amount of data backup). I have started editing videos, so I will have a lot of big files in the future. Because of 4K resolution, high bitrate and more versions of the same project, I can create more than 10 TB of video files every month. I want to keep my projects possibly forever. Those files will not be accessed very often, but I would also like to avoid some cold cloud storage where restoring data can take many hours. So files should be accessible quite fast, but on the other hand, they won't be accessed on daily basis. I will have also some databases and 3D engine projects, but those files would be always copied to NVMe SSD when I would work with them.\n\nI have heard about [Sync.com](https://Sync.com) unlimited cloud storage plan, but I don't have any experience with them and I have heard about low upload speeds etc. \n\nSo I am thinking I will need to just keep buying HDDs and save my project backups on those drives. I don't think NAS is needed as data will not be synced between devices and data will be accessed only from time to time. \n\nMy current plan is to buy an external 3.5\" USB HDD docking station for 2 - 4 hard drives and just use it only when I will need to write/read/copy back to faster SSD purposes. And when the free space on the HDD is gone, just switch to another HDD. \n\n\\- What would you recommend to me? Cloud or keep it at home on hard drives?\n\n\\- I was looking at Seagate Exos 20TB Hard drives, do you think is it better to have high capacity drives or better smaller ones (like 6 - 8 TB)?\n\n\\- Does my approach even make any sense? Like I said, I have no experience, so trying to find solution on my own, but if you have better way or some tips for me, I'll be very happy.\n\nThanks!", "author_fullname": "t2_5mazhle4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud vs HDD backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177m6n4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697278042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have no experience with data backup (better said with huge amount of data backup). I have started editing videos, so I will have a lot of big files in the future. Because of 4K resolution, high bitrate and more versions of the same project, I can create more than 10 TB of video files every month. I want to keep my projects possibly forever. Those files will not be accessed very often, but I would also like to avoid some cold cloud storage where restoring data can take many hours. So files should be accessible quite fast, but on the other hand, they won&amp;#39;t be accessed on daily basis. I will have also some databases and 3D engine projects, but those files would be always copied to NVMe SSD when I would work with them.&lt;/p&gt;\n\n&lt;p&gt;I have heard about &lt;a href=\"https://Sync.com\"&gt;Sync.com&lt;/a&gt; unlimited cloud storage plan, but I don&amp;#39;t have any experience with them and I have heard about low upload speeds etc. &lt;/p&gt;\n\n&lt;p&gt;So I am thinking I will need to just keep buying HDDs and save my project backups on those drives. I don&amp;#39;t think NAS is needed as data will not be synced between devices and data will be accessed only from time to time. &lt;/p&gt;\n\n&lt;p&gt;My current plan is to buy an external 3.5&amp;quot; USB HDD docking station for 2 - 4 hard drives and just use it only when I will need to write/read/copy back to faster SSD purposes. And when the free space on the HDD is gone, just switch to another HDD. &lt;/p&gt;\n\n&lt;p&gt;- What would you recommend to me? Cloud or keep it at home on hard drives?&lt;/p&gt;\n\n&lt;p&gt;- I was looking at Seagate Exos 20TB Hard drives, do you think is it better to have high capacity drives or better smaller ones (like 6 - 8 TB)?&lt;/p&gt;\n\n&lt;p&gt;- Does my approach even make any sense? Like I said, I have no experience, so trying to find solution on my own, but if you have better way or some tips for me, I&amp;#39;ll be very happy.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177m6n4", "is_robot_indexable": true, "report_reasons": null, "author": "casstoner27", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177m6n4/cloud_vs_hdd_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177m6n4/cloud_vs_hdd_backup/", "subreddit_subscribers": 706698, "created_utc": 1697278042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First, thank you in advance for any guidance you can provide.\n\nI have a PC with an adaptec 71605 raid controller and 4 [WD80EMAZ](https://www.westerndigital.com/products/internal-drives/wd-red-plus-sata-3-5-hdd?sku=WD10EFRX) (8gb) drives.  Asrock Motherboard (don't recall), 32 gb mem and strong i7 CPU.  Windows 10 pro or 11 (sorry I don't recall and unable to boot to verify).  It has an AMD 6800 Video card.\n\nEverything was working fine (famous last words) until the controller started a high pitch alarm.  I did a standard shutdown through windows.\n\nThought this may be a heat related (explanation as to why below) issue so I opened the case, put a fan on it, and allowed 15 minutes to cool down.Now when I attempt to restart I now get the following message\n\n[https://imgur.com/K1pbyzl](https://imgur.com/K1pbyzl)\n\nThe reason I thought this to be a heat related issue is that 30 days ago, the alarm sounded in the middle of the night.  I truly thought it was one of my smoke detectors and my house was on fire; it was so loud.\n\nThe next day I recreated the load the computer was under (upscaling and enhancing large video files (using Topaz AI) that take 8 to 10 hours to process (thus why I crunch them overnight). \n\nUnder duplicate conditions I found the ADAPTC card to be 115 Degrees F directly being the control chip on the back of the card, so upgraded the heatsink and fans, and running temps under load dropped 20 degrees. \n\nIt has run flawlessly since.\n\nOld heatsink config - [https://imgur.com/6af1ZE5](https://imgur.com/6af1ZE5)\n\nNew Heat Sink - [https://imgur.com/xiUuGWf](https://imgur.com/xiUuGWf)\n\nNew Heat Sink In Place - [https://imgur.com/3lFP0CF](https://imgur.com/3lFP0CF)\n\nMy understanding was with the battery back up, the raid could be recovered. Additionally I have 3 additional identical drives,  a second raid card, and batterback up memory that attaches to the card. These should help to diagnose and fix (I hope).   I kept these just in-case, but realized that I don't have any idea what to do.\n\nMy biggest concern is clicking something incorrectly and losing the information that is there. Some files are irreplaceable.\n\nI have limited knowledge, but smart enough to know this is completely out of my league. Any guidance or suggestions are appreciated.", "author_fullname": "t2_3vzsujkt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Guidance with Adaptec 71605 controller Raid 5 | PLEASE HELP|", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177ltqc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697276446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First, thank you in advance for any guidance you can provide.&lt;/p&gt;\n\n&lt;p&gt;I have a PC with an adaptec 71605 raid controller and 4 &lt;a href=\"https://www.westerndigital.com/products/internal-drives/wd-red-plus-sata-3-5-hdd?sku=WD10EFRX\"&gt;WD80EMAZ&lt;/a&gt; (8gb) drives.  Asrock Motherboard (don&amp;#39;t recall), 32 gb mem and strong i7 CPU.  Windows 10 pro or 11 (sorry I don&amp;#39;t recall and unable to boot to verify).  It has an AMD 6800 Video card.&lt;/p&gt;\n\n&lt;p&gt;Everything was working fine (famous last words) until the controller started a high pitch alarm.  I did a standard shutdown through windows.&lt;/p&gt;\n\n&lt;p&gt;Thought this may be a heat related (explanation as to why below) issue so I opened the case, put a fan on it, and allowed 15 minutes to cool down.Now when I attempt to restart I now get the following message&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/K1pbyzl\"&gt;https://imgur.com/K1pbyzl&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The reason I thought this to be a heat related issue is that 30 days ago, the alarm sounded in the middle of the night.  I truly thought it was one of my smoke detectors and my house was on fire; it was so loud.&lt;/p&gt;\n\n&lt;p&gt;The next day I recreated the load the computer was under (upscaling and enhancing large video files (using Topaz AI) that take 8 to 10 hours to process (thus why I crunch them overnight). &lt;/p&gt;\n\n&lt;p&gt;Under duplicate conditions I found the ADAPTC card to be 115 Degrees F directly being the control chip on the back of the card, so upgraded the heatsink and fans, and running temps under load dropped 20 degrees. &lt;/p&gt;\n\n&lt;p&gt;It has run flawlessly since.&lt;/p&gt;\n\n&lt;p&gt;Old heatsink config - &lt;a href=\"https://imgur.com/6af1ZE5\"&gt;https://imgur.com/6af1ZE5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;New Heat Sink - &lt;a href=\"https://imgur.com/xiUuGWf\"&gt;https://imgur.com/xiUuGWf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;New Heat Sink In Place - &lt;a href=\"https://imgur.com/3lFP0CF\"&gt;https://imgur.com/3lFP0CF&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My understanding was with the battery back up, the raid could be recovered. Additionally I have 3 additional identical drives,  a second raid card, and batterback up memory that attaches to the card. These should help to diagnose and fix (I hope).   I kept these just in-case, but realized that I don&amp;#39;t have any idea what to do.&lt;/p&gt;\n\n&lt;p&gt;My biggest concern is clicking something incorrectly and losing the information that is there. Some files are irreplaceable.&lt;/p&gt;\n\n&lt;p&gt;I have limited knowledge, but smart enough to know this is completely out of my league. Any guidance or suggestions are appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xl_KQWVSIQnEbZ03PuuU3-ePX9iWAtFtY40q3WzXPms.jpg?auto=webp&amp;s=790048748e4980a652609e82a4436043dc40ae0a", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/xl_KQWVSIQnEbZ03PuuU3-ePX9iWAtFtY40q3WzXPms.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=28c465e3200e1c6e6dbb7aa466d611e7dbb77141", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/xl_KQWVSIQnEbZ03PuuU3-ePX9iWAtFtY40q3WzXPms.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=60f3917aff6afee7c055a3d81ac4a0e07026b087", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/xl_KQWVSIQnEbZ03PuuU3-ePX9iWAtFtY40q3WzXPms.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=80a8b3c340fa9abc2c11beeb9d99497c9ab53175", "width": 320, "height": 168}], "variants": {}, "id": "7ViyWioditWLgxrgjxN95siZEUT1Oq4RBzzMQHRlNA0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177ltqc", "is_robot_indexable": true, "report_reasons": null, "author": "eleutherios4u", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177ltqc/need_guidance_with_adaptec_71605_controller_raid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177ltqc/need_guidance_with_adaptec_71605_controller_raid/", "subreddit_subscribers": 706698, "created_utc": 1697276446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, I\u2019ve been scouring the internet and this sub for an answer to this but I haven\u2019t found anything. I\u2019m in the process of trying to backup my external hard drive to another, and after doing some research I decided to give the free trial of Chronosync a try. During my first backup, though, I noticed maybe 10 random files weren\u2019t going through, they refuse to synchronize, and they all give me the error \u201cError: Source Target encountered error: Error Code -19.\u201d I also got the log \u201cFSEvent database problems detected on: Root folder on \u201chard drive\u201d. Everything is fine but your sync tasks may run less than optimally.\u201d and then the synchronize always fails. \n\nHas anyone here used Chronosync and knows what this means? Or maybe does this have nothing to do with Chronosync and more with the select files? I\u2019m just super confused because there doesn\u2019t seem to be anything about those specific files that are different from the many other files that did go through. \n\nI\u2019m new to this kind of thing, so this has stumped me. Does anyone have any ideas or explanation as to why this might be happening? If this is just how backups go I\u2019ll just make sure to keep copies on hand to fill in the gaps, but if it\u2019s something I\u2019m doing wrong I\u2019d really appreciate some guidance.", "author_fullname": "t2_3suov14m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having trouble backing up with Chronosync", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177gqmk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697255408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I\u2019ve been scouring the internet and this sub for an answer to this but I haven\u2019t found anything. I\u2019m in the process of trying to backup my external hard drive to another, and after doing some research I decided to give the free trial of Chronosync a try. During my first backup, though, I noticed maybe 10 random files weren\u2019t going through, they refuse to synchronize, and they all give me the error \u201cError: Source Target encountered error: Error Code -19.\u201d I also got the log \u201cFSEvent database problems detected on: Root folder on \u201chard drive\u201d. Everything is fine but your sync tasks may run less than optimally.\u201d and then the synchronize always fails. &lt;/p&gt;\n\n&lt;p&gt;Has anyone here used Chronosync and knows what this means? Or maybe does this have nothing to do with Chronosync and more with the select files? I\u2019m just super confused because there doesn\u2019t seem to be anything about those specific files that are different from the many other files that did go through. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m new to this kind of thing, so this has stumped me. Does anyone have any ideas or explanation as to why this might be happening? If this is just how backups go I\u2019ll just make sure to keep copies on hand to fill in the gaps, but if it\u2019s something I\u2019m doing wrong I\u2019d really appreciate some guidance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177gqmk", "is_robot_indexable": true, "report_reasons": null, "author": "Expensive_Grape", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177gqmk/having_trouble_backing_up_with_chronosync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177gqmk/having_trouble_backing_up_with_chronosync/", "subreddit_subscribers": 706698, "created_utc": 1697255408.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just bought two 10TB HDD's for a future planned raspberry pi NAS build. I read about softRAID's verify function, so made a start on that as soon as the disks arrived. It's been going for 48 hours and has 30 hours remaining. However, (stupidly, I know) I only just read softRAID's [installation instructions](https://softraid.com/docs/softraid-quick-start-guide/installation-macos/additional-steps-for-apple-silicon-macs/) for apple silicon macs. Apparently I was supposed to enable reduced security and enable full disk access?\n\nMy question is, does this matter for the verify function on external hdd's in an OWC Mercury Pro Dual enclosure, connected via USB? Have I wasted the 48-hours it's taken thus far and need to start again with the proper installation method?\n\nI didn't get any issues pop up during the installation, I restarted the mac as softRAID requested, and it never said I needed to enable reduced security or full disk access. Nor have there been any errors during the verify function, it seems to be going fine so far. I'm hoping that I haven't wasted my time, and that those functions are only needed if I actually then went on to create a software RAID, or else run those functions on the system ssd?", "author_fullname": "t2_1996co4u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have I wasted my time with SoftRAID's certify?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1778pc4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697231120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just bought two 10TB HDD&amp;#39;s for a future planned raspberry pi NAS build. I read about softRAID&amp;#39;s verify function, so made a start on that as soon as the disks arrived. It&amp;#39;s been going for 48 hours and has 30 hours remaining. However, (stupidly, I know) I only just read softRAID&amp;#39;s &lt;a href=\"https://softraid.com/docs/softraid-quick-start-guide/installation-macos/additional-steps-for-apple-silicon-macs/\"&gt;installation instructions&lt;/a&gt; for apple silicon macs. Apparently I was supposed to enable reduced security and enable full disk access?&lt;/p&gt;\n\n&lt;p&gt;My question is, does this matter for the verify function on external hdd&amp;#39;s in an OWC Mercury Pro Dual enclosure, connected via USB? Have I wasted the 48-hours it&amp;#39;s taken thus far and need to start again with the proper installation method?&lt;/p&gt;\n\n&lt;p&gt;I didn&amp;#39;t get any issues pop up during the installation, I restarted the mac as softRAID requested, and it never said I needed to enable reduced security or full disk access. Nor have there been any errors during the verify function, it seems to be going fine so far. I&amp;#39;m hoping that I haven&amp;#39;t wasted my time, and that those functions are only needed if I actually then went on to create a software RAID, or else run those functions on the system ssd?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qOUvtwV5CN77I71A6XKclfqf2UsUiwy-xoqsF2-EiR0.jpg?auto=webp&amp;s=423402e9367bd885d07409ef7a9617bdead7b336", "width": 396, "height": 347}, "resolutions": [{"url": "https://external-preview.redd.it/qOUvtwV5CN77I71A6XKclfqf2UsUiwy-xoqsF2-EiR0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2d97c40fbb06a698a296a193fa171244fcfba80b", "width": 108, "height": 94}, {"url": "https://external-preview.redd.it/qOUvtwV5CN77I71A6XKclfqf2UsUiwy-xoqsF2-EiR0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=92ac229ae2124a66e776916b3e28f3e72b27ecf8", "width": 216, "height": 189}, {"url": "https://external-preview.redd.it/qOUvtwV5CN77I71A6XKclfqf2UsUiwy-xoqsF2-EiR0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=62b62bac7cbc2b2d89979dbb0ec5f1a48fb9c470", "width": 320, "height": 280}], "variants": {}, "id": "l91vH6H_gPkAl-Fao9OhwbWPE8gEeq8Tko0sx2_tToI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1778pc4", "is_robot_indexable": true, "report_reasons": null, "author": "IIb-dII", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1778pc4/have_i_wasted_my_time_with_softraids_certify/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1778pc4/have_i_wasted_my_time_with_softraids_certify/", "subreddit_subscribers": 706698, "created_utc": 1697231120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I purchased an inexpensive composite to USB video capture device that reportedly works in Linux using OSB   [UVC USB 2.0 Video Capture](https://www.amazon.com/dp/B00RMYWGWC). \n\nI did a fresh install of Ubuntu and Linux Mint and get no video but I do get audio. I tried on my Linux server (Mint) and it works without a problem. Device works fine in Windows on my regular desktop that has the Linux install on it. \n\nI tried OSB and VLC (using Open capture device) but just get errors. Anyone use this or have any ideas as I'm unsure where to ask and I'm trying to digitize all my old VHS tapes so I can get rid of the physical copies).", "author_fullname": "t2_3bdvh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Composite to USB vid capture and Linux", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_177sgv9", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697298493.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I purchased an inexpensive composite to USB video capture device that reportedly works in Linux using OSB   &lt;a href=\"https://www.amazon.com/dp/B00RMYWGWC\"&gt;UVC USB 2.0 Video Capture&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;I did a fresh install of Ubuntu and Linux Mint and get no video but I do get audio. I tried on my Linux server (Mint) and it works without a problem. Device works fine in Windows on my regular desktop that has the Linux install on it. &lt;/p&gt;\n\n&lt;p&gt;I tried OSB and VLC (using Open capture device) but just get errors. Anyone use this or have any ideas as I&amp;#39;m unsure where to ask and I&amp;#39;m trying to digitize all my old VHS tapes so I can get rid of the physical copies).&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177sgv9", "is_robot_indexable": true, "report_reasons": null, "author": "mitzman", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177sgv9/composite_to_usb_vid_capture_and_linux/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177sgv9/composite_to_usb_vid_capture_and_linux/", "subreddit_subscribers": 706698, "created_utc": 1697298493.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't need anything fast and I don't play video games, I just want to regularly back up documents and videos and the like, in case my laptop dies. I'm thinking I don't need anything more than 4 or 5 TB. I gather that a lot of sellers of external hard drives can't be trusted. Is this a reasonable purchase, or are there downsides I'm unaware of?: https://www.microcenter.com/product/618695/seagate-5tb-usb-31-(gen-1-type-a)-25-portable-external-hard-drive-black\n\nThanks!", "author_fullname": "t2_m2z1t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Would this external hard drive be a reasonable purchase to make for someone who just wants to back up data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_177rs5v", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697296496.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t need anything fast and I don&amp;#39;t play video games, I just want to regularly back up documents and videos and the like, in case my laptop dies. I&amp;#39;m thinking I don&amp;#39;t need anything more than 4 or 5 TB. I gather that a lot of sellers of external hard drives can&amp;#39;t be trusted. Is this a reasonable purchase, or are there downsides I&amp;#39;m unaware of?: &lt;a href=\"https://www.microcenter.com/product/618695/seagate-5tb-usb-31-(gen-1-type-a)-25-portable-external-hard-drive-black\"&gt;https://www.microcenter.com/product/618695/seagate-5tb-usb-31-(gen-1-type-a)-25-portable-external-hard-drive-black&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177rs5v", "is_robot_indexable": true, "report_reasons": null, "author": "ncvbn", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177rs5v/would_this_external_hard_drive_be_a_reasonable/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177rs5v/would_this_external_hard_drive_be_a_reasonable/", "subreddit_subscribers": 706698, "created_utc": 1697296496.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Question about Supermicro CSE 864\n\nHi there, sorry for my bad english but it's not my native language.\n\nI own a Supermicro 864 case with 24 bays. All worked fine for over a year bur now there is a problem.\n\nMy server operating system is ubuntu (22 server) and I use docker for application deployment.\n\nUnfourtuantley suddenly streams from Jelleyin (only 4k) beginn to stutter but only if I streamded directly from one particullare hdd. First i thought the hdd is gone put then I put the hdd in another slot (the server is populated with 7 hdd and 3 ssd currently) and all worked fine again :-(.\n\nThe backplane ist the  **SUPERMICRO BPN-SAS2-846EL1 and the sas controller LSI SAS 9207-8i**  . \n\nNow I start to wonder if the backplane is failing or the SAS Controller or something else?\n\nDo you have any idea?\n\nThanks in advance for your help\n\nThis Question was also posted in r/homeserver", "author_fullname": "t2_crbyql2c", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Advice on CSE 864", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_177rogx", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697296206.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Question about Supermicro CSE 864&lt;/p&gt;\n\n&lt;p&gt;Hi there, sorry for my bad english but it&amp;#39;s not my native language.&lt;/p&gt;\n\n&lt;p&gt;I own a Supermicro 864 case with 24 bays. All worked fine for over a year bur now there is a problem.&lt;/p&gt;\n\n&lt;p&gt;My server operating system is ubuntu (22 server) and I use docker for application deployment.&lt;/p&gt;\n\n&lt;p&gt;Unfourtuantley suddenly streams from Jelleyin (only 4k) beginn to stutter but only if I streamded directly from one particullare hdd. First i thought the hdd is gone put then I put the hdd in another slot (the server is populated with 7 hdd and 3 ssd currently) and all worked fine again :-(.&lt;/p&gt;\n\n&lt;p&gt;The backplane ist the  &lt;strong&gt;SUPERMICRO BPN-SAS2-846EL1 and the sas controller LSI SAS 9207-8i&lt;/strong&gt;  . &lt;/p&gt;\n\n&lt;p&gt;Now I start to wonder if the backplane is failing or the SAS Controller or something else?&lt;/p&gt;\n\n&lt;p&gt;Do you have any idea?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance for your help&lt;/p&gt;\n\n&lt;p&gt;This Question was also posted in &lt;a href=\"/r/homeserver\"&gt;r/homeserver&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177rogx", "is_robot_indexable": true, "report_reasons": null, "author": "AppropriateEstate457", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177rogx/advice_on_cse_864/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177rogx/advice_on_cse_864/", "subreddit_subscribers": 706698, "created_utc": 1697296206.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I know this sounds weird, or maybe there already is a term for this, but let me explain.\n\nMy Hyper Backup runs once a week, so in case of a disaster the maximum amount of loss would be ~7 days. (Let's hope the off-site backup is intact)\n\nSo, I came up with an idea to make another backup script, which only syncs the most recent (7 days) files, while automatically ditching old ones. This will run in a separate backup drive. Actually I have a free 5TB Sharepoint so I would like to use it as the \"7-day backup\". The total amount of my data is much more than 5TB, however I won't modify / create more than 5TB in a week.\n\nSo I was wondering if there is a service / solution for this, as I couldn't find by myself.\n\nThanks in advance!", "author_fullname": "t2_8ztm4g37", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recent file backup service for Synology?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_177rnm2", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697296137.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know this sounds weird, or maybe there already is a term for this, but let me explain.&lt;/p&gt;\n\n&lt;p&gt;My Hyper Backup runs once a week, so in case of a disaster the maximum amount of loss would be ~7 days. (Let&amp;#39;s hope the off-site backup is intact)&lt;/p&gt;\n\n&lt;p&gt;So, I came up with an idea to make another backup script, which only syncs the most recent (7 days) files, while automatically ditching old ones. This will run in a separate backup drive. Actually I have a free 5TB Sharepoint so I would like to use it as the &amp;quot;7-day backup&amp;quot;. The total amount of my data is much more than 5TB, however I won&amp;#39;t modify / create more than 5TB in a week.&lt;/p&gt;\n\n&lt;p&gt;So I was wondering if there is a service / solution for this, as I couldn&amp;#39;t find by myself.&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177rnm2", "is_robot_indexable": true, "report_reasons": null, "author": "Indefatigablex", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177rnm2/recent_file_backup_service_for_synology/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177rnm2/recent_file_backup_service_for_synology/", "subreddit_subscribers": 706698, "created_utc": 1697296137.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an unraid server and I want to add a SSD to backup my data to.  What's the most reliable NVME drive?  I'm going to be adding it to my PCIE slot and it's a physical 16x but only PCIE 3.0 1x speed (1GB/s) which is plenty fine, and loads faster than having it backup to a hard drive.  Since I don't need something doing 4GB/s I might as well just going for reliability instead. I know TLC vs QLC there's different reliability due to increase in speeds but I don't know what drive I should be looking at.   ", "author_fullname": "t2_ntk67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Most reliable NVME?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_177ri9m", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697295724.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an unraid server and I want to add a SSD to backup my data to.  What&amp;#39;s the most reliable NVME drive?  I&amp;#39;m going to be adding it to my PCIE slot and it&amp;#39;s a physical 16x but only PCIE 3.0 1x speed (1GB/s) which is plenty fine, and loads faster than having it backup to a hard drive.  Since I don&amp;#39;t need something doing 4GB/s I might as well just going for reliability instead. I know TLC vs QLC there&amp;#39;s different reliability due to increase in speeds but I don&amp;#39;t know what drive I should be looking at.   &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177ri9m", "is_robot_indexable": true, "report_reasons": null, "author": "FlyingTexan", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177ri9m/most_reliable_nvme/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177ri9m/most_reliable_nvme/", "subreddit_subscribers": 706698, "created_utc": 1697295724.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello everyone, I been scouring the internet trying to find way to backup my 48tb of data. I have six 8TB hardrives in a JBOD config in a hard drive enclosure. A couple of month ago I bought 2 20tb drives and cherry picked through my 48tb JBODs and transferred all but 8TB of data to my 20TB drives. So I still have 8TB of data that need to be backed up. I want and will increase my data usage soon but I want to tackle this problem first. I dont want to continue to buy 20TB hardrives, so I need to come up with a solution to efficiency backup my data while being cost efficient. I also have an Western Digital EX 4100 NAS drive bay enclosure I had for 5 years but I stopped using it because to me the software sucked. I read online about backblaze, crashplan, and other online services but I have a lot of data and I don't know if they will allow me to backup that much. Also, I was thinking about LTO tape technology but the initial startup is expensive but it might be worth it long term. Any suggestions or tips would be greatly appreciated. What do you guys use to backup large TBs of data?", "author_fullname": "t2_h9yzj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Best way to back up 48tb+ of data \ud83e\udee1", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177qn33", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697293221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": true, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone, I been scouring the internet trying to find way to backup my 48tb of data. I have six 8TB hardrives in a JBOD config in a hard drive enclosure. A couple of month ago I bought 2 20tb drives and cherry picked through my 48tb JBODs and transferred all but 8TB of data to my 20TB drives. So I still have 8TB of data that need to be backed up. I want and will increase my data usage soon but I want to tackle this problem first. I dont want to continue to buy 20TB hardrives, so I need to come up with a solution to efficiency backup my data while being cost efficient. I also have an Western Digital EX 4100 NAS drive bay enclosure I had for 5 years but I stopped using it because to me the software sucked. I read online about backblaze, crashplan, and other online services but I have a lot of data and I don&amp;#39;t know if they will allow me to backup that much. Also, I was thinking about LTO tape technology but the initial startup is expensive but it might be worth it long term. Any suggestions or tips would be greatly appreciated. What do you guys use to backup large TBs of data?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177qn33", "is_robot_indexable": true, "report_reasons": null, "author": "Multimeechy", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177qn33/best_way_to_back_up_48tb_of_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177qn33/best_way_to_back_up_48tb_of_data/", "subreddit_subscribers": 706698, "created_utc": 1697293221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I asked Backblaze:\n\n&gt;My concern is that using a debit or credit card is  not a reliable way of payment. Sometimes payments don't work (i.e. the  account is frozen/closed for some random reason, other technical  issues).Can I make a prepayment for the B2 service to be sure that my files will not be deleted after a failed transaction?I  know about your gift cards but my impression is that they are for\u00a0 your  other services. If not, you did not communicate it well to customers  that the credit is also good for the B2 service.I do not trust banks and payment service providers. They are not reliable.\n\nTheir answer:\n\n&gt;Unfortunately there is no way to schedule a pre-payment for our B2  service as it is all calculated on a per-monthly basis. We apologies for  the inconvenience.\n\nDo you know any similar service that allow making a payment in advance (prepayment)?\n\nMaybe the word prepayment is misleading. My idea is to give some money to the company to be used to cover my future expenses (in order to avoid data loss incidents because of payment failures for the monthly/yearly invoices). Of course I realize that the amount I will owe can't be determined in advance.", "author_fullname": "t2_i61gg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File storage (or backup) services that allow prepayment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177q0af", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697291431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I asked Backblaze:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;My concern is that using a debit or credit card is  not a reliable way of payment. Sometimes payments don&amp;#39;t work (i.e. the  account is frozen/closed for some random reason, other technical  issues).Can I make a prepayment for the B2 service to be sure that my files will not be deleted after a failed transaction?I  know about your gift cards but my impression is that they are for\u00a0 your  other services. If not, you did not communicate it well to customers  that the credit is also good for the B2 service.I do not trust banks and payment service providers. They are not reliable.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Their answer:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Unfortunately there is no way to schedule a pre-payment for our B2  service as it is all calculated on a per-monthly basis. We apologies for  the inconvenience.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Do you know any similar service that allow making a payment in advance (prepayment)?&lt;/p&gt;\n\n&lt;p&gt;Maybe the word prepayment is misleading. My idea is to give some money to the company to be used to cover my future expenses (in order to avoid data loss incidents because of payment failures for the monthly/yearly invoices). Of course I realize that the amount I will owe can&amp;#39;t be determined in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "177q0af", "is_robot_indexable": true, "report_reasons": null, "author": "vstoykov", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177q0af/file_storage_or_backup_services_that_allow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177q0af/file_storage_or_backup_services_that_allow/", "subreddit_subscribers": 706698, "created_utc": 1697291431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm excited to finally have somewhere to dump and organize huge (by my standards) quantities of scattered files that i can then access from anywhere and can depend to stay online, and also to set up file streaming for family for movies/tv shows and maybe a little utorrent seedbox. Anyway, I kinda bought 90tb of hard disks (they were a good deal) + 2x 4tb nvme drives to be a r/w cache + 32gb ecc ram + ups + 10gbe pcie card for the NAS and my PC, etc...all just to kit out a Synology ds1522+ to the gills. However, my current amount of data after years of hoarding it in my pc including various external drives, internal hot swap drives, usb sticks, etc. is probably only around 15-20tb, maybe less if some of these decade old 500gb drives I have lying everywhere died over the years. This amount of data took many years to amass, albeit i was never drowning in free space like I'm about to be so I have been deleting some stuff.\n\nHow should I configure it when it gets here? I don't need anywhere near 90tb yet apparently, so I was thinking of just running 4 of the drives in Raid 10, 1 spare, and just having 36tb of fast storage that i can easily leverage 10gbe with in sequential and with some redundancy and higher iops. Kind of a waste of a bay for now, but If I need more storage later (maybe years later), and I haven't had to use the spare yet, wouldn't it be possible for me to simply degrade the array down to 3 disks, copy all 36tb onto the spare + the raid orphaned drive, and then rebuild the array into a fresh raid 5, copy the data off of the single drives onto the raid array and then expand the array into the 2 singles seamlessly, without having to call up backblaze and have backups literally delivered to my door? I am not sure if this is possible because I've never used a raid array before, but it sounds doable from what I've read.\n\nAlso also, could I go from 10 to 5 to 6 for that sweet extra URE rebuild protection with this sequence of actions? Degrade 36tb raid 10 -&gt; Copy all files to 2x 18tb single drives -&gt; Build 3-disk Raid 5 -&gt; Transfer one of the disk's data onto the Raid 5 -&gt; Expand Raid 5 into this disk -&gt; Copy the remaining files off the other single disk onto the Raid 5 -&gt; Add it to the Raid 5 array as a second parity disk to create a raid 6 with all the original data.\n\nIt bears mentioning I have no solid concept of the sheer amount of TIME either of these methods of raid conversions may take with drives this size.\n\nYeah, I've made some very questionable financial choices today... Any other advice other than return some of the drives is appreciated, I NEED THIS.. because I want it...", "author_fullname": "t2_cyh4y6wh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "newbie, just bought first nas... I probably overdid it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177jlme", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.56, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697267197.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697266755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m excited to finally have somewhere to dump and organize huge (by my standards) quantities of scattered files that i can then access from anywhere and can depend to stay online, and also to set up file streaming for family for movies/tv shows and maybe a little utorrent seedbox. Anyway, I kinda bought 90tb of hard disks (they were a good deal) + 2x 4tb nvme drives to be a r/w cache + 32gb ecc ram + ups + 10gbe pcie card for the NAS and my PC, etc...all just to kit out a Synology ds1522+ to the gills. However, my current amount of data after years of hoarding it in my pc including various external drives, internal hot swap drives, usb sticks, etc. is probably only around 15-20tb, maybe less if some of these decade old 500gb drives I have lying everywhere died over the years. This amount of data took many years to amass, albeit i was never drowning in free space like I&amp;#39;m about to be so I have been deleting some stuff.&lt;/p&gt;\n\n&lt;p&gt;How should I configure it when it gets here? I don&amp;#39;t need anywhere near 90tb yet apparently, so I was thinking of just running 4 of the drives in Raid 10, 1 spare, and just having 36tb of fast storage that i can easily leverage 10gbe with in sequential and with some redundancy and higher iops. Kind of a waste of a bay for now, but If I need more storage later (maybe years later), and I haven&amp;#39;t had to use the spare yet, wouldn&amp;#39;t it be possible for me to simply degrade the array down to 3 disks, copy all 36tb onto the spare + the raid orphaned drive, and then rebuild the array into a fresh raid 5, copy the data off of the single drives onto the raid array and then expand the array into the 2 singles seamlessly, without having to call up backblaze and have backups literally delivered to my door? I am not sure if this is possible because I&amp;#39;ve never used a raid array before, but it sounds doable from what I&amp;#39;ve read.&lt;/p&gt;\n\n&lt;p&gt;Also also, could I go from 10 to 5 to 6 for that sweet extra URE rebuild protection with this sequence of actions? Degrade 36tb raid 10 -&amp;gt; Copy all files to 2x 18tb single drives -&amp;gt; Build 3-disk Raid 5 -&amp;gt; Transfer one of the disk&amp;#39;s data onto the Raid 5 -&amp;gt; Expand Raid 5 into this disk -&amp;gt; Copy the remaining files off the other single disk onto the Raid 5 -&amp;gt; Add it to the Raid 5 array as a second parity disk to create a raid 6 with all the original data.&lt;/p&gt;\n\n&lt;p&gt;It bears mentioning I have no solid concept of the sheer amount of TIME either of these methods of raid conversions may take with drives this size.&lt;/p&gt;\n\n&lt;p&gt;Yeah, I&amp;#39;ve made some very questionable financial choices today... Any other advice other than return some of the drives is appreciated, I NEED THIS.. because I want it...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177jlme", "is_robot_indexable": true, "report_reasons": null, "author": "100Eve", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177jlme/newbie_just_bought_first_nas_i_probably_overdid_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177jlme/newbie_just_bought_first_nas_i_probably_overdid_it/", "subreddit_subscribers": 706698, "created_utc": 1697266755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "from a cursory look-around, i gathered that jdowloader2 was a reliable way to download my deviantart favorites gallery, but i have been unsuccessful in figuring out how to do that.\n\ni got as far as successfully installing Eclipse and Jdowloader2 but i am unclear on where to go from here . i think i might have all the tools , i just don\u2019t know what to do with them .\n\ncan anyone help me out here ?", "author_fullname": "t2_51yimtz6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "deviantart downloading favorites gallery with jdownloader2 help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177gl1y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697254816.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;from a cursory look-around, i gathered that jdowloader2 was a reliable way to download my deviantart favorites gallery, but i have been unsuccessful in figuring out how to do that.&lt;/p&gt;\n\n&lt;p&gt;i got as far as successfully installing Eclipse and Jdowloader2 but i am unclear on where to go from here . i think i might have all the tools , i just don\u2019t know what to do with them .&lt;/p&gt;\n\n&lt;p&gt;can anyone help me out here ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177gl1y", "is_robot_indexable": true, "report_reasons": null, "author": "TheGarbageRatMan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177gl1y/deviantart_downloading_favorites_gallery_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177gl1y/deviantart_downloading_favorites_gallery_with/", "subreddit_subscribers": 706698, "created_utc": 1697254816.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mac mini M2 + Synology DS1522+ Plex Server Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1778p9u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_gf09d", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "synology", "selftext": "Hey all, apologies if these questions have been answered elsewhere. I'm completely new to running a fully-featured Plex server (though I briefly ran an Nvidia Shield PMS), and I could use some help figuring out some of the details with how things should be set up. \n\nI'm going to have all my media stored on a DS1522+, with two 12TB Seagate Ironwolf drives and another 12TB Western Digital drive that I need to shuck out of an EasyStore external hard drive enclosure. \n\nThat WD drive currently has a few hundred 4K Blu-Ray rips from when I tried running an Nvidia Shield server, so I'd like to keep the media on them when I set up the Synology box.\n\nI'd also like to run Plex Media Server natively on the Mac mini vs. running in a Docker container, as I've heard PMS runs really well, now that it's native to Apple Silicon. I'd like to use the hardware for transcoding, when necessary. \n\nOn the DS1522+, I'd like to run Docker containers for Sonarr, Radarr, and Sabnzbd (or nzbget, whichever is better). Basically, I\u2019d like to have the NAS handle all downloading and media storage and have the Mac exclusively run all Plex server tasks.\n\nSo with this information in mind can you help answer these questions:\n\n1.\tWould there be any benefit to upgrading the hardware on the DS1522+, like the RAM, NVMe, or 10GbE?\n2.\tDo I need to run a RAID or SHR on the NAS for ideal performance? If so, what\u2019re the best steps to get my media from my WD drive onto the array?\n3.\tWhat\u2019s the best way to connect the Synology to my Mac?\n\nAny other tips, advice, or guidance would be great!\n\nThank you so much!", "author_fullname": "t2_gf09d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mac mini M2 + Synology DS1522+ Plex Server Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/synology", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1778oen", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "NAS hardware", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697231903.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697231054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.synology", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, apologies if these questions have been answered elsewhere. I&amp;#39;m completely new to running a fully-featured Plex server (though I briefly ran an Nvidia Shield PMS), and I could use some help figuring out some of the details with how things should be set up. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m going to have all my media stored on a DS1522+, with two 12TB Seagate Ironwolf drives and another 12TB Western Digital drive that I need to shuck out of an EasyStore external hard drive enclosure. &lt;/p&gt;\n\n&lt;p&gt;That WD drive currently has a few hundred 4K Blu-Ray rips from when I tried running an Nvidia Shield server, so I&amp;#39;d like to keep the media on them when I set up the Synology box.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d also like to run Plex Media Server natively on the Mac mini vs. running in a Docker container, as I&amp;#39;ve heard PMS runs really well, now that it&amp;#39;s native to Apple Silicon. I&amp;#39;d like to use the hardware for transcoding, when necessary. &lt;/p&gt;\n\n&lt;p&gt;On the DS1522+, I&amp;#39;d like to run Docker containers for Sonarr, Radarr, and Sabnzbd (or nzbget, whichever is better). Basically, I\u2019d like to have the NAS handle all downloading and media storage and have the Mac exclusively run all Plex server tasks.&lt;/p&gt;\n\n&lt;p&gt;So with this information in mind can you help answer these questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; Would there be any benefit to upgrading the hardware on the DS1522+, like the RAM, NVMe, or 10GbE?&lt;/li&gt;\n&lt;li&gt; Do I need to run a RAID or SHR on the NAS for ideal performance? If so, what\u2019re the best steps to get my media from my WD drive onto the array?&lt;/li&gt;\n&lt;li&gt; What\u2019s the best way to connect the Synology to my Mac?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any other tips, advice, or guidance would be great!&lt;/p&gt;\n\n&lt;p&gt;Thank you so much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b45c7c8-4b25-11ed-a1f3-5a29a1a8c4d9", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2s4co", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#cc3600", "id": "1778oen", "is_robot_indexable": true, "report_reasons": null, "author": "rackemrackbar", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/synology/comments/1778oen/mac_mini_m2_synology_ds1522_plex_server_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/synology/comments/1778oen/mac_mini_m2_synology_ds1522_plex_server_help/", "subreddit_subscribers": 130916, "created_utc": 1697231054.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1697231115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.synology", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/synology/comments/1778oen/mac_mini_m2_synology_ds1522_plex_server_help/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1778p9u", "is_robot_indexable": true, "report_reasons": null, "author": "rackemrackbar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1778oen", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1778p9u/mac_mini_m2_synology_ds1522_plex_server_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/synology/comments/1778oen/mac_mini_m2_synology_ds1522_plex_server_help/", "subreddit_subscribers": 706698, "created_utc": 1697231115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I wanted to download my Snapchat data to try and archive all of the saved texts and snaps from a specific group chat. The problem is, when I downloaded it the text is perfectly well organized but all the media is lumped into one file with no time stamps or even info on what chat they were from. Is there a way for me to properly create a timeline of saved photos that have been sent to a specific group chat? ", "author_fullname": "t2_28q8pd4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snapchat data saved photos not having any timestamps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1775gyu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697222155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted to download my Snapchat data to try and archive all of the saved texts and snaps from a specific group chat. The problem is, when I downloaded it the text is perfectly well organized but all the media is lumped into one file with no time stamps or even info on what chat they were from. Is there a way for me to properly create a timeline of saved photos that have been sent to a specific group chat? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1775gyu", "is_robot_indexable": true, "report_reasons": null, "author": "BforBaloney", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1775gyu/snapchat_data_saved_photos_not_having_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1775gyu/snapchat_data_saved_photos_not_having_any/", "subreddit_subscribers": 706698, "created_utc": 1697222155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have thousands of files in a few folders on my PC, I need to sort and arrange those files, what I need is a software that let's me select multiple files , allows me to create a folder, move said files to the folder which I will name on the spot.\n\nIs there such a thing? I'm on windows and I have thousands of files on multiple folders to sort through.\n\nPlease help and thank you!", "author_fullname": "t2_1qcdd344", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software to quickly move multiple files to a folder?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1775913", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697221574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have thousands of files in a few folders on my PC, I need to sort and arrange those files, what I need is a software that let&amp;#39;s me select multiple files , allows me to create a folder, move said files to the folder which I will name on the spot.&lt;/p&gt;\n\n&lt;p&gt;Is there such a thing? I&amp;#39;m on windows and I have thousands of files on multiple folders to sort through.&lt;/p&gt;\n\n&lt;p&gt;Please help and thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1775913", "is_robot_indexable": true, "report_reasons": null, "author": "RusselAxel", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1775913/software_to_quickly_move_multiple_files_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1775913/software_to_quickly_move_multiple_files_to_a/", "subreddit_subscribers": 706698, "created_utc": 1697221574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have a spare 2.5 SSD I would like to put in my PC, but the 6 SATA connectors on my motherboard are already taken. I do have an internal USB 3.0 and 3.1 free, but I can't find any SATA adapters for them. My motherboard: [https://www.gigabyte.com/Motherboard/X570-AORUS-ELITE-rev-10](https://www.gigabyte.com/Motherboard/X570-AORUS-ELITE-rev-10)\n\n&amp;#x200B;\n\nThis is what I saw so far:\n\n[https://www.amazon.co.uk/SYSTEM-S-SATA-Placa-Adaptador-Conversor/dp/B08J7Q81SF](https://www.amazon.co.uk/SYSTEM-S-SATA-Placa-Adaptador-Conversor/dp/B08J7Q81SF) \\--&gt; Seems it's unavailable everywhere.\n\n&amp;#x200B;\n\n[https://www.amazon.co.uk/Cavis-Type-Placa-frontal-pulgadas/dp/B083S5DBS6](https://www.amazon.co.uk/Cavis-Type-Placa-frontal-pulgadas/dp/B083S5DBS6) \\--&gt; Available on Amazon Spain, but it would take to much time to arrive, and does not seem very reliable.\n\n&amp;#x200B;\n\n[https://www.amazon.co.uk/BEYIMEI-controladora-Tarjetas-expansi%C3%B3n-Adaptador/dp/B07PRRQ41J](https://www.amazon.co.uk/BEYIMEI-controladora-Tarjetas-expansi%C3%B3n-Adaptador/dp/B07PRRQ41J) \\--&gt; This would arrive on time and it's not expensive, but I don't know this brand.\n\n&amp;#x200B;\n\nWhat would you guys recommend me?\n\n&amp;#x200B;\n\nThanks!\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_2b4fxjk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to connect SATA 2.5 SSD to internal USB ports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1774vb7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697220546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a spare 2.5 SSD I would like to put in my PC, but the 6 SATA connectors on my motherboard are already taken. I do have an internal USB 3.0 and 3.1 free, but I can&amp;#39;t find any SATA adapters for them. My motherboard: &lt;a href=\"https://www.gigabyte.com/Motherboard/X570-AORUS-ELITE-rev-10\"&gt;https://www.gigabyte.com/Motherboard/X570-AORUS-ELITE-rev-10&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This is what I saw so far:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.co.uk/SYSTEM-S-SATA-Placa-Adaptador-Conversor/dp/B08J7Q81SF\"&gt;https://www.amazon.co.uk/SYSTEM-S-SATA-Placa-Adaptador-Conversor/dp/B08J7Q81SF&lt;/a&gt; --&amp;gt; Seems it&amp;#39;s unavailable everywhere.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.co.uk/Cavis-Type-Placa-frontal-pulgadas/dp/B083S5DBS6\"&gt;https://www.amazon.co.uk/Cavis-Type-Placa-frontal-pulgadas/dp/B083S5DBS6&lt;/a&gt; --&amp;gt; Available on Amazon Spain, but it would take to much time to arrive, and does not seem very reliable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.co.uk/BEYIMEI-controladora-Tarjetas-expansi%C3%B3n-Adaptador/dp/B07PRRQ41J\"&gt;https://www.amazon.co.uk/BEYIMEI-controladora-Tarjetas-expansi%C3%B3n-Adaptador/dp/B07PRRQ41J&lt;/a&gt; --&amp;gt; This would arrive on time and it&amp;#39;s not expensive, but I don&amp;#39;t know this brand.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What would you guys recommend me?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AWbJCOXyKYAeiT2ATKD6BJB52YUQGxsYk5QMaqKCFAs.jpg?auto=webp&amp;s=4bba92159a6747027dd56f8070e0f007106923a9", "width": 1000, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/AWbJCOXyKYAeiT2ATKD6BJB52YUQGxsYk5QMaqKCFAs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e065d072acf246ff2cc41832a6ece5bc08f178df", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/AWbJCOXyKYAeiT2ATKD6BJB52YUQGxsYk5QMaqKCFAs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=03475e5ddaece6c21d61f8edb6f4f9be762c16f5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/AWbJCOXyKYAeiT2ATKD6BJB52YUQGxsYk5QMaqKCFAs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f7ba02a706ece8b814c17cf800fe90d480c73a8e", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/AWbJCOXyKYAeiT2ATKD6BJB52YUQGxsYk5QMaqKCFAs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7101a25928aff53d2643be2d36141b7cc39f3ea8", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/AWbJCOXyKYAeiT2ATKD6BJB52YUQGxsYk5QMaqKCFAs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d78f59e18b6437b3a7db08038915a20caef89f06", "width": 960, "height": 960}], "variants": {}, "id": "iyt73ffRfhIaLFcHzXiC235amzR4u_A7sBB24S54bRA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1774vb7", "is_robot_indexable": true, "report_reasons": null, "author": "eXtremeDevil", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1774vb7/need_to_connect_sata_25_ssd_to_internal_usb_ports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1774vb7/need_to_connect_sata_25_ssd_to_internal_usb_ports/", "subreddit_subscribers": 706698, "created_utc": 1697220546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I had been using the Snapscan s1300i for about 9 years. Scanning strictly documents only. No receipts, no business cards, etc. Just legal sizes documents. \n\nWorked AMAZING, loved it.  \nRecently upgraded to a new comp. and I don't know why but my s1300i is no longer working which isn't a big deal as it was time to upgrade.  \nMy immediate thought was to just buy the upgraded model, ix1300. I prepared by first downloading and installing the Snapscan Home software to prep. for the eventual purchase but then I checked my task manager and saw that Snapscan had almost 20 processes running.\n\nIs this normal?\n\nI'm trying to figure out whether or not these processes are there because I installed the software and haven't hooked up the scanner yet or if these processes will be permanenet going forward. If it's the later, I'm not sure if I want to dedicate almost a gig of my ram just for Snapscan.\n\nIs there a substitute program I could use?  \n\n\nhttps://preview.redd.it/tyome3xe40ub1.png?width=1604&amp;format=png&amp;auto=webp&amp;s=c090d85c11a6916df7ee7245854619148b9061e1", "author_fullname": "t2_wx4sh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scanner with Lightweight Software? ix1300 or other options?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tyome3xe40ub1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 75, "x": 108, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fdc189b5451bee77385842518b2d57a276cf99a0"}, {"y": 150, "x": 216, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7fc33a90a1e3f894d595e6ffae5176c3294c7fea"}, {"y": 223, "x": 320, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3dd5c6576d2cbd265c68c3d05a6299ba8f6c4c54"}, {"y": 446, "x": 640, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=560760ac9bede2d89db47cdd5d38bc7a1951ed77"}, {"y": 669, "x": 960, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a07f4ed72faece1bf75c166fcc2c1f100272bfd"}, {"y": 752, "x": 1080, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=778be28762748b954b7f04fdc4f1972acb15e31d"}], "s": {"y": 1118, "x": 1604, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=1604&amp;format=png&amp;auto=webp&amp;s=c090d85c11a6916df7ee7245854619148b9061e1"}, "id": "tyome3xe40ub1"}}, "name": "t3_1773j2o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jkb00_Hs2h1V3SdyYVCf4a4dIae8Ua7g0uXPbTF1InY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697216815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had been using the Snapscan s1300i for about 9 years. Scanning strictly documents only. No receipts, no business cards, etc. Just legal sizes documents. &lt;/p&gt;\n\n&lt;p&gt;Worked AMAZING, loved it.&lt;br/&gt;\nRecently upgraded to a new comp. and I don&amp;#39;t know why but my s1300i is no longer working which isn&amp;#39;t a big deal as it was time to upgrade.&lt;br/&gt;\nMy immediate thought was to just buy the upgraded model, ix1300. I prepared by first downloading and installing the Snapscan Home software to prep. for the eventual purchase but then I checked my task manager and saw that Snapscan had almost 20 processes running.&lt;/p&gt;\n\n&lt;p&gt;Is this normal?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out whether or not these processes are there because I installed the software and haven&amp;#39;t hooked up the scanner yet or if these processes will be permanenet going forward. If it&amp;#39;s the later, I&amp;#39;m not sure if I want to dedicate almost a gig of my ram just for Snapscan.&lt;/p&gt;\n\n&lt;p&gt;Is there a substitute program I could use?  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tyome3xe40ub1.png?width=1604&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c090d85c11a6916df7ee7245854619148b9061e1\"&gt;https://preview.redd.it/tyome3xe40ub1.png?width=1604&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c090d85c11a6916df7ee7245854619148b9061e1&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1773j2o", "is_robot_indexable": true, "report_reasons": null, "author": "imnotuglyyouare", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1773j2o/scanner_with_lightweight_software_ix1300_or_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1773j2o/scanner_with_lightweight_software_ix1300_or_other/", "subreddit_subscribers": 706698, "created_utc": 1697216815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "How is iknowwhatyoudownload.com seeing all my ISO downloads when I have everything going through my VPN? My proxy works (checked via whatsmyipaddress.com) as well as VPN for download client!\n\nI received a notice from my ISP (AT&amp;T) saying they got notified my IP address acquired copyrighted ISO's. They had a list and they're all from about a 3 month period (late June-Sept 2023). I think these showed up because my VPN probably disconnected and downloads still happened. I have since changed the \"network lock\" setting to \"strict\" on the vpn so no traffic will go through that VM if the vpn is disconnected. I have an Ubuntu VM with expressVPN installed as my download client and use a proxy for all the ARR's to search through. I have tested (and test regularly) that the vpn is working including as a proxy by checking the whatsmyipaddress site.\n\nAfter I got the notice from AT&amp;T I started digging around just to triple check I was good and happened upon a post that had the [https://iknowwhatyoudownload.com/](https://iknowwhatyoudownload.com/) site on it. I checked this site with my real IP address and it has up-to-date ISO downloads listed!!! And I mean very up to date.... How is this possible???\n\n&amp;#x200B;\n\nhttps://preview.redd.it/1bixypaax6ub1.png?width=696&amp;format=png&amp;auto=webp&amp;s=f5bac96be057bde1ffe9bc14ca73678efe051fe4\n\n&amp;#x200B;", "author_fullname": "t2_7wpgwhdc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I thought I was safe!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 121, "top_awarded_type": null, "hide_score": true, "media_metadata": {"1bixypaax6ub1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 93, "x": 108, "u": "https://preview.redd.it/1bixypaax6ub1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=d790c5025b8172fb61fa84e679ef6299228fbc07"}, {"y": 187, "x": 216, "u": "https://preview.redd.it/1bixypaax6ub1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=92ada877f081df058eeb262b2dd5527d26368238"}, {"y": 277, "x": 320, "u": "https://preview.redd.it/1bixypaax6ub1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a984c1aa2b661cd1b4c0a09ae66c10c274385870"}, {"y": 555, "x": 640, "u": "https://preview.redd.it/1bixypaax6ub1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=7e55a1b2ef0bf03d559cc46858729a17c9eb51fb"}], "s": {"y": 604, "x": 696, "u": "https://preview.redd.it/1bixypaax6ub1.png?width=696&amp;format=png&amp;auto=webp&amp;s=f5bac96be057bde1ffe9bc14ca73678efe051fe4"}, "id": "1bixypaax6ub1"}}, "name": "t3_177snd1", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/cFOw-Xkp1sy90dmw13QOK2ROUkb3ZrZBfK0VJmNASbI.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697299009.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;How is iknowwhatyoudownload.com seeing all my ISO downloads when I have everything going through my VPN? My proxy works (checked via whatsmyipaddress.com) as well as VPN for download client!&lt;/p&gt;\n\n&lt;p&gt;I received a notice from my ISP (AT&amp;amp;T) saying they got notified my IP address acquired copyrighted ISO&amp;#39;s. They had a list and they&amp;#39;re all from about a 3 month period (late June-Sept 2023). I think these showed up because my VPN probably disconnected and downloads still happened. I have since changed the &amp;quot;network lock&amp;quot; setting to &amp;quot;strict&amp;quot; on the vpn so no traffic will go through that VM if the vpn is disconnected. I have an Ubuntu VM with expressVPN installed as my download client and use a proxy for all the ARR&amp;#39;s to search through. I have tested (and test regularly) that the vpn is working including as a proxy by checking the whatsmyipaddress site.&lt;/p&gt;\n\n&lt;p&gt;After I got the notice from AT&amp;amp;T I started digging around just to triple check I was good and happened upon a post that had the &lt;a href=\"https://iknowwhatyoudownload.com/\"&gt;https://iknowwhatyoudownload.com/&lt;/a&gt; site on it. I checked this site with my real IP address and it has up-to-date ISO downloads listed!!! And I mean very up to date.... How is this possible???&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/1bixypaax6ub1.png?width=696&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f5bac96be057bde1ffe9bc14ca73678efe051fe4\"&gt;https://preview.redd.it/1bixypaax6ub1.png?width=696&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=f5bac96be057bde1ffe9bc14ca73678efe051fe4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177snd1", "is_robot_indexable": true, "report_reasons": null, "author": "JBizzle03", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177snd1/i_thought_i_was_safe/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177snd1/i_thought_i_was_safe/", "subreddit_subscribers": 706698, "created_utc": 1697299009.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I was thinking big Special device + large small blocks == hybrid pool\n\nPro's &amp;&amp; Con's please \ud83d\ude4f \n\n\nWith ssd prices dropping and black friday coming it's maybe intresting?", "author_fullname": "t2_nfjbku4y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "ZFS: Fast pool with SSD/HDD hybrid?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_177sl07", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697298818.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I was thinking big Special device + large small blocks == hybrid pool&lt;/p&gt;\n\n&lt;p&gt;Pro&amp;#39;s &amp;amp;&amp;amp; Con&amp;#39;s please \ud83d\ude4f &lt;/p&gt;\n\n&lt;p&gt;With ssd prices dropping and black friday coming it&amp;#39;s maybe intresting?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177sl07", "is_robot_indexable": true, "report_reasons": null, "author": "Sad_Faithlessness873", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177sl07/zfs_fast_pool_with_ssdhdd_hybrid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177sl07/zfs_fast_pool_with_ssdhdd_hybrid/", "subreddit_subscribers": 706698, "created_utc": 1697298818.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}