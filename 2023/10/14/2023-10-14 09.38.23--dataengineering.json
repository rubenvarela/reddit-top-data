{"kind": "Listing", "data": {"after": null, "dist": 24, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have 5+ years of Data Analysis experience. I am pretty good with SQL/PLSQL, BI tools, in python - pandas, numpy.\n\nIt's  a one hour interview with a senior data scientist and a senior manager.  They will evaluate my SQL skills, Python and System Design.\n\nSince  python is so vast and me having sub par skills, can you all recommend  any resources/ topics I should focus on most? I bought leetcode and  stratascratch monthly subscriptions, but the problems are overwhelming  me.\n\nThe employer is on GCP platform. Their main data engineering tools are Dataflow, Cloud Composer, Pub/Sub and Datafusion.\n\nAll responses are appreciated!", "author_fullname": "t2_10gy1fws", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What python skills I should focus on for a Senior Data Engineer technical interview round?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17754gk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697221238.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have 5+ years of Data Analysis experience. I am pretty good with SQL/PLSQL, BI tools, in python - pandas, numpy.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s  a one hour interview with a senior data scientist and a senior manager.  They will evaluate my SQL skills, Python and System Design.&lt;/p&gt;\n\n&lt;p&gt;Since  python is so vast and me having sub par skills, can you all recommend  any resources/ topics I should focus on most? I bought leetcode and  stratascratch monthly subscriptions, but the problems are overwhelming  me.&lt;/p&gt;\n\n&lt;p&gt;The employer is on GCP platform. Their main data engineering tools are Dataflow, Cloud Composer, Pub/Sub and Datafusion.&lt;/p&gt;\n\n&lt;p&gt;All responses are appreciated!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "17754gk", "is_robot_indexable": true, "report_reasons": null, "author": "mcfryme", "discussion_type": null, "num_comments": 22, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17754gk/what_python_skills_i_should_focus_on_for_a_senior/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17754gk/what_python_skills_i_should_focus_on_for_a_senior/", "subreddit_subscribers": 133962, "created_utc": 1697221238.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_4ql6f", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Introducing Dagster Pipes", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_1771qcz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Open Source", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "https://b.thumbs.redditmedia.com/a94VlgTiaSgEhCGaYx17XBb5B4Ca-fnT3W5BJioZpyY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697211918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dagster.io", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dagster.io/blog/dagster-pipes", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7crrZ1xcu8FOujin37UUhOxmZsKIVRzrCXatGEqrgQM.jpg?auto=webp&amp;s=281d520d80dd744a0655b719182c0eedead6ccd8", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/7crrZ1xcu8FOujin37UUhOxmZsKIVRzrCXatGEqrgQM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e29908c5606d8acd7c969fe65c809353b2dc587", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/7crrZ1xcu8FOujin37UUhOxmZsKIVRzrCXatGEqrgQM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=66d868910d85305218ab355ae23d01a3e5947748", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/7crrZ1xcu8FOujin37UUhOxmZsKIVRzrCXatGEqrgQM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=00859baacb49080594affe61ea9be41dde55b076", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/7crrZ1xcu8FOujin37UUhOxmZsKIVRzrCXatGEqrgQM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=2f3b0da5cf4738e797ad9eafffc80a747e76f403", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/7crrZ1xcu8FOujin37UUhOxmZsKIVRzrCXatGEqrgQM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=966e9652cc069fe30cff8cef65a08c8d99b2177b", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/7crrZ1xcu8FOujin37UUhOxmZsKIVRzrCXatGEqrgQM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=7d27b993a35fdbaaa41b15e2b6c002b5f14c1ac0", "width": 1080, "height": 567}], "variants": {}, "id": "SyeXSR1vLqHcPsnqa-VMokh4Yw53R3oGFU-UZBXn9Jw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "3957ca64-3440-11ed-8329-2aa6ad243a59", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#005ba1", "id": "1771qcz", "is_robot_indexable": true, "report_reasons": null, "author": "schrockn", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1771qcz/introducing_dagster_pipes/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dagster.io/blog/dagster-pipes", "subreddit_subscribers": 133962, "created_utc": 1697211918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I can write manual scripts and run DAGs, why spends 50k+ on expensive tools?", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Why should I deploy data observability for our data stack?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1771xvz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 14, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 14, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697212498.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I can write manual scripts and run DAGs, why spends 50k+ on expensive tools?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1771xvz", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1771xvz/why_should_i_deploy_data_observability_for_our/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1771xvz/why_should_i_deploy_data_observability_for_our/", "subreddit_subscribers": 133962, "created_utc": 1697212498.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "New to data, doing a Analytics/AI Masters. Also a Technical Program Manager with java/sql experience, got laid off and looking for jobs, have this one job description trying to figure out:\n\n We are currently looking for Principal Technology Program Manager to  design design solution, quality control, testing strategy and  architectural documentation for our Data Platform. \n\nit's a sports media company, any help will be greatly appreciated. looking to understand the tech stack.", "author_fullname": "t2_upvmvlzj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "what do companies mean by the term data platform?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17714nd", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 12, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 12, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697210310.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;New to data, doing a Analytics/AI Masters. Also a Technical Program Manager with java/sql experience, got laid off and looking for jobs, have this one job description trying to figure out:&lt;/p&gt;\n\n&lt;p&gt;We are currently looking for Principal Technology Program Manager to  design design solution, quality control, testing strategy and  architectural documentation for our Data Platform. &lt;/p&gt;\n\n&lt;p&gt;it&amp;#39;s a sports media company, any help will be greatly appreciated. looking to understand the tech stack.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "17714nd", "is_robot_indexable": true, "report_reasons": null, "author": "skinnypop123", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17714nd/what_do_companies_mean_by_the_term_data_platform/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17714nd/what_do_companies_mean_by_the_term_data_platform/", "subreddit_subscribers": 133962, "created_utc": 1697210310.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6on5x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Syncing TBs of data from PostgreSQL to Snowflake", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 28, "top_awarded_type": null, "hide_score": false, "name": "t3_17735oa", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/J2lxlmFhUUaTh5KfIm7XuYD6bxKi_MxDj49Km-vdyIc.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697215771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "medium.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://medium.com/motive-eng/syncing-data-from-postgresql-to-snowflake-with-debezium-cdc-pipelines-0aeebf37583a", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/x_QFM_vvj7LmtgzCXZ_lzByzzqc4Ny1QsvbDc8_EmTc.jpg?auto=webp&amp;s=06063ac0b2315f16c5c99afaf872b4840ff206d0", "width": 1200, "height": 245}, "resolutions": [{"url": "https://external-preview.redd.it/x_QFM_vvj7LmtgzCXZ_lzByzzqc4Ny1QsvbDc8_EmTc.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ace34c4a086bbdb399b3914eb45768825d028e9e", "width": 108, "height": 22}, {"url": "https://external-preview.redd.it/x_QFM_vvj7LmtgzCXZ_lzByzzqc4Ny1QsvbDc8_EmTc.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c921ec81cd56e8ef2f7d95ded52064ab8c3704a7", "width": 216, "height": 44}, {"url": "https://external-preview.redd.it/x_QFM_vvj7LmtgzCXZ_lzByzzqc4Ny1QsvbDc8_EmTc.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1044f8ac10405ddbbf95a2c2c34dc2144b1b839a", "width": 320, "height": 65}, {"url": "https://external-preview.redd.it/x_QFM_vvj7LmtgzCXZ_lzByzzqc4Ny1QsvbDc8_EmTc.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=df0b4723bf5145b999f2f428d66d7d78654d54b1", "width": 640, "height": 130}, {"url": "https://external-preview.redd.it/x_QFM_vvj7LmtgzCXZ_lzByzzqc4Ny1QsvbDc8_EmTc.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=dc69929a4b5f28bcaa2be7c5b1b5190503126dd9", "width": 960, "height": 196}, {"url": "https://external-preview.redd.it/x_QFM_vvj7LmtgzCXZ_lzByzzqc4Ny1QsvbDc8_EmTc.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=641a98c865db2669c94643b66ae4e4e97f133b73", "width": 1080, "height": 220}], "variants": {}, "id": "QO9jRNqpxUlxNjeF9CHJDxzdUJIz-XbzZ4xdHnANZAI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "17735oa", "is_robot_indexable": true, "report_reasons": null, "author": "noodlesoup89", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17735oa/syncing_tbs_of_data_from_postgresql_to_snowflake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://medium.com/motive-eng/syncing-data-from-postgresql-to-snowflake-with-debezium-cdc-pipelines-0aeebf37583a", "subreddit_subscribers": 133962, "created_utc": 1697215771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, I was just trying to learn kakfa , i know python and have been working with it for a while but i wanted to try something with kafka and my existing skillset. Have a look and give me some feedbacks.\n\nGithub:\nhttps://github.com/kanchansapkota27/Youtube-LiveChat-Analysis\n\nDemo:\nhttps://youtu.be/RPR3K9yUDVM?si=RFiK__28yvslYSba", "author_fullname": "t2_61oxwl70", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First Project With Kafka - Youtube Live Chat Analysis", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177h56q", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Personal Project Showcase", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697256897.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, I was just trying to learn kakfa , i know python and have been working with it for a while but i wanted to try something with kafka and my existing skillset. Have a look and give me some feedbacks.&lt;/p&gt;\n\n&lt;p&gt;Github:\n&lt;a href=\"https://github.com/kanchansapkota27/Youtube-LiveChat-Analysis\"&gt;https://github.com/kanchansapkota27/Youtube-LiveChat-Analysis&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Demo:\n&lt;a href=\"https://youtu.be/RPR3K9yUDVM?si=RFiK__28yvslYSba\"&gt;https://youtu.be/RPR3K9yUDVM?si=RFiK__28yvslYSba&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/XX53ppuRWWh8-LszXb5Nw3IWLFa7arKXrqwwOapwPew.jpg?auto=webp&amp;s=958aff6974296dca0057f3f74c73395a1905dfb5", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/XX53ppuRWWh8-LszXb5Nw3IWLFa7arKXrqwwOapwPew.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=84301e7dfe7c9eada3fcfb55a744df6bd85dc46f", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/XX53ppuRWWh8-LszXb5Nw3IWLFa7arKXrqwwOapwPew.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5370400a44e535f4f00a4029fad432339a84f568", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/XX53ppuRWWh8-LszXb5Nw3IWLFa7arKXrqwwOapwPew.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e4748ff88db2cd3c734822ab7793a49f32ab6a93", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/XX53ppuRWWh8-LszXb5Nw3IWLFa7arKXrqwwOapwPew.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=41b97d034ce58974b8a4cc67b6eeb276e5d811cd", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/XX53ppuRWWh8-LszXb5Nw3IWLFa7arKXrqwwOapwPew.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=688dd1d313d3f8bbec14e3b113d49896ef257b0e", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/XX53ppuRWWh8-LszXb5Nw3IWLFa7arKXrqwwOapwPew.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=1529ad431ee8e45e9859a343dd05c79a3f4e3ebb", "width": 1080, "height": 540}], "variants": {}, "id": "59wvsjoWNHprIB_-VEkPE5SkOqxz-SsWi7bCL42S9-c"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "4134b452-dc3b-11ec-a21a-0262096eec38", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ddbd37", "id": "177h56q", "is_robot_indexable": true, "report_reasons": null, "author": "EonWolf27", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/177h56q/first_project_with_kafka_youtube_live_chat/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/177h56q/first_project_with_kafka_youtube_live_chat/", "subreddit_subscribers": 133962, "created_utc": 1697256897.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Any tips on dimensional modeling Shopify data? I am thinking fact_order_line. Should it include order and order line data in the same table or should I create two facts? What are the typical measures in that table? Also, what kind of dimensions should be created? Product, Customer, Order, Address. Anything I am missing? I am coming from a different industry so new to the e-commerce space.", "author_fullname": "t2_9izf3j1a", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data Modeling Shopify Data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177evaf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697249134.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Any tips on dimensional modeling Shopify data? I am thinking fact_order_line. Should it include order and order line data in the same table or should I create two facts? What are the typical measures in that table? Also, what kind of dimensions should be created? Product, Customer, Order, Address. Anything I am missing? I am coming from a different industry so new to the e-commerce space.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "177evaf", "is_robot_indexable": true, "report_reasons": null, "author": "Used_Ad_2628", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/177evaf/data_modeling_shopify_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/177evaf/data_modeling_shopify_data/", "subreddit_subscribers": 133962, "created_utc": 1697249134.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "My project team has decided to suddenly ditch redshift and some custom python frameworks. They want to move to dbt and Snowflake with airflow. Is it the best decision considering the cost factor, efficiency w.r.t to millions of records processed on daily basis.\nAlso from an upskilling pov what are the best resources for dbt and Snowflake with hands on labs.", "author_fullname": "t2_602lxjl2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT and Snowflake resources", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177373h", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697215881.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;My project team has decided to suddenly ditch redshift and some custom python frameworks. They want to move to dbt and Snowflake with airflow. Is it the best decision considering the cost factor, efficiency w.r.t to millions of records processed on daily basis.\nAlso from an upskilling pov what are the best resources for dbt and Snowflake with hands on labs.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "177373h", "is_robot_indexable": true, "report_reasons": null, "author": "ankititachi", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/177373h/dbt_and_snowflake_resources/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/177373h/dbt_and_snowflake_resources/", "subreddit_subscribers": 133962, "created_utc": 1697215881.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "what should i spend 200$ on ? 199$ on yearly premium subscr-n on sql  interview questions or just do spark developer certification?", "author_fullname": "t2_e6wts", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "200$ on yearly premium for data eng prep or spark cert?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176wx1f", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.99, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697197833.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;what should i spend 200$ on ? 199$ on yearly premium subscr-n on sql  interview questions or just do spark developer certification?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "176wx1f", "is_robot_indexable": true, "report_reasons": null, "author": "erjcan", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176wx1f/200_on_yearly_premium_for_data_eng_prep_or_spark/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176wx1f/200_on_yearly_premium_for_data_eng_prep_or_spark/", "subreddit_subscribers": 133962, "created_utc": 1697197833.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, so I wanted to ask is this syllabus good for learning DE and hopefully lead to jobs or do I need to add something to it ? Please so share your thoughts, thanks\n\n\nYou will build two different projects that will help you learn the basic and advanced concepts of Python, and other industry relevant tools such as the command line and version control tools, such as git and GitHub. In the first project you will create a command line assistant that helps you process multiple entries from IMDB. In the second project you build an implementation of the Hangman game using object oriented programming in Python.\n\n\nData Engineering\n\nLearn how to store, share and process various types of data at scale.\n\nBuild a complete data solution for a multinational organisation, from data acquisition to analysis . Write Python code to extract large datasets from multiple data sources. Utilise the power of Pandas to clean and analyse the data. Build a STAR based database schema for optimised data storage and access. Perform complex SQL data queries to extract valuable insights and make informed decisions for the organisation.\n\nBuild Pinterest's experiment analytics data pipeline which runs thousands of experiments per day and crunches billions of datapoints to provide valuable insights to improve the product.\n\nModule 1: Data Formats and Processing Libraries\nJSON, CSV, XLSX and YAML\nTabular Data\nPandas Dataframes\nAdvanced Dataframe Operations\nData Cleaning in Pandas\nNumpy\nMissing Data\n\nModule 2: Web APIs\nBasics of APIs and Communication Protocols\nWorking with API Requests\nFastAPI \nRouting with FastAPI\nSending Data to FastAPI\n\nModule 3: SQL\nWhat is SQL?\nSQL Setup\nSQL Tools Setup\nSQL Commands\nSQL best practices\nSELECT and Sorting\nThe WHERE Clause\nCRUD Creating Tables\nCRUD Altering Tables\nSQL JOINs\nSQL JOIN Types\nSQL Common Aggregations\nSQL GROUP BY\nCreating Subqueries\nTypes of Subqueries\nCRUD Subquery Operations\nCommon Table Expressions (CTEs)\npyscopg2 and SQLAlchemy\n\nModule 4: Essential Cloud Technology\nWhat is the Cloud\nEssential Cloud Concepts\nAWS Identity and Access Management\nAWS CLI\nIntroduction to Amazon S3\nS3 Objects and boto3\nAmazon EC2\nVirtual Private Cloud\nIAM Roles\nAmazon RDS\nBilling in AWS\n\nModule 5: Big Data Engineering Foundations\nThe Data Engineering Landscape \nData Pipelines\nData Ingestion and Data Storage\nEnterprise Data Warehouses\nBatch vs Real-Time Processing\nStructured, Unstructured and Complex Data\n\nModule 6: Data Ingestion\nPrinciples of Data Ingestion\nBatch Processing\nReal-Time Data Processing\nKafka Essentials\nKafka-Python\nStreaming in Kafka\n\nModule 7: Data wrangling and transformation\nData Transformations: ELT &amp; ETL\nApache Spark and Pyspark\nDistributed Processing with Spark\nIntegrating Spark &amp; Kafka\nIntegrating Spark &amp; AWS S3\nSpark Streaming\n\nModule 8: Data Orchestration\nApache Airflow\nIntegrating Airflow &amp; Spark\nModule 9: Advanced Cloud Technologies and Databricks\nMSK and MSK Connect\nAWS API Gateway\nIntegrating API Gateway with Kafka\nDatabricks Essentials\nIntegrating Databricks with Amazon S3\nAWS MWAA\nOrchestrating Databricks Workloads on MWAA\nAWS Kinesis\nIntegrating Databricks with AWS Kinesis\nIntegrating API Gateway with Kinesis", "author_fullname": "t2_4jsiips8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is this syllabus good to learn DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176w8lf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697195333.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, so I wanted to ask is this syllabus good for learning DE and hopefully lead to jobs or do I need to add something to it ? Please so share your thoughts, thanks&lt;/p&gt;\n\n&lt;p&gt;You will build two different projects that will help you learn the basic and advanced concepts of Python, and other industry relevant tools such as the command line and version control tools, such as git and GitHub. In the first project you will create a command line assistant that helps you process multiple entries from IMDB. In the second project you build an implementation of the Hangman game using object oriented programming in Python.&lt;/p&gt;\n\n&lt;p&gt;Data Engineering&lt;/p&gt;\n\n&lt;p&gt;Learn how to store, share and process various types of data at scale.&lt;/p&gt;\n\n&lt;p&gt;Build a complete data solution for a multinational organisation, from data acquisition to analysis . Write Python code to extract large datasets from multiple data sources. Utilise the power of Pandas to clean and analyse the data. Build a STAR based database schema for optimised data storage and access. Perform complex SQL data queries to extract valuable insights and make informed decisions for the organisation.&lt;/p&gt;\n\n&lt;p&gt;Build Pinterest&amp;#39;s experiment analytics data pipeline which runs thousands of experiments per day and crunches billions of datapoints to provide valuable insights to improve the product.&lt;/p&gt;\n\n&lt;p&gt;Module 1: Data Formats and Processing Libraries\nJSON, CSV, XLSX and YAML\nTabular Data\nPandas Dataframes\nAdvanced Dataframe Operations\nData Cleaning in Pandas\nNumpy\nMissing Data&lt;/p&gt;\n\n&lt;p&gt;Module 2: Web APIs\nBasics of APIs and Communication Protocols\nWorking with API Requests\nFastAPI \nRouting with FastAPI\nSending Data to FastAPI&lt;/p&gt;\n\n&lt;p&gt;Module 3: SQL\nWhat is SQL?\nSQL Setup\nSQL Tools Setup\nSQL Commands\nSQL best practices\nSELECT and Sorting\nThe WHERE Clause\nCRUD Creating Tables\nCRUD Altering Tables\nSQL JOINs\nSQL JOIN Types\nSQL Common Aggregations\nSQL GROUP BY\nCreating Subqueries\nTypes of Subqueries\nCRUD Subquery Operations\nCommon Table Expressions (CTEs)\npyscopg2 and SQLAlchemy&lt;/p&gt;\n\n&lt;p&gt;Module 4: Essential Cloud Technology\nWhat is the Cloud\nEssential Cloud Concepts\nAWS Identity and Access Management\nAWS CLI\nIntroduction to Amazon S3\nS3 Objects and boto3\nAmazon EC2\nVirtual Private Cloud\nIAM Roles\nAmazon RDS\nBilling in AWS&lt;/p&gt;\n\n&lt;p&gt;Module 5: Big Data Engineering Foundations\nThe Data Engineering Landscape \nData Pipelines\nData Ingestion and Data Storage\nEnterprise Data Warehouses\nBatch vs Real-Time Processing\nStructured, Unstructured and Complex Data&lt;/p&gt;\n\n&lt;p&gt;Module 6: Data Ingestion\nPrinciples of Data Ingestion\nBatch Processing\nReal-Time Data Processing\nKafka Essentials\nKafka-Python\nStreaming in Kafka&lt;/p&gt;\n\n&lt;p&gt;Module 7: Data wrangling and transformation\nData Transformations: ELT &amp;amp; ETL\nApache Spark and Pyspark\nDistributed Processing with Spark\nIntegrating Spark &amp;amp; Kafka\nIntegrating Spark &amp;amp; AWS S3\nSpark Streaming&lt;/p&gt;\n\n&lt;p&gt;Module 8: Data Orchestration\nApache Airflow\nIntegrating Airflow &amp;amp; Spark\nModule 9: Advanced Cloud Technologies and Databricks\nMSK and MSK Connect\nAWS API Gateway\nIntegrating API Gateway with Kafka\nDatabricks Essentials\nIntegrating Databricks with Amazon S3\nAWS MWAA\nOrchestrating Databricks Workloads on MWAA\nAWS Kinesis\nIntegrating Databricks with AWS Kinesis\nIntegrating API Gateway with Kinesis&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176w8lf", "is_robot_indexable": true, "report_reasons": null, "author": "saqi786x", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176w8lf/is_this_syllabus_good_to_learn_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176w8lf/is_this_syllabus_good_to_learn_de/", "subreddit_subscribers": 133962, "created_utc": 1697195333.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hey all, I\u2019m currently an automation analyst and aspiring data engineer. I\u2019m looking for jobs under \u201cData Engineer\u201d on several popular sites like Indeed and LinkedIn, but there doesn\u2019t seem to be a lot of activity at the moment. With that, how did you find your current job, and what is your official title?", "author_fullname": "t2_2jyflj51", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How did you get your job?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177apz9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697236468.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, I\u2019m currently an automation analyst and aspiring data engineer. I\u2019m looking for jobs under \u201cData Engineer\u201d on several popular sites like Indeed and LinkedIn, but there doesn\u2019t seem to be a lot of activity at the moment. With that, how did you find your current job, and what is your official title?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "177apz9", "is_robot_indexable": true, "report_reasons": null, "author": "ShortAngle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/177apz9/how_did_you_get_your_job/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/177apz9/how_did_you_get_your_job/", "subreddit_subscribers": 133962, "created_utc": 1697236468.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Is 70k a high salary for a Senior DE? What is the benchmark salary?", "author_fullname": "t2_bsuu4apm2", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hey guys, anyone here working in the Netherlands?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1775ra3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697222919.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is 70k a high salary for a Senior DE? What is the benchmark salary?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1775ra3", "is_robot_indexable": true, "report_reasons": null, "author": "CrimsonMentone30", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1775ra3/hey_guys_anyone_here_working_in_the_netherlands/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1775ra3/hey_guys_anyone_here_working_in_the_netherlands/", "subreddit_subscribers": 133962, "created_utc": 1697222919.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi Guys,\n\n&amp;#x200B;\n\nI am currently working as an applicaion support at a company for about a year. I mainly work with SQL to query data, write procedures/functions and investigate data issues and also use XML/JSON files.\n\nI know Python from my self knowledge and have a decent understanding of OOP concepts.\n\nIs data engineering relevant owards me at this point or should I try to first of all get a job as a data analyst/bi developer before? Since my only real experience related to the field is tech support esentially.\n\n&amp;#x200B;\n\nThanks", "author_fullname": "t2_hljgw2wbw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is data engineering relevant for me?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1774azf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697219006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi Guys,&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I am currently working as an applicaion support at a company for about a year. I mainly work with SQL to query data, write procedures/functions and investigate data issues and also use XML/JSON files.&lt;/p&gt;\n\n&lt;p&gt;I know Python from my self knowledge and have a decent understanding of OOP concepts.&lt;/p&gt;\n\n&lt;p&gt;Is data engineering relevant owards me at this point or should I try to first of all get a job as a data analyst/bi developer before? Since my only real experience related to the field is tech support esentially.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1774azf", "is_robot_indexable": true, "report_reasons": null, "author": "Competitive_Luck_763", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1774azf/is_data_engineering_relevant_for_me/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1774azf/is_data_engineering_relevant_for_me/", "subreddit_subscribers": 133962, "created_utc": 1697219006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Are there any offline first data pipeline tools where you can build pipelines with sample local data and then deploy them in cloud ? I used Tableau for short period of time and I think it's cost effective to let people do all the shift on local without worrying about the cost. Any thoughts? ?", "author_fullname": "t2_6pp6gh9x", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Offline first data pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1772avb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697213458.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Are there any offline first data pipeline tools where you can build pipelines with sample local data and then deploy them in cloud ? I used Tableau for short period of time and I think it&amp;#39;s cost effective to let people do all the shift on local without worrying about the cost. Any thoughts? ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "1772avb", "is_robot_indexable": true, "report_reasons": null, "author": "Snoo-8502", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1772avb/offline_first_data_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1772avb/offline_first_data_pipelines/", "subreddit_subscribers": 133962, "created_utc": 1697213458.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Several days ago I failed an DE interviiew on the coding test, the questions don't look like DSA questions I've practiced on leetcode.\n\nExample of the questions is like:\n\n1. Give a list of arrays with cloud costing plan(how many cores would cost how much bill), and provide maximum number of cores avaliable on the cloud, find the optimal cost for N days\n2. Give a text file in directory that contains several directories of files, do some manipulation to split the file to expect name type and content.\n\nThe questions doesn't look like questions I practiced on leetcode, especially the second one. I've also found some example questions shared online for DE interview about data processing using Pandas, however I seldom use pandas now and won't able to solve it if I'm not familiar with the functions.\n\n&amp;#x200B;\n\nThough DSA questions is sometimes considered non-relevant to actual work, I found some coding questions hard to prepare since there is no range to practice beforehand.\n\n&amp;#x200B;\n\nI'm thinking to practice on HackerRank to do more different type questions aside from leetcode.\n\n&amp;#x200B;\n\nHow does everyone practice coding questions aside from DSA problems?", "author_fullname": "t2_11cquw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do you prepare coding interview for non-DSA questions?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177gkl0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697254767.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Several days ago I failed an DE interviiew on the coding test, the questions don&amp;#39;t look like DSA questions I&amp;#39;ve practiced on leetcode.&lt;/p&gt;\n\n&lt;p&gt;Example of the questions is like:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Give a list of arrays with cloud costing plan(how many cores would cost how much bill), and provide maximum number of cores avaliable on the cloud, find the optimal cost for N days&lt;/li&gt;\n&lt;li&gt;Give a text file in directory that contains several directories of files, do some manipulation to split the file to expect name type and content.&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;The questions doesn&amp;#39;t look like questions I practiced on leetcode, especially the second one. I&amp;#39;ve also found some example questions shared online for DE interview about data processing using Pandas, however I seldom use pandas now and won&amp;#39;t able to solve it if I&amp;#39;m not familiar with the functions.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Though DSA questions is sometimes considered non-relevant to actual work, I found some coding questions hard to prepare since there is no range to practice beforehand.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking to practice on HackerRank to do more different type questions aside from leetcode.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;How does everyone practice coding questions aside from DSA problems?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "177gkl0", "is_robot_indexable": true, "report_reasons": null, "author": "Laurence-Lin", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/177gkl0/how_do_you_prepare_coding_interview_for_nondsa/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/177gkl0/how_do_you_prepare_coding_interview_for_nondsa/", "subreddit_subscribers": 133962, "created_utc": 1697254767.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just wonder if you can share your interview experienced with Facebook DE Meta onsite? I need little bit guidance", "author_fullname": "t2_tt7raezh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Facebook DE Meta onsite", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177ghw2", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697254495.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just wonder if you can share your interview experienced with Facebook DE Meta onsite? I need little bit guidance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "177ghw2", "is_robot_indexable": true, "report_reasons": null, "author": "Motor_Kaleidoscope23", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/177ghw2/facebook_de_meta_onsite/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/177ghw2/facebook_de_meta_onsite/", "subreddit_subscribers": 133962, "created_utc": 1697254495.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Has anyone used the new DBT project explorer? It looks much better.", "author_fullname": "t2_1n3qfa0v", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "DBT Project Explorer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177fs5t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697252100.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Has anyone used the new DBT project explorer? It looks much better.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "177fs5t", "is_robot_indexable": true, "report_reasons": null, "author": "Culpgrant21", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/177fs5t/dbt_project_explorer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/177fs5t/dbt_project_explorer/", "subreddit_subscribers": 133962, "created_utc": 1697252100.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Going to make this quick, \n\nFirst year as data engineer straight out of school\u2026 was wondering how I could find data sources of data  that has been aggregated from other tables. Trying to move the data from Hadoop to another vendor, people that help create these data and aggregate that I am trying to move are long gone.", "author_fullname": "t2_77yx7k22", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to find data", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1773pkz", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697217335.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Going to make this quick, &lt;/p&gt;\n\n&lt;p&gt;First year as data engineer straight out of school\u2026 was wondering how I could find data sources of data  that has been aggregated from other tables. Trying to move the data from Hadoop to another vendor, people that help create these data and aggregate that I am trying to move are long gone.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1773pkz", "is_robot_indexable": true, "report_reasons": null, "author": "Forsaken-Hearing3540", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1773pkz/how_to_find_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1773pkz/how_to_find_data/", "subreddit_subscribers": 133962, "created_utc": 1697217335.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi,\n\nI can connect fine from a sparkjob directly to Planetscale but want to use data catalog/connections/crawlers for playing around with the hashing. Planetscale has an export limit of 100 000 rows which I so far haven't been able to get around from direct jobs. \n\nGoal is to use Glue since rest of infra is very AWS heavy. Data is not huge, aka I could copy everything I need with a small ec2 instance but plan 1A is to use serverless solutions. Company do not want more servers to manage. \n\nFivetran etc is no go due to too big potential variations in row count. Yes small company. \n\nThanks and have the best of weekends all!", "author_fullname": "t2_5v1mzu66", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anyone had any luck/experience connecting AWS Glue Data Catalog to Planetscale?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1771nmo", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697211714.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I can connect fine from a sparkjob directly to Planetscale but want to use data catalog/connections/crawlers for playing around with the hashing. Planetscale has an export limit of 100 000 rows which I so far haven&amp;#39;t been able to get around from direct jobs. &lt;/p&gt;\n\n&lt;p&gt;Goal is to use Glue since rest of infra is very AWS heavy. Data is not huge, aka I could copy everything I need with a small ec2 instance but plan 1A is to use serverless solutions. Company do not want more servers to manage. &lt;/p&gt;\n\n&lt;p&gt;Fivetran etc is no go due to too big potential variations in row count. Yes small company. &lt;/p&gt;\n\n&lt;p&gt;Thanks and have the best of weekends all!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1771nmo", "is_robot_indexable": true, "report_reasons": null, "author": "Desperate-Dig2806", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1771nmo/anyone_had_any_luckexperience_connecting_aws_glue/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1771nmo/anyone_had_any_luckexperience_connecting_aws_glue/", "subreddit_subscribers": 133962, "created_utc": 1697211714.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have an Azure Stack with ADF and ServiceNow as souce.\nDue to reporting Purposes, we do an ELT for the tables from Service Now to our DWH.\n\nThe table in ServiceNow have a lot of columns (like 100+ or also 200+), while I know that someone could say that a restructuration would be better, we can't do nothing because we're in several companies handling it.\n\nDue to space coinstrants we try to avoid copying all the columns and it happened that we had to load a table with all columns causing us to have two tables with same data but different columns.\n\nHow do you handle or suggest to do it ? I would copy the table with all columns but client would not be happy.", "author_fullname": "t2_fsoatxql", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to handle adding new columns in table", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_176yonm", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697203469.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an Azure Stack with ADF and ServiceNow as souce.\nDue to reporting Purposes, we do an ELT for the tables from Service Now to our DWH.&lt;/p&gt;\n\n&lt;p&gt;The table in ServiceNow have a lot of columns (like 100+ or also 200+), while I know that someone could say that a restructuration would be better, we can&amp;#39;t do nothing because we&amp;#39;re in several companies handling it.&lt;/p&gt;\n\n&lt;p&gt;Due to space coinstrants we try to avoid copying all the columns and it happened that we had to load a table with all columns causing us to have two tables with same data but different columns.&lt;/p&gt;\n\n&lt;p&gt;How do you handle or suggest to do it ? I would copy the table with all columns but client would not be happy.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "176yonm", "is_robot_indexable": true, "report_reasons": null, "author": "CauliflowerJolly4599", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176yonm/how_to_handle_adding_new_columns_in_table/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176yonm/how_to_handle_adding_new_columns_in_table/", "subreddit_subscribers": 133962, "created_utc": 1697203469.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello everyone,\n\nI have data about the performance of the advertising campaigns. The advertising appears on different channels (Facebook, Instagram, Twitter, Google Adwords, ...) and for each of these channels we have multiple campaigns.\n\nWe can download data in different formats and with different periodicity from each advertising platform. The basic dataset we can fetch is consistent between platforms: for each campaign and for each day in which it was active, we can have the number of impressions, clicks, and purchases, as well as the amount spent for this marketing effort. All these figures, grouped by country where the ads were displayed. As we have different contracts with each platform, the amount spent can be expressed with different currencies.\n\nHere, as an example, a JSON fragment representing the data described above, as it could have been downloaded from an external API when asking for data for a particular day (2022-03-21):\n\n    {\n    \"day\": \"2022-03-21\",\n    \"platform\": \"Facebook Ads\",\n    \"campaign\": \"Native_UA_NOA_WhyUSTab_iOS_mobile\",\n    \u201ccountry\u201d: \u201cUS\u201d,\n    \"impressions\": 512,\n    \"clicks\": 102,\n    \"purchases\": 5,\n    \"spent\": 15.5,\n    \u201ccurrency\u201d: \u201cUSD\u201d\n    },\n    {\n    \"day\": \"2022-03-21\",\n    \n    \"platform\": \"Facebook Ads\",\n    \"campaign\": \"Native_UA_DACH_WhyDETab_iOS_mobile\",\n    \u201cCountry\u201d: \u201cDE\u201d,\n    \"impressions\": 252,\n    \"clicks\": 48,\n    \"purchases\": 2,\n    \"spent\": 7.5,\n    \u201cCurrency\u201d: \u201cEUR\u201d\n    },\n\nI have to propose a database schema to store the information described. which I have done below:\n\n[Relational Model](https://preview.redd.it/rndv8k04qytb1.png?width=699&amp;format=png&amp;auto=webp&amp;s=0f32063744a3e45c1bed5a56163aa81acabea1c7)\n\n&amp;#x200B;\n\n**Suggestion require:** Could you please provide your suggestion what could be improved based on the above scenario?\n\nAlso, It's typical for advertising networks to revise and consolidate data over time, so that the same data request made in different moments can lead to different results. For example, here there are two fragments of data representing the same data request made in two different moments.\n\n**Data fetched on 2022-04-01** \n\n    {\n    \"day\": \"2022-03-21\",\n    \"platform\": \"Facebook Ads\",\n    \"campaign\":\n    \"Native_UA_DACH_WhyDETab_iOS_mob\n    ile\",\n    \u201cCountry\u201d: \u201cDE\u201d,\n    \"impressions\": 252,\n    \"clicks\": 48,\n    \"purchases\": 2,\n    \"spent\": 7.5,\n    \u201cCurrency\u201d: \u201cEUR\u201d\n    }\n\n**Data fetched on 2022-04-08**\n\n    {\n    \"day\": \"2022-03-21\",\n    \"platform\": \"Facebook Ads\",\n    \"campaign\":\n    \"Native_UA_DACH_WhyDETab_iOS_mob\n    ile\",\n    \u201cCountry\u201d: \u201cDE\u201d,\n    \"impressions\": 253,\n    \"clicks\": 47,\n    \"purchases\": 2,\n    \"spent\": 7.5,\n    \u201cCurrency\u201d: \u201cEUR\u201d\n    }\n\nI mean one would\u00a0get a \\*complete\\* data set both on 2022-04-01 and on 2022-04-08, but\u00a0it is possible that individual values differ inside these data sets (in the example,\u00a0the values of \"impressions\" and \"clicks\")\n\n**Q.** How should I manage such a scenario in data ingestion procedure? \n\n**Q.** Should I make any changes in the relational model schema?", "author_fullname": "t2_uj6cs26m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Relational Model Schema", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 71, "top_awarded_type": null, "hide_score": false, "media_metadata": {"rndv8k04qytb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 55, "x": 108, "u": "https://preview.redd.it/rndv8k04qytb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=6d86c92644d698aa4eba58364b73779a22c5683f"}, {"y": 110, "x": 216, "u": "https://preview.redd.it/rndv8k04qytb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=06f063c17dfe8d293457f7b76e5c4ff22aef3971"}, {"y": 163, "x": 320, "u": "https://preview.redd.it/rndv8k04qytb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a500158a7da267b33e90e8cf8c200474b6a8810a"}, {"y": 327, "x": 640, "u": "https://preview.redd.it/rndv8k04qytb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5dbd428715016de336bf5eff0b7ca42a0ee8f5f4"}], "s": {"y": 358, "x": 699, "u": "https://preview.redd.it/rndv8k04qytb1.png?width=699&amp;format=png&amp;auto=webp&amp;s=0f32063744a3e45c1bed5a56163aa81acabea1c7"}, "id": "rndv8k04qytb1"}}, "name": "t3_176xi97", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/3H31o8-jWhbhiBEz2neL2iqCAvErKcQr_vK7VXY4Wyw.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697199792.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello everyone,&lt;/p&gt;\n\n&lt;p&gt;I have data about the performance of the advertising campaigns. The advertising appears on different channels (Facebook, Instagram, Twitter, Google Adwords, ...) and for each of these channels we have multiple campaigns.&lt;/p&gt;\n\n&lt;p&gt;We can download data in different formats and with different periodicity from each advertising platform. The basic dataset we can fetch is consistent between platforms: for each campaign and for each day in which it was active, we can have the number of impressions, clicks, and purchases, as well as the amount spent for this marketing effort. All these figures, grouped by country where the ads were displayed. As we have different contracts with each platform, the amount spent can be expressed with different currencies.&lt;/p&gt;\n\n&lt;p&gt;Here, as an example, a JSON fragment representing the data described above, as it could have been downloaded from an external API when asking for data for a particular day (2022-03-21):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n&amp;quot;day&amp;quot;: &amp;quot;2022-03-21&amp;quot;,\n&amp;quot;platform&amp;quot;: &amp;quot;Facebook Ads&amp;quot;,\n&amp;quot;campaign&amp;quot;: &amp;quot;Native_UA_NOA_WhyUSTab_iOS_mobile&amp;quot;,\n\u201ccountry\u201d: \u201cUS\u201d,\n&amp;quot;impressions&amp;quot;: 512,\n&amp;quot;clicks&amp;quot;: 102,\n&amp;quot;purchases&amp;quot;: 5,\n&amp;quot;spent&amp;quot;: 15.5,\n\u201ccurrency\u201d: \u201cUSD\u201d\n},\n{\n&amp;quot;day&amp;quot;: &amp;quot;2022-03-21&amp;quot;,\n\n&amp;quot;platform&amp;quot;: &amp;quot;Facebook Ads&amp;quot;,\n&amp;quot;campaign&amp;quot;: &amp;quot;Native_UA_DACH_WhyDETab_iOS_mobile&amp;quot;,\n\u201cCountry\u201d: \u201cDE\u201d,\n&amp;quot;impressions&amp;quot;: 252,\n&amp;quot;clicks&amp;quot;: 48,\n&amp;quot;purchases&amp;quot;: 2,\n&amp;quot;spent&amp;quot;: 7.5,\n\u201cCurrency\u201d: \u201cEUR\u201d\n},\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I have to propose a database schema to store the information described. which I have done below:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/rndv8k04qytb1.png?width=699&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=0f32063744a3e45c1bed5a56163aa81acabea1c7\"&gt;Relational Model&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Suggestion require:&lt;/strong&gt; Could you please provide your suggestion what could be improved based on the above scenario?&lt;/p&gt;\n\n&lt;p&gt;Also, It&amp;#39;s typical for advertising networks to revise and consolidate data over time, so that the same data request made in different moments can lead to different results. For example, here there are two fragments of data representing the same data request made in two different moments.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Data fetched on 2022-04-01&lt;/strong&gt; &lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n&amp;quot;day&amp;quot;: &amp;quot;2022-03-21&amp;quot;,\n&amp;quot;platform&amp;quot;: &amp;quot;Facebook Ads&amp;quot;,\n&amp;quot;campaign&amp;quot;:\n&amp;quot;Native_UA_DACH_WhyDETab_iOS_mob\nile&amp;quot;,\n\u201cCountry\u201d: \u201cDE\u201d,\n&amp;quot;impressions&amp;quot;: 252,\n&amp;quot;clicks&amp;quot;: 48,\n&amp;quot;purchases&amp;quot;: 2,\n&amp;quot;spent&amp;quot;: 7.5,\n\u201cCurrency\u201d: \u201cEUR\u201d\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;&lt;strong&gt;Data fetched on 2022-04-08&lt;/strong&gt;&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;{\n&amp;quot;day&amp;quot;: &amp;quot;2022-03-21&amp;quot;,\n&amp;quot;platform&amp;quot;: &amp;quot;Facebook Ads&amp;quot;,\n&amp;quot;campaign&amp;quot;:\n&amp;quot;Native_UA_DACH_WhyDETab_iOS_mob\nile&amp;quot;,\n\u201cCountry\u201d: \u201cDE\u201d,\n&amp;quot;impressions&amp;quot;: 253,\n&amp;quot;clicks&amp;quot;: 47,\n&amp;quot;purchases&amp;quot;: 2,\n&amp;quot;spent&amp;quot;: 7.5,\n\u201cCurrency\u201d: \u201cEUR\u201d\n}\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I mean one would\u00a0get a *complete* data set both on 2022-04-01 and on 2022-04-08, but\u00a0it is possible that individual values differ inside these data sets (in the example,\u00a0the values of &amp;quot;impressions&amp;quot; and &amp;quot;clicks&amp;quot;)&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Q.&lt;/strong&gt; How should I manage such a scenario in data ingestion procedure? &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Q.&lt;/strong&gt; Should I make any changes in the relational model schema?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "176xi97", "is_robot_indexable": true, "report_reasons": null, "author": "Huge_Jicama_3087", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176xi97/relational_model_schema/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/176xi97/relational_model_schema/", "subreddit_subscribers": 133962, "created_utc": 1697199792.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3dyum", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Ultimate Guide: 200+ Free Datasets for Data Science, Machine learning, AI, NLP", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_176ugc8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/psAac2uk82w6tqDFuE-xQXhnyeq4ADtQtHzh4TQOzuE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697187936.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "bigdataanalyticsnews.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://bigdataanalyticsnews.com/datasets/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mo6g6MsH4ezMt_jez90hg9OylBGm-OA3pEAfKH-yRlE.jpg?auto=webp&amp;s=53ec28897d016c0d862fddff65fd3ef33f0a83ea", "width": 1024, "height": 1024}, "resolutions": [{"url": "https://external-preview.redd.it/mo6g6MsH4ezMt_jez90hg9OylBGm-OA3pEAfKH-yRlE.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=feedc96585c8a837a53a0a347c16e4a9871b52be", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/mo6g6MsH4ezMt_jez90hg9OylBGm-OA3pEAfKH-yRlE.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=271009c0452f81c6d9fbf42eb8f987e0b65de6a6", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/mo6g6MsH4ezMt_jez90hg9OylBGm-OA3pEAfKH-yRlE.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5f67782df471eda50c64747c387a87bb93ccd0e6", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/mo6g6MsH4ezMt_jez90hg9OylBGm-OA3pEAfKH-yRlE.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f2c0c86eb4de5d97cb769ace6100b502f0399136", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/mo6g6MsH4ezMt_jez90hg9OylBGm-OA3pEAfKH-yRlE.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=25cd41166773d2dcd6549019a82768f0a7f9699a", "width": 960, "height": 960}], "variants": {}, "id": "sNRD7_-MRcoQfp8BL1rTdqBoi6ENy6krewqJaDbvrdU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "176ugc8", "is_robot_indexable": true, "report_reasons": null, "author": "Veerans", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/176ugc8/ultimate_guide_200_free_datasets_for_data_science/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://bigdataanalyticsnews.com/datasets/", "subreddit_subscribers": 133962, "created_utc": 1697187936.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a BI Analyst and have just started work at a small company who do everything in Excel, and I've been asked to step into a 'not-quite but-almost data engineering' role. The first challenge I have is:  \n\nEvery day they receive a CSV file sales report (pulled from a third party who manage their data in a hosted service off-site). Every day several thousand rows are added as new transaction take place, and this is close to approaching Excel's row limit.\n\nIt has been asked that I put a pipeline in place to pick up the latest file when it arrives, (same file name + days date) upload to Microsoft Fabric.  \n\nFrom there I can build a Power BI dashboard that will produce the outputs required, it's just the automation of daily ingestion that I'm unsure of the best way to approach.  What would you advise?\n\nthanks in advance!", "author_fullname": "t2_2s6myxsc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data ingestion help needed - using Fabric", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1770ntk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697209055.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a BI Analyst and have just started work at a small company who do everything in Excel, and I&amp;#39;ve been asked to step into a &amp;#39;not-quite but-almost data engineering&amp;#39; role. The first challenge I have is:  &lt;/p&gt;\n\n&lt;p&gt;Every day they receive a CSV file sales report (pulled from a third party who manage their data in a hosted service off-site). Every day several thousand rows are added as new transaction take place, and this is close to approaching Excel&amp;#39;s row limit.&lt;/p&gt;\n\n&lt;p&gt;It has been asked that I put a pipeline in place to pick up the latest file when it arrives, (same file name + days date) upload to Microsoft Fabric.  &lt;/p&gt;\n\n&lt;p&gt;From there I can build a Power BI dashboard that will produce the outputs required, it&amp;#39;s just the automation of daily ingestion that I&amp;#39;m unsure of the best way to approach.  What would you advise?&lt;/p&gt;\n\n&lt;p&gt;thanks in advance!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "1770ntk", "is_robot_indexable": true, "report_reasons": null, "author": "Dog_In_A_Human_Suit", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1770ntk/data_ingestion_help_needed_using_fabric/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1770ntk/data_ingestion_help_needed_using_fabric/", "subreddit_subscribers": 133962, "created_utc": 1697209055.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work for this database company SingleStore and we are hosting a Data and AI conference in San Francisco on 17th of October, 2023.\n\nIt is an in-person conference with amazing speakers line-up like Harrison Chase, co-founder and CEO of LangChain and many more. We will have hands-on workshops, swags giveaway and much more.\n\nI don't know if it makes sense to share this but I believe it might help some of you near San Francisco to go and meet the industry leaders and network with other data engineering folks.\n\nUse my discount coupon code 'PAVAN100OFF' to avail 100% off on the ticket price. (the original ticket price is $199)\n\n[Get your tickets now!](https://singlestore.com/now)", "author_fullname": "t2_129ag6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data &amp; AI conference happening in San Francisco: 100% off on the ticket price!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1770yer", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.45, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697210177.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697209830.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work for this database company SingleStore and we are hosting a Data and AI conference in San Francisco on 17th of October, 2023.&lt;/p&gt;\n\n&lt;p&gt;It is an in-person conference with amazing speakers line-up like Harrison Chase, co-founder and CEO of LangChain and many more. We will have hands-on workshops, swags giveaway and much more.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know if it makes sense to share this but I believe it might help some of you near San Francisco to go and meet the industry leaders and network with other data engineering folks.&lt;/p&gt;\n\n&lt;p&gt;Use my discount coupon code &amp;#39;PAVAN100OFF&amp;#39; to avail 100% off on the ticket price. (the original ticket price is $199)&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://singlestore.com/now\"&gt;Get your tickets now!&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "1770yer", "is_robot_indexable": true, "report_reasons": null, "author": "PavanBelagatti", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/1770yer/data_ai_conference_happening_in_san_francisco_100/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/1770yer/data_ai_conference_happening_in_san_francisco_100/", "subreddit_subscribers": 133962, "created_utc": 1697209830.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}