{"kind": "Listing", "data": {"after": "t3_1770hh0", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_pnocu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "is_gallery": true, "title": "I bought a fake 4TB \"990 Pro\"! So that you don't have to...", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"l0f5urz3jztb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/l0f5urz3jztb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=9b96f03fd3c80cff66fb953c7df9de6ca2fd0807"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/l0f5urz3jztb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a5a4eab76826af592b299380faffe8c702bca17c"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/l0f5urz3jztb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=00c671b464a5a70b7287022d7510bda8ed356cc0"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/l0f5urz3jztb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=a153571ad5e6f3d27ad9f2f5fc3843c666392bde"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/l0f5urz3jztb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=240670c9e831c56a18e8298f309354daffdc75f7"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/l0f5urz3jztb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=5d544692d9584332f7e260c758565bfe141c875f"}], "s": {"y": 3000, "x": 4000, "u": "https://preview.redd.it/l0f5urz3jztb1.jpg?width=4000&amp;format=pjpg&amp;auto=webp&amp;s=bca63885bd6b7f2b2900cffe712cadb72c8a81d3"}, "id": "l0f5urz3jztb1"}, "7eg7816pjztb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 125, "x": 108, "u": "https://preview.redd.it/7eg7816pjztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2ae3d8b89eecdf045d9025027ab0750e26078831"}, {"y": 250, "x": 216, "u": "https://preview.redd.it/7eg7816pjztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d14c4e2618ede8ae9ac8bc7d83797908ec48611f"}, {"y": 370, "x": 320, "u": "https://preview.redd.it/7eg7816pjztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=4bbf9e34b7c9dbc5c7456dce9722620724ac9b0f"}], "s": {"y": 630, "x": 544, "u": "https://preview.redd.it/7eg7816pjztb1.png?width=544&amp;format=png&amp;auto=webp&amp;s=1e2e05855a62949a54140c3f0831bfff93f79346"}, "id": "7eg7816pjztb1"}, "91i7tg04jztb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/91i7tg04jztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=b12c3de24c64855f09ef2aa1d676491834834aed"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/91i7tg04jztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7852501871c0bdf46c0ae18630b7f3d1a8487163"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/91i7tg04jztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=82b3630afdbc03c861bc51a3532c42a3610bd66a"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/91i7tg04jztb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=c9c7079db23bad00acbb7ca93a37972926bfb733"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/91i7tg04jztb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=c4173a85b15d4a8dfe486532770c15f113fe9de6"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/91i7tg04jztb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=4e081ef6fdd7eda540d25ce386ae74411a376d9b"}], "s": {"y": 969, "x": 1292, "u": "https://preview.redd.it/91i7tg04jztb1.png?width=1292&amp;format=png&amp;auto=webp&amp;s=f12e791b88235fc6b2e29717cb5fbe195b8be2bf"}, "id": "91i7tg04jztb1"}, "mp4dgf04jztb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/mp4dgf04jztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=02da41afe9941ab1a0e23e1fae06cb69b9aa5ab3"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/mp4dgf04jztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=92f95abb2ce344c1fe7fd67d96a168c82a35b2e5"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/mp4dgf04jztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=8cc4b717b6892422ab1d208adf58a56c213d9ed8"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/mp4dgf04jztb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=26848c9da51322c58e805c4c2bba3ec605d9abba"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/mp4dgf04jztb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=33af59316d0486caf708eea39e617ab644bdb486"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/mp4dgf04jztb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0721033f9850efb489e2d5e6abbeb24129066309"}], "s": {"y": 969, "x": 1292, "u": "https://preview.redd.it/mp4dgf04jztb1.png?width=1292&amp;format=png&amp;auto=webp&amp;s=8056eaadfafd1e690fe6c9ca8b94889f932a03e5"}, "id": "mp4dgf04jztb1"}, "ko39vrz3jztb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 45, "x": 108, "u": "https://preview.redd.it/ko39vrz3jztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=eefb52541fd308851102f482db73d47b43d9c20b"}, {"y": 90, "x": 216, "u": "https://preview.redd.it/ko39vrz3jztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=035addc3c6954a27a20cc14e9fc89f6ea29a674c"}, {"y": 134, "x": 320, "u": "https://preview.redd.it/ko39vrz3jztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=fd92c221b3db10ba333c712aff1de53c06cf3e0f"}], "s": {"y": 168, "x": 401, "u": "https://preview.redd.it/ko39vrz3jztb1.png?width=401&amp;format=png&amp;auto=webp&amp;s=eddc3f0456a961791cfa5d42e8093a38a161979d"}, "id": "ko39vrz3jztb1"}, "6wv5bg04jztb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/6wv5bg04jztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=2ec045e563e4023a06c4f1ac1351ae114d9b02fd"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/6wv5bg04jztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b085ead135b28ad30ff5e75dcacaf72fd9bae620"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/6wv5bg04jztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1259e5be00cb2b94f0c855109b2ca48dabadc95a"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/6wv5bg04jztb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=d4e60469c69c2e99800155a5d7d28b816e6b0720"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/6wv5bg04jztb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=ddc8efc55033bc749be7f5bac5d8536f70c67692"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/6wv5bg04jztb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c7f166e5e48679ab218f6438945785f4c4fb0c0f"}], "s": {"y": 969, "x": 1292, "u": "https://preview.redd.it/6wv5bg04jztb1.png?width=1292&amp;format=png&amp;auto=webp&amp;s=f2eb24a306b6478282d19f89db44e207981d4a79"}, "id": "6wv5bg04jztb1"}, "z1i1he04jztb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/z1i1he04jztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=53eae24d654496804e0f681e56a53bdda076c10d"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/z1i1he04jztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=bb7498dc73b159d5010516c3a45ef5b3795bd9cc"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/z1i1he04jztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=92154d59e5199542e710537f1d54f3dcea03503b"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/z1i1he04jztb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=aff206ee788645c8701206d2e3402fca97026acb"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/z1i1he04jztb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=496005e827de6a8a7bea06adae4201efc5c0b495"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/z1i1he04jztb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=caf420a18cc1693cb026d0b86fef7699f576455d"}], "s": {"y": 969, "x": 1292, "u": "https://preview.redd.it/z1i1he04jztb1.png?width=1292&amp;format=png&amp;auto=webp&amp;s=352fa9f1d9a1f54b98570a6fc4db7ccd4036c68c"}, "id": "z1i1he04jztb1"}, "gusuloz3jztb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 111, "x": 108, "u": "https://preview.redd.it/gusuloz3jztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=ae8b1e6ea50082c5cf2a41a6e52b38544ab7d97a"}, {"y": 222, "x": 216, "u": "https://preview.redd.it/gusuloz3jztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=eee20f02be2761683902b398cb16341a81772d55"}, {"y": 329, "x": 320, "u": "https://preview.redd.it/gusuloz3jztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=ce4951952b3bf48087eb93ad8fee4ade3196c53c"}, {"y": 659, "x": 640, "u": "https://preview.redd.it/gusuloz3jztb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=76da99d0b05bf7a684e2d7bdf0f519fe18da8dd6"}], "s": {"y": 689, "x": 669, "u": "https://preview.redd.it/gusuloz3jztb1.png?width=669&amp;format=png&amp;auto=webp&amp;s=e53489121171c00da00901c142ba3f457c36da8a"}, "id": "gusuloz3jztb1"}, "fpu4gsz3jztb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 145, "x": 108, "u": "https://preview.redd.it/fpu4gsz3jztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=72dadd0fb1f3bb075efc142cbeeb1b306bd7731e"}, {"y": 290, "x": 216, "u": "https://preview.redd.it/fpu4gsz3jztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=d1ca85e69c2e7c984f165a3eba3a32c5becb0a68"}, {"y": 430, "x": 320, "u": "https://preview.redd.it/fpu4gsz3jztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=395506ef853fba1844209b150077ab466f38526c"}], "s": {"y": 547, "x": 407, "u": "https://preview.redd.it/fpu4gsz3jztb1.png?width=407&amp;format=png&amp;auto=webp&amp;s=abe4142d8d4beea0dade83548c475ce0a9ef8ca9"}, "id": "fpu4gsz3jztb1"}, "6tod7j04jztb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/6tod7j04jztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=baf61915d75d091f4216f915c46f85b431c1ffc5"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/6tod7j04jztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=cf8b6e921c4eaa4f9622b41befbdf6a13e61f837"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/6tod7j04jztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=5ac6e357c06b3effb24b2df67d43be356b722924"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/6tod7j04jztb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=866ba2d2b59102f87a9c376a8c2358e2548a809e"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/6tod7j04jztb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=f6536c23f79e7d6ed24748c71541427b168d96d3"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/6tod7j04jztb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=633f76ec768b651be78e1b8ba0c391ee7a7db2a5"}], "s": {"y": 969, "x": 1292, "u": "https://preview.redd.it/6tod7j04jztb1.png?width=1292&amp;format=png&amp;auto=webp&amp;s=5e30d1f3f4e2813717c03bc4dbb1dcc111b28197"}, "id": "6tod7j04jztb1"}, "9qalrqz3jztb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 78, "x": 108, "u": "https://preview.redd.it/9qalrqz3jztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=21b31ff24186a275e6d3d5ed0085149e494f62ff"}, {"y": 157, "x": 216, "u": "https://preview.redd.it/9qalrqz3jztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=b6333fbbdb3674155897d5cee6189ce219411132"}, {"y": 232, "x": 320, "u": "https://preview.redd.it/9qalrqz3jztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=9d8883318f4a7653aac4d9a47c5c7c4e8b66b4ad"}], "s": {"y": 347, "x": 477, "u": "https://preview.redd.it/9qalrqz3jztb1.png?width=477&amp;format=png&amp;auto=webp&amp;s=e81abeeb298f2b7894c9facefd9381f9bf7ec28f"}, "id": "9qalrqz3jztb1"}}, "name": "t3_1770wcc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 326, "domain": "old.reddit.com", "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "gallery_data": {"items": [{"media_id": "7eg7816pjztb1", "id": 341989623}, {"media_id": "gusuloz3jztb1", "id": 341989624}, {"media_id": "9qalrqz3jztb1", "id": 341989625}, {"media_id": "ko39vrz3jztb1", "id": 341989626}, {"media_id": "fpu4gsz3jztb1", "id": 341989627}, {"media_id": "z1i1he04jztb1", "id": 341989628}, {"media_id": "mp4dgf04jztb1", "id": 341989629}, {"media_id": "6tod7j04jztb1", "id": 341989630}, {"media_id": "91i7tg04jztb1", "id": 341989631}, {"media_id": "l0f5urz3jztb1", "id": 341989632}, {"media_id": "6wv5bg04jztb1", "id": 341989633}]}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 326, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://a.thumbs.redditmedia.com/xoDHPjE5pfGOsQ1dZmm64a8RLHvhmsjoWcRVhkQFSE4.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697209674.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "total_awards_received": 0, "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.reddit.com/gallery/1770wcc", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "1770wcc", "is_robot_indexable": true, "report_reasons": null, "author": "nukklear", "discussion_type": null, "num_comments": 74, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1770wcc/i_bought_a_fake_4tb_990_pro_so_that_you_dont_have/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.reddit.com/gallery/1770wcc", "subreddit_subscribers": 706687, "created_utc": 1697209674.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "author_fullname": "t2_4pdfnevq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hit the Jackpot at an Estate Sale! Scored this 18TB WD Ultrastar for $50 and 2x 5TB Portable Drives for $20ea. Warranty confirmed still good for another 3 years! Crystaldisk info 13k hrs w/ good health. w00t!", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "friday", "downs": 0, "thumbnail_height": 89, "top_awarded_type": null, "hide_score": false, "name": "t3_17709xt", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.91, "author_flair_background_color": null, "ups": 259, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Free-Post Friday!", "can_mod_post": false, "score": 259, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/sAYUh6mYOzxXR0GucCOKMmtR98POOoREK6-HMTf9WSk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1697207984.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": true, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/lnztv988cztb1.jpg", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/lnztv988cztb1.jpg?auto=webp&amp;s=b20545ea4d2e0e094cd21f2409159dfee8a2d5ac", "width": 1916, "height": 1227}, "resolutions": [{"url": "https://preview.redd.it/lnztv988cztb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=21ba155d5377c17321b29019d6cf894ee362dea2", "width": 108, "height": 69}, {"url": "https://preview.redd.it/lnztv988cztb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=4e81c5df802eee5a2be6d2fd0e5689d31fe060e9", "width": 216, "height": 138}, {"url": "https://preview.redd.it/lnztv988cztb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=039c062c9aa99a02eb906ad295d7fb82ba99219c", "width": 320, "height": 204}, {"url": "https://preview.redd.it/lnztv988cztb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=723567a40d7e09c6cb614977c23c081b02e656f4", "width": 640, "height": 409}, {"url": "https://preview.redd.it/lnztv988cztb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d71713a45844c43ce4c3f28fb620b88f103745a1", "width": 960, "height": 614}, {"url": "https://preview.redd.it/lnztv988cztb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0ab68e0d71086e31dc29e61471a6ebfe78754fab", "width": 1080, "height": 691}], "variants": {}, "id": "v8lXWfFLHdBDGtfrBFPzyg1PAka8oMwokTJJNXRVILk"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "82f515be-b94e-11eb-9f8a-0e1030dba663", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "17709xt", "is_robot_indexable": true, "report_reasons": null, "author": "Valor_X", "discussion_type": null, "num_comments": 35, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/17709xt/hit_the_jackpot_at_an_estate_sale_scored_this/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/lnztv988cztb1.jpg", "subreddit_subscribers": 706687, "created_utc": 1697207984.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I recently had a failure on my working drive (an external hard drive... yeah I know) which led me to *almost* lose important data if weren't for very good data recovery.  \n\n\nI'm now here looking for advice on setting up a storage solution that is more resilient for my data. I occasionally work with large video/audio projects so whatever solution would need to be quick enough to edit from. I have a mac mini with a 10gb ethernet connection. Realistically I only need to access like 8GB of storage, and everything else could be moved to long term backups.\n\nThank you guys so much!\n\n&amp;#x200B;", "author_fullname": "t2_2z5oulej", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Had my first data loss scare, and now I'm here", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177b9j0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 21, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 21, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697238004.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I recently had a failure on my working drive (an external hard drive... yeah I know) which led me to &lt;em&gt;almost&lt;/em&gt; lose important data if weren&amp;#39;t for very good data recovery.  &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m now here looking for advice on setting up a storage solution that is more resilient for my data. I occasionally work with large video/audio projects so whatever solution would need to be quick enough to edit from. I have a mac mini with a 10gb ethernet connection. Realistically I only need to access like 8GB of storage, and everything else could be moved to long term backups.&lt;/p&gt;\n\n&lt;p&gt;Thank you guys so much!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177b9j0", "is_robot_indexable": true, "report_reasons": null, "author": "Sttql", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177b9j0/had_my_first_data_loss_scare_and_now_im_here/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177b9j0/had_my_first_data_loss_scare_and_now_im_here/", "subreddit_subscribers": 706687, "created_utc": 1697238004.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": " I put this old disk into my PC thinking I could copy the data from it onto the PC. it then prompted \"How do you want to use this disk?\" It didnt say anything about reformatting the disk and I realized too late, it started the formatting process. I stopped it a few seconds after it began but now the dvd isnt even playing on my dvd player.\n\nis there anything I can do to recover the home movies? And I have other disks of the same format, how do I go about saving them digitally?", "author_fullname": "t2_4chk9t7t", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Recovering old home movies from DVD+r", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177261i", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697213097.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I put this old disk into my PC thinking I could copy the data from it onto the PC. it then prompted &amp;quot;How do you want to use this disk?&amp;quot; It didnt say anything about reformatting the disk and I realized too late, it started the formatting process. I stopped it a few seconds after it began but now the dvd isnt even playing on my dvd player.&lt;/p&gt;\n\n&lt;p&gt;is there anything I can do to recover the home movies? And I have other disks of the same format, how do I go about saving them digitally?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177261i", "is_robot_indexable": true, "report_reasons": null, "author": "s-atch", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177261i/recovering_old_home_movies_from_dvdr/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177261i/recovering_old_home_movies_from_dvdr/", "subreddit_subscribers": 706687, "created_utc": 1697213097.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello! Is there an easy way to recover data from HDD that was installed in a single bay TS-133 NAS? I have a Windows, Ubuntu and a Mac computer. They all see my HDD but cannot access the data. Ubuntu sees data partition as RAID and is also unable to access\n\nAnd a bonus question: is there way to disable RAID completely (since I have only a one bay NAS) so I don\u2019t run into this issue in the future?", "author_fullname": "t2_2or3zqpu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get data off a HDD that was in a Qnap NAS?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_177oxk5", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697288106.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! Is there an easy way to recover data from HDD that was installed in a single bay TS-133 NAS? I have a Windows, Ubuntu and a Mac computer. They all see my HDD but cannot access the data. Ubuntu sees data partition as RAID and is also unable to access&lt;/p&gt;\n\n&lt;p&gt;And a bonus question: is there way to disable RAID completely (since I have only a one bay NAS) so I don\u2019t run into this issue in the future?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177oxk5", "is_robot_indexable": true, "report_reasons": null, "author": "Karmacosmik", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177oxk5/how_to_get_data_off_a_hdd_that_was_in_a_qnap_nas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177oxk5/how_to_get_data_off_a_hdd_that_was_in_a_qnap_nas/", "subreddit_subscribers": 706687, "created_utc": 1697288106.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have an unraid server with a 13700(non-k) cpu, MSI PRO B760 motherboard, RTX 4060 GPU, and two SAS HBA cards connected to 24 drives.  I'm about to modify things where instead of using two SAS HBA cards I'll only use one.  I'm trying to figure out how many pcie lanes I have and how they're utilized.\n\n&amp;#x200B;\n\nhttps://preview.redd.it/ah7sf5vuiztb1.png?width=824&amp;format=png&amp;auto=webp&amp;s=5a1676f7ee86b1bed51a60960d1a77db13713ed7\n\n&amp;#x200B;\n\nTop slot RTX 4060 (8 lanes)\n\n3rd slot HBA Card LSI 9300-16i (Supports 8 lanes but I don't know if that's what it's using)\n\n5th slot HBA Card LSI 9211-8i (Supports 8 lanes but again don't know what it's using just know it works)\n\n&amp;#x200B;\n\nWhat I'm wanting to do is go down to a single HBA card. I'm also considering getting a PCIe NVME card so I could add additional NVME drives to my setup as a cache.\n\n&amp;#x200B;\n\nI don't really get how PCIE lanes work.  I know there's different generations, etc. So my real question I guess is we can go rounds trying to get my numb brain to figure this out or someone else could just answer it for me. Could I have (starting closest to the CPU going down) a RTX 4060, a [PCIe NVME card](https://www.amazon.com/EZDIY-FAB-Expansion-Heatsink-Platform-Bifurcatin/dp/B0B5CF3J99/ref=sr_1_10?keywords=nvme+pcie+card&amp;qid=1697208862&amp;refinements=p_72%3A1248879011&amp;rnid=1248877011&amp;s=electronics&amp;sr=1-10#customerReviews), then my HBA card?  I could swap the cards around as needed.  I don't really need top speed out of anything. The RTX is there as a transcoding card and not for gaming.  The NVMEs are there as a cache setup for unraid.  The HBA card would connect to the 24 drives which generally only a 3 or 4 are spinning at any one time depending on what data is being accessed.\n\nI do currently have both NVME slots on the motherboard populated. However I was thinking of taking those two and putting them on the card as well so (not fully understanding PCIe lanes) that would free up some lanes, right?", "author_fullname": "t2_ntk67", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PCIe Lanes and build questions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "media_metadata": {"ah7sf5vuiztb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 134, "x": 108, "u": "https://preview.redd.it/ah7sf5vuiztb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=4e6520ba38a5c74ead2a7aba38c07f3cac80eea6"}, {"y": 269, "x": 216, "u": "https://preview.redd.it/ah7sf5vuiztb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=c4bccadfec7bc7c13e8e995bcdeb045edd1a85d8"}, {"y": 399, "x": 320, "u": "https://preview.redd.it/ah7sf5vuiztb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=1c11649f56118a5417f6953c64fe34226aa8d538"}, {"y": 799, "x": 640, "u": "https://preview.redd.it/ah7sf5vuiztb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=fd7725034f5b11aee5c911152d0546daa6e76b80"}], "s": {"y": 1029, "x": 824, "u": "https://preview.redd.it/ah7sf5vuiztb1.png?width=824&amp;format=png&amp;auto=webp&amp;s=5a1676f7ee86b1bed51a60960d1a77db13713ed7"}, "id": "ah7sf5vuiztb1"}}, "name": "t3_1770sc3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/zVk9Itq5kfKCnLReB8PBYk2rk-Fo5QZ8xZJDySAU-Jk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697209381.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have an unraid server with a 13700(non-k) cpu, MSI PRO B760 motherboard, RTX 4060 GPU, and two SAS HBA cards connected to 24 drives.  I&amp;#39;m about to modify things where instead of using two SAS HBA cards I&amp;#39;ll only use one.  I&amp;#39;m trying to figure out how many pcie lanes I have and how they&amp;#39;re utilized.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/ah7sf5vuiztb1.png?width=824&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5a1676f7ee86b1bed51a60960d1a77db13713ed7\"&gt;https://preview.redd.it/ah7sf5vuiztb1.png?width=824&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=5a1676f7ee86b1bed51a60960d1a77db13713ed7&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Top slot RTX 4060 (8 lanes)&lt;/p&gt;\n\n&lt;p&gt;3rd slot HBA Card LSI 9300-16i (Supports 8 lanes but I don&amp;#39;t know if that&amp;#39;s what it&amp;#39;s using)&lt;/p&gt;\n\n&lt;p&gt;5th slot HBA Card LSI 9211-8i (Supports 8 lanes but again don&amp;#39;t know what it&amp;#39;s using just know it works)&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;m wanting to do is go down to a single HBA card. I&amp;#39;m also considering getting a PCIe NVME card so I could add additional NVME drives to my setup as a cache.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t really get how PCIE lanes work.  I know there&amp;#39;s different generations, etc. So my real question I guess is we can go rounds trying to get my numb brain to figure this out or someone else could just answer it for me. Could I have (starting closest to the CPU going down) a RTX 4060, a &lt;a href=\"https://www.amazon.com/EZDIY-FAB-Expansion-Heatsink-Platform-Bifurcatin/dp/B0B5CF3J99/ref=sr_1_10?keywords=nvme+pcie+card&amp;amp;qid=1697208862&amp;amp;refinements=p_72%3A1248879011&amp;amp;rnid=1248877011&amp;amp;s=electronics&amp;amp;sr=1-10#customerReviews\"&gt;PCIe NVME card&lt;/a&gt;, then my HBA card?  I could swap the cards around as needed.  I don&amp;#39;t really need top speed out of anything. The RTX is there as a transcoding card and not for gaming.  The NVMEs are there as a cache setup for unraid.  The HBA card would connect to the 24 drives which generally only a 3 or 4 are spinning at any one time depending on what data is being accessed.&lt;/p&gt;\n\n&lt;p&gt;I do currently have both NVME slots on the motherboard populated. However I was thinking of taking those two and putting them on the card as well so (not fully understanding PCIe lanes) that would free up some lanes, right?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1770sc3", "is_robot_indexable": true, "report_reasons": null, "author": "FlyingTexan", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1770sc3/pcie_lanes_and_build_questions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1770sc3/pcie_lanes_and_build_questions/", "subreddit_subscribers": 706687, "created_utc": 1697209381.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi,\n\nI have no experience with data backup (better said with huge amount of data backup). I have started editing videos, so I will have a lot of big files in the future. Because of 4K resolution, high bitrate and more versions of the same project, I can create more than 10 TB of video files every month. I want to keep my projects possibly forever. Those files will not be accessed very often, but I would also like to avoid some cold cloud storage where restoring data can take many hours. So files should be accessible quite fast, but on the other hand, they won't be accessed on daily basis. I will have also some databases and 3D engine projects, but those files would be always copied to NVMe SSD when I would work with them.\n\nI have heard about [Sync.com](https://Sync.com) unlimited cloud storage plan, but I don't have any experience with them and I have heard about low upload speeds etc. \n\nSo I am thinking I will need to just keep buying HDDs and save my project backups on those drives. I don't think NAS is needed as data will not be synced between devices and data will be accessed only from time to time. \n\nMy current plan is to buy an external 3.5\" USB HDD docking station for 2 - 4 hard drives and just use it only when I will need to write/read/copy back to faster SSD purposes. And when the free space on the HDD is gone, just switch to another HDD. \n\n\\- What would you recommend to me? Cloud or keep it at home on hard drives?\n\n\\- I was looking at Seagate Exos 20TB Hard drives, do you think is it better to have high capacity drives or better smaller ones (like 6 - 8 TB)?\n\n\\- Does my approach even make any sense? Like I said, I have no experience, so trying to find solution on my own, but if you have better way or some tips for me, I'll be very happy.\n\nThanks!", "author_fullname": "t2_5mazhle4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Cloud vs HDD backup", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "backup", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177m6n4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Backup", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697278042.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi,&lt;/p&gt;\n\n&lt;p&gt;I have no experience with data backup (better said with huge amount of data backup). I have started editing videos, so I will have a lot of big files in the future. Because of 4K resolution, high bitrate and more versions of the same project, I can create more than 10 TB of video files every month. I want to keep my projects possibly forever. Those files will not be accessed very often, but I would also like to avoid some cold cloud storage where restoring data can take many hours. So files should be accessible quite fast, but on the other hand, they won&amp;#39;t be accessed on daily basis. I will have also some databases and 3D engine projects, but those files would be always copied to NVMe SSD when I would work with them.&lt;/p&gt;\n\n&lt;p&gt;I have heard about &lt;a href=\"https://Sync.com\"&gt;Sync.com&lt;/a&gt; unlimited cloud storage plan, but I don&amp;#39;t have any experience with them and I have heard about low upload speeds etc. &lt;/p&gt;\n\n&lt;p&gt;So I am thinking I will need to just keep buying HDDs and save my project backups on those drives. I don&amp;#39;t think NAS is needed as data will not be synced between devices and data will be accessed only from time to time. &lt;/p&gt;\n\n&lt;p&gt;My current plan is to buy an external 3.5&amp;quot; USB HDD docking station for 2 - 4 hard drives and just use it only when I will need to write/read/copy back to faster SSD purposes. And when the free space on the HDD is gone, just switch to another HDD. &lt;/p&gt;\n\n&lt;p&gt;- What would you recommend to me? Cloud or keep it at home on hard drives?&lt;/p&gt;\n\n&lt;p&gt;- I was looking at Seagate Exos 20TB Hard drives, do you think is it better to have high capacity drives or better smaller ones (like 6 - 8 TB)?&lt;/p&gt;\n\n&lt;p&gt;- Does my approach even make any sense? Like I said, I have no experience, so trying to find solution on my own, but if you have better way or some tips for me, I&amp;#39;ll be very happy.&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "7eead6f2-b94e-11eb-af94-0e4c7cd4fb01", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177m6n4", "is_robot_indexable": true, "report_reasons": null, "author": "casstoner27", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177m6n4/cloud_vs_hdd_backup/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177m6n4/cloud_vs_hdd_backup/", "subreddit_subscribers": 706687, "created_utc": 1697278042.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "First, thank you in advance for any guidance you can provide.\n\nI have a PC with an adaptec 71605 raid controller and 4 [WD80EMAZ](https://www.westerndigital.com/products/internal-drives/wd-red-plus-sata-3-5-hdd?sku=WD10EFRX) (8gb) drives.  Asrock Motherboard (don't recall), 32 gb mem and strong i7 CPU.  Windows 10 pro or 11 (sorry I don't recall and unable to boot to verify).  It has an AMD 6800 Video card.\n\nEverything was working fine (famous last words) until the controller started a high pitch alarm.  I did a standard shutdown through windows.\n\nThought this may be a heat related (explanation as to why below) issue so I opened the case, put a fan on it, and allowed 15 minutes to cool down.Now when I attempt to restart I now get the following message\n\n[https://imgur.com/K1pbyzl](https://imgur.com/K1pbyzl)\n\nThe reason I thought this to be a heat related issue is that 30 days ago, the alarm sounded in the middle of the night.  I truly thought it was one of my smoke detectors and my house was on fire; it was so loud.\n\nThe next day I recreated the load the computer was under (upscaling and enhancing large video files (using Topaz AI) that take 8 to 10 hours to process (thus why I crunch them overnight). \n\nUnder duplicate conditions I found the ADAPTC card to be 115 Degrees F directly being the control chip on the back of the card, so upgraded the heatsink and fans, and running temps under load dropped 20 degrees. \n\nIt has run flawlessly since.\n\nOld heatsink config - [https://imgur.com/6af1ZE5](https://imgur.com/6af1ZE5)\n\nNew Heat Sink - [https://imgur.com/xiUuGWf](https://imgur.com/xiUuGWf)\n\nNew Heat Sink In Place - [https://imgur.com/3lFP0CF](https://imgur.com/3lFP0CF)\n\nMy understanding was with the battery back up, the raid could be recovered. Additionally I have 3 additional identical drives,  a second raid card, and batterback up memory that attaches to the card. These should help to diagnose and fix (I hope).   I kept these just in-case, but realized that I don't have any idea what to do.\n\nMy biggest concern is clicking something incorrectly and losing the information that is there. Some files are irreplaceable.\n\nI have limited knowledge, but smart enough to know this is completely out of my league. Any guidance or suggestions are appreciated.", "author_fullname": "t2_3vzsujkt", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need Guidance with Adaptec 71605 controller Raid 5 | PLEASE HELP|", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177ltqc", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697276446.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;First, thank you in advance for any guidance you can provide.&lt;/p&gt;\n\n&lt;p&gt;I have a PC with an adaptec 71605 raid controller and 4 &lt;a href=\"https://www.westerndigital.com/products/internal-drives/wd-red-plus-sata-3-5-hdd?sku=WD10EFRX\"&gt;WD80EMAZ&lt;/a&gt; (8gb) drives.  Asrock Motherboard (don&amp;#39;t recall), 32 gb mem and strong i7 CPU.  Windows 10 pro or 11 (sorry I don&amp;#39;t recall and unable to boot to verify).  It has an AMD 6800 Video card.&lt;/p&gt;\n\n&lt;p&gt;Everything was working fine (famous last words) until the controller started a high pitch alarm.  I did a standard shutdown through windows.&lt;/p&gt;\n\n&lt;p&gt;Thought this may be a heat related (explanation as to why below) issue so I opened the case, put a fan on it, and allowed 15 minutes to cool down.Now when I attempt to restart I now get the following message&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://imgur.com/K1pbyzl\"&gt;https://imgur.com/K1pbyzl&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The reason I thought this to be a heat related issue is that 30 days ago, the alarm sounded in the middle of the night.  I truly thought it was one of my smoke detectors and my house was on fire; it was so loud.&lt;/p&gt;\n\n&lt;p&gt;The next day I recreated the load the computer was under (upscaling and enhancing large video files (using Topaz AI) that take 8 to 10 hours to process (thus why I crunch them overnight). &lt;/p&gt;\n\n&lt;p&gt;Under duplicate conditions I found the ADAPTC card to be 115 Degrees F directly being the control chip on the back of the card, so upgraded the heatsink and fans, and running temps under load dropped 20 degrees. &lt;/p&gt;\n\n&lt;p&gt;It has run flawlessly since.&lt;/p&gt;\n\n&lt;p&gt;Old heatsink config - &lt;a href=\"https://imgur.com/6af1ZE5\"&gt;https://imgur.com/6af1ZE5&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;New Heat Sink - &lt;a href=\"https://imgur.com/xiUuGWf\"&gt;https://imgur.com/xiUuGWf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;New Heat Sink In Place - &lt;a href=\"https://imgur.com/3lFP0CF\"&gt;https://imgur.com/3lFP0CF&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My understanding was with the battery back up, the raid could be recovered. Additionally I have 3 additional identical drives,  a second raid card, and batterback up memory that attaches to the card. These should help to diagnose and fix (I hope).   I kept these just in-case, but realized that I don&amp;#39;t have any idea what to do.&lt;/p&gt;\n\n&lt;p&gt;My biggest concern is clicking something incorrectly and losing the information that is there. Some files are irreplaceable.&lt;/p&gt;\n\n&lt;p&gt;I have limited knowledge, but smart enough to know this is completely out of my league. Any guidance or suggestions are appreciated.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xl_KQWVSIQnEbZ03PuuU3-ePX9iWAtFtY40q3WzXPms.jpg?auto=webp&amp;s=790048748e4980a652609e82a4436043dc40ae0a", "width": 600, "height": 315}, "resolutions": [{"url": "https://external-preview.redd.it/xl_KQWVSIQnEbZ03PuuU3-ePX9iWAtFtY40q3WzXPms.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=28c465e3200e1c6e6dbb7aa466d611e7dbb77141", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/xl_KQWVSIQnEbZ03PuuU3-ePX9iWAtFtY40q3WzXPms.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=60f3917aff6afee7c055a3d81ac4a0e07026b087", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/xl_KQWVSIQnEbZ03PuuU3-ePX9iWAtFtY40q3WzXPms.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=80a8b3c340fa9abc2c11beeb9d99497c9ab53175", "width": 320, "height": 168}], "variants": {}, "id": "7ViyWioditWLgxrgjxN95siZEUT1Oq4RBzzMQHRlNA0"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177ltqc", "is_robot_indexable": true, "report_reasons": null, "author": "eleutherios4u", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177ltqc/need_guidance_with_adaptec_71605_controller_raid/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177ltqc/need_guidance_with_adaptec_71605_controller_raid/", "subreddit_subscribers": 706687, "created_utc": 1697276446.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi all, I\u2019ve been scouring the internet and this sub for an answer to this but I haven\u2019t found anything. I\u2019m in the process of trying to backup my external hard drive to another, and after doing some research I decided to give the free trial of Chronosync a try. During my first backup, though, I noticed maybe 10 random files weren\u2019t going through, they refuse to synchronize, and they all give me the error \u201cError: Source Target encountered error: Error Code -19.\u201d I also got the log \u201cFSEvent database problems detected on: Root folder on \u201chard drive\u201d. Everything is fine but your sync tasks may run less than optimally.\u201d and then the synchronize always fails. \n\nHas anyone here used Chronosync and knows what this means? Or maybe does this have nothing to do with Chronosync and more with the select files? I\u2019m just super confused because there doesn\u2019t seem to be anything about those specific files that are different from the many other files that did go through. \n\nI\u2019m new to this kind of thing, so this has stumped me. Does anyone have any ideas or explanation as to why this might be happening? If this is just how backups go I\u2019ll just make sure to keep copies on hand to fill in the gaps, but if it\u2019s something I\u2019m doing wrong I\u2019d really appreciate some guidance.", "author_fullname": "t2_3suov14m", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Having trouble backing up with Chronosync", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "troubleshooting", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177gqmk", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Troubleshooting", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697255408.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I\u2019ve been scouring the internet and this sub for an answer to this but I haven\u2019t found anything. I\u2019m in the process of trying to backup my external hard drive to another, and after doing some research I decided to give the free trial of Chronosync a try. During my first backup, though, I noticed maybe 10 random files weren\u2019t going through, they refuse to synchronize, and they all give me the error \u201cError: Source Target encountered error: Error Code -19.\u201d I also got the log \u201cFSEvent database problems detected on: Root folder on \u201chard drive\u201d. Everything is fine but your sync tasks may run less than optimally.\u201d and then the synchronize always fails. &lt;/p&gt;\n\n&lt;p&gt;Has anyone here used Chronosync and knows what this means? Or maybe does this have nothing to do with Chronosync and more with the select files? I\u2019m just super confused because there doesn\u2019t seem to be anything about those specific files that are different from the many other files that did go through. &lt;/p&gt;\n\n&lt;p&gt;I\u2019m new to this kind of thing, so this has stumped me. Does anyone have any ideas or explanation as to why this might be happening? If this is just how backups go I\u2019ll just make sure to keep copies on hand to fill in the gaps, but if it\u2019s something I\u2019m doing wrong I\u2019d really appreciate some guidance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "5b6d7a04-b94e-11eb-b676-0ed4dfcb172d", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177gqmk", "is_robot_indexable": true, "report_reasons": null, "author": "Expensive_Grape", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177gqmk/having_trouble_backing_up_with_chronosync/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177gqmk/having_trouble_backing_up_with_chronosync/", "subreddit_subscribers": 706687, "created_utc": 1697255408.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I just bought two 10TB HDD's for a future planned raspberry pi NAS build. I read about softRAID's verify function, so made a start on that as soon as the disks arrived. It's been going for 48 hours and has 30 hours remaining. However, (stupidly, I know) I only just read softRAID's [installation instructions](https://softraid.com/docs/softraid-quick-start-guide/installation-macos/additional-steps-for-apple-silicon-macs/) for apple silicon macs. Apparently I was supposed to enable reduced security and enable full disk access?\n\nMy question is, does this matter for the verify function on external hdd's in an OWC Mercury Pro Dual enclosure, connected via USB? Have I wasted the 48-hours it's taken thus far and need to start again with the proper installation method?\n\nI didn't get any issues pop up during the installation, I restarted the mac as softRAID requested, and it never said I needed to enable reduced security or full disk access. Nor have there been any errors during the verify function, it seems to be going fine so far. I'm hoping that I haven't wasted my time, and that those functions are only needed if I actually then went on to create a software RAID, or else run those functions on the system ssd?", "author_fullname": "t2_1996co4u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Have I wasted my time with SoftRAID's certify?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1778pc4", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697231120.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I just bought two 10TB HDD&amp;#39;s for a future planned raspberry pi NAS build. I read about softRAID&amp;#39;s verify function, so made a start on that as soon as the disks arrived. It&amp;#39;s been going for 48 hours and has 30 hours remaining. However, (stupidly, I know) I only just read softRAID&amp;#39;s &lt;a href=\"https://softraid.com/docs/softraid-quick-start-guide/installation-macos/additional-steps-for-apple-silicon-macs/\"&gt;installation instructions&lt;/a&gt; for apple silicon macs. Apparently I was supposed to enable reduced security and enable full disk access?&lt;/p&gt;\n\n&lt;p&gt;My question is, does this matter for the verify function on external hdd&amp;#39;s in an OWC Mercury Pro Dual enclosure, connected via USB? Have I wasted the 48-hours it&amp;#39;s taken thus far and need to start again with the proper installation method?&lt;/p&gt;\n\n&lt;p&gt;I didn&amp;#39;t get any issues pop up during the installation, I restarted the mac as softRAID requested, and it never said I needed to enable reduced security or full disk access. Nor have there been any errors during the verify function, it seems to be going fine so far. I&amp;#39;m hoping that I haven&amp;#39;t wasted my time, and that those functions are only needed if I actually then went on to create a software RAID, or else run those functions on the system ssd?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/qOUvtwV5CN77I71A6XKclfqf2UsUiwy-xoqsF2-EiR0.jpg?auto=webp&amp;s=423402e9367bd885d07409ef7a9617bdead7b336", "width": 396, "height": 347}, "resolutions": [{"url": "https://external-preview.redd.it/qOUvtwV5CN77I71A6XKclfqf2UsUiwy-xoqsF2-EiR0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=2d97c40fbb06a698a296a193fa171244fcfba80b", "width": 108, "height": 94}, {"url": "https://external-preview.redd.it/qOUvtwV5CN77I71A6XKclfqf2UsUiwy-xoqsF2-EiR0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=92ac229ae2124a66e776916b3e28f3e72b27ecf8", "width": 216, "height": 189}, {"url": "https://external-preview.redd.it/qOUvtwV5CN77I71A6XKclfqf2UsUiwy-xoqsF2-EiR0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=62b62bac7cbc2b2d89979dbb0ec5f1a48fb9c470", "width": 320, "height": 280}], "variants": {}, "id": "l91vH6H_gPkAl-Fao9OhwbWPE8gEeq8Tko0sx2_tToI"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1778pc4", "is_robot_indexable": true, "report_reasons": null, "author": "IIb-dII", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1778pc4/have_i_wasted_my_time_with_softraids_certify/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1778pc4/have_i_wasted_my_time_with_softraids_certify/", "subreddit_subscribers": 706687, "created_utc": 1697231120.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I asked Backblaze:\n\n&gt;My concern is that using a debit or credit card is  not a reliable way of payment. Sometimes payments don't work (i.e. the  account is frozen/closed for some random reason, other technical  issues).Can I make a prepayment for the B2 service to be sure that my files will not be deleted after a failed transaction?I  know about your gift cards but my impression is that they are for\u00a0 your  other services. If not, you did not communicate it well to customers  that the credit is also good for the B2 service.I do not trust banks and payment service providers. They are not reliable.\n\nTheir answer:\n\n&gt;Unfortunately there is no way to schedule a pre-payment for our B2  service as it is all calculated on a per-monthly basis. We apologies for  the inconvenience.\n\nDo you know any similar service that allow making a payment in advance (prepayment)?\n\nMaybe the word prepayment is misleading. My idea is to give some money to the company to be used to cover my future expenses (in order to avoid data loss incidents because of payment failures for the monthly/yearly invoices). Of course I realize that the amount I will owe can't be determined in advance.", "author_fullname": "t2_i61gg", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "File storage (or backup) services that allow prepayment", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "discussion", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_177q0af", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697291431.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I asked Backblaze:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;My concern is that using a debit or credit card is  not a reliable way of payment. Sometimes payments don&amp;#39;t work (i.e. the  account is frozen/closed for some random reason, other technical  issues).Can I make a prepayment for the B2 service to be sure that my files will not be deleted after a failed transaction?I  know about your gift cards but my impression is that they are for\u00a0 your  other services. If not, you did not communicate it well to customers  that the credit is also good for the B2 service.I do not trust banks and payment service providers. They are not reliable.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Their answer:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Unfortunately there is no way to schedule a pre-payment for our B2  service as it is all calculated on a per-monthly basis. We apologies for  the inconvenience.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Do you know any similar service that allow making a payment in advance (prepayment)?&lt;/p&gt;\n\n&lt;p&gt;Maybe the word prepayment is misleading. My idea is to give some money to the company to be used to cover my future expenses (in order to avoid data loss incidents because of payment failures for the monthly/yearly invoices). Of course I realize that the amount I will owe can&amp;#39;t be determined in advance.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "20c598d2-b3f5-11ea-8f7a-0e7cd54fad9b", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#dadada", "id": "177q0af", "is_robot_indexable": true, "report_reasons": null, "author": "vstoykov", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177q0af/file_storage_or_backup_services_that_allow/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177q0af/file_storage_or_backup_services_that_allow/", "subreddit_subscribers": 706687, "created_utc": 1697291431.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Bit of a Mac OS X specific thing, but I'm sure it all comes down to the UNIX foundations in the end, right?\n\nA good while ago I had an issue with just one database, my sqlite Notes database getting corrupt, and I think it happened somehow when I used my external USB drive as memory for Photoshop, carried the laptop and drive across to another room and it may have shifted around a bit.\n\nMy thinking was, its sorta like when you get the books in your bookshelf out of order by a fraction, it throws the whole thing off eventually, so something seemed to have moved around, and that file and others became corrupt the more I began to use the computer.\n\nIn the end, I had made a backup before it got too bad, but that also would have backed up said corrupt files. My thinking is they are sorta 'frozen in time' and won't go about corrupting things of their own accord.\n\nNow, I've looked through the backup as best as I can, its with CCC, and everything seems to be in order, and I've been thinking of dragging and dropping or command line copying folders one by one, ignoring the system and starting the OS fresh just to be safe.\n\nWhat's the chances that the other files are somehow corrupt in ways I can't see? Is that a thing that can happen with files?\n\nI say this as I also have noticed with some external drives that have backups on them, these are say 4\u20135TB drives, sometimes they don't report the accurate file count. It'll say the accurate folder size but list it as having 0 files inside, when I can see that there are files.\n\nThe problem I'm trying to avoid here is say if I copy my Documents or Photos that there's some rogue file in there that is going to spread outwards corrupting the brand new OS, starting the problem all over again.\n\nWould love some guidance, advice, and help understanding how this all works. I'm developing my fluency in these systems still!\n\nEdit: Love this subreddit so much by the way, there's so many straight up \\*nerds\\* about data and I love it, I'm so glad people get so hyped and passionate about data, archiving, and best practices, it resonates with my A.S.  \n\n\nHappy to give more overly verbose information if needed to help answer some of this!", "author_fullname": "t2_ay9kx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can slowly reintroducing backup files to a fresh OS also unknowingly copy corrupts files too?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177o237", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697285208.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Bit of a Mac OS X specific thing, but I&amp;#39;m sure it all comes down to the UNIX foundations in the end, right?&lt;/p&gt;\n\n&lt;p&gt;A good while ago I had an issue with just one database, my sqlite Notes database getting corrupt, and I think it happened somehow when I used my external USB drive as memory for Photoshop, carried the laptop and drive across to another room and it may have shifted around a bit.&lt;/p&gt;\n\n&lt;p&gt;My thinking was, its sorta like when you get the books in your bookshelf out of order by a fraction, it throws the whole thing off eventually, so something seemed to have moved around, and that file and others became corrupt the more I began to use the computer.&lt;/p&gt;\n\n&lt;p&gt;In the end, I had made a backup before it got too bad, but that also would have backed up said corrupt files. My thinking is they are sorta &amp;#39;frozen in time&amp;#39; and won&amp;#39;t go about corrupting things of their own accord.&lt;/p&gt;\n\n&lt;p&gt;Now, I&amp;#39;ve looked through the backup as best as I can, its with CCC, and everything seems to be in order, and I&amp;#39;ve been thinking of dragging and dropping or command line copying folders one by one, ignoring the system and starting the OS fresh just to be safe.&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the chances that the other files are somehow corrupt in ways I can&amp;#39;t see? Is that a thing that can happen with files?&lt;/p&gt;\n\n&lt;p&gt;I say this as I also have noticed with some external drives that have backups on them, these are say 4\u20135TB drives, sometimes they don&amp;#39;t report the accurate file count. It&amp;#39;ll say the accurate folder size but list it as having 0 files inside, when I can see that there are files.&lt;/p&gt;\n\n&lt;p&gt;The problem I&amp;#39;m trying to avoid here is say if I copy my Documents or Photos that there&amp;#39;s some rogue file in there that is going to spread outwards corrupting the brand new OS, starting the problem all over again.&lt;/p&gt;\n\n&lt;p&gt;Would love some guidance, advice, and help understanding how this all works. I&amp;#39;m developing my fluency in these systems still!&lt;/p&gt;\n\n&lt;p&gt;Edit: Love this subreddit so much by the way, there&amp;#39;s so many straight up *nerds* about data and I love it, I&amp;#39;m so glad people get so hyped and passionate about data, archiving, and best practices, it resonates with my A.S.  &lt;/p&gt;\n\n&lt;p&gt;Happy to give more overly verbose information if needed to help answer some of this!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177o237", "is_robot_indexable": true, "report_reasons": null, "author": "louisbullock", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177o237/can_slowly_reintroducing_backup_files_to_a_fresh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177o237/can_slowly_reintroducing_backup_files_to_a_fresh/", "subreddit_subscribers": 706687, "created_utc": 1697285208.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I'm excited to finally have somewhere to dump and organize huge (by my standards) quantities of scattered files that i can then access from anywhere and can depend to stay online, and also to set up file streaming for family for movies/tv shows and maybe a little utorrent seedbox. Anyway, I kinda bought 90tb of hard disks (they were a good deal) + 2x 4tb nvme drives to be a r/w cache + 32gb ecc ram + ups + 10gbe pcie card for the NAS and my PC, etc...all just to kit out a Synology ds1522+ to the gills. However, my current amount of data after years of hoarding it in my pc including various external drives, internal hot swap drives, usb sticks, etc. is probably only around 15-20tb, maybe less if some of these decade old 500gb drives I have lying everywhere died over the years. This amount of data took many years to amass, albeit i was never drowning in free space like I'm about to be so I have been deleting some stuff.\n\nHow should I configure it when it gets here? I don't need anywhere near 90tb yet apparently, so I was thinking of just running 4 of the drives in Raid 10, 1 spare, and just having 36tb of fast storage that i can easily leverage 10gbe with in sequential and with some redundancy and higher iops. Kind of a waste of a bay for now, but If I need more storage later (maybe years later), and I haven't had to use the spare yet, wouldn't it be possible for me to simply degrade the array down to 3 disks, copy all 36tb onto the spare + the raid orphaned drive, and then rebuild the array into a fresh raid 5, copy the data off of the single drives onto the raid array and then expand the array into the 2 singles seamlessly, without having to call up backblaze and have backups literally delivered to my door? I am not sure if this is possible because I've never used a raid array before, but it sounds doable from what I've read.\n\nAlso also, could I go from 10 to 5 to 6 for that sweet extra URE rebuild protection with this sequence of actions? Degrade 36tb raid 10 -&gt; Copy all files to 2x 18tb single drives -&gt; Build 3-disk Raid 5 -&gt; Transfer one of the disk's data onto the Raid 5 -&gt; Expand Raid 5 into this disk -&gt; Copy the remaining files off the other single disk onto the Raid 5 -&gt; Add it to the Raid 5 array as a second parity disk to create a raid 6 with all the original data.\n\nIt bears mentioning I have no solid concept of the sheer amount of TIME either of these methods of raid conversions may take with drives this size.\n\nYeah, I've made some very questionable financial choices today... Any other advice other than return some of the drives is appreciated, I NEED THIS.. because I want it...", "author_fullname": "t2_cyh4y6wh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "newbie, just bought first nas... I probably overdid it.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177jlme", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.62, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697267197.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697266755.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m excited to finally have somewhere to dump and organize huge (by my standards) quantities of scattered files that i can then access from anywhere and can depend to stay online, and also to set up file streaming for family for movies/tv shows and maybe a little utorrent seedbox. Anyway, I kinda bought 90tb of hard disks (they were a good deal) + 2x 4tb nvme drives to be a r/w cache + 32gb ecc ram + ups + 10gbe pcie card for the NAS and my PC, etc...all just to kit out a Synology ds1522+ to the gills. However, my current amount of data after years of hoarding it in my pc including various external drives, internal hot swap drives, usb sticks, etc. is probably only around 15-20tb, maybe less if some of these decade old 500gb drives I have lying everywhere died over the years. This amount of data took many years to amass, albeit i was never drowning in free space like I&amp;#39;m about to be so I have been deleting some stuff.&lt;/p&gt;\n\n&lt;p&gt;How should I configure it when it gets here? I don&amp;#39;t need anywhere near 90tb yet apparently, so I was thinking of just running 4 of the drives in Raid 10, 1 spare, and just having 36tb of fast storage that i can easily leverage 10gbe with in sequential and with some redundancy and higher iops. Kind of a waste of a bay for now, but If I need more storage later (maybe years later), and I haven&amp;#39;t had to use the spare yet, wouldn&amp;#39;t it be possible for me to simply degrade the array down to 3 disks, copy all 36tb onto the spare + the raid orphaned drive, and then rebuild the array into a fresh raid 5, copy the data off of the single drives onto the raid array and then expand the array into the 2 singles seamlessly, without having to call up backblaze and have backups literally delivered to my door? I am not sure if this is possible because I&amp;#39;ve never used a raid array before, but it sounds doable from what I&amp;#39;ve read.&lt;/p&gt;\n\n&lt;p&gt;Also also, could I go from 10 to 5 to 6 for that sweet extra URE rebuild protection with this sequence of actions? Degrade 36tb raid 10 -&amp;gt; Copy all files to 2x 18tb single drives -&amp;gt; Build 3-disk Raid 5 -&amp;gt; Transfer one of the disk&amp;#39;s data onto the Raid 5 -&amp;gt; Expand Raid 5 into this disk -&amp;gt; Copy the remaining files off the other single disk onto the Raid 5 -&amp;gt; Add it to the Raid 5 array as a second parity disk to create a raid 6 with all the original data.&lt;/p&gt;\n\n&lt;p&gt;It bears mentioning I have no solid concept of the sheer amount of TIME either of these methods of raid conversions may take with drives this size.&lt;/p&gt;\n\n&lt;p&gt;Yeah, I&amp;#39;ve made some very questionable financial choices today... Any other advice other than return some of the drives is appreciated, I NEED THIS.. because I want it...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177jlme", "is_robot_indexable": true, "report_reasons": null, "author": "100Eve", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177jlme/newbie_just_bought_first_nas_i_probably_overdid_it/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177jlme/newbie_just_bought_first_nas_i_probably_overdid_it/", "subreddit_subscribers": 706687, "created_utc": 1697266755.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "from a cursory look-around, i gathered that jdowloader2 was a reliable way to download my deviantart favorites gallery, but i have been unsuccessful in figuring out how to do that.\n\ni got as far as successfully installing Eclipse and Jdowloader2 but i am unclear on where to go from here . i think i might have all the tools , i just don\u2019t know what to do with them .\n\ncan anyone help me out here ?", "author_fullname": "t2_51yimtz6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "deviantart downloading favorites gallery with jdownloader2 help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177gl1y", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697254816.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;from a cursory look-around, i gathered that jdowloader2 was a reliable way to download my deviantart favorites gallery, but i have been unsuccessful in figuring out how to do that.&lt;/p&gt;\n\n&lt;p&gt;i got as far as successfully installing Eclipse and Jdowloader2 but i am unclear on where to go from here . i think i might have all the tools , i just don\u2019t know what to do with them .&lt;/p&gt;\n\n&lt;p&gt;can anyone help me out here ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177gl1y", "is_robot_indexable": true, "report_reasons": null, "author": "TheGarbageRatMan", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177gl1y/deviantart_downloading_favorites_gallery_with/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177gl1y/deviantart_downloading_favorites_gallery_with/", "subreddit_subscribers": 706687, "created_utc": 1697254816.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "", "user_reports": [], "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mac mini M2 + Synology DS1522+ Plex Server Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1778p9u", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "author_fullname": "t2_gf09d", "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "crosspost_parent_list": [{"approved_at_utc": null, "subreddit": "synology", "selftext": "Hey all, apologies if these questions have been answered elsewhere. I'm completely new to running a fully-featured Plex server (though I briefly ran an Nvidia Shield PMS), and I could use some help figuring out some of the details with how things should be set up. \n\nI'm going to have all my media stored on a DS1522+, with two 12TB Seagate Ironwolf drives and another 12TB Western Digital drive that I need to shuck out of an EasyStore external hard drive enclosure. \n\nThat WD drive currently has a few hundred 4K Blu-Ray rips from when I tried running an Nvidia Shield server, so I'd like to keep the media on them when I set up the Synology box.\n\nI'd also like to run Plex Media Server natively on the Mac mini vs. running in a Docker container, as I've heard PMS runs really well, now that it's native to Apple Silicon. I'd like to use the hardware for transcoding, when necessary. \n\nOn the DS1522+, I'd like to run Docker containers for Sonarr, Radarr, and Sabnzbd (or nzbget, whichever is better). Basically, I\u2019d like to have the NAS handle all downloading and media storage and have the Mac exclusively run all Plex server tasks.\n\nSo with this information in mind can you help answer these questions:\n\n1.\tWould there be any benefit to upgrading the hardware on the DS1522+, like the RAM, NVMe, or 10GbE?\n2.\tDo I need to run a RAID or SHR on the NAS for ideal performance? If so, what\u2019re the best steps to get my media from my WD drive onto the array?\n3.\tWhat\u2019s the best way to connect the Synology to my Mac?\n\nAny other tips, advice, or guidance would be great!\n\nThank you so much!", "author_fullname": "t2_gf09d", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Mac mini M2 + Synology DS1522+ Plex Server Help", "link_flair_richtext": [], "subreddit_name_prefixed": "r/synology", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1778oen", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "NAS hardware", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697231903.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697231054.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.synology", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey all, apologies if these questions have been answered elsewhere. I&amp;#39;m completely new to running a fully-featured Plex server (though I briefly ran an Nvidia Shield PMS), and I could use some help figuring out some of the details with how things should be set up. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m going to have all my media stored on a DS1522+, with two 12TB Seagate Ironwolf drives and another 12TB Western Digital drive that I need to shuck out of an EasyStore external hard drive enclosure. &lt;/p&gt;\n\n&lt;p&gt;That WD drive currently has a few hundred 4K Blu-Ray rips from when I tried running an Nvidia Shield server, so I&amp;#39;d like to keep the media on them when I set up the Synology box.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d also like to run Plex Media Server natively on the Mac mini vs. running in a Docker container, as I&amp;#39;ve heard PMS runs really well, now that it&amp;#39;s native to Apple Silicon. I&amp;#39;d like to use the hardware for transcoding, when necessary. &lt;/p&gt;\n\n&lt;p&gt;On the DS1522+, I&amp;#39;d like to run Docker containers for Sonarr, Radarr, and Sabnzbd (or nzbget, whichever is better). Basically, I\u2019d like to have the NAS handle all downloading and media storage and have the Mac exclusively run all Plex server tasks.&lt;/p&gt;\n\n&lt;p&gt;So with this information in mind can you help answer these questions:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt; Would there be any benefit to upgrading the hardware on the DS1522+, like the RAM, NVMe, or 10GbE?&lt;/li&gt;\n&lt;li&gt; Do I need to run a RAID or SHR on the NAS for ideal performance? If so, what\u2019re the best steps to get my media from my WD drive onto the array?&lt;/li&gt;\n&lt;li&gt; What\u2019s the best way to connect the Synology to my Mac?&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Any other tips, advice, or guidance would be great!&lt;/p&gt;\n\n&lt;p&gt;Thank you so much!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "1b45c7c8-4b25-11ed-a1f3-5a29a1a8c4d9", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2s4co", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#cc3600", "id": "1778oen", "is_robot_indexable": true, "report_reasons": null, "author": "rackemrackbar", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/synology/comments/1778oen/mac_mini_m2_synology_ds1522_plex_server_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/synology/comments/1778oen/mac_mini_m2_synology_ds1522_plex_server_help/", "subreddit_subscribers": 130912, "created_utc": 1697231054.0, "num_crossposts": 2, "media": null, "is_video": false}], "created": 1697231115.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.synology", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "/r/synology/comments/1778oen/mac_mini_m2_synology_ds1522_plex_server_help/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1778p9u", "is_robot_indexable": true, "report_reasons": null, "author": "rackemrackbar", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "crosspost_parent": "t3_1778oen", "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1778p9u/mac_mini_m2_synology_ds1522_plex_server_help/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "/r/synology/comments/1778oen/mac_mini_m2_synology_ds1522_plex_server_help/", "subreddit_subscribers": 706687, "created_utc": 1697231115.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I wanted to download my Snapchat data to try and archive all of the saved texts and snaps from a specific group chat. The problem is, when I downloaded it the text is perfectly well organized but all the media is lumped into one file with no time stamps or even info on what chat they were from. Is there a way for me to properly create a timeline of saved photos that have been sent to a specific group chat? ", "author_fullname": "t2_28q8pd4l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Snapchat data saved photos not having any timestamps", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1775gyu", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697222155.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I wanted to download my Snapchat data to try and archive all of the saved texts and snaps from a specific group chat. The problem is, when I downloaded it the text is perfectly well organized but all the media is lumped into one file with no time stamps or even info on what chat they were from. Is there a way for me to properly create a timeline of saved photos that have been sent to a specific group chat? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1775gyu", "is_robot_indexable": true, "report_reasons": null, "author": "BforBaloney", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1775gyu/snapchat_data_saved_photos_not_having_any/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1775gyu/snapchat_data_saved_photos_not_having_any/", "subreddit_subscribers": 706687, "created_utc": 1697222155.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have thousands of files in a few folders on my PC, I need to sort and arrange those files, what I need is a software that let's me select multiple files , allows me to create a folder, move said files to the folder which I will name on the spot.\n\nIs there such a thing? I'm on windows and I have thousands of files on multiple folders to sort through.\n\nPlease help and thank you!", "author_fullname": "t2_1qcdd344", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Software to quickly move multiple files to a folder?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1775913", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697221574.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have thousands of files in a few folders on my PC, I need to sort and arrange those files, what I need is a software that let&amp;#39;s me select multiple files , allows me to create a folder, move said files to the folder which I will name on the spot.&lt;/p&gt;\n\n&lt;p&gt;Is there such a thing? I&amp;#39;m on windows and I have thousands of files on multiple folders to sort through.&lt;/p&gt;\n\n&lt;p&gt;Please help and thank you!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1775913", "is_robot_indexable": true, "report_reasons": null, "author": "RusselAxel", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1775913/software_to_quickly_move_multiple_files_to_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1775913/software_to_quickly_move_multiple_files_to_a/", "subreddit_subscribers": 706687, "created_utc": 1697221574.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "So I have a spare 2.5 SSD I would like to put in my PC, but the 6 SATA connectors on my motherboard are already taken. I do have an internal USB 3.0 and 3.1 free, but I can't find any SATA adapters for them. My motherboard: [https://www.gigabyte.com/Motherboard/X570-AORUS-ELITE-rev-10](https://www.gigabyte.com/Motherboard/X570-AORUS-ELITE-rev-10)\n\n&amp;#x200B;\n\nThis is what I saw so far:\n\n[https://www.amazon.co.uk/SYSTEM-S-SATA-Placa-Adaptador-Conversor/dp/B08J7Q81SF](https://www.amazon.co.uk/SYSTEM-S-SATA-Placa-Adaptador-Conversor/dp/B08J7Q81SF) \\--&gt; Seems it's unavailable everywhere.\n\n&amp;#x200B;\n\n[https://www.amazon.co.uk/Cavis-Type-Placa-frontal-pulgadas/dp/B083S5DBS6](https://www.amazon.co.uk/Cavis-Type-Placa-frontal-pulgadas/dp/B083S5DBS6) \\--&gt; Available on Amazon Spain, but it would take to much time to arrive, and does not seem very reliable.\n\n&amp;#x200B;\n\n[https://www.amazon.co.uk/BEYIMEI-controladora-Tarjetas-expansi%C3%B3n-Adaptador/dp/B07PRRQ41J](https://www.amazon.co.uk/BEYIMEI-controladora-Tarjetas-expansi%C3%B3n-Adaptador/dp/B07PRRQ41J) \\--&gt; This would arrive on time and it's not expensive, but I don't know this brand.\n\n&amp;#x200B;\n\nWhat would you guys recommend me?\n\n&amp;#x200B;\n\nThanks!\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_2b4fxjk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Need to connect SATA 2.5 SSD to internal USB ports", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1774vb7", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1697220546.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I have a spare 2.5 SSD I would like to put in my PC, but the 6 SATA connectors on my motherboard are already taken. I do have an internal USB 3.0 and 3.1 free, but I can&amp;#39;t find any SATA adapters for them. My motherboard: &lt;a href=\"https://www.gigabyte.com/Motherboard/X570-AORUS-ELITE-rev-10\"&gt;https://www.gigabyte.com/Motherboard/X570-AORUS-ELITE-rev-10&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;This is what I saw so far:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.co.uk/SYSTEM-S-SATA-Placa-Adaptador-Conversor/dp/B08J7Q81SF\"&gt;https://www.amazon.co.uk/SYSTEM-S-SATA-Placa-Adaptador-Conversor/dp/B08J7Q81SF&lt;/a&gt; --&amp;gt; Seems it&amp;#39;s unavailable everywhere.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.co.uk/Cavis-Type-Placa-frontal-pulgadas/dp/B083S5DBS6\"&gt;https://www.amazon.co.uk/Cavis-Type-Placa-frontal-pulgadas/dp/B083S5DBS6&lt;/a&gt; --&amp;gt; Available on Amazon Spain, but it would take to much time to arrive, and does not seem very reliable.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.amazon.co.uk/BEYIMEI-controladora-Tarjetas-expansi%C3%B3n-Adaptador/dp/B07PRRQ41J\"&gt;https://www.amazon.co.uk/BEYIMEI-controladora-Tarjetas-expansi%C3%B3n-Adaptador/dp/B07PRRQ41J&lt;/a&gt; --&amp;gt; This would arrive on time and it&amp;#39;s not expensive, but I don&amp;#39;t know this brand.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;What would you guys recommend me?&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/AWbJCOXyKYAeiT2ATKD6BJB52YUQGxsYk5QMaqKCFAs.jpg?auto=webp&amp;s=4bba92159a6747027dd56f8070e0f007106923a9", "width": 1000, "height": 1000}, "resolutions": [{"url": "https://external-preview.redd.it/AWbJCOXyKYAeiT2ATKD6BJB52YUQGxsYk5QMaqKCFAs.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e065d072acf246ff2cc41832a6ece5bc08f178df", "width": 108, "height": 108}, {"url": "https://external-preview.redd.it/AWbJCOXyKYAeiT2ATKD6BJB52YUQGxsYk5QMaqKCFAs.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=03475e5ddaece6c21d61f8edb6f4f9be762c16f5", "width": 216, "height": 216}, {"url": "https://external-preview.redd.it/AWbJCOXyKYAeiT2ATKD6BJB52YUQGxsYk5QMaqKCFAs.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f7ba02a706ece8b814c17cf800fe90d480c73a8e", "width": 320, "height": 320}, {"url": "https://external-preview.redd.it/AWbJCOXyKYAeiT2ATKD6BJB52YUQGxsYk5QMaqKCFAs.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=7101a25928aff53d2643be2d36141b7cc39f3ea8", "width": 640, "height": 640}, {"url": "https://external-preview.redd.it/AWbJCOXyKYAeiT2ATKD6BJB52YUQGxsYk5QMaqKCFAs.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=d78f59e18b6437b3a7db08038915a20caef89f06", "width": 960, "height": 960}], "variants": {}, "id": "iyt73ffRfhIaLFcHzXiC235amzR4u_A7sBB24S54bRA"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1774vb7", "is_robot_indexable": true, "report_reasons": null, "author": "eXtremeDevil", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1774vb7/need_to_connect_sata_25_ssd_to_internal_usb_ports/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1774vb7/need_to_connect_sata_25_ssd_to_internal_usb_ports/", "subreddit_subscribers": 706687, "created_utc": 1697220546.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I had been using the Snapscan s1300i for about 9 years. Scanning strictly documents only. No receipts, no business cards, etc. Just legal sizes documents. \n\nWorked AMAZING, loved it.  \nRecently upgraded to a new comp. and I don't know why but my s1300i is no longer working which isn't a big deal as it was time to upgrade.  \nMy immediate thought was to just buy the upgraded model, ix1300. I prepared by first downloading and installing the Snapscan Home software to prep. for the eventual purchase but then I checked my task manager and saw that Snapscan had almost 20 processes running.\n\nIs this normal?\n\nI'm trying to figure out whether or not these processes are there because I installed the software and haven't hooked up the scanner yet or if these processes will be permanenet going forward. If it's the later, I'm not sure if I want to dedicate almost a gig of my ram just for Snapscan.\n\nIs there a substitute program I could use?  \n\n\nhttps://preview.redd.it/tyome3xe40ub1.png?width=1604&amp;format=png&amp;auto=webp&amp;s=c090d85c11a6916df7ee7245854619148b9061e1", "author_fullname": "t2_wx4sh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scanner with Lightweight Software? ix1300 or other options?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": 97, "top_awarded_type": null, "hide_score": false, "media_metadata": {"tyome3xe40ub1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 75, "x": 108, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=fdc189b5451bee77385842518b2d57a276cf99a0"}, {"y": 150, "x": 216, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=7fc33a90a1e3f894d595e6ffae5176c3294c7fea"}, {"y": 223, "x": 320, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=3dd5c6576d2cbd265c68c3d05a6299ba8f6c4c54"}, {"y": 446, "x": 640, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=560760ac9bede2d89db47cdd5d38bc7a1951ed77"}, {"y": 669, "x": 960, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=8a07f4ed72faece1bf75c166fcc2c1f100272bfd"}, {"y": 752, "x": 1080, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=778be28762748b954b7f04fdc4f1972acb15e31d"}], "s": {"y": 1118, "x": 1604, "u": "https://preview.redd.it/tyome3xe40ub1.png?width=1604&amp;format=png&amp;auto=webp&amp;s=c090d85c11a6916df7ee7245854619148b9061e1"}, "id": "tyome3xe40ub1"}}, "name": "t3_1773j2o", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/jkb00_Hs2h1V3SdyYVCf4a4dIae8Ua7g0uXPbTF1InY.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697216815.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I had been using the Snapscan s1300i for about 9 years. Scanning strictly documents only. No receipts, no business cards, etc. Just legal sizes documents. &lt;/p&gt;\n\n&lt;p&gt;Worked AMAZING, loved it.&lt;br/&gt;\nRecently upgraded to a new comp. and I don&amp;#39;t know why but my s1300i is no longer working which isn&amp;#39;t a big deal as it was time to upgrade.&lt;br/&gt;\nMy immediate thought was to just buy the upgraded model, ix1300. I prepared by first downloading and installing the Snapscan Home software to prep. for the eventual purchase but then I checked my task manager and saw that Snapscan had almost 20 processes running.&lt;/p&gt;\n\n&lt;p&gt;Is this normal?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out whether or not these processes are there because I installed the software and haven&amp;#39;t hooked up the scanner yet or if these processes will be permanenet going forward. If it&amp;#39;s the later, I&amp;#39;m not sure if I want to dedicate almost a gig of my ram just for Snapscan.&lt;/p&gt;\n\n&lt;p&gt;Is there a substitute program I could use?  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/tyome3xe40ub1.png?width=1604&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c090d85c11a6916df7ee7245854619148b9061e1\"&gt;https://preview.redd.it/tyome3xe40ub1.png?width=1604&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=c090d85c11a6916df7ee7245854619148b9061e1&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1773j2o", "is_robot_indexable": true, "report_reasons": null, "author": "imnotuglyyouare", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1773j2o/scanner_with_lightweight_software_ix1300_or_other/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1773j2o/scanner_with_lightweight_software_ix1300_or_other/", "subreddit_subscribers": 706687, "created_utc": 1697216815.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hi y'all,\n\nthroughout the years I've used a bunch of different hard drives and cloud storage services, and my data is spread across all of them. Now I've bought 2 new 18TB drives and I'm trying to consolidate all my data on one of them (and use the other one as a backup)\n\nMy main issue is that I have a lot of duplicate data, especially duplicate folder structures that may have some files missing\\*\n\nSo basically, here are my goals:\n\n* Unify all these files into a single filesystem\n* Have these files be encrypted in some way\n* Copy this backup onto a second drive\n* Ensure file integrity so I can safely delete the old drives\n* Have some way to access and search these files\n* Add new folders/backups going forward\n\nThrough my research and in searching this subreddit I've found 2 main strategies for doing this:\n\n* Put all files onto a single filesystem (ext4+LUKS?) and deduplicate them (with a tool like dupeguru). For copying I'd just use rsync. I might have to do the deduplication throughout the process for space reasons\n\nOR\n\n* Put all files into restic (or borg?) and call it a day. I don't know if restic properly supports this amount of data and I'll need to look into how the deduplication works\n\n**Any Input on both strategy and tooling would be greatly appreciated**\n\n\\* I've prevously attempted to consolidate my data but never actually deleted anything. That's the problem", "author_fullname": "t2_16sfkh", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Consolidating old Hard Drives", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1771sdf", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.63, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "eac073cc-b98a-11e2-84c9-12313d1841d1", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": "vhs", "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697212071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi y&amp;#39;all,&lt;/p&gt;\n\n&lt;p&gt;throughout the years I&amp;#39;ve used a bunch of different hard drives and cloud storage services, and my data is spread across all of them. Now I&amp;#39;ve bought 2 new 18TB drives and I&amp;#39;m trying to consolidate all my data on one of them (and use the other one as a backup)&lt;/p&gt;\n\n&lt;p&gt;My main issue is that I have a lot of duplicate data, especially duplicate folder structures that may have some files missing*&lt;/p&gt;\n\n&lt;p&gt;So basically, here are my goals:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Unify all these files into a single filesystem&lt;/li&gt;\n&lt;li&gt;Have these files be encrypted in some way&lt;/li&gt;\n&lt;li&gt;Copy this backup onto a second drive&lt;/li&gt;\n&lt;li&gt;Ensure file integrity so I can safely delete the old drives&lt;/li&gt;\n&lt;li&gt;Have some way to access and search these files&lt;/li&gt;\n&lt;li&gt;Add new folders/backups going forward&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Through my research and in searching this subreddit I&amp;#39;ve found 2 main strategies for doing this:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Put all files onto a single filesystem (ext4+LUKS?) and deduplicate them (with a tool like dupeguru). For copying I&amp;#39;d just use rsync. I might have to do the deduplication throughout the process for space reasons&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;OR&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Put all files into restic (or borg?) and call it a day. I don&amp;#39;t know if restic properly supports this amount of data and I&amp;#39;ll need to look into how the deduplication works&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&lt;strong&gt;Any Input on both strategy and tooling would be greatly appreciated&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;* I&amp;#39;ve prevously attempted to consolidate my data but never actually deleted anything. That&amp;#39;s the problem&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "VHS", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1771sdf", "is_robot_indexable": true, "report_reasons": null, "author": "theminortom", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/DataHoarder/comments/1771sdf/consolidating_old_hard_drives/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1771sdf/consolidating_old_hard_drives/", "subreddit_subscribers": 706687, "created_utc": 1697212071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I don't have really hardcore use for my NAS.  Currently I have a 7 year old WD My Cloud 4TB that's no longer supported, so it only works at home, no remote access.  Which is fine.  But it's old and I was looking to replace it with a 2 bay NAS that I could use in mirroring mode.  Just to hold my media files.  The Sonos speakers and my Xbox do all the processing work for playback, so I just need the NAS to serve the files.  I'm not familiar with Plex, but I hear that the NAS often does work to transcode videos for playback.  I don't need that stuff.\n\nI have Windows 11 on my PC, and I was looking to hook up the new NAS with 2 new HDDs installed (8TB drives) and have them mirrored so I have 8TB of storage.  Then I load it with my audio and video files and just use my Sonos speakers and Xbox (with the Kodi app) for playing them.\n\nAny advice on what to buy appreciated.  What I put on the NAS is already backed up on multiple hard drives and stored away.  The NAS data isn't critical.  I just wanted mirroring to make life easier when a NAS drive dies.  Just pop in a new drive and have it restore, and keep going!", "author_fullname": "t2_1iovrpc6", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help wanted shopping for a 2-bay NAS in mirror mode for serving audio/video files to Xbox (video) and Sonos speakers (audio) and no transcoding needed. Running Windows 11, want drag and drop through Windows Explorer. Any suggestions? I see Qnap, WD My Cloud, Synology on Amazon, what to buy?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177f18w", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697249662.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t have really hardcore use for my NAS.  Currently I have a 7 year old WD My Cloud 4TB that&amp;#39;s no longer supported, so it only works at home, no remote access.  Which is fine.  But it&amp;#39;s old and I was looking to replace it with a 2 bay NAS that I could use in mirroring mode.  Just to hold my media files.  The Sonos speakers and my Xbox do all the processing work for playback, so I just need the NAS to serve the files.  I&amp;#39;m not familiar with Plex, but I hear that the NAS often does work to transcode videos for playback.  I don&amp;#39;t need that stuff.&lt;/p&gt;\n\n&lt;p&gt;I have Windows 11 on my PC, and I was looking to hook up the new NAS with 2 new HDDs installed (8TB drives) and have them mirrored so I have 8TB of storage.  Then I load it with my audio and video files and just use my Sonos speakers and Xbox (with the Kodi app) for playing them.&lt;/p&gt;\n\n&lt;p&gt;Any advice on what to buy appreciated.  What I put on the NAS is already backed up on multiple hard drives and stored away.  The NAS data isn&amp;#39;t critical.  I just wanted mirroring to make life easier when a NAS drive dies.  Just pop in a new drive and have it restore, and keep going!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177f18w", "is_robot_indexable": true, "report_reasons": null, "author": "Kevalemig", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177f18w/help_wanted_shopping_for_a_2bay_nas_in_mirror/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177f18w/help_wanted_shopping_for_a_2bay_nas_in_mirror/", "subreddit_subscribers": 706687, "created_utc": 1697249662.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Hello, \n\nI've never used rsync before so I'm just trying to find out if my speeds are to be expected or if I'm doing something wrong. Some details below:\n\n\\- The source box running OMV is reading from a USB external HDD (first clue that my speeds might be at their maximum).\n\n\\- Source box reports &lt;30% CPU utilization, won't go above this. (Another clue that maybe I've reached the limits of my disk, but if there's more performance I can squeeze out of it I'd like to).\n\n\\- Target box reports &lt;15% CPU usage, which makes sense to me.\n\n\\- Writing to SSD cache currently.\n\n\\- Should also mention this is on Gigabit networking over ssh.\n\nI  don't know if this is enough information to get anything out of, but I'm just looking for a sanity check that my speeds are as expected. Thanks!", "author_fullname": "t2_cjvn70fo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "rsync from openmediavault to unraid, maxing out at around 100MBs. Normal?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1778omv", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697231071.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve never used rsync before so I&amp;#39;m just trying to find out if my speeds are to be expected or if I&amp;#39;m doing something wrong. Some details below:&lt;/p&gt;\n\n&lt;p&gt;- The source box running OMV is reading from a USB external HDD (first clue that my speeds might be at their maximum).&lt;/p&gt;\n\n&lt;p&gt;- Source box reports &amp;lt;30% CPU utilization, won&amp;#39;t go above this. (Another clue that maybe I&amp;#39;ve reached the limits of my disk, but if there&amp;#39;s more performance I can squeeze out of it I&amp;#39;d like to).&lt;/p&gt;\n\n&lt;p&gt;- Target box reports &amp;lt;15% CPU usage, which makes sense to me.&lt;/p&gt;\n\n&lt;p&gt;- Writing to SSD cache currently.&lt;/p&gt;\n\n&lt;p&gt;- Should also mention this is on Gigabit networking over ssh.&lt;/p&gt;\n\n&lt;p&gt;I  don&amp;#39;t know if this is enough information to get anything out of, but I&amp;#39;m just looking for a sanity check that my speeds are as expected. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1778omv", "is_robot_indexable": true, "report_reasons": null, "author": "gluebabie", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1778omv/rsync_from_openmediavault_to_unraid_maxing_out_at/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1778omv/rsync_from_openmediavault_to_unraid_maxing_out_at/", "subreddit_subscribers": 706687, "created_utc": 1697231071.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a bunch of high-bitrate screen recordings of low-bitrate streaming content (Zoom calls). The files are absolutely massive, but the actual video content quality is minimal.\n\nI'd like to re-encode using more suitable settings to save some space. However, I'm not sure which settings to use. Being a data hoarder, I'd like to quantitatively figure out which settings offer the best tradeoffs, and at what point the quality starts to degrade, instead of subjectively evaluating the files.\n\nAre there any open source programs that I can use to obtain this number?", "author_fullname": "t2_fmblw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Tool to help quantitatively figure out best encoding settings / quality loss?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_177j7o3", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697265118.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a bunch of high-bitrate screen recordings of low-bitrate streaming content (Zoom calls). The files are absolutely massive, but the actual video content quality is minimal.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d like to re-encode using more suitable settings to save some space. However, I&amp;#39;m not sure which settings to use. Being a data hoarder, I&amp;#39;d like to quantitatively figure out which settings offer the best tradeoffs, and at what point the quality starts to degrade, instead of subjectively evaluating the files.&lt;/p&gt;\n\n&lt;p&gt;Are there any open source programs that I can use to obtain this number?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "177j7o3", "is_robot_indexable": true, "report_reasons": null, "author": "goldcakes", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/177j7o3/tool_to_help_quantitatively_figure_out_best/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/177j7o3/tool_to_help_quantitatively_figure_out_best/", "subreddit_subscribers": 706687, "created_utc": 1697265118.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "I have a few 3TB disks I'm retiring from a NAS and would like to repurpose for cold storage. They're possibly not in the worst shape, and I'm not ready to shred them just yet.\n\nWhat I'd like to do with them is store some data on them for extra local redundancy in addition to my other backups for a worst case scenario. Once files are copied onto the drives, further changes are not expected. I want to spin them up every few months to verify data integrity and then put them back to the sleep. It feels pretty straightforward to me.\n\nIs there any software that will go through every folder and store file name and checksums in each folder as a text file? Every few months, I can spin up the drive and the software will just look at the text file in each folder and check the folders one by one.\n\nMy worst case scenario is having to hastily grab whatever drives I can and fleeing to another country and not have access to any of my existing machines. I'd like to be able to buy a new computer, run the check, and make more copies as soon as possible.\n\nMy main concern is losing stuff like a couple decades of memories, so security isn't the hugest deal for me, but encryption is preferable if possible. I'm also open to better solutions ranging from free to a one-time double-digit purchase. My use macOS, but if it's something I can run in a VM, I'm open to that, too.\n\nThanks for reading!", "author_fullname": "t2_8g28sgu0", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Hoping to store data on hard drives in a dry box with periodic, manual integrity checks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1772msd", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697214330.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a few 3TB disks I&amp;#39;m retiring from a NAS and would like to repurpose for cold storage. They&amp;#39;re possibly not in the worst shape, and I&amp;#39;m not ready to shred them just yet.&lt;/p&gt;\n\n&lt;p&gt;What I&amp;#39;d like to do with them is store some data on them for extra local redundancy in addition to my other backups for a worst case scenario. Once files are copied onto the drives, further changes are not expected. I want to spin them up every few months to verify data integrity and then put them back to the sleep. It feels pretty straightforward to me.&lt;/p&gt;\n\n&lt;p&gt;Is there any software that will go through every folder and store file name and checksums in each folder as a text file? Every few months, I can spin up the drive and the software will just look at the text file in each folder and check the folders one by one.&lt;/p&gt;\n\n&lt;p&gt;My worst case scenario is having to hastily grab whatever drives I can and fleeing to another country and not have access to any of my existing machines. I&amp;#39;d like to be able to buy a new computer, run the check, and make more copies as soon as possible.&lt;/p&gt;\n\n&lt;p&gt;My main concern is losing stuff like a couple decades of memories, so security isn&amp;#39;t the hugest deal for me, but encryption is preferable if possible. I&amp;#39;m also open to better solutions ranging from free to a one-time double-digit purchase. My use macOS, but if it&amp;#39;s something I can run in a VM, I&amp;#39;m open to that, too.&lt;/p&gt;\n\n&lt;p&gt;Thanks for reading!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1772msd", "is_robot_indexable": true, "report_reasons": null, "author": "inconspiciousdude", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1772msd/hoping_to_store_data_on_hard_drives_in_a_dry_box/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1772msd/hoping_to_store_data_on_hard_drives_in_a_dry_box/", "subreddit_subscribers": 706687, "created_utc": 1697214330.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "DataHoarder", "selftext": "Or do I have to manually start the backup?\n\nYes I know annoying Apple question. I need a Mac for work and am irritated with how Apple does things and what they charge for storage.\n\nI'm trying to figure out how I'm going to manage my data on this new laptop so that I can figure out how to configure it's storage options before I order it. The current laptop I'm typing this on has 18TB onboard, this is a rather painful process :S...\n\nI'm thinking my plan is to have 4TB of SSD in the MacBook and have a 4TB M.2 SSD dedicated for Time Machine in an external USB-C enclosure.\n\nWhat are the options for setting the backup schedule in Time Machine?\n\nIf and when I'm overdue for a backup, will Time Machine automatically start a backup as soon as the USB drive is plugged in without any steps required on my end?\n\nI'm on the road a lot and won't have the drive connected 24/7.\n\nIdeally, I was hoping to be able to plug in the drive once a week and have Time Machine automatically start and run in the background till the backup is complete.\n\nI don't  want to use iCloud and don't want to waste my time with 3rd party software, not for this machine.\n\nMy aplogies for bringing Apple into the subreddit!", "author_fullname": "t2_xkiqe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Can Apple Time Machine automatically start a backup when an external USB drive is connected?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/DataHoarder", "hidden": false, "pwls": 6, "link_flair_css_class": "question", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_1770hh0", "quarantine": false, "link_flair_text_color": "dark", "upvote_ratio": 0.43, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Question/Advice", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1697208845.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1697208580.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.DataHoarder", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Or do I have to manually start the backup?&lt;/p&gt;\n\n&lt;p&gt;Yes I know annoying Apple question. I need a Mac for work and am irritated with how Apple does things and what they charge for storage.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m trying to figure out how I&amp;#39;m going to manage my data on this new laptop so that I can figure out how to configure it&amp;#39;s storage options before I order it. The current laptop I&amp;#39;m typing this on has 18TB onboard, this is a rather painful process :S...&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m thinking my plan is to have 4TB of SSD in the MacBook and have a 4TB M.2 SSD dedicated for Time Machine in an external USB-C enclosure.&lt;/p&gt;\n\n&lt;p&gt;What are the options for setting the backup schedule in Time Machine?&lt;/p&gt;\n\n&lt;p&gt;If and when I&amp;#39;m overdue for a backup, will Time Machine automatically start a backup as soon as the USB drive is plugged in without any steps required on my end?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m on the road a lot and won&amp;#39;t have the drive connected 24/7.&lt;/p&gt;\n\n&lt;p&gt;Ideally, I was hoping to be able to plug in the drive once a week and have Time Machine automatically start and run in the background till the backup is complete.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t  want to use iCloud and don&amp;#39;t want to waste my time with 3rd party software, not for this machine.&lt;/p&gt;\n\n&lt;p&gt;My aplogies for bringing Apple into the subreddit!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "268afdf0-4bf8-11e3-be37-12313d18f999", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_2x7he", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#d3d6da", "id": "1770hh0", "is_robot_indexable": true, "report_reasons": null, "author": "blackberriesandthink", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/DataHoarder/comments/1770hh0/can_apple_time_machine_automatically_start_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/DataHoarder/comments/1770hh0/can_apple_time_machine_automatically_start_a/", "subreddit_subscribers": 706687, "created_utc": 1697208580.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}