{"kind": "Listing", "data": {"after": "t3_16xjavi", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most are pretty aware of dbt, but technology moves fast. Has any serious competitor come up? Curious if anyone has tried sqlmesh - what's your first impression?\n\nContex:\nJust generally curious", "author_fullname": "t2_hj2y0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt vs sqlmesh vs ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xbiar", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 32, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 32, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696191264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most are pretty aware of dbt, but technology moves fast. Has any serious competitor come up? Curious if anyone has tried sqlmesh - what&amp;#39;s your first impression?&lt;/p&gt;\n\n&lt;p&gt;Contex:\nJust generally curious&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xbiar", "is_robot_indexable": true, "report_reasons": null, "author": "Cryptojacob", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xbiar/dbt_vs_sqlmesh_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xbiar/dbt_vs_sqlmesh_vs/", "subreddit_subscribers": 131615, "created_utc": 1696191264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Planning to buy a Nuc 11 Enthusiast instead of a Steam Deck to upskill myself as well as not screwing my Gaming PC . Are there any ideas where i can start this journey . My aim to setup homelab is :  \n\n1. Networking side with OpenWrt , pfSense \n2. Containers/Virtualization  with Dockers and Vmware \n3. Server Side with Proxmox\n\nShare if its sufficient to run multiple VMs and Containers with this thing as well as share how do you use homelab for upskilling your DE skills .", "author_fullname": "t2_cl5vl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any DEs here have homelabs to upskill , make a dedicated dev env, and do other server side stuff ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16x6mf6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 29, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 29, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696180108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Planning to buy a Nuc 11 Enthusiast instead of a Steam Deck to upskill myself as well as not screwing my Gaming PC . Are there any ideas where i can start this journey . My aim to setup homelab is :  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Networking side with OpenWrt , pfSense &lt;/li&gt;\n&lt;li&gt;Containers/Virtualization  with Dockers and Vmware &lt;/li&gt;\n&lt;li&gt;Server Side with Proxmox&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Share if its sufficient to run multiple VMs and Containers with this thing as well as share how do you use homelab for upskilling your DE skills .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16x6mf6", "is_robot_indexable": true, "report_reasons": null, "author": "Redxer", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x6mf6/any_des_here_have_homelabs_to_upskill_make_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16x6mf6/any_des_here_have_homelabs_to_upskill_make_a/", "subreddit_subscribers": 131615, "created_utc": 1696180108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was looking through old posts on this subreddit about system design and came across a comment a couple years ago that discussed a useful scaling exercise to practice for DE interviews: creating a pipeline that ingests 1MB at first, then 1GB, then 10GB, 100GB, 1TB, etc. and then talking about challenges along the way.\n\nI was wondering if this community had some ideas about things to consider as you get further and further up the throughput ladder. Here's a few I've compiled (I assumed the volume at an hourly rate):\n\n&amp;#x200B;\n\n* **@ 1MB / hour**\n   * ingestion: either batch or streaming is possible depending on the nature of the data and our business requirements. Orchestration and processing can live on same machine comfortably.\n   * Throughput is relatively small and should not require distributed processing. Libraries like pandas or numpy would be sufficient for most operations\n   * loading into a relational store or data warehouse should be trivial, though we still need to adopt best practices for designing our schema, managing indexes, etc.\n* **@ 1 GB / hour**\n   * Batch and streaming are both possible, but examine the data to find the most efficient approach. If the data is a single 1GB-sized file arriving hourly, it could be processed in batch, but it wouldn't be ideal to read the whole thing into memory on a lone machine. If the data is from an external source, we also have to pay attention to network I/O. Better to partition the data and have multiple machines read it in parallel. If instead the data is comprised of several small log files or messages in the KB-level, try consuming from an event broker.\n   * Processing data with Pandas on a single machine is possible if scaling vertically, but not ideal. Should switch to a small Spark cluster, or something like Dask. Again, depends on the transformations.\n   * Tools for logging, monitoring pipeline health, and analyzing resource utilization are recommended. (Should be recommended at all levels, but becomes more and more necessary as data scales)\n   * Using an optimized storage format is recommended for large data files (e.g. parquet, avro)\n   * If writing to a relational db, need to be mindful of our transactions/sec and not create strain on the server. (use load balancer and connection pooling)\n* **@ 10 GB / hour**\n   * Horizontal scaling preferred over vertical scaling. Should use a distributed cluster regardless of batch or streaming requirements.\n   * During processing, make sure our joins/transformations aren't creating uneven shards and resulting in bottlenecks on our nodes.\n   * Have strong data governance policies in place for data quality checks, data observability, data lineage, etc.\n   * Continuous monitoring of resource and CPU utilization of the cluster, notifications when thresholds are breached (again, useful at all levels). Also create pipelines for centralized log analysis (with ElasticSearch perhaps?)\n   * Properly partition data in data lake or relational store, with strategies for rolling off data as costs build up.\n   * Optimize compression and indexing wherever possible.\n* **@ 100 GB / hour**\n   * Proper configuration, load balancing, and partitioning of the event broker is essential\n   * Critical to have a properly tuned cluster that can auto-scale to accommodate job size as costs increase.\n   * Watch for bottlenecks in processing, OutOfMemory exceptions are likely if improper join strategies are used.\n   * Clean data, especially data deduplication, is critical for reducing redundant processing.\n   * Writing to traditional relational dbs may struggle to keep up with volume of writes. Distributed databases may be preferred (e.g. Cassandra).\n   * Employ caching liberally, both in serving queries and in processing data\n   * Optimizing queries is crucial, as poorly written SQL can result in long execution and resource contention.\n* **@ 1 TB / hour**\n   * Efficiency in configuring compute and storage is a must. Improperly tuned cloud services can be hugely expensive.\n   * Distributed databases/DWH typically required.\n   * Use an appropriate partitioning strategy in data lake\n   * Avoid processing data that is not necessary for the business, and move data that isn't used to cheaper, long-term storage.\n   * Optimize data model and indexing strategy for efficient queries.\n   * Good data retention policies prevent expensive, unmanageable database growth.\n   * Monitoring and alerting systems should be sophisticated and battle-tested to track overall resource utilization.\n\n# Above all, know how the business plans to use the data, as that will have the biggest influence on design!\n\n**Considerations at all levels:**\n\n* caching\n* security and privacy\n* metadata management\n* CI/CD, testing\n* redundancy and fault-tolerance\n* labor and maintenance overhead\n* cost-complexity ratio\n\n&amp;#x200B;\n\nAnyone have anything else to add? In an interview, I would obviously flesh out a lot of these bullet points.", "author_fullname": "t2_5zyhb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scaling exercise for DE interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16x7m4d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.95, "author_flair_background_color": null, "subreddit_type": "public", "ups": 19, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 19, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696182404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was looking through old posts on this subreddit about system design and came across a comment a couple years ago that discussed a useful scaling exercise to practice for DE interviews: creating a pipeline that ingests 1MB at first, then 1GB, then 10GB, 100GB, 1TB, etc. and then talking about challenges along the way.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if this community had some ideas about things to consider as you get further and further up the throughput ladder. Here&amp;#39;s a few I&amp;#39;ve compiled (I assumed the volume at an hourly rate):&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;@ 1MB / hour&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;ingestion: either batch or streaming is possible depending on the nature of the data and our business requirements. Orchestration and processing can live on same machine comfortably.&lt;/li&gt;\n&lt;li&gt;Throughput is relatively small and should not require distributed processing. Libraries like pandas or numpy would be sufficient for most operations&lt;/li&gt;\n&lt;li&gt;loading into a relational store or data warehouse should be trivial, though we still need to adopt best practices for designing our schema, managing indexes, etc.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;@ 1 GB / hour&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Batch and streaming are both possible, but examine the data to find the most efficient approach. If the data is a single 1GB-sized file arriving hourly, it could be processed in batch, but it wouldn&amp;#39;t be ideal to read the whole thing into memory on a lone machine. If the data is from an external source, we also have to pay attention to network I/O. Better to partition the data and have multiple machines read it in parallel. If instead the data is comprised of several small log files or messages in the KB-level, try consuming from an event broker.&lt;/li&gt;\n&lt;li&gt;Processing data with Pandas on a single machine is possible if scaling vertically, but not ideal. Should switch to a small Spark cluster, or something like Dask. Again, depends on the transformations.&lt;/li&gt;\n&lt;li&gt;Tools for logging, monitoring pipeline health, and analyzing resource utilization are recommended. (Should be recommended at all levels, but becomes more and more necessary as data scales)&lt;/li&gt;\n&lt;li&gt;Using an optimized storage format is recommended for large data files (e.g. parquet, avro)&lt;/li&gt;\n&lt;li&gt;If writing to a relational db, need to be mindful of our transactions/sec and not create strain on the server. (use load balancer and connection pooling)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;@ 10 GB / hour&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Horizontal scaling preferred over vertical scaling. Should use a distributed cluster regardless of batch or streaming requirements.&lt;/li&gt;\n&lt;li&gt;During processing, make sure our joins/transformations aren&amp;#39;t creating uneven shards and resulting in bottlenecks on our nodes.&lt;/li&gt;\n&lt;li&gt;Have strong data governance policies in place for data quality checks, data observability, data lineage, etc.&lt;/li&gt;\n&lt;li&gt;Continuous monitoring of resource and CPU utilization of the cluster, notifications when thresholds are breached (again, useful at all levels). Also create pipelines for centralized log analysis (with ElasticSearch perhaps?)&lt;/li&gt;\n&lt;li&gt;Properly partition data in data lake or relational store, with strategies for rolling off data as costs build up.&lt;/li&gt;\n&lt;li&gt;Optimize compression and indexing wherever possible.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;@ 100 GB / hour&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Proper configuration, load balancing, and partitioning of the event broker is essential&lt;/li&gt;\n&lt;li&gt;Critical to have a properly tuned cluster that can auto-scale to accommodate job size as costs increase.&lt;/li&gt;\n&lt;li&gt;Watch for bottlenecks in processing, OutOfMemory exceptions are likely if improper join strategies are used.&lt;/li&gt;\n&lt;li&gt;Clean data, especially data deduplication, is critical for reducing redundant processing.&lt;/li&gt;\n&lt;li&gt;Writing to traditional relational dbs may struggle to keep up with volume of writes. Distributed databases may be preferred (e.g. Cassandra).&lt;/li&gt;\n&lt;li&gt;Employ caching liberally, both in serving queries and in processing data&lt;/li&gt;\n&lt;li&gt;Optimizing queries is crucial, as poorly written SQL can result in long execution and resource contention.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;@ 1 TB / hour&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Efficiency in configuring compute and storage is a must. Improperly tuned cloud services can be hugely expensive.&lt;/li&gt;\n&lt;li&gt;Distributed databases/DWH typically required.&lt;/li&gt;\n&lt;li&gt;Use an appropriate partitioning strategy in data lake&lt;/li&gt;\n&lt;li&gt;Avoid processing data that is not necessary for the business, and move data that isn&amp;#39;t used to cheaper, long-term storage.&lt;/li&gt;\n&lt;li&gt;Optimize data model and indexing strategy for efficient queries.&lt;/li&gt;\n&lt;li&gt;Good data retention policies prevent expensive, unmanageable database growth.&lt;/li&gt;\n&lt;li&gt;Monitoring and alerting systems should be sophisticated and battle-tested to track overall resource utilization.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Above all, know how the business plans to use the data, as that will have the biggest influence on design!&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;Considerations at all levels:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;caching&lt;/li&gt;\n&lt;li&gt;security and privacy&lt;/li&gt;\n&lt;li&gt;metadata management&lt;/li&gt;\n&lt;li&gt;CI/CD, testing&lt;/li&gt;\n&lt;li&gt;redundancy and fault-tolerance&lt;/li&gt;\n&lt;li&gt;labor and maintenance overhead&lt;/li&gt;\n&lt;li&gt;cost-complexity ratio&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Anyone have anything else to add? In an interview, I would obviously flesh out a lot of these bullet points.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16x7m4d", "is_robot_indexable": true, "report_reasons": null, "author": "LurkLurkington", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x7m4d/scaling_exercise_for_de_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16x7m4d/scaling_exercise_for_de_interviews/", "subreddit_subscribers": 131615, "created_utc": 1696182404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "About a year ago, I began to realize how suboptimal my experience was while working with dbt and other data engineering projects in my company. As a result, I started exploring ways to improve this situation.\n\nAfter some time, I have come up with three solutions that I would like to share:\n\n* When working with dbt specifically, use \u201cdbt Power User\u201d plugin for VSCode to get contextual information, suggestions, data lineage for dbt models, etc. It makes the workflow really enjoyable.\n* Incorporate SQLFluff for linting and formatting SQL code. It should bring a consistent code to your project and you finally stop arguing about leading vs trailing commas.\n* Also implement pre-commit hooks, small scripts that run before committing code to Github. These script usually perform various checks on the project, such as YAML validity, documentation and test availability, etc.\n\nBasically, I explained all three solutions in greater details in my newsletter [here](https://dbtips.substack.com/p/get-the-ultimate-developer-experience).\n\nDo you have any other tips of improving DX you can share?", "author_fullname": "t2_4679pe1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to improve your developer experience when working with dbt (and not only)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16x9maj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696186924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;About a year ago, I began to realize how suboptimal my experience was while working with dbt and other data engineering projects in my company. As a result, I started exploring ways to improve this situation.&lt;/p&gt;\n\n&lt;p&gt;After some time, I have come up with three solutions that I would like to share:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;When working with dbt specifically, use \u201cdbt Power User\u201d plugin for VSCode to get contextual information, suggestions, data lineage for dbt models, etc. It makes the workflow really enjoyable.&lt;/li&gt;\n&lt;li&gt;Incorporate SQLFluff for linting and formatting SQL code. It should bring a consistent code to your project and you finally stop arguing about leading vs trailing commas.&lt;/li&gt;\n&lt;li&gt;Also implement pre-commit hooks, small scripts that run before committing code to Github. These script usually perform various checks on the project, such as YAML validity, documentation and test availability, etc.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Basically, I explained all three solutions in greater details in my newsletter &lt;a href=\"https://dbtips.substack.com/p/get-the-ultimate-developer-experience\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Do you have any other tips of improving DX you can share?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?auto=webp&amp;s=d3bb661896828bac4429562f6ce7fff4ef505422", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5af75ad43a854078e3cea834f3ef698663e88cdc", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=37ae9fc5f3b20c68d9199ed55882ebca83ef2855", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5685fef764bd1fa720328ebd972cc947f012bd86", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0c958b3293f06f32b4616718b83399f29154edee", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=89fca96637cd1490f814b4b891f7bdc567c62f1f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0f972567e2eba31f2c54f818bdce4b34235f400e", "width": 1080, "height": 540}], "variants": {}, "id": "ntcEH-D8yVlbOqdDYiN0TVlVBkXGXM6b3WJWBcIF5sw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16x9maj", "is_robot_indexable": true, "report_reasons": null, "author": "oleg_agapov", "discussion_type": null, "num_comments": 8, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x9maj/how_to_improve_your_developer_experience_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16x9maj/how_to_improve_your_developer_experience_when/", "subreddit_subscribers": 131615, "created_utc": 1696186924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would you rather work on different projects where you implement something and then go to the next project (consulting) or work in a team with a single project developing a single data ecosystem?\n\nI was wondering what DEs in this sub rather do. I\u2019ve  doing the first one (consulting) for a while, but I was curious about how is the day in the life outside of consulting.", "author_fullname": "t2_66knxh65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you rather do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xfsg6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.91, "author_flair_background_color": null, "subreddit_type": "public", "ups": 9, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696201028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would you rather work on different projects where you implement something and then go to the next project (consulting) or work in a team with a single project developing a single data ecosystem?&lt;/p&gt;\n\n&lt;p&gt;I was wondering what DEs in this sub rather do. I\u2019ve  doing the first one (consulting) for a while, but I was curious about how is the day in the life outside of consulting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xfsg6", "is_robot_indexable": true, "report_reasons": null, "author": "WarNeverChanges1997", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xfsg6/what_would_you_rather_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xfsg6/what_would_you_rather_do/", "subreddit_subscribers": 131615, "created_utc": 1696201028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineer with a few years experience in SQL/NoSQL. I've designed/diagnosed high throughput TPS systems, warehousing clusters, HA, DR, DBA, code reviews.\n\nUnfortunately due to health reasons I took a few years off with just occasionally solving a brain teaser on LeetCode. I'm trying to get my career back on track. I've been reading a lot about AI and frankly i think its the future of search. This quickly drew me to Vector DBs and I'm wondering if you suggest getting deep into that, or what else, and i'd appreciate links to courses/tuts.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_edkp97o8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting back into DB world, should I learn Vector DBs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xe9jr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696197530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineer with a few years experience in SQL/NoSQL. I&amp;#39;ve designed/diagnosed high throughput TPS systems, warehousing clusters, HA, DR, DBA, code reviews.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately due to health reasons I took a few years off with just occasionally solving a brain teaser on LeetCode. I&amp;#39;m trying to get my career back on track. I&amp;#39;ve been reading a lot about AI and frankly i think its the future of search. This quickly drew me to Vector DBs and I&amp;#39;m wondering if you suggest getting deep into that, or what else, and i&amp;#39;d appreciate links to courses/tuts.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16xe9jr", "is_robot_indexable": true, "report_reasons": null, "author": "no_deal_111", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xe9jr/getting_back_into_db_world_should_i_learn_vector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xe9jr/getting_back_into_db_world_should_i_learn_vector/", "subreddit_subscribers": 131615, "created_utc": 1696197530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my latest blog post, I've summarized the key takeaways from Snowflake Summit 2023 in Bangalore, so that those who couldn't attend can benefit from the latest updates on data governance and cost management.  \n\n\nData Governance Highlights:  \n1) Data Quality Monitoring  \n2) Query Constraint Policies  \n3) Data Access Policies  \n4) Data Governance UI  \n5) Classification UI  \n6) Global PII Classification  \n\n\nCost Control Highlights:  \n1) Budget  \n2) Warehouse Utilization  \n3) SnowLens  \n\n\nBlog Link - [Unlocking the Power of Data Governance and Cost Control: Insights from Snowflake Summit 2023](https://medium.com/bi3-technologies/unlocking-the-power-of-data-governance-and-privacy-insights-from-snowflake-summit-2023-7ffcb697e005)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/z371joftmqrb1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=7aa178f639e8751472f63f1d63fcc22805cd9d90\n\nI want to thank the event organizers and the insightful speakers:  \n\n\n1) [Hemant Raorane](https://www.linkedin.com/in/ACoAABMXMIIB6tUTKUjbYz1CqBz2jS3NCnSpM7I), Sales Engineer, [Snowflake](https://www.linkedin.com/company/snowflake-computing/) India  \n2) [Sachin Gangwar](https://www.linkedin.com/in/ACoAAAZGouMBkudPlBY9PD76sXVTAdnwWQNQm9w), Senior Sales Engineer, [Snowflake](https://www.linkedin.com/company/snowflake-computing/) India  \n3) [Wasim El-Omari](https://www.linkedin.com/in/ACoAAC-O1KYBhH78QJa92-7ggpODUPFVS3jvgAc), Principal Architect, Security, Field CTO Office, [Snowflake](https://www.linkedin.com/company/snowflake-computing/)  \n4) [Pawan Mall](https://www.linkedin.com/in/ACoAAAEq2hkBAI8EwgK_ROKoaULMSB-72GQrnS0), Senior Sales Engineer, [Snowflake](https://www.linkedin.com/company/snowflake-computing/) India  \n5) [Vikash K.](https://www.linkedin.com/in/ACoAACea-JUBwLCCA2Iqcbrpm_F6rHUrEKHpHA4), Senior Data Cloud Architect | GSI Partners, [Snowflake](https://www.linkedin.com/company/snowflake-computing/) India  \n\n\nYour expertise will shape how we handle data in our projects.  \n\n\n[\\#SnowflakeSummit2023](https://www.linkedin.com/feed/hashtag/?keywords=snowflakesummit2023&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#DataGovernance](https://www.linkedin.com/feed/hashtag/?keywords=datagovernance&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#CostControl](https://www.linkedin.com/feed/hashtag/?keywords=costcontrol&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#DataManagement](https://www.linkedin.com/feed/hashtag/?keywords=datamanagement&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#TechTrends](https://www.linkedin.com/feed/hashtag/?keywords=techtrends&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#DataAnalytics](https://www.linkedin.com/feed/hashtag/?keywords=dataanalytics&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#DataSecurity](https://www.linkedin.com/feed/hashtag/?keywords=datasecurity&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#Snowflake](https://www.linkedin.com/feed/hashtag/?keywords=snowflake&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#SnowflakeDevelopers](https://www.linkedin.com/feed/hashtag/?keywords=snowflakedevelopers&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) ", "author_fullname": "t2_hhlcq19gr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Key takeaways from Snowflake Summit 2023 in Bangalore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"z371joftmqrb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=632d25e3e54af280ce7616d3debab386c63f0568"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9bfbd5f8788550e35d5658dcefb105c1c63d6b0d"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f77fa2d109d22fad0d51dbf0bcd975b9114bd1d5"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f028485b825f179d5aed019f12d7568ebb1adaf2"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b201bb9b074bf1f4348fa10aa0d65cd0ada5e4c4"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0e153a28fa2528f892f5df29d19402d8c80efb2c"}], "s": {"y": 1200, "x": 1600, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=7aa178f639e8751472f63f1d63fcc22805cd9d90"}, "id": "z371joftmqrb1"}}, "name": "t3_16xprjr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.89, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GTriMGw7dhnIVYinyVqUBxw7GM_RpAGKtQqnNof47ck.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1696230074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my latest blog post, I&amp;#39;ve summarized the key takeaways from Snowflake Summit 2023 in Bangalore, so that those who couldn&amp;#39;t attend can benefit from the latest updates on data governance and cost management.  &lt;/p&gt;\n\n&lt;p&gt;Data Governance Highlights:&lt;br/&gt;\n1) Data Quality Monitoring&lt;br/&gt;\n2) Query Constraint Policies&lt;br/&gt;\n3) Data Access Policies&lt;br/&gt;\n4) Data Governance UI&lt;br/&gt;\n5) Classification UI&lt;br/&gt;\n6) Global PII Classification  &lt;/p&gt;\n\n&lt;p&gt;Cost Control Highlights:&lt;br/&gt;\n1) Budget&lt;br/&gt;\n2) Warehouse Utilization&lt;br/&gt;\n3) SnowLens  &lt;/p&gt;\n\n&lt;p&gt;Blog Link - &lt;a href=\"https://medium.com/bi3-technologies/unlocking-the-power-of-data-governance-and-privacy-insights-from-snowflake-summit-2023-7ffcb697e005\"&gt;Unlocking the Power of Data Governance and Cost Control: Insights from Snowflake Summit 2023&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/z371joftmqrb1.jpg?width=1600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7aa178f639e8751472f63f1d63fcc22805cd9d90\"&gt;https://preview.redd.it/z371joftmqrb1.jpg?width=1600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7aa178f639e8751472f63f1d63fcc22805cd9d90&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I want to thank the event organizers and the insightful speakers:  &lt;/p&gt;\n\n&lt;p&gt;1) &lt;a href=\"https://www.linkedin.com/in/ACoAABMXMIIB6tUTKUjbYz1CqBz2jS3NCnSpM7I\"&gt;Hemant Raorane&lt;/a&gt;, Sales Engineer, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt; India&lt;br/&gt;\n2) &lt;a href=\"https://www.linkedin.com/in/ACoAAAZGouMBkudPlBY9PD76sXVTAdnwWQNQm9w\"&gt;Sachin Gangwar&lt;/a&gt;, Senior Sales Engineer, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt; India&lt;br/&gt;\n3) &lt;a href=\"https://www.linkedin.com/in/ACoAAC-O1KYBhH78QJa92-7ggpODUPFVS3jvgAc\"&gt;Wasim El-Omari&lt;/a&gt;, Principal Architect, Security, Field CTO Office, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt;&lt;br/&gt;\n4) &lt;a href=\"https://www.linkedin.com/in/ACoAAAEq2hkBAI8EwgK_ROKoaULMSB-72GQrnS0\"&gt;Pawan Mall&lt;/a&gt;, Senior Sales Engineer, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt; India&lt;br/&gt;\n5) &lt;a href=\"https://www.linkedin.com/in/ACoAACea-JUBwLCCA2Iqcbrpm_F6rHUrEKHpHA4\"&gt;Vikash K.&lt;/a&gt;, Senior Data Cloud Architect | GSI Partners, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt; India  &lt;/p&gt;\n\n&lt;p&gt;Your expertise will shape how we handle data in our projects.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=snowflakesummit2023&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#SnowflakeSummit2023&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=datagovernance&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#DataGovernance&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=costcontrol&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#CostControl&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=datamanagement&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#DataManagement&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=techtrends&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#TechTrends&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=dataanalytics&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#DataAnalytics&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=datasecurity&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#DataSecurity&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=snowflake&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#Snowflake&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=snowflakedevelopers&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#SnowflakeDevelopers&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?auto=webp&amp;s=87203ce307f9b72fb094e85035ea3a41a5c8c384", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9637f60474d774efa820fda8f5974253eaefa50", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=83868552d3590e90338962cb8d1672ccbaa73828", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4b715c2453ce59b28c1dcce84f0153ab57bd1f0", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9699bdf7ecc3f6608279ad7cb3f1411d89fc0424", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7c95fed484686b328184f7151ca8e51384b94448", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=20407829974bcc45a6f50e4809fca58564a96763", "width": 1080, "height": 565}], "variants": {}, "id": "4x9_UIUovtScdP6OlrszrrtgeXaSEDyQR_m-Sv_lbvk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xprjr", "is_robot_indexable": true, "report_reasons": null, "author": "ijiv_s", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xprjr/key_takeaways_from_snowflake_summit_2023_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xprjr/key_takeaways_from_snowflake_summit_2023_in/", "subreddit_subscribers": 131615, "created_utc": 1696230074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I don't see any pricing details for glue workflows but I would assume there's an extra cost since it's providing additional functionality. I only see pricing based on DPUs for Glue jobs. Does this mean that if I use Glue Workflows to orchestrate glue jobs, I will only pay for the cost of the glue jobs and the orchestration will just be free? If that's the case, is there any benefit to using Airflow for orchestration of glue jobs if glue workflows can be used?", "author_fullname": "t2_jx5l6r0ay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any added cost to using Glue workflows with Glue jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16x6tkl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696180572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t see any pricing details for glue workflows but I would assume there&amp;#39;s an extra cost since it&amp;#39;s providing additional functionality. I only see pricing based on DPUs for Glue jobs. Does this mean that if I use Glue Workflows to orchestrate glue jobs, I will only pay for the cost of the glue jobs and the orchestration will just be free? If that&amp;#39;s the case, is there any benefit to using Airflow for orchestration of glue jobs if glue workflows can be used?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16x6tkl", "is_robot_indexable": true, "report_reasons": null, "author": "IllRepresentative858", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x6tkl/is_there_any_added_cost_to_using_glue_workflows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16x6tkl/is_there_any_added_cost_to_using_glue_workflows/", "subreddit_subscribers": 131615, "created_utc": 1696180572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There is a lot of overlap between data engineering and analytics for these jobs, so I'll post in both subs. It's my first job out of college, and down the line I'm really looking to be a full fledged tech professional, whatever that means. I'm looking at 2 vastly different offers. They are both at hospital systems, remote isn't an option for either. And I'm not declining either job just because its not remote, I have no leverage as an unemployed college grad desparate for a job. Pay and commute are similar.\n\nOffer 1: Mostly analytics, using SQL and drag-drop software for ETL processes. More emphasis is placed on understanding the stakeholder needs rather than coding. Data architecture is well established by third party vendor. Workload seems fairly low, easy-going office environment. No on call, typical 9-5, 4 days in office.\n\nOffer 2: Getting my hands dirty with Python, SQL, and Linux command line for ETL processes, existing data architecture needs lots of work. Job duties also include providing basic IT phone support for hospital employees. On call, unsure of frequency. 9-5, 5 days in office.\n\nOffer 1 is nice because of the work-life balance, easy and established reporting process is already in place, but it's no code. Offer 2 is enticing because of the amount of raw coding I'll be doing, but also having to answer phone calls from nurses and doctors to troubleshoot basic issues and being on call is a huge downside. Thoughts?", "author_fullname": "t2_5pddzf1hy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First job out of college? What would you choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xitxb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696209933.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696208771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is a lot of overlap between data engineering and analytics for these jobs, so I&amp;#39;ll post in both subs. It&amp;#39;s my first job out of college, and down the line I&amp;#39;m really looking to be a full fledged tech professional, whatever that means. I&amp;#39;m looking at 2 vastly different offers. They are both at hospital systems, remote isn&amp;#39;t an option for either. And I&amp;#39;m not declining either job just because its not remote, I have no leverage as an unemployed college grad desparate for a job. Pay and commute are similar.&lt;/p&gt;\n\n&lt;p&gt;Offer 1: Mostly analytics, using SQL and drag-drop software for ETL processes. More emphasis is placed on understanding the stakeholder needs rather than coding. Data architecture is well established by third party vendor. Workload seems fairly low, easy-going office environment. No on call, typical 9-5, 4 days in office.&lt;/p&gt;\n\n&lt;p&gt;Offer 2: Getting my hands dirty with Python, SQL, and Linux command line for ETL processes, existing data architecture needs lots of work. Job duties also include providing basic IT phone support for hospital employees. On call, unsure of frequency. 9-5, 5 days in office.&lt;/p&gt;\n\n&lt;p&gt;Offer 1 is nice because of the work-life balance, easy and established reporting process is already in place, but it&amp;#39;s no code. Offer 2 is enticing because of the amount of raw coding I&amp;#39;ll be doing, but also having to answer phone calls from nurses and doctors to troubleshoot basic issues and being on call is a huge downside. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xitxb", "is_robot_indexable": true, "report_reasons": null, "author": "knewtonslol", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xitxb/first_job_out_of_college_what_would_you_choose/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xitxb/first_job_out_of_college_what_would_you_choose/", "subreddit_subscribers": 131615, "created_utc": 1696208771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\"Seeking guidance on learning feature engineering. Should I prioritize Python libraries for feature engineering, like Scikit-learn and MLlib, while maintaining a basic understanding of machine learning, given my background in executing PySpark projects using Databricks? Any recommendations on efficient ways to dive into feature engineering?\"\n\nKindly advise video courses and or books \n\nDatacamp\nMike chambers \n\nIf someone has experience please share", "author_fullname": "t2_peoywkn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xe83b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696197435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Seeking guidance on learning feature engineering. Should I prioritize Python libraries for feature engineering, like Scikit-learn and MLlib, while maintaining a basic understanding of machine learning, given my background in executing PySpark projects using Databricks? Any recommendations on efficient ways to dive into feature engineering?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Kindly advise video courses and or books &lt;/p&gt;\n\n&lt;p&gt;Datacamp\nMike chambers &lt;/p&gt;\n\n&lt;p&gt;If someone has experience please share&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16xe83b", "is_robot_indexable": true, "report_reasons": null, "author": "angadaws", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xe83b/feature_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xe83b/feature_engineering/", "subreddit_subscribers": 131615, "created_utc": 1696197435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thanks to the community for being so helpful and supportive!\n\nI am considering to start a data engineering consulting. My niche is e-commerce business.\n\nWhat to hear what the community thinks about this? \n\nIs this a bad decision to focus on building a company around DE consulting? \nWhat are the key challenges I need to prepare for?\nWhat industries to target?\nHow to grow my business? \n\nThanks again!", "author_fullname": "t2_hlf7js20w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering consulting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xob54", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696224918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thanks to the community for being so helpful and supportive!&lt;/p&gt;\n\n&lt;p&gt;I am considering to start a data engineering consulting. My niche is e-commerce business.&lt;/p&gt;\n\n&lt;p&gt;What to hear what the community thinks about this? &lt;/p&gt;\n\n&lt;p&gt;Is this a bad decision to focus on building a company around DE consulting? \nWhat are the key challenges I need to prepare for?\nWhat industries to target?\nHow to grow my business? &lt;/p&gt;\n\n&lt;p&gt;Thanks again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xob54", "is_robot_indexable": true, "report_reasons": null, "author": "No-Dream-420", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xob54/data_engineering_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xob54/data_engineering_consulting/", "subreddit_subscribers": 131615, "created_utc": 1696224918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If a company is not very technical and does not want to spend loads of money on data engineers/ People who can build and manage complex systems can use it as a central repository for their data (Getting it set up via some contractor) and hire analysts who can write SQL (Using good practices) to get value out of data. \n\nMe and my brother are going to start a data engineering services company, initially we want to have one offer for a single type of customer so I am trying to figure out the offer and target customers by reading about various vendors (only Snowflake done so far). \n\nPlease help me know this offer fully so I can properly compare it to other offers in the future. DataBricks and Microsoft Fabric are in the list so far...", "author_fullname": "t2_ens6kw85", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "This is where snowflake best fits:", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xsy3d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696242168.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If a company is not very technical and does not want to spend loads of money on data engineers/ People who can build and manage complex systems can use it as a central repository for their data (Getting it set up via some contractor) and hire analysts who can write SQL (Using good practices) to get value out of data. &lt;/p&gt;\n\n&lt;p&gt;Me and my brother are going to start a data engineering services company, initially we want to have one offer for a single type of customer so I am trying to figure out the offer and target customers by reading about various vendors (only Snowflake done so far). &lt;/p&gt;\n\n&lt;p&gt;Please help me know this offer fully so I can properly compare it to other offers in the future. DataBricks and Microsoft Fabric are in the list so far...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16xsy3d", "is_robot_indexable": true, "report_reasons": null, "author": "Diligent-Tadpole-564", "discussion_type": null, "num_comments": 7, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xsy3d/this_is_where_snowflake_best_fits/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xsy3d/this_is_where_snowflake_best_fits/", "subreddit_subscribers": 131615, "created_utc": 1696242168.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are looking for a database for all our laboratory data, our requirements are that the database must be capable of handling multiple data types (sensor data, images), easily accessible to everyone and most importantly has the functionality to link different databases. We would have a primary database that will have information about multiple processes and then each process has its own database. Whatever data is inserted in the primary database should get updated automatically on the respective process specific secondary database. Been trying to look for something that does these, any suggestions would be appreciated! Thank you.", "author_fullname": "t2_ndudpuk3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open source data management platform for academia", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xcbec", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696193080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are looking for a database for all our laboratory data, our requirements are that the database must be capable of handling multiple data types (sensor data, images), easily accessible to everyone and most importantly has the functionality to link different databases. We would have a primary database that will have information about multiple processes and then each process has its own database. Whatever data is inserted in the primary database should get updated automatically on the respective process specific secondary database. Been trying to look for something that does these, any suggestions would be appreciated! Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16xcbec", "is_robot_indexable": true, "report_reasons": null, "author": "chipsandcokerule", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xcbec/open_source_data_management_platform_for_academia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xcbec/open_source_data_management_platform_for_academia/", "subreddit_subscribers": 131615, "created_utc": 1696193080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Tips. Optimizing JDBC data source reads", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16x7kis", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p1GjGScxcKmQ-FPaqLmcZc3MHdyx7rPDYi802AF_oDE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696182306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luminousmen.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luminousmen.com/post/spark-tips-optimizing-jdbc-data-source-reads", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QEMI5q4IwnMz4l6gRxc8YFGNhwM5v8MuF8yNJm3e1T4.jpg?auto=webp&amp;s=6feb316599e137f192368d3c5f8a09812a2fb9b3", "width": 800, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/QEMI5q4IwnMz4l6gRxc8YFGNhwM5v8MuF8yNJm3e1T4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb47d235eb134e4426e30eb7cc852b9c1767bd28", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/QEMI5q4IwnMz4l6gRxc8YFGNhwM5v8MuF8yNJm3e1T4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=042a2aae04d7b9c5e900bd441411b71f0d3fe891", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/QEMI5q4IwnMz4l6gRxc8YFGNhwM5v8MuF8yNJm3e1T4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e6a7cc51735acd26f5ae97f3b0fbcac4f6ca11e4", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/QEMI5q4IwnMz4l6gRxc8YFGNhwM5v8MuF8yNJm3e1T4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b490b48832c9be9449eb2a5452e626717f703562", "width": 640, "height": 480}], "variants": {}, "id": "FAw-sDyD8fCBR3nlCjPbH2rgCvhf8lX7QDTmW7bd0yU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16x7kis", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x7kis/spark_tips_optimizing_jdbc_data_source_reads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luminousmen.com/post/spark-tips-optimizing-jdbc-data-source-reads", "subreddit_subscribers": 131615, "created_utc": 1696182306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.\n\nExamples:\n\n* What are you working on this month?\n* What was something you accomplished?\n* What was something you learned recently?\n* What is something frustrating you currently?\n\nAs always, sub rules apply. Please be respectful and stay curious.\n\n**Community Links:**\n\n* [Monthly newsletter](https://dataengineeringcommunity.substack.com/)\n* [Data Engineering Events](https://dataengineering.wiki/Community/Events)\n* [Data Engineering Meetups](https://dataengineering.wiki/Community/Meetups)\n* [Get involved in the community](https://dataengineering.wiki/Community/Get+Involved)", "author_fullname": "t2_6l4z3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Monthly General Discussion - Oct 2023", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "collections": [{"permalink": "https://www.reddit.com/r/dataengineering/collection/6278fda2-fad1-4706-9e82-6ddb67d49c0b", "link_ids": ["t3_shzqhy", "t3_t4clgk", "t3_ttu87x", "t3_ug2xqg", "t3_v2ka5e", "t3_vp487n", "t3_wdl07g", "t3_x3bb2b", "t3_xsyy4v", "t3_yjchhi", "t3_z9szlc", "t3_100nsr2", "t3_10qzpp1", "t3_11f8z5h", "t3_128qhe2", "t3_134qgn8", "t3_13xle38", "t3_14nylwl", "t3_15fgn9y", "t3_167b40e", "t3_16x4y7c"], "description": "", "title": "Monthly General Discussions", "created_at_utc": 1642292653.587, "subreddit_id": "t5_36en4", "author_name": "theporterhaus", "collection_id": "6278fda2-fad1-4706-9e82-6ddb67d49c0b", "author_id": "t2_2tv9i42n", "last_update_utc": 1696176058.352, "display_layout": null}], "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16x4y7c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1696176058.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This thread is a place where you can share things that might not warrant their own thread. It is automatically posted each month and you can find previous threads in the collection.&lt;/p&gt;\n\n&lt;p&gt;Examples:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;What are you working on this month?&lt;/li&gt;\n&lt;li&gt;What was something you accomplished?&lt;/li&gt;\n&lt;li&gt;What was something you learned recently?&lt;/li&gt;\n&lt;li&gt;What is something frustrating you currently?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;As always, sub rules apply. Please be respectful and stay curious.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Community Links:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineeringcommunity.substack.com/\"&gt;Monthly newsletter&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Events\"&gt;Data Engineering Events&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Meetups\"&gt;Data Engineering Meetups&lt;/a&gt;&lt;/li&gt;\n&lt;li&gt;&lt;a href=\"https://dataengineering.wiki/Community/Get+Involved\"&gt;Get involved in the community&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/c1tDGdXyXGdsLQ6pwjWc8mXKh5-H7Rix5dx2etHXDU4.jpg?auto=webp&amp;s=02e6018b7f945f491d0b3a2effc39732c734f1e1", "width": 920, "height": 480}, "resolutions": [{"url": "https://external-preview.redd.it/c1tDGdXyXGdsLQ6pwjWc8mXKh5-H7Rix5dx2etHXDU4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=dccc2af8931f0a3ac9ada660b34e9cba537b2fd1", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/c1tDGdXyXGdsLQ6pwjWc8mXKh5-H7Rix5dx2etHXDU4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=a24a390861290f321df46393893e52524fe7623f", "width": 216, "height": 112}, {"url": "https://external-preview.redd.it/c1tDGdXyXGdsLQ6pwjWc8mXKh5-H7Rix5dx2etHXDU4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=53c673cdf215f673c496a58a993c4eac464fc2bb", "width": 320, "height": 166}, {"url": "https://external-preview.redd.it/c1tDGdXyXGdsLQ6pwjWc8mXKh5-H7Rix5dx2etHXDU4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=db34a5d7735459993d15b53c8a1b7aff4d3b2ec4", "width": 640, "height": 333}], "variants": {}, "id": "FmCaWz0_zzuMIYjO5Y9qwrC5XQ9HEDt0Z1CdPOgLQk4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16x4y7c", "is_robot_indexable": true, "report_reasons": null, "author": "AutoModerator", "discussion_type": null, "num_comments": 0, "send_replies": false, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x4y7c/monthly_general_discussion_oct_2023/", "parent_whitelist_status": "all_ads", "stickied": true, "url": "https://old.reddit.com/r/dataengineering/comments/16x4y7c/monthly_general_discussion_oct_2023/", "subreddit_subscribers": 131615, "created_utc": 1696176058.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting Started with Airflow for Beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": true, "name": "t3_16xw41s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 3, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Getting Started with Airflow for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xUKIL7zsjos/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16xw41s", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IfZ7wJhL9utiPsC-TD-zD8lu-CTQx4ysaSk8Sv6M6fA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696251805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/xUKIL7zsjos", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?auto=webp&amp;s=57532a9798dd0f63f82f98e6bdad2b089b1be608", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa7e8c5e146fd23eb95bfc63815b710a803be4e6", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=15475b8c73de173bfc254994ecfb17fcdb78c882", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=40b1b167450b074097af8c9efc000061a07aed17", "width": 320, "height": 240}], "variants": {}, "id": "LmI8hdoYDnBSx0i5v80cfgwiuAE39fOk0kw_zg9f3lw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xw41s", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xw41s/getting_started_with_airflow_for_beginners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/xUKIL7zsjos", "subreddit_subscribers": 131615, "created_utc": 1696251805.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Getting Started with Airflow for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xUKIL7zsjos/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I am comfortable with setting up a pipeline, it runs more or less as I expect but I am not really confident when it comes to configure it, automate to the fullest, parametrize, orchestrate maybe, so all the MS docs and most of youtube/udemy tackles the topic vaguely, just letting you dip the toes and while it'll make you know the tool, it doesnt make you being independent. Now I landed on client site, created some pipelines and need to make them config driven, so there is no further development at UAT's, it should be prone to any changes, additions etc. Are there any prototypes/projects with descriptions, where those things have been discussed in depth, ETL configs etc? Or some blog posts? Thank you in advance", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get good at config driven pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16xuvb6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696248221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I am comfortable with setting up a pipeline, it runs more or less as I expect but I am not really confident when it comes to configure it, automate to the fullest, parametrize, orchestrate maybe, so all the MS docs and most of youtube/udemy tackles the topic vaguely, just letting you dip the toes and while it&amp;#39;ll make you know the tool, it doesnt make you being independent. Now I landed on client site, created some pipelines and need to make them config driven, so there is no further development at UAT&amp;#39;s, it should be prone to any changes, additions etc. Are there any prototypes/projects with descriptions, where those things have been discussed in depth, ETL configs etc? Or some blog posts? Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xuvb6", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xuvb6/how_to_get_good_at_config_driven_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xuvb6/how_to_get_good_at_config_driven_pipelines/", "subreddit_subscribers": 131615, "created_utc": 1696248221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Just trying to do some calculations on data pipelines via Synapse, mainly the costings for activity runs.\n\nForEach &amp; Switches (iterations &amp; conditionals), do they have to be included in the cost as a activity run cost? They don't fall under Azure Integration Runtime or Self Hosted so I assume not?\n\nThanks!", "author_fullname": "t2_2ybq8ird", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Azure Synapse Analytics - Data Pipeline - Costings on Activity Runs", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xt4op", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696242822.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Just trying to do some calculations on data pipelines via Synapse, mainly the costings for activity runs.&lt;/p&gt;\n\n&lt;p&gt;ForEach &amp;amp; Switches (iterations &amp;amp; conditionals), do they have to be included in the cost as a activity run cost? They don&amp;#39;t fall under Azure Integration Runtime or Self Hosted so I assume not?&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16xt4op", "is_robot_indexable": true, "report_reasons": null, "author": "downsy2019", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xt4op/azure_synapse_analytics_data_pipeline_costings_on/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xt4op/azure_synapse_analytics_data_pipeline_costings_on/", "subreddit_subscribers": 131615, "created_utc": 1696242822.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_3wfwjk6u", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Multinode - Rapidly build distributed cloud applications in Python", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": false, "name": "t3_16xsgpk", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/dkhKchQwhE0TTeRQh35qsOPz_4p7Zp1UuGNs4ACGRPE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696240366.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "producthunt.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.producthunt.com/posts/multinode", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/s99t33kSlp-dcnmSbs78dBx0BxF22ho1nq_E220A5sQ.jpg?auto=webp&amp;s=af0da3398c58627d506a54470020d5b3ed522e2f", "width": 1024, "height": 512}, "resolutions": [{"url": "https://external-preview.redd.it/s99t33kSlp-dcnmSbs78dBx0BxF22ho1nq_E220A5sQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=216d32b8b453e6cd160154ed9f6edf095af9fa48", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/s99t33kSlp-dcnmSbs78dBx0BxF22ho1nq_E220A5sQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=74ac10036bf62144f815cc6016f16914fc65bd52", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/s99t33kSlp-dcnmSbs78dBx0BxF22ho1nq_E220A5sQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=44718c4ec85e33ad348d20e9c0b6c4621e52a9d8", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/s99t33kSlp-dcnmSbs78dBx0BxF22ho1nq_E220A5sQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0b8877225ff45028299bec02323e665be71da8d2", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/s99t33kSlp-dcnmSbs78dBx0BxF22ho1nq_E220A5sQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=e495c1a36d907161492f1e7eeec314c088a24648", "width": 960, "height": 480}], "variants": {}, "id": "dTQzALzz7Cn3xV8hkRzL-y6L94QLfRTsDar3pdqTpAk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xsgpk", "is_robot_indexable": true, "report_reasons": null, "author": "akaam_s", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xsgpk/multinode_rapidly_build_distributed_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.producthunt.com/posts/multinode", "subreddit_subscribers": 131615, "created_utc": 1696240366.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello,  \nWe make use of the Debezium PostgreSQL connector but we don't appreciate that it cannot deliver DDL operations. (citation [https://debezium.io/documentation/reference/stable/connectors/postgresql.html](https://debezium.io/documentation/reference/stable/connectors/postgresql.html))\n\nOur expectation was that we could simply hook up Debezium and our PostgreSQL instance and get near-real-time \"mirroring\" to Kafka. We eventually need this mirroring to end up in Redshift, but that's out of scope of this question.\n\nQuestion: are there any alternatives to Debezium's PostgreSQL connector that do capture DDL operations? Some constraints:\n\n\\- cannot send data to a third party. Everything must take place on prem.", "author_fullname": "t2_3aird6b7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative to Debezium PostgreSQL connector?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xoddt", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696225138.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello,&lt;br/&gt;\nWe make use of the Debezium PostgreSQL connector but we don&amp;#39;t appreciate that it cannot deliver DDL operations. (citation &lt;a href=\"https://debezium.io/documentation/reference/stable/connectors/postgresql.html\"&gt;https://debezium.io/documentation/reference/stable/connectors/postgresql.html&lt;/a&gt;)&lt;/p&gt;\n\n&lt;p&gt;Our expectation was that we could simply hook up Debezium and our PostgreSQL instance and get near-real-time &amp;quot;mirroring&amp;quot; to Kafka. We eventually need this mirroring to end up in Redshift, but that&amp;#39;s out of scope of this question.&lt;/p&gt;\n\n&lt;p&gt;Question: are there any alternatives to Debezium&amp;#39;s PostgreSQL connector that do capture DDL operations? Some constraints:&lt;/p&gt;\n\n&lt;p&gt;- cannot send data to a third party. Everything must take place on prem.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xoddt", "is_robot_indexable": true, "report_reasons": null, "author": "agsilvio", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xoddt/alternative_to_debezium_postgresql_connector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xoddt/alternative_to_debezium_postgresql_connector/", "subreddit_subscribers": 131615, "created_utc": 1696225138.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello, ive been a data analyst in a FMCG corpo in a smaller BI team, working with microstrategy dwh, azure snowflake, databricks, and SAp, with strong python and sql(downstream analytical) skills. Ive worked in pretty mature data environment, where i had all the raw and unaggregated data \"served\" and could choose using DWH program for ad hoc small extractions, creating dashboards in it aswell, or doing longer/repeating processes with python/sql and extraction to excel.\nI mostly had self made python  libraries and programs which automated SAP and azure connections/sql script running and all the data transformation, excel storing and mail sending. Before i came in the office, processes were very slow and manually made. This is my background in short.\n\nOn new job ill be working in production and sales company, as DE, on AWS, and first time working on  \"other side\" of sql. Ill be working mostly on extraction of data from excel from various departments, some scraping, some data from softwares/web site. I believe its not as data mature company as one where i was before. As i understood, python is 90% of work. \n\nIll also have a smaller part of the job using tableu and creating dashboards. \n\nCurrently reading fundamentals of data engineering. Will focus on sources, how data is used and pipelines when i start working. Ill try to learn AWS and more about cloud. \n\nWhat good info, sources, suggestions and tips do you have for me? Thank you in advance", "author_fullname": "t2_nj1ve", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Landed new job, from DA to DE would like to hear your advice for first job", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16x84y6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.6, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696183611.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, ive been a data analyst in a FMCG corpo in a smaller BI team, working with microstrategy dwh, azure snowflake, databricks, and SAp, with strong python and sql(downstream analytical) skills. Ive worked in pretty mature data environment, where i had all the raw and unaggregated data &amp;quot;served&amp;quot; and could choose using DWH program for ad hoc small extractions, creating dashboards in it aswell, or doing longer/repeating processes with python/sql and extraction to excel.\nI mostly had self made python  libraries and programs which automated SAP and azure connections/sql script running and all the data transformation, excel storing and mail sending. Before i came in the office, processes were very slow and manually made. This is my background in short.&lt;/p&gt;\n\n&lt;p&gt;On new job ill be working in production and sales company, as DE, on AWS, and first time working on  &amp;quot;other side&amp;quot; of sql. Ill be working mostly on extraction of data from excel from various departments, some scraping, some data from softwares/web site. I believe its not as data mature company as one where i was before. As i understood, python is 90% of work. &lt;/p&gt;\n\n&lt;p&gt;Ill also have a smaller part of the job using tableu and creating dashboards. &lt;/p&gt;\n\n&lt;p&gt;Currently reading fundamentals of data engineering. Will focus on sources, how data is used and pipelines when i start working. Ill try to learn AWS and more about cloud. &lt;/p&gt;\n\n&lt;p&gt;What good info, sources, suggestions and tips do you have for me? Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16x84y6", "is_robot_indexable": true, "report_reasons": null, "author": "Kichmad", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x84y6/landed_new_job_from_da_to_de_would_like_to_hear/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16x84y6/landed_new_job_from_da_to_de_would_like_to_hear/", "subreddit_subscribers": 131615, "created_utc": 1696183611.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi!\n\nIm leading a team of a few part time contractors to build out my company's first Data Warehouse and we are trying to determine the best solution to orchestrate DBT transformations. We work within an AWS ecosystem and have strict rules about maintaining GDPR compliance, which requires that our data remain in Canada. This has proven to be a pretty limiting factor since all of the cloud orchestration tools either dont have Canada as a hosting region or they gets exponentially more expensive to host there (example with Astronomer. This is due to the fact that you are unable to deactivate your cluster, so it runs 24/7 at $2/hour. They claim they are releasing a feature next month to control that, but I cant depend on a sales reps word for this decision). \n\nOur data is small in size so we can use that to our advantage, since many of the options come out to be more affordable. The decision im working through is whether or not we should leverage MWAA (which would be about $4-5k/year with our current needs) or try another solution within the AWS ecosystem like step functions or fargate. Im finding this choice difficult as I do not have experience with these AWS products and I dont want to risk over engineering here.\n\nAny advice would be appreciated :)", "author_fullname": "t2_dkfbs", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Orchestrating DBT Jobs with Airflow/Step functions/Fargate/etc", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xbu4w", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696191987.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi!&lt;/p&gt;\n\n&lt;p&gt;Im leading a team of a few part time contractors to build out my company&amp;#39;s first Data Warehouse and we are trying to determine the best solution to orchestrate DBT transformations. We work within an AWS ecosystem and have strict rules about maintaining GDPR compliance, which requires that our data remain in Canada. This has proven to be a pretty limiting factor since all of the cloud orchestration tools either dont have Canada as a hosting region or they gets exponentially more expensive to host there (example with Astronomer. This is due to the fact that you are unable to deactivate your cluster, so it runs 24/7 at $2/hour. They claim they are releasing a feature next month to control that, but I cant depend on a sales reps word for this decision). &lt;/p&gt;\n\n&lt;p&gt;Our data is small in size so we can use that to our advantage, since many of the options come out to be more affordable. The decision im working through is whether or not we should leverage MWAA (which would be about $4-5k/year with our current needs) or try another solution within the AWS ecosystem like step functions or fargate. Im finding this choice difficult as I do not have experience with these AWS products and I dont want to risk over engineering here.&lt;/p&gt;\n\n&lt;p&gt;Any advice would be appreciated :)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16xbu4w", "is_robot_indexable": true, "report_reasons": null, "author": "biga410", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xbu4w/orchestrating_dbt_jobs_with_airflowstep/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xbu4w/orchestrating_dbt_jobs_with_airflowstep/", "subreddit_subscribers": 131615, "created_utc": 1696191987.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "But seeing the posts here, I'm concerned if there are enough and well paying jobs in DE these days.  \n Please help/guide to switch to DE or get a hybrid kind of job (if there is)", "author_fullname": "t2_3k9gevl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to switch from BI Reporting to DE ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xu4w0", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696246098.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;But seeing the posts here, I&amp;#39;m concerned if there are enough and well paying jobs in DE these days.&lt;br/&gt;\n Please help/guide to switch to DE or get a hybrid kind of job (if there is)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16xu4w0", "is_robot_indexable": true, "report_reasons": null, "author": "Pillstyr", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xu4w0/how_to_switch_from_bi_reporting_to_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xu4w0/how_to_switch_from_bi_reporting_to_de/", "subreddit_subscribers": 131615, "created_utc": 1696246098.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I\u2019m an expert in python, SQL and Bash. Do data engineers still used Java? Since MapReduce is kinda phased out by Spark/PySpark.", "author_fullname": "t2_muzoa5tk", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Java still a requirement in DE?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xqihp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.4, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696232898.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I\u2019m an expert in python, SQL and Bash. Do data engineers still used Java? Since MapReduce is kinda phased out by Spark/PySpark.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16xqihp", "is_robot_indexable": true, "report_reasons": null, "author": "Legitimate-Box-7", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xqihp/java_still_a_requirement_in_de/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xqihp/java_still_a_requirement_in_de/", "subreddit_subscribers": 131615, "created_utc": 1696232898.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello! Has anyone recently attempted the Qlik replicate cert? If yes - can you please share any resources you used to prepare? Struggling to find practice tests online / any course material other than Qlik\u2019s continuous classroom offering. \n\nThanks!", "author_fullname": "t2_fwuj5vp8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Qlik Replicate Certification", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xjavi", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696210041.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello! Has anyone recently attempted the Qlik replicate cert? If yes - can you please share any resources you used to prepare? Struggling to find practice tests online / any course material other than Qlik\u2019s continuous classroom offering. &lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16xjavi", "is_robot_indexable": true, "report_reasons": null, "author": "SuccotashPopular9660", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xjavi/qlik_replicate_certification/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xjavi/qlik_replicate_certification/", "subreddit_subscribers": 131615, "created_utc": 1696210041.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}