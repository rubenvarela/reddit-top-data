{"kind": "Listing", "data": {"after": "t3_16xx761", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Most are pretty aware of dbt, but technology moves fast. Has any serious competitor come up? Curious if anyone has tried sqlmesh - what's your first impression?\n\nContex:\nJust generally curious", "author_fullname": "t2_hj2y0l", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt vs sqlmesh vs ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xbiar", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 34, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 34, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696191264.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Most are pretty aware of dbt, but technology moves fast. Has any serious competitor come up? Curious if anyone has tried sqlmesh - what&amp;#39;s your first impression?&lt;/p&gt;\n\n&lt;p&gt;Contex:\nJust generally curious&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xbiar", "is_robot_indexable": true, "report_reasons": null, "author": "Cryptojacob", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xbiar/dbt_vs_sqlmesh_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xbiar/dbt_vs_sqlmesh_vs/", "subreddit_subscribers": 131649, "created_utc": 1696191264.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Planning to buy a Nuc 11 Enthusiast instead of a Steam Deck to upskill myself as well as not screwing my Gaming PC . Are there any ideas where i can start this journey . My aim to setup homelab is :  \n\n1. Networking side with OpenWrt , pfSense \n2. Containers/Virtualization  with Dockers and Vmware \n3. Server Side with Proxmox\n\nShare if its sufficient to run multiple VMs and Containers with this thing as well as share how do you use homelab for upskilling your DE skills .", "author_fullname": "t2_cl5vl", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any DEs here have homelabs to upskill , make a dedicated dev env, and do other server side stuff ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16x6mf6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.85, "author_flair_background_color": null, "subreddit_type": "public", "ups": 27, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 27, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696180108.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Planning to buy a Nuc 11 Enthusiast instead of a Steam Deck to upskill myself as well as not screwing my Gaming PC . Are there any ideas where i can start this journey . My aim to setup homelab is :  &lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Networking side with OpenWrt , pfSense &lt;/li&gt;\n&lt;li&gt;Containers/Virtualization  with Dockers and Vmware &lt;/li&gt;\n&lt;li&gt;Server Side with Proxmox&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;Share if its sufficient to run multiple VMs and Containers with this thing as well as share how do you use homelab for upskilling your DE skills .&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16x6mf6", "is_robot_indexable": true, "report_reasons": null, "author": "Redxer", "discussion_type": null, "num_comments": 14, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x6mf6/any_des_here_have_homelabs_to_upskill_make_a/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16x6mf6/any_des_here_have_homelabs_to_upskill_make_a/", "subreddit_subscribers": 131649, "created_utc": 1696180108.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I was looking through old posts on this subreddit about system design and came across a comment a couple years ago that discussed a useful scaling exercise to practice for DE interviews: creating a pipeline that ingests 1MB at first, then 1GB, then 10GB, 100GB, 1TB, etc. and then talking about challenges along the way.\n\nI was wondering if this community had some ideas about things to consider as you get further and further up the throughput ladder. Here's a few I've compiled (I assumed the volume at an hourly rate):\n\n&amp;#x200B;\n\n* **@ 1MB / hour**\n   * ingestion: either batch or streaming is possible depending on the nature of the data and our business requirements. Orchestration and processing can live on same machine comfortably.\n   * Throughput is relatively small and should not require distributed processing. Libraries like pandas or numpy would be sufficient for most operations\n   * loading into a relational store or data warehouse should be trivial, though we still need to adopt best practices for designing our schema, managing indexes, etc.\n* **@ 1 GB / hour**\n   * Batch and streaming are both possible, but examine the data to find the most efficient approach. If the data is a single 1GB-sized file arriving hourly, it could be processed in batch, but it wouldn't be ideal to read the whole thing into memory on a lone machine. If the data is from an external source, we also have to pay attention to network I/O. Better to partition the data and have multiple machines read it in parallel. If instead the data is comprised of several small log files or messages in the KB-level, try consuming from an event broker.\n   * Processing data with Pandas on a single machine is possible if scaling vertically, but not ideal. Should switch to a small Spark cluster, or something like Dask. Again, depends on the transformations.\n   * Tools for logging, monitoring pipeline health, and analyzing resource utilization are recommended. (Should be recommended at all levels, but becomes more and more necessary as data scales)\n   * Using an optimized storage format is recommended for large data files (e.g. parquet, avro)\n   * If writing to a relational db, need to be mindful of our transactions/sec and not create strain on the server. (use load balancer and connection pooling)\n* **@ 10 GB / hour**\n   * Horizontal scaling preferred over vertical scaling. Should use a distributed cluster regardless of batch or streaming requirements.\n   * During processing, make sure our joins/transformations aren't creating uneven shards and resulting in bottlenecks on our nodes.\n   * Have strong data governance policies in place for data quality checks, data observability, data lineage, etc.\n   * Continuous monitoring of resource and CPU utilization of the cluster, notifications when thresholds are breached (again, useful at all levels). Also create pipelines for centralized log analysis (with ElasticSearch perhaps?)\n   * Properly partition data in data lake or relational store, with strategies for rolling off data as costs build up.\n   * Optimize compression and indexing wherever possible.\n* **@ 100 GB / hour**\n   * Proper configuration, load balancing, and partitioning of the event broker is essential\n   * Critical to have a properly tuned cluster that can auto-scale to accommodate job size as costs increase.\n   * Watch for bottlenecks in processing, OutOfMemory exceptions are likely if improper join strategies are used.\n   * Clean data, especially data deduplication, is critical for reducing redundant processing.\n   * Writing to traditional relational dbs may struggle to keep up with volume of writes. Distributed databases may be preferred (e.g. Cassandra).\n   * Employ caching liberally, both in serving queries and in processing data\n   * Optimizing queries is crucial, as poorly written SQL can result in long execution and resource contention.\n* **@ 1 TB / hour**\n   * Efficiency in configuring compute and storage is a must. Improperly tuned cloud services can be hugely expensive.\n   * Distributed databases/DWH typically required.\n   * Use an appropriate partitioning strategy in data lake\n   * Avoid processing data that is not necessary for the business, and move data that isn't used to cheaper, long-term storage.\n   * Optimize data model and indexing strategy for efficient queries.\n   * Good data retention policies prevent expensive, unmanageable database growth.\n   * Monitoring and alerting systems should be sophisticated and battle-tested to track overall resource utilization.\n\n# Above all, know how the business plans to use the data, as that will have the biggest influence on design!\n\n**Considerations at all levels:**\n\n* caching\n* security and privacy\n* metadata management\n* CI/CD, testing\n* redundancy and fault-tolerance\n* labor and maintenance overhead\n* cost-complexity ratio\n\n&amp;#x200B;\n\nAnyone have anything else to add? In an interview, I would obviously flesh out a lot of these bullet points.", "author_fullname": "t2_5zyhb", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Scaling exercise for DE interviews", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16x7m4d", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 18, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 18, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696182404.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was looking through old posts on this subreddit about system design and came across a comment a couple years ago that discussed a useful scaling exercise to practice for DE interviews: creating a pipeline that ingests 1MB at first, then 1GB, then 10GB, 100GB, 1TB, etc. and then talking about challenges along the way.&lt;/p&gt;\n\n&lt;p&gt;I was wondering if this community had some ideas about things to consider as you get further and further up the throughput ladder. Here&amp;#39;s a few I&amp;#39;ve compiled (I assumed the volume at an hourly rate):&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;strong&gt;@ 1MB / hour&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;ingestion: either batch or streaming is possible depending on the nature of the data and our business requirements. Orchestration and processing can live on same machine comfortably.&lt;/li&gt;\n&lt;li&gt;Throughput is relatively small and should not require distributed processing. Libraries like pandas or numpy would be sufficient for most operations&lt;/li&gt;\n&lt;li&gt;loading into a relational store or data warehouse should be trivial, though we still need to adopt best practices for designing our schema, managing indexes, etc.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;@ 1 GB / hour&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Batch and streaming are both possible, but examine the data to find the most efficient approach. If the data is a single 1GB-sized file arriving hourly, it could be processed in batch, but it wouldn&amp;#39;t be ideal to read the whole thing into memory on a lone machine. If the data is from an external source, we also have to pay attention to network I/O. Better to partition the data and have multiple machines read it in parallel. If instead the data is comprised of several small log files or messages in the KB-level, try consuming from an event broker.&lt;/li&gt;\n&lt;li&gt;Processing data with Pandas on a single machine is possible if scaling vertically, but not ideal. Should switch to a small Spark cluster, or something like Dask. Again, depends on the transformations.&lt;/li&gt;\n&lt;li&gt;Tools for logging, monitoring pipeline health, and analyzing resource utilization are recommended. (Should be recommended at all levels, but becomes more and more necessary as data scales)&lt;/li&gt;\n&lt;li&gt;Using an optimized storage format is recommended for large data files (e.g. parquet, avro)&lt;/li&gt;\n&lt;li&gt;If writing to a relational db, need to be mindful of our transactions/sec and not create strain on the server. (use load balancer and connection pooling)&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;@ 10 GB / hour&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Horizontal scaling preferred over vertical scaling. Should use a distributed cluster regardless of batch or streaming requirements.&lt;/li&gt;\n&lt;li&gt;During processing, make sure our joins/transformations aren&amp;#39;t creating uneven shards and resulting in bottlenecks on our nodes.&lt;/li&gt;\n&lt;li&gt;Have strong data governance policies in place for data quality checks, data observability, data lineage, etc.&lt;/li&gt;\n&lt;li&gt;Continuous monitoring of resource and CPU utilization of the cluster, notifications when thresholds are breached (again, useful at all levels). Also create pipelines for centralized log analysis (with ElasticSearch perhaps?)&lt;/li&gt;\n&lt;li&gt;Properly partition data in data lake or relational store, with strategies for rolling off data as costs build up.&lt;/li&gt;\n&lt;li&gt;Optimize compression and indexing wherever possible.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;@ 100 GB / hour&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Proper configuration, load balancing, and partitioning of the event broker is essential&lt;/li&gt;\n&lt;li&gt;Critical to have a properly tuned cluster that can auto-scale to accommodate job size as costs increase.&lt;/li&gt;\n&lt;li&gt;Watch for bottlenecks in processing, OutOfMemory exceptions are likely if improper join strategies are used.&lt;/li&gt;\n&lt;li&gt;Clean data, especially data deduplication, is critical for reducing redundant processing.&lt;/li&gt;\n&lt;li&gt;Writing to traditional relational dbs may struggle to keep up with volume of writes. Distributed databases may be preferred (e.g. Cassandra).&lt;/li&gt;\n&lt;li&gt;Employ caching liberally, both in serving queries and in processing data&lt;/li&gt;\n&lt;li&gt;Optimizing queries is crucial, as poorly written SQL can result in long execution and resource contention.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;li&gt;&lt;strong&gt;@ 1 TB / hour&lt;/strong&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Efficiency in configuring compute and storage is a must. Improperly tuned cloud services can be hugely expensive.&lt;/li&gt;\n&lt;li&gt;Distributed databases/DWH typically required.&lt;/li&gt;\n&lt;li&gt;Use an appropriate partitioning strategy in data lake&lt;/li&gt;\n&lt;li&gt;Avoid processing data that is not necessary for the business, and move data that isn&amp;#39;t used to cheaper, long-term storage.&lt;/li&gt;\n&lt;li&gt;Optimize data model and indexing strategy for efficient queries.&lt;/li&gt;\n&lt;li&gt;Good data retention policies prevent expensive, unmanageable database growth.&lt;/li&gt;\n&lt;li&gt;Monitoring and alerting systems should be sophisticated and battle-tested to track overall resource utilization.&lt;/li&gt;\n&lt;/ul&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h1&gt;Above all, know how the business plans to use the data, as that will have the biggest influence on design!&lt;/h1&gt;\n\n&lt;p&gt;&lt;strong&gt;Considerations at all levels:&lt;/strong&gt;&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;caching&lt;/li&gt;\n&lt;li&gt;security and privacy&lt;/li&gt;\n&lt;li&gt;metadata management&lt;/li&gt;\n&lt;li&gt;CI/CD, testing&lt;/li&gt;\n&lt;li&gt;redundancy and fault-tolerance&lt;/li&gt;\n&lt;li&gt;labor and maintenance overhead&lt;/li&gt;\n&lt;li&gt;cost-complexity ratio&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Anyone have anything else to add? In an interview, I would obviously flesh out a lot of these bullet points.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16x7m4d", "is_robot_indexable": true, "report_reasons": null, "author": "LurkLurkington", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x7m4d/scaling_exercise_for_de_interviews/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16x7m4d/scaling_exercise_for_de_interviews/", "subreddit_subscribers": 131649, "created_utc": 1696182404.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Would you rather work on different projects where you implement something and then go to the next project (consulting) or work in a team with a single project developing a single data ecosystem?\n\nI was wondering what DEs in this sub rather do. I\u2019ve  doing the first one (consulting) for a while, but I was curious about how is the day in the life outside of consulting.", "author_fullname": "t2_66knxh65", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What would you rather do?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xfsg6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.86, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": true, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696201028.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would you rather work on different projects where you implement something and then go to the next project (consulting) or work in a team with a single project developing a single data ecosystem?&lt;/p&gt;\n\n&lt;p&gt;I was wondering what DEs in this sub rather do. I\u2019ve  doing the first one (consulting) for a while, but I was curious about how is the day in the life outside of consulting.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xfsg6", "is_robot_indexable": true, "report_reasons": null, "author": "WarNeverChanges1997", "discussion_type": null, "num_comments": 21, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xfsg6/what_would_you_rather_do/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xfsg6/what_would_you_rather_do/", "subreddit_subscribers": 131649, "created_utc": 1696201028.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "About a year ago, I began to realize how suboptimal my experience was while working with dbt and other data engineering projects in my company. As a result, I started exploring ways to improve this situation.\n\nAfter some time, I have come up with three solutions that I would like to share:\n\n* When working with dbt specifically, use \u201cdbt Power User\u201d plugin for VSCode to get contextual information, suggestions, data lineage for dbt models, etc. It makes the workflow really enjoyable.\n* Incorporate SQLFluff for linting and formatting SQL code. It should bring a consistent code to your project and you finally stop arguing about leading vs trailing commas.\n* Also implement pre-commit hooks, small scripts that run before committing code to Github. These script usually perform various checks on the project, such as YAML validity, documentation and test availability, etc.\n\nBasically, I explained all three solutions in greater details in my newsletter [here](https://dbtips.substack.com/p/get-the-ultimate-developer-experience).\n\nDo you have any other tips of improving DX you can share?", "author_fullname": "t2_4679pe1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to improve your developer experience when working with dbt (and not only)", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16x9maj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.92, "author_flair_background_color": null, "subreddit_type": "public", "ups": 10, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 10, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696186924.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;About a year ago, I began to realize how suboptimal my experience was while working with dbt and other data engineering projects in my company. As a result, I started exploring ways to improve this situation.&lt;/p&gt;\n\n&lt;p&gt;After some time, I have come up with three solutions that I would like to share:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;When working with dbt specifically, use \u201cdbt Power User\u201d plugin for VSCode to get contextual information, suggestions, data lineage for dbt models, etc. It makes the workflow really enjoyable.&lt;/li&gt;\n&lt;li&gt;Incorporate SQLFluff for linting and formatting SQL code. It should bring a consistent code to your project and you finally stop arguing about leading vs trailing commas.&lt;/li&gt;\n&lt;li&gt;Also implement pre-commit hooks, small scripts that run before committing code to Github. These script usually perform various checks on the project, such as YAML validity, documentation and test availability, etc.&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Basically, I explained all three solutions in greater details in my newsletter &lt;a href=\"https://dbtips.substack.com/p/get-the-ultimate-developer-experience\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Do you have any other tips of improving DX you can share?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?auto=webp&amp;s=d3bb661896828bac4429562f6ce7fff4ef505422", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=5af75ad43a854078e3cea834f3ef698663e88cdc", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=37ae9fc5f3b20c68d9199ed55882ebca83ef2855", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=5685fef764bd1fa720328ebd972cc947f012bd86", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0c958b3293f06f32b4616718b83399f29154edee", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=89fca96637cd1490f814b4b891f7bdc567c62f1f", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/s0TIqqlC6I0ChDA1sGkNSIbFqZTLX1cxIH_yrPkaYj0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0f972567e2eba31f2c54f818bdce4b34235f400e", "width": 1080, "height": 540}], "variants": {}, "id": "ntcEH-D8yVlbOqdDYiN0TVlVBkXGXM6b3WJWBcIF5sw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16x9maj", "is_robot_indexable": true, "report_reasons": null, "author": "oleg_agapov", "discussion_type": null, "num_comments": 11, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x9maj/how_to_improve_your_developer_experience_when/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16x9maj/how_to_improve_your_developer_experience_when/", "subreddit_subscribers": 131649, "created_utc": 1696186924.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "For me: I was pushed to use FiveTran and from there the pain started, our simple infra became complicated. Took me almost 8 months to convince my boss to replace that with ELT approach where sink to S3 -&gt; dbt-&gt;Redshift", "author_fullname": "t2_5b3y9jqyc", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any tool, you regret buying or deploying in the data infrastructure?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xxu15", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 13, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 13, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696256235.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;For me: I was pushed to use FiveTran and from there the pain started, our simple infra became complicated. Took me almost 8 months to convince my boss to replace that with ELT approach where sink to S3 -&amp;gt; dbt-&amp;gt;Redshift&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xxu15", "is_robot_indexable": true, "report_reasons": null, "author": "de4all", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xxu15/any_tool_you_regret_buying_or_deploying_in_the/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xxu15/any_tool_you_regret_buying_or_deploying_in_the/", "subreddit_subscribers": 131649, "created_utc": 1696256235.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_2mhgth69", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting Started with Airflow for Beginners", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16xw41s", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 9, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Getting Started with Airflow for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xUKIL7zsjos/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/16xw41s", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 9, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/IfZ7wJhL9utiPsC-TD-zD8lu-CTQx4ysaSk8Sv6M6fA.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696251805.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtu.be", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://youtu.be/xUKIL7zsjos", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?auto=webp&amp;s=57532a9798dd0f63f82f98e6bdad2b089b1be608", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fa7e8c5e146fd23eb95bfc63815b710a803be4e6", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=15475b8c73de173bfc254994ecfb17fcdb78c882", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/T4YyMc6VC2UOui-2zwFVrE9aBp71kYlVV1JqoszmaYY.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=40b1b167450b074097af8c9efc000061a07aed17", "width": 320, "height": 240}], "variants": {}, "id": "LmI8hdoYDnBSx0i5v80cfgwiuAE39fOk0kw_zg9f3lw"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xw41s", "is_robot_indexable": true, "report_reasons": null, "author": "marclamberti", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xw41s/getting_started_with_airflow_for_beginners/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://youtu.be/xUKIL7zsjos", "subreddit_subscribers": 131649, "created_utc": 1696251805.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Getting Started with Airflow for Beginners", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/xUKIL7zsjos?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Getting Started with Airflow for Beginners\"&gt;&lt;/iframe&gt;", "author_name": "Data with Marc", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/xUKIL7zsjos/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MarcLamberti"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "There is a lot of overlap between data engineering and analytics for these jobs, so I'll post in both subs. It's my first job out of college, and down the line I'm really looking to be a full fledged tech professional, whatever that means. I'm looking at 2 vastly different offers. They are both at hospital systems, remote isn't an option for either. And I'm not declining either job just because its not remote, I have no leverage as an unemployed college grad desparate for a job. Pay and commute are similar.\n\nOffer 1: Mostly analytics, using SQL and drag-drop software for ETL processes. More emphasis is placed on understanding the stakeholder needs rather than coding. Data architecture is well established by third party vendor. Workload seems fairly low, easy-going office environment. No on call, typical 9-5, 4 days in office.\n\nOffer 2: Getting my hands dirty with Python, SQL, and Linux command line for ETL processes, existing data architecture needs lots of work. Job duties also include providing basic IT phone support for hospital employees. On call, unsure of frequency. 9-5, 5 days in office.\n\nOffer 1 is nice because of the work-life balance, easy and established reporting process is already in place, but it's no code. Offer 2 is enticing because of the amount of raw coding I'll be doing, but also having to answer phone calls from nurses and doctors to troubleshoot basic issues and being on call is a huge downside. Thoughts?", "author_fullname": "t2_5pddzf1hy", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "First job out of college? What would you choose?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xitxb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696209933.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696208771.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;There is a lot of overlap between data engineering and analytics for these jobs, so I&amp;#39;ll post in both subs. It&amp;#39;s my first job out of college, and down the line I&amp;#39;m really looking to be a full fledged tech professional, whatever that means. I&amp;#39;m looking at 2 vastly different offers. They are both at hospital systems, remote isn&amp;#39;t an option for either. And I&amp;#39;m not declining either job just because its not remote, I have no leverage as an unemployed college grad desparate for a job. Pay and commute are similar.&lt;/p&gt;\n\n&lt;p&gt;Offer 1: Mostly analytics, using SQL and drag-drop software for ETL processes. More emphasis is placed on understanding the stakeholder needs rather than coding. Data architecture is well established by third party vendor. Workload seems fairly low, easy-going office environment. No on call, typical 9-5, 4 days in office.&lt;/p&gt;\n\n&lt;p&gt;Offer 2: Getting my hands dirty with Python, SQL, and Linux command line for ETL processes, existing data architecture needs lots of work. Job duties also include providing basic IT phone support for hospital employees. On call, unsure of frequency. 9-5, 5 days in office.&lt;/p&gt;\n\n&lt;p&gt;Offer 1 is nice because of the work-life balance, easy and established reporting process is already in place, but it&amp;#39;s no code. Offer 2 is enticing because of the amount of raw coding I&amp;#39;ll be doing, but also having to answer phone calls from nurses and doctors to troubleshoot basic issues and being on call is a huge downside. Thoughts?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xitxb", "is_robot_indexable": true, "report_reasons": null, "author": "knewtonslol", "discussion_type": null, "num_comments": 18, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xitxb/first_job_out_of_college_what_would_you_choose/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xitxb/first_job_out_of_college_what_would_you_choose/", "subreddit_subscribers": 131649, "created_utc": 1696208771.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm a data engineer with a few years experience in SQL/NoSQL. I've designed/diagnosed high throughput TPS systems, warehousing clusters, HA, DR, DBA, code reviews.\n\nUnfortunately due to health reasons I took a few years off with just occasionally solving a brain teaser on LeetCode. I'm trying to get my career back on track. I've been reading a lot about AI and frankly i think its the future of search. This quickly drew me to Vector DBs and I'm wondering if you suggest getting deep into that, or what else, and i'd appreciate links to courses/tuts.\n\n&amp;#x200B;\n\n&amp;#x200B;", "author_fullname": "t2_edkp97o8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Getting back into DB world, should I learn Vector DBs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xe9jr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696197530.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m a data engineer with a few years experience in SQL/NoSQL. I&amp;#39;ve designed/diagnosed high throughput TPS systems, warehousing clusters, HA, DR, DBA, code reviews.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately due to health reasons I took a few years off with just occasionally solving a brain teaser on LeetCode. I&amp;#39;m trying to get my career back on track. I&amp;#39;ve been reading a lot about AI and frankly i think its the future of search. This quickly drew me to Vector DBs and I&amp;#39;m wondering if you suggest getting deep into that, or what else, and i&amp;#39;d appreciate links to courses/tuts.&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16xe9jr", "is_robot_indexable": true, "report_reasons": null, "author": "no_deal_111", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xe9jr/getting_back_into_db_world_should_i_learn_vector/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xe9jr/getting_back_into_db_world_should_i_learn_vector/", "subreddit_subscribers": 131649, "created_utc": 1696197530.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "In my latest blog post, I've summarized the key takeaways from Snowflake Summit 2023 in Bangalore, so that those who couldn't attend can benefit from the latest updates on data governance and cost management.  \n\n\nData Governance Highlights:  \n1) Data Quality Monitoring  \n2) Query Constraint Policies  \n3) Data Access Policies  \n4) Data Governance UI  \n5) Classification UI  \n6) Global PII Classification  \n\n\nCost Control Highlights:  \n1) Budget  \n2) Warehouse Utilization  \n3) SnowLens  \n\n\nBlog Link - [Unlocking the Power of Data Governance and Cost Control: Insights from Snowflake Summit 2023](https://medium.com/bi3-technologies/unlocking-the-power-of-data-governance-and-privacy-insights-from-snowflake-summit-2023-7ffcb697e005)\n\n&amp;#x200B;\n\nhttps://preview.redd.it/z371joftmqrb1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=7aa178f639e8751472f63f1d63fcc22805cd9d90\n\nI want to thank the event organizers and the insightful speakers:  \n\n\n1) [Hemant Raorane](https://www.linkedin.com/in/ACoAABMXMIIB6tUTKUjbYz1CqBz2jS3NCnSpM7I), Sales Engineer, [Snowflake](https://www.linkedin.com/company/snowflake-computing/) India  \n2) [Sachin Gangwar](https://www.linkedin.com/in/ACoAAAZGouMBkudPlBY9PD76sXVTAdnwWQNQm9w), Senior Sales Engineer, [Snowflake](https://www.linkedin.com/company/snowflake-computing/) India  \n3) [Wasim El-Omari](https://www.linkedin.com/in/ACoAAC-O1KYBhH78QJa92-7ggpODUPFVS3jvgAc), Principal Architect, Security, Field CTO Office, [Snowflake](https://www.linkedin.com/company/snowflake-computing/)  \n4) [Pawan Mall](https://www.linkedin.com/in/ACoAAAEq2hkBAI8EwgK_ROKoaULMSB-72GQrnS0), Senior Sales Engineer, [Snowflake](https://www.linkedin.com/company/snowflake-computing/) India  \n5) [Vikash K.](https://www.linkedin.com/in/ACoAACea-JUBwLCCA2Iqcbrpm_F6rHUrEKHpHA4), Senior Data Cloud Architect | GSI Partners, [Snowflake](https://www.linkedin.com/company/snowflake-computing/) India  \n\n\nYour expertise will shape how we handle data in our projects.  \n\n\n[\\#SnowflakeSummit2023](https://www.linkedin.com/feed/hashtag/?keywords=snowflakesummit2023&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#DataGovernance](https://www.linkedin.com/feed/hashtag/?keywords=datagovernance&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#CostControl](https://www.linkedin.com/feed/hashtag/?keywords=costcontrol&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#DataManagement](https://www.linkedin.com/feed/hashtag/?keywords=datamanagement&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#TechTrends](https://www.linkedin.com/feed/hashtag/?keywords=techtrends&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#DataAnalytics](https://www.linkedin.com/feed/hashtag/?keywords=dataanalytics&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#DataSecurity](https://www.linkedin.com/feed/hashtag/?keywords=datasecurity&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#Snowflake](https://www.linkedin.com/feed/hashtag/?keywords=snowflake&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) [\\#SnowflakeDevelopers](https://www.linkedin.com/feed/hashtag/?keywords=snowflakedevelopers&amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944) ", "author_fullname": "t2_hhlcq19gr", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Key takeaways from Snowflake Summit 2023 in Bangalore", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "media_metadata": {"z371joftmqrb1": {"status": "valid", "e": "Image", "m": "image/jpg", "p": [{"y": 81, "x": 108, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=632d25e3e54af280ce7616d3debab386c63f0568"}, {"y": 162, "x": 216, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=9bfbd5f8788550e35d5658dcefb105c1c63d6b0d"}, {"y": 240, "x": 320, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f77fa2d109d22fad0d51dbf0bcd975b9114bd1d5"}, {"y": 480, "x": 640, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=f028485b825f179d5aed019f12d7568ebb1adaf2"}, {"y": 720, "x": 960, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=b201bb9b074bf1f4348fa10aa0d65cd0ada5e4c4"}, {"y": 810, "x": 1080, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=0e153a28fa2528f892f5df29d19402d8c80efb2c"}], "s": {"y": 1200, "x": 1600, "u": "https://preview.redd.it/z371joftmqrb1.jpg?width=1600&amp;format=pjpg&amp;auto=webp&amp;s=7aa178f639e8751472f63f1d63fcc22805cd9d90"}, "id": "z371joftmqrb1"}}, "name": "t3_16xprjr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GTriMGw7dhnIVYinyVqUBxw7GM_RpAGKtQqnNof47ck.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "subreddit_type": "public", "created": 1696230074.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In my latest blog post, I&amp;#39;ve summarized the key takeaways from Snowflake Summit 2023 in Bangalore, so that those who couldn&amp;#39;t attend can benefit from the latest updates on data governance and cost management.  &lt;/p&gt;\n\n&lt;p&gt;Data Governance Highlights:&lt;br/&gt;\n1) Data Quality Monitoring&lt;br/&gt;\n2) Query Constraint Policies&lt;br/&gt;\n3) Data Access Policies&lt;br/&gt;\n4) Data Governance UI&lt;br/&gt;\n5) Classification UI&lt;br/&gt;\n6) Global PII Classification  &lt;/p&gt;\n\n&lt;p&gt;Cost Control Highlights:&lt;br/&gt;\n1) Budget&lt;br/&gt;\n2) Warehouse Utilization&lt;br/&gt;\n3) SnowLens  &lt;/p&gt;\n\n&lt;p&gt;Blog Link - &lt;a href=\"https://medium.com/bi3-technologies/unlocking-the-power-of-data-governance-and-privacy-insights-from-snowflake-summit-2023-7ffcb697e005\"&gt;Unlocking the Power of Data Governance and Cost Control: Insights from Snowflake Summit 2023&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/z371joftmqrb1.jpg?width=1600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7aa178f639e8751472f63f1d63fcc22805cd9d90\"&gt;https://preview.redd.it/z371joftmqrb1.jpg?width=1600&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=7aa178f639e8751472f63f1d63fcc22805cd9d90&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;I want to thank the event organizers and the insightful speakers:  &lt;/p&gt;\n\n&lt;p&gt;1) &lt;a href=\"https://www.linkedin.com/in/ACoAABMXMIIB6tUTKUjbYz1CqBz2jS3NCnSpM7I\"&gt;Hemant Raorane&lt;/a&gt;, Sales Engineer, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt; India&lt;br/&gt;\n2) &lt;a href=\"https://www.linkedin.com/in/ACoAAAZGouMBkudPlBY9PD76sXVTAdnwWQNQm9w\"&gt;Sachin Gangwar&lt;/a&gt;, Senior Sales Engineer, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt; India&lt;br/&gt;\n3) &lt;a href=\"https://www.linkedin.com/in/ACoAAC-O1KYBhH78QJa92-7ggpODUPFVS3jvgAc\"&gt;Wasim El-Omari&lt;/a&gt;, Principal Architect, Security, Field CTO Office, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt;&lt;br/&gt;\n4) &lt;a href=\"https://www.linkedin.com/in/ACoAAAEq2hkBAI8EwgK_ROKoaULMSB-72GQrnS0\"&gt;Pawan Mall&lt;/a&gt;, Senior Sales Engineer, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt; India&lt;br/&gt;\n5) &lt;a href=\"https://www.linkedin.com/in/ACoAACea-JUBwLCCA2Iqcbrpm_F6rHUrEKHpHA4\"&gt;Vikash K.&lt;/a&gt;, Senior Data Cloud Architect | GSI Partners, &lt;a href=\"https://www.linkedin.com/company/snowflake-computing/\"&gt;Snowflake&lt;/a&gt; India  &lt;/p&gt;\n\n&lt;p&gt;Your expertise will shape how we handle data in our projects.  &lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=snowflakesummit2023&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#SnowflakeSummit2023&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=datagovernance&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#DataGovernance&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=costcontrol&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#CostControl&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=datamanagement&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#DataManagement&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=techtrends&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#TechTrends&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=dataanalytics&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#DataAnalytics&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=datasecurity&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#DataSecurity&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=snowflake&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#Snowflake&lt;/a&gt; &lt;a href=\"https://www.linkedin.com/feed/hashtag/?keywords=snowflakedevelopers&amp;amp;highlightedUpdateUrns=urn%3Ali%3Aactivity%3A7114183004519890944\"&gt;#SnowflakeDevelopers&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?auto=webp&amp;s=87203ce307f9b72fb094e85035ea3a41a5c8c384", "width": 1200, "height": 628}, "resolutions": [{"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=a9637f60474d774efa820fda8f5974253eaefa50", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=83868552d3590e90338962cb8d1672ccbaa73828", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=c4b715c2453ce59b28c1dcce84f0153ab57bd1f0", "width": 320, "height": 167}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=9699bdf7ecc3f6608279ad7cb3f1411d89fc0424", "width": 640, "height": 334}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=7c95fed484686b328184f7151ca8e51384b94448", "width": 960, "height": 502}, {"url": "https://external-preview.redd.it/mOnZdotm_swfXKikgDWKR7RoivQD5XTwI3LWgQELgoQ.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=20407829974bcc45a6f50e4809fca58564a96763", "width": 1080, "height": 565}], "variants": {}, "id": "4x9_UIUovtScdP6OlrszrrtgeXaSEDyQR_m-Sv_lbvk"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xprjr", "is_robot_indexable": true, "report_reasons": null, "author": "ijiv_s", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xprjr/key_takeaways_from_snowflake_summit_2023_in/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xprjr/key_takeaways_from_snowflake_summit_2023_in/", "subreddit_subscribers": 131649, "created_utc": 1696230074.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Thanks to the community for being so helpful and supportive!\n\nI am considering to start a data engineering consulting. My niche is e-commerce business.\n\nWhat to hear what the community thinks about this? \n\nIs this a bad decision to focus on building a company around DE consulting? \nWhat are the key challenges I need to prepare for?\nWhat industries to target?\nHow to grow my business? \n\nThanks again!", "author_fullname": "t2_hlf7js20w", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineering consulting", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xob54", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.9, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696224918.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Thanks to the community for being so helpful and supportive!&lt;/p&gt;\n\n&lt;p&gt;I am considering to start a data engineering consulting. My niche is e-commerce business.&lt;/p&gt;\n\n&lt;p&gt;What to hear what the community thinks about this? &lt;/p&gt;\n\n&lt;p&gt;Is this a bad decision to focus on building a company around DE consulting? \nWhat are the key challenges I need to prepare for?\nWhat industries to target?\nHow to grow my business? &lt;/p&gt;\n\n&lt;p&gt;Thanks again!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16xob54", "is_robot_indexable": true, "report_reasons": null, "author": "No-Dream-420", "discussion_type": null, "num_comments": 10, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xob54/data_engineering_consulting/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xob54/data_engineering_consulting/", "subreddit_subscribers": 131649, "created_utc": 1696224918.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I don't see any pricing details for glue workflows but I would assume there's an extra cost since it's providing additional functionality. I only see pricing based on DPUs for Glue jobs. Does this mean that if I use Glue Workflows to orchestrate glue jobs, I will only pay for the cost of the glue jobs and the orchestration will just be free? If that's the case, is there any benefit to using Airflow for orchestration of glue jobs if glue workflows can be used?", "author_fullname": "t2_jx5l6r0ay", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is there any added cost to using Glue workflows with Glue jobs?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16x6tkl", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696180572.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t see any pricing details for glue workflows but I would assume there&amp;#39;s an extra cost since it&amp;#39;s providing additional functionality. I only see pricing based on DPUs for Glue jobs. Does this mean that if I use Glue Workflows to orchestrate glue jobs, I will only pay for the cost of the glue jobs and the orchestration will just be free? If that&amp;#39;s the case, is there any benefit to using Airflow for orchestration of glue jobs if glue workflows can be used?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16x6tkl", "is_robot_indexable": true, "report_reasons": null, "author": "IllRepresentative858", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x6tkl/is_there_any_added_cost_to_using_glue_workflows/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16x6tkl/is_there_any_added_cost_to_using_glue_workflows/", "subreddit_subscribers": 131649, "created_utc": 1696180572.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "\"Seeking guidance on learning feature engineering. Should I prioritize Python libraries for feature engineering, like Scikit-learn and MLlib, while maintaining a basic understanding of machine learning, given my background in executing PySpark projects using Databricks? Any recommendations on efficient ways to dive into feature engineering?\"\n\nKindly advise video courses and or books \n\nDatacamp\nMike chambers \n\nIf someone has experience please share", "author_fullname": "t2_peoywkn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Feature Engineering", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xe83b", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.65, "author_flair_background_color": null, "subreddit_type": "public", "ups": 5, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 5, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696197435.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Seeking guidance on learning feature engineering. Should I prioritize Python libraries for feature engineering, like Scikit-learn and MLlib, while maintaining a basic understanding of machine learning, given my background in executing PySpark projects using Databricks? Any recommendations on efficient ways to dive into feature engineering?&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Kindly advise video courses and or books &lt;/p&gt;\n\n&lt;p&gt;Datacamp\nMike chambers &lt;/p&gt;\n\n&lt;p&gt;If someone has experience please share&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "16xe83b", "is_robot_indexable": true, "report_reasons": null, "author": "angadaws", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xe83b/feature_engineering/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xe83b/feature_engineering/", "subreddit_subscribers": 131649, "created_utc": 1696197435.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I am comfortable with setting up a pipeline, it runs more or less as I expect but I am not really confident when it comes to configure it, automate to the fullest, parametrize, orchestrate maybe, so all the MS docs and most of youtube/udemy tackles the topic vaguely, just letting you dip the toes and while it'll make you know the tool, it doesnt make you being independent. Now I landed on client site, created some pipelines and need to make them config driven, so there is no further development at UAT's, it should be prone to any changes, additions etc. Are there any prototypes/projects with descriptions, where those things have been discussed in depth, ETL configs etc? Or some blog posts? Thank you in advance", "author_fullname": "t2_ajcdrgrx", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to get good at config driven pipelines", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xuvb6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696248221.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I am comfortable with setting up a pipeline, it runs more or less as I expect but I am not really confident when it comes to configure it, automate to the fullest, parametrize, orchestrate maybe, so all the MS docs and most of youtube/udemy tackles the topic vaguely, just letting you dip the toes and while it&amp;#39;ll make you know the tool, it doesnt make you being independent. Now I landed on client site, created some pipelines and need to make them config driven, so there is no further development at UAT&amp;#39;s, it should be prone to any changes, additions etc. Are there any prototypes/projects with descriptions, where those things have been discussed in depth, ETL configs etc? Or some blog posts? Thank you in advance&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xuvb6", "is_robot_indexable": true, "report_reasons": null, "author": "Commercial-Ask971", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xuvb6/how_to_get_good_at_config_driven_pipelines/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xuvb6/how_to_get_good_at_config_driven_pipelines/", "subreddit_subscribers": 131649, "created_utc": 1696248221.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "We are looking for a database for all our laboratory data, our requirements are that the database must be capable of handling multiple data types (sensor data, images), easily accessible to everyone and most importantly has the functionality to link different databases. We would have a primary database that will have information about multiple processes and then each process has its own database. Whatever data is inserted in the primary database should get updated automatically on the respective process specific secondary database. Been trying to look for something that does these, any suggestions would be appreciated! Thank you.", "author_fullname": "t2_ndudpuk3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Open source data management platform for academia", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xcbec", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696193080.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;We are looking for a database for all our laboratory data, our requirements are that the database must be capable of handling multiple data types (sensor data, images), easily accessible to everyone and most importantly has the functionality to link different databases. We would have a primary database that will have information about multiple processes and then each process has its own database. Whatever data is inserted in the primary database should get updated automatically on the respective process specific secondary database. Been trying to look for something that does these, any suggestions would be appreciated! Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16xcbec", "is_robot_indexable": true, "report_reasons": null, "author": "chipsandcokerule", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xcbec/open_source_data_management_platform_for_academia/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xcbec/open_source_data_management_platform_for_academia/", "subreddit_subscribers": 131649, "created_utc": 1696193080.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I am dealing with small to medium sized customers looking for a basic data warehouse solution for Power BI reports. They generally have several GB up to a maximum of a 100 GB of data to store, and several dozens of users.\n\nFor these small scale solutions, is it really better to use OLAP databases like Synapse, Snowflake, Redshift? It seems like a simple Azure database or PostgreSQL as a service is much cheaper and would offer sufficient performance? Am I missing something?\n\nI have been involved with Snowflake solutions twice before, but in both cases the client had a negative perception of the costs. Or could I configure Snowflake in such a way that it runs cheaply?", "author_fullname": "t2_u2p974i5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Do I really need an OLAP database for a data warehouse?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16xzlm4", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696260420.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am dealing with small to medium sized customers looking for a basic data warehouse solution for Power BI reports. They generally have several GB up to a maximum of a 100 GB of data to store, and several dozens of users.&lt;/p&gt;\n\n&lt;p&gt;For these small scale solutions, is it really better to use OLAP databases like Synapse, Snowflake, Redshift? It seems like a simple Azure database or PostgreSQL as a service is much cheaper and would offer sufficient performance? Am I missing something?&lt;/p&gt;\n\n&lt;p&gt;I have been involved with Snowflake solutions twice before, but in both cases the client had a negative perception of the costs. Or could I configure Snowflake in such a way that it runs cheaply?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xzlm4", "is_robot_indexable": true, "report_reasons": null, "author": "MarcScripts", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xzlm4/do_i_really_need_an_olap_database_for_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xzlm4/do_i_really_need_an_olap_database_for_a_data/", "subreddit_subscribers": 131649, "created_utc": 1696260420.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_xf2t5", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Spark Tips. Optimizing JDBC data source reads", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_16x7kis", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/p1GjGScxcKmQ-FPaqLmcZc3MHdyx7rPDYi802AF_oDE.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696182306.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "luminousmen.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://luminousmen.com/post/spark-tips-optimizing-jdbc-data-source-reads", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/QEMI5q4IwnMz4l6gRxc8YFGNhwM5v8MuF8yNJm3e1T4.jpg?auto=webp&amp;s=6feb316599e137f192368d3c5f8a09812a2fb9b3", "width": 800, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/QEMI5q4IwnMz4l6gRxc8YFGNhwM5v8MuF8yNJm3e1T4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=fb47d235eb134e4426e30eb7cc852b9c1767bd28", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/QEMI5q4IwnMz4l6gRxc8YFGNhwM5v8MuF8yNJm3e1T4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=042a2aae04d7b9c5e900bd441411b71f0d3fe891", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/QEMI5q4IwnMz4l6gRxc8YFGNhwM5v8MuF8yNJm3e1T4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=e6a7cc51735acd26f5ae97f3b0fbcac4f6ca11e4", "width": 320, "height": 240}, {"url": "https://external-preview.redd.it/QEMI5q4IwnMz4l6gRxc8YFGNhwM5v8MuF8yNJm3e1T4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=b490b48832c9be9449eb2a5452e626717f703562", "width": 640, "height": 480}], "variants": {}, "id": "FAw-sDyD8fCBR3nlCjPbH2rgCvhf8lX7QDTmW7bd0yU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16x7kis", "is_robot_indexable": true, "report_reasons": null, "author": "luminoumen", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16x7kis/spark_tips_optimizing_jdbc_data_source_reads/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://luminousmen.com/post/spark-tips-optimizing-jdbc-data-source-reads", "subreddit_subscribers": 131649, "created_utc": 1696182306.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Let's say we have a column called previous_order_id that gives the order_id of the previous customer for a given order. It is defined as (using snowflake):\n\n    lag(order_id, 1, 0) over (partition by customer_id order by created_at asc) as previous_email_id\n\nHow would we test the values are correct? \n\nI guess in general, if we generate a SQL based report, how do we know the report has generated the correct values? Aside from testing nulls, accepted values etc.", "author_fullname": "t2_ske3s9us", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Testing complex logic of SQL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16y0fcs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696262318.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Let&amp;#39;s say we have a column called previous_order_id that gives the order_id of the previous customer for a given order. It is defined as (using snowflake):&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;lag(order_id, 1, 0) over (partition by customer_id order by created_at asc) as previous_email_id\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;How would we test the values are correct? &lt;/p&gt;\n\n&lt;p&gt;I guess in general, if we generate a SQL based report, how do we know the report has generated the correct values? Aside from testing nulls, accepted values etc.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16y0fcs", "is_robot_indexable": true, "report_reasons": null, "author": "iamanoob38", "discussion_type": null, "num_comments": 2, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16y0fcs/testing_complex_logic_of_sql/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16y0fcs/testing_complex_logic_of_sql/", "subreddit_subscribers": 131649, "created_utc": 1696262318.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, does someone have experience running Google's Dataform to model data in BigQuery in a ELT stack? Are there any limitations in comparison to dbt? Handling complicated data modeling queries, docs generation, lineage etc.? There is a huge difference in costs since Dataform is free and dbt Cloud Team for a 5 people is 6K per year, and Enterprise for 5 people is 24K.", "author_fullname": "t2_7chglbbu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "dbt vs Dataform when using BigQuery as a data warehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16xzyrh", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696261252.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, does someone have experience running Google&amp;#39;s Dataform to model data in BigQuery in a ELT stack? Are there any limitations in comparison to dbt? Handling complicated data modeling queries, docs generation, lineage etc.? There is a huge difference in costs since Dataform is free and dbt Cloud Team for a 5 people is 6K per year, and Enterprise for 5 people is 24K.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16xzyrh", "is_robot_indexable": true, "report_reasons": null, "author": "Computingss", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xzyrh/dbt_vs_dataform_when_using_bigquery_as_a_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xzyrh/dbt_vs_dataform_when_using_bigquery_as_a_data/", "subreddit_subscribers": 131649, "created_utc": 1696261252.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, currently we are using Fivetran to get our Hubspot data and put it into a Fivetran managed BigQuery dataset. However, I remember I've seen somewhere that Google Cloud has some tool that can do basically the same without too much development needed. I'm so confused with all these Google Cloud services names for data analytics and engineering.", "author_fullname": "t2_7chglbbu", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What is the Google Cloud tool alternative to Fivetran?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16xzqni", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696260739.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, currently we are using Fivetran to get our Hubspot data and put it into a Fivetran managed BigQuery dataset. However, I remember I&amp;#39;ve seen somewhere that Google Cloud has some tool that can do basically the same without too much development needed. I&amp;#39;m so confused with all these Google Cloud services names for data analytics and engineering.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "16xzqni", "is_robot_indexable": true, "report_reasons": null, "author": "Computingss", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xzqni/what_is_the_google_cloud_tool_alternative_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xzqni/what_is_the_google_cloud_tool_alternative_to/", "subreddit_subscribers": 131649, "created_utc": 1696260739.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_hdte75ow1", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Goodbye Spark. Hello Polars + Delta Lake.", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_16xzcqx", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uoju8UTP0tZAIdqZc3iW3ef3oNtUOsvWrwPRLKKEcso.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696259823.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "dataengineeringcentral.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://dataengineeringcentral.substack.com/p/goodbye-spark-hello-polars-delta", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?auto=webp&amp;s=e585ee336c489e1e9d450ed5159b115f114faf2a", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=e5c6d53daaae3bdf1918e25f3f0270fc6dc7f597", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=aa672a15ff78edbc9baca55c9808ad1f74530570", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=754d2c0745079122b89f58f096f81dd3529333b2", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=233e82aa2321f7d05735593d9a37da1064b50bc0", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=91e26d7ce3a240db9569e53c0674a9b3db878065", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/8bn5fKYCKOZmmY4iCQy1Iva_CHlYcdIAXfm7TeL4H8Y.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=69f818883fada4b287989c118a7cd66802bf6540", "width": 1080, "height": 540}], "variants": {}, "id": "PURvM--d-7MgOYB6-qnYgEtr-OWAeVREK0gXETFQvXQ"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xzcqx", "is_robot_indexable": true, "report_reasons": null, "author": "dataengineeringdude", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xzcqx/goodbye_spark_hello_polars_delta_lake/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://dataengineeringcentral.substack.com/p/goodbye-spark-hello-polars-delta", "subreddit_subscribers": 131649, "created_utc": 1696259823.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working at a company that is trying to make a push for I4.0. Whether or not you think thats a buzzword, there are tons of companies making the push towards smart manufacturing. My question, is it worth it?\n\nMaybe it is only because we are new to it and I'm not seeing the full benefits but cost of collection (sensors, PLCs, etc) is often expensive. If you want production data to be captured constantly (good counts, scrap counts, etc.) you need redundant networking/power.\n\nMoving data to the cloud is unbelievably expensive at this volume and SCADAs/Historians are equally expensive. The hardware requires highly skilled employees to set up and maintain the system.\n\nAll this for managerial metrics and the ability to root cause faster? Maybe if you're good enough get some predictive maintenance?\n\nTo the others in the industry, is this all worth it? Have you seen the value add at your own job?", "author_fullname": "t2_f0vap1y", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "To those that work in manufacturing, do you believe IoT (and heavy collection of manufacturing data) is a fad?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16xyt26", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.8, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696258506.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working at a company that is trying to make a push for I4.0. Whether or not you think thats a buzzword, there are tons of companies making the push towards smart manufacturing. My question, is it worth it?&lt;/p&gt;\n\n&lt;p&gt;Maybe it is only because we are new to it and I&amp;#39;m not seeing the full benefits but cost of collection (sensors, PLCs, etc) is often expensive. If you want production data to be captured constantly (good counts, scrap counts, etc.) you need redundant networking/power.&lt;/p&gt;\n\n&lt;p&gt;Moving data to the cloud is unbelievably expensive at this volume and SCADAs/Historians are equally expensive. The hardware requires highly skilled employees to set up and maintain the system.&lt;/p&gt;\n\n&lt;p&gt;All this for managerial metrics and the ability to root cause faster? Maybe if you&amp;#39;re good enough get some predictive maintenance?&lt;/p&gt;\n\n&lt;p&gt;To the others in the industry, is this all worth it? Have you seen the value add at your own job?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xyt26", "is_robot_indexable": true, "report_reasons": null, "author": "Reddit_Account_C-137", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xyt26/to_those_that_work_in_manufacturing_do_you/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xyt26/to_those_that_work_in_manufacturing_do_you/", "subreddit_subscribers": 131649, "created_utc": 1696258506.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_90mri5a8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "The Economics of a Data Mesh", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 70, "top_awarded_type": null, "hide_score": true, "name": "t3_16xylzj", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/asYHsIY2kWUJFwtiE2r846XwB1kMey6DWhbL0qhH6RU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696258006.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "open.substack.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://open.substack.com/pub/hubertdulay/p/the-economics-of-a-data-mesh?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?auto=webp&amp;s=7c34009cf87a9174cefcac1ea03e4e8915ebe8ec", "width": 1200, "height": 600}, "resolutions": [{"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=f32b9a9cd7b57620422d8eda54ea146ef1886234", "width": 108, "height": 54}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=44dd3db79dcc5c718e4c70adedbd3fd157d6c9ed", "width": 216, "height": 108}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=977ed1c2fd28853d7d2cd2955ad926ae1c141923", "width": 320, "height": 160}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c04e0b8d6ca89d0628ba471d9e580492926f8957", "width": 640, "height": 320}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ddb0864bca29658a528df99596a5cf9a251a1efd", "width": 960, "height": 480}, {"url": "https://external-preview.redd.it/7XfgEcuDydnUKT-IAgTAhJmRgPkLmqnlp4g6z2X5NO0.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=8ff2c7a04498f0549c3bf53b29cc99e9078e8295", "width": 1080, "height": 540}], "variants": {}, "id": "NcNSsLXEhXs6fOgmhbwaZYHPgD_-CjFwtLmWBLgasOU"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "16xylzj", "is_robot_indexable": true, "report_reasons": null, "author": "hkdelay", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xylzj/the_economics_of_a_data_mesh/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://open.substack.com/pub/hubertdulay/p/the-economics-of-a-data-mesh?r=46sqk&amp;utm_campaign=post&amp;utm_medium=web", "subreddit_subscribers": 131649, "created_utc": 1696258006.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi there! I'm reading some documentation about Databricks and how to optimize the table sizes. I've found that the default (and sometimes recommended) value of individual files when using OPTIMIZE is 1 GB (and I understand the rationale for this file size) but then found out that there is another feature called AUTO OPTIMIZE that will set the file size at 128 MB in order to *accelerate write-intensive operations (as mentioned in* [here](https://docs.databricks.com/en/delta/tune-file-size.html#autotune-workload)). \n\nI'm a little bit confused about why having smaller files would be good for write operations (I'm guessing it may have something to do with parallelization, but not sure), and also confirm that (if I understood correctly) we want large files for improving reads on tables but small files for improving writes.\n\nCould anyone shed some light on this questions?\n\n ", "author_fullname": "t2_zn4k7", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "1 GB (OPTIMIZE) vs 128 MB (AUTO OPTIMIZE) file size in Databricks", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_16xyl6t", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696257954.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there! I&amp;#39;m reading some documentation about Databricks and how to optimize the table sizes. I&amp;#39;ve found that the default (and sometimes recommended) value of individual files when using OPTIMIZE is 1 GB (and I understand the rationale for this file size) but then found out that there is another feature called AUTO OPTIMIZE that will set the file size at 128 MB in order to &lt;em&gt;accelerate write-intensive operations (as mentioned in&lt;/em&gt; &lt;a href=\"https://docs.databricks.com/en/delta/tune-file-size.html#autotune-workload\"&gt;here&lt;/a&gt;). &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m a little bit confused about why having smaller files would be good for write operations (I&amp;#39;m guessing it may have something to do with parallelization, but not sure), and also confirm that (if I understood correctly) we want large files for improving reads on tables but small files for improving writes.&lt;/p&gt;\n\n&lt;p&gt;Could anyone shed some light on this questions?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?auto=webp&amp;s=9dd59568b8579947f05ce66ee028655ef14e64d6", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=99613d282007d0bcc41947bc7f0846da94adca04", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=400ef45c57444e53fb95c1358e9a0b6419c3112e", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6ed83d9a6c1afb35b8be4de3f85b722298d1c3d6", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=768e111879e31b88e5a61b81d8d367edaa5e5351", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=c2a359111feb6e4d3ffa529f6614614a63914c4e", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/weHg2vXuXJrvIzt7BevX9in3FR2J78iQjABoSHU6aQ4.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=f6e5d40f18830851f93eb2158f465da573a5df80", "width": 1080, "height": 567}], "variants": {}, "id": "RDPFo3n-9ZSpTUT0k9sCNnHc7tSD0wBu2TyDFfITIDs"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "16xyl6t", "is_robot_indexable": true, "report_reasons": null, "author": "DUM00", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xyl6t/1_gb_optimize_vs_128_mb_auto_optimize_file_size/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xyl6t/1_gb_optimize_vs_128_mb_auto_optimize_file_size/", "subreddit_subscribers": 131649, "created_utc": 1696257954.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I know for sql there is data lemur, leetcode, hacker rank but for big data , visualisation etc where to prepare that? Should I use chat gpt ? Is it a good idea", "author_fullname": "t2_8d8kaiqq", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What are some resources for interview preparation?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_16xx761", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Interview", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696254694.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I know for sql there is data lemur, leetcode, hacker rank but for big data , visualisation etc where to prepare that? Should I use chat gpt ? Is it a good idea&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "0922f6d6-a952-11eb-91e4-0e23043eebfb", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ffb000", "id": "16xx761", "is_robot_indexable": true, "report_reasons": null, "author": "lemmeguessindian", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/16xx761/what_are_some_resources_for_interview_preparation/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/16xx761/what_are_some_resources_for_interview_preparation/", "subreddit_subscribers": 131649, "created_utc": 1696254694.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}