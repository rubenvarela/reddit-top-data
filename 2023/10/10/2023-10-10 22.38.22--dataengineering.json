{"kind": "Listing", "data": {"after": "t3_174jlsf", "dist": 25, "modhash": "", "geo_filter": "", "children": [{"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have been etl developer for 15 years(SSIS) and it is time to update skills, I think.\nSearching for suggestions, how can I move to data engineering? Should I just apply to entry position? Market is so bad \ud83d\ude1e.", "author_fullname": "t2_bfrtvbx9o", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Data engineer from ETL developer", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174aeb1", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.93, "author_flair_background_color": null, "subreddit_type": "public", "ups": 22, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 22, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696905373.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have been etl developer for 15 years(SSIS) and it is time to update skills, I think.\nSearching for suggestions, how can I move to data engineering? Should I just apply to entry position? Market is so bad \ud83d\ude1e.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "174aeb1", "is_robot_indexable": true, "report_reasons": null, "author": "Charming_Function_35", "discussion_type": null, "num_comments": 23, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174aeb1/data_engineer_from_etl_developer/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174aeb1/data_engineer_from_etl_developer/", "subreddit_subscribers": 133102, "created_utc": 1696905373.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " \n\nHi there \n\nI\u2019m trying to understand the real reason for using Airflow + DBT, if the first one can connect directly to the database and apply all necessary transformations by using Operators (Postgres, Redshift, etc).  \n \n\nIs DBT just adding more complexity to the project, or can it be helpful in other ways that I cannot find out?", "author_fullname": "t2_iweexjfw", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Airflow + DBT - question", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_17481kb", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.87, "author_flair_background_color": null, "subreddit_type": "public", "ups": 16, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 16, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696898583.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi there &lt;/p&gt;\n\n&lt;p&gt;I\u2019m trying to understand the real reason for using Airflow + DBT, if the first one can connect directly to the database and apply all necessary transformations by using Operators (Postgres, Redshift, etc).  &lt;/p&gt;\n\n&lt;p&gt;Is DBT just adding more complexity to the project, or can it be helpful in other ways that I cannot find out?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "17481kb", "is_robot_indexable": true, "report_reasons": null, "author": "yeager_doug", "discussion_type": null, "num_comments": 15, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/17481kb/airflow_dbt_question/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/17481kb/airflow_dbt_question/", "subreddit_subscribers": 133102, "created_utc": 1696898583.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you'd start a career in data engineering  in 2023 ,\n\n&amp; you've exp in python sql  , \n\nwould you pursue learning ssis or choose cloud technology ? \n\nThank you ", "author_fullname": "t2_t3nz93za", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On Premises Vs Cloud", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174jezy", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.83, "author_flair_background_color": null, "subreddit_type": "public", "ups": 15, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 15, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696939266.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you&amp;#39;d start a career in data engineering  in 2023 ,&lt;/p&gt;\n\n&lt;p&gt;&amp;amp; you&amp;#39;ve exp in python sql  , &lt;/p&gt;\n\n&lt;p&gt;would you pursue learning ssis or choose cloud technology ? &lt;/p&gt;\n\n&lt;p&gt;Thank you &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174jezy", "is_robot_indexable": true, "report_reasons": null, "author": "Repulsive-Ad7769", "discussion_type": null, "num_comments": 42, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174jezy/on_premises_vs_cloud/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174jezy/on_premises_vs_cloud/", "subreddit_subscribers": 133102, "created_utc": 1696939266.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6vz2k", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "[Help] Tried highlighting what Databricks does \"in-house\" for a project. Is this accurate?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 140, "top_awarded_type": null, "hide_score": false, "name": "t3_174j9ov", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.69, "author_flair_background_color": null, "ups": 7, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": true, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 7, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/q3Q6PeLx4nf2CkBUckenFrp8x3M87-n6tWdw4vsV20M.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "image", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696938786.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "i.redd.it", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://i.redd.it/dqmlofum5dtb1.png", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://preview.redd.it/dqmlofum5dtb1.png?auto=webp&amp;s=934d980ca188a1b4bf1a6c5a211557f9b454fc6e", "width": 2264, "height": 2323}, "resolutions": [{"url": "https://preview.redd.it/dqmlofum5dtb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=f3435cde6ec91dfa9ca9f535eaf0a228bc0b461b", "width": 108, "height": 110}, {"url": "https://preview.redd.it/dqmlofum5dtb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=0cd06c19a55477daca085fa59cd60b8ce2189463", "width": 216, "height": 221}, {"url": "https://preview.redd.it/dqmlofum5dtb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=a7cf468576834af1e6abfe22f983baf6c0683803", "width": 320, "height": 328}, {"url": "https://preview.redd.it/dqmlofum5dtb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=5f780866b1d8438d2d36ea255b01eef82974c2e6", "width": 640, "height": 656}, {"url": "https://preview.redd.it/dqmlofum5dtb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=816f4f3aee433d66db633a010df2efe0a00a3ba1", "width": 960, "height": 985}, {"url": "https://preview.redd.it/dqmlofum5dtb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=16fa3fcde7e1fddbff3687503e7403c027f6a376", "width": 1080, "height": 1108}], "variants": {}, "id": "1XiupRIo73tDBkiQdN0J0Hw0qRuljcK-TfvELTnl8Bo"}], "enabled": true}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174j9ov", "is_robot_indexable": true, "report_reasons": null, "author": "boulking", "discussion_type": null, "num_comments": 13, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174j9ov/help_tried_highlighting_what_databricks_does/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://i.redd.it/dqmlofum5dtb1.png", "subreddit_subscribers": 133102, "created_utc": 1696938786.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I work at a consultancy but I've been thinking recently that a lot of SME requirements can really be handled by a solo developer and don't need a whole team or business behind them. \n\nThe biggest obstacles I see are client acquisition and also that a client may not be comfortable hiring a one man team. \n\nDoes anyone have any experience striking out as a solo? I'd love to hear any stories. Or if anyone knows of anything online where someone has documented their own journey.\n\nEven if you haven't done it yourself it'd be interesting to hear your general thoughts on the prospect.", "author_fullname": "t2_6o5du", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Anybody here started a solo consultancy (or can share a good resource for it)?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174irny", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.79, "author_flair_background_color": null, "subreddit_type": "public", "ups": 8, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 8, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696937086.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I work at a consultancy but I&amp;#39;ve been thinking recently that a lot of SME requirements can really be handled by a solo developer and don&amp;#39;t need a whole team or business behind them. &lt;/p&gt;\n\n&lt;p&gt;The biggest obstacles I see are client acquisition and also that a client may not be comfortable hiring a one man team. &lt;/p&gt;\n\n&lt;p&gt;Does anyone have any experience striking out as a solo? I&amp;#39;d love to hear any stories. Or if anyone knows of anything online where someone has documented their own journey.&lt;/p&gt;\n\n&lt;p&gt;Even if you haven&amp;#39;t done it yourself it&amp;#39;d be interesting to hear your general thoughts on the prospect.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "174irny", "is_robot_indexable": true, "report_reasons": null, "author": "Cypher211", "discussion_type": null, "num_comments": 12, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174irny/anybody_here_started_a_solo_consultancy_or_can/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174irny/anybody_here_started_a_solo_consultancy_or_can/", "subreddit_subscribers": 133102, "created_utc": 1696937086.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I have a data stored in a bronze delta that I need to further process. It is only about 2 billion rows and is 20gb of data read from storage. The problem, I think, in short is that the data is highly compressed and while unserialized, my cluster / its settings is not prepared for it and breakdown ensues.\n\nMy first DAG step, mapping partition blocks to RDD, takes an enormously long time (hours). The data is split on my executors in a fairly balanced form, where each gets roughly 1.1 gb of data while my shuffle write is tiny ranging from bytes to kb.\n\nThe only knob I know to turn to alter the input stage is this: spark.sql.files.maxPartitionBytes but it does not help. With a small value, Spark will blow through the first n-thousands but will grind on the last 50-ish blocks of data.\n\nRepartitioning or coalescing is only an option after my first DAG step. Running OPTIMIZE fails; I get OOM on my executors and I have tried these operations on many configs / cluster sizes.", "author_fullname": "t2_u4zm4", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "PySpark - How to break up extremely compressed data?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174c1zs", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.81, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696910635.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I have a data stored in a bronze delta that I need to further process. It is only about 2 billion rows and is 20gb of data read from storage. The problem, I think, in short is that the data is highly compressed and while unserialized, my cluster / its settings is not prepared for it and breakdown ensues.&lt;/p&gt;\n\n&lt;p&gt;My first DAG step, mapping partition blocks to RDD, takes an enormously long time (hours). The data is split on my executors in a fairly balanced form, where each gets roughly 1.1 gb of data while my shuffle write is tiny ranging from bytes to kb.&lt;/p&gt;\n\n&lt;p&gt;The only knob I know to turn to alter the input stage is this: spark.sql.files.maxPartitionBytes but it does not help. With a small value, Spark will blow through the first n-thousands but will grind on the last 50-ish blocks of data.&lt;/p&gt;\n\n&lt;p&gt;Repartitioning or coalescing is only an option after my first DAG step. Running OPTIMIZE fails; I get OOM on my executors and I have tried these operations on many configs / cluster sizes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174c1zs", "is_robot_indexable": true, "report_reasons": null, "author": "JohnStud85", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174c1zs/pyspark_how_to_break_up_extremely_compressed_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174c1zs/pyspark_how_to_break_up_extremely_compressed_data/", "subreddit_subscribers": 133102, "created_utc": 1696910635.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_vk94wnpj", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "What\u2019s the difference between Databricks\u2019s Overwatch and System Tables tools?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 93, "top_awarded_type": null, "hide_score": false, "name": "t3_174j9fg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/7H7guNkrLzYUixs3AR3Psyd23HlFvAUyaDvJr6r1KQs.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696938761.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "blog.det.life", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://blog.det.life/whats-the-difference-between-databricks-s-overwatch-and-system-tables-tools-f9d0cd75a2f2", "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?auto=webp&amp;s=cdf604b54fe85e5e161f564bad80873c3b0b2d73", "width": 1200, "height": 800}, "resolutions": [{"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=495021a9846e755e37ba06d7fb7b00bdd919d5af", "width": 108, "height": 72}, {"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=74fc4c3c060466a5374a28a66f96c5e3a1efaa3e", "width": 216, "height": 144}, {"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=f2f1a08b5cf74574326b34e55fcaa8a7192d42f2", "width": 320, "height": 213}, {"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=60ae1eaf20860d2e12e3860d79789872c68c554f", "width": 640, "height": 426}, {"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=8619f09a42879ea79dc90050268fbd11970bf2a0", "width": 960, "height": 640}, {"url": "https://external-preview.redd.it/Nw9t-SE-cYa0esSiNqnHZrCn0-HY9eMK0EjI3OZp_rM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=dfe55cdcb6fd4feaba16b6a4a3591f9e94b9c621", "width": 1080, "height": 720}], "variants": {}, "id": "XTYuj6I-Q2v_xqeIXOzOgfp785bB9G0Zkdojd7TtV_w"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "174j9fg", "is_robot_indexable": true, "report_reasons": null, "author": "sync_jeff", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174j9fg/whats_the_difference_between_databrickss/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://blog.det.life/whats-the-difference-between-databricks-s-overwatch-and-system-tables-tools-f9d0cd75a2f2", "subreddit_subscribers": 133102, "created_utc": 1696938761.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello. I work in a two man team for a government organization as an all purpose data engineer. Meaning we set up and maintain all data pipelines, the databases, the data reports and do machine learning projects when we have time. The methodology for the last three years, (yes the organization just started to think about data three years ago), has been a low hanging fruit methodology, meaning we start a project, create some value from it, publish it and move on. \n\nNeedless to say that has left a lot of quality control neglected. Name giving is inconsistent, data owners and users are often unknown and some quick fix sh\\*t solutions are still being used like windows scheduler to run some codes. There is hardly any documentation about our data infrastructure to add. \n\nNow I don't think any one is to blame for this as this is a government organization on a budget and the two of us are head over heels in projects but the time has come to tighten loose ends. My question is, has anyone experienced a similar scenario and solved it? How did you solve it? Is there any good literature on the subject or other resources? \n\nFYI we are using Microsoft solutions like Azure and power platform for 90% of what we do. We are also a REIT and construction management type of organization if that is relevant.\n\nThanks a lot in advance for all responses.", "author_fullname": "t2_6j5e93w9", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Organizational documentation for data infrastructure", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174hlpp", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.88, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696932690.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello. I work in a two man team for a government organization as an all purpose data engineer. Meaning we set up and maintain all data pipelines, the databases, the data reports and do machine learning projects when we have time. The methodology for the last three years, (yes the organization just started to think about data three years ago), has been a low hanging fruit methodology, meaning we start a project, create some value from it, publish it and move on. &lt;/p&gt;\n\n&lt;p&gt;Needless to say that has left a lot of quality control neglected. Name giving is inconsistent, data owners and users are often unknown and some quick fix sh*t solutions are still being used like windows scheduler to run some codes. There is hardly any documentation about our data infrastructure to add. &lt;/p&gt;\n\n&lt;p&gt;Now I don&amp;#39;t think any one is to blame for this as this is a government organization on a budget and the two of us are head over heels in projects but the time has come to tighten loose ends. My question is, has anyone experienced a similar scenario and solved it? How did you solve it? Is there any good literature on the subject or other resources? &lt;/p&gt;\n\n&lt;p&gt;FYI we are using Microsoft solutions like Azure and power platform for 90% of what we do. We are also a REIT and construction management type of organization if that is relevant.&lt;/p&gt;\n\n&lt;p&gt;Thanks a lot in advance for all responses.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "174hlpp", "is_robot_indexable": true, "report_reasons": null, "author": "arachnarus96", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174hlpp/organizational_documentation_for_data/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174hlpp/organizational_documentation_for_data/", "subreddit_subscribers": 133102, "created_utc": 1696932690.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi. I\u2019m a data analyst based in UK with 4 years experience. I saw an ad for a \u201cData Analyst / Data Engineering\u201d position for a huge company (with 1 day a week university training), and I decided to apply.\nTurned out after the interview and briefing, the position was \u201cAnalytics Engineering\u201d\u2026 I had to Google that\u2026\n\nThe thing is I\u2019ve passed the second round interview and assignment using ChatGPT and previous knowledge to connect dots, however I\u2019m way more skilled as a Data Analyst than an Engineer. I\u2019d honestly struggle to describe what I built for the assignment without notes.\n\nSo naturally, I\u2019m still not 100% sure if Analytics Engineering is right for me although the company and programme looks great. I get the feeling every Analytics Engineering job mightn\u2019t be an equal split.\n\nIs this a role that\u2019s more suited to someone with solely Data Engineer or Data Analytics experience?\n\nTLDR: ended up interviewing as an Analytics engineering. Is my data analyst experience good enough?", "author_fullname": "t2_shaidtoo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Is an Analytics Engineering position possible to pivot from Data Analyst?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174g2q6", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.71, "author_flair_background_color": null, "subreddit_type": "public", "ups": 6, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 6, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696926815.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696926514.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi. I\u2019m a data analyst based in UK with 4 years experience. I saw an ad for a \u201cData Analyst / Data Engineering\u201d position for a huge company (with 1 day a week university training), and I decided to apply.\nTurned out after the interview and briefing, the position was \u201cAnalytics Engineering\u201d\u2026 I had to Google that\u2026&lt;/p&gt;\n\n&lt;p&gt;The thing is I\u2019ve passed the second round interview and assignment using ChatGPT and previous knowledge to connect dots, however I\u2019m way more skilled as a Data Analyst than an Engineer. I\u2019d honestly struggle to describe what I built for the assignment without notes.&lt;/p&gt;\n\n&lt;p&gt;So naturally, I\u2019m still not 100% sure if Analytics Engineering is right for me although the company and programme looks great. I get the feeling every Analytics Engineering job mightn\u2019t be an equal split.&lt;/p&gt;\n\n&lt;p&gt;Is this a role that\u2019s more suited to someone with solely Data Engineer or Data Analytics experience?&lt;/p&gt;\n\n&lt;p&gt;TLDR: ended up interviewing as an Analytics engineering. Is my data analyst experience good enough?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "174g2q6", "is_robot_indexable": true, "report_reasons": null, "author": "Noot-Noot-456", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174g2q6/is_an_analytics_engineering_position_possible_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174g2q6/is_an_analytics_engineering_position_possible_to/", "subreddit_subscribers": 133102, "created_utc": 1696926514.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hello all, and TIA! I'm a data engineer in a somewhat restrictive environment- we're all baremetal at my shop, and the *only* pipelines we've run are using boutique code I've had to create, manage, and supervise. It's an extremely nonstandard environment- we're 100% locked down to our intranet- no pip/apt/yum install etc. We have a single RDBMS for a warehouse and my single server to process on.\n\nI see this as a huge detriment to my career long term. I'm still working on a degree, as is my wife- so I don't have enough time to play around on my own time and stay up to speed on the modern data stack. I therefore have absolutely 0 professional cloud experience.\n\nHowever, an internal transfer position has opened as a cloud engineer. This would give me a broader skillset. Is there any reason I shouldn't jump on it? I do intend, in the long run, to move back to data engineering with the broader experience gained. I'm also 1 year from finishing my degree and my wife is 1.5 from finishing her doctorate, so I'll have more time to play with things on my own time. Is there any angle I'm not considering here? Would this be a bad move for any reason? For argument's sake, assume no salary or working condition changes.", "author_fullname": "t2_sa00zipn", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benefit to holding adjacent positions", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174p2q9", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.75, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696954376.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello all, and TIA! I&amp;#39;m a data engineer in a somewhat restrictive environment- we&amp;#39;re all baremetal at my shop, and the &lt;em&gt;only&lt;/em&gt; pipelines we&amp;#39;ve run are using boutique code I&amp;#39;ve had to create, manage, and supervise. It&amp;#39;s an extremely nonstandard environment- we&amp;#39;re 100% locked down to our intranet- no pip/apt/yum install etc. We have a single RDBMS for a warehouse and my single server to process on.&lt;/p&gt;\n\n&lt;p&gt;I see this as a huge detriment to my career long term. I&amp;#39;m still working on a degree, as is my wife- so I don&amp;#39;t have enough time to play around on my own time and stay up to speed on the modern data stack. I therefore have absolutely 0 professional cloud experience.&lt;/p&gt;\n\n&lt;p&gt;However, an internal transfer position has opened as a cloud engineer. This would give me a broader skillset. Is there any reason I shouldn&amp;#39;t jump on it? I do intend, in the long run, to move back to data engineering with the broader experience gained. I&amp;#39;m also 1 year from finishing my degree and my wife is 1.5 from finishing her doctorate, so I&amp;#39;ll have more time to play with things on my own time. Is there any angle I&amp;#39;m not considering here? Would this be a bad move for any reason? For argument&amp;#39;s sake, assume no salary or working condition changes.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "174p2q9", "is_robot_indexable": true, "report_reasons": null, "author": "dillan_pickle", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174p2q9/benefit_to_holding_adjacent_positions/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174p2q9/benefit_to_holding_adjacent_positions/", "subreddit_subscribers": 133102, "created_utc": 1696954376.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone. I have a case of eCommerce data where the transactional database has `orders` and `products`. I'm confused as to how to model this in a star schema.\n\nMy thoughts are that the `orders` should be a fact table (`fct_orders`) containing an aggregate of `products` total value, ie `fct_orders.total_order_value`. However, if an order has multiple products, what would the foreign key look like in `fct_orders`?\n\nI've tried searching online for answers and have read that what defines a fact and dimension table is the one-to-many relationships; there would only be a 1:N relationship between a dimension and fact table, not the other way around - which would make my `products` table the fact table. However, how can I model the aggregate `fct_orders.total_order_value`?\n\nThanks in advance!\n\n&amp;#x200B;\n\nEdit: just learned about bridge tables ([https://www.leapfrogbi.com/bridge-tables/](https://www.leapfrogbi.com/bridge-tables/)), would this be an appropriate use case of this? It feels like extra compute overhead on the deserialisation and compute though...", "author_fullname": "t2_9trbw25s", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to model one fact table that joins to multiple rows in dimension table?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174avck", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.84, "author_flair_background_color": null, "subreddit_type": "public", "ups": 4, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 4, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": 1696908569.0, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696906843.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone. I have a case of eCommerce data where the transactional database has &lt;code&gt;orders&lt;/code&gt; and &lt;code&gt;products&lt;/code&gt;. I&amp;#39;m confused as to how to model this in a star schema.&lt;/p&gt;\n\n&lt;p&gt;My thoughts are that the &lt;code&gt;orders&lt;/code&gt; should be a fact table (&lt;code&gt;fct_orders&lt;/code&gt;) containing an aggregate of &lt;code&gt;products&lt;/code&gt; total value, ie &lt;code&gt;fct_orders.total_order_value&lt;/code&gt;. However, if an order has multiple products, what would the foreign key look like in &lt;code&gt;fct_orders&lt;/code&gt;?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;ve tried searching online for answers and have read that what defines a fact and dimension table is the one-to-many relationships; there would only be a 1:N relationship between a dimension and fact table, not the other way around - which would make my &lt;code&gt;products&lt;/code&gt; table the fact table. However, how can I model the aggregate &lt;code&gt;fct_orders.total_order_value&lt;/code&gt;?&lt;/p&gt;\n\n&lt;p&gt;Thanks in advance!&lt;/p&gt;\n\n&lt;p&gt;&amp;#x200B;&lt;/p&gt;\n\n&lt;p&gt;Edit: just learned about bridge tables (&lt;a href=\"https://www.leapfrogbi.com/bridge-tables/\"&gt;https://www.leapfrogbi.com/bridge-tables/&lt;/a&gt;), would this be an appropriate use case of this? It feels like extra compute overhead on the deserialisation and compute though...&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/M5E3roN5E1_WPpGThJnBk5bFrVOpMN0ED6ABAtD5x5s.jpg?auto=webp&amp;s=736d9650919a08025a3b529a262d040d5eccc7c4", "width": 508, "height": 553}, "resolutions": [{"url": "https://external-preview.redd.it/M5E3roN5E1_WPpGThJnBk5bFrVOpMN0ED6ABAtD5x5s.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=709171c289f304a1417184d7d2ebada30a823909", "width": 108, "height": 117}, {"url": "https://external-preview.redd.it/M5E3roN5E1_WPpGThJnBk5bFrVOpMN0ED6ABAtD5x5s.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=c77e4d74b3cfefe997d1d3a271f7c82a6eaa5c5d", "width": 216, "height": 235}, {"url": "https://external-preview.redd.it/M5E3roN5E1_WPpGThJnBk5bFrVOpMN0ED6ABAtD5x5s.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=6d6b309475f6fb91e4e9b925f4e3d75edb053c17", "width": 320, "height": 348}], "variants": {}, "id": "bIfqiV67OXElDsn2F_5SezvPv1apC5LPOp1agLPkfo4"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174avck", "is_robot_indexable": true, "report_reasons": null, "author": "ternary-thought", "discussion_type": null, "num_comments": 9, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174avck/how_to_model_one_fact_table_that_joins_to/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174avck/how_to_model_one_fact_table_that_joins_to/", "subreddit_subscribers": 133102, "created_utc": 1696906843.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "[PeerDB's](https://peerdb.io/) founding engineer Kevin provides a detailed analysis on benchmarks comparing PeerDB with AirByte. The benchmark involves syncing a large table (\\~1.5TB) from Postgres to Snowflake. Results show that PeerDB can be\u00a02x-16x faster\u00a0than AirByte. He digs deep into\u00a0how\u00a0PeerDB is able to achieve this performance.  \n[https://blog.peerdb.io/benchmarking-postgres-replication-peerdb-vs-airbyte](https://blog.peerdb.io/benchmarking-postgres-replication-peerdb-vs-airbyte)", "author_fullname": "t2_simedz82", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Benchmarking Postgres Replication: PeerDB vs Airbyte", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174t7j8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696964716.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://peerdb.io/\"&gt;PeerDB&amp;#39;s&lt;/a&gt; founding engineer Kevin provides a detailed analysis on benchmarks comparing PeerDB with AirByte. The benchmark involves syncing a large table (~1.5TB) from Postgres to Snowflake. Results show that PeerDB can be\u00a02x-16x faster\u00a0than AirByte. He digs deep into\u00a0how\u00a0PeerDB is able to achieve this performance.&lt;br/&gt;\n&lt;a href=\"https://blog.peerdb.io/benchmarking-postgres-replication-peerdb-vs-airbyte\"&gt;https://blog.peerdb.io/benchmarking-postgres-replication-peerdb-vs-airbyte&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "174t7j8", "is_robot_indexable": true, "report_reasons": null, "author": "saipeerdb", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174t7j8/benchmarking_postgres_replication_peerdb_vs/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174t7j8/benchmarking_postgres_replication_peerdb_vs/", "subreddit_subscribers": 133102, "created_utc": 1696964716.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "If you are interested in massive data processing, [this case](https://doris.apache.org/zh-CN/blog/Log-Analysis-How-to-Digest-15-Billion-Logs-Per-Day-and-Keep-Big-Queries-Within-1-Second) might help.\n\nhttps://preview.redd.it/cbo62wez7dtb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=bfddfc33093973663168acaa2faec12eacf0f460", "author_fullname": "t2_no0j2ndo", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Log Analysis: How to Digest 15 Billion Logs Per Day and Keep Big Queries Within 1 Second", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 66, "top_awarded_type": null, "hide_score": false, "media_metadata": {"cbo62wez7dtb1": {"status": "valid", "e": "Image", "m": "image/png", "p": [{"y": 51, "x": 108, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=108&amp;crop=smart&amp;auto=webp&amp;s=0a5caa4edbd79f9685695161cdef806fde66dcf1"}, {"y": 102, "x": 216, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=216&amp;crop=smart&amp;auto=webp&amp;s=57bd4f7571a2e26560df0d73593faadb8719ce72"}, {"y": 152, "x": 320, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=320&amp;crop=smart&amp;auto=webp&amp;s=39755c160045c001c5e73a094aa359423c6b977b"}, {"y": 304, "x": 640, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=640&amp;crop=smart&amp;auto=webp&amp;s=afe1f4773ac6e4a30eef23670a47ba7aa01ccf1a"}, {"y": 456, "x": 960, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=960&amp;crop=smart&amp;auto=webp&amp;s=0bb433e300b8c0ca107dfdc6c5950f37b3b1d24b"}, {"y": 513, "x": 1080, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=1080&amp;crop=smart&amp;auto=webp&amp;s=c5d59d668997a10e02f0d0e92ce0fb0abbbb75de"}], "s": {"y": 609, "x": 1280, "u": "https://preview.redd.it/cbo62wez7dtb1.png?width=1280&amp;format=png&amp;auto=webp&amp;s=bfddfc33093973663168acaa2faec12eacf0f460"}, "id": "cbo62wez7dtb1"}}, "name": "t3_174jidr", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 3, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 3, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/Kie1SniWpE6PDH5ujmco-oEtxQ7mTnSn37C3nGuPrIk.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696939550.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;If you are interested in massive data processing, &lt;a href=\"https://doris.apache.org/zh-CN/blog/Log-Analysis-How-to-Digest-15-Billion-Logs-Per-Day-and-Keep-Big-Queries-Within-1-Second\"&gt;this case&lt;/a&gt; might help.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://preview.redd.it/cbo62wez7dtb1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bfddfc33093973663168acaa2faec12eacf0f460\"&gt;https://preview.redd.it/cbo62wez7dtb1.png?width=1280&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=bfddfc33093973663168acaa2faec12eacf0f460&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "174jidr", "is_robot_indexable": true, "report_reasons": null, "author": "ApacheDoris", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174jidr/log_analysis_how_to_digest_15_billion_logs_per/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174jidr/log_analysis_how_to_digest_15_billion_logs_per/", "subreddit_subscribers": 133102, "created_utc": 1696939550.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi, my company has about 30GB total on a sharepoint site. I need to get all these files into an Azure storage account.\n\nI was planning on doing this simply with ADF but the catch is that I can't establish the connection due to permissions (no sharepoint linked service).\n\nDoes anyone have a suggestion on how to do this efficiently?\n\nCurrently I'm biting through the pain and downloading everything as zip -&gt; upload zip to storage and unpack using ADF.", "author_fullname": "t2_16t847", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How do I move 30GB from sharepoint to Azure storage?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174mh1z", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696947696.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, my company has about 30GB total on a sharepoint site. I need to get all these files into an Azure storage account.&lt;/p&gt;\n\n&lt;p&gt;I was planning on doing this simply with ADF but the catch is that I can&amp;#39;t establish the connection due to permissions (no sharepoint linked service).&lt;/p&gt;\n\n&lt;p&gt;Does anyone have a suggestion on how to do this efficiently?&lt;/p&gt;\n\n&lt;p&gt;Currently I&amp;#39;m biting through the pain and downloading everything as zip -&amp;gt; upload zip to storage and unpack using ADF.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174mh1z", "is_robot_indexable": true, "report_reasons": null, "author": "drollerfoot7", "discussion_type": null, "num_comments": 4, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174mh1z/how_do_i_move_30gb_from_sharepoint_to_azure/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174mh1z/how_do_i_move_30gb_from_sharepoint_to_azure/", "subreddit_subscribers": 133102, "created_utc": 1696947696.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, I'm a fresher in DA and DE. I was assigned a task to build a user dimension.\n\n**Purpose**: map user between 3 sources (firebase, MAX, appsflyer) in order to create a complete user journey\n\nIdentifiers that can be used in 3 tables: user\\_id (from firebase), idfa, idfv, appsflyer\\_id\n\nI started to analyze how each identifier would change:\n\n* for user\\_id, it will change after re-installs because my app doesn't require any login so the user\\_id is not consistent \n* idfa will change if a user reset OS or turn on limit ad tracking\n* idfv will change if a user switches to new device\n\nWhat I'm struggling is how i can identify a user and develop general logic, given one of real-life scenarios:\n\n* a user can have multiple devices. how can i identify these devices as 1 particular person?\n* if a user re-installs the app (user\\_id changes), how can i identify him/her as old user coming back?\n* what if a user change platform? (from ios to android) how can i identify this user as old one without treating him/her as new one?\n* not all records in 3 tables can be joined with user\\_id, idfa or idfv (separately); sometimes, user\\_id AND idfa; sometimes, idfa only; sometimes, user\\_id and idfv as i tried to figure out how to layer these ids (trying to put things in a nested field)\n* answering and solving above cases (separately) is not too hard but when those 3 happen at the same time. things starts to become too complex and tangled for me to process (it's demoralizing af :((( )\n\nWrong or missed identification will result in wrong analytics, e.g: wrong CLV as $40K revenue for 10K users is different from $40K revenue for 20K users\n\nIs there any aspects or approaches that i should consider to solve this? Thanks in advanced \\^\\^", "author_fullname": "t2_8wrp4ovv", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "How to approach user identification when building user dimension?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174eeqe", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": "transparent", "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": "19bba012-ac9d-11eb-b77b-0eec37c01719", "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696919412.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, I&amp;#39;m a fresher in DA and DE. I was assigned a task to build a user dimension.&lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: map user between 3 sources (firebase, MAX, appsflyer) in order to create a complete user journey&lt;/p&gt;\n\n&lt;p&gt;Identifiers that can be used in 3 tables: user_id (from firebase), idfa, idfv, appsflyer_id&lt;/p&gt;\n\n&lt;p&gt;I started to analyze how each identifier would change:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;for user_id, it will change after re-installs because my app doesn&amp;#39;t require any login so the user_id is not consistent &lt;/li&gt;\n&lt;li&gt;idfa will change if a user reset OS or turn on limit ad tracking&lt;/li&gt;\n&lt;li&gt;idfv will change if a user switches to new device&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What I&amp;#39;m struggling is how i can identify a user and develop general logic, given one of real-life scenarios:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;a user can have multiple devices. how can i identify these devices as 1 particular person?&lt;/li&gt;\n&lt;li&gt;if a user re-installs the app (user_id changes), how can i identify him/her as old user coming back?&lt;/li&gt;\n&lt;li&gt;what if a user change platform? (from ios to android) how can i identify this user as old one without treating him/her as new one?&lt;/li&gt;\n&lt;li&gt;not all records in 3 tables can be joined with user_id, idfa or idfv (separately); sometimes, user_id AND idfa; sometimes, idfa only; sometimes, user_id and idfv as i tried to figure out how to layer these ids (trying to put things in a nested field)&lt;/li&gt;\n&lt;li&gt;answering and solving above cases (separately) is not too hard but when those 3 happen at the same time. things starts to become too complex and tangled for me to process (it&amp;#39;s demoralizing af :((( )&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Wrong or missed identification will result in wrong analytics, e.g: wrong CLV as $40K revenue for 10K users is different from $40K revenue for 20K users&lt;/p&gt;\n\n&lt;p&gt;Is there any aspects or approaches that i should consider to solve this? Thanks in advanced ^^&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": "Data Analyst", "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "174eeqe", "is_robot_indexable": true, "report_reasons": null, "author": "girlsyesboysno", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": "dark", "permalink": "/r/dataengineering/comments/174eeqe/how_to_approach_user_identification_when_building/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174eeqe/how_to_approach_user_identification_when_building/", "subreddit_subscribers": 133102, "created_utc": 1696919412.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi everyone, I recently started a job as a Junior Data Engineer. I have learned a lot so far working with DBT, Snowflake, Looker, Jira workflow, and Git using SQL and Python.\n\nI plan to stay at this company for 2 years. My boss has assured me that if I work hard I will progress from a Junior to full Data Engineer.\n\nMy question is: what other paths could I take after working as a Data Engineer for 2-3 years? What other skills should I learn to enable me to increase my salary?\n\nFrom basic research: Data Management, Senior Data Engineer, Data Scientist, Backend Engineer, Machine Learning Engineer are some potential paths. (I personally am interested in Machine Learning)\n\nJust looking for some advice/suggestions. Thanks!", "author_fullname": "t2_138zju", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Potential Career path", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": true, "name": "t3_174xegg", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 2, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 2, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696975079.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everyone, I recently started a job as a Junior Data Engineer. I have learned a lot so far working with DBT, Snowflake, Looker, Jira workflow, and Git using SQL and Python.&lt;/p&gt;\n\n&lt;p&gt;I plan to stay at this company for 2 years. My boss has assured me that if I work hard I will progress from a Junior to full Data Engineer.&lt;/p&gt;\n\n&lt;p&gt;My question is: what other paths could I take after working as a Data Engineer for 2-3 years? What other skills should I learn to enable me to increase my salary?&lt;/p&gt;\n\n&lt;p&gt;From basic research: Data Management, Senior Data Engineer, Data Scientist, Backend Engineer, Machine Learning Engineer are some potential paths. (I personally am interested in Machine Learning)&lt;/p&gt;\n\n&lt;p&gt;Just looking for some advice/suggestions. Thanks!&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": false, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "174xegg", "is_robot_indexable": true, "report_reasons": null, "author": "SydeFxs", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174xegg/potential_career_path/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174xegg/potential_career_path/", "subreddit_subscribers": 133102, "created_utc": 1696975079.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I'm working in a medium-sized company and due to regulatory reasons must work on-prem for now. \n\nI am setting up a data lake + warehouse solution to support our BI. The data isn't enormous (say 200 million rows across a bunch of SQL sources). \n\nI am considering a lake house type approach using either delta tables or Apache Iceberg tables so that a lot of the work would be reusable and easy to migrate if/when we get to move to Databricks or something. Does this sound reasonable?\n\nWhat I am a bit confused about is setting up the infrastructure for writing data into the deltalake tables. Do I really need to run Spark locally to do that, or am I getting something wrong? In terms of computation Spark seems a bit overkill for our usecase, but I would really like to use delta tables or iceberg for the metadata niceties.", "author_fullname": "t2_7qz9ccwa", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "On-prem setup for a lakehouse", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174qp1c", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696958474.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m working in a medium-sized company and due to regulatory reasons must work on-prem for now. &lt;/p&gt;\n\n&lt;p&gt;I am setting up a data lake + warehouse solution to support our BI. The data isn&amp;#39;t enormous (say 200 million rows across a bunch of SQL sources). &lt;/p&gt;\n\n&lt;p&gt;I am considering a lake house type approach using either delta tables or Apache Iceberg tables so that a lot of the work would be reusable and easy to migrate if/when we get to move to Databricks or something. Does this sound reasonable?&lt;/p&gt;\n\n&lt;p&gt;What I am a bit confused about is setting up the infrastructure for writing data into the deltalake tables. Do I really need to run Spark locally to do that, or am I getting something wrong? In terms of computation Spark seems a bit overkill for our usecase, but I would really like to use delta tables or iceberg for the metadata niceties.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "174qp1c", "is_robot_indexable": true, "report_reasons": null, "author": "s0uha1", "discussion_type": null, "num_comments": 6, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174qp1c/onprem_setup_for_a_lakehouse/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174qp1c/onprem_setup_for_a_lakehouse/", "subreddit_subscribers": 133102, "created_utc": 1696958474.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_w07bcus", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Stream Processing: Is SQL Good Enough?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 87, "top_awarded_type": null, "hide_score": false, "name": "t3_174q5m8", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/m-nviphLFZNePYKXTsZIqh7RxuLz_qDejMO0lLcKA1s.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696957135.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "risingwave.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.risingwave.com/blog/stream-processing-is-sql-good-enough/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/W-kS7-1Y-tErpDg2blzoCby5ZTsaZwoA2S1Xcbg1J5c.jpg?auto=webp&amp;s=2d15e8b6fc572ad9b89fa028fb7a00ed99ce0f47", "width": 1440, "height": 900}, "resolutions": [{"url": "https://external-preview.redd.it/W-kS7-1Y-tErpDg2blzoCby5ZTsaZwoA2S1Xcbg1J5c.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=494a8898f5202805a99993b4b14077eac0bb8b72", "width": 108, "height": 67}, {"url": "https://external-preview.redd.it/W-kS7-1Y-tErpDg2blzoCby5ZTsaZwoA2S1Xcbg1J5c.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=29f19efa2ed0d0f56a7de8b1254f7824575c2322", "width": 216, "height": 135}, {"url": "https://external-preview.redd.it/W-kS7-1Y-tErpDg2blzoCby5ZTsaZwoA2S1Xcbg1J5c.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=8e7b5be7f693257f0ad5226b6efbc28ec8b12a2c", "width": 320, "height": 200}, {"url": "https://external-preview.redd.it/W-kS7-1Y-tErpDg2blzoCby5ZTsaZwoA2S1Xcbg1J5c.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=93dac0110dc5092bd1f6bd2ef577daf9d70ec2a8", "width": 640, "height": 400}, {"url": "https://external-preview.redd.it/W-kS7-1Y-tErpDg2blzoCby5ZTsaZwoA2S1Xcbg1J5c.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=ffeb1d2113257e3d2ce792e0ecc3dc66df5dbd55", "width": 960, "height": 600}, {"url": "https://external-preview.redd.it/W-kS7-1Y-tErpDg2blzoCby5ZTsaZwoA2S1Xcbg1J5c.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=37d9a6a2b232ce4f24150105e59691e8dbc389a3", "width": 1080, "height": 675}], "variants": {}, "id": "7jcvZmk8COUYN3Ur5q1G6apCxmdtIUmVLW3yr7Sltlo"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "174q5m8", "is_robot_indexable": true, "report_reasons": null, "author": "yingjunwu", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174q5m8/stream_processing_is_sql_good_enough/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.risingwave.com/blog/stream-processing-is-sql-good-enough/", "subreddit_subscribers": 133102, "created_utc": 1696957135.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": " Hi all.\n\nBasically I will have multiple files (CSV, XML, etc.) ingested in our database but normally we use pipeline to ingest the file into a staging table and then a stored procedures with a match and merge T-SQL code to normalize the data and after that views that java developers can call. \n\nI want to transform this in more a Data Engineer way using python, airflow etc. I'm SQL Developer but I have some knowledge in python and some data engineer tools.\n\nI would like to know your opinion and what I could do to make this process more modern and use more data engineering tools and not just T-SQL code. If possible using only open-source tools.\n\nTIA.", "author_fullname": "t2_yvtk2r3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Alternative method for a SQL Server T-SQL ETL", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174q4x7", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696957082.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all.&lt;/p&gt;\n\n&lt;p&gt;Basically I will have multiple files (CSV, XML, etc.) ingested in our database but normally we use pipeline to ingest the file into a staging table and then a stored procedures with a match and merge T-SQL code to normalize the data and after that views that java developers can call. &lt;/p&gt;\n\n&lt;p&gt;I want to transform this in more a Data Engineer way using python, airflow etc. I&amp;#39;m SQL Developer but I have some knowledge in python and some data engineer tools.&lt;/p&gt;\n\n&lt;p&gt;I would like to know your opinion and what I could do to make this process more modern and use more data engineering tools and not just T-SQL code. If possible using only open-source tools.&lt;/p&gt;\n\n&lt;p&gt;TIA.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174q4x7", "is_robot_indexable": true, "report_reasons": null, "author": "peixinho3", "discussion_type": null, "num_comments": 5, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174q4x7/alternative_method_for_a_sql_server_tsql_etl/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174q4x7/alternative_method_for_a_sql_server_tsql_etl/", "subreddit_subscribers": 133102, "created_utc": 1696957082.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_6qpanfe", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "lkml2cube \u2014 Python tool for Looker to Cube migration", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 73, "top_awarded_type": null, "hide_score": false, "name": "t3_174p08y", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/GozUw7rjDqDnEWxOLuOQx3_1TmMF9JnqnGL1gTr-ILM.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "link", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696954215.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "cube.dev", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://cube.dev/blog/introducing-a-tool-for-looker-to-cube-migration", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?auto=webp&amp;s=b8eba6ffc77a44754baf05f96de17f030efb060f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=383c436589031515ff8397aedca4f5b01a0d4975", "width": 108, "height": 56}, {"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=fde98a1c0b9bf8b65edbe8060349c707a4d9668f", "width": 216, "height": 113}, {"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=a68b94465cfab03d609b94d4be932d2595c1d586", "width": 320, "height": 168}, {"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=d436ec35787d4ce31655cee673aa0977ac88b71e", "width": 640, "height": 336}, {"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=87c6b8d6eee163118e7d71a3167d88c56761da52", "width": 960, "height": 504}, {"url": "https://external-preview.redd.it/xJUtM_iAi00Ma8HJBNNiEuVUjg-bp3NUbqHviNsXATk.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=6cdb3d80b9ba7698ee60180bedda92b27ab1db7a", "width": 1080, "height": 567}], "variants": {}, "id": "YN4ONYvMYrtjTMi361aNDScXaUCDC4BoWTi_F_Fd1wE"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "174p08y", "is_robot_indexable": true, "report_reasons": null, "author": "igorlukanin", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174p08y/lkml2cube_python_tool_for_looker_to_cube_migration/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://cube.dev/blog/introducing-a-tool-for-looker-to-cube-migration", "subreddit_subscribers": 133102, "created_utc": 1696954215.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Basically I did some basic sql projects where I have generated insights through sql queries but now I want to create a schema with er diagrams in it any help/tips will be appreaciated", "author_fullname": "t2_6ybces6n", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Help needed regarding SQL Project ideas", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174opdw", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 1.0, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Help", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696953483.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Basically I did some basic sql projects where I have generated insights through sql queries but now I want to create a schema with er diagrams in it any help/tips will be appreaciated&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ea0027", "id": "174opdw", "is_robot_indexable": true, "report_reasons": null, "author": "Narrow-Tea-9187", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174opdw/help_needed_regarding_sql_project_ideas/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174opdw/help_needed_regarding_sql_project_ideas/", "subreddit_subscribers": 133102, "created_utc": 1696953483.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "I've been a web application developer for years, just changed to a new data-science related work .  I was asked to give a software solution for data storage. It should be open sourced and good for enterprise-class usage. The data are all kind of forms with metadata and should be distributed stored with duplicate copy. In the future they could introduce ML for further analysis. I have studied ElasticSearch and Hadoop, ElasticSearch can ingest un-structured data as well as indexing and searching (even vector searching) , Hadoop HDFS can do distributed storage. in addition AWS Cloud offers everything we need (S3, RDS, Redshift). But none of them are up-to-date or a open source solution. Any suggestions ?", "author_fullname": "t2_bw4lhoaj3", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Any open source solution for enterprise class data storage", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174u7a3", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.33, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Discussion", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": true, "mod_note": null, "created": 1696967117.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been a web application developer for years, just changed to a new data-science related work .  I was asked to give a software solution for data storage. It should be open sourced and good for enterprise-class usage. The data are all kind of forms with metadata and should be distributed stored with duplicate copy. In the future they could introduce ML for further analysis. I have studied ElasticSearch and Hadoop, ElasticSearch can ingest un-structured data as well as indexing and searching (even vector searching) , Hadoop HDFS can do distributed storage. in addition AWS Cloud offers everything we need (S3, RDS, Redshift). But none of them are up-to-date or a open source solution. Any suggestions ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "92b74b58-aaca-11eb-b160-0e6181e3773f", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#ff4500", "id": "174u7a3", "is_robot_indexable": true, "report_reasons": null, "author": "Some-Birthday9503", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174u7a3/any_open_source_solution_for_enterprise_class/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174u7a3/any_open_source_solution_for_enterprise_class/", "subreddit_subscribers": 133102, "created_utc": 1696967117.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_csphaytka", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "Meet the MinIO Engineers: Harshavardhana - Object Handling", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": 105, "top_awarded_type": null, "hide_score": false, "name": "t3_174ti37", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "ups": 0, "total_awards_received": 0, "media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zFvR83BdAKw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Meet the MinIO Engineers: Harshavardhana - Object Handling\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "height": 200}, "thumbnail_width": 140, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Meet the MinIO Engineers: Harshavardhana - Object Handling", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zFvR83BdAKw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Meet the MinIO Engineers: Harshavardhana - Object Handling\"&gt;&lt;/iframe&gt;", "author_name": "MinIO", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/zFvR83BdAKw/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MINIO"}}, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {"content": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zFvR83BdAKw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Meet the MinIO Engineers: Harshavardhana - Object Handling\"&gt;&lt;/iframe&gt;", "width": 356, "scrolling": false, "media_domain_url": "https://www.redditmedia.com/mediaembed/174ti37", "height": 200}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "https://b.thumbs.redditmedia.com/uc2f-g3MAlENyidlkLTxE3Jf9mwrn7OYWjCBu2QgdqU.jpg", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "rich:video", "content_categories": null, "is_self": false, "subreddit_type": "public", "created": 1696965422.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "youtube.com", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://www.youtube.com/watch?v=zFvR83BdAKw&amp;utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=meet_engineers_harsha+", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/Vdc46Oe3WKUe_Gw_okATqk1WILYAHpzhxYLp0G50c9w.jpg?auto=webp&amp;s=e56c12f7e4c8df6ed5549c68754c5ddb633499f4", "width": 480, "height": 360}, "resolutions": [{"url": "https://external-preview.redd.it/Vdc46Oe3WKUe_Gw_okATqk1WILYAHpzhxYLp0G50c9w.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=84e75d8a6d6c9c9aa661303756a62847b48c03b2", "width": 108, "height": 81}, {"url": "https://external-preview.redd.it/Vdc46Oe3WKUe_Gw_okATqk1WILYAHpzhxYLp0G50c9w.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=5773b808764d0fd3ccfa4f8f0171c7c69e3a498a", "width": 216, "height": 162}, {"url": "https://external-preview.redd.it/Vdc46Oe3WKUe_Gw_okATqk1WILYAHpzhxYLp0G50c9w.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=55c11c8ce50a8c641cc442983a39a6ebfd12540e", "width": 320, "height": 240}], "variants": {}, "id": "A2JpYaaxlaQLNLNz5LlPT0zHbt58OiyIoKtGWkQjBjg"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "mod_note": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "num_reports": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "174ti37", "is_robot_indexable": true, "report_reasons": null, "author": "swodtke", "discussion_type": null, "num_comments": 0, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174ti37/meet_the_minio_engineers_harshavardhana_object/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://www.youtube.com/watch?v=zFvR83BdAKw&amp;utm_source=reddit&amp;utm_medium=organic-social+&amp;utm_campaign=meet_engineers_harsha+", "subreddit_subscribers": 133102, "created_utc": 1696965422.0, "num_crossposts": 0, "media": {"type": "youtube.com", "oembed": {"provider_url": "https://www.youtube.com/", "version": "1.0", "title": "Meet the MinIO Engineers: Harshavardhana - Object Handling", "type": "video", "thumbnail_width": 480, "height": 200, "width": 356, "html": "&lt;iframe width=\"356\" height=\"200\" src=\"https://www.youtube.com/embed/zFvR83BdAKw?feature=oembed&amp;enablejsapi=1\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen title=\"Meet the MinIO Engineers: Harshavardhana - Object Handling\"&gt;&lt;/iframe&gt;", "author_name": "MinIO", "provider_name": "YouTube", "thumbnail_url": "https://i.ytimg.com/vi/zFvR83BdAKw/hqdefault.jpg", "thumbnail_height": 360, "author_url": "https://www.youtube.com/@MINIO"}}, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "Hi guys, \n\nLooking to do a DE bootcamp which is govt funded in the UK,  after contemplating between this and devops, I think as a beginner this would be the appropriate way to go and something I would actually enjoy\n\nI'm checking out various options, could you guys please share your thoughts on the syllabus and the projects mentioned in the course if it's any good and would it be able to get me somewhat ready for the industry or should I avoid ?\n\nhttps://www.theaicore.com/course\n\nMy only concern is I read one negative review on them here on reddit, which said most of their teachers are former students and their is not much help in getting actual interviews or into the industry itself , however there is also very little to go on tbf, I do understand bootcamp rep also matters because not all are the same either, but I want to give myself the best chance possible to start a new career, please advise, thanks.", "author_fullname": "t2_4jsiips8", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "AI Core Bootcamp ?", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174myur", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.67, "author_flair_background_color": null, "subreddit_type": "public", "ups": 1, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Career", "can_mod_post": false, "score": 1, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "self", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "post_hint": "self", "content_categories": null, "is_self": true, "mod_note": null, "created": 1696949001.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "self.dataengineering", "allow_live_comments": false, "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi guys, &lt;/p&gt;\n\n&lt;p&gt;Looking to do a DE bootcamp which is govt funded in the UK,  after contemplating between this and devops, I think as a beginner this would be the appropriate way to go and something I would actually enjoy&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m checking out various options, could you guys please share your thoughts on the syllabus and the projects mentioned in the course if it&amp;#39;s any good and would it be able to get me somewhat ready for the industry or should I avoid ?&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.theaicore.com/course\"&gt;https://www.theaicore.com/course&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;My only concern is I read one negative review on them here on reddit, which said most of their teachers are former students and their is not much help in getting actual interviews or into the industry itself , however there is also very little to go on tbf, I do understand bootcamp rep also matters because not all are the same either, but I want to give myself the best chance possible to start a new career, please advise, thanks.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "likes": null, "suggested_sort": null, "banned_at_utc": null, "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "preview": {"images": [{"source": {"url": "https://external-preview.redd.it/RCRG1-58lhjlZv1LaNLfcknuuzYvLbI_3sIEWzkxdmM.jpg?auto=webp&amp;s=6cbaa5437c0d2b8d84feba3d743b207825134f3c", "width": 1240, "height": 610}, "resolutions": [{"url": "https://external-preview.redd.it/RCRG1-58lhjlZv1LaNLfcknuuzYvLbI_3sIEWzkxdmM.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=81b002951daa012ecc56322c603051216e32ec93", "width": 108, "height": 53}, {"url": "https://external-preview.redd.it/RCRG1-58lhjlZv1LaNLfcknuuzYvLbI_3sIEWzkxdmM.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b111a20bf237ab20f25c6af398e5f5e7befee8e1", "width": 216, "height": 106}, {"url": "https://external-preview.redd.it/RCRG1-58lhjlZv1LaNLfcknuuzYvLbI_3sIEWzkxdmM.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=db669cee24bb1e832d29ee9427863bd43a5eaab7", "width": 320, "height": 157}, {"url": "https://external-preview.redd.it/RCRG1-58lhjlZv1LaNLfcknuuzYvLbI_3sIEWzkxdmM.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=170994247e2eba0c1c5c4bb25e729df5f57688ab", "width": 640, "height": 314}, {"url": "https://external-preview.redd.it/RCRG1-58lhjlZv1LaNLfcknuuzYvLbI_3sIEWzkxdmM.jpg?width=960&amp;crop=smart&amp;auto=webp&amp;s=f0d42bfe08a51e8ea00c2cc58434c5bf8a1771ad", "width": 960, "height": 472}, {"url": "https://external-preview.redd.it/RCRG1-58lhjlZv1LaNLfcknuuzYvLbI_3sIEWzkxdmM.jpg?width=1080&amp;crop=smart&amp;auto=webp&amp;s=be4550e87be5d00b9dfa0576e97c3f06df0941e5", "width": 1080, "height": 531}], "variants": {}, "id": "qBElg6l4Bmzpo_AONeuGwPp4lJLqCIF5bvY1xq4O4h8"}], "enabled": false}, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "069dd614-a7dc-11eb-8e48-0e90f49436a3", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#349e48", "id": "174myur", "is_robot_indexable": true, "report_reasons": null, "author": "saqi786x", "discussion_type": null, "num_comments": 1, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174myur/ai_core_bootcamp/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://old.reddit.com/r/dataengineering/comments/174myur/ai_core_bootcamp/", "subreddit_subscribers": 133102, "created_utc": 1696949001.0, "num_crossposts": 0, "media": null, "is_video": false}}, {"kind": "t3", "data": {"approved_at_utc": null, "subreddit": "dataengineering", "selftext": "", "author_fullname": "t2_y9qpd", "saved": false, "mod_reason_title": null, "gilded": 0, "clicked": false, "title": "I created a tool that navigates the Internet and scrapes data using GPT-4", "link_flair_richtext": [], "subreddit_name_prefixed": "r/dataengineering", "hidden": false, "pwls": 6, "link_flair_css_class": "", "downs": 0, "thumbnail_height": null, "top_awarded_type": null, "hide_score": false, "name": "t3_174jlsf", "quarantine": false, "link_flair_text_color": "light", "upvote_ratio": 0.5, "author_flair_background_color": null, "subreddit_type": "public", "ups": 0, "total_awards_received": 0, "media_embed": {}, "thumbnail_width": null, "author_flair_template_id": null, "is_original_content": false, "user_reports": [], "secure_media": null, "is_reddit_media_domain": false, "is_meta": false, "category": null, "secure_media_embed": {}, "link_flair_text": "Blog", "can_mod_post": false, "score": 0, "approved_by": null, "is_created_from_ads_ui": false, "author_premium": false, "thumbnail": "default", "edited": false, "author_flair_css_class": null, "author_flair_richtext": [], "gildings": {}, "content_categories": null, "is_self": false, "mod_note": null, "created": 1696939855.0, "link_flair_type": "text", "wls": 6, "removed_by_category": null, "banned_by": null, "author_flair_type": "text", "domain": "singleapi.co", "allow_live_comments": false, "selftext_html": null, "likes": null, "suggested_sort": null, "banned_at_utc": null, "url_overridden_by_dest": "https://singleapi.co/", "view_count": null, "archived": false, "no_follow": true, "is_crosspostable": false, "pinned": false, "over_18": false, "all_awardings": [], "awarders": [], "media_only": false, "link_flair_template_id": "eb739554-a7db-11eb-95d7-0ec0f8f30313", "can_gild": false, "spoiler": false, "locked": false, "author_flair_text": null, "treatment_tags": [], "visited": false, "removed_by": null, "num_reports": null, "distinguished": null, "subreddit_id": "t5_36en4", "author_is_blocked": false, "mod_reason_by": null, "removal_reason": null, "link_flair_background_color": "#0079d3", "id": "174jlsf", "is_robot_indexable": true, "report_reasons": null, "author": "semanser", "discussion_type": null, "num_comments": 3, "send_replies": true, "whitelist_status": "all_ads", "contest_mode": false, "mod_reports": [], "author_patreon_flair": false, "author_flair_text_color": null, "permalink": "/r/dataengineering/comments/174jlsf/i_created_a_tool_that_navigates_the_internet_and/", "parent_whitelist_status": "all_ads", "stickied": false, "url": "https://singleapi.co/", "subreddit_subscribers": 133102, "created_utc": 1696939855.0, "num_crossposts": 0, "media": null, "is_video": false}}], "before": null}}